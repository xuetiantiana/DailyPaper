{
  "data": [
    {
      "id": "2507.17753",
      "abstract": "Large Language Model (LLM) agents are increasingly utilized in AI-aided education to support tutoring and learning. Effective communication strategies among LLM agents improve collaborative problem-solving efficiency and facilitate cost-effective adoption in education. However, little research has systematically evaluated the impact of different communication strategies on agents' problem-solving. Our study examines four communication modes, \\textit{teacher-student interaction}, \\textit{peer-to-peer collaboration}, \\textit{reciprocal peer teaching}, and \\textit{critical debate}, in a dual-agent, chat-based mathematical problem-solving environment using the OpenAI GPT-4o model. Evaluated on the MATH dataset, our results show that dual-agent setups outperform single agents, with \\textit{peer-to-peer collaboration} achieving the highest accuracy. Dialogue acts like statements, acknowledgment, and hints play a key role in collaborative problem-solving. While multi-agent frameworks enhance computational tasks, effective communication strategies are essential for tackling complex problems in AI education.",
      "authors": [
        "Liang Zhang",
        "Xiaoming Zhai",
        "Jionghao Lin",
        "Jionghao Lin",
        "Jennifer Kleiman",
        "Diego Zapata-Rivera",
        "Carol Forsyth",
        "Yang Jiang",
        "Xiangen Hu",
        "Arthur C. Graesser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T03:31:14+00:00",
          "link": "https://arxiv.org/abs/2507.17753v1",
          "size": "1250kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Communication Strategies for Collaborative LLM Agents in Mathematical Problem-Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17753",
        "HTML": "https://arxiv.org/html/2507.17753v1",
        "PDF": "https://arxiv.org/pdf/2507.17753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores communication strategies for collaborative LLM agents in mathematical problem-solving, which does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17754",
      "abstract": "Clinician burnout has motivated the growing adoption of ambient medical scribes in the clinic. In this work, we introduce a custom-built ambient scribe application integrated into the EHR system at Included Health, a personalized all-in-one healthcare company offering telehealth services. The application uses Whisper for transcription and a modular in-context learning pipeline with GPT-4o to automatically generate SOAP notes and patient instructions. Testing on mock visit data shows that the notes generated by the application exceed the quality of expert-written notes as determined by an LLM-as-a-judge. The application has been widely adopted by the clinical practice, with over 540 clinicians at Included Health using the application at least once. 94% (n = 63) of surveyed clinicians report reduced cognitive load during visits and 97% (n = 66) report less documentation burden when using the application. Additionally, we show that post-processing notes with a fine-tuned BART model improves conciseness. These findings highlight the potential for AI systems to ease administrative burdens and support clinicians in delivering efficient, high-quality care.",
      "authors": [
        "Justin Morse",
        "Kurt Gilbert",
        "Kyle Shin",
        "Rick Cooke",
        "Peyton Rose",
        "Jack Sullivan",
        "Angelo Sisante"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T14:10:03+00:00",
          "link": "https://arxiv.org/abs/2507.17754v1",
          "size": "493kb",
          "version": "v1"
        }
      ],
      "title": "A Custom-Built Ambient Scribe Reduces Cognitive Load and Documentation Burden for Telehealth Clinicians",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17754",
        "PDF": "https://arxiv.org/pdf/2507.17754"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses generating and post-processing clinical notes using LLMs, which may involve some data processing aspects, the main focus is on application in telehealth rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17755",
      "abstract": "In the digital era, social media platforms play a pivotal role in shaping adolescents' body image perceptions. This study examines how Douyin and WeChat, two contrasting Chinese social media platforms, influence body image among Chinese male adolescents. Employing a platformization perspective, we surveyed 395 male adolescents aged 10 to 24 using the Multidimensional Body-Self Relations Questionnaire-Appearance Scales (MBSRQ-AS) to assess self-evaluation and body satisfaction. Our findings reveal that Douyin usage is significantly correlated with appearance evaluation and body area satisfaction, while WeChat usage shows no significant correlation with any body image dimensions. These results suggest that Douyin's algorithm-driven, video-centric environment intensifies exposure to idealized body standards, impacting users at a cognitive level. This study underscores the importance of considering platform-specific characteristics in understanding social media's impact on body image. It contributes to the broader discourse on how technological design and content modalities mediate psychological outcomes, offering insights for addressing body image concerns among male adolescents in China.",
      "authors": [
        "Jianfeng Lan and Yingjia Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T16:13:46+00:00",
          "link": "https://arxiv.org/abs/2507.17755v1",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "title": "Between Filters and Feeds: Investigating Douyin and WeChat's Influence on Chinese Adolescent Body Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17755",
        "PDF": "https://arxiv.org/pdf/2507.17755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates the influence of social media on body image among adolescents, which is unrelated to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17756",
      "abstract": "This study investigates how railway professionals perceive safety as a concept within rail, with the intention to help inform future technological developments within the industry. Through a series of interviews with drivers, route planners,and administrative personnel, the research explores the currentstate of safety practices, the potential for automation and the understanding of the railway as a system of systems. Key findings highlight a cautious attitude towards automation, a preference for assistive technologies, and a complex understanding of safety that integrates human, systematic and technological factors. The study also addresses the limitations of transferring automotive automation technologies to railways and the need for a railway-specific causation model to better evaluate and enhance safety in an evolving technological landscape. This study aims to bridge thegap between contemporary research and practical applications, contributing to the development of more effective safety metrics.",
      "authors": [
        "Josh Hunter",
        "John McDermid",
        "Simon Burton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T13:12:06+00:00",
          "link": "https://arxiv.org/abs/2507.17756v1",
          "size": "680kb",
          "version": "v1"
        }
      ],
      "title": "Insights from Railway Professionals: Rethinking Railway assumptions regarding safety and autonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17756",
        "HTML": "https://arxiv.org/html/2507.17756v1",
        "PDF": "https://arxiv.org/pdf/2507.17756"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines safety and autonomy in railways, focusing on human and technological factors in safety practices, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17757",
      "abstract": "Background: Type 1 diabetes (T1D) has seen a rapid evolution in management technology and forms a useful case study for the future management of other chronic conditions. Further development of this management technology requires an exploration of its real-world use and the potential of additional data streams. To facilitate this, we contribute the BrisT1D Dataset to the growing number of public T1D management datasets. The dataset was developed from a longitudinal study of 24 young adults in the UK who used a smartwatch alongside their usual T1D management. Findings: The BrisT1D dataset features both device data from the T1D management systems and smartwatches used by participants, as well as transcripts of monthly interviews and focus groups conducted during the study. The device data is provided in a processed state, for usability and more rapid analysis, and in a raw state, for in-depth exploration of novel insights captured in the study. Conclusions: This dataset has a range of potential applications. The quantitative elements can support blood glucose prediction, hypoglycaemia prediction, and closed-loop algorithm development. The qualitative elements enable the exploration of user experiences and opinions, as well as broader mixed-methods research into the role of smartwatches in T1D management.",
      "authors": [
        "Sam Gordon James",
        "Miranda Elaine Glynis Armstrong",
        "Aisling Ann O'Kane",
        "Harry Emerson and Zahraa S. Abdallah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T07:50:42+00:00",
          "link": "https://arxiv.org/abs/2507.17757v1",
          "size": "246kb",
          "version": "v1"
        }
      ],
      "title": "BrisT1D Dataset: Young Adults with Type 1 Diabetes in the UK using Smartwatches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17757",
        "PDF": "https://arxiv.org/pdf/2507.17757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The BrisT1D Dataset focuses on health data from Type 1 diabetes management using smartwatches. It has no relevance to LLM training data processing, as it is centered around healthcare applications and data management rather than language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17758",
      "abstract": "This paper explores the integration of generative AI into the fashion design process. Drawing on insights from the January 2025 seminar ``Tisser le futur,'' it investigates how AI reshapes creative workflows, from ideation to prototyping, while interrogating the ethical, aesthetic, and labor implications. The paper highlights co-creative dynamics between humans and machines, the potential for aesthetic innovation, and the environmental and cultural challenges of algorithmic design.",
      "authors": [
        "Pierre-Marie Chauvin",
        "Ang\\`ele Merlin",
        "Xavier Fresquet",
        "Hugo Caselles-Dupr\\'e",
        "Benjamin Simmenauer (IFM",
        "AHP-PReST)",
        "Mathieu de Fayet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T09:16:20+00:00",
          "link": "https://arxiv.org/abs/2507.17758v1",
          "size": "12944kb",
          "version": "v1"
        }
      ],
      "title": "Weaving the Future: Generative AI and the Reimagining of Fashion Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17758",
        "PDF": "https://arxiv.org/pdf/2507.17758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the use of generative AI in fashion design. It does not address any aspect of training data processing for LLMs, as it focuses on creative workflows and the integration of AI in design rather than data used in language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17759",
      "abstract": "Traditional hostel management practices in academic institutions often suffer from inefficiencies, delays, and fragmented communication. These systems fail to meet the expectations of digitally native students and place a significant operational burden on hostel staff. This paper introduces DHMS (Digital Hostel Management System), a modular and integrated platform designed to digitize and streamline essential hostel management functions. DHMS leverages modern web technologies, artificial intelligence, and cloud infrastructure to automate room allotment, grievance redressal, gate pass logistics, and communication via a natural language chatbot. In simulation tests, DHMS achieved a 92% student satisfaction rate in room allocation and maintained an average chatbot response time below one second. Additional features include predictive analytics for proactive maintenance planning and sentiment analysis for feedback processing. While promising, the system requires further testing for integration across multiple hostel blocks, user acceptance, scalability under load, and ERP compatibility before campus-wide deployment. This work discusses the system architecture, implementation approach, and factors critical to improving user experience, administrative efficiency, and decision-making processes.",
      "authors": [
        "Riddhi Heda",
        "Sidhant Singh",
        "Umair Yasir",
        "Tanmay Jaiswal",
        "Anil Mokhade"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T14:06:56+00:00",
          "link": "https://arxiv.org/abs/2507.17759v1",
          "size": "489kb",
          "version": "v1"
        }
      ],
      "title": "DHMS: A Digital Hostel Management System Integrating Campus ChatBot, Predictive Intelligence, and Real-Time Automation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17759",
        "HTML": "https://arxiv.org/html/2507.17759v1",
        "PDF": "https://arxiv.org/pdf/2507.17759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a digital hostel management system that employs AI for automation and efficiency improvements in hospitality settings. It does not involve any LLM training data processing or datasets relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17760",
      "abstract": "Supporting students in developing effective diagnostic reasoning is a key challenge in various educational domains. Novices often struggle with cognitive biases such as premature closure and over-reliance on heuristics. Scenario-based learning (SBL) can address these challenges by offering realistic case experiences and iterative practice, but the optimal sequencing of instruction and problem-solving activities remains unclear. This study examines how personalized support can be incorporated into different instructional sequences and whether providing explicit diagnostic strategy instruction before (I-PS) or after problem-solving (PS-I) improves learning and its transfer. We employ a between-groups design in an online SBL environment called PharmaSim, which simulates real-world client interactions for pharmacy technician apprentices. Results indicate that while both instruction types are beneficial, PS-I leads to significantly higher performance in transfer tasks.",
      "authors": [
        "Fatma Bet\\\"ul G\\\"ure\\c{s}",
        "Tanya Nazaretsky",
        "Bahar Radmehr",
        "Martina Rau",
        "Tanja K\\\"aser"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T14:43:57+00:00",
          "link": "https://arxiv.org/abs/2507.17760v1",
          "size": "2898kb",
          "version": "v1"
        }
      ],
      "title": "How Instructional Sequence and Personalized Support Impact Diagnostic Strategy Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17760",
        "HTML": "https://arxiv.org/html/2507.17760v1",
        "PDF": "https://arxiv.org/pdf/2507.17760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines instructional approaches for improving diagnostic reasoning in educational settings. The focus is on educational methodologies rather than data processing for LLMs, making it irrelevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17761",
      "abstract": "Modern AI systems are complex workflows containing multiple components and data sources. Data provenance provides the ability to interrogate and potentially explain the outputs of these systems. However, provenance is often too detailed and not contextualized for the user trying to understand the AI system. In this work, we present our vision for an interactive agent that works together with the user to co-construct an explanation that is simultaneously useful to the user as well as grounded in data provenance. To illustrate this vision, we present: 1) an initial prototype of such an agent; and 2) a scalable evaluation framework based on user simulations and a large language model as a judge approach.",
      "authors": [
        "Jan-Christoph Kalo",
        "Fina Polat",
        "Shubha Guha",
        "Paul Groth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T20:52:41+00:00",
          "link": "https://arxiv.org/abs/2507.17761v1",
          "size": "492kb",
          "version": "v1"
        }
      ],
      "title": "Co-constructing Explanations for AI Systems using Provenance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17761",
        "HTML": "https://arxiv.org/html/2507.17761v1",
        "PDF": "https://arxiv.org/pdf/2507.17761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a system involving data provenance to explain AI outputs. While related to understanding AI systems, it does not involve data processing operations specific to LLM training, making it irrelevant to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17766",
      "abstract": "In August 2024, Bittensor's Subnet 9 (SN9) demonstrated that a distributed network of incentivized, permissionless actors could each pretrain large language models (LLMs) ranging from 700 million to 14 billion parameters, while surpassing established baselines. While that work validated blockchain-based decentralized pretraining as viable, it contained core issues: (i) every miner had to fit an entire model locally, and (ii) \"winner-takes-all\" rewards encouraged model hoarding.\n  Here we introduce IOTA (Incentivized Orchestrated Training Architecture), an architecture that addresses these limitations by transforming SN9's previously isolated competitors into a single cooperating unit that can scale arbitrarily while still rewarding each contributor fairly.\n  Key preliminary results: (1) Data- and Pipeline-parallel SWARM architecture - An orchestrator distributes model layers across heterogeneous miners and streams activations between them, enabling model sizes to scale with the number of participants rather than being constrained by the VRAM of a single machine; (2) Granular, continuous incentives - Validators measure each miner's contribution and allocate token emissions proportionally; (3) Activation compression - We used model-bottlenecks to cut communication bandwidths of activations by up to 128x, vastly improving training speed; (4) Butterfly All-Reduce - Miners average disjoint parameter slices in O(1) bandwidth, offering linear scalability, redundancy and built-in collusion detection; (5) CLASP (Contribution Loss Assessment via Sampling of Pathways) - A fair attribution scheme assigns credit to miners proportional to their marginal utility and detects exploits, even when contributions are interdependent across the pipeline.",
      "authors": [
        "Felix Quinque",
        "Alan Aboudib",
        "Szymon Fonau",
        "Rodrigo Lopez Portillo Alcocer",
        "Brian McCrindle",
        "Steffen Cruz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:16:21+00:00",
          "link": "https://arxiv.org/abs/2507.17766v1",
          "size": "8343kb",
          "version": "v1"
        }
      ],
      "title": "Incentivised Orchestrated Training Architecture (IOTA): A Technical Primer for Release",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17766",
        "HTML": "https://arxiv.org/html/2507.17766v1",
        "PDF": "https://arxiv.org/pdf/2507.17766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While this paper presents a new architecture for distributed LLM pretraining, it does not focus on training data processing or dataset creation, which are essential criteria."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17768",
      "abstract": "With the development of mobile and edge computing, the demand for low-bit quantized models on edge devices is increasing to achieve efficient deployment. To enhance the performance, it is often necessary to retrain the quantized models using edge data. However, due to privacy concerns, certain sensitive data can only be processed on edge devices. Therefore, employing Quantization-Aware Training (QAT) on edge devices has become an effective solution. Nevertheless, traditional QAT relies on the complete dataset for training, which incurs a huge computational cost. Coreset selection techniques can mitigate this issue by training on the most representative subsets. However, existing methods struggle to eliminate quantization errors in the model when using small-scale datasets (e.g., only 10% of the data), leading to significant performance degradation. To address these issues, we propose QuaRC, a QAT framework with coresets on edge devices, which consists of two main phases: In the coreset selection phase, QuaRC introduces the ``Relative Entropy Score\" to identify the subsets that most effectively capture the model's quantization errors. During the training phase, QuaRC employs the Cascaded Layer Correction strategy to align the intermediate layer outputs of the quantized model with those of the full-precision model, thereby effectively reducing the quantization errors in the intermediate layers. Experimental results demonstrate the effectiveness of our approach. For instance, when quantizing ResNet-18 to 2-bit using a 1% data subset, QuaRC achieves a 5.72% improvement in Top-1 accuracy on the ImageNet-1K dataset compared to state-of-the-art techniques.",
      "authors": [
        "Yujia Tong",
        "Jingling Yuan",
        "Chuang Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:19:33+00:00",
          "link": "https://arxiv.org/abs/2507.17768v1",
          "size": "994kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17768",
        "HTML": "https://arxiv.org/html/2507.17768v1",
        "PDF": "https://arxiv.org/pdf/2507.17768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for Quantization-Aware Training using coreset selection on edge devices, focusing on model compression rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17769",
      "abstract": "Advances in Large Language Models (LLMs) have led to a surge of LLM-powered applications. These applications have diverse token-generation latency requirements. As a result, simply classifying workloads as latency-sensitive (LS) or best-effort (BE) overlooks the nuances within the latency-sensitive category and results in suboptimal user experiences and scheduling opportunities. However, efficiently serving requests with multiple SLO requirements poses significant challenges. First, all requests within a batch generate new tokens simultaneously, which can misalign them with their distinct SLO requirements. Moreover, while existing systems focus on auto-scaling for handling various overall request rates, the diversity of SLOs necessitates fine-grained auto-scaling among these SLO tiers. Finally, unlike LS/BE scenarios, where BE requests can be aborted at any time to ensure the SLO attainment of LS requests, those with different latency-sensitive SLOs cannot tolerate prolonged delays, and tail latency must be controlled.\n  To tackle these challenges, we propose PolyServe, a novel multi-SLO scheduling policy at scale that maintains high SLO attainment while maximizing throughput. PolyServe first groups requests into multiple bins based on their per-token latency requirement, then schedules each bin to a subset of the server fleet. PolyServe routes requests to the highest-load but still SLO-attainable server to create a load gradient that facilitates auto-scaling. To increase utilization, PolyServe permits looser-SLO requests to share tighter-SLO instances when their own servers are saturated. PolyServe uses profiling data to guide scheduling decisions and manage tail latency through request-wait-time-aware scheduling, dynamic chunking, and continuous chunked prefill prediction. PolyServe achieves 1.23x goodput gain compared to existing policies, achieving up to 92.5% of optimal goodput.",
      "authors": [
        "Kan Zhu",
        "Haiyang Shi",
        "Le Xu",
        "Jiaxin Shan",
        "Arvind Krishnamurthy",
        "Baris Kasikci",
        "Liguang Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:54:42+00:00",
          "link": "https://arxiv.org/abs/2507.17769v1",
          "size": "423kb",
          "version": "v1"
        }
      ],
      "title": "PolyServe: Efficient Multi-SLO Serving at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17769",
        "HTML": "https://arxiv.org/html/2507.17769v1",
        "PDF": "https://arxiv.org/pdf/2507.17769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PolyServe addresses challenges in latency management for LLM-powered applications but does not involve any contributions to LLM training data processing or dataset quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17770",
      "abstract": "Quadratic Unconstrained Binary Optimization (QUBO) is a versatile framework for modeling combinatorial optimization problems. This study benchmarks five software-based QUBO solvers: Neal, PyTorch (CPU), PyTorch (GPU), JAX, and SciPy, on randomly generated QUBO matrices ranging from 1000x1000 to 45000x45000, under six convergence thresholds from 10^-1 to 10^-6. We evaluate their performance in terms of solution quality (energy) and computational time. Among the solvers tested, Neal achieved the lowest energy values but was limited to problems with up to 6000 variables due to high memory consumption. PyTorch produced slightly higher energy results than Neal but demonstrated superior scalability, solving instances with up to 45000 variables. Its support for GPU acceleration and CPU multi-threading also resulted in significantly shorter runtimes. JAX yielded energy values slightly above those of PyTorch and was limited to 25000 variables, with runtimes comparable to PyTorch on GPU. SciPy was the most constrained solver, handling only up to 6000 variables and consistently producing the highest energy values with the longest computation times. These findings highlight trade-offs between solution quality, scalability, and runtime efficiency, and suggest that PyTorch is the most balanced choice for large-scale QUBO problems when computational resources permit.",
      "authors": [
        "Pei-Kun Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:19:53+00:00",
          "link": "https://arxiv.org/abs/2507.17770v1",
          "size": "1115kb",
          "version": "v1"
        }
      ],
      "title": "Comparative Evaluation of PyTorch, JAX, SciPy, and Neal for Solving QUBO Problems at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17770",
        "PDF": "https://arxiv.org/pdf/2507.17770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking QUBO solvers and does not involve any aspect of LLM training data processing, such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17771",
      "abstract": "The emergence of heterogeneity and domain-specific architectures targeting deep learning inference show great potential for enabling the deployment of modern CNNs on resource-constrained embedded platforms. A significant development is the diversification of custom hardware solely targeting the most expensive parts of CNNs. DLAs (deep learning accelerators) and NPUs (neural processing units), among others, can overcome the approaching limits of traditional silicon scaling and provide a solution to the power/performance tradeoff within embedded SoCs. Efficient DSA utilization requires proper system integration and a compilation/execution model for balanced execution in these heterogeneous architectures. There is a critical need for proper system integration and an efficient compilation/execution model for balanced execution in these heterogeneous architectures. This work highlights the hardware integration challenges for efficiently placing these units within the memory hierarchy and correct proximity to other execution blocks. We experimentally verify performance bottlenecks in CNN execution and pre/post-processing at runtime, where previous attention has generally been given to accelerator speedup alone. This work takes advantage of the ratification of the RISC-V Vector 1.0 extension and demonstrates its potential as a flexible target within a well-suited cache hierarchy scheme to reduce pre-processing bottlenecks and CPU fallback processes. Our results show up to a 9x speedup of image pre-processing and YOLOv3 fallback layer execution by up to 3x compared to CPU. We demonstrate RVV-1.0 in exposing a flexible programming model that can enable a balanced computation and memory footprint on accelerator-rich embedded SoCs supporting modern deep-learning dataflows while consuming less power than traditional parallel execution platforms.",
      "authors": [
        "Dmitri Lyalikov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T00:57:54+00:00",
          "link": "https://arxiv.org/abs/2507.17771v1",
          "size": "1412kb",
          "version": "v1"
        }
      ],
      "title": "Flexible Vector Integration in Embedded RISC-V SoCs for End to End CNN Inference Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17771",
        "HTML": "https://arxiv.org/html/2507.17771v1",
        "PDF": "https://arxiv.org/pdf/2507.17771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses hardware and integration challenges in CNN inference on embedded SoCs, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17772",
      "abstract": "Federated Learning (FL) allows multiple distributed devices to jointly train a shared model without centralizing data, but communication cost remains a major bottleneck, especially in resource-constrained environments. This paper introduces caching strategies - FIFO, LRU, and Priority-Based - to reduce unnecessary model update transmissions. By selectively forwarding significant updates, our approach lowers bandwidth usage while maintaining model accuracy. Experiments on CIFAR-10 and medical datasets show reduced communication with minimal accuracy loss. Results confirm that intelligent caching improves scalability, memory efficiency, and supports reliable FL in edge IoT networks, making it practical for deployment in smart cities, healthcare, and other latency-sensitive applications.",
      "authors": [
        "Ahmad Alhonainy (1)",
        "Praveen Rao (1) ((1) University of Missouri",
        "USA)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:02:15+00:00",
          "link": "https://arxiv.org/abs/2507.17772v1",
          "size": "816kb",
          "version": "v1"
        }
      ],
      "title": "Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17772",
        "HTML": "https://arxiv.org/html/2507.17772v1",
        "PDF": "https://arxiv.org/pdf/2507.17772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses communication cost reduction in federated learning using caching strategies, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17773",
      "abstract": "The automatic generation of deep learning (DL) kernels using large language models (LLMs) has emerged as a promising approach to reduce the manual effort and hardware-specific expertise required for writing high-performance operator implementations. However, existing benchmarks for evaluating LLMs in this domain suffer from limited hardware support, coarse-grained kernel categorization, and imbalanced task coverage. To address these limitations, we introduce MultiKernelBench, the first comprehensive, multi-platform benchmark for LLM-based DL kernel generation. MultiKernelBench spans 285 tasks across 14 well-defined kernel categories and supports three major hardware platforms: Nvidia GPUs, Huawei NPUs, and Google TPUs. To enable future extensibility, we design a modular backend abstraction layer that decouples platform-specific logic from the core benchmarking infrastructure, allowing easy integration of new hardware platforms. We further propose a simple yet effective category-aware one-shot prompting method that improves generation quality by providing in-category exemplars. Through systematic evaluations of seven state-of-the-art LLMs, we reveal significant variation in task difficulty, poor generalization to platforms with less training exposure, and the effectiveness of targeted prompting strategies. MultiKernelBench is publicly available at https://github.com/wzzll123/MultiKernelBench.",
      "authors": [
        "Zhongzhen Wen",
        "Yinghui Zhang",
        "Zhong Li",
        "Zhongxin Liu",
        "Linna Xie",
        "Tian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T00:58:33+00:00",
          "link": "https://arxiv.org/abs/2507.17773v1",
          "size": "256kb",
          "version": "v1"
        }
      ],
      "title": "MultiKernelBench: A Multi-Platform Benchmark for Kernel Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17773",
        "HTML": "https://arxiv.org/html/2507.17773v1",
        "PDF": "https://arxiv.org/pdf/2507.17773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper is primarily about benchmarking LLM-based DL kernel generation, it briefly mentions the use of LLMs for generative tasks, which might involve some minimal data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17774",
      "abstract": "As artificial intelligence (AI) continues to evolve from a back-end computational tool into an interactive, generative collaborator, its integration into early-stage design processes demands a rethinking of traditional workflows in human-centered design. This paper explores the emergent paradigm of human-AI co-creation, where AI is not merely used for automation or efficiency gains, but actively participates in ideation, visual conceptualization, and decision-making. Specifically, we investigate the use of large language models (LLMs) like GPT-4 and multimodal diffusion models such as Stable Diffusion as creative agents that engage designers in iterative cycles of proposal, critique, and revision.",
      "authors": [
        "Zhangqi Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T04:29:33+00:00",
          "link": "https://arxiv.org/abs/2507.17774v1",
          "size": "942kb",
          "version": "v1"
        }
      ],
      "title": "Human-AI Co-Creation: A Framework for Collaborative Design in Intelligent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17774",
        "PDF": "https://arxiv.org/pdf/2507.17774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores human-AI co-creation in design processes with LLMs, focusing on AI's role as a creative agent rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17777",
      "abstract": "Unlike conventional Machine-Learning (ML) approaches, often criticized as \"black boxes\", Symbolic Regression (SR) stands out as a powerful tool for revealing interpretable mathematical relationships in complex physical systems, requiring no a priori assumptions about models' structures. Motivated by the recognition that, in fluid mechanics, an understanding of the underlying flow physics is as crucial as accurate prediction, this study applies SR to model a fundamental three-dimensional (3D) incompressible flow in a rectangular channel, focusing on the (axial) velocity and pressure fields under laminar conditions. By employing the PySR library, compact symbolic equations were derived directly from numerical simulation data, revealing key characteristics of the flow dynamics. These equations not only approximate the parabolic velocity profile and pressure drop observed in the studied fluid flow, but also perfectly coincide with analytical solutions from the literature. Furthermore, we propose an innovative approach that integrates SR with the knowledge-representation framework of Answer Set Programming (ASP), combining the generative power of SR with the declarative reasoning strengths of ASP. The proposed hybrid SR/ASP framework ensures that the SR-generated symbolic expressions are not only statistically accurate, but also physically plausible, adhering to domain-specific principles. Overall, the study highlights two key contributions: SR's ability to simplify complex flow behaviours into concise, interpretable equations, and the potential of knowledge-representation approaches to improve the reliability and alignment of data-driven SR models with domain principles. Insights from the examined 3D channel flow pave the way for integrating such hybrid approaches into efficient frameworks, [...] where explainable predictions and real-time data analysis are crucial.",
      "authors": [
        "Theofanis Aravanis",
        "Grigorios Chrimatopoulos",
        "Mohammad Ferdows",
        "Michalis Xenos",
        "Efstratios Em Tzirtzilakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T15:16:20+00:00",
          "link": "https://arxiv.org/abs/2507.17777v1",
          "size": "4135kb",
          "version": "v1"
        }
      ],
      "title": "ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17777",
        "HTML": "https://arxiv.org/html/2507.17777v1",
        "PDF": "https://arxiv.org/pdf/2507.17777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study revolves around applying symbolic regression and Answer Set Programming to fluid mechanics, and does not make contributions towards LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17778",
      "abstract": "Contemporary database systems, while effective, suffer severe issues related to complexity and usability, especially among individuals who lack technical expertise but are unfamiliar with query languages like Structured Query Language (SQL). This paper presents a new database system supported by Artificial Intelligence (AI), which is intended to improve the management of data using natural language processing (NLP) - based intuitive interfaces, and automatic creation of structured queries and semi-structured data formats like yet another markup language (YAML), java script object notation (JSON), and application program interface (API) documentation. The system is intended to strengthen the potential of databases through the integration of Large Language Models (LLMs) and advanced machine learning algorithms. The integration is purposed to allow the automation of fundamental tasks such as data modeling, schema creation, query comprehension, and performance optimization. We present in this paper a system that aims to alleviate the main problems with current database technologies. It is meant to reduce the need for technical skills, manual tuning for better performance, and the potential for human error. The AI database employs generative schema inference and format selection to build its schema models and execution formats.",
      "authors": [
        "M. Tedeschi",
        "S. Rizwan",
        "C. Shringi",
        "V. Devram Chandgir",
        "S. Belich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T16:10:45+00:00",
          "link": "https://arxiv.org/abs/2507.17778v1",
          "size": "1928kb",
          "version": "v1"
        }
      ],
      "title": "An advanced AI driven database system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17778",
        "PDF": "https://arxiv.org/pdf/2507.17778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses AI-driven database systems using LLMs, it focuses on database management rather than on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17780",
      "abstract": "We present four open conjectures in graph theory generated by the automated conjecturing system \\texttt{TxGraffiti}. Each conjecture is concise, grounded in natural graph invariants, and empirically validated across hundreds of graphs. Despite extensive effort, these statements remain unresolved--defying both proof and counterexample. They are not only mathematical challenges but creative expressions--born of symbolic pattern recognition and mathematician-defined heuristics, refined through years of human dialogue, and now offered back to the community as collaborative artifacts. These conjectures invite not only formal proof, but also reflection on how machines can evoke wonder, spark curiosity, and contribute to the raw material of discovery. By highlighting these problems, we aim to inspire both human mathematicians and AI systems to engage with them--not only to solve them, but to reflect on what it means when machines participate meaningfully in the creative process of mathematical thought.",
      "authors": [
        "Randy Davila",
        "Boris Brimkov",
        "and Ryan Pepper"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Artificial Intelligence (cs.AI)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:49:32+00:00",
          "link": "https://arxiv.org/abs/2507.17780v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17780",
        "HTML": "https://arxiv.org/html/2507.17780v1",
        "PDF": "https://arxiv.org/pdf/2507.17780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses open conjectures in graph theory developed by an automated system but does not address LLM training data processing, as there is no mention of data collection, filtering, or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17784",
      "abstract": "In this study, we design a low-complexity and generalized AI model that can capture common knowledge to improve data reconstruction of the channel decoder for semantic communication. Specifically, we propose a generative adversarial network that leverages causality-invariant learning to extract causal and non-causal representations from the data. Causal representations are invariant and encompass crucial information to identify the data's label. They can encapsulate semantic knowledge and facilitate effective data reconstruction at the receiver. Moreover, the causal mechanism ensures that learned representations remain consistent across different domains, making the system reliable even with users collecting data from diverse domains. As user-collected data evolves over time causing knowledge divergence among users, we design sparse update protocols to improve the invariant properties of the knowledge while minimizing communication overheads. Three key observations were drawn from our empirical evaluations. Firstly, causality-invariant knowledge ensures consistency across different devices despite the diverse training data. Secondly, invariant knowledge has promising performance in classification tasks, which is pivotal for goal-oriented semantic communications. Thirdly, our knowledge-based data reconstruction highlights the robustness of our decoder, which surpasses other state-of-the-art data reconstruction and semantic compression methods in terms of Peak Signal-to-Noise Ratio (PSNR).",
      "authors": [
        "Minh-Duong Nguyen",
        "Quoc-Viet Pham",
        "Nguyen H. Tran",
        "Hoang-Khoi Do",
        "Duy T. Ngo",
        "Won-Joo Hwang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:56:07+00:00",
          "link": "https://arxiv.org/abs/2507.17784v1",
          "size": "17677kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Abstraction for Knowledge-based Semantic Communication: A Generative Causality Invariant Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17784",
        "HTML": "https://arxiv.org/html/2507.17784v1",
        "PDF": "https://arxiv.org/pdf/2507.17784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semantic communication and generative adversarial networks for data reconstruction and classification, but does not involve LLM training data processing or dataset generation related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17785",
      "abstract": "Current research has found that some deep neural networks exhibit strong hierarchical self-similarity in feature representation or parameter distribution. However, aside from preliminary studies on how the power-law distribution of weights across different training stages affects model performance,there has been no quantitative analysis on how the self-similarity of hidden space geometry influences model weight optimization, nor is there a clear understanding of the dynamic behavior of internal neurons. Therefore, this paper proposes a complex network modeling method based on the output features of hidden-layer neurons to investigate the self-similarity of feature networks constructed at different hidden layers, and analyzes how adjusting the degree of self-similarity in feature networks can enhance the classification performance of deep neural networks. Validated on three types of networks MLP architectures, convolutional networks, and attention architectures this study reveals that the degree of self-similarity exhibited by feature networks varies across different model architectures. Furthermore, embedding constraints on the self-similarity of feature networks during the training process can improve the performance of self-similar deep neural networks (MLP architectures and attention architectures) by up to 6 percentage points.",
      "authors": [
        "Jingyi Ding",
        "Chengwen Qi",
        "Hongfei Wang",
        "Jianshe Wu",
        "Licheng Jiao",
        "Yuwei Guo",
        "Jian Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:01:53+00:00",
          "link": "https://arxiv.org/abs/2507.17785v1",
          "size": "1200kb",
          "version": "v1"
        }
      ],
      "title": "Self-similarity Analysis in Deep Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17785",
        "HTML": "https://arxiv.org/html/2507.17785v1",
        "PDF": "https://arxiv.org/pdf/2507.17785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research investigates self-similarity in deep neural networks, emphasizing feature representation and network architecture. It does not address any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17786",
      "abstract": "We introduce a reinforcement learning (RL) based adaptive optimization algorithm for aerodynamic shape optimization focused on dimensionality reduction. The form in which RL is applied here is that of a surrogate-based, actor-critic policy evaluation MCMC approach allowing for temporal 'freezing' of some of the parameters to be optimized. The goals are to minimize computational effort, and to use the observed optimization results for interpretation of the discovered extrema in terms of their role in achieving the desired flow-field.\n  By a sequence of local optimized parameter changes around intermediate CFD simulations acting as ground truth, it is possible to speed up the global optimization if (a) the local neighbourhoods of the parameters in which the changed parameters must reside are sufficiently large to compete with the grid-sized steps and its large number of simulations, and (b) the estimates of the rewards and costs on these neighbourhoods necessary for a good step-wise parameter adaption are sufficiently accurate. We give an example of a simple fluid-dynamical problem on which the method allows interpretation in the sense of a feature importance scoring.",
      "authors": [
        "Florian Sobieczky",
        "Alfredo Lopez",
        "Erika Dudkin",
        "Christopher Lackner",
        "Matthias Hochsteger",
        "Bernhard Scheichl",
        "Helmut Sobieczky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:14:25+00:00",
          "link": "https://arxiv.org/abs/2507.17786v1",
          "size": "1507kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning for Accelerated Aerodynamic Shape Optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17786",
        "PDF": "https://arxiv.org/pdf/2507.17786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning for aerodynamic shape optimization, which is not related to LLM training data processing or relevant to the creation or processing of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17787",
      "abstract": "Foundation models pre-trained on massive datasets, including large language models (LLMs), vision-language models (VLMs), and large multimodal models, have demonstrated remarkable success in diverse downstream tasks. However, recent studies have shown fundamental limitations of these models: (1) limited representational capacity, (2) lower adaptability, and (3) diminishing scalability. These shortcomings raise a critical question: is Euclidean geometry truly the optimal inductive bias for all foundation models, or could incorporating alternative geometric spaces enable models to better align with the intrinsic structure of real-world data and improve reasoning processes? Hyperbolic spaces, a class of non-Euclidean manifolds characterized by exponential volume growth with respect to distance, offer a mathematically grounded solution. These spaces enable low-distortion embeddings of hierarchical structures (e.g., trees, taxonomies) and power-law distributions with substantially fewer dimensions compared to Euclidean counterparts. Recent advances have leveraged these properties to enhance foundation models, including improving LLMs' complex reasoning ability, VLMs' zero-shot generalization, and cross-modal semantic alignment, while maintaining parameter efficiency. This paper provides a comprehensive review of hyperbolic neural networks and their recent development for foundation models. We further outline key challenges and research directions to advance the field.",
      "authors": [
        "Neil He",
        "Hiren Madhu",
        "Ngoc Bui",
        "Menglin Yang",
        "Rex Ying"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:50:17+00:00",
          "link": "https://arxiv.org/abs/2507.17787v1",
          "size": "2717kb",
          "version": "v1"
        }
      ],
      "title": "Hyperbolic Deep Learning for Foundation Models: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17787",
        "HTML": "https://arxiv.org/html/2507.17787v1",
        "PDF": "https://arxiv.org/pdf/2507.17787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey explores hyperbolic spaces for foundation models, including LLMs, but focuses on model architecture and reasoning processes rather than LLM training data processing operations or dataset improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17788",
      "abstract": "When using LLMs to rank items based on given criteria, or evaluate answers, the order of candidate items can influence the model's final decision. This sensitivity to item positioning in a LLM's prompt is known as position bias. Prior research shows that this bias exists even in large models, though its severity varies across models and tasks. In addition to position bias, LLMs also exhibit varying degrees of low repetition consistency, where repeating the LLM call with the same candidate ordering can lead to different rankings. To address both inconsistencies, a common approach is to prompt the model multiple times with different candidate orderings and aggregate the results via majority voting. However, this repetition strategy, significantly increases computational costs. Extending prior findings, we observe that both the direction -- favoring either the earlier or later candidate in the prompt -- and magnitude of position bias across instances vary substantially, even within a single dataset. This observation highlights the need for a per-instance mitigation strategy. To this end, we introduce a dynamic early-stopping method that adaptively determines the number of repetitions required for each instance. Evaluating our approach across three LLMs of varying sizes and on two tasks, namely re-ranking and alignment, we demonstrate that transitioning to a dynamic repetition strategy reduces the number of LLM calls by an average of 81%, while preserving the accuracy. Furthermore, we propose a confidence-based adaptation to our early-stopping method, reducing LLM calls by an average of 87% compared to static repetition, with only a slight accuracy trade-off relative to our original early-stopping method.",
      "authors": [
        "Ali Vardasbi",
        "Gustavo Penha",
        "Claudia Hauff",
        "and Hugues Bouchard"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:54:44+00:00",
          "link": "https://arxiv.org/abs/2507.17788v1",
          "size": "361kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Repetition for Mitigating Position Bias in LLM-Based Ranking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17788",
        "HTML": "https://arxiv.org/html/2507.17788v1",
        "PDF": "https://arxiv.org/pdf/2507.17788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses position bias and inconsistency in LLM-based ranking tasks, focusing on methods to dynamically reduce computational costs for repeated LLM calls. It does not discuss data processing for LLM training stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17791",
      "abstract": "Helix is an open-source, extensible, Python-based software framework to facilitate reproducible and interpretable machine learning workflows for tabular data. It addresses the growing need for transparent experimental data analytics provenance, ensuring that the entire analytical process -- including decisions around data transformation and methodological choices -- is documented, accessible, reproducible, and comprehensible to relevant stakeholders. The platform comprises modules for standardised data preprocessing, visualisation, machine learning model training, evaluation, interpretation, results inspection, and model prediction for unseen data. To further empower researchers without formal training in data science to derive meaningful and actionable insights, Helix features a user-friendly interface that enables the design of computational experiments, inspection of outcomes, including a novel interpretation approach to machine learning decisions using linguistic terms all within an integrated environment. Released under the MIT licence, Helix is accessible via GitHub and PyPI, supporting community-driven development and promoting adherence to the FAIR principles.",
      "authors": [
        "Eduardo Aguilar-Bejarano",
        "Daniel Lea",
        "Karthikeyan Sivakumar",
        "Jimiama M. Mase",
        "Reza Omidvar",
        "Ruizhe Li",
        "Troy Kettle",
        "James Mitchell-White",
        "Morgan R Alexander",
        "David A Winkler",
        "Grazziela Figueredo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:33:35+00:00",
          "link": "https://arxiv.org/abs/2507.17791v1",
          "size": "1747kb",
          "version": "v1"
        }
      ],
      "title": "Helix 1.0: An Open-Source Framework for Reproducible and Interpretable Machine Learning on Tabular Scientific Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17791",
        "PDF": "https://arxiv.org/pdf/2507.17791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Helix is a framework for machine learning on tabular data, focusing on reproducibility and interpretability. The paper does not address LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17792",
      "abstract": "To gain deeper insights into a complex sensor system through the lens of causality, we present common and individual causal mechanism estimation (CICME), a novel three-step approach to inferring causal mechanisms from heterogeneous data collected across multiple domains. By leveraging the principle of Causal Transfer Learning (CTL), CICME is able to reliably detect domain-invariant causal mechanisms when provided with sufficient samples. The identified common causal mechanisms are further used to guide the estimation of the remaining causal mechanisms in each domain individually. The performance of CICME is evaluated on linear Gaussian models under scenarios inspired from a manufacturing process. Building upon existing continuous optimization-based causal discovery methods, we show that CICME leverages the benefits of applying causal discovery on the pooled data and repeatedly on data from individual domains, and it even outperforms both baseline methods under certain scenarios.",
      "authors": [
        "Jingyi Yu",
        "Tim Pychynski",
        "and Marco F. Huber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:35:37+00:00",
          "link": "https://arxiv.org/abs/2507.17792v1",
          "size": "226kb",
          "version": "v1"
        }
      ],
      "title": "Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17792",
        "HTML": "https://arxiv.org/html/2507.17792v1",
        "PDF": "https://arxiv.org/pdf/2507.17792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for causal mechanism estimation in multi-sensor systems, which involves data collected across multiple domains. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17793",
      "abstract": "What if you could piece together your own custom biometrics and AI analysis system, a bit like LEGO blocks? We aim to bring that technology to field operators in the field who require flexible, high-performance edge AI system that can be adapted on a moment's notice. This paper introduces CHAMP (Configurable Hot-swappable Architecture for Machine Perception), a modular edge computing platform that allows operators to dynamically swap in specialized AI \"capability cartridges\" for tasks like face recognition, object tracking, and document analysis. CHAMP leverages low-power FPGA-based accelerators on a high-throughput bus, orchestrated by a custom operating system (VDiSK) to enable plug-and-play AI pipelines and cryptographically secured biometric datasets. In this paper we describe the CHAMP design, including its modular scaling with multiple accelerators and the VDiSK operating system for runtime reconfiguration, along with its cryptographic capabilities to keep data stored on modules safe and private. Experiments demonstrate near-linear throughput scaling from 1 to 5 neural compute accelerators, highlighting both the performance gains and saturation limits of the USB3-based bus. Finally, we discuss applications of CHAMP in field biometrics, surveillance, and disaster response, and outline future improvements in bus protocols, cartridge capabilities, and system software.",
      "authors": [
        "Joel Brogan",
        "Matthew Yohe",
        "David Cornett"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:46:33+00:00",
          "link": "https://arxiv.org/abs/2507.17793v1",
          "size": "3589kb",
          "version": "v1"
        }
      ],
      "title": "CHAMP: A Configurable, Hot-Swappable Edge Architecture for Adaptive Biometric Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17793",
        "HTML": "https://arxiv.org/html/2507.17793v1",
        "PDF": "https://arxiv.org/pdf/2507.17793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "CHAMP focuses on a modular edge architecture for adaptive biometric and AI tasks, highlighting hardware and architectural innovations rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17795",
      "abstract": "Service-level mobile traffic prediction for individual users is essential for network efficiency and quality of service enhancement. However, current prediction methods are limited in their adaptability across different urban environments and produce inaccurate results due to the high uncertainty in personal traffic patterns, the lack of detailed environmental context, and the complex dependencies among different network services. These challenges demand advanced modeling techniques that can capture dynamic traffic distributions and rich environmental features. Inspired by the recent success of diffusion models in distribution modeling and Large Language Models (LLMs) in contextual understanding, we propose an LLM-Enhanced Spatio-temporal Diffusion Model (LSDM). LSDM integrates the generative power of diffusion models with the adaptive learning capabilities of transformers, augmented by the ability to capture multimodal environmental information for modeling service-level patterns and dynamics. Extensive evaluations on real-world service-level datasets demonstrate that the model excels in traffic usage predictions, showing outstanding generalization and adaptability. After incorporating contextual information via LLM, the performance improves by at least 2.83% in terms of the coefficient of determination. Compared to models of a similar type, such as CSDI, the root mean squared error can be reduced by at least 8.29%. The code and dataset will be available at: https://github.com/SoftYuaneR/LSDM.",
      "authors": [
        "Shiyuan Zhang",
        "Tong Li",
        "Zhu Xiao",
        "Hongyang Du",
        "Kaibin Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:01:16+00:00",
          "link": "https://arxiv.org/abs/2507.17795v1",
          "size": "991kb",
          "version": "v1"
        }
      ],
      "title": "LSDM: LLM-Enhanced Spatio-temporal Diffusion Model for Service-Level Mobile Traffic Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17795",
        "HTML": "https://arxiv.org/html/2507.17795v1",
        "PDF": "https://arxiv.org/pdf/2507.17795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it discusses the integration of LLMs for enhanced modeling in mobile traffic prediction, it does not discuss LLM training data processing, dataset creation, or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17796",
      "abstract": "We propose a novel framework that harnesses the power of generative artificial intelligence and copula-based modeling to address two critical challenges in multivariate time-series analysis: delivering accurate predictions and enabling robust anomaly detection. Our method, Copula-based Conformal Anomaly Identification for Multivariate Time-Series (CoCAI), leverages a diffusion-based model to capture complex dependencies within the data, enabling high quality forecasting. The model's outputs are further calibrated using a conformal prediction technique, yielding predictive regions which are statistically valid, i.e., cover the true target values with a desired confidence level. Starting from these calibrated forecasts, robust outlier detection is performed by combining dimensionality reduction techniques with copula-based modeling, providing a statistically grounded anomaly score. CoCAI benefits from an offline calibration phase that allows for minimal overhead during deployment and delivers actionable results rooted in established theoretical foundations. Empirical tests conducted on real operational data derived from water distribution and sewerage systems confirm CoCAI's effectiveness in accurately forecasting target sequences of data and in identifying anomalous segments within them.",
      "authors": [
        "Nicholas A. Pearson",
        "Francesca Zanello",
        "Davide Russo",
        "Luca Bortolussi",
        "Francesca Cairoli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:15:31+00:00",
          "link": "https://arxiv.org/abs/2507.17796v1",
          "size": "18143kb",
          "version": "v1"
        }
      ],
      "title": "CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17796",
        "HTML": "https://arxiv.org/html/2507.17796v1",
        "PDF": "https://arxiv.org/pdf/2507.17796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel framework for multivariate time-series analysis and anomaly detection using copula-based modeling and conformal prediction, rather than addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17797",
      "abstract": "Generative reward models with parallel sampling have enabled effective test-time scaling for reasoning tasks. Current approaches employ pointwise scoring of individual solutions or pairwise comparisons. However, pointwise methods underutilize LLMs' comparative abilities, while pairwise methods scale inefficiently with larger sampling budgets. We introduce GenSelect, where the LLM uses long reasoning to select the best solution among N candidates. This leverages LLMs' comparative strengths while scaling efficiently across parallel sampling budgets. For math reasoning, we demonstrate that reasoning models, such as QwQ and DeepSeek-R1-0528, excel at GenSelect, outperforming existing scoring approaches with simple prompting.",
      "authors": [
        "Shubham Toshniwal",
        "Ivan Sorokin",
        "Aleksander Ficek",
        "Ivan Moshkov",
        "Igor Gitman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:22:51+00:00",
          "link": "https://arxiv.org/abs/2507.17797v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "GenSelect: A Generative Approach to Best-of-N",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17797",
        "PDF": "https://arxiv.org/pdf/2507.17797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces GenSelect for reasoning tasks via LLMs, focusing on generative reward models and test-time scaling, without any discussion on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17798",
      "abstract": "High-resolution (HR) precipitation prediction is essential for reducing damage from stationary and localized heavy rainfall; however, HR precipitation forecasts using process-driven numerical weather prediction models remains challenging. This study proposes using Wasserstein Generative Adversarial Network (WGAN) to perform precipitation downscaling with an optimal transport cost. In contrast to a conventional neural network trained with mean squared error, the WGAN generated visually realistic precipitation fields with fine-scale structures even though the WGAN exhibited slightly lower performance on conventional evaluation metrics. The learned critic of WGAN correlated well with human perceptual realism. Case-based analysis revealed that large discrepancies in critic scores can help identify both unrealistic WGAN outputs and potential artifacts in the reference data. These findings suggest that the WGAN framework not only improves perceptual realism in precipitation downscaling but also offers a new perspective for evaluating and quality-controlling precipitation datasets.",
      "authors": [
        "Kenta Shiraishi",
        "Yuka Muto",
        "Atsushi Okazaki and Shunji Kotsuki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:29:34+00:00",
          "link": "https://arxiv.org/abs/2507.17798v1",
          "size": "2811kb",
          "version": "v1"
        }
      ],
      "title": "Wasserstein GAN-Based Precipitation Downscaling with Optimal Transport for Enhancing Perceptual Realism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17798",
        "PDF": "https://arxiv.org/pdf/2507.17798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a WGAN for precipitation downscaling, aimed at enhancing perceptual realism in weather prediction data, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17801",
      "abstract": "We present Lumina-mGPT 2.0, a stand-alone, decoder-only autoregressive model that revisits and revitalizes the autoregressive paradigm for high-quality image generation and beyond. Unlike existing approaches that rely on pretrained components or hybrid architectures, Lumina-mGPT 2.0 is trained entirely from scratch, enabling unrestricted architectural design and licensing freedom. It achieves generation quality on par with state-of-the-art diffusion models such as DALL-E 3 and SANA, while preserving the inherent flexibility and compositionality of autoregressive modeling. Our unified tokenization scheme allows the model to seamlessly handle a wide spectrum of tasks-including subject-driven generation, image editing, controllable synthesis, and dense prediction-within a single generative framework. To further boost usability, we incorporate efficient decoding strategies like inference-time scaling and speculative Jacobi sampling to improve quality and speed, respectively. Extensive evaluations on standard text-to-image benchmarks (e.g., GenEval, DPG) demonstrate that Lumina-mGPT 2.0 not only matches but in some cases surpasses diffusion-based models. Moreover, we confirm its multi-task capabilities on the Graph200K benchmark, with the native Lumina-mGPT 2.0 performing exceptionally well. These results position Lumina-mGPT 2.0 as a strong, flexible foundation model for unified multimodal generation. We have released our training details, code, and models at https://github.com/Alpha-VLLM/Lumina-mGPT-2.0.",
      "authors": [
        "Yi Xin",
        "Juncheng Yan",
        "Qi Qin",
        "Zhen Li",
        "Dongyang Liu",
        "Shicheng Li",
        "Victor Shea-Jay Huang",
        "Yupeng Zhou",
        "Renrui Zhang",
        "Le Zhuo",
        "Tiancheng Han",
        "Xiaoqing Sun",
        "Siqi Luo",
        "Mengmeng Wang",
        "Bin Fu",
        "Yuewen Cao",
        "Hongsheng Li",
        "Guangtao Zhai",
        "Xiaohong Liu",
        "Yu Qiao",
        "Peng Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:42:13+00:00",
          "link": "https://arxiv.org/abs/2507.17801v1",
          "size": "22581kb",
          "version": "v1"
        }
      ],
      "title": "Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17801",
        "HTML": "https://arxiv.org/html/2507.17801v1",
        "PDF": "https://arxiv.org/pdf/2507.17801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on image generation using Lumina-mGPT 2.0, a model for autoregressive image modeling without pre-existing components. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17834",
      "abstract": "We study three classical online problems -- $k$-server, $k$-taxi, and chasing size $k$ sets -- through a lens of smoothed analysis. Our setting allows request locations to be adversarial up to small perturbations, interpolating between worst-case and average-case models. Specifically, we show that if the metric space is contained in a ball in any normed space and requests are drawn from distributions whose density functions are upper bounded by $1/\\sigma$ times the uniform density over the ball, then all three problems admit polylog$(k/\\sigma)$-competitive algorithms. Our approach is simple: it reduces smoothed instances to fully adversarial instances on finite metrics and leverages existing algorithms in a black-box manner. We also provide a lower bound showing that no algorithm can achieve a competitive ratio sub-polylogarithmic in $k/\\sigma$, matching our upper bounds up to the exponent of the polylogarithm. In contrast, the best known competitive ratios for these problems in the fully adversarial setting are $2k-1$, $\\infty$ and $\\Theta(k^2)$, respectively.",
      "authors": [
        "Christian Coester",
        "Jack Umenberger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:01:13+00:00",
          "link": "https://arxiv.org/abs/2507.17834v1",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "title": "Smoothed Analysis of Online Metric Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17834",
        "HTML": "https://arxiv.org/html/2507.17834v1",
        "PDF": "https://arxiv.org/pdf/2507.17834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Examining online metric problems under smoothed analysis, this paper is concerned with theoretical computer science topics, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17835",
      "abstract": "In future AI-native wireless networks, the presence of mismatches between the latent spaces of independently designed and trained deep neural network (DNN) encoders may impede mutual understanding due to the emergence of semantic channel noise. This undermines the receiver's ability to interpret transmitted representations, thereby reducing overall system performance. To address this issue, we propose the Parseval Frame Equalizer (PFE), a zero-shot, frame-based semantic channel equalizer that aligns latent spaces of heterogeneous encoders without requiring system retraining. PFE enables dynamic signal compression and expansion, mitigating semantic noise while preserving performance on downstream tasks. Building on this capability, we introduce a dynamic optimization strategy that coordinates communication, computation, and learning resources to balance energy consumption, end-to-end (E2E) latency, and task performance in multi-agent semantic communication scenarios. Extensive simulations confirm the effectiveness of our approach in maintaining semantic consistency and meeting long-term constraints on latency and accuracy under diverse and time-varying network conditions.",
      "authors": [
        "Simone Fiorellino",
        "Claudio Battiloro",
        "Emilio Calvanese Strinati",
        "and Paolo Di Lorenzo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:02:33+00:00",
          "link": "https://arxiv.org/abs/2507.17835v1",
          "size": "21005kb",
          "version": "v1"
        }
      ],
      "title": "Frame-Based Zero-Shot Semantic Channel Equalization for AI-Native Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17835",
        "HTML": "https://arxiv.org/html/2507.17835v1",
        "PDF": "https://arxiv.org/pdf/2507.17835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research proposes solutions for semantic channel equalization in AI-native communications, not related to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17841",
      "abstract": "In the semi-streaming model, an algorithm must process any $n$-vertex graph by making one or few passes over a stream of its edges, use $O(n \\cdot \\text{polylog }n)$ words of space, and at the end of the last pass, output a solution to the problem at hand. Approximating (single-source) shortest paths on undirected graphs is a longstanding open question in this model. In this work, we make progress on this question from both upper and lower bound fronts:\n  We present a simple randomized algorithm that for any $\\epsilon > 0$, with high probability computes $(1+\\epsilon)$-approximate shortest paths from a given source vertex in \\[\n  O\\left(\\frac{1}{\\epsilon} \\cdot n \\log^3 n \\right)~\\text{space} \\quad \\text{and} \\quad O\\left(\\frac{1}{\\epsilon} \\cdot \\left(\\frac{\\log n}{\\log\\log n} \\right) ^2\\right) ~\\text{passes}.\n  \\] The algorithm can also be derandomized and made to work on dynamic streams at a cost of some extra $\\text{poly}(\\log n, 1/\\epsilon)$ factors only in the space. Previously, the best known algorithms for this problem required $1/\\epsilon \\cdot \\log^{c}(n)$ passes, for an unspecified large constant $c$.\n  We prove that any semi-streaming algorithm that with large constant probability outputs any constant approximation to shortest paths from a given source vertex (even to a single fixed target vertex and only the distance, not necessarily the path) requires \\[ \\Omega\\left(\\frac{\\log n}{\\log\\log n}\\right) ~\\text{passes}. \\] We emphasize that our lower bound holds for any constant-factor approximation of shortest paths. Previously, only constant-pass lower bounds were known and only for small approximation ratios below two.\n  Our results collectively reduce the gap in the pass complexity of approximating single-source shortest paths in the semi-streaming model from $\\text{polylog } n$ vs $\\omega(1)$ to only a quadratic gap.",
      "authors": [
        "Sepehr Assadi",
        "Gary Hoppenworth",
        "Janani Sundaresan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:09:51+00:00",
          "link": "https://arxiv.org/abs/2507.17841v1",
          "size": "605kb",
          "version": "v1"
        }
      ],
      "title": "Better Bounds for Semi-Streaming Single-Source Shortest Paths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17841",
        "PDF": "https://arxiv.org/pdf/2507.17841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithms for approximating shortest paths in graphs within the semi-streaming model, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17842",
      "abstract": "Large Language Models (LLMs) have recently demonstrated strong potential in generating 'believable human-like' behavior in web environments. Prior work has explored augmenting training data with LLM-synthesized rationales and applying supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can improve downstream action prediction. However, the performance of such approaches remains inherently bounded by the reasoning capabilities of the model used to generate the rationales. In this paper, we introduce Shop-R1, a novel reinforcement learning (RL) framework aimed at enhancing the reasoning ability of LLMs for simulation of real human behavior in online shopping environments Specifically, Shop-R1 decomposes the human behavior simulation task into two stages: rationale generation and action prediction, each guided by distinct reward signals. For rationale generation, we leverage internal model signals (e.g., logit distributions) to guide the reasoning process in a self-supervised manner. For action prediction, we propose a hierarchical reward structure with difficulty-aware scaling to prevent reward hacking and enable fine-grained reward assignment. This design evaluates both high-level action types and the correctness of fine-grained sub-action details (attributes and values), rewarding outputs proportionally to their difficulty. Experimental results show that our method achieves a relative improvement of over 65% compared to the baseline.",
      "authors": [
        "Yimeng Zhang",
        "Tian Wang",
        "Jiri Gesi",
        "Ziyi Wang",
        "Yuxuan Lu",
        "Jiacheng Lin",
        "Sinong Zhan",
        "Vianne Gao",
        "Ruochen Jiao",
        "Junze Liu",
        "Kun Qian",
        "Yuxin Tang",
        "Ran Xue",
        "Houyu Zhang",
        "Qingjun Cui",
        "Yufan Guo",
        "Dakuo Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:10:43+00:00",
          "link": "https://arxiv.org/abs/2507.17842v1",
          "size": "756kb",
          "version": "v1"
        }
      ],
      "title": "Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17842",
        "HTML": "https://arxiv.org/html/2507.17842v1",
        "PDF": "https://arxiv.org/pdf/2507.17842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using reinforcement learning to enhance LLMs for simulating human behavior in online shopping. Although it involves the decomposition of tasks into rationale generation and action prediction, the focus is more on the model's reasoning and behavior simulation rather than the training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17843",
      "abstract": "The latest generation of games and pervasive communication technologies poses challenges in service management and Service-Level Agreement compliance for mobile users. State-of-the-art edge-gaming techniques enhance throughput, reduce latency, and leverage cloud computing. However, further development of core functions such as the User Plane Function (UPF) is needed for non-intrusive user latency measurement. This paper proposes a closed-loop architecture integrating the Network Data Analytics Function (NWDAF) and UPF to estimate user latency and enhance the 5G control plane by making it latency-aware. The results show that embedding an artificial intelligence model within NWDAF enables game classification and opens new avenues for mobile edge gaming research.",
      "authors": [
        "Bruno Marques da Silva and Larissa Ferreira Rodrigues Moreira and Fl\\'avio de Oliveira Silva and Rodrigo Moreira"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:11:28+00:00",
          "link": "https://arxiv.org/abs/2507.17843v1",
          "size": "1247kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Edge Gaming Slices through an Enhanced User Plane Function and Analytics in Beyond-5G Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17843",
        "HTML": "https://arxiv.org/html/2507.17843v1",
        "PDF": "https://arxiv.org/pdf/2507.17843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses optimization in mobile edge gaming within Beyond-5G networks, focusing on network functions and latency measurement, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17844",
      "abstract": "This paper addresses the challenge of automated sports video analysis, which has traditionally been limited by computationally intensive models requiring server-side processing and lacking fine-grained understanding of athletic movements. Current approaches struggle to capture the nuanced biomechanical transitions essential for meaningful sports analysis, often missing critical phases like preparation, execution, and follow-through that occur within seconds. To address these limitations, we introduce SV3.3B, a lightweight 3.3B parameter video understanding model that combines novel temporal motion difference sampling with self-supervised learning for efficient on-device deployment. Our approach employs a DWT-VGG16-LDA based keyframe extraction mechanism that intelligently identifies the 16 most representative frames from sports sequences, followed by a V-DWT-JEPA2 encoder pretrained through mask-denoising objectives and an LLM decoder fine-tuned for sports action description generation. Evaluated on a subset of the NSVA basketball dataset, SV3.3B achieves superior performance across both traditional text generation metrics and sports-specific evaluation criteria, outperforming larger closed-source models including GPT-4o variants while maintaining significantly lower computational requirements. Our model demonstrates exceptional capability in generating technically detailed and analytically rich sports descriptions, achieving 29.2% improvement over GPT-4o in ground truth validation metrics, with substantial improvements in information density, action complexity, and measurement precision metrics essential for comprehensive athletic analysis. Model Available at https://huggingface.co/sportsvision/SV3.3B.",
      "authors": [
        "Sai Varun Kodathala",
        "Yashwanth Reddy Vutukoori and Rakesh Vunnam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:11:39+00:00",
          "link": "https://arxiv.org/abs/2507.17844v1",
          "size": "1079kb",
          "version": "v1"
        }
      ],
      "title": "SV3.3B: A Sports Video Understanding Model for Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17844",
        "PDF": "https://arxiv.org/pdf/2507.17844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model for understanding sports videos and generating sports action descriptions. It does not address any aspect of training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17846",
      "abstract": "Pottery creation is a complicated art form that requires dexterous, precise and delicate actions to slowly morph a block of clay to a meaningful, and often useful 3D goal shape. In this work, we aim to create a robotic system that can create simple pottery goals with only pinch-based actions. This pinch pottery task allows us to explore the challenges of a highly multi-modal and long-horizon deformable manipulation task. To this end, we present PinchBot, a goal-conditioned diffusion policy model that when combined with pre-trained 3D point cloud embeddings, task progress prediction and collision-constrained action projection, is able to successfully create a variety of simple pottery goals. For experimental videos and access to the demonstration dataset, please visit our project website: https://sites.google.com/andrew.cmu.edu/pinchbot/home.",
      "authors": [
        "Alison Bartsch",
        "Arvind Car",
        "Amir Barati Farimani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:13:41+00:00",
          "link": "https://arxiv.org/abs/2507.17846v1",
          "size": "6622kb",
          "version": "v1"
        }
      ],
      "title": "PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17846",
        "HTML": "https://arxiv.org/html/2507.17846v1",
        "PDF": "https://arxiv.org/pdf/2507.17846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a robotic system for creating pottery using a goal-conditioned diffusion policy model, which is unrelated to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17848",
      "abstract": "Graph Neural Networks (GNNs) have achieved outstanding performance across a wide range of graph-related tasks. However, their \"black-box\" nature poses significant challenges to their explainability, and existing methods often fail to effectively capture the intricate interaction patterns among nodes within the network. In this work, we propose a novel explainability framework, GraphEXT, which leverages cooperative game theory and the concept of social externalities. GraphEXT partitions graph nodes into coalitions, decomposing the original graph into independent subgraphs. By integrating graph structure as an externality and incorporating the Shapley value under externalities, GraphEXT quantifies node importance through their marginal contributions to GNN predictions as the nodes transition between coalitions. Unlike traditional Shapley value-based methods that primarily focus on node attributes, our GraphEXT places greater emphasis on the interactions among nodes and the impact of structural changes on GNN predictions. Experimental studies on both synthetic and real-world datasets show that GraphEXT outperforms existing baseline methods in terms of fidelity across diverse GNN architectures , significantly enhancing the explainability of GNN models.",
      "authors": [
        "Lijun Wu",
        "Dong Hao",
        "Zhiyi Fan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:36:47+00:00",
          "link": "https://arxiv.org/abs/2507.17848v1",
          "size": "1542kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Graph Neural Networks via Structural Externalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17848",
        "HTML": "https://arxiv.org/html/2507.17848v1",
        "PDF": "https://arxiv.org/pdf/2507.17848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on explainability for Graph Neural Networks, leveraging social externalities and Shapley values, without any discussion of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17849",
      "abstract": "Process Reward Models (PRMs) are crucial for guiding Large Language Models (LLMs) in complex scenarios by providing dense reward signals. However, existing PRMs primarily rely on heuristic approaches, which struggle with cross-domain generalization. While LLM-as-judge has been proposed to provide generalized rewards, current research has focused mainly on feedback results, overlooking the meaningful guidance embedded within the text. Additionally, static and coarse-grained evaluation criteria struggle to adapt to complex process supervision. To tackle these challenges, we propose Dynamic and Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to capture and store fine-grained, multi-dimensional reward criteria. DG-PRM dynamically selects reward signals for step-wise reward scoring. To handle multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation to identify discriminative positive and negative pairs. Experimental results show that DG-PRM achieves stunning performance on prevailing benchmarks, significantly boosting model performance across tasks with dense rewards. Further analysis reveals that DG-PRM adapts well to out-of-distribution scenarios, demonstrating exceptional generalizability.",
      "authors": [
        "Zhangyue Yin",
        "Qiushi Sun",
        "Zhiyuan Zeng",
        "Qinyuan Cheng",
        "Xipeng Qiu",
        "Xuanjing Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:17:22+00:00",
          "link": "https://arxiv.org/abs/2507.17849v1",
          "size": "505kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic and Generalizable Process Reward Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17849",
        "HTML": "https://arxiv.org/html/2507.17849v1",
        "PDF": "https://arxiv.org/pdf/2507.17849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a dynamic reward modeling approach for LLMs, which could indirectly relate to data processing by affecting model training outcomes, it primarily focuses on the methodological model rather than concrete data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17850",
      "abstract": "The deployment of large-scale software-based 5G core functions presents significant challenges due to their reliance on optimized and intelligent resource provisioning for their services. Many studies have focused on analyzing the impact of resource allocation for complex deployments using mathematical models, queue theories, or even Artificial Intelligence (AI). This paper elucidates the effects of chaotic workloads, generated by Distributed Denial of Service (DDoS) on different Network Functions (NFs) on User Equipment registration performance. Our findings highlight the necessity of diverse resource profiles to ensure Service-Level Agreement (SLA) compliance in large-scale 5G core deployments. Additionally, our analysis of packet capture approaches demonstrates the potential of kernel-based monitoring for scalable security threat defense. Finally, our empirical evaluation provides insights into the effective deployment of 5G NFs in complex scenarios.",
      "authors": [
        "Rodrigo Moreira and Larissa F. Rodrigues Moreira and Fl\\'avio de Oliveira Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:17:26+00:00",
          "link": "https://arxiv.org/abs/2507.17850v1",
          "size": "814kb",
          "version": "v1"
        }
      ],
      "title": "Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17850",
        "HTML": "https://arxiv.org/html/2507.17850v1",
        "PDF": "https://arxiv.org/pdf/2507.17850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on performance evaluation and threat mitigation within 5G core network deployments, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17851",
      "abstract": "Speech pretrained models contain task-specific information across different layers, but decoupling content and timbre information remains challenging as removing speaker-specific information often causes content loss. Current research lacks direct metrics to quantify timbre residual in model encodings, relying on indirect evaluation through downstream tasks. This paper addresses these challenges through interpretability-based speaker disentanglement in speech pretraining models. We quantitatively evaluate timbre residual in model embeddings and improve speaker disentanglement using interpretive representations. Our contributions include: (1) InterpTRQE-SptME Benchmark - a timbre residual recognition framework using interpretability. The benchmark concatenates content embeddings with timbre embeddings for speaker classification, then applies Gradient SHAP Explainer to quantify timbre residual. We evaluate seven speech pretraining model variations. (2) InterpTF-SptME method - an interpretability-based timbre filtering approach using SHAP Noise and SHAP Cropping techniques. This model-agnostic method transforms intermediate encodings to remove timbre while preserving content. Experiments on VCTK dataset with HuBERT LARGE demonstrate successful content preservation and significant speaker disentanglement optimization. Results show the SHAP Noise method can reduce timbre residual from 18.05% to near 0% while maintaining content integrity, contributing to enhanced performance in content-related speech processing tasks and preventing timbre privacy leakage.",
      "authors": [
        "Xiaoxu Zhu",
        "Junhua Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:49:49+00:00",
          "link": "https://arxiv.org/abs/2507.17851v1",
          "size": "893kb",
          "version": "v1"
        }
      ],
      "title": "Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17851",
        "HTML": "https://arxiv.org/html/2507.17851v1",
        "PDF": "https://arxiv.org/pdf/2507.17851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses speaker disentanglement and timbre reduction in speech pretraining models, which does not pertain to LLM training data processing operations or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17852",
      "abstract": "Building on the conceptual framework presented in our previous work on agentic AI for pharmaceutical research, this paper provides a comprehensive technical analysis of Tippy's multi-agent system implementation for drug discovery laboratory automation. We present a distributed microservices architecture featuring five specialized agents (Supervisor, Molecule, Lab, Analysis, and Report) that coordinate through OpenAI Agents SDK orchestration and access laboratory tools via the Model Context Protocol (MCP). The system architecture encompasses agent-specific tool integration, asynchronous communication patterns, and comprehensive configuration management through Git-based tracking. Our production deployment strategy utilizes Kubernetes container orchestration with Helm charts, Docker containerization, and CI/CD pipelines for automated testing and deployment. The implementation integrates vector databases for RAG functionality and employs an Envoy reverse proxy for secure external access. This work demonstrates how specialized AI agents can effectively coordinate complex laboratory workflows while maintaining security, scalability, reliability, and integration with existing laboratory infrastructure through standardized protocols.",
      "authors": [
        "Yao Fehlis",
        "Charles Crain",
        "Aidan Jensen",
        "Michael Watson",
        "James Juhasz",
        "Paul Mandel",
        "Betty Liu",
        "Shawn Mahon",
        "Daren Wilson",
        "Nick Lynch-Jonely",
        "Ben Leedom",
        "David Fuller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:57:40+00:00",
          "link": "https://arxiv.org/abs/2507.17852v1",
          "size": "390kb",
          "version": "v1"
        }
      ],
      "title": "Technical Implementation of Tippy: Multi-Agent Architecture and System Design for Drug Discovery Laboratory Automation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17852",
        "HTML": "https://arxiv.org/html/2507.17852v1",
        "PDF": "https://arxiv.org/pdf/2507.17852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the implementation of a multi-agent system for drug discovery laboratory automation, which involves technical aspects of microservices architecture, agent coordination, and system integration, but does not address any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17853",
      "abstract": "Recent advances in text-to-image (T2I) generation have led to impressive visual results. However, these models still face significant challenges when handling complex prompt, particularly those involving multiple subjects with distinct attributes. Inspired by the human drawing process, which first outlines the composition and then incrementally adds details, we propose Detail++, a training-free framework that introduces a novel Progressive Detail Injection (PDI) strategy to address this limitation. Specifically, we decompose a complex prompt into a sequence of simplified sub-prompts, guiding the generation process in stages. This staged generation leverages the inherent layout-controlling capacity of self-attention to first ensure global composition, followed by precise refinement. To achieve accurate binding between attributes and corresponding subjects, we exploit cross-attention mechanisms and further introduce a Centroid Alignment Loss at test time to reduce binding noise and enhance attribute consistency. Extensive experiments on T2I-CompBench and a newly constructed style composition benchmark demonstrate that Detail++ significantly outperforms existing methods, particularly in scenarios involving multiple objects and complex stylistic conditions.",
      "authors": [
        "Lifeng Chen",
        "Jiner Wang",
        "Zihao Pan",
        "Beier Zhu",
        "Xiaofeng Yang and Chi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:20:46+00:00",
          "link": "https://arxiv.org/abs/2507.17853v1",
          "size": "13263kb",
          "version": "v1"
        }
      ],
      "title": "Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17853",
        "HTML": "https://arxiv.org/html/2507.17853v1",
        "PDF": "https://arxiv.org/pdf/2507.17853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a strategy for enhancing detail in text-to-image diffusion models. It discusses strategies for image generation but does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17856",
      "abstract": "Designing a Model Predictive Control (MPC) scheme that enables a mobile robot to safely navigate through an obstacle-filled environment is a complicated yet essential task in robotics. In this technical report, safety refers to ensuring that the robot respects state and input constraints while avoiding collisions with obstacles despite the presence of disturbances and measurement noise. This report offers a step-by-step approach to implementing Nonlinear Model Predictive Control (NMPC) schemes addressing these safety requirements. Numerous books and survey papers provide comprehensive overviews of linear MPC (LMPC) \\cite{bemporad2007robust,kouvaritakis2016model}, NMPC \\cite{rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook}, and their applications in various domains, including robotics \\cite{nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc}. This report does not aim to replicate those exhaustive reviews. Instead, it focuses specifically on NMPC as a foundation for safe mobile robot navigation. The goal is to provide a practical and accessible path from theoretical concepts to mathematical proofs and implementation, emphasizing safety and performance guarantees. It is intended for researchers, robotics engineers, and practitioners seeking to bridge the gap between theoretical NMPC formulations and real-world robotic applications.\n  This report is not necessarily meant to remain fixed over time. If someone finds an error in the presented theory, please reach out via the given email addresses. We are happy to update the document if necessary.",
      "authors": [
        "Dennis Benders",
        "Laura Ferranti and Johannes K\\\"ohler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:26:18+00:00",
          "link": "https://arxiv.org/abs/2507.17856v1",
          "size": "247kb",
          "version": "v1"
        }
      ],
      "title": "A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17856",
        "HTML": "https://arxiv.org/html/2507.17856v1",
        "PDF": "https://arxiv.org/pdf/2507.17856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a guide on Nonlinear Model Predictive Control for mobile robot navigation and focuses on robotics, safety, and control algorithms, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17859",
      "abstract": "Accurate fish detection in underwater imagery is essential for ecological monitoring, aquaculture automation, and robotic perception. However, practical deployment remains limited by fragmented datasets, heterogeneous imaging conditions, and inconsistent evaluation protocols. To address these gaps, we present \\textit{FishDet-M}, the largest unified benchmark for fish detection, comprising 13 publicly available datasets spanning diverse aquatic environments including marine, brackish, occluded, and aquarium scenes. All data are harmonized using COCO-style annotations with both bounding boxes and segmentation masks, enabling consistent and scalable cross-domain evaluation. We systematically benchmark 28 contemporary object detection models, covering the YOLOv8 to YOLOv12 series, R-CNN based detectors, and DETR based models. Evaluations are conducted using standard metrics including mAP, mAP@50, and mAP@75, along with scale-specific analyses (AP$_S$, AP$_M$, AP$_L$) and inference profiling in terms of latency and parameter count. The results highlight the varying detection performance across models trained on FishDet-M, as well as the trade-off between accuracy and efficiency across models of different architectures. To support adaptive deployment, we introduce a CLIP-based model selection framework that leverages vision-language alignment to dynamically identify the most semantically appropriate detector for each input image. This zero-shot selection strategy achieves high performance without requiring ensemble computation, offering a scalable solution for real-time applications. FishDet-M establishes a standardized and reproducible platform for evaluating object detection in complex aquatic scenes. All datasets, pretrained models, and evaluation tools are publicly available to facilitate future research in underwater computer vision and intelligent marine systems.",
      "authors": [
        "Muayad Abujabal",
        "Lyes Saad Saoud",
        "and Irfan Hussain"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:32:01+00:00",
          "link": "https://arxiv.org/abs/2507.17859v1",
          "size": "27636kb",
          "version": "v1"
        }
      ],
      "title": "FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17859",
        "HTML": "https://arxiv.org/html/2507.17859v1",
        "PDF": "https://arxiv.org/pdf/2507.17859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents FishDet-M, a benchmark for fish detection in aquatic environments. It focuses on dataset harmonization and evaluation of object detection models but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17860",
      "abstract": "Recent advancements in Deep Learning and its application on the edge hold great potential for the revolution of routine screenings for skin cancers like Melanoma. Along with the anticipated benefits of this technology, potential dangers arise from unforseen and inherent biases. Thus, assessing and improving the fairness of such systems is of utmost importance. A key challenge in fairness assessment is to ensure that the evaluation dataset is sufficiently representative of different Personal Identifiable Information (PII) (sex, age, and race) and other minority groups. Against the backdrop of this challenge, this study leverages the state-of-the-art Generative AI (GenAI) LightningDiT model to assess the fairness of publicly available melanoma classifiers. The results suggest that fairness assessment using highly realistic synthetic data is a promising direction. Yet, our findings indicate that verifying fairness becomes difficult when the melanoma-detection model used for evaluation is trained on data that differ from the dataset underpinning the synthetic images. Nonetheless, we propose that our approach offers a valuable new avenue for employing synthetic data to gauge and enhance fairness in medical-imaging GenAI systems.",
      "authors": [
        "Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:33:27+00:00",
          "link": "https://arxiv.org/abs/2507.17860v1",
          "size": "2083kb",
          "version": "v1"
        }
      ],
      "title": "Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17860",
        "HTML": "https://arxiv.org/html/2507.17860v1",
        "PDF": "https://arxiv.org/pdf/2507.17860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of generative AI for fairness assessment in medical imaging classifiers. It focuses on the synthesis of image data for bias evaluation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17861",
      "abstract": "Artificial Intelligence (AI) plays a key role in developing 6G networks. While current specifications already include Network Data Analytics Function (NWDAF) as a network element responsible for providing information about the core, a more comprehensive approach will be needed to enable automation of network segments that are not yet fully explored in the context of 5G. In this paper, we present Automated Radio Coverage Anomalies Detection and Evaluation (ARCADE), a methodology for identifying and diagnosing anomalies in the cellular access network. Furthermore, we demonstrate how a hybrid architecture of network analytics functions in the evolution toward 6G can enhance the application of AI in a broader network context, using ARCADE as a practical example of this approach.",
      "authors": [
        "Daniel Ricardo Cunha Oliveira and Rodrigo Moreira and Fl\\'avio de Oliveira Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:34:45+00:00",
          "link": "https://arxiv.org/abs/2507.17861v1",
          "size": "934kb",
          "version": "v1"
        }
      ],
      "title": "ARCADE: A RAN Diagnosis Methodology in a Hybrid AI Environment for 6G Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17861",
        "HTML": "https://arxiv.org/html/2507.17861v1",
        "PDF": "https://arxiv.org/pdf/2507.17861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses ARCADE, a methodology for diagnosing anomalies in cellular networks, which is irrelevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17865",
      "abstract": "The convergence of Large Language Models (LLMs) and Internet of Things (IoT) networks open new opportunities for building intelligent, responsive, and user-friendly systems. This work presents an edge-centric framework that integrates LLMs into IoT architectures to enable natural language-based control, context-aware decision-making, and enhanced automation. The proposed modular and lightweight Retrieval Augmented Generation (RAG)-based LLMs are deployed on edge computing devices connected to IoT gateways, enabling local processing of user commands and sensor data for reduced latency, improved privacy, and enhanced inference quality. We validate the framework through a smart home prototype using LLaMA 3 and Gemma 2B models for controlling smart devices. Experimental results highlight the trade-offs between model accuracy and inference time with respect to models size. At last, we also discuss the potential applications that can use LLM-based IoT systems, and a few key challenges associated with such systems.",
      "authors": [
        "Alakesh Kalita"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:39:59+00:00",
          "link": "https://arxiv.org/abs/2507.17865v1",
          "size": "463kb",
          "version": "v1"
        }
      ],
      "title": "Talk with the Things: Integrating LLMs into IoT Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17865",
        "HTML": "https://arxiv.org/html/2507.17865v1",
        "PDF": "https://arxiv.org/pdf/2507.17865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for integrating LLMs into IoT networks to improve automation and privacy, but does not address data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17868",
      "abstract": "Amidst the growing demand for implementing advanced control and decision-making algorithms|to enhance the reliability, resilience, and stability of power systems|arises a crucial concern regarding the safety of employing machine learning techniques. While these methods can be applied to derive more optimal control decisions, they often lack safety assurances. This paper proposes a framework based on control barrier functions to facilitate safe learning and deployment of reinforcement learning agents for power system control applications, specifically in the context of automatic generation control. We develop the safety barriers and reinforcement learning framework necessary to establish trust in reinforcement learning as a safe option for automatic generation control - as foundation for future detailed verification and application studies.",
      "authors": [
        "Amr S. Mohamed",
        "Emily Nguyen",
        "Deepa Kundur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:52:11+00:00",
          "link": "https://arxiv.org/abs/2507.17868v1",
          "size": "287kb",
          "version": "v1"
        }
      ],
      "title": "Safe Reinforcement Learning-based Automatic Generation Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17868",
        "HTML": "https://arxiv.org/html/2507.17868v1",
        "PDF": "https://arxiv.org/pdf/2507.17868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on safe reinforcement learning for power system control, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17874",
      "abstract": "Recent advances in agentic systems for data analysis have emphasized automation of insight generation through multi-agent frameworks, and orchestration layers. While these systems effectively manage tasks like query translation, data transformation, and visualization, they often overlook the structured reasoning process underlying analytical thinking. Reasoning large language models (LLMs) used for multi-step problem solving are trained as general-purpose problem solvers. As a result, their reasoning or thinking steps do not adhere to fixed processes for specific tasks. Real-world data analysis requires a consistent cognitive workflow: interpreting vague goals, grounding them in contextual knowledge, constructing abstract plans, and adapting execution based on intermediate outcomes. We introduce I2I-STRADA (Information-to-Insight via Structured Reasoning Agent for Data Analysis), an agentic architecture designed to formalize this reasoning process. I2I-STRADA focuses on modeling how analysis unfolds via modular sub-tasks that reflect the cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench benchmarks show that I2I-STRADA outperforms prior systems in planning coherence and insight alignment, highlighting the importance of structured cognitive workflows in agent design for data analysis.",
      "authors": [
        "SaiBarath Sundar",
        "Pranav Satheesan",
        "Udayaadithya Avadhanam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:58:42+00:00",
          "link": "https://arxiv.org/abs/2507.17874v1",
          "size": "390kb",
          "version": "v1"
        }
      ],
      "title": "I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17874",
        "HTML": "https://arxiv.org/html/2507.17874v1",
        "PDF": "https://arxiv.org/pdf/2507.17874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces I2I-STRADA, an architecture to enhance reasoning in data analysis, without addressing LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17875",
      "abstract": "Multi-agent collaboration enhances situational awareness in intelligence, surveillance, and reconnaissance (ISR) missions. Ad hoc networks of unmanned aerial vehicles (UAVs) allow for real-time data sharing, but they face security challenges due to their decentralized nature, making them vulnerable to cyber-physical attacks. This paper introduces a trust-based framework for assured sensor fusion in distributed multi-agent networks, utilizing a hidden Markov model (HMM)-based approach to estimate the trustworthiness of agents and their provided information in a decentralized fashion. Trust-informed data fusion prioritizes fusing data from reliable sources, enhancing resilience and accuracy in contested environments. To evaluate the assured sensor fusion under attacks on system/mission sensing, we present a novel multi-agent aerial dataset built from the Unreal Engine simulator. We demonstrate through case studies improved ISR performance and an ability to detect malicious actors in adversarial settings.",
      "authors": [
        "R. Spencer Hallyburton and Miroslav Pajic"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:03:47+00:00",
          "link": "https://arxiv.org/abs/2507.17875v1",
          "size": "2416kb",
          "version": "v1"
        }
      ],
      "title": "Trusted Data Fusion, Multi-Agent Autonomy, Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17875",
        "HTML": "https://arxiv.org/html/2507.17875v1",
        "PDF": "https://arxiv.org/pdf/2507.17875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a trust-based framework for sensor fusion in multi-agent networks, specifically in ISR missions using UAVs. It does not address LLM training data processing or related data operations for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17876",
      "abstract": "The scarcity of molecules with desirable properties (i.e., 'positive' molecules) is an inherent bottleneck for generative molecule design. To sidestep such obstacle, here we propose molecular task arithmetic: training a model on diverse and abundant negative examples to learn 'property directions' $--$ without accessing any positively labeled data $--$ and moving models in the opposite property directions to generate positive molecules. When analyzed on 20 zero-shot design experiments, molecular task arithmetic generated more diverse and successful designs than models trained on positive molecules. Moreover, we employed molecular task arithmetic in dual-objective and few-shot design tasks. We find that molecular task arithmetic can consistently increase the diversity of designs while maintaining desirable design properties. With its simplicity, data efficiency, and performance, molecular task arithmetic bears the potential to become the $\\textit{de-facto}$ transfer learning strategy for de novo molecule design.",
      "authors": [
        "R{\\i}za \\\"Oz\\c{c}elik",
        "Sarah de Ruiter",
        "Francesca Grisoni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:05:37+00:00",
          "link": "https://arxiv.org/abs/2507.17876v1",
          "size": "399kb",
          "version": "v1"
        }
      ],
      "title": "Look the Other Way: Designing 'Positive' Molecules with Negative Data via Task Arithmetic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17876",
        "HTML": "https://arxiv.org/html/2507.17876v1",
        "PDF": "https://arxiv.org/pdf/2507.17876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with molecular design using task arithmetic on negative examples and does not relate to LLM training data processing or datasets used for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17878",
      "abstract": "We introduce a new notion of sparsification, called \\emph{strong sparsification}, in which constraints are not removed but variables can be merged. As our main result, we present a strong sparsification algorithm for 1-in-3-SAT. The correctness of the algorithm relies on establishing a sub-quadratic bound on the size of certain sets of vectors in $\\mathbb{F}_2^d$. This result, obtained using the recent \\emph{Polynomial Freiman-Ruzsa Theorem} (Gowers, Green, Manners and Tao, Ann. Math. 2025), could be of independent interest. As an application, we improve the state-of-the-art algorithm for approximating linearly-ordered colourings of 3-uniform hypergraphs (H{\\aa}stad, Martinsson, Nakajima and{\\v{Z}}ivn{\\'{y}}, APPROX 2024).",
      "authors": [
        "Benjamin Bedert and Tamio-Vesa Nakajima and Karolina Okrasa and Stanislav \\v{Z}ivn\\'y"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:11:32+00:00",
          "link": "https://arxiv.org/abs/2507.17878v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17878",
        "HTML": "https://arxiv.org/html/2507.17878v1",
        "PDF": "https://arxiv.org/pdf/2507.17878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a strong sparsification algorithm for 1-in-3-SAT, which is unrelated to LLM training data processing or datasets used in LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17886",
      "abstract": "Neuromorphic computing (NMC) is increasingly viewed as a low-power alternative to conventional von Neumann architectures such as central processing units (CPUs) and graphics processing units (GPUs), however the computational value proposition has been difficult to define precisely.\n  Here, we explain how NMC should be seen as general-purpose and programmable even though it differs considerably from a conventional stored-program architecture. We show that the time and space scaling of NMC is equivalent to that of a theoretically infinite processor conventional system, however the energy scaling is significantly different. Specifically, the energy of conventional systems scales with absolute algorithm work, whereas the energy of neuromorphic systems scales with the derivative of algorithm state. The unique characteristics of NMC architectures make it well suited for different classes of algorithms than conventional multi-core systems like GPUs that have been optimized for dense numerical applications such as linear algebra. In contrast, the unique characteristics of NMC make it ideally suited for scalable and sparse algorithms whose activity is proportional to an objective function, such as iterative optimization and large-scale sampling (e.g., Monte Carlo).",
      "authors": [
        "James B Aimone"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:28:23+00:00",
          "link": "https://arxiv.org/abs/2507.17886v1",
          "size": "567kb",
          "version": "v1"
        }
      ],
      "title": "Neuromorphic Computing: A Theoretical Framework for Time, Space, and Energy Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17886",
        "HTML": "https://arxiv.org/html/2507.17886v1",
        "PDF": "https://arxiv.org/pdf/2507.17886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses neuromorphic computing frameworks, focusing on energy scaling and architectural differences with conventional systems, without addressing LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17887",
      "abstract": "This paper introduces an operator-based neural network, the mirror-padded Fourier neural operator (MFNO), designed to learn the dynamics of stochastic systems. MFNO extends the standard Fourier neural operator (FNO) by incorporating mirror padding, enabling it to handle non-periodic inputs. We rigorously prove that MFNOs can approximate solutions of path-dependent stochastic differential equations and Lipschitz transformations of fractional Brownian motions to an arbitrary degree of accuracy. Our theoretical analysis builds on Wong--Zakai type theorems and various approximation techniques. Empirically, the MFNO exhibits strong resolution generalization--a property rarely seen in standard architectures such as LSTMs, TCNs, and DeepONet. Furthermore, our model achieves performance that is comparable or superior to these baselines while offering significantly faster sample path generation than classical numerical schemes.",
      "authors": [
        "Wonjae Lee",
        "Taeyoung Kim",
        "Hyungbin Park"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:30:34+00:00",
          "link": "https://arxiv.org/abs/2507.17887v1",
          "size": "593kb",
          "version": "v1"
        }
      ],
      "title": "Fourier Neural Operators for Non-Markovian Processes:Approximation Theorems and Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17887",
        "HTML": "https://arxiv.org/html/2507.17887v1",
        "PDF": "https://arxiv.org/pdf/2507.17887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development and theoretical analysis of Fourier neural operator networks for stochastic processes, without mention of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17888",
      "abstract": "Detecting security vulnerabilities in open-source software is a critical task that is highly regarded in the related research communities. Several approaches have been proposed in the literature for detecting vulnerable codes and identifying the classes of vulnerabilities. However, there is still room to work in explaining the root causes of detected vulnerabilities through locating vulnerable statements and the discovery of paths leading to the activation of the vulnerability. While frameworks like SliceLocator offer explanations by identifying vulnerable paths, they rely on rule-based sink identification that limits their generalization. In this paper, we introduce VulPathFinder, an explainable vulnerability path discovery framework that enhances SliceLocator's methodology by utilizing a novel Graph Neural Network (GNN) model for detecting sink statements, rather than relying on predefined rules. The proposed GNN captures semantic and syntactic dependencies to find potential sink points (PSPs), which are candidate statements where vulnerable paths end. After detecting PSPs, program slicing can be used to extract potentially vulnerable paths, which are then ranked by feeding them back into the target graph-based detector. Ultimately, the most probable path is returned, explaining the root cause of the detected vulnerability. We demonstrated the effectiveness of the proposed approach by performing evaluations on a benchmark of the buffer overflow CWEs from the SARD dataset, providing explanations for the corresponding detected vulnerabilities. The results show that VulPathFinder outperforms both original SliceLocator and GNNExplainer (as a general GNN explainability tool) in discovery of vulnerability paths to identified PSPs.",
      "authors": [
        "Nima Atashin",
        "Behrouz Tork Ladani",
        "Mohammadreza Sharbaf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:30:37+00:00",
          "link": "https://arxiv.org/abs/2507.17888v1",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Locate: GNN-Powered Vulnerability Path Discovery in Open Source Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17888",
        "HTML": "https://arxiv.org/html/2507.17888v1",
        "PDF": "https://arxiv.org/pdf/2507.17888"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores a framework for vulnerability detection in software using graph neural networks. It has no connection to LLM training data processing processes like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17892",
      "abstract": "Transformers, with their self-attention mechanisms for modeling long-range dependencies, have become a dominant paradigm in image restoration tasks. However, the high computational cost of self-attention limits scalability to high-resolution images, making efficiency-quality trade-offs a key research focus. To address this, Restormer employs channel-wise self-attention, which computes attention across channels instead of spatial dimensions. While effective, this approach may overlook localized artifacts that are crucial for high-quality image restoration. To bridge this gap, we explore Dilated Neighborhood Attention (DiNA) as a promising alternative, inspired by its success in high-level vision tasks. DiNA balances global context and local precision by integrating sliding-window attention with mixed dilation factors, effectively expanding the receptive field without excessive overhead. However, our preliminary experiments indicate that directly applying this global-local design to the classic deblurring task hinders accurate visual restoration, primarily due to the constrained global context understanding within local attention. To address this, we introduce a channel-aware module that complements local attention, effectively integrating global context without sacrificing pixel-level precision. The proposed DiNAT-IR, a Transformer-based architecture specifically designed for image restoration, achieves competitive results across multiple benchmarks, offering a high-quality solution for diverse low-level computer vision problems.",
      "authors": [
        "Hanzhou Liu",
        "Binghan Li",
        "Chengkai Liu",
        "Mi Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:41:49+00:00",
          "link": "https://arxiv.org/abs/2507.17892v1",
          "size": "702kb",
          "version": "v1"
        }
      ],
      "title": "DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17892",
        "HTML": "https://arxiv.org/html/2507.17892v1",
        "PDF": "https://arxiv.org/pdf/2507.17892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an image restoration framework using Transformers, which is outside the scope of LLM training data processing relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17893",
      "abstract": "This paper explores the application of reinforcement learning techniques to enhance the performance of decoding of linear block codes based on flipping bits and finding optimal decisions. We describe the methodology for mapping the iterative decoding process into Markov Decision Processes (MDPs) and propose different methods to reduce the number of states in the MDP. A truncated MDP is proposed to reduce the number of states in the MDP by learning a Hamming ball with a specified radius around codewords. We then propose a general scheme for reinforcement learning based decoders applicable to any class of codes to improve the performance of decoders. We call this scheme an action-list decoding. We design an action-list decoder based on the Deep-Q network values that substantially enhance performance. We also get benefit of automorphism group of code to further improve the code performance. Additionally, we propose a feedback-based method to exploit and enhance the performance of existing high-performing decoders by applying reinforcement learning algorithms after the existing decoders. These approaches effectively reduces the complexity of the reinforcement learning block. Finally, we present experimental results for the Low-Density Parity Check (LDPC) codes over the Binary Symmetric Channel (BSC) to demonstrate the efficiency of the proposed methods.",
      "authors": [
        "Milad Taghipour",
        "Bane Vasic"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:42:51+00:00",
          "link": "https://arxiv.org/abs/2507.17893v1",
          "size": "354kb",
          "version": "v1"
        }
      ],
      "title": "Action-List Reinforcement Learning Syndrome Decoding for Binary Linear Block Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17893",
        "HTML": "https://arxiv.org/html/2507.17893v1",
        "PDF": "https://arxiv.org/pdf/2507.17893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on reinforcement learning techniques for decoding binary linear block codes, not related to LLM training data processing or any data engineering operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17895",
      "abstract": "The most effective differentially private machine learning algorithms in practice rely on an additional source of purportedly public data. This paradigm is most interesting when the two sources combine to be more than the sum of their parts. However, there are settings such as mean estimation where we have strong lower bounds, showing that when the two data sources have the same distribution, there is no complementary value to combining the two data sources. In this work we extend the known lower bounds for public-private learning to setting where the two data sources exhibit significant distribution shift. Our results apply to both Gaussian mean estimation where the two distributions have different means, and to Gaussian linear regression where the two distributions exhibit parameter shift. We find that when the shift is small (relative to the desired accuracy), either public or private data must be sufficiently abundant to estimate the private parameter. Conversely, when the shift is large, public data provides no benefit.",
      "authors": [
        "Amrith Setlur and Pratiksha Thaker and Jonathan Ullman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:46:08+00:00",
          "link": "https://arxiv.org/abs/2507.17895v1",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "title": "Lower Bounds for Public-Private Learning under Distribution Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17895",
        "HTML": "https://arxiv.org/html/2507.17895v1",
        "PDF": "https://arxiv.org/pdf/2507.17895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work investigates differential privacy in machine learning under distribution shift, which does not address LLM training data processing or any data curation or generation activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17896",
      "abstract": "Application systems using natural language interfaces to databases (NLIDBs) have democratized data analysis. This positive development has also brought forth an urgent challenge to help users who might use these systems without a background in statistical analysis to formulate bias-free analytical questions. Although significant research has focused on text-to-SQL generation accuracy, addressing cognitive biases in analytical questions remains underexplored. We present VeriMinder, https://veriminder.ai, an interactive system for detecting and mitigating such analytical vulnerabilities. Our approach introduces three key innovations: (1) a contextual semantic mapping framework for biases relevant to specific analysis contexts (2) an analytical framework that operationalizes the Hard-to-Vary principle and guides users in systematic data analysis (3) an optimized LLM-powered system that generates high-quality, task-specific prompts using a structured process involving multiple candidates, critic feedback, and self-reflection.\n  User testing confirms the merits of our approach. In direct user experience evaluation, 82.5% participants reported positively impacting the quality of the analysis. In comparative evaluation, VeriMinder scored significantly higher than alternative approaches, at least 20% better when considered for metrics of the analysis's concreteness, comprehensiveness, and accuracy. Our system, implemented as a web application, is set to help users avoid \"wrong question\" vulnerability during data analysis. VeriMinder code base with prompts, https://reproducibility.link/veriminder, is available as an MIT-licensed open-source software to facilitate further research and adoption within the community.",
      "authors": [
        "Shubham Mohole",
        "Sainyam Galhotra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:48:12+00:00",
          "link": "https://arxiv.org/abs/2507.17896v1",
          "size": "4448kb",
          "version": "v1"
        }
      ],
      "title": "VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17896",
        "HTML": "https://arxiv.org/html/2507.17896v1",
        "PDF": "https://arxiv.org/pdf/2507.17896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mitigating analytical vulnerabilities in natural language interfaces to databases, particularly addressing biases in analytical question formulation. It does not contribute to LLM training data processing tasks such as data collection, filtering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17898",
      "abstract": "Domain-specific visualizations sometimes focus on narrow, albeit important, tasks for one group of users. This focus limits the utility of a visualization to other groups working with the same data. While tasks elicited from other groups can present a design pitfall if not disambiguated, they also present a design opportunity -- development of visualizations that support multiple groups. This development choice presents a trade off of broadening the scope but limiting support for the more narrow tasks of any one group, which in some cases can enhance the overall utility of the visualization. We investigate this scenario through a design study where we develop \\textit{Guidepost}, a notebook-embedded visualization of supercomputer queue data that helps scientists assess supercomputer queue wait times, machine learning researchers understand prediction accuracy, and system maintainers analyze usage trends. We adapt the use of personas for visualization design from existing literature in the HCI and software engineering domains and apply them in categorizing tasks based on their uniqueness across the stakeholder personas. Under this model, tasks shared between all groups should be supported by interactive visualizations and tasks unique to each group can be deferred to scripting with notebook-embedded visualization design. We evaluate our visualization with nine expert analysts organized into two groups: a \"research analyst\" group that uses supercomputer queue data in their research (representing the Machine Learning researchers and Jobs Data Analyst personas) and a \"supercomputer user\" group that uses this data conditionally (representing the HPC User persona). We find that our visualization serves our three stakeholder groups by enabling users to successfully execute shared tasks with point-and-click interaction while facilitating case-specific programmatic analysis workflows.",
      "authors": [
        "Connor Scully-Allison",
        "Kevin Menear",
        "Kristin Potter",
        "Andrew McNutt",
        "Katherine E. Isaacs",
        "Dmitry Duplyakin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:49:38+00:00",
          "link": "https://arxiv.org/abs/2507.17898v1",
          "size": "1119kb",
          "version": "v1"
        }
      ],
      "title": "Same Data, Different Audiences: Using Personas to Scope a Supercomputing Job Queue Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17898",
        "HTML": "https://arxiv.org/html/2507.17898v1",
        "PDF": "https://arxiv.org/pdf/2507.17898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a visualization tool for supercomputing job queues, employing personas to support various user groups. It does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17903",
      "abstract": "Federated Learning (FL) is an emerging distributed machine learning paradigm, where the collaborative training of a model involves dynamic participation of devices to achieve broad objectives. In contrast, classical machine learning (ML) typically requires data to be located on-premises for training, whereas FL leverages numerous user devices to train a shared global model without the need to share private data. Current robotic manipulation tasks are constrained by the individual capabilities and speed of robots due to limited low-latency computing resources. Consequently, the concept of cloud robotics has emerged, allowing robotic applications to harness the flexibility and reliability of computing resources, effectively alleviating their computational demands across the cloud-edge continuum. Undoubtedly, within this distributed computing context, as exemplified in cloud robotic manipulation scenarios, FL offers manifold advantages while also presenting several challenges and opportunities. In this paper, we present fundamental concepts of FL and their connection to cloud robotic manipulation. Additionally, we envision the opportunities and challenges associated with realizing efficient and reliable cloud robotic manipulation at scale through FL, where researchers adopt to design and verify FL models in either centralized or decentralized settings.",
      "authors": [
        "Obaidullah Zaland",
        "Chanh Nguyen",
        "Florian T. Pokorny and Monowar Bhuyan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:01:36+00:00",
          "link": "https://arxiv.org/abs/2507.17903v1",
          "size": "2648kb",
          "version": "v1"
        }
      ],
      "title": "Federated Learning for Large-Scale Cloud Robotic Manipulation: Opportunities and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17903",
        "HTML": "https://arxiv.org/html/2507.17903v1",
        "PDF": "https://arxiv.org/pdf/2507.17903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses federated learning concepts in the context of cloud robotic manipulation. It discusses distributed model training but does not involve data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17904",
      "abstract": "The exponential growth of large-scale AI models has led to computational and power demands that can exceed the capacity of a single data center. This is due to the limited power supplied by regional grids that leads to limited regional computational power. Consequently, distributing training workloads across geographically distributed sites has become essential. However, this approach introduces a significant challenge in the form of communication overhead, creating a fundamental trade-off between the performance gains from accessing greater aggregate power and the performance losses from increased network latency. Although prior work has focused on reducing communication volume or using heuristics for distribution, these methods assume constant homogeneous power supplies and ignore the challenge of heterogeneous power availability between sites.\n  To address the challenge of training large models in power-constrained, geo-distributed environments, we introduce PowerTrip, a system that dynamically selects a subset of sites during runtime to optimize the power-communication trade-off. Specifically, PowerTrip selects sites based on a power-to-cost heuristic, prioritizing those with high power availability and low network latency. PowerTrip employs a dynamic greedy approach and uses the marginal gain in training efficiency, i.e., accuracy improvement per unit of time, to optimize for the number of sites where the performance penalty from network overhead negates the benefit of adding more computational power. Our evaluation, which uses real-world Google power traces to model realistic power capacity constraints, demonstrates that PowerTrip can reduce time-to-accuracy by up to 50% compared to existing baseline policies.",
      "authors": [
        "Talha Mehboob",
        "Luanzheng Guo",
        "Nathan Tallent",
        "Michael Zink",
        "David Irwin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:02:06+00:00",
          "link": "https://arxiv.org/abs/2507.17904v1",
          "size": "438kb",
          "version": "v1"
        }
      ],
      "title": "PowerTrip: Exploiting Federated Heterogeneous Datacenter Power for Distributed ML Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17904",
        "HTML": "https://arxiv.org/html/2507.17904v1",
        "PDF": "https://arxiv.org/pdf/2507.17904"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on optimizing distributed ML training through power-communication trade-offs in data centers. It does not pertain to LLM training data processing operations or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17905",
      "abstract": "LPWANs have become ubiquitous due to their ability to connect sensors over large geographic areas in a single hop. It is, however, very challenging to achieve massive scalability in LPWANs, where numerous sensors can transmit data efficiently and with low latency, which emerging IoT and CPS applications may require. In this paper, we address the above challenges by significantly advancing an LPWAN technology called SNOW. SNOW exploits distributed orthogonal frequency division multiplexing, D-OFDM, subcarriers to enable parallel reception of data to a BS from multiple asynchronous sensors, each using a different subcarrier. In this paper, we achieve massive scalability in SNOW by enabling the BS to decode concurrent data from numerous asynchronous sensors on the same subcarrier while parallelly decoding from other subcarriers as well. Additionally, we enable numerous asynchronous sensors to receive distinct data from the BS on the same subcarrier while other sensors also receive data parallelly on other subcarriers. To do this, we develop a set of Gold code-based pseudorandom noise or PN sequences that are mutually non-interfering within and across the subcarriers. Each sensor uses its PN sequence from the set for encoding or decoding data on its subcarriers, enabling massive concurrency. Our evaluation results demonstrate that we can achieve approximately 9x more scalability in SNOW while being timely in data collection at the BS and energy efficient at the sensors. This may enable emerging IoT and CPS applications requiring tens of thousands of sensors with longer battery life and making data-driven, time-sensitive decisions.",
      "authors": [
        "Mahbubur Rahman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:06:12+00:00",
          "link": "https://arxiv.org/abs/2507.17905v1",
          "size": "2224kb",
          "version": "v1"
        }
      ],
      "title": "Enabling Scalability in Asynchronous and Bidirectional Communication in LPWAN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17905",
        "HTML": "https://arxiv.org/html/2507.17905v1",
        "PDF": "https://arxiv.org/pdf/2507.17905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enabling scalability in LPWAN technology for IoT applications, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17907",
      "abstract": "The ultimate aim of the study is to explore the inverse design of porous metamaterials using a deep learning-based generative framework. Specifically, we develop a property-variational autoencoder (pVAE), a variational autoencoder (VAE) augmented with a regressor, to generate structured metamaterials with tailored hydraulic properties, such as porosity and permeability. While this work uses the lattice Boltzmann method (LBM) to generate intrinsic permeability tensor data for limited porous microstructures, a convolutional neural network (CNN) is trained using a bottom-up approach to predict effective hydraulic properties. This significantly reduces the computational cost compared to direct LBM simulations. The pVAE framework is trained on two datasets: a synthetic dataset of artificial porous microstructures and CT-scan images of volume elements from real open-cell foams. The encoder-decoder architecture of the VAE captures key microstructural features, mapping them into a compact and interpretable latent space for efficient structure-property exploration. The study provides a detailed analysis and interpretation of the latent space, demonstrating its role in structure-property mapping, interpolation, and inverse design. This approach facilitates the generation of new metamaterials with desired properties. The datasets and codes used in this study will be made open-access to support further research.",
      "authors": [
        "Phu Thien Nguyen",
        "Yousef Heider",
        "Dennis M. Kochmann",
        "Fadi Aldakheel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:07:53+00:00",
          "link": "https://arxiv.org/abs/2507.17907v1",
          "size": "30545kb",
          "version": "v1"
        }
      ],
      "title": "Deep learning-aided inverse design of porous metamaterials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17907",
        "HTML": "https://arxiv.org/html/2507.17907v1",
        "PDF": "https://arxiv.org/pdf/2507.17907"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores the inverse design of porous metamaterials using a deep learning framework but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17912",
      "abstract": "We present a SemiEmpirical Theory of Learning (SETOL) that explains the remarkable performance of State-Of-The-Art (SOTA) Neural Networks (NNs). We provide a formal explanation of the origin of the fundamental quantities in the phenomenological theory of Heavy-Tailed Self-Regularization (HTSR): the heavy-tailed power-law layer quality metrics, alpha and alpha-hat. In prior work, these metrics have been shown to predict trends in the test accuracies of pretrained SOTA NN models, importantly, without needing access to either testing or training data. Our SETOL uses techniques from statistical mechanics as well as advanced methods from random matrix theory and quantum chemistry. The derivation suggests new mathematical preconditions for ideal learning, including a new metric, ERG, which is equivalent to applying a single step of the Wilson Exact Renormalization Group. We test the assumptions and predictions of SETOL on a simple 3-layer multilayer perceptron (MLP), demonstrating excellent agreement with the key theoretical assumptions. For SOTA NN models, we show how to estimate the individual layer qualities of a trained NN by simply computing the empirical spectral density (ESD) of the layer weight matrices and plugging this ESD into our SETOL formulas. Notably, we examine the performance of the HTSR alpha and the SETOL ERG layer quality metrics, and find that they align remarkably well, both on our MLP and on SOTA NNs.",
      "authors": [
        "Charles H Martin and Christopher Hinrichs"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistical Mechanics (cond-mat.stat-mech)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:22:20+00:00",
          "link": "https://arxiv.org/abs/2507.17912v1",
          "size": "2975kb",
          "version": "v1"
        }
      ],
      "title": "SETOL: A Semi-Empirical Theory of (Deep) Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17912",
        "HTML": "https://arxiv.org/html/2507.17912v1",
        "PDF": "https://arxiv.org/pdf/2507.17912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work presents a theoretical framework (SETOL) for explaining neural network performance without needing training data, which does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17916",
      "abstract": "This paper introduces recovery thresholding hyperinterpolations, a novel class of methods for sparse signal reconstruction in the presence of noise. We develop a framework that integrates thresholding operators--including hard thresholding, springback, and Newton thresholding--directly into the hyperinterpolation structure to maintain sparsity during signal recovery. Our approach leverages Newton's method to minimize one-dimensional nonconvex functions, which we then extend to solve multivariable nonconvex regularization problems. The proposed methods demonstrate robust performance in reconstructing signals corrupted by both Gaussian and impulse noise. Through numerical experiments, we validate the effectiveness of these recovery thresholding hyperinterpolations for signal reconstruction and function denoising applications, showing their advantages over traditional approaches in preserving signal sparsity while achieving accurate recovery.",
      "authors": [
        "Congpei An and Jiashu Ran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:29:13+00:00",
          "link": "https://arxiv.org/abs/2507.17916v1",
          "size": "488kb",
          "version": "v1"
        }
      ],
      "title": "Recovery Thresholding Hyperinterpolations in Signal Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17916",
        "HTML": "https://arxiv.org/html/2507.17916v1",
        "PDF": "https://arxiv.org/pdf/2507.17916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on novel methods for sparse signal reconstruction, specifically recovery thresholding hyperinterpolations, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17918",
      "abstract": "We present an efficient end-to-end approach for holistic Automatic Speaking Assessment (ASA) of multi-part second-language tests, developed for the 2025 Speak & Improve Challenge. Our system's main novelty is the ability to process all four spoken responses with a single Whisper-small encoder, combine all information via a lightweight aggregator, and predict the final score. This architecture removes the need for transcription and per-part models, cuts inference time, and makes ASA practical for large-scale Computer-Assisted Language Learning systems.\n  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming the text-based baseline (0.44) while using at most 168M parameters (about 70% of Whisper-small). Furthermore, we propose a data sampling strategy, allowing the model to train on only 44.8% of the speakers in the corpus and still reach 0.383 RMSE, demonstrating improved performance on imbalanced classes and strong data efficiency.",
      "authors": [
        "Nhan Phan",
        "Anusha Porwal",
        "Yaroslav Getman",
        "Ekaterina Voskoboinik",
        "Tam\\'as Gr\\'osz",
        "Mikko Kurimo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:31:40+00:00",
          "link": "https://arxiv.org/abs/2507.17918v1",
          "size": "396kb",
          "version": "v1"
        }
      ],
      "title": "One Whisper to Grade Them All",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17918",
        "HTML": "https://arxiv.org/html/2507.17918v1",
        "PDF": "https://arxiv.org/pdf/2507.17918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an approach for Automatic Speaking Assessment and proposes a data sampling strategy for improved training efficiency, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17922",
      "abstract": "Text-to-image (T2I) models have become prevalent across numerous applications, making their robust evaluation against adversarial attacks a critical priority. Continuous access to new and challenging adversarial prompts across diverse domains is essential for stress-testing these models for resilience against novel attacks from multiple vectors. Current techniques for generating such prompts are either entirely authored by humans or synthetically generated. On the one hand, datasets of human-crafted adversarial prompts are often too small in size and imbalanced in their cultural and contextual representation. On the other hand, datasets of synthetically-generated prompts achieve scale, but typically lack the realistic nuances and creative adversarial strategies found in human-crafted prompts. To combine the strengths of both human and machine approaches, we propose Seed2Harvest, a hybrid red-teaming method for guided expansion of culturally diverse, human-crafted adversarial prompt seeds. The resulting prompts preserve the characteristics and attack patterns of human prompts while maintaining comparable average attack success rates (0.31 NudeNet, 0.36 SD NSFW, 0.12 Q16). Our expanded dataset achieves substantially higher diversity with 535 unique geographic locations and a Shannon entropy of 7.48, compared to 58 locations and 5.28 entropy in the original dataset. Our work demonstrates the importance of human-machine collaboration in leveraging human creativity and machine computational capacity to achieve comprehensive, scalable red-teaming for continuous T2I model safety evaluation.",
      "authors": [
        "Jessica Quaye",
        "Charvi Rastogi",
        "Alicia Parrish",
        "Oana Inel",
        "Minsuk Kahng",
        "Lora Aroyo",
        "Vijay Janapa Reddi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:39:14+00:00",
          "link": "https://arxiv.org/abs/2507.17922v1",
          "size": "2507kb",
          "version": "v1"
        }
      ],
      "title": "From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17922",
        "PDF": "https://arxiv.org/pdf/2507.17922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method for generating adversarial prompts for text-to-image models which involves data augmentation and diversity. While it involves data generation, it focuses on T2I models, not LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17924",
      "abstract": "Accurate population flow prediction is essential for urban planning, transportation management, and public health. Yet existing methods face key limitations: traditional models rely on static spatial assumptions, deep learning models struggle with cross-city generalization, and Large Language Models (LLMs) incur high computational costs while failing to capture spatial structure. Moreover, many approaches sacrifice resolution by clustering Points of Interest (POIs) or restricting coverage to subregions, limiting their utility for city-wide analytics. We introduce UrbanPulse, a scalable deep learning framework that delivers ultra-fine-grained, city-wide OD flow predictions by treating each POI as an individual node. It combines a temporal graph convolutional encoder with a transformer-based decoder to model multi-scale spatiotemporal dependencies. To ensure robust generalization across urban contexts, UrbanPulse employs a three-stage transfer learning strategy: pretraining on large-scale urban graphs, cold-start adaptation, and reinforcement learning fine-tuning.Evaluated on over 103 million cleaned GPS records from three metropolitan areas in California, UrbanPulse achieves state-of-the-art accuracy and scalability. Through efficient transfer learning, UrbanPulse takes a key step toward making high-resolution, AI-powered urban forecasting deployable in practice across diverse cities.",
      "authors": [
        "Hongrong Yang",
        "Markus Schlaepfer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.17924v1",
          "size": "28273kb",
          "version": "v1"
        }
      ],
      "title": "UrbanPulse: A Cross-City Deep Learning Framework for Ultra-Fine-Grained Population Transfer Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17924",
        "PDF": "https://arxiv.org/pdf/2507.17924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a deep learning framework for urban population flow prediction and involves transfer learning strategies but is not connected to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17927",
      "abstract": "Large language models (LLMs) present intriguing opportunities to enhance user interaction with traditional algorithms and tools in real-world applications. An advanced planning system (APS) is a sophisticated software that leverages optimization to help operations planners create, interpret, and modify an operational plan. While highly beneficial, many customers are priced out of using an APS due to the ongoing costs of consultants responsible for customization and maintenance. To address the need for a more accessible APS expressed by supply chain planners, we present SmartAPS, a conversational system built on a tool-augmented LLM. Our system provides operations planners with an intuitive natural language chat interface, allowing them to query information, perform counterfactual reasoning, receive recommendations, and execute scenario analysis to better manage their operation. A short video demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw",
      "authors": [
        "Timothy Tin Long Yu",
        "Mahdi Mostajabdaveh",
        "Jabo Serge Byusa",
        "Rindra Ramamonjison",
        "Giuseppe Carenini",
        "Kun Mao",
        "Zirui Zhou",
        "Yong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:53:40+00:00",
          "link": "https://arxiv.org/abs/2507.17927v1",
          "size": "3101kb",
          "version": "v1"
        }
      ],
      "title": "SMARTAPS: Tool-augmented LLMs for Operations Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17927",
        "HTML": "https://arxiv.org/html/2507.17927v1",
        "PDF": "https://arxiv.org/pdf/2507.17927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces SmartAPS, a system for enhancing operations management with a tool-augmented LLM. It focuses on user interaction and operational planning, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17928",
      "abstract": "Surface plasmon polaritons (SPPs) are generated on the graphene surface, and provide a window into the nano-optical and electrodynamic response of their host material and its dielectric environment. An accurate simulation of SPPs presents several unique challenges, since SPPs often occur at complex interfaces between materials of different dielectric constants and appropriate boundary conditions at the graphene interfaces are crucial. Here we develop a simplified graphene model and propose a new finite element method accordingly. Stability for the continuous model is established, and extensive numerical results are presented to demonstrate that the new model can capture the SPPs very well for various complex graphene sheets.",
      "authors": [
        "Jichun Li",
        "Michael Neunteufel",
        "Li Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:54:16+00:00",
          "link": "https://arxiv.org/abs/2507.17928v1",
          "size": "2236kb",
          "version": "v1"
        }
      ],
      "title": "A novel finite element method for simulating surface plasmon polaritons on complex graphene sheets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17928",
        "HTML": "https://arxiv.org/html/2507.17928v1",
        "PDF": "https://arxiv.org/pdf/2507.17928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper develops a finite element method for simulating surface plasmon polaritons on graphene, which does not involve LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17930",
      "abstract": "Artificial Intelligence (AI) has the potential to transform Software Engineering (SE) by enhancing productivity, efficiency, and decision support. Tools like GitHub Copilot and ChatGPT have given rise to \"vibe coding\"-an exploratory, prompt-driven development style. Yet, how software engineers engage with these tools in daily tasks, especially in deciding whether to trust, refine, or reject AI-generated outputs, remains underexplored. This paper presents two complementary contributions. First, a pragmatic process model capturing real-world AI-assisted SE activities, including prompt design, inspection, fallback, and refinement. Second, a 2D decision framework that could help developers reason about trade-offs between effort saved and output quality. Grounded in practitioner reports and direct observations in three industry settings across Turkiye and Azerbaijan, our work illustrates how engineers navigate AI use with human oversight. These models offer structured, lightweight guidance to support more deliberate and effective use of AI tools in SE, contributing to ongoing discussions on practical human-AI collaboration.",
      "authors": [
        "Vahid Garousi",
        "Zafar Jafarov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:00:21+00:00",
          "link": "https://arxiv.org/abs/2507.17930v1",
          "size": "960kb",
          "version": "v1"
        }
      ],
      "title": "How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17930",
        "PDF": "https://arxiv.org/pdf/2507.17930"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a process model and decision framework for AI-assisted software engineering, focusing on how engineers interact with AI tools, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17934",
      "abstract": "Accurately assessing post quality requires complex relational reasoning to capture nuanced topic-post relationships. However, existing studies face three major limitations: (1) treating the task as unimodal categorization, which fails to leverage multimodal cues and fine-grained quality distinctions; (2) introducing noise during deep multimodal fusion, leading to misleading signals; and (3) lacking the ability to capture complex semantic relationships like relevance and comprehensiveness. To address these issues, we propose the Multimodal Fine-grained Topic-post Relational Reasoning (MFTRR) framework, which mimics human cognitive processes. MFTRR reframes post-quality assessment as a ranking task and incorporates multimodal data to better capture quality variations. It consists of two key modules: (1) the Local-Global Semantic Correlation Reasoning Module, which models fine-grained semantic interactions between posts and topics at both local and global levels, enhanced by a maximum information fusion mechanism to suppress noise; and (2) the Multi-Level Evidential Relational Reasoning Module, which explores macro- and micro-level relational cues to strengthen evidence-based reasoning. We evaluate MFTRR on three newly constructed multimodal topic-post datasets and the public Lazada-Home dataset. Experimental results demonstrate that MFTRR significantly outperforms state-of-the-art baselines, achieving up to 9.52% NDCG@3 improvement over the best unimodal method on the Art History dataset.",
      "authors": [
        "Xiaoxu Guo",
        "Siyan Liang",
        "Yachao Cui",
        "Juxiang Zhou",
        "Lei Wang",
        "Han Cao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:30:50+00:00",
          "link": "https://arxiv.org/abs/2507.17934v1",
          "size": "5815kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Fine-grained Reasoning for Post Quality Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17934",
        "HTML": "https://arxiv.org/html/2507.17934v1",
        "PDF": "https://arxiv.org/pdf/2507.17934"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for post quality evaluation using multimodal data, but it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17937",
      "abstract": "Lyrics-to-Song (LS2) generation models promise end-to-end music synthesis from text, yet their vulnerability to training data memorization remains underexplored. We introduce Adversarial PhoneTic Prompting (APT), a novel attack where lyrics are semantically altered while preserving their acoustic structure through homophonic substitutions (e.g., Eminem's famous \"mom's spaghetti\" $\\rightarrow$ \"Bob's confetti\"). Despite these distortions, we uncover a powerful form of sub-lexical memorization: models like SUNO and YuE regenerate outputs strikingly similar to known training content, achieving high similarity across audio-domain metrics, including CLAP, AudioJudge, and CoverID. This vulnerability persists across multiple languages and genres. More surprisingly, we discover that phoneme-altered lyrics alone can trigger visual memorization in text-to-video models. When prompted with phonetically modified lyrics from Lose Yourself, Veo 3 reconstructs visual elements from the original music video -- including character appearance and scene composition -- despite no visual cues in the prompt. We term this phenomenon phonetic-to-visual regurgitation. Together, these findings expose a critical vulnerability in transcript-conditioned multimodal generation: phonetic prompting alone can unlock memorized audiovisual content, raising urgent questions about copyright, safety, and content provenance in modern generative systems. Example generations are available on our demo page (jrohsc.github.io/music_attack/).",
      "authors": [
        "Jaechul Roh",
        "Zachary Novack",
        "Yuefeng Peng",
        "Niloofar Mireshghallah",
        "Taylor Berg-Kirkpatrick",
        "Amir Houmansadr"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:11:47+00:00",
          "link": "https://arxiv.org/abs/2507.17937v1",
          "size": "5219kb",
          "version": "v1"
        }
      ],
      "title": "Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17937",
        "HTML": "https://arxiv.org/html/2507.17937v1",
        "PDF": "https://arxiv.org/pdf/2507.17937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on vulnerabilities in music and video generation models, specifically phonetic memorization attacks and their implications. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17941",
      "abstract": "This technical report outlines our approach to Task 3A of the Detection and Classification of Acoustic Scenes and Events (DCASE) 2024, focusing on Sound Event Localization and Detection (SELD). SELD provides valuable insights by estimating sound event localization and detection, aiding in various machine cognition tasks such as environmental inference, navigation, and other sound localization-related applications. This year's challenge evaluates models using either audio-only (Track A) or audiovisual (Track B) inputs on annotated recordings of real sound scenes. A notable change this year is the introduction of distance estimation, with evaluation metrics adjusted accordingly for a comprehensive assessment. Our submission is for Task A of the Challenge, which focuses on the audio-only track. Our approach utilizes log-mel spectrograms, intensity vectors, and employs multiple data augmentations. We proposed an EINV2-based [1] network architecture, achieving improved results: an F-score of 40.2%, Angular Error (DOA) of 17.7 degrees, and Relative Distance Error (RDE) of 0.32 on the test set of the Development Dataset [2 ,3].",
      "authors": [
        "Quoc Thinh Vo",
        "David Han"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:18:01+00:00",
          "link": "https://arxiv.org/abs/2507.17941v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "Resnet-conformer network with shared weights and attention mechanism for sound event localization, detection, and distance estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17941",
        "HTML": "https://arxiv.org/html/2507.17941v1",
        "PDF": "https://arxiv.org/pdf/2507.17941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an approach for sound event localization, detection, and distance estimation using a Resnet-conformer network. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17942",
      "abstract": "We study a privacy-preserving data-sharing setting where a privatizer transforms private data into a sanitized version observed by an authorized reconstructor and two unauthorized adversaries, each with access to side information correlated with the private data.\n  The reconstructor is evaluated under a distortion function, while each adversary is evaluated using a separate loss function. The privatizer ensures the reconstructor distortion remains below a fixed threshold while maximizing the minimum loss across the two adversaries. This two-adversary setting models cases where individual users cannot reconstruct the data accurately, but their combined side information enables estimation within the distortion threshold. The privatizer maximizes individual loss while permitting accurate reconstruction only through collaboration. This echoes secret-sharing principles, but with lossy rather than perfect recovery. We frame this as a constrained data-driven minimax optimization problem and propose a data-driven training procedure that alternately updates the privatizer, reconstructor, and adversaries. We also analyze the Gaussian and binary cases as special scenarios where optimal solutions can be obtained. These theoretical optimal results are benchmarks for evaluating the proposed minimax training approach.",
      "authors": [
        "Amirarsalan Moatazedian",
        "Yauhen Yakimenka",
        "R\\'emi A. Chou",
        "J\\\"org Kliewer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:22:35+00:00",
          "link": "https://arxiv.org/abs/2507.17942v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Minimax Data Sanitization with Distortion Constraint and Adversarial Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17942",
        "HTML": "https://arxiv.org/html/2507.17942v1",
        "PDF": "https://arxiv.org/pdf/2507.17942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses privacy-preserving data-sharing with a focus on data sanitization and adversarial inference, but it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17943",
      "abstract": "Response timing measures play a crucial role in the assessment of automated driving systems (ADS) in collision avoidance scenarios, including but not limited to establishing human benchmarks and comparing ADS to human driver response performance. For example, measuring the response time (of a human driver or ADS) to a conflict requires the determination of a stimulus onset and a response onset. In existing studies, response onset relies on manual annotation or vehicle control signals such as accelerator and brake pedal movements. These methods are not applicable when analyzing large scale data where vehicle control signals are not available. This holds in particular for the rapidly expanding sets of ADS log data where the behavior of surrounding road users is observed via onboard sensors. To advance evaluation techniques for ADS and enable measuring response timing when vehicle control signals are not available, we developed a simple and efficient algorithm, based on a piecewise linear acceleration model, to automatically estimate brake onset that can be applied to any type of driving data that includes vehicle longitudinal time series data. We also proposed a manual annotation method to identify brake onset and used it as ground truth for validation. R2 was used as a confidence metric to measure the accuracy of the algorithm, and its classification performance was analyzed using naturalistic collision avoidance data of both ADS and humans, where our method was validated against human manual annotation. Although our algorithm is subject to certain limitations, it is efficient, generalizable, applicable to any road user and scenario types, and is highly configurable.",
      "authors": [
        "Shu-Yuan Liu",
        "Johan Engstr\\\"om",
        "Gustav Markkula"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:22:41+00:00",
          "link": "https://arxiv.org/abs/2507.17943v1",
          "size": "1966kb",
          "version": "v1"
        }
      ],
      "title": "Automated Brake Onset Detection in Naturalistic Driving Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17943",
        "PDF": "https://arxiv.org/pdf/2507.17943"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on automated brake onset detection in naturalistic driving data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17944",
      "abstract": "Large language models (LLMs) have rapidly transformed the creation of written materials. LLMs have led to questions about writing integrity, thereby driving the creation of artificial intelligence (AI) detection technologies. Adversarial attacks, such as standard and humanized paraphrasing, inhibit detectors' ability to detect machine-generated text. Previous studies have mainly focused on ChatGPT and other well-known LLMs and have shown varying accuracy across detectors. However, there is a clear gap in the literature about DeepSeek, a recently published LLM. Therefore, in this work, we investigate whether six generally accessible AI detection tools -- AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can consistently recognize text generated by DeepSeek. The detectors were exposed to the aforementioned adversarial attacks. We also considered DeepSeek as a detector by performing few-shot prompting and chain-of-thought reasoning (CoT) for classifying AI and human-written text. We collected 49 human-authored question-answer pairs from before the LLM era and generated matching responses using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied adversarial techniques such as paraphrasing and humanizing to add 196 more samples. These were used to challenge detector robustness and assess accuracy impact. While QuillBot and Copyleaks showed near-perfect performance on original and paraphrased DeepSeek text, others -- particularly AI Text Classifier and GPT-2 -- showed inconsistent results. The most effective attack was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and 52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best five-shot result misclassifying only one of 49 samples (AI recall 96%, human recall 100%).",
      "authors": [
        "Hulayyil Alshammari",
        "Praveen Rao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:26:33+00:00",
          "link": "https://arxiv.org/abs/2507.17944v1",
          "size": "1012kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17944",
        "PDF": "https://arxiv.org/pdf/2507.17944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper primarily evaluates the performance of AI text detectors and adversarial attacks on text generation, it involves some creation of text data samples using DeepSeek-v3 for testing, which is a minor aspect of data generation pertinent to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17948",
      "abstract": "Retrieval-augmented generation (RAG) systems are increasingly adopted in clinical decision support, yet they remain methodologically blind-they retrieve evidence but cannot vet its scientific quality. A paper claiming \"Antioxidant proteins decreased after alloferon treatment\" and a rigorous multi-laboratory replication study will be treated as equally credible, even if the former lacked scientific rigor or was even retracted. To address this challenge, we introduce VERIRAG, a framework that makes three notable contributions: (i) the Veritable, an 11-point checklist that evaluates each source for methodological rigor, including data integrity and statistical validity; (ii) a Hard-to-Vary (HV) Score, a quantitative aggregator that weights evidence by its quality and diversity; and (iii) a Dynamic Acceptance Threshold, which calibrates the required evidence based on how extraordinary a claim is. Across four datasets-comprising retracted, conflicting, comprehensive, and settled science corpora-the VERIRAG approach consistently outperforms all baselines, achieving absolute F1 scores ranging from 0.53 to 0.65, representing a 10 to 14 point improvement over the next-best method in each respective dataset. We will release all materials necessary for reproducing our results.",
      "authors": [
        "Shubham Mohole",
        "Hongjun Choi",
        "Shusen Liu",
        "Christine Klymko",
        "Shashank Kushwaha",
        "Derek Shi",
        "Wesam Sakla",
        "Sainyam Galhotra",
        "Ruben Glatt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:32:50+00:00",
          "link": "https://arxiv.org/abs/2507.17948v1",
          "size": "3651kb",
          "version": "v1"
        }
      ],
      "title": "VERIRAG: Healthcare Claim Verification via Statistical Audit in Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17948",
        "PDF": "https://arxiv.org/pdf/2507.17948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on retrieval-augmented generation systems in healthcare claim verification and proposes VERIRAG framework, primarily dealing with evaluating methodological rigor and scientific quality of sources, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17950",
      "abstract": "To reduce channel acquisition overhead, spatial, time, and frequency-domain channel extrapolation techniques have been widely studied. In this paper, we propose a novel deep learning-based Position-domain Channel Extrapolation framework (named PCEnet) for cell-free massive multiple-input multiple-output (MIMO) systems. The user's position, which contains significant channel characteristic information, can greatly enhance the efficiency of channel acquisition. In cell-free massive MIMO, while the propagation environments between different base stations and a specific user vary and their respective channels are uncorrelated, the user's position remains constant and unique across all channels. Building on this, the proposed PCEnet framework leverages the position as a bridge between channels to establish a mapping between the characteristics of different channels, thereby using one acquired channel to assist in the estimation and feedback of others. Specifically, this approach first utilizes neural networks (NNs) to infer the user's position from the obtained channel. {The estimated position, shared among BSs through a central processing unit (CPU)}, is then fed into an NN to design pilot symbols and concatenated with the feedback information to the channel reconstruction NN to reconstruct other channels, thereby significantly enhancing channel acquisition performance. Additionally, we propose a simplified strategy where only the estimated position is used in the reconstruction process without modifying the pilot design, thereby reducing latency. Furthermore, we introduce a position label-free approach that infers the relative user position instead of the absolute position, eliminating the need for ground truth position labels during the localization NN training. Simulation results demonstrate that the proposed PCEnet framework reduces pilot and feedback overheads by up to 50%.",
      "authors": [
        "Jiajia Guo and Chao-Kai Wen and Xiao Li and Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:45:44+00:00",
          "link": "https://arxiv.org/abs/2507.17950v1",
          "size": "1091kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning-based Position-domain Channel Extrapolation for Cell-Free Massive MIMO",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17950",
        "HTML": "https://arxiv.org/html/2507.17950v1",
        "PDF": "https://arxiv.org/pdf/2507.17950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a deep learning framework for channel extrapolation in massive MIMO systems. It addresses technical aspects of wireless communication systems rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17951",
      "abstract": "Do larger and more capable language models learn to update their \"beliefs\" about propositions more consistently with Bayes' theorem when presented with evidence in-context? To test this, we formulate a Bayesian Coherence Coefficient (BCC) metric and generate a dataset with which to measure the BCC. We measure BCC for multiple pre-trained-only language models across five model families, comparing against the number of model parameters, the amount of training data, and model scores on common benchmarks. Our results provide evidence for our hypothesis that larger and more capable pre-trained language models assign credences that are more coherent with Bayes' theorem. These results have important implications for our understanding and governance of LLMs.",
      "authors": [
        "Sohaib Imran",
        "Ihor Kendiukhov",
        "Matthew Broerman",
        "Aditya Thomas",
        "Riccardo Campanella",
        "Rob Lamb",
        "Peter M. Atkinson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:46:37+00:00",
          "link": "https://arxiv.org/abs/2507.17951v1",
          "size": "7461kb",
          "version": "v1"
        }
      ],
      "title": "Are LLM Belief Updates Consistent with Bayes' Theorem?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17951",
        "PDF": "https://arxiv.org/pdf/2507.17951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the Bayesian Coherence Coefficient metric and a dataset to measure it, which relates to understanding LLM behavior but does not make a direct technical contribution to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17953",
      "abstract": "Clo-HDnn is an on-device learning (ODL) accelerator designed for emerging continual learning (CL) tasks. Clo-HDnn integrates hyperdimensional computing (HDC) along with low-cost Kronecker HD Encoder and weight clustering feature extraction (WCFE) to optimize accuracy and efficiency. Clo-HDnn adopts gradient-free CL to efficiently update and store the learned knowledge in the form of class hypervectors. Its dual-mode operation enables bypassing costly feature extraction for simpler datasets, while progressive search reduces complexity by up to 61% by encoding and comparing only partial query hypervectors. Achieving 4.66 TFLOPS/W (FE) and 3.78 TOPS/W (classifier), Clo-HDnn delivers 7.77x and 4.85x higher energy efficiency compared to SOTA ODL accelerators.",
      "authors": [
        "Chang Eun Song",
        "Weihong Xu",
        "Keming Fan",
        "Soumil Jain",
        "Gopabandhu Hota",
        "Haichao Yang",
        "Leo Liu",
        "Kerem Akarvardar",
        "Meng-Fan Chang",
        "Carlos H. Diaz",
        "Gert Cauwenberghs",
        "Tajana Rosing",
        "Mingu Kang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:50:28+00:00",
          "link": "https://arxiv.org/abs/2507.17953v1",
          "size": "3240kb",
          "version": "v1"
        }
      ],
      "title": "Clo-HDnn: A 4.66 TFLOPS/W and 3.78 TOPS/W Continual On-Device Learning Accelerator with Energy-efficient Hyperdimensional Computing via Progressive Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17953",
        "HTML": "https://arxiv.org/html/2507.17953v1",
        "PDF": "https://arxiv.org/pdf/2507.17953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an on-device learning accelerator, Clo-HDnn, for continual learning tasks, emphasizing hardware efficiency and hyperdimensional computing, not training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17956",
      "abstract": "The modular inverse is an essential piece of computation required for elliptic curve operations used for digital signatures in Bitcoin and other applications. A novel approach to the extended Euclidean algorithm has been developed by Bernstein and Yang within the last few years and incorporated into the libsecp256k1 cryptographic library used by Bitcoin. However, novel algorithms introduce new risks of errors. To address this we have completed a computer verified proof of the correctness of (one of) libsecp256k1's modular inverse implementations with the Coq proof assistant using the Verifiable C's implementation of separation logic.",
      "authors": [
        "Russell O'Connor and Andrew Poelstra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:57:30+00:00",
          "link": "https://arxiv.org/abs/2507.17956v1",
          "size": "283kb",
          "version": "v1"
        }
      ],
      "title": "Formal Verification of the Safegcd Implementation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17956",
        "PDF": "https://arxiv.org/pdf/2507.17956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes formal verification of a cryptographic implementation, specifically related to elliptic curve operations, and does not discuss LLM training data processing at all."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17957",
      "abstract": "In Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS), a model is trained on labeled source domain data (e.g., synthetic images) and adapted to an unlabeled target domain (e.g., real-world images) without access to target annotations. Existing UDA-SS methods often struggle to balance fine-grained local details with global contextual information, leading to segmentation errors in complex regions. To address this, we introduce the Adaptive Feature Refinement (AFR) module, which enhances segmentation accuracy by refining highresolution features using semantic priors from low-resolution logits. AFR also integrates high-frequency components, which capture fine-grained structures and provide crucial boundary information, improving object delineation. Additionally, AFR adaptively balances local and global information through uncertaintydriven attention, reducing misclassifications. Its lightweight design allows seamless integration into HRDA-based UDA methods, leading to state-of-the-art segmentation performance. Our approach improves existing UDA-SS methods by 1.05% mIoU on GTA V --> Cityscapes and 1.04% mIoU on Synthia-->Cityscapes. The implementation of our framework is available at: https://github.com/Masrur02/AFRDA",
      "authors": [
        "Md. Al-Masrur Khan",
        "Durgakant Pushp",
        "and Lantao Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:02:17+00:00",
          "link": "https://arxiv.org/abs/2507.17957v1",
          "size": "27103kb",
          "version": "v1"
        }
      ],
      "title": "AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17957",
        "HTML": "https://arxiv.org/html/2507.17957v1",
        "PDF": "https://arxiv.org/pdf/2507.17957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Unsupervised Domain Adaptive Semantic Segmentation for computer vision tasks and does not address LLM training data processing or contribute to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17958",
      "abstract": "We present VIBE, a two-stage Transformer that fuses multi-modal video, audio, and text features to predict fMRI activity. Representations from open-source models (Qwen2.5, BEATs, Whisper, SlowFast, V-JEPA) are merged by a modality-fusion transformer and temporally decoded by a prediction transformer with rotary embeddings. Trained on 65 hours of movie data from the CNeuroMod dataset and ensembled across 20 seeds, VIBE attains mean parcel-wise Pearson correlations of 32.25 on in-distribution Friends S07 and 21.25 on six out-of-distribution films. An earlier iteration of the same architecture obtained 0.3198 and 0.2096, respectively, winning Phase-1 and placing second overall in the Algonauts 2025 Challenge.",
      "authors": [
        "Daniel Carlstrom Schad",
        "Shrey Dixit",
        "Janis Keck",
        "Viktor Studenyak",
        "Aleksandr Shpilevoi",
        "Andrej Bicanski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:02:56+00:00",
          "link": "https://arxiv.org/abs/2507.17958v1",
          "size": "4434kb",
          "version": "v1"
        }
      ],
      "title": "VIBE: Video-Input Brain Encoder for fMRI Response Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17958",
        "HTML": "https://arxiv.org/html/2507.17958v1",
        "PDF": "https://arxiv.org/pdf/2507.17958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents VIBE, which models fMRI activity using multi-modal inputs and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17959",
      "abstract": "Engagement in virtual learning is essential for participant satisfaction, performance, and adherence, particularly in online education and virtual rehabilitation, where interactive communication plays a key role. Yet, accurately measuring engagement in virtual group settings remains a challenge. There is increasing interest in using artificial intelligence (AI) for large-scale, real-world, automated engagement recognition. While engagement has been widely studied in younger academic populations, research and datasets focused on older adults in virtual and telehealth learning settings remain limited. Existing methods often neglect contextual relevance and the longitudinal nature of engagement across sessions. This paper introduces OPEN (Older adult Patient ENgagement), a novel dataset supporting AI-driven engagement recognition. It was collected from eleven older adults participating in weekly virtual group learning sessions over six weeks as part of cardiac rehabilitation, producing over 35 hours of data, making it the largest dataset of its kind. To protect privacy, raw video is withheld; instead, the released data include facial, hand, and body joint landmarks, along with affective and behavioral features extracted from video. Annotations include binary engagement states, affective and behavioral labels, and context-type indicators, such as whether the instructor addressed the group or an individual. The dataset offers versions with 5-, 10-, 30-second, and variable-length samples. To demonstrate utility, multiple machine learning and deep learning models were trained, achieving engagement recognition accuracy of up to 81 percent. OPEN provides a scalable foundation for personalized engagement modeling in aging populations and contributes to broader engagement recognition research.",
      "authors": [
        "Ali Abedi",
        "Sadaf Safa",
        "Tracey J.F. Colella",
        "Shehroz S. Khan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:03:29+00:00",
          "link": "https://arxiv.org/abs/2507.17959v1",
          "size": "1385kb",
          "version": "v1"
        }
      ],
      "title": "OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17959",
        "HTML": "https://arxiv.org/html/2507.17959v1",
        "PDF": "https://arxiv.org/pdf/2507.17959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces the OPEN dataset for engagement recognition in virtual rehabilitation, which does not pertain to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17962",
      "abstract": "Achieving timing closure and design-specific optimizations in FPGA-targeted High-Level Synthesis (HLS) remains a significant challenge due to the complex interaction between architectural constraints, resource utilization, and the absence of automated support for platform-specific pragmas. In this work, we propose TimelyHLS, a novel framework integrating Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) to automatically generate and iteratively refine HLS code optimized for FPGA-specific timing and performance requirements. TimelyHLS is driven by a structured architectural knowledge base containing FPGA-specific features, synthesis directives, and pragma templates. Given a kernel, TimelyHLS generates HLS code annotated with both timing-critical and design-specific pragmas. The synthesized RTL is then evaluated using commercial toolchains, and simulation correctness is verified against reference outputs via custom testbenches. TimelyHLS iteratively incorporates synthesis logs and performance reports into the LLM engine for refinement in the presence of functional discrepancies. Experimental results across 10 FPGA architectures and diverse benchmarks show that TimelyHLS reduces the need for manual tuning by up to 70%, while achieving up to 4x latency speedup (e.g., 3.85x for Matrix Multiplication, 3.7x for Bitonic Sort) and over 50% area savings in certain cases (e.g., 57% FF reduction in Viterbi). TimelyHLS consistently achieves timing closure and functional correctness across platforms, highlighting the effectiveness of LLM-driven, architecture-aware synthesis in automating FPGA design.",
      "authors": [
        "Nowfel Mashnoor",
        "Mohammad Akyash",
        "Hadi Kamali",
        "Kimia Azar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:08:15+00:00",
          "link": "https://arxiv.org/abs/2507.17962v1",
          "size": "376kb",
          "version": "v1"
        }
      ],
      "title": "TimelyHLS: LLM-Based Timing-Aware and Architecture-Specific FPGA HLS Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17962",
        "HTML": "https://arxiv.org/html/2507.17962v1",
        "PDF": "https://arxiv.org/pdf/2507.17962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes TimelyHLS, a framework for FPGA HLS optimization using LLMs, focusing on hardware design and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17963",
      "abstract": "Recent advances in text-to-video generation have enabled high-quality synthesis from text and image prompts. While the personalization of dynamic concepts, which capture subject-specific appearance and motion from a single video, is now feasible, most existing methods require per-instance fine-tuning, limiting scalability. We introduce a fully zero-shot framework for dynamic concept personalization in text-to-video models. Our method leverages structured 2x2 video grids that spatially organize input and output pairs, enabling the training of lightweight Grid-LoRA adapters for editing and composition within these grids. At inference, a dedicated Grid Fill module completes partially observed layouts, producing temporally coherent and identity preserving outputs. Once trained, the entire system operates in a single forward pass, generalizing to previously unseen dynamic concepts without any test-time optimization. Extensive experiments demonstrate high-quality and consistent results across a wide range of subjects beyond trained concepts and editing scenarios.",
      "authors": [
        "Rameen Abdal",
        "Or Patashnik",
        "Ekaterina Deyneka",
        "Hao Chen",
        "Aliaksandr Siarohin",
        "Sergey Tulyakov",
        "Daniel Cohen-Or",
        "Kfir Aberman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:09:38+00:00",
          "link": "https://arxiv.org/abs/2507.17963v1",
          "size": "12697kb",
          "version": "v1"
        }
      ],
      "title": "Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17963",
        "HTML": "https://arxiv.org/html/2507.17963v1",
        "PDF": "https://arxiv.org/pdf/2507.17963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses zero-shot dynamic concept personalization in text-to-video models, which does not involve LLM training data processing techniques or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17974",
      "abstract": "Despite being spoken by millions of people, Tigrinya remains severely underrepresented in Natural Language Processing (NLP) research. This work presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40 studies spanning more than a decade of work from 2011 to 2025. We systematically review the current state of computational resources, models, and applications across ten distinct downstream tasks, including morphological processing, machine translation, speech recognition, and question-answering. Our analysis reveals a clear trajectory from foundational, rule-based systems to modern neural architectures, with progress consistently unlocked by resource creation milestones. We identify key challenges rooted in Tigrinya's morphological complexity and resource scarcity, while highlighting promising research directions, including morphology-aware modeling, cross-lingual transfer, and community-centered resource development. This work serves as both a comprehensive reference for researchers and a roadmap for advancing Tigrinya NLP. A curated metadata of the surveyed studies and resources is made publicly available.\\footnote{Tigrinya NLP Anthology: https://github.com/fgaim/tigrinya-nlp-anthology.",
      "authors": [
        "Fitsum Gaim and Jong C. Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:45:30+00:00",
          "link": "https://arxiv.org/abs/2507.17974v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Natural Language Processing for Tigrinya: Current State and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17974",
        "PDF": "https://arxiv.org/pdf/2507.17974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper reviews NLP research for Tigrinya, mentioning resource creation milestones. However, the main focus is on surveying existing literature and setting future research directions, not on making a technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17976",
      "abstract": "In a Conversational Image Recommendation task, users can provide natural language feedback on a recommended image item, which leads to an improved recommendation in the next turn. While typical instantiations of this task assume that the user's target item will (eventually) be returned, this might often not be true, for example, the item the user seeks is not within the item catalogue. Failing to return a user's desired item can lead to user frustration, as the user needs to interact with the system for an increased number of turns. To mitigate this issue, in this paper, we introduce the task of Supervised Conversational Performance Prediction, inspired by Query Performance Prediction (QPP) for predicting effectiveness in response to a search engine query. In this regard, we propose predictors for conversational performance that detect conversation failures using multi-turn semantic information contained in the embedded representations of retrieved image items. Specifically, our AutoEncoder-based predictor learns a compressed representation of top-retrieved items of the train turns and uses the classification labels to predict the evaluation turn. Our evaluation scenario addressed two recommendation scenarios, by differentiating between system failure, where the system is unable to find the target, and catalogue failure, where the target does not exist in the item catalogue. In our experiments using the Shoes and FashionIQ Dresses datasets, we measure the accuracy of predictors for both system and catalogue failures. Our results demonstrate the promise of our proposed predictors for predicting system failures (existing evaluation scenario), while we detect a considerable decrease in predictive performance in the case of catalogue failure prediction (when inducing a missing item scenario) compared to system failures.",
      "authors": [
        "Maria Vlachou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:51:08+00:00",
          "link": "https://arxiv.org/abs/2507.17976v1",
          "size": "323kb",
          "version": "v1"
        }
      ],
      "title": "Failure Prediction in Conversational Recommendation Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17976",
        "HTML": "https://arxiv.org/html/2507.17976v1",
        "PDF": "https://arxiv.org/pdf/2507.17976"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses failure prediction in conversational recommendation systems. It does not address LLM training data processing, focusing instead on recommendation system performance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17977",
      "abstract": "Accurate modeling and explaining geospatial tabular data (GTD) are critical for understanding geospatial phenomena and their underlying processes. Recent work has proposed a novel transformer-based deep learning model named GeoAggregator (GA) for this purpose, and has demonstrated that it outperforms other statistical and machine learning approaches. In this short paper, we further improve GA by 1) developing an optimized pipeline that accelerates the dataloading process and streamlines the forward pass of GA to achieve better computational efficiency; and 2) incorporating a model ensembling strategy and a post-hoc model explanation function based on the GeoShapley framework to enhance model explainability. We validate the functionality and efficiency of the proposed strategies by applying the improved GA model to synthetic datasets. Experimental results show that our implementation improves the prediction accuracy and inference speed of GA compared to the original implementation. Moreover, explanation experiments indicate that GA can effectively captures the inherent spatial effects in the designed synthetic dataset. The complete pipeline has been made publicly available for community use (https://github.com/ruid7181/GA-sklearn).",
      "authors": [
        "Rui Deng",
        "Ziqi Li and Mingshu Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:51:09+00:00",
          "link": "https://arxiv.org/abs/2507.17977v1",
          "size": "215kb",
          "version": "v1"
        }
      ],
      "title": "Improving the Computational Efficiency and Explainability of GeoAggregator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17977",
        "HTML": "https://arxiv.org/html/2507.17977v1",
        "PDF": "https://arxiv.org/pdf/2507.17977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work improves the computational efficiency and explainability of a geospatial data model, GeoAggregator. It does not pertain to LLM training data processing but focuses on geospatial modeling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17978",
      "abstract": "Phishing emails continue to pose a significant threat to cybersecurity by exploiting human vulnerabilities through deceptive content and malicious payloads. While Machine Learning (ML) models are effective at detecting phishing threats, their performance largely relies on the quality and diversity of the training data. This paper presents MeAJOR (Merged email Assets from Joint Open-source Repositories) Corpus, a novel, multi-source phishing email dataset designed to overcome critical limitations in existing resources. It integrates 135894 samples representing a broad number of phishing tactics and legitimate emails, with a wide spectrum of engineered features. We evaluated the dataset's utility for phishing detection research through systematic experiments with four classification models (RF, XGB, MLP, and CNN) across multiple feature configurations. Results highlight the dataset's effectiveness, achieving 98.34% F1 with XGB. By integrating broad features from multiple categories, our dataset provides a reusable and consistent resource, while addressing common challenges like class imbalance, generalisability and reproducibility.",
      "authors": [
        "Paulo Mendes (1)",
        "Eva Maia (1)",
        "Isabel Pra\\c{c}a (1) ((1) GECAD",
        "ISEP",
        "Polytechnic of Porto",
        "Portugal)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:57:08+00:00",
          "link": "https://arxiv.org/abs/2507.17978v1",
          "size": "98kb",
          "version": "v1"
        }
      ],
      "title": "MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17978",
        "HTML": "https://arxiv.org/html/2507.17978v1",
        "PDF": "https://arxiv.org/pdf/2507.17978"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the MeAJOR Corpus, a dataset for phishing email detection, addressing issues like class imbalance and data quality. While not directly related to LLMs, it involves the creation and processing of a dataset for machine learning, contributing to data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17979",
      "abstract": "Identifying the factors driving data shifts in tabular datasets is a significant challenge for analysis and decision support systems, especially those focusing on healthcare. Privacy rules restrict data access, and noise from complex processes hinders analysis. To address this challenge, we propose SIFOTL (Statistically-Informed Fidelity-Optimization Method for Tabular Learning) that (i) extracts privacy-compliant data summary statistics, (ii) employs twin XGBoost models to disentangle intervention signals from noise with assistance from LLMs, and (iii) merges XGBoost outputs via a Pareto-weighted decision tree to identify interpretable segments responsible for the shift. Unlike existing analyses which may ignore noise or require full data access for LLM-based analysis, SIFOTL addresses both challenges using only privacy-safe summary statistics. Demonstrating its real-world efficacy, for a MEPS panel dataset mimicking a new Medicare drug subsidy, SIFOTL achieves an F1 score of 0.85, substantially outperforming BigQuery Contribution Analysis (F1=0.46) and statistical tests (F1=0.20) in identifying the segment receiving the subsidy. Furthermore, across 18 diverse EHR datasets generated based on Synthea ABM, SIFOTL sustains F1 scores of 0.86-0.96 without noise and >= 0.75 even with injected observational noise, whereas baseline average F1 scores range from 0.19-0.67 under the same tests. SIFOTL, therefore, provides an interpretable, privacy-conscious workflow that is empirically robust to observational noise.",
      "authors": [
        "Shubham Mohole",
        "Sainyam Galhotra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:00:24+00:00",
          "link": "https://arxiv.org/abs/2507.17979v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "SIFOTL: A Principled, Statistically-Informed Fidelity-Optimization Method for Tabular Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17979",
        "HTML": "https://arxiv.org/html/2507.17979v1",
        "PDF": "https://arxiv.org/pdf/2507.17979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces SIFOTL, which is a method for interpreting tabular learning datasets in a privacy-conscious manner. It focuses on data analysis and decision-support processes, not directly related to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17981",
      "abstract": "In the context of single-winner ranked-choice elections between $m$ candidates, we explore the tradeoff between two competing goals in every democratic system: the majority principle (maximizing the social welfare) and the minority principle (safeguarding minority groups from overly bad outcomes).To measure the social welfare, we use the well-established framework of metric distortion subject to various objectives: utilitarian (i.e., total cost), $\\alpha$-percentile (e.g., median cost for $\\alpha = 1/2$), and egalitarian (i.e., max cost). To measure the protection of minorities, we introduce the $\\ell$-mutual minority criterion, which requires that if a sufficiently large (parametrized by $\\ell$) coalition $T$ of voters ranks all candidates in $S$ lower than all other candidates, then none of the candidates in $S$ should win. The highest $\\ell$ for which the criterion is satisfied provides a well-defined measure of mutual minority protection (ranging from 1 to $m$).\n  Our main contribution is the analysis of a recently proposed class of voting rules called $k$-Approval Veto, offering a comprehensive range of trade-offs between the two principles. This class spans between Plurality Veto (for $k=1$) - a simple voting rule achieving optimal metric distortion - and Vote By Veto (for $k=m$) which picks a candidate from the proportional veto core. We show that $k$-Approval Veto has minority protection at least $k$, and thus, it accommodates any desired level of minority protection. However, this comes at the price of lower social welfare. For the utilitarian objective, the metric distortion increases linearly in $k$. For the $\\alpha$-percentile objective, the metric distortion is the optimal value of 5 for $\\alpha \\ge k/(k+1)$ and unbounded for $\\alpha < k/(k+1)$. For the egalitarian objective, the metric distortion is the optimal value of 3 for all values of $k$.",
      "authors": [
        "Fatih Erdem Kizilkaya and David Kempe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:04:16+00:00",
          "link": "https://arxiv.org/abs/2507.17981v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "$k$-Approval Veto: A Spectrum of Voting Rules Balancing Metric Distortion and Minority Protection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17981",
        "HTML": "https://arxiv.org/html/2507.17981v1",
        "PDF": "https://arxiv.org/pdf/2507.17981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses $k$-Approval Veto voting rules and the balance between metric distortion and minority protection in elections. This topic is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17984",
      "abstract": "Data-driven traffic state estimation and prediction (TSEP) relies heavily on data sources that contain sensitive information. While the abundance of data has fueled significant breakthroughs, particularly in machine learning-based methods, it also raises concerns regarding privacy, cybersecurity, and data freshness. These issues can erode public trust in intelligent transportation systems. Recently, regulations have introduced the \"right to be forgotten\", allowing users to request the removal of their private data from models. As machine learning models can remember old data, simply removing it from back-end databases is insufficient in such systems. To address these challenges, this study introduces a novel learning paradigm for TSEP-Machine Unlearning TSEP-which enables a trained TSEP model to selectively forget privacy-sensitive, poisoned, or outdated data. By empowering models to \"unlearn,\" we aim to enhance the trustworthiness and reliability of data-driven traffic TSEP.",
      "authors": [
        "Xin Wang",
        "R. Tyrrell Rockafellar",
        "Xuegang (Jeff) Ban"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:23:18+00:00",
          "link": "https://arxiv.org/abs/2507.17984v1",
          "size": "765kb",
          "version": "v1"
        }
      ],
      "title": "Machine Unlearning of Traffic State Estimation and Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17984",
        "HTML": "https://arxiv.org/html/2507.17984v1",
        "PDF": "https://arxiv.org/pdf/2507.17984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces a machine learning paradigm for 'unlearning' specific data in traffic state estimation to address privacy concerns. It doesn't address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17985",
      "abstract": "The integration of large language models (LLMs) into educational tools has the potential to substantially impact how teachers plan instruction, support diverse learners, and engage in professional reflection. Yet little is known about how educators actually use these tools in practice and how their interactions with AI can be meaningfully studied at scale. This paper presents a human-AI collaborative methodology for large-scale qualitative analysis of over 140,000 educator-AI messages drawn from a generative AI platform used by K-12 teachers. Through a four-phase coding pipeline, we combined inductive theme discovery, codebook development, structured annotation, and model benchmarking to examine patterns of educator engagement and evaluate the performance of LLMs in qualitative coding tasks. We developed a hierarchical codebook aligned with established teacher evaluation frameworks, capturing educators' instructional goals, contextual needs, and pedagogical strategies. Our findings demonstrate that LLMs, particularly Claude 3.5 Haiku, can reliably support theme identification, extend human recognition in complex scenarios, and outperform open-weight models in both accuracy and structural reliability. The analysis also reveals substantive patterns in how educators inquire AI to enhance instructional practices (79.7 percent of total conversations), create or adapt content (76.1 percent), support assessment and feedback loop (46.9 percent), attend to student needs for tailored instruction (43.3 percent), and assist other professional responsibilities (34.2 percent), highlighting emerging AI-related competencies that have direct implications for teacher preparation and professional development. This study offers a scalable, transparent model for AI-augmented qualitative research and provides foundational insights into the evolving role of generative AI in educational practice.",
      "authors": [
        "Alex Liu",
        "Lief Esbenshade",
        "Shawon Sarkar",
        "Victor Tian",
        "Zachary Zhang",
        "Kevin He",
        "Min Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:23:38+00:00",
          "link": "https://arxiv.org/abs/2507.17985v1",
          "size": "1078kb",
          "version": "v1"
        }
      ],
      "title": "Decoding Instructional Dialogue: Human-AI Collaborative Analysis of Teacher Use of AI Tool at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17985",
        "PDF": "https://arxiv.org/pdf/2507.17985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a methodology for analyzing teacher interactions with AI in an educational setting, focusing on usage patterns and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17987",
      "abstract": "Traditional monitoring of bearded dragon (Pogona Viticeps) behaviour is time-consuming and prone to errors. This project introduces an automated system for real-time video analysis, using You Only Look Once (YOLO) object detection models to identify two key behaviours: basking and hunting. We trained five YOLO variants (v5, v7, v8, v11, v12) on a custom, publicly available dataset of 1200 images, encompassing bearded dragons (600), heating lamps (500), and crickets (100). YOLOv8s was selected as the optimal model due to its superior balance of accuracy (mAP@0.5:0.95 = 0.855) and speed. The system processes video footage by extracting per-frame object coordinates, applying temporal interpolation for continuity, and using rule-based logic to classify specific behaviours. Basking detection proved reliable. However, hunting detection was less accurate, primarily due to weak cricket detection (mAP@0.5 = 0.392). Future improvements will focus on enhancing cricket detection through expanded datasets or specialised small-object detectors. This automated system offers a scalable solution for monitoring reptile behaviour in controlled environments, significantly improving research efficiency and data quality.",
      "authors": [
        "Arsen Yermukan",
        "Pedro Machado",
        "Feliciano Domingos",
        "Isibor Kennedy Ihianle",
        "Jordan J. Bird",
        "Stefano S. K. Kaburu",
        "Samantha J. Ward"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:35:11+00:00",
          "link": "https://arxiv.org/abs/2507.17987v1",
          "size": "1603kb",
          "version": "v1"
        }
      ],
      "title": "Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17987",
        "HTML": "https://arxiv.org/html/2507.17987v1",
        "PDF": "https://arxiv.org/pdf/2507.17987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on automating behavioral monitoring of bearded dragons using object detection models, and while it mentions a custom dataset, it does not contribute to LLM training data processing, as it pertains to a specialized domain not related to pretraining or fine-tuning of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17988",
      "abstract": "Qualitative timeline-based planning models domains as sets of independent, but\n  interacting, components whose behaviors over time, the timelines, are governed\n  by sets of qualitative temporal constraints (ordering relations), called\n  synchronization rules.\n  Its plan-existence problem has been shown to be PSPACE-complete; in\n  particular, PSPACE-membership has been proved via reduction to the\n  nonemptiness problem for nondeterministic finite automata.\n  However, nondeterministic automata cannot be directly used to synthesize\n  planning strategies as a costly determinization step is needed.\n  In this paper, we identify a fragment of qualitative timeline-based planning\n  whose plan-existence problem can be directly mapped into the nonemptiness\n  problem of deterministic finite automata, which can then\n  synthesize strategies.\n  In addition, we identify a maximal subset of Allen's relations that fits into\n  such a deterministic fragment.",
      "authors": [
        "Dario Della Monica",
        "Angelo Montanari",
        "Pietro Sala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:39:04+00:00",
          "link": "https://arxiv.org/abs/2507.17988v1",
          "size": "228kb",
          "version": "v1"
        }
      ],
      "title": "Synthesis of timeline-based planning strategies avoiding determinization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17988",
        "HTML": "https://arxiv.org/html/2507.17988v1",
        "PDF": "https://arxiv.org/pdf/2507.17988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses timeline-based planning strategies and deterministic finite automata, which is unrelated to LLM training data processing. It does not cover any aspect of data processing for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17990",
      "abstract": "Designing industrial systems, such as building, improving, and automating distribution centers and manufacturing plants, involves critical decision-making with limited information in the early phases. The lack of information leads to less accurate designs of the systems, which are often difficult to resolve later. It is effective to use simulators to model the designed system and find out the issues early. However, the modeling time required by conventional simulators is too long to allow for rapid model creation to meet decision-making demands. In this paper, we propose a Rapid Modeling Architecture (RMA) for a lightweight industrial simulator that mitigates the modeling burden while maintaining the essential details in order to accelerate and improve decision-making. We have prototyped a simulator based on the RMA and applied it to the actual factory layout design problem. We also compared the modeling time of our simulator to that of an existing simulator, and as a result, our simulator achieved a 78.3% reduction in modeling time compared to conventional simulators.",
      "authors": [
        "Takumi Kato and Zhi Li Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:46:57+00:00",
          "link": "https://arxiv.org/abs/2507.17990v1",
          "size": "5438kb",
          "version": "v1"
        }
      ],
      "title": "Rapid Modeling Architecture for Lightweight Simulator to Accelerate and Improve Decision Making for Industrial Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17990",
        "HTML": "https://arxiv.org/html/2507.17990v1",
        "PDF": "https://arxiv.org/pdf/2507.17990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a rapid modeling architecture for simulators used in industrial systems' decision-making. It does not involve data processing for LLMs, nor does it address training data processing operations or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17991",
      "abstract": "The causes of the reproducibility crisis include lack of standardization and transparency in scientific reporting. Checklists such as ARRIVE and CONSORT seek to improve transparency, but they are not always followed by authors and peer review often fails to identify missing items. To address these issues, there are several automated tools that have been designed to check different rigor criteria. We have conducted a broad comparison of 11 automated tools across 9 different rigor criteria from the ScreenIT group. We found some criteria, including detecting open data, where the combination of tools showed a clear winner, a tool which performed much better than other tools. In other cases, including detection of inclusion and exclusion criteria, the combination of tools exceeded the performance of any one tool. We also identified key areas where tool developers should focus their effort to make their tool maximally useful. We conclude with a set of insights and recommendations for stakeholders in the development of rigor and transparency detection tools. The code and data for the study is available at https://github.com/PeterEckmann1/tool-comparison.",
      "authors": [
        "Peter Eckmann",
        "Adrian Barnett",
        "Alexandra Bannach-Brown",
        "Elisa Pilar Bascunan Atria",
        "Guillaume Cabanac",
        "Louise Delwen Owen Franzen",
        "Ma{\\l}gorzata Anna Gazda",
        "Kaitlyn Hair",
        "James Howison",
        "Halil Kilicoglu",
        "Cyril Labbe",
        "Sarah McCann",
        "Vladislav Nachev",
        "Martijn Roelandse",
        "Maia Salholz-Hillel",
        "Robert Schulz",
        "Gerben ter Riet",
        "Colby Vorland",
        "Anita Bandrowski",
        "Tracey Weissgerber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:49:28+00:00",
          "link": "https://arxiv.org/abs/2507.17991v1",
          "size": "451kb",
          "version": "v1"
        }
      ],
      "title": "Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17991",
        "HTML": "https://arxiv.org/html/2507.17991v1",
        "PDF": "https://arxiv.org/pdf/2507.17991"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on evaluating tools for checking rigor and transparency in scientific reporting, which is not related to LLM training data processing. It does not involve any aspect of data collection, filtering, or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17995",
      "abstract": "Person re-identification (Re-ID) across visible and infrared modalities is crucial for 24-hour surveillance systems, but existing datasets primarily focus on ground-level perspectives. While ground-based IR systems offer nighttime capabilities, they suffer from occlusions, limited coverage, and vulnerability to obstructions--problems that aerial perspectives uniquely solve. To address these limitations, we introduce AG-VPReID.VIR, the first aerial-ground cross-modality video-based person Re-ID dataset. This dataset captures 1,837 identities across 4,861 tracklets (124,855 frames) using both UAV-mounted and fixed CCTV cameras in RGB and infrared modalities. AG-VPReID.VIR presents unique challenges including cross-viewpoint variations, modality discrepancies, and temporal dynamics. Additionally, we propose TCC-VPReID, a novel three-stream architecture designed to address the joint challenges of cross-platform and cross-modality person Re-ID. Our approach bridges the domain gaps between aerial-ground perspectives and RGB-IR modalities, through style-robust feature learning, memory-based cross-view adaptation, and intermediary-guided temporal modeling. Experiments show that AG-VPReID.VIR presents distinctive challenges compared to existing datasets, with our TCC-VPReID framework achieving significant performance gains across multiple evaluation protocols. Dataset and code are available at https://github.com/agvpreid25/AG-VPReID.VIR.",
      "authors": [
        "Huy Nguyen",
        "Kien Nguyen",
        "Akila Pemasiri",
        "Akmal Jahan",
        "Clinton Fookes",
        "and Sridha Sridharan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:13:25+00:00",
          "link": "https://arxiv.org/abs/2507.17995v1",
          "size": "18340kb",
          "version": "v1"
        }
      ],
      "title": "AG-VPReID.VIR: Bridging Aerial and Ground Platforms for Video-based Visible-Infrared Person Re-ID",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17995",
        "HTML": "https://arxiv.org/html/2507.17995v1",
        "PDF": "https://arxiv.org/pdf/2507.17995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a dataset for person re-identification across different modalities and platforms without any relevance to LLM training data processing. It does not contribute to techniques or datasets for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17996",
      "abstract": "Systematic mislabelling affecting specific subgroups (i.e., label bias) in medical imaging datasets represents an understudied issue concerning the fairness of medical AI systems. In this work, we investigated how size and separability of subgroups affected by label bias influence the learned features and performance of a deep learning model. Therefore, we trained deep learning models for binary tissue density classification using the EMory BrEast imaging Dataset (EMBED), where label bias affected separable subgroups (based on imaging manufacturer) or non-separable \"pseudo-subgroups\". We found that simulated subgroup label bias led to prominent shifts in the learned feature representations of the models. Importantly, these shifts within the feature space were dependent on both the relative size and the separability of the subgroup affected by label bias. We also observed notable differences in subgroup performance depending on whether a validation set with clean labels was used to define the classification threshold for the model. For instance, with label bias affecting the majority separable subgroup, the true positive rate for that subgroup fell from 0.898, when the validation set had clean labels, to 0.518, when the validation set had biased labels. Our work represents a key contribution toward understanding the consequences of label bias on subgroup fairness in medical imaging AI.",
      "authors": [
        "Emma A.M. Stanley",
        "Raghav Mehta",
        "M\\'elanie Roschewitz",
        "Nils D. Forkert",
        "Ben Glocker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:21:12+00:00",
          "link": "https://arxiv.org/abs/2507.17996v1",
          "size": "411kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the interplay of label bias with subgroup size and separability: A case study in mammographic density classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17996",
        "HTML": "https://arxiv.org/html/2507.17996v1",
        "PDF": "https://arxiv.org/pdf/2507.17996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores the impact of label bias in medical imaging datasets, which does not pertain to LLM training data processing. It focuses on subgroup fairness in medical AI rather than contributing to LLM-specific data operations or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17997",
      "abstract": "In this work we study the identification of spatial correlation in distributions of 2D scalar fields, presented across different forms of visual displays. We study simple visual displays that directly show color-mapped scalar fields, namely those drawn from a distribution, and whether humans can identify strongly correlated spatial regions in these displays. In this setting, the recognition of correlation requires making judgments on a set of fields, rather than just one field. Thus, in our experimental design we compare two basic visualization designs: animation-based displays against juxtaposed views of scalar fields, along different choices of color scales. Moreover, we investigate the impacts of the distribution itself, controlling for the level of spatial correlation and discriminability in spatial scales. Our study's results illustrate the impacts of these distribution characteristics, while also highlighting how different visual displays impact the types of judgments made in assessing spatial correlation. Supplemental material is available at https://osf.io/zn4qy",
      "authors": [
        "Yayan Zhao and Matthew Berger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:25:56+00:00",
          "link": "https://arxiv.org/abs/2507.17997v1",
          "size": "3180kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating judgment of spatial correlation in visual displays of scalar field distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17997",
        "HTML": "https://arxiv.org/html/2507.17997v1",
        "PDF": "https://arxiv.org/pdf/2507.17997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines human judgment of spatial correlations in visual scalar fields, which is unrelated to LLM training data processing. It discusses visualization techniques rather than data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17998",
      "abstract": "Affine Grassmannian has been favored for expressing proximity between lines and planes due to its theoretical exactness in measuring distances among features. Despite this advantage, the existing method can only measure the proximity without yielding the distance as an explicit function of rigid body transformation. Thus, an optimizable distance function on the manifold has remained underdeveloped, stifling its application in registration problems. This paper is the first to explicitly derive an optimizable cost function between two Grassmannian features with respect to rigid body transformation ($\\mathbf{R}$ and $\\mathbf{t}$). Specifically, we present a rigorous mathematical proof demonstrating that the bases of high-dimensional linear subspaces can serve as an explicit representation of the cost. Finally, we propose an optimizable cost function based on the transformed bases that can be applied to the registration problem of any affine subspace. Compared to vector parameter-based approaches, our method is able to find a globally optimal solution by directly minimizing the geodesic distance which is agnostic to representation ambiguity. The resulting cost function and its extension to the inlier-set maximizing \\ac{BnB} solver have been demonstrated to improve the convergence of existing solutions or outperform them in various computer vision tasks. The code is available on https://github.com/joomeok/GrassmannRegistration.",
      "authors": [
        "Jaeho Shin",
        "Hyeonjae Gil",
        "Junwoo Jang",
        "Maani Ghaffari",
        "Ayoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:28:01+00:00",
          "link": "https://arxiv.org/abs/2507.17998v1",
          "size": "1677kb",
          "version": "v1"
        }
      ],
      "title": "Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17998",
        "HTML": "https://arxiv.org/html/2507.17998v1",
        "PDF": "https://arxiv.org/pdf/2507.17998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on affine subspace alignment using mathematical methods for computer vision tasks, not on any aspect of LLM training data processing or dataset creation relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17999",
      "abstract": "We show that the max entropy algorithm is a randomized 1.49776 approximation for half-integral TSP, improving upon the previous known bound of 1.49993 from Karlin et al. This also improves upon the best-known approximation for half-integral TSP due to Gupta et al. Our improvement results from using the dual, instead of the primal, to analyze the expected cost of the matching. We believe this method of analysis could lead to a simpler proof that max entropy is a better-than-3/2 approximation in the general case.\n  We also give a 1.4671 approximation for half integral LP solutions with no proper minimum cuts and an even number of vertices, improving upon the bound of Haddadan and Newman of 1.476. We then extend the analysis to the case when there are an odd number of vertices $n$ at the cost of an additional $O(1/n)$ factor.",
      "authors": [
        "Nathan Klein and Mehrshad Taziki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:30:17+00:00",
          "link": "https://arxiv.org/abs/2507.17999v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Dual Charging for Half-Integral TSP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17999",
        "HTML": "https://arxiv.org/html/2507.17999v1",
        "PDF": "https://arxiv.org/pdf/2507.17999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents advancements in approximation algorithms for half-integral TSP, which is unrelated to LLM training data or processing. It deals with optimization in mathematical problems, not LLM dataset engineering or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18001",
      "abstract": "Small-signal stability issues-induced broadband oscillations pose significant threats to the secure operation of multi-inverter systems, attracting extensive research attention. Researches revealed that system instability is led by the lacking of positive damping, yet it has not been clearly specified how much the exact amount of damping compensation required to sufficiently ensure system global stability. This paper presents a feasible solution for quantitative damping calculation and compensation to enhance the global stability of inverter-based systems. First, based on the system nodal admittance model, a quantitative damping calculation algorithm is presented, which can suggest the required damping compensation as well as compensation location for sufficient stability improvement. Then, we propose a specific AD with output current feedforward control strategy, which make the AD be quasi-pure resistive and can effectively enhance system damping efficiency. Finally, a testing system with three inverters is used as case study, showing that the proposed method provides a promising solution to efficiently enhance the global stability improvement of inverter-based systems. Simulations and experiments validate the proposed method.",
      "authors": [
        "Yang Li",
        "Zenghui Zheng",
        "Xiangyang Wu",
        "Jiayong Li",
        "Wei Wang",
        "Qiang Zeng",
        "Zhikang Shuai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:31:02+00:00",
          "link": "https://arxiv.org/abs/2507.18001v1",
          "size": "5775kb",
          "version": "v1"
        }
      ],
      "title": "Quantitative Damping Calculation and Compensation Method for Global Stability Improvement of Inverter-Based Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18001",
        "PDF": "https://arxiv.org/pdf/2507.18001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on stability improvement of inverter-based systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18004",
      "abstract": "How can AI move beyond imitation toward genuine creativity? This paper proposes the E.A.R.T.H. framework, a five-stage generative pipeline that transforms model-generated errors into creative assets through Error generation, Amplification, Refine selection, Transform, and Harness feedback. Drawing on cognitive science and generative modeling, we posit that \"creative potential hides in failure\" and operationalize this via structured prompts, semantic scoring, and human-in-the-loop evaluation. Implemented using LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the pipeline employs a composite reward function based on novelty, surprise, and relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to 1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4% improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a 4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment (CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones (3.99). Feedback highlights stylistic precision and emotional resonance. These results demonstrate that error-centered, feedback-driven generation enhances creativity, offering a scalable path toward self-evolving, human-aligned creative AI.",
      "authors": [
        "Yusen Peng",
        "Shuhua Mao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:39:19+00:00",
          "link": "https://arxiv.org/abs/2507.18004v1",
          "size": "3929kb",
          "version": "v1"
        }
      ],
      "title": "E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18004",
        "HTML": "https://arxiv.org/html/2507.18004v1",
        "PDF": "https://arxiv.org/pdf/2507.18004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses a generative AI framework that involves feedback-driven generation, it mainly centers on creativity and generative processes rather than focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18005",
      "abstract": "Microservices transform traditional monolithic applications into lightweight, loosely coupled application components and have been widely adopted in many enterprises. Cloud platform infrastructure providers enhance the resource utilization efficiency of microservices systems by co-locating different microservices. However, this approach also introduces resource competition and interference among microservices. Designing interference-aware strategies for large-scale, co-located microservice clusters is crucial for enhancing resource utilization and mitigating competition-induced interference. These challenges are further exacerbated by unreliable metrics, application diversity, and node heterogeneity.\n  In this paper, we first analyze the characteristics of large-scale and co-located microservices clusters at Alibaba and further discuss why cycle per instruction (CPI) is adopted as a metric for interference measurement in large-scale production clusters, as well as how to achieve accurate prediction of CPI through multi-dimensional metrics. Based on CPI interference prediction and analysis, we also present the design of the C-Koordinator platform, an open-source solution utilized in Alibaba cluster, which incorporates co-location and interference mitigation strategies. The interference prediction models consistently achieve over 90.3% accuracy, enabling precise prediction and rapid mitigation of interference in operational environments. As a result, application latency is reduced and stabilized across all percentiles (P50, P90, P99) response time (RT), achieving improvements ranging from 16.7% to 36.1% under various system loads compared with state-of-the-art system. These results demonstrate the system's ability to maintain smooth application performance in co-located environments.",
      "authors": [
        "Shengye Song",
        "Minxian Xu",
        "Zuowei Zhang",
        "Chengxi Gao",
        "Fansong Zeng",
        "Yu Ding",
        "Kejiang Ye",
        "Chengzhong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:49:41+00:00",
          "link": "https://arxiv.org/abs/2507.18005v1",
          "size": "1060kb",
          "version": "v1"
        }
      ],
      "title": "C-Koordinator: Interference-aware Management for Large-scale and Co-located Microservice Clusters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18005",
        "HTML": "https://arxiv.org/html/2507.18005v1",
        "PDF": "https://arxiv.org/pdf/2507.18005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with resource management and interference in microservice clusters, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18006",
      "abstract": "The rise of large language models (LLMs) has created new opportunities across various fields but has also introduced significant challenges in resource management. Current LLM serving systems face a fundamental tension: balancing serving demands with limited resources while adapting to unpredictable traffic patterns. Static deployments lead to suboptimal resource utilization and performance degradation under dynamic workloads. Furthermore, the high cost of adjusting instances hinders dynamic scaling, limiting the true potential of efficient LLM serving.\n  To address this, we propose CoCoServe, an elastic system that facilitates dynamic and fine-grained scaling. Its key innovation lies in the module-level operations for the replication and migration of LLM modules, such as decoder layers and projections. Through a comprehensive analysis of the trade-offs associated with these operations, we develop an auto-scaling mechanism that dynamically regulates module-level resource allocation and performance optimization, enabling a more cost-effective deployment of LLMs. Our evaluation demonstrates that the scaling operations employed by CoCoServe exhibit excellent scalability and can reduce costs by 46% while maintaining availability. Compared to state-of-the-art LLM serving systems (e.g., Hugging Face Transformers and vLLM), our approach reduces latency by 14%-75% and achieves 1.16x-4x throughput on average across different model sizes and workloads.",
      "authors": [
        "Jingfeng Wu",
        "Yiyuan He",
        "Minxian Xu",
        "Xitong Gao",
        "Kejiang Ye",
        "Chengzhong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:49:48+00:00",
          "link": "https://arxiv.org/abs/2507.18006v1",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "title": "Unlock the Potential of Fine-grained LLM Serving via Dynamic Module Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18006",
        "HTML": "https://arxiv.org/html/2507.18006v1",
        "PDF": "https://arxiv.org/pdf/2507.18006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on resource management and scaling for LLM serving, not on the processes involved in training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18007",
      "abstract": "Large Language Models (LLMs) are revolutionizing numerous industries, but their substantial computational demands create challenges for efficient deployment, particularly in cloud environments. Traditional approaches to inference serving often struggle with resource inefficiencies, leading to high operational costs, latency issues, and limited scalability. This article explores how Cloud Native technologies, such as containerization, microservices, and dynamic scheduling, can fundamentally improve LLM inference serving. By leveraging these technologies, we demonstrate how a Cloud Native system enables more efficient resource allocation, reduces latency, and enhances throughput in high-demand scenarios. Through real-world evaluations using Kubernetes-based autoscaling, we show that Cloud Native architectures can dynamically adapt to workload fluctuations, mitigating performance bottlenecks while optimizing LLM inference serving performance. This discussion provides a broader perspective on how Cloud Native frameworks could reshape the future of scalable LLM inference serving, offering key insights for researchers, practitioners, and industry leaders in cloud computing and artificial intelligence.",
      "authors": [
        "Minxian Xu",
        "Junhan Liao",
        "Jingfeng Wu",
        "Yiyuan He",
        "Kejiang Ye",
        "Chengzhong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:49:56+00:00",
          "link": "https://arxiv.org/abs/2507.18007v1",
          "size": "1579kb",
          "version": "v1"
        }
      ],
      "title": "Cloud Native System for LLM Inference Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18007",
        "HTML": "https://arxiv.org/html/2507.18007v1",
        "PDF": "https://arxiv.org/pdf/2507.18007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores cloud-native systems for LLM inference serving, which does not pertain to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18009",
      "abstract": "State-of-the-art (SOTA) image and text generation models are multimodal models that have many similarities to large language models (LLMs). Despite achieving strong performances, leading foundational multimodal model architectures frequently lag behind the architectural sophistication of contemporary LLMs. We propose GRR-CoCa, an improved SOTA Contrastive Captioner (CoCa) model that incorporates Gaussian error gated linear units, root mean squared normalization, and rotary positional embedding into the textual decoders and the vision transformer (ViT) encoder. Each architectural modification has been shown to improve model performance in LLMs, but has yet to be adopted in CoCa. We benchmarked GRR-CoCa against Baseline CoCa, a model with the same modified textual decoders but with CoCa's original ViT encoder. We used standard pretraining and fine-tuning workflows to benchmark the models on contrastive and generative tasks. Our GRR-CoCa significantly outperformed Baseline CoCa on the pretraining dataset and three diverse fine-tuning datasets. Pretraining improvements were 27.25% in contrastive loss, 3.71% in perplexity, and 7.15% in CoCa loss. The average fine-tuning improvements were 13.66% in contrastive loss, 5.18% in perplexity, and 5.55% in CoCa loss. We show that GRR-CoCa's modified architecture improves performance and generalization across vision-language domains.",
      "authors": [
        "Jake R. Patock",
        "Nicole Catherine Lewis",
        "Kevin McCoy",
        "Christina Gomez",
        "Canling Chen",
        "Lorenzo Luzi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:54:31+00:00",
          "link": "https://arxiv.org/abs/2507.18009v1",
          "size": "792kb",
          "version": "v1"
        }
      ],
      "title": "GRR-CoCa: Leveraging LLM Mechanisms in Multimodal Model Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18009",
        "HTML": "https://arxiv.org/html/2507.18009v1",
        "PDF": "https://arxiv.org/pdf/2507.18009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improvements in multimodal model architecture and performance benchmarking, without addressing any aspect of LLM training data processing or operations related to dataset creation or quality enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18013",
      "abstract": "We introduce the latest series of TeleChat models: \\textbf{TeleChat2}, \\textbf{TeleChat2.5}, and \\textbf{T1}, offering a significant upgrade over their predecessor, TeleChat. Despite minimal changes to the model architecture, the new series achieves substantial performance gains through enhanced training strategies in both pre-training and post-training stages. The series begins with \\textbf{TeleChat2}, which undergoes pretraining on 10 trillion high-quality and diverse tokens. This is followed by Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to further enhance its capabilities. \\textbf{TeleChat2.5} and \\textbf{T1} expand the pipeline by incorporating a continual pretraining phase with domain-specific datasets, combined with reinforcement learning (RL) to improve performance in code generation and mathematical reasoning tasks. The \\textbf{T1} variant is designed for complex reasoning, supporting long Chain-of-Thought (CoT) reasoning and demonstrating substantial improvements in mathematics and coding. In contrast, \\textbf{TeleChat2.5} prioritizes speed, delivering rapid inference. Both flagship models of \\textbf{T1} and \\textbf{TeleChat2.5} are dense Transformer-based architectures with 115B parameters, showcasing significant advancements in reasoning and general task performance compared to the original TeleChat. Notably, \\textbf{T1-115B} outperform proprietary models such as OpenAI's o1-mini and GPT-4o. We publicly release \\textbf{TeleChat2}, \\textbf{TeleChat2.5} and \\textbf{T1}, including post-trained versions with 35B and 115B parameters, to empower developers and researchers with state-of-the-art language models tailored for diverse applications.",
      "authors": [
        "Zihan Wang",
        "Xinzhang Liu",
        "Yitong Yao",
        "Chao Wang",
        "Yu Zhao",
        "Zhihao Yang",
        "Wenmin Deng",
        "Kaipeng Jia",
        "Jiaxin Peng",
        "Yuyao Huang",
        "Sishi Xiong",
        "Zhuo Jiang",
        "Kaidong Yu",
        "Xiaohui Hu",
        "Fubei Yao",
        "Ruiyu Fang",
        "Zhuoru Jiang",
        "Ruiting Song",
        "Qiyi Xie",
        "Rui Xue",
        "Xuewei He",
        "Yanlei Xue",
        "Zhu Yuan",
        "Zhaoxi Zhang",
        "Zilu Huang",
        "Shiquan Wang",
        "Xin Wang",
        "Hanming Wu",
        "Mingyuan Wang",
        "Xufeng Zhan",
        "Yuhan Sun",
        "Zhaohu Xing",
        "Yuhao Jiang",
        "Bingkai Yang",
        "Shuangyong Song",
        "Yongxiang Li",
        "Zhongjiang He",
        "Xuelong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:00:48+00:00",
          "link": "https://arxiv.org/abs/2507.18013v1",
          "size": "646kb",
          "version": "v1"
        }
      ],
      "title": "Technical Report of TeleChat2, TeleChat2.5 and T1",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18013",
        "HTML": "https://arxiv.org/html/2507.18013v1",
        "PDF": "https://arxiv.org/pdf/2507.18013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper does mention pretraining on high-quality datasets and fine-tuning processes for improving model performance, it primarily focuses on model architecture and less on novel contributions to data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18014",
      "abstract": "Fine-tuning large language models (LLMs) for reasoning tasks using reinforcement learning methods like Group Relative Policy Optimization (GRPO) is computationally expensive. To address this, we propose a predictive framework that models training dynamics and helps optimize resource usage. Through experiments on Llama and Qwen models (3B 8B), we derive an empirical scaling law based on model size, initial performance, and training progress. This law predicts reward trajectories and identifies three consistent training phases: slow start, rapid improvement, and plateau. We find that training beyond certain number of an epoch offers little gain, suggesting earlier stopping can significantly reduce compute without sacrificing performance. Our approach generalizes across model types, providing a practical guide for efficient GRPO-based fine-tuning.",
      "authors": [
        "Datta Nimmaturi",
        "Vaishnavi Bhargava",
        "Rajat Ghosh",
        "Johnu George",
        "Debojyoti Dutta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:09:25+00:00",
          "link": "https://arxiv.org/abs/2507.18014v1",
          "size": "488kb",
          "version": "v1"
        }
      ],
      "title": "Predictive Scaling Laws for Efficient GRPO Training of Large Reasoning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18014",
        "HTML": "https://arxiv.org/html/2507.18014v1",
        "PDF": "https://arxiv.org/pdf/2507.18014"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the optimization of training processes via predictive scaling laws, with limited focus on the role of training data processing. It emphasizes optimizing compute resources in fine-tuning, not on the dataset itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18015",
      "abstract": "The rapid advancement of AI technologies has significantly increased the diversity of DeepFake videos circulating online, posing a pressing challenge for \\textit{generalizable forensics}, \\ie, detecting a wide range of unseen DeepFake types using a single model. Addressing this challenge requires datasets that are not only large-scale but also rich in forgery diversity. However, most existing datasets, despite their scale, include only a limited variety of forgery types, making them insufficient for developing generalizable detection methods. Therefore, we build upon our earlier Celeb-DF dataset and introduce {Celeb-DF++}, a new large-scale and challenging video DeepFake benchmark dedicated to the generalizable forensics challenge. Celeb-DF++ covers three commonly encountered forgery scenarios: Face-swap (FS), Face-reenactment (FR), and Talking-face (TF). Each scenario contains a substantial number of high-quality forged videos, generated using a total of 22 various recent DeepFake methods. These methods differ in terms of architectures, generation pipelines, and targeted facial regions, covering the most prevalent DeepFake cases witnessed in the wild. We also introduce evaluation protocols for measuring the generalizability of 24 recent detection methods, highlighting the limitations of existing detection methods and the difficulty of our new dataset.",
      "authors": [
        "Yuezun Li",
        "Delong Zhu",
        "Xinjie Cui",
        "Siwei Lyu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:12:28+00:00",
          "link": "https://arxiv.org/abs/2507.18015v1",
          "size": "2571kb",
          "version": "v1"
        }
      ],
      "title": "Celeb-DF++: A Large-scale Challenging Video DeepFake Benchmark for Generalizable Forensics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18015",
        "HTML": "https://arxiv.org/html/2507.18015v1",
        "PDF": "https://arxiv.org/pdf/2507.18015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces the Celeb-DF++ dataset, a new benchmark for DeepFake detection involving diverse forgery types. It significantly contributes to the creation of datasets aimed at enhancing forgery detection capabilities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18017",
      "abstract": "In Conversational Recommendation Systems (CRS), a user provides feedback on recommended items at each turn, leading the CRS towards improved recommendations. Due to the need for a large amount of data, a user simulator is employed for both training and evaluation. Such user simulators critique the current retrieved item based on knowledge of a single target item. However, system evaluation in offline settings with simulators is limited by the focus on a single target item and their unlimited patience over a large number of turns. To overcome these limitations of existing simulators, we propose Fashion-AlterEval, a new dataset that contains human judgments for a selection of alternative items by adding new annotations in common fashion CRS datasets. Consequently, we propose two novel meta-user simulators that use the collected judgments and allow simulated users not only to express their preferences about alternative items to their original target, but also to change their mind and level of patience. In our experiments using the Shoes and Fashion IQ as the original datasets and three CRS models, we find that using the knowledge of alternatives by the simulator can have a considerable impact on the evaluation of existing CRS models, specifically that the existing single-target evaluation underestimates their effectiveness, and when simulatedusers are allowed to instead consider alternative relevant items, the system can rapidly respond to more quickly satisfy the user.",
      "authors": [
        "Maria Vlachou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:18:24+00:00",
          "link": "https://arxiv.org/abs/2507.18017v1",
          "size": "824kb",
          "version": "v1"
        }
      ],
      "title": "Fashion-AlterEval: A Dataset for Improved Evaluation of Conversational Recommendation Systems with Alternative Relevant Items",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18017",
        "HTML": "https://arxiv.org/html/2507.18017v1",
        "PDF": "https://arxiv.org/pdf/2507.18017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a dataset for evaluating conversational recommendation systems and does not contribute to LLM training data processing. It is concerned with user simulation and its impact on recommendation systems, which is unrelated to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18022",
      "abstract": "Charts and graphs help people analyze data, but can they also be useful to AI systems? To investigate this question, we perform a series of experiments with two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three representative analysis tasks, the two systems describe synthetic datasets more precisely and accurately when raw data is accompanied by a scatterplot, especially as datasets grow in complexity. Comparison with two baselines -- providing a blank chart and a chart with mismatched data -- shows that the improved performance is due to the content of the charts. Our results are initial evidence that AI systems, like humans, can benefit from visualization.",
      "authors": [
        "Victoria R. Li",
        "Johnathan Sun",
        "and Martin Wattenberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:47:34+00:00",
          "link": "https://arxiv.org/abs/2507.18022v1",
          "size": "889kb",
          "version": "v1"
        }
      ],
      "title": "Does visualization help AI understand data?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18022",
        "HTML": "https://arxiv.org/html/2507.18022v1",
        "PDF": "https://arxiv.org/pdf/2507.18022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines whether visualization aids AI systems in understanding data. It involves experiments with vision-language models but does not address any aspect of LLM training data processing directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18023",
      "abstract": "Recent advancements in multi-view 3D reconstruction and novel-view synthesis, particularly through Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have greatly enhanced the fidelity and efficiency of 3D content creation. However, inpainting 3D scenes remains a challenging task due to the inherent irregularity of 3D structures and the critical need for maintaining multi-view consistency. In this work, we propose a novel 3D Gaussian inpainting framework that reconstructs complete 3D scenes by leveraging sparse inpainted views. Our framework incorporates an automatic Mask Refinement Process and region-wise Uncertainty-guided Optimization. Specifically, we refine the inpainting mask using a series of operations, including Gaussian scene filtering and back-projection, enabling more accurate localization of occluded regions and realistic boundary restoration. Furthermore, our Uncertainty-guided Fine-grained Optimization strategy, which estimates the importance of each region across multi-view images during training, alleviates multi-view inconsistencies and enhances the fidelity of fine details in the inpainted results. Comprehensive experiments conducted on diverse datasets demonstrate that our approach outperforms existing state-of-the-art methods in both visual quality and view consistency.",
      "authors": [
        "Jun Zhou",
        "Dinghao Li",
        "Nannan Li",
        "Mingjie Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:48:50+00:00",
          "link": "https://arxiv.org/abs/2507.18023v1",
          "size": "33263kb",
          "version": "v1"
        }
      ],
      "title": "High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18023",
        "HTML": "https://arxiv.org/html/2507.18023v1",
        "PDF": "https://arxiv.org/pdf/2507.18023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for high-fidelity 3D Gaussian inpainting, focusing on 3D reconstruction and novel-view synthesis. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18025",
      "abstract": "Distributed multi-task learning (DMTL) effectively improves model generalization performance through the collaborative training of multiple related models. However, in large-scale learning scenarios, communication bottlenecks severely limit practical system performance. In this paper, we investigate the communication bottleneck within a typical DMTL system that employs non-linear global updates. This system involves distributed workers, assisted by a central server, who collaboratively learn distinct models derived from a non-linear aggregation of their local model parameters. We first characterize the communication process as a matrix decomposition problem. It transforms workers' data storage constraints into structural characteristics of the uplink encoding matrix, and worker data retrieval demands into Maximum Distance Separable (MDS) properties of the downlink encoding matrix. Building on this, we propose a novel coded DTML scheme that can greatly reduce the communication cost of the DTML with heterogeneous data placement. Theoretical analysis demonstrates that the proposed scheme achieves the theoretical lower bound for communication overhead under mild conditions. Remarkably, this optimality holds for both traditional homogeneous computing environments and various heterogeneous scenarios. Furthermore, our scheme is extensible to a distributed linearly separable computation problem where the target function involves multiple linear combinations of local update values. This indicates that our scheme offers a new way of tackling heterogeneous data placement challenges in various distributed applications.",
      "authors": [
        "Minquan Cheng",
        "Yongkang Wang",
        "Lingyu Zhang",
        "and Youlong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:55:15+00:00",
          "link": "https://arxiv.org/abs/2507.18025v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Coded Computing Approach for Distributed Multi-Task Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18025",
        "HTML": "https://arxiv.org/html/2507.18025v1",
        "PDF": "https://arxiv.org/pdf/2507.18025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a coded computing approach for distributed multi-task learning, addressing communication bottlenecks and model parameter aggregation. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18026",
      "abstract": "Emotion recognition through body movements has emerged as a compelling and privacy-preserving alternative to traditional methods that rely on facial expressions or physiological signals. Recent advancements in 3D skeleton acquisition technologies and pose estimation algorithms have significantly enhanced the feasibility of emotion recognition based on full-body motion. This survey provides a comprehensive and systematic review of skeleton-based emotion recognition techniques. First, we introduce psychological models of emotion and examine the relationship between bodily movements and emotional expression. Next, we summarize publicly available datasets, highlighting the differences in data acquisition methods and emotion labeling strategies. We then categorize existing methods into posture-based and gait-based approaches, analyzing them from both data-driven and technical perspectives. In particular, we propose a unified taxonomy that encompasses four primary technical paradigms: Traditional approaches, Feat2Net, FeatFusionNet, and End2EndNet. Representative works within each category are reviewed and compared, with benchmarking results across commonly used datasets. Finally, we explore the extended applications of emotion recognition in mental health assessment, such as detecting depression and autism, and discuss the open challenges and future research directions in this rapidly evolving field.",
      "authors": [
        "Haifeng Lu",
        "Jiuyi Chen",
        "Zhen Zhang",
        "Ruida Liu",
        "Runhao Zeng",
        "Xiping Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:58:57+00:00",
          "link": "https://arxiv.org/abs/2507.18026v1",
          "size": "1383kb",
          "version": "v1"
        }
      ],
      "title": "Emotion Recognition from Skeleton Data: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18026",
        "HTML": "https://arxiv.org/html/2507.18026v1",
        "PDF": "https://arxiv.org/pdf/2507.18026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on emotion recognition through skeleton data, summarizing available datasets and techniques but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18028",
      "abstract": "Efficiently editing knowledge stored in large language models (LLMs) enables model updates without large-scale training. One possible solution is Locate-and-Edit (L\\&E), allowing simultaneous modifications of a massive number of facts. However, such editing may compromise the general abilities of LLMs and even result in forgetting edited facts when scaling up to thousands of edits. In this paper, we model existing linear L\\&E methods as querying a Key-Value (KV) database. From this perspective, we then propose NeuralDB, an editing framework that explicitly represents the edited facts as a neural KV database equipped with a non-linear gated retrieval module, % In particular, our gated module only operates when inference involves the edited facts, effectively preserving the general abilities of LLMs. Comprehensive experiments involving the editing of 10,000 facts were conducted on the ZsRE and CounterFacts datasets, using GPT2-XL, GPT-J (6B) and Llama-3 (8B). The results demonstrate that NeuralDB not only excels in editing efficacy, generalization, specificity, fluency, and consistency, but also preserves overall performance across six representative text understanding and generation tasks. Further experiments indicate that NeuralDB maintains its effectiveness even when scaled to 100,000 facts (\\textbf{50x} more than in prior work).",
      "authors": [
        "Weizhi Fei",
        "Hao Shi",
        "Jing Xu",
        "Jingchen Peng",
        "Jiazheng Li",
        "Jingzhao Zhang",
        "Bo Bai",
        "Wei Han",
        "Zhenyuan Chen",
        "Xueyan Niu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:00:09+00:00",
          "link": "https://arxiv.org/abs/2507.18028v1",
          "size": "1785kb",
          "version": "v1"
        }
      ],
      "title": "NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18028",
        "HTML": "https://arxiv.org/html/2507.18028v1",
        "PDF": "https://arxiv.org/pdf/2507.18028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses NeuralDB, which involves model editing via a Key-Value database but does not primarily address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18029",
      "abstract": "The growing capabilities of generative AI (GenAI) have begun to reshape how games are designed and developed, offering new tools for content creation, gameplay simulation, and design ideation. While prior research has explored traditional uses of AI in games, such as controlling agents or generating procedural content. There is limited empirical understanding of how GenAI is adopted by developers in real-world contexts, especially within the open-source community. This study aims to explore how GenAI technologies are discussed, adopted, and integrated into open-source game development by analyzing issue discussions on GitHub. We investigate the tools, tasks, and challenges associated with GenAI by comparing GenAI-related issues to those involving traditional AI (TradAI) and NonAI topics. Our goal is to uncover how GenAI differs from other approaches in terms of usage patterns, developer concerns, and integration practices. To address this objective, we construct a dataset of open-source game repositories that discuss AI-related topics. We apply open card sorting and thematic analysis to a stratified sample of GitHub issues, labelling each by type and content. These annotations enable comparative analysis across GenAI, TradAI, and NonAI groups, and provide insight into how GenAI is shaping the workflows and pain points of open-source game developers.",
      "authors": [
        "Xiang Echo Chen",
        "Wenhan Zhu",
        "Guoshuai Albert Shi",
        "Michael W. Godfrey"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:03:12+00:00",
          "link": "https://arxiv.org/abs/2507.18029v1",
          "size": "1095kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18029",
        "HTML": "https://arxiv.org/html/2507.18029v1",
        "PDF": "https://arxiv.org/pdf/2507.18029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the adoption and use of GenAI in open-source game development, rather than on LLM training data processing or related technical contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18031",
      "abstract": "The rapid rise of deepfake technology, which produces realistic but fraudulent digital content, threatens the authenticity of media. Traditional deepfake detection approaches often struggle with sophisticated, customized deepfakes, especially in terms of generalization and robustness against malicious attacks. This paper introduces ViGText, a novel approach that integrates images with Vision Large Language Model (VLLM) Text explanations within a Graph-based framework to improve deepfake detection. The novelty of ViGText lies in its integration of detailed explanations with visual data, as it provides a more context-aware analysis than captions, which often lack specificity and fail to reveal subtle inconsistencies. ViGText systematically divides images into patches, constructs image and text graphs, and integrates them for analysis using Graph Neural Networks (GNNs) to identify deepfakes. Through the use of multi-level feature extraction across spatial and frequency domains, ViGText captures details that enhance its robustness and accuracy to detect sophisticated deepfakes. Extensive experiments demonstrate that ViGText significantly enhances generalization and achieves a notable performance boost when it detects user-customized deepfakes. Specifically, average F1 scores rise from 72.45% to 98.32% under generalization evaluation, and reflects the model's superior ability to generalize to unseen, fine-tuned variations of stable diffusion models. As for robustness, ViGText achieves an increase of 11.1% in recall compared to other deepfake detection approaches. When facing targeted attacks that exploit its graph-based architecture, ViGText limits classification performance degradation to less than 4%. ViGText uses detailed visual and textual analysis to set a new standard for detecting deepfakes, helping ensure media authenticity and information integrity.",
      "authors": [
        "Ahmad ALBarqawi",
        "Mahmoud Nazzal",
        "Issa Khalil",
        "Abdallah Khreishah",
        "NhatHai Phan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:04:58+00:00",
          "link": "https://arxiv.org/abs/2507.18031v1",
          "size": "5328kb",
          "version": "v1"
        }
      ],
      "title": "ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18031",
        "HTML": "https://arxiv.org/html/2507.18031v1",
        "PDF": "https://arxiv.org/pdf/2507.18031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for deepfake detection using vision-language models, focusing on media authenticity rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18033",
      "abstract": "Pre-trained large language models (LLMs) have demonstrated strong common-sense reasoning abilities, making them promising for robotic navigation and planning tasks. However, despite recent progress, bridging the gap between language descriptions and actual robot actions in the open-world, beyond merely invoking limited predefined motion primitives, remains an open challenge. In this work, we aim to enable robots to interpret and decompose complex language instructions, ultimately synthesizing a sequence of trajectory points to complete diverse navigation tasks given open-set instructions and open-set objects. We observe that multi-modal large language models (MLLMs) exhibit strong cross-modal understanding when processing free-form language instructions, demonstrating robust scene comprehension. More importantly, leveraging their code-generation capability, MLLMs can interact with vision-language perception models to generate compositional 2D bird-eye-view value maps, effectively integrating semantic knowledge from MLLMs with spatial information from maps to reinforce the robot's spatial understanding. To further validate our approach, we effectively leverage large-scale autonomous vehicle datasets (AVDs) to validate our proposed zero-shot vision-language navigation framework in outdoor navigation tasks, demonstrating its capability to execute a diverse range of free-form natural language navigation instructions while maintaining robustness against object detection errors and linguistic ambiguities. Furthermore, we validate our system on a Husky robot in both indoor and outdoor scenes, demonstrating its real-world robustness and applicability. Supplementary videos are available at https://trailab.github.io/OpenNav-website/",
      "authors": [
        "Mingfeng Yuan",
        "Letian Wang",
        "Steven L. Waslander"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:05:28+00:00",
          "link": "https://arxiv.org/abs/2507.18033v1",
          "size": "5210kb",
          "version": "v1"
        }
      ],
      "title": "OpenNav: Open-World Navigation with Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18033",
        "HTML": "https://arxiv.org/html/2507.18033v1",
        "PDF": "https://arxiv.org/pdf/2507.18033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using large language models for robotic navigation and planning tasks, not on processing training data for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18034",
      "abstract": "The intellectual property of deep generative networks (GNets) can be protected using a cascaded hiding network (HNet) which embeds watermarks (or marks) into GNet outputs, known as box-free watermarking. Although both GNet and HNet are encapsulated in a black box (called operation network, or ONet), with only the generated and marked outputs from HNet being released to end users and deemed secure, in this paper, we reveal an overlooked vulnerability in such systems. Specifically, we show that the hidden GNet outputs can still be reliably estimated via query-based reverse engineering, leaking the generated and unmarked images, despite the attacker's limited knowledge of the system. Our first attempt is to reverse-engineer an inverse model for HNet under the stringent black-box condition, for which we propose to exploit the query process with specially curated input images. While effective, this method yields unsatisfactory image quality. To improve this, we subsequently propose an alternative method leveraging the equivalent additive property of box-free model watermarking and reverse-engineering a forward surrogate model of HNet, with better image quality preservation. Extensive experimental results on image processing and image generation tasks demonstrate that both attacks achieve impressive watermark removal success rates (100%) while also maintaining excellent image quality (reaching the highest PSNR of 34.69 dB), substantially outperforming existing attacks, highlighting the urgent need for robust defensive strategies to mitigate the identified vulnerability in box-free model watermarking.",
      "authors": [
        "Haonan An",
        "Guang Hua",
        "Hangcheng Cao",
        "Zhengru Fang",
        "Guowen Xu",
        "Susanto Rahardja",
        "Yuguang Fang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:05:55+00:00",
          "link": "https://arxiv.org/abs/2507.18034v1",
          "size": "7582kb",
          "version": "v1"
        }
      ],
      "title": "Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18034",
        "HTML": "https://arxiv.org/html/2507.18034v1",
        "PDF": "https://arxiv.org/pdf/2507.18034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with watermark removal for image-to-image generative models and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18036",
      "abstract": "The intellectual property of deep neural network (DNN) models can be protected with DNN watermarking, which embeds copyright watermarks into model parameters (white-box), model behavior (black-box), or model outputs (box-free), and the watermarks can be subsequently extracted to verify model ownership or detect model theft. Despite recent advances, these existing methods are inherently intrusive, as they either modify the model parameters or alter the structure. This natural intrusiveness raises concerns about watermarking-induced shifts in model behavior and the additional cost of fine-tuning, further exacerbated by the rapidly growing model size. As a result, model owners are often reluctant to adopt DNN watermarking in practice, which limits the development of practical Watermarking as a Service (WaaS) systems. To address this issue, we introduce Nonintrusive Watermarking as a Service (NWaaS), a novel trustless paradigm designed for X-to-Image models, in which we hypothesize that with the model untouched, an owner-defined watermark can still be extracted from model outputs. Building on this concept, we propose ShadowMark, a concrete implementation of NWaaS which addresses critical deployment challenges by establishing a robust and nonintrusive side channel in the protected model's black-box API, leveraging a key encoder and a watermark decoder. It is significantly distinctive from existing solutions by attaining the so-called absolute fidelity and being applicable to different DNN architectures, while being also robust against existing attacks, eliminating the fidelity-robustness trade-off. Extensive experiments on image-to-image, noise-to-image, noise-and-text-to-image, and text-to-image models, demonstrate the efficacy and practicality of ShadowMark for real-world deployment of nonintrusive DNN watermarking.",
      "authors": [
        "Haonan An",
        "Guang Hua",
        "Yu Guo",
        "Hangcheng Cao",
        "Susanto Rahardja",
        "Yuguang Fang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:07:28+00:00",
          "link": "https://arxiv.org/abs/2507.18036v1",
          "size": "1213kb",
          "version": "v1"
        }
      ],
      "title": "NWaaS: Nonintrusive Watermarking as a Service for X-to-Image DNN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18036",
        "HTML": "https://arxiv.org/html/2507.18036v1",
        "PDF": "https://arxiv.org/pdf/2507.18036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a watermarking method for deep neural networks, focusing on model protection and IP verification, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18037",
      "abstract": "The MITRE Adversarial Tactics, Techniques and Common Knowledge (MITRE ATT&CK) Attack Technique to Proactive Software Supply Chain Risk Management Framework (P-SSCRM) Task mapping described in this document helps software organizations to determine how different tasks mitigate the attack techniques of software supply chain attacks. The mapping was created through four independent strategies to find agreed-upon mappings. Because each P-SSCRM task is mapped to one or more tasks from the 10 frameworks, the mapping we provide is also a mapping between MITRE ATT&CK and other prominent government and industry frameworks.",
      "authors": [
        "Sivana Hamer",
        "Jacob Bowen",
        "Md Nazmul Haque",
        "Chris Madden",
        "Laurie Williams"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:14:00+00:00",
          "link": "https://arxiv.org/abs/2507.18037v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18037",
        "HTML": "https://arxiv.org/html/2507.18037v1",
        "PDF": "https://arxiv.org/pdf/2507.18037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a framework for mapping software tasks to MITRE ATT&CK techniques, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18039",
      "abstract": "This research full paper investigates the factors influencing computing educators' adoption of project-based learning (PjBL) in software engineering and computing curricula. Recognized as a student-centered pedagogical approach, PjBL has the potential to enhance student motivation, engagement, critical thinking, collaboration, and problem-solving skills. Despite these benefits, faculty adoption remains inconsistent due to challenges such as insufficient institutional support, time constraints, limited training opportunities, designing or sourcing projects, and aligning them with course objectives. This research explores these barriers and investigates the strategies and resources that facilitate a successful adoption. Using a mixed-methods approach, data from 80 computing faculty were collected through an online survey comprising closed-ended questions to quantify barriers, enablers, and resource needs, along with an open-ended question to gather qualitative insights. Quantitative data were analyzed using statistical methods, while qualitative responses underwent thematic analysis. Results reveal that while PjBL is widely valued, its adoption is often selective and impacted by challenges in planning and managing the learning process, designing suitable projects, and a lack of institutional support, such as time, funding, and teaching assistants. Faculty are more likely to adopt or sustain PjBL when they have access to peer collaboration, professional development, and institutional incentives. In addition, sourcing projects from research, industry partnerships, and borrowing from peers emerged as key facilitators for new projects. These findings underscore the need for systemic support structures to empower faculty to experiment with and scale PjBL practices.",
      "authors": [
        "Ahmad D. Suleiman",
        "Yiming Tang",
        "Daqing Hou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:16:29+00:00",
          "link": "https://arxiv.org/abs/2507.18039v1",
          "size": "94kb",
          "version": "v1"
        }
      ],
      "title": "Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18039",
        "HTML": "https://arxiv.org/html/2507.18039v1",
        "PDF": "https://arxiv.org/pdf/2507.18039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates factors affecting project-based learning adoption in education, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18040",
      "abstract": "Multi-chiplet architectures enabled by glass interposer offer superior electrical performance, enable higher bus widths due to reduced crosstalk, and have lower capacitance in the redistribution layer than current silicon interposer-based systems. These advantages result in lower energy per bit, higher communication frequencies, and extended interconnect range. However, deformation of the package (warpage) in glass interposer-based systems becomes a critical challenge as system size increases, leading to severe mechanical stress and reliability concerns. Beyond a certain size, conventional packaging techniques fail to manage warpage effectively, necessitating new approaches to mitigate warpage induced bending with scalable performance for glass interposer based multi-chiplet systems. To address these inter-twined challenges, we propose a thermal-, warpage-, and performance-aware design framework that employs architecture and packaging co-optimization. The proposed framework disintegrates the surface and embedded chiplets to balance conflicting design objectives, ensuring optimal trade-offs between performance, power, and structural reliability. Our experiments demonstrate that optimized multi-chiplet architectures from our design framework achieve up to 64.7% performance improvement and 40% power reduction compared to traditional 2.5D systems to execute deep neural network workloads with lower fabrication costs.",
      "authors": [
        "Harsh Sharma",
        "Janardhan Rao Doppa",
        "Umit Y. Ogras",
        "Partha Pratim Pande"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:26:08+00:00",
          "link": "https://arxiv.org/abs/2507.18040v1",
          "size": "7455kb",
          "version": "v1"
        }
      ],
      "title": "Designing High-Performance and Thermally Feasible Multi-Chiplet Architectures enabled by Non-bendable Glass Interposer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18040",
        "PDF": "https://arxiv.org/pdf/2507.18040"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multi-chiplet architectures, thermal and warpage issues of glass interposers, and design frameworks for deep neural network workloads, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18043",
      "abstract": "Inference-time steering methods offer a lightweight alternative to fine-tuning large language models (LLMs) and vision-language models (VLMs) by modifying internal activations at test time without updating model weights. However, most existing approaches rely on fixed, global intervention vectors, overlook the causal influence of individual input tokens, and fail to leverage informative gradients from the model's logits, particularly in multimodal settings where visual and textual inputs contribute unevenly. To address these limitations, we introduce GrAInS, an inference-time steering approach that operates across both language-only and vision-language models and tasks. GrAInS uses contrastive, gradient-based attribution via Integrated Gradients to identify the top-k most influential tokens, both positively and negatively attributed based on their contribution to preferred versus dispreferred outputs. These tokens are then used to construct directional steering vectors that capture semantic shifts from undesirable to desirable behavior. During inference, GrAInS adjusts hidden activations at transformer layers guided by token-level attribution signals, and normalizes activations to preserve representational scale. This enables fine-grained, interpretable, and modular control over model behavior, without retraining or auxiliary supervision. Empirically, GrAInS consistently outperforms both fine-tuning and existing steering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using Llama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514 with LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all while preserving the model's fluency and general capabilities.",
      "authors": [
        "Duy Nguyen",
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:34:13+00:00",
          "link": "https://arxiv.org/abs/2507.18043v1",
          "size": "19886kb",
          "version": "v1"
        }
      ],
      "title": "GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18043",
        "HTML": "https://arxiv.org/html/2507.18043v1",
        "PDF": "https://arxiv.org/pdf/2507.18043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an inference-time steering method for LLMs and VLMs without discussing any training data processing stages or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18044",
      "abstract": "Current approaches to phrase break prediction address crucial prosodic aspects of text-to-speech systems but heavily rely on vast human annotations from audio or text, incurring significant manual effort and cost. Inherent variability in the speech domain, driven by phonetic factors, further complicates acquiring consistent, high-quality data. Recently, large language models (LLMs) have shown success in addressing data challenges in NLP by generating tailored synthetic data while reducing manual annotation needs. Motivated by this, we explore leveraging LLM to generate synthetic phrase break annotations, addressing the challenges of both manual annotation and speech-related tasks by comparing with traditional annotations and assessing effectiveness across multiple languages. Our findings suggest that LLM-based synthetic data generation effectively mitigates data challenges in phrase break prediction and highlights the potential of LLMs as a viable solution for the speech domain.",
      "authors": [
        "Hoyeon Lee",
        "Sejung Son",
        "Ye-Eun Kang",
        "Jong-Hwan Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:45:03+00:00",
          "link": "https://arxiv.org/abs/2507.18044v1",
          "size": "774kb",
          "version": "v1"
        }
      ],
      "title": "Synthetic Data Generation for Phrase Break Prediction with Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18044",
        "HTML": "https://arxiv.org/html/2507.18044v1",
        "PDF": "https://arxiv.org/pdf/2507.18044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper explores synthetic data generation using LLMs for phrase break prediction. It directly addresses data generation challenges and aims to reduce human annotation needs, contributing significantly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18046",
      "abstract": "Recent advances in AI-generated video have shown strong performance on \\emph{text-to-video} tasks, particularly for short clips depicting a single scene. However, current models struggle to generate longer videos with coherent scene transitions, primarily because they cannot infer when a transition is needed from the prompt. Most open-source models are trained on datasets consisting of single-scene video clips, which limits their capacity to learn and respond to prompts requiring multiple scenes. Developing scene transition awareness is essential for multi-scene generation, as it allows models to identify and segment videos into distinct clips by accurately detecting transitions.\n  To address this, we propose the \\textbf{Transition-Aware Video} (TAV) dataset, which consists of preprocessed video clips with multiple scene transitions. Our experiment shows that post-training on the \\textbf{TAV} dataset improves prompt-based scene transition understanding, narrows the gap between required and generated scenes, and maintains image quality.",
      "authors": [
        "Hanwen Shen",
        "Jiajie Lu",
        "Yupeng Cao",
        "Xiaonan Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:50:26+00:00",
          "link": "https://arxiv.org/abs/2507.18046v1",
          "size": "888kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Scene Transition Awareness in Video Generation via Post-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18046",
        "HTML": "https://arxiv.org/html/2507.18046v1",
        "PDF": "https://arxiv.org/pdf/2507.18046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset (TAV) for enhancing scene transition awareness in video generation. Though it involves dataset creation, the focus is predominantly on video generation, with limited relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18047",
      "abstract": "The growing complexity of Edge Video Analytics (EVA) facilitates new kind of intelligent applications, but creates challenges in real-time inference serving systems. State-of-the-art (SOTA) scheduling systems optimize global workload distributions for heterogeneous devices but often suffer from extended scheduling cycles, leading to sub-optimal processing in rapidly changing Edge environments. Local Reinforcement Learning (RL) enables quick adjustments between cycles but faces scalability, knowledge integration, and adaptability issues. Thus, we propose FCPO, which combines Continual RL (CRL) with Federated RL (FRL) to address these challenges. This integration dynamically adjusts inference batch sizes, input resolutions, and multi-threading during pre- and post-processing. CRL allows agents to learn from changing Markov Decision Processes, capturing dynamic environmental variations, while FRL improves generalization and convergence speed by integrating experiences across inference models. FCPO combines these via an agent-specific aggregation scheme and a diversity-aware experience buffer. Experiments on a real-world EVA testbed showed over 5 times improvement in effective throughput, 60% reduced latency, and 20% faster convergence with up to 10 times less memory consumption compared to SOTA RL-based approaches.",
      "authors": [
        "Lucas Liebe and Thanh-Tung Nguyen and Dongman Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:51:06+00:00",
          "link": "https://arxiv.org/abs/2507.18047v1",
          "size": "9466kb",
          "version": "v1"
        }
      ],
      "title": "FCPO: Federated Continual Policy Optimization for Real-Time High-Throughput Edge Video Analytics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18047",
        "HTML": "https://arxiv.org/html/2507.18047v1",
        "PDF": "https://arxiv.org/pdf/2507.18047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents FCPO, a federated learning approach for edge video analytics, focusing on real-time processing and optimization, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18050",
      "abstract": "Rising demand for complex simulations highlights conventional engines'scalability limits, spurring Parallel Discrete Event Simulation (PDES) adoption.Warped2, a PDES engine leveraging Time Warp synchronization with Pending Event Set optimization, delivers strong performance, it struggles with inherent wargaming limitations: inefficient LP resource allocation during synchronization and unaddressed complex entity interaction patterns. To address these challenges, we present an optimized framework featuring four synergistic improvements: (1) Asynchronous listener threads are introduced to address event monitoring latency in large-scale scenarios, instead of synchronous polling mechanisms, (2) METIS-based load rebalancing strategy is incorporated to address the issue of dynamic event allocation during real-world simulation, (3) Entity interaction solver with constraint satisfaction mechanisms is designed to mitigate state conflicts, and (4) Spatial hashing algorithm to overcome O(n^2) complexity bottlenecks in large-scale nearest-neighbor searches. Experimental validation through a GridWorld demo demonstrates significant enhancements in temporal fidelity and computational efficiency. Benchmark results show our framework achieves 16x acceleration over baseline implementations and maintains 8x speedup over 1-thread configuration across MPI and Pthreads implementations.The combined load balancing and LP migration strategy reduces synchronization overhead by 58.18%, with load balancing accounting for 57% of the total improvement as the dominant optimization factor. These improvements provide an enhanced solution for PDES implementation in large-scale simulation scenarios.",
      "authors": [
        "Xiaoning Jia",
        "Ruilin Kong",
        "Guangya Si",
        "Bilong Shen",
        "Zhe Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:55:31+00:00",
          "link": "https://arxiv.org/abs/2507.18050v1",
          "size": "4055kb",
          "version": "v1"
        }
      ],
      "title": "A large-scale distributed parallel discrete event simulation engines based on Warped2 for Wargaming simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18050",
        "HTML": "https://arxiv.org/html/2507.18050v1",
        "PDF": "https://arxiv.org/pdf/2507.18050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improvements in Parallel Discrete Event Simulation engines for wargaming, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18051",
      "abstract": "This paper presents the TEA-ASLP's system submitted to the MLC-SLM 2025 Challenge, addressing multilingual conversational automatic speech recognition (ASR) in Task I and speech diarization ASR in Task II. For Task I, we enhance Ideal-LLM model by integrating known language identification and a multilingual MOE LoRA structure, along with using CTC-predicted tokens as prompts to improve autoregressive generation. The model is trained on approximately 180k hours of multilingual ASR data. In Task II, we replace the baseline English-Chinese speaker diarization model with a more suitable English-only version. Our approach achieves a 30.8% reduction in word error rate (WER) compared to the baseline speech language model, resulting in a final WER of 9.60% in Task I and a time-constrained minimum-permutation WER of 17.49% in Task II, earning first and second place in the respective challenge tasks.",
      "authors": [
        "Hongfei Xue",
        "Kaixun Huang",
        "Zhikai Zhou",
        "Shen Huang",
        "Shidong Shang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:56:29+00:00",
          "link": "https://arxiv.org/abs/2507.18051v1",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "title": "The TEA-ASLP System for Multilingual Conversational Speech Recognition and Speech Diarization in MLC-SLM 2025 Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18051",
        "HTML": "https://arxiv.org/html/2507.18051v1",
        "PDF": "https://arxiv.org/pdf/2507.18051"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses multilingual conversational speech recognition and diarization for a competition challenge, without discussing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18052",
      "abstract": "DanceGraph is an architecture for synchronized online dancing overcoming the latency of networked body pose sharing. We break down this challenge by developing a real-time bandwidth-efficient architecture to minimize lag and reduce the timeframe of required motion prediction for synchronization with the music's rhythm. In addition, we show an interactive method for the parameterized stylization of dance motions for rhythmic dance using online dance correctives.",
      "authors": [
        "David Sinclair",
        "Ademyemi Ademola",
        "Babis Koniaris",
        "Kenny Mitchell"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:56:30+00:00",
          "link": "https://arxiv.org/abs/2507.18052v1",
          "size": "1394kb",
          "version": "v1"
        }
      ],
      "title": "DanceGraph: A Complementary Architecture for Synchronous Dancing Online",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18052",
        "HTML": "https://arxiv.org/html/2507.18052v1",
        "PDF": "https://arxiv.org/pdf/2507.18052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an architecture for synchronized online dancing, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18053",
      "abstract": "Resource Consumption Attacks (RCAs) have emerged as a significant threat to the deployment of Large Language Models (LLMs). With the integration of vision modalities, additional attack vectors exacerbate the risk of RCAs in large vision-language models (LVLMs). However, existing red-teaming studies have largely overlooked visual inputs as a potential attack surface, resulting in insufficient mitigation strategies against RCAs in LVLMs. To address this gap, we propose RECALLED (\\textbf{RE}source \\textbf{C}onsumption \\textbf{A}ttack on \\textbf{L}arge Vision-\\textbf{L}anguag\\textbf{E} Mo\\textbf{D}els), the first approach for exploiting visual modalities to trigger unbounded RCAs red-teaming. First, we present \\textit{Vision Guided Optimization}, a fine-grained pixel-level optimization, to obtain \\textit{Output Recall} adversarial perturbations, which can induce repeating output. Then, we inject the perturbations into visual inputs, triggering unbounded generations to achieve the goal of RCAs. Additionally, we introduce \\textit{Multi-Objective Parallel Losses} to generate universal attack templates and resolve optimization conflicts when intending to implement parallel attacks. Empirical results demonstrate that RECALLED increases service response latency by over 26 $\\uparrow$, resulting in an additional 20\\% increase in GPU utilization and memory consumption. Our study exposes security vulnerabilities in LVLMs and establishes a red-teaming framework that can facilitate future defense development against RCAs.",
      "authors": [
        "Haoran Gao",
        "Yuanhe Zhang",
        "Zhenhong Zhou",
        "Lei Jiang",
        "Fanyu Meng",
        "Yujia Xiao",
        "Kun Wang",
        "Yang Liu",
        "Junlan Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:58:16+00:00",
          "link": "https://arxiv.org/abs/2507.18053v1",
          "size": "1598kb",
          "version": "v1"
        }
      ],
      "title": "RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18053",
        "HTML": "https://arxiv.org/html/2507.18053v1",
        "PDF": "https://arxiv.org/pdf/2507.18053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on exploiting vulnerabilities in large vision-language models, not on any processes related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18055",
      "abstract": "The increasing use of synthetic data generated by Large Language Models (LLMs) presents both opportunities and challenges in data-driven applications. While synthetic data provides a cost-effective, scalable alternative to real-world data to facilitate model training, its diversity and privacy risks remain underexplored. Focusing on text-based synthetic data, we propose a comprehensive set of metrics to quantitatively assess the diversity (i.e., linguistic expression, sentiment, and user perspective), and privacy (i.e., re-identification risk and stylistic outliers) of synthetic datasets generated by several state-of-the-art LLMs. Experiment results reveal significant limitations in LLMs' capabilities in generating diverse and privacy-preserving synthetic data. Guided by the evaluation results, a prompt-based approach is proposed to enhance the diversity of synthetic reviews while preserving reviewer privacy.",
      "authors": [
        "Tevin Atwal",
        "Chan Nam Tieu",
        "Yefeng Yuan",
        "Zhan Shi",
        "Yuhong Liu",
        "Liang Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:12:16+00:00",
          "link": "https://arxiv.org/abs/2507.18055v1",
          "size": "785kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18055",
        "HTML": "https://arxiv.org/html/2507.18055v1",
        "PDF": "https://arxiv.org/pdf/2507.18055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper's main focus is synthetic data privacy and diversity evaluation using LLMs, it discusses generating synthetic datasets, which ties into data processing but is not the core focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18059",
      "abstract": "Due to practical constraints such as partial observability and limited communication, Centralized Training with Decentralized Execution (CTDE) has become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning (MARL). However, existing CTDE methods often underutilize centralized training or lack theoretical guarantees. We propose Multi-Agent Guided Policy Optimization (MAGPO), a novel framework that better leverages centralized training by integrating centralized guidance with decentralized execution. MAGPO uses an auto-regressive joint policy for scalable, coordinated exploration and explicitly aligns it with decentralized policies to ensure deployability under partial observability. We provide theoretical guarantees of monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across 6 diverse environments. Results show that MAGPO consistently outperforms strong CTDE baselines and matches or surpasses fully centralized approaches, offering a principled and practical solution for decentralized multi-agent learning. Our code and experimental data can be found in https://github.com/liyheng/MAGPO.",
      "authors": [
        "Yueheng Li",
        "Guangming Xie",
        "Zongqing Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:22:21+00:00",
          "link": "https://arxiv.org/abs/2507.18059v1",
          "size": "1848kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Agent Guided Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18059",
        "HTML": "https://arxiv.org/html/2507.18059v1",
        "PDF": "https://arxiv.org/pdf/2507.18059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel framework in cooperative Multi-Agent Reinforcement Learning (MARL) and does not discuss any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18060",
      "abstract": "We introduce BokehDiff, a novel lens blur rendering method that achieves physically accurate and visually appealing outcomes, with the help of generative diffusion prior. Previous methods are bounded by the accuracy of depth estimation, generating artifacts in depth discontinuities. Our method employs a physics-inspired self-attention module that aligns with the image formation process, incorporating depth-dependent circle of confusion constraint and self-occlusion effects. We adapt the diffusion model to the one-step inference scheme without introducing additional noise, and achieve results of high quality and fidelity. To address the lack of scalable paired data, we propose to synthesize photorealistic foregrounds with transparency with diffusion models, balancing authenticity and scene diversity.",
      "authors": [
        "Chengxuan Zhu",
        "Qingnan Fan",
        "Qi Zhang",
        "Jinwei Chen",
        "Huaqi Zhang",
        "Chao Xu",
        "Boxin Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:23:19+00:00",
          "link": "https://arxiv.org/abs/2507.18060v1",
          "size": "45870kb",
          "version": "v1"
        }
      ],
      "title": "BokehDiff: Neural Lens Blur with One-Step Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18060",
        "HTML": "https://arxiv.org/html/2507.18060v1",
        "PDF": "https://arxiv.org/pdf/2507.18060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces BokehDiff, a lens blur rendering method, which is unrelated to any stage of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18061",
      "abstract": "Spoken language models (SLMs) have seen rapid progress in recent years, along with the development of numerous benchmarks for evaluating their performance. However, most existing benchmarks primarily focus on evaluating whether SLMs can perform complex tasks comparable to those tackled by large language models (LLMs), often failing to align with how users naturally interact in real-world conversational scenarios. In this paper, we propose TELEVAL, a dynamic benchmark specifically designed to evaluate SLMs' effectiveness as conversational agents in realistic Chinese interactive settings. TELEVAL defines three evaluation dimensions: Explicit Semantics, Paralinguistic and Implicit Semantics, and System Abilities. It adopts a dialogue format consistent with real-world usage and evaluates text and audio outputs separately. TELEVAL particularly focuses on the model's ability to extract implicit cues from user speech and respond appropriately without additional instructions. Our experiments demonstrate that despite recent progress, existing SLMs still have considerable room for improvement in natural conversational tasks. We hope that TELEVAL can serve as a user-centered evaluation framework that directly reflects the user experience and contributes to the development of more capable dialogue-oriented SLMs.",
      "authors": [
        "Zehan Li",
        "Hongjie Chen",
        "Yuxin Zhang",
        "Jing Zhou",
        "Xuening Wang",
        "Hang Lv",
        "Mengjie Du",
        "Yaodong Song",
        "Jie Lian",
        "Jian Kang",
        "Jie Li",
        "Yongxiang Li",
        "Zhongjiang He",
        "Xuelong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:23:55+00:00",
          "link": "https://arxiv.org/abs/2507.18061v1",
          "size": "355kb",
          "version": "v1"
        }
      ],
      "title": "TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18061",
        "PDF": "https://arxiv.org/pdf/2507.18061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on evaluating spoken language models using the TELEVAL benchmark, which does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18062",
      "abstract": "Continuous Integration (CI) has evolved from a tooling strategy to a fundamental mindset in modern CI engineering. It enables teams to develop, test, and deliver software rapidly and collaboratively. Among CI services, GitHub Actions (GHA) has emerged as a dominant service due to its deep integration with GitHub and a vast ecosystem of reusable workflow actions. Although GHA provides official documentation and community-supported best practices, there appears to be limited empirical understanding of how open-source real-world CI workflows align with such practices. Many workflows might be unnecessarily complex and not aligned with the simplicity goals of CI practices. This study will investigate the structure, complexity, heterogeneity, and compliance of GHA workflows in open-source software repositories. Using a large dataset of GHA workflows from Java, Python, and C++ repositories, our goal is to (a) identify workflow complexities, (b) analyze recurring and heterogeneous structuring patterns, (c) assess compliance with GHA best practices, and (d) uncover differences in CI pipeline design across programming languages. Our findings are expected to reveal both areas of strong adherence to best practices and areas for improvement where needed. These insights will also have implications for CI services, as they will highlight the need for clearer guidelines and comprehensive examples in CI documentation.",
      "authors": [
        "Edward Abrokwah and Taher A. Ghaleb"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:26:38+00:00",
          "link": "https://arxiv.org/abs/2507.18062v1",
          "size": "120kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18062",
        "HTML": "https://arxiv.org/html/2507.18062v1",
        "PDF": "https://arxiv.org/pdf/2507.18062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on GitHub Actions workflows in the context of continuous integration, which is not connected to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18064",
      "abstract": "Most existing low-light image enhancement (LLIE) methods rely on pre-trained model priors, low-light inputs, or both, while neglecting the semantic guidance available from normal-light images. This limitation hinders their effectiveness in complex lighting conditions. In this paper, we propose VLM-IMI, a novel framework that leverages large vision-language models (VLMs) with iterative and manual instructions (IMIs) for LLIE. VLM-IMI incorporates textual descriptions of the desired normal-light content as enhancement cues, enabling semantically informed restoration. To effectively integrate cross-modal priors, we introduce an instruction prior fusion module, which dynamically aligns and fuses image and text features, promoting the generation of detailed and semantically coherent outputs. During inference, we adopt an iterative and manual instruction strategy to refine textual instructions, progressively improving visual quality. This refinement enhances structural fidelity, semantic alignment, and the recovery of fine details under extremely low-light conditions. Extensive experiments across diverse scenarios demonstrate that VLM-IMI outperforms state-of-the-art methods in both quantitative metrics and perceptual quality. The source code is available at https://github.com/sunxiaoran01/VLM-IMI.",
      "authors": [
        "Xiaoran Sun",
        "Liyan Wang",
        "Cong Wang",
        "Yeying Jin",
        "Kin-man Lam",
        "Zhixun Su",
        "Yang Yang",
        "Jinshan Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:35:20+00:00",
          "link": "https://arxiv.org/abs/2507.18064v1",
          "size": "5339kb",
          "version": "v1"
        }
      ],
      "title": "Adapting Large VLMs with Iterative and Manual Instructions for Generative Low-light Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18064",
        "HTML": "https://arxiv.org/html/2507.18064v1",
        "PDF": "https://arxiv.org/pdf/2507.18064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper develops a framework using vision-language models (VLMs) for low-light image enhancement, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18067",
      "abstract": "Accurate modeling of physical systems governed by partial differential equations is a central challenge in scientific computing. In oceanography, high-resolution current data are critical for coastal management, environmental monitoring, and maritime safety. However, available satellite products, such as Copernicus data for sea water velocity at ~0.08 degrees spatial resolution and global ocean models, often lack the spatial granularity required for detailed local analyses. In this work, we (a) introduce a supervised deep learning framework based on neural operators for solving PDEs and providing arbitrary resolution solutions, and (b) propose downscaling models with an application to Copernicus ocean current data. Additionally, our method can model surrogate PDEs and predict solutions at arbitrary resolution, regardless of the input resolution. We evaluated our model on real-world Copernicus ocean current data and synthetic Navier-Stokes simulation datasets.",
      "authors": [
        "Abdessamad El-Kabid",
        "Loubna Benabbou",
        "Redouane Lguensat",
        "Alex Hern\\'andez-Garc\\'ia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:42:06+00:00",
          "link": "https://arxiv.org/abs/2507.18067v1",
          "size": "1613kb",
          "version": "v1"
        }
      ],
      "title": "Multiscale Neural PDE Surrogates for Prediction and Downscaling: Application to Ocean Currents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18067",
        "HTML": "https://arxiv.org/html/2507.18067v1",
        "PDF": "https://arxiv.org/pdf/2507.18067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling ocean currents using neural PDE surrogates and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18070",
      "abstract": "In this paper we propose a modular nonlinear least squares filtering approach for systems composed of independent subsystems. The state and error covariance estimate of each subsystem is updated independently, even when a relative measurement simultaneously depends on the states of multiple subsystems. We integrate the Covariance Intersection (CI) algorithm as part of our solution in order to prevent double counting of information when subsystems share estimates with each other. An alternative derivation of the CI algorithm based on least squares estimation makes this integration possible. We particularise the proposed approach to the robot-landmark localization problem. In this problem, noisy measurements of the bearing angle to a stationary landmark position measured relative to the SE(2) pose of a moving robot couple the estimation problems for the robot pose and the landmark position. In a randomized simulation study, we benchmark the proposed modular method against a monolithic joint state filter to elucidate their respective trade-offs. In this study we also include variants of the proposed method that achieve a graceful degradation of performance with reduced communication and bandwidth requirements.",
      "authors": [
        "Behzad Zamani and Jochen Trumpf and Chris Manzie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:49:43+00:00",
          "link": "https://arxiv.org/abs/2507.18070v1",
          "size": "223kb",
          "version": "v1"
        }
      ],
      "title": "Modular Robot and Landmark Localisation Using Relative Bearing Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18070",
        "HTML": "https://arxiv.org/html/2507.18070v1",
        "PDF": "https://arxiv.org/pdf/2507.18070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a localization approach using relative bearing measurements in robotic systems, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18071",
      "abstract": "This paper introduces Group Sequence Policy Optimization (GSPO), our stable, efficient, and performant reinforcement learning algorithm for training large language models. Unlike previous algorithms that adopt token-level importance ratios, GSPO defines the importance ratio based on sequence likelihood and performs sequence-level clipping, rewarding, and optimization. We demonstrate that GSPO achieves superior training efficiency and performance compared to the GRPO algorithm, notably stabilizes Mixture-of-Experts (MoE) RL training, and has the potential for simplifying the design of RL infrastructure. These merits of GSPO have contributed to the remarkable improvements in the latest Qwen3 models.",
      "authors": [
        "Chujie Zheng",
        "Shixuan Liu",
        "Mingze Li",
        "Xiong-Hui Chen",
        "Bowen Yu",
        "Chang Gao",
        "Kai Dang",
        "Yuqiong Liu",
        "Rui Men",
        "An Yang",
        "Jingren Zhou",
        "Junyang Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:50:32+00:00",
          "link": "https://arxiv.org/abs/2507.18071v1",
          "size": "258kb",
          "version": "v1"
        }
      ],
      "title": "Group Sequence Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18071",
        "PDF": "https://arxiv.org/pdf/2507.18071"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a reinforcement learning algorithm for training LLMs, focusing on optimization techniques rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18072",
      "abstract": "Wearable accelerometers and gyroscopes encode fine-grained behavioural signatures that can be exploited to re-identify users, making privacy protection essential for healthcare applications. We introduce C-AAE, a compressive anonymizing autoencoder that marries an Anonymizing AutoEncoder (AAE) with Adaptive Differential Pulse-Code Modulation (ADPCM). The AAE first projects raw sensor windows into a latent space that retains activity-relevant features while suppressing identity cues. ADPCM then differentially encodes this latent stream, further masking residual identity information and shrinking the bitrate. Experiments on the MotionSense and PAMAP2 datasets show that C-AAE cuts user re-identification F1 scores by 10-15 percentage points relative to AAE alone, while keeping activity-recognition F1 within 5 percentage points of the unprotected baseline. ADPCM also reduces data volume by roughly 75 %, easing transmission and storage overheads. These results demonstrate that C-AAE offers a practical route to balancing privacy and utility in continuous, sensor-based activity recognition for healthcare.",
      "authors": [
        "Ryusei Fujimoto",
        "Yugo Nakamura",
        "Yutaka Arakawa"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:55:04+00:00",
          "link": "https://arxiv.org/abs/2507.18072v1",
          "size": "9932kb",
          "version": "v1"
        }
      ],
      "title": "C-AAE: Compressively Anonymizing Autoencoders for Privacy-Preserving Activity Recognition in Healthcare Sensor Streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18072",
        "HTML": "https://arxiv.org/html/2507.18072v1",
        "PDF": "https://arxiv.org/pdf/2507.18072"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents privacy-preserving techniques for sensor data in healthcare applications, not focusing on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18073",
      "abstract": "Deploying large language models (LLMs) is challenging due to their massive parameters and high computational costs. Ultra low-bit quantization can significantly reduce storage and accelerate inference, but extreme compression (i.e., mean bit-width <= 2) often leads to severe performance degradation. To address this, we propose Squeeze10-LLM, effectively \"squeezing\" 16-bit LLMs' weights by 10 times. Specifically, Squeeze10-LLM is a staged mixed-precision post-training quantization (PTQ) framework and achieves an average of 1.6 bits per weight by quantizing 80% of the weights to 1 bit and 20% to 4 bits. We introduce Squeeze10LLM with two key innovations: Post-Binarization Activation Robustness (PBAR) and Full Information Activation Supervision (FIAS). PBAR is a refined weight significance metric that accounts for the impact of quantization on activations, improving accuracy in low-bit settings. FIAS is a strategy that preserves full activation information during quantization to mitigate cumulative error propagation across layers. Experiments on LLaMA and LLaMA2 show that Squeeze10-LLM achieves state-of-the-art performance for sub-2bit weight-only quantization, improving average accuracy from 43% to 56% on six zero-shot classification tasks--a significant boost over existing PTQ methods. Our code will be released upon publication.",
      "authors": [
        "Qingcheng Zhu",
        "Yangyang Ren",
        "Linlin Yang",
        "Mingbao Lin",
        "Yanjing Li",
        "Sheng Xu",
        "Zichao Feng",
        "Haodong Zhu",
        "Yuguang Yang",
        "Juan Zhang",
        "Runqi Wang",
        "Baochang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:55:19+00:00",
          "link": "https://arxiv.org/abs/2507.18073v1",
          "size": "21244kb",
          "version": "v1"
        }
      ],
      "title": "Squeeze10-LLM: Squeezing LLMs' Weights by 10 Times via a Staged Mixed-Precision Quantization Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18073",
        "HTML": "https://arxiv.org/html/2507.18073v1",
        "PDF": "https://arxiv.org/pdf/2507.18073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a mixed-precision quantization method for optimizing LLM weights, unrelated to the processing or generation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18074",
      "abstract": "While AI systems demonstrate exponentially improving capabilities, the pace of AI research itself remains linearly bounded by human cognitive capacity, creating an increasingly severe development bottleneck. We present ASI-Arch, the first demonstration of Artificial Superintelligence for AI research (ASI4AI) in the critical domain of neural architecture discovery--a fully autonomous system that shatters this fundamental constraint by enabling AI to conduct its own architectural innovation. Moving beyond traditional Neural Architecture Search (NAS), which is fundamentally limited to exploring human-defined spaces, we introduce a paradigm shift from automated optimization to automated innovation. ASI-Arch can conduct end-to-end scientific research in the domain of architecture discovery, autonomously hypothesizing novel architectural concepts, implementing them as executable code, training and empirically validating their performance through rigorous experimentation and past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000 GPU hours, culminating in the discovery of 106 innovative, state-of-the-art (SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed unexpected strategic insights invisible to human players, our AI-discovered architectures demonstrate emergent design principles that systematically surpass human-designed baselines and illuminate previously unknown pathways for architectural innovation. Crucially, we establish the first empirical scaling law for scientific discovery itself--demonstrating that architectural breakthroughs can be scaled computationally, transforming research progress from a human-limited to a computation-scalable process. We provide comprehensive analysis of the emergent design patterns and autonomous research capabilities that enabled these breakthroughs, establishing a blueprint for self-accelerating AI systems.",
      "authors": [
        "Yixiu Liu",
        "Yang Nan",
        "Weixian Xu",
        "Xiangkun Hu",
        "Lyumanshan Ye",
        "Zhen Qin",
        "Pengfei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:57:27+00:00",
          "link": "https://arxiv.org/abs/2507.18074v1",
          "size": "2130kb",
          "version": "v1"
        }
      ],
      "title": "AlphaGo Moment for Model Architecture Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18074",
        "PDF": "https://arxiv.org/pdf/2507.18074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural architecture discovery using Artificial Superintelligence, with no discussion on training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18075",
      "abstract": "Python software development heavily relies on third-party packages. Direct and transitive dependencies create a labyrinth of software supply chains. While it is convenient to reuse code, vulnerabilities within these dependency chains can propagate through dependencies, potentially affecting down-stream packages and applications. PyPI, the official Python package repository, hosts many packages and lacks a comprehensive analysis of the prevalence of vulnerable dependencies. This paper introduces PyPitfall, a quantitative analysis of vulnerable dependencies across the PyPI ecosystem. We analyzed the dependency structures of 378,573 PyPI packages and identified 4,655 packages that explicitly require at least one known-vulnerable version and 141,044 packages that permit vulnerable versions within specified ranges. By characterizing the ecosystem-wide dependency landscape and the security impact of transitive dependencies, we aim to raise awareness of Python software supply chain security.",
      "authors": [
        "Jacob Mahon",
        "Chenxi Hou",
        "Zhihao Yao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T03:58:18+00:00",
          "link": "https://arxiv.org/abs/2507.18075v1",
          "size": "2154kb",
          "version": "v1"
        }
      ],
      "title": "PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18075",
        "HTML": "https://arxiv.org/html/2507.18075v1",
        "PDF": "https://arxiv.org/pdf/2507.18075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses software supply chain vulnerabilities in Python, focusing on dependencies and security, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18076",
      "abstract": "Fine-tuning large language models (LLMs) remains a computational bottleneck due to their scale and memory demands. This paper presents a comprehensive evaluation of parameter-efficient fine-tuning (PEFT) techniques, including LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that dynamically integrates BOFT's orthogonal stability with LoRA-GA's gradient-aligned rapid convergence. By computing per-layer adaptive updates guided by gradient norms, the hybrid method achieves superior convergence efficiency and generalization across diverse tasks. We also explore, for the first time, the adaptation of unitary RNN (uRNN) principles to transformer-based LLMs, enhancing gradient stability through structured unitary constraints. Empirical evaluations on four benchmarks -- GLUE, GSM8K, MT-Bench, and HumanEval -- using models ranging from 7B to 405B parameters demonstrate that our hybrid method consistently outperforms individual PEFT baselines, approaching full fine-tuning accuracy while reducing resource consumption by up to 2.1 times in training time and 50 percent in memory usage. These findings establish the hybrid approach as a practical and scalable fine-tuning solution for real-world deployment of LLMs under resource constraints.",
      "authors": [
        "Haomin Qi",
        "Zihan Dai",
        "Chengbo Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T04:00:02+00:00",
          "link": "https://arxiv.org/abs/2507.18076v1",
          "size": "300kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18076",
        "HTML": "https://arxiv.org/html/2507.18076v1",
        "PDF": "https://arxiv.org/pdf/2507.18076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates parameter-efficient fine-tuning techniques for LLMs, including a novel hybrid method. Although it involves fine-tuning, the focus is on computational efficiency rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18077",
      "abstract": "Power systems decarbonization are at the focal point of the clean energy transition. While system operators and utility companies increasingly publicize system-level carbon emission information, it remains unclear how emissions from individual generators are transported through the grid and how they impact electricity users at specific locations. This paper presents a novel and computationally efficient approach for exact quantification of nodal average and marginal carbon emission rates, applicable to both AC and DC optimal power flow problems. The approach leverages graph-based topological sorting and directed cycle removal techniques, applied to directed graphs formed by generation dispatch and optimal power flow solutions. Our proposed algorithm efficiently identifies each generator's contribution to each node, capturing how emissions are spatially distributed under varying system conditions. To validate its effectiveness and reveal locational and temporal emission patterns in the real world, we simulate the 8,870-bus realistic California grid using actual CAISO data and the CATS model. Based on year long hourly data on nodal loads and renewable generation, obtained or estimated from CAISO public data, our method accurately estimates power flow conditions, generation mixes, and systemwide emissions, and delivers fine grained spatiotemporal emission analysis for every California county. Both our algorithm and the California study are open-sourced, providing a foundation for future research on grid emissions, planning, operations, and energy policy.",
      "authors": [
        "Yuqing Shen",
        "Yuanyuan Shi",
        "Daniel Kirschen",
        "and Yize Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T04:01:54+00:00",
          "link": "https://arxiv.org/abs/2507.18077v1",
          "size": "3199kb",
          "version": "v1"
        }
      ],
      "title": "Carbon Emission Flow Tracing: Fast Algorithm and California Grid Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18077",
        "HTML": "https://arxiv.org/html/2507.18077v1",
        "PDF": "https://arxiv.org/pdf/2507.18077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research pertains to carbon emission tracing in power systems and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18081",
      "abstract": "Identifier names, which comprise a significant portion of the codebase, are the cornerstone of effective program comprehension. However, research has shown that poorly chosen names can significantly increase cognitive load and hinder collaboration. Even names that appear readable in isolation may lead to misunderstandings in contexts when they closely resemble other names in either structure or functionality. In this exploratory study, we present our preliminary findings on the occurrence of identifier name similarity in software projects through the development of a taxonomy that categorizes different forms of identifier name similarity. We envision our initial taxonomy providing researchers with a platform to analyze and evaluate the impact of identifier name similarity on code comprehension, maintainability, and collaboration among developers, while also allowing for further refinement and expansion of the taxonomy.",
      "authors": [
        "Carol Wong and Mai Abe and Silvia De Benedictis and Marissa Halim and Anthony Peruma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T04:13:26+00:00",
          "link": "https://arxiv.org/abs/2507.18081v1",
          "size": "90kb",
          "version": "v1"
        }
      ],
      "title": "Identifier Name Similarities: An Exploratory Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18081",
        "HTML": "https://arxiv.org/html/2507.18081v1",
        "PDF": "https://arxiv.org/pdf/2507.18081"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores identifier name similarities in software projects, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18082",
      "abstract": "Pancreatic cancer carries a poor prognosis and relies on endoscopic ultrasound (EUS) for targeted biopsy and radiotherapy. However, the speckle noise, low contrast, and unintuitive appearance of EUS make segmentation of pancreatic tumors with fully supervised deep learning (DL) models both error-prone and dependent on large, expert-curated annotation datasets. To address these challenges, we present TextSAM-EUS, a novel, lightweight, text-driven adaptation of the Segment Anything Model (SAM) that requires no manual geometric prompts at inference. Our approach leverages text prompt learning (context optimization) through the BiomedCLIP text encoder in conjunction with a LoRA-based adaptation of SAM's architecture to enable automatic pancreatic tumor segmentation in EUS, tuning only 0.86% of the total parameters. On the public Endoscopic Ultrasound Database of the Pancreas, TextSAM-EUS with automatic prompts attains 82.69% Dice and 85.28% normalized surface distance (NSD), and with manual geometric prompts reaches 83.10% Dice and 85.70% NSD, outperforming both existing state-of-the-art (SOTA) supervised DL models and foundation models (e.g., SAM and its variants). As the first attempt to incorporate prompt learning in SAM-based medical image segmentation, TextSAM-EUS offers a practical option for efficient and robust automatic EUS segmentation. Our code will be publicly available upon acceptance.",
      "authors": [
        "Pascal Spiegler",
        "Taha Koleilat",
        "Arash Harirpoush",
        "Corey S. Miller",
        "Hassan Rivaz",
        "Marta Kersten-Oertel and Yiming Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T04:17:06+00:00",
          "link": "https://arxiv.org/abs/2507.18082v1",
          "size": "713kb",
          "version": "v1"
        }
      ],
      "title": "TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18082",
        "HTML": "https://arxiv.org/html/2507.18082v1",
        "PDF": "https://arxiv.org/pdf/2507.18082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel segmentation model for pancreatic tumor detection in medical imaging, using text prompt learning and DL model adaptation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18084",
      "abstract": "While much of the research in digital games has emphasized hedonic experiences, such as flow, enjoyment, and positive affect, recent years have seen increased interest in eudaimonic gaming experiences, typically mixed-affect and associated with personal meaningfulness and growth. The formation of such experiences in games is theorized to have four constituent elements: motivation, game use, experience, and effects. However, while the first three elements have been relatively well explored in the literature, the effects - and how they may influence positive individual outcomes - have been underexplored thus far. To this end, in this work, we investigate the perceived outcomes of eudaimonic gaming and how different components of the experience influence these effects. We conducted a survey (n = 166) in which respondents recounted meaningful gaming experiences and how they affected their present lives. We used a mixed-methods approach to classify effects and identify significant subcomponents of their formation. We contribute an empirical understanding of how meaningful gaming experiences can lead to positive reflective, learning, social, health, and career effects, extending current theoretical models of eudaimonic gaming experiences and offering implications for how researchers and practitioners might use these findings to promote positive outcomes for players.",
      "authors": [
        "Nisha Devasia",
        "Georgia Kenderova",
        "Michele Newman",
        "Julie Kientz",
        "and Jin Ha Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T04:34:18+00:00",
          "link": "https://arxiv.org/abs/2507.18084v1",
          "size": "532kb",
          "version": "v1"
        }
      ],
      "title": "\"I Would Not Be This Version of Myself Today\": Elaborating on the Effects of Eudaimonic Gaming Experiences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18084",
        "HTML": "https://arxiv.org/html/2507.18084v1",
        "PDF": "https://arxiv.org/pdf/2507.18084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the effects of eudaimonic gaming experiences, focusing on personal growth and meaningfulness. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18085",
      "abstract": "System responsiveness (SR) is defined as the elapsed time until a system responds to user control. SR fluctuates over time, so it must be described statistically with mean (MSR) and standard deviation (SDSR). In this paper, we examine SR in virtual environments (VEs), outlining its components and methods of experimental measurement and manipulation. Three studies of MSR and SDSR effects on performance of grasp and placement tasks are then presented. The studies used within-subjects designs with 11, 12, and 10 participants, respectively. Results showed that SDSR affected performance only if it was above 82 ms. Placement required more frequent visual feedback and was more sensitive to SR. We infer that VE designers need not tightly control SDSR and may wish to vary SR control based on required visual feedback frequency. These results may be used to improve the human-computer interface in a wide range of interactive graphical applications, including scientific visualization, training, mental health, and entertainment.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "William Ribarsky",
        "Victoria Spaulding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T04:38:20+00:00",
          "link": "https://arxiv.org/abs/2507.18085v1",
          "size": "122kb",
          "version": "v1"
        }
      ],
      "title": "Effects of variation in system responsiveness on user performance in virtual environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18085",
        "PDF": "https://arxiv.org/pdf/2507.18085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines system responsiveness in virtual environments and its impact on user performance. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18095",
      "abstract": "Mobile power sources (MPSs) have been gradually deployed in microgrids as critical resources to coordinate with repair crews (RCs) towards resilience enhancement owing to their flexibility and mobility in handling the complex coupled power-transport systems. However, previous work solves the coordinated dispatch problem of MPSs and RCs in a centralized manner with the assumption that the communication network is still fully functioning after the event. However, there is growing evidence that certain extreme events will damage or degrade communication infrastructure, which makes centralized decision making impractical. To fill this gap, this paper formulates the resilience-driven dispatch problem of MPSs and RCs in a decentralized framework. To solve this problem, a hierarchical multi-agent reinforcement learning method featuring a two-level framework is proposed, where the high-level action is used to switch decision-making between power and transport networks, and the low-level action constructed via a hybrid policy is used to compute continuous scheduling and discrete routing decisions in power and transport networks, respectively. The proposed method also uses an embedded function encapsulating system dynamics to enhance learning stability and scalability. Case studies based on IEEE 33-bus and 69-bus power networks are conducted to validate the effectiveness of the proposed method in load restoration.",
      "authors": [
        "Yi Wang",
        "Dawei Qiu",
        "Fei Teng",
        "Goran Strbac"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:16:39+00:00",
          "link": "https://arxiv.org/abs/2507.18095v1",
          "size": "1465kb",
          "version": "v1"
        }
      ],
      "title": "Towards Microgrid Resilience Enhancement via Mobile Power Sources and Repair Crews: A Multi-Agent Reinforcement Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18095",
        "PDF": "https://arxiv.org/pdf/2507.18095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a decentralized approach for microgrid resilience enhancement using mobile power sources and repair crews. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18098",
      "abstract": "In scenarios where training data is limited due to observation costs or data scarcity, enriching the label information associated with each instance becomes crucial for building high-accuracy classification models. In such contexts, it is often feasible to obtain not only hard labels but also {\\it additional supervision}, such as the confidences for the hard labels. This setting naturally raises fundamental questions: {\\it What kinds of additional supervision are intrinsically beneficial?} And {\\it how do they contribute to improved generalization performance?} To address these questions, we propose a theoretical framework that treats both hard labels and additional supervision as probability distributions, and constructs soft labels through their affine combination. Our theoretical analysis reveals that the essential component of additional supervision is not the confidence score of the assigned hard label, but rather the information of the distribution over the non-hard-labeled classes. Moreover, we demonstrate that the additional supervision and the mixing coefficient contribute to the refinement of soft labels in complementary roles. Intuitively, in the probability simplex, the additional supervision determines the direction in which the deterministic distribution representing the hard label should be adjusted toward the true label distribution, while the mixing coefficient controls the step size along that direction. Through generalization error analysis, we theoretically characterize how the additional supervision and its mixing coefficient affect both the convergence rate and asymptotic value of the error bound. Finally, we experimentally demonstrate that, based on our theory, designing additional supervision can lead to improved classification accuracy, even when utilized in a simple manner.",
      "authors": [
        "Kosuke Sugiyama",
        "Masato Uchida"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:19:07+00:00",
          "link": "https://arxiv.org/abs/2507.18098v1",
          "size": "1324kb",
          "version": "v1"
        }
      ],
      "title": "Learning from Hard Labels with Additional Supervision on Non-Hard-Labeled Classes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18098",
        "PDF": "https://arxiv.org/pdf/2507.18098"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving classification models through additional supervision and soft label refinement, without addressing any aspect of LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18099",
      "abstract": "Land Use Land Cover (LULC) mapping is essential for urban and resource planning, and is one of the key elements in developing smart and sustainable cities.This study evaluates advanced LULC mapping techniques, focusing on Look-Up Table (LUT)-based Atmospheric Correction applied to Cartosat Multispectral (MX) sensor images, followed by supervised and semi-supervised learning models for LULC prediction. We explore DeeplabV3+ and Cross-Pseudo Supervision (CPS). The CPS model is further refined with dynamic weighting, enhancing pseudo-label reliability during training. This comprehensive approach analyses the accuracy and utility of LULC mapping techniques for various urban planning applications. A case study of Hyderabad, India, illustrates significant land use changes due to rapid urbanization. By analyzing Cartosat MX images over time, we highlight shifts such as urban sprawl, shrinking green spaces, and expanding industrial areas. This demonstrates the practical utility of these techniques for urban planners and policymakers.",
      "authors": [
        "Naman Srivastava",
        "Joel D Joy",
        "Yash Dixit",
        "Swarup E",
        "Rakshit Ramesh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:23:02+00:00",
          "link": "https://arxiv.org/abs/2507.18099v1",
          "size": "6368kb",
          "version": "v1"
        }
      ],
      "title": "Comparison of Segmentation Methods in Remote Sensing for Land Use Land Cover",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18099",
        "HTML": "https://arxiv.org/html/2507.18099v1",
        "PDF": "https://arxiv.org/pdf/2507.18099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with segmentation methods in remote sensing for land use mapping and does not discuss any LLM training data processing operations or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18100",
      "abstract": "Video Temporal Grounding (VTG) aims to localize relevant temporal segments in videos given natural language queries. Despite recent progress with large vision-language models (LVLMs) and instruction-tuning, existing approaches often suffer from limited temporal awareness and poor generalization. In this work, we introduce a two-stage training framework that integrates supervised fine-tuning with reinforcement learning (RL) to improve both the accuracy and robustness of VTG models. Our approach first leverages high-quality curated cold start data for SFT initialization, followed by difficulty-controlled RL to further enhance temporal localization and reasoning abilities. Comprehensive experiments on multiple VTG benchmarks demonstrate that our method consistently outperforms existing models, particularly in challenging and open-domain scenarios. We conduct an in-depth analysis of training strategies and dataset curation, highlighting the importance of both high-quality cold start data and difficulty-controlled RL. To facilitate further research and industrial adoption, we release all intermediate datasets, models, and code to the community.",
      "authors": [
        "Ruizhe Chen",
        "Zhiting Fan",
        "Tianze Luo",
        "Heqing Zou",
        "Zhaopeng Feng",
        "Guiyang Xie",
        "Hansheng Zhang",
        "Zhuochen Wang",
        "Zuozhu Liu",
        "Huaijian Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:24:01+00:00",
          "link": "https://arxiv.org/abs/2507.18100v1",
          "size": "9238kb",
          "version": "v1"
        }
      ],
      "title": "Datasets and Recipes for Video Temporal Grounding via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18100",
        "HTML": "https://arxiv.org/html/2507.18100v1",
        "PDF": "https://arxiv.org/pdf/2507.18100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces datasets and training frameworks for Video Temporal Grounding, involving data curation and supervised fine-tuning. It emphasizes high-quality dataset development and releases all related datasets, making a direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18102",
      "abstract": "Large renewable penetration has been witnessed in power systems, resulting in reduced levels of system inertia and increasing requirements for frequency response services. There have been plenty of studies developing frequency-constrained models for power system security. However, most existing literature only considers uniform frequency security, while neglecting frequency spatial differences in different regions. To fill this gap, this paper proposes a novel planning model for the optimal sizing problem of power systems, capturing regional frequency security and inter-area frequency oscillations. Specifically, regional frequency constraints are first extracted via an enhanced input convex neural network (ICNN) and then embedded into the original optimisation for frequency security, where a principled weight initialisation strategy is adopted to deal with the gradient vanishing issues of non-negative weights in traditional ICNNs and enhance its fitting ability. An adaptive genetic algorithm with sparsity calculation and local search is developed to separate the planning model into two stages and effectively solve it iteratively. Case studies have been conducted on three different power systems to verify the effectiveness of the proposed frequency-constrained planning model in ensuring regional system security and obtaining realistic investment decisions.",
      "authors": [
        "Yi Wang",
        "Goran Strbac"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:28:52+00:00",
          "link": "https://arxiv.org/abs/2507.18102v1",
          "size": "1590kb",
          "version": "v1"
        }
      ],
      "title": "Regional Frequency-Constrained Planning for the Optimal Sizing of Power Systems via Enhanced Input Convex Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18102",
        "PDF": "https://arxiv.org/pdf/2507.18102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on power system planning using neural networks, addressing frequency constraints, and does not involve any LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18103",
      "abstract": "This report documents, describes, and evaluates new 2024 English GloVe (Global Vectors for Word Representation) models. While the original GloVe models built in 2014 have been widely used and found useful, languages and the world continue to evolve and we thought that current usage could benefit from updated models. Moreover, the 2014 models were not carefully documented as to the exact data versions and preprocessing that were used, and we rectify this by documenting these new models. We trained two sets of word embeddings using Wikipedia, Gigaword, and a subset of Dolma. Evaluation through vocabulary comparison, direct testing, and NER tasks shows that the 2024 vectors incorporate new culturally and linguistically relevant words, perform comparably on structural tasks like analogy and similarity, and demonstrate improved performance on recent, temporally dependent NER datasets such as non-Western newswire data.",
      "authors": [
        "Riley Carlson",
        "John Bauer",
        "and Christopher D. Manning"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:29:18+00:00",
          "link": "https://arxiv.org/abs/2507.18103v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "A New Pair of GloVes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18103",
        "HTML": "https://arxiv.org/html/2507.18103v1",
        "PDF": "https://arxiv.org/pdf/2507.18103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper documents the creation of updated GloVe models with new data from Wikipedia, Gigaword, and Dolma datasets. This involves data generation and processing, which are significant for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18104",
      "abstract": "The Algonauts 2025 Challenge called on the community to develop encoding models that predict whole-brain fMRI responses to naturalistic multimodal movies. In this submission, we propose a sequence-to-sequence Transformer that autoregressively predicts fMRI activity from visual, auditory, and language inputs. Stimulus features were extracted using pretrained models including VideoMAE, HuBERT, Qwen, and BridgeTower. The decoder integrates information from prior brain states, current stimuli, and episode-level summaries via dual cross-attention mechanisms that attend to both perceptual information extracted from the stimulus as well as narrative information provided by high-level summaries of narrative content. One core innovation of our approach is the use of sequences of multimodal context to predict sequences of brain activity, enabling the model to capture long-range temporal structure in both stimuli and neural responses. Another is the combination of a shared encoder with partial subject-specific decoder, which leverages common structure across subjects while accounting for individual variability. Our model achieves strong performance on both in-distribution and out-of-distribution data, demonstrating the effectiveness of temporally-aware, multimodal sequence modeling for brain activity prediction. The code is available at https://github.com/Angelneer926/Algonauts_challenge.",
      "authors": [
        "Qianyi He",
        "Yuan Chang Leong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:29:37+00:00",
          "link": "https://arxiv.org/abs/2507.18104v1",
          "size": "3207kb",
          "version": "v1"
        }
      ],
      "title": "A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18104",
        "HTML": "https://arxiv.org/html/2507.18104v1",
        "PDF": "https://arxiv.org/pdf/2507.18104"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on predicting brain responses using a multimodal Seq2Seq Transformer, which is unrelated to LLM training data processing as it involves brain activity prediction rather than LLM data enhancements or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18105",
      "abstract": "The rise of Large Language Models (LLMs) has led to the widespread deployment of LLM-based systems across diverse domains. As these systems proliferate, understanding the risks associated with their complex supply chains is increasingly important. LLM-based systems are not standalone as they rely on interconnected supply chains involving pretrained models, third-party libraries, datasets, and infrastructure. Yet, most risk assessments narrowly focus on model or data level, overlooking broader supply chain vulnerabilities. While recent studies have begun to address LLM supply chain risks, there remains a lack of benchmarks for systematic research.\n  To address this gap, we introduce the first comprehensive dataset for analyzing and benchmarking LLM supply chain security. We collect 3,859 real-world LLM applications and perform interdependency analysis, identifying 109,211 models, 2,474 datasets, and 9,862 libraries. We extract model fine-tuning paths, dataset reuse, and library reliance, mapping the ecosystem's structure. To evaluate security, we gather 1,555 risk-related issues-50 for applications, 325 for models, 18 for datasets, and 1,229 for libraries from public vulnerability databases.\n  Using this dataset, we empirically analyze component dependencies and risks. Our findings reveal deeply nested dependencies in LLM applications and significant vulnerabilities across the supply chain, underscoring the need for comprehensive security analysis. We conclude with practical recommendations to guide researchers and developers toward safer, more trustworthy LLM-enabled systems.",
      "authors": [
        "Yujie Ma",
        "Lili Quan",
        "Xiaofei Xie",
        "Qiang Hu",
        "Jiongchi Yu",
        "Yao Zhang",
        "Sen Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:30:54+00:00",
          "link": "https://arxiv.org/abs/2507.18105v1",
          "size": "5022kb",
          "version": "v1"
        }
      ],
      "title": "Understanding the Supply Chain and Risks of Large Language Model Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18105",
        "HTML": "https://arxiv.org/html/2507.18105v1",
        "PDF": "https://arxiv.org/pdf/2507.18105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a dataset for analyzing LLM supply chain security, its primary focus is on supply chain risks and security rather than on LLM training data processing. It briefly touches on data aspects but is not centered around training data improvements or dataset generation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18106",
      "abstract": "Estimating uncertainty from deep neural networks is a widely used approach for detecting out-of-distribution (OoD) samples, which typically exhibit high predictive uncertainty. However, conventional methods such as Monte Carlo (MC) Dropout often focus solely on either model or data uncertainty, failing to align with the semantic objective of OoD detection. To address this, we propose the Free-Energy Posterior Network, a novel framework that jointly models distributional uncertainty and identifying OoD and misclassified regions using free energy. Our method introduces two key contributions: (1) a free-energy-based density estimator parameterized by a Beta distribution, which enables fine-grained uncertainty estimation near ambiguous or unseen regions; and (2) a loss integrated within a posterior network, allowing direct uncertainty estimation from learned parameters without requiring stochastic sampling. By integrating our approach with the residual prediction branch (RPL) framework, the proposed method goes beyond post-hoc energy thresholding and enables the network to learn OoD regions by leveraging the variance of the Beta distribution, resulting in a semantically meaningful and computationally efficient solution for uncertainty-aware segmentation. We validate the effectiveness of our method on challenging real-world benchmarks, including Fishyscapes, RoadAnomaly, and Segment-Me-If-You-Can.",
      "authors": [
        "JinYoung Kim",
        "DaeUng Jo",
        "Kimin Yun",
        "Jeonghyo Song",
        "Youngjoon Yoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:35:49+00:00",
          "link": "https://arxiv.org/abs/2507.18106v1",
          "size": "9794kb",
          "version": "v1"
        }
      ],
      "title": "Distributional Uncertainty for Out-of-Distribution Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18106",
        "HTML": "https://arxiv.org/html/2507.18106v1",
        "PDF": "https://arxiv.org/pdf/2507.18106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with out-of-distribution detection using uncertainty estimation methods but does not address LLM training data processing, such as dataset curation, data quality improvement, or dataset generation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18107",
      "abstract": "Text-to-video (T2V) models have shown remarkable performance in generating visually reasonable scenes, while their capability to leverage world knowledge for ensuring semantic consistency and factual accuracy remains largely understudied. In response to this challenge, we propose T2VWorldBench, the first systematic evaluation framework for evaluating the world knowledge generation abilities of text-to-video models, covering 6 major categories, 60 subcategories, and 1,200 prompts across a wide range of domains, including physics, nature, activity, culture, causality, and object. To address both human preference and scalable evaluation, our benchmark incorporates both human evaluation and automated evaluation using vision-language models (VLMs). We evaluated the 10 most advanced text-to-video models currently available, ranging from open source to commercial models, and found that most models are unable to understand world knowledge and generate truly correct videos. These findings point out a critical gap in the capability of current text-to-video models to leverage world knowledge, providing valuable research opportunities and entry points for constructing models with robust capabilities for commonsense reasoning and factual generation.",
      "authors": [
        "Yubin Chen",
        "Xuyang Guo",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:37:08+00:00",
          "link": "https://arxiv.org/abs/2507.18107v1",
          "size": "9114kb",
          "version": "v1"
        }
      ],
      "title": "T2VWorldBench: A Benchmark for Evaluating World Knowledge in Text-to-Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18107",
        "HTML": "https://arxiv.org/html/2507.18107v1",
        "PDF": "https://arxiv.org/pdf/2507.18107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a benchmark for evaluating text-to-video generation models' world knowledge capabilities, which does not relate to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18110",
      "abstract": "High renewable penetration has been witnessed in power systems, resulting in reduced system inertia and increasing requirements for frequency response services. Electric vehicles (EVs), owing to their vehicle-to-grid (V2G) capabilities, can provide cost-effective frequency services for transmission system operators (TSOs). However, EVs that are inherently connected to distribution networks may pose voltage security issues for distribution system operators (DSOs) when supporting TSO frequency. To coordinate both TSO frequency and DSO voltage, this paper proposes a two-stage service provision framework for multi-EVs. At stage one, EVs participate in day-ahead TSO-DSO interactions for frequency reserve schedules; at stage two, EVs make real-time dispatching behaviors in distribution networks for reserve delivery while supporting DSO voltage. Considering the potentially large EV number and environment complexity, a decentralized operation paradigm is introduced for real-time EV dispatches at stage two, while a communication-efficient reinforcement learning (RL) algorithm is proposed to reduce the communication overhead during large-scale multi-agent RL training without compromising policy performance. Case studies are carried out on a 6-bus transmission and 33-bus distribution network as well as a 69-bus distribution network to evaluate the effectiveness and scalability of the proposed method in enabling EVs for frequency service and voltage support.",
      "authors": [
        "Yi Wang",
        "Dawei Qiu",
        "Fei Teng",
        "Goran Strbac"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:45:06+00:00",
          "link": "https://arxiv.org/abs/2507.18110v1",
          "size": "2462kb",
          "version": "v1"
        }
      ],
      "title": "Two-Stage TSO-DSO Services Provision Framework for Electric Vehicle Coordination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18110",
        "PDF": "https://arxiv.org/pdf/2507.18110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focused on electric vehicle coordination and services in power systems, this paper does not involve any aspect of LLM training data processing, such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18111",
      "abstract": "In this paper, we tackle the challenge of radio access network (RAN) slicing within an open RAN (O-RAN) architecture. Our focus centers on a network that includes multiple mobile virtual network operators (MVNOs) competing for physical resource blocks (PRBs) with the goal of meeting probabilistic delay upper bound constraints for their clients while minimizing PRB utilization. Initially, we derive a reward function based on the law of large numbers (LLN), then implement practical modifications to adapt it for real-world experimental scenarios. We then propose our solution, the Percentile-based Delay-Aware Deep Reinforcement Learning (PDA-DRL), which demonstrates its superiority over several baselines, including DRL models optimized for average delay constraints, by achieving a 38\\% reduction in resultant average delay. Furthermore, we delve into the issue of model weight sharing among multiple MVNOs to develop a robust personalized model. We introduce a reward-based personalization method where each agent prioritizes other agents' model weights based on their performance. This technique surpasses traditional aggregation methods, such as federated averaging, and strategies reliant on traffic patterns and model weight distance similarities.",
      "authors": [
        "Peyman Tehrani",
        "Anas Alsoliman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:45:41+00:00",
          "link": "https://arxiv.org/abs/2507.18111v1",
          "size": "2473kb",
          "version": "v1"
        }
      ],
      "title": "Percentile-Based Deep Reinforcement Learning and Reward Based Personalization For Delay Aware RAN Slicing in O-RAN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18111",
        "HTML": "https://arxiv.org/html/2507.18111v1",
        "PDF": "https://arxiv.org/pdf/2507.18111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on RAN slicing and network optimization using deep reinforcement learning, not addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18113",
      "abstract": "Reinforcement learning (RL) has achieved remarkable success in fields like robotics and autonomous driving, but adversarial attacks designed to mislead RL systems remain challenging. Existing approaches often rely on modifying the environment or policy, limiting their practicality. This paper proposes an adversarial attack method in which existing agents in the environment guide the target policy to output suboptimal actions without altering the environment. We propose a reward iteration optimization framework that leverages large language models (LLMs) to generate adversarial rewards explicitly tailored to the vulnerabilities of the target agent, thereby enhancing the effectiveness of inducing the target agent toward suboptimal decision-making. Additionally, a critical state identification algorithm is designed to pinpoint the target agent's most vulnerable states, where suboptimal behavior from the victim leads to significant degradation in overall performance. Experimental results in diverse environments demonstrate the superiority of our method over existing approaches.",
      "authors": [
        "Junyong Jiang",
        "Buwei Tian",
        "Chenxing Xu",
        "Songze Li",
        "Lu Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:52:06+00:00",
          "link": "https://arxiv.org/abs/2507.18113v1",
          "size": "996kb",
          "version": "v1"
        }
      ],
      "title": "Policy Disruption in Reinforcement Learning:Adversarial Attack with Large Language Models and Critical State Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18113",
        "HTML": "https://arxiv.org/html/2507.18113v1",
        "PDF": "https://arxiv.org/pdf/2507.18113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about adversarial attacks in reinforcement learning systems and does not discuss any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18115",
      "abstract": "Building and deploying machine learning solutions in healthcare remains expensive and labor-intensive due to fragmented preprocessing workflows, model compatibility issues, and stringent data privacy constraints. In this work, we introduce an Agentic AI framework that automates the entire clinical data pipeline, from ingestion to inference, through a system of modular, task-specific agents. These agents handle both structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing recommendation without manual intervention. We evaluate the system on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging. For example, in the case of structured data (anxiety data) and unstructured data (colonoscopy polyps data), the pipeline begins with file-type detection by the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring privacy compliance, where we first identify the data type and then anonymize it. The Feature Extraction Agent identifies features using an embedding-based approach for tabular data, extracting all column names, and a multi-stage MedGemma-based approach for image data, which infers modality and disease name. These features guide the Model-Data Feature Matcher Agent in selecting the best-fit model from a curated repository. The Preprocessing Recommender Agent and Preprocessing Implementor Agent then apply tailored preprocessing based on data type and model requirements. Finally, the ``Model Inference Agent\" runs the selected model on the uploaded data and generates interpretable outputs using tools like SHAP, LIME, and DETR attention maps. By automating these high-friction stages of the ML lifecycle, the proposed framework reduces the need for repeated expert intervention, offering a scalable, cost-efficient pathway for operationalizing AI in clinical environments.",
      "authors": [
        "Soorya Ram Shimgekar",
        "Shayan Vassef",
        "Abhay Goyal",
        "Navin Kumar",
        "Koustuv Saha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:56:25+00:00",
          "link": "https://arxiv.org/abs/2507.18115v1",
          "size": "11868kb",
          "version": "v1"
        }
      ],
      "title": "Agentic AI framework for End-to-End Medical Data Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18115",
        "HTML": "https://arxiv.org/html/2507.18115v1",
        "PDF": "https://arxiv.org/pdf/2507.18115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an AI framework for automating the clinical data pipeline, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18119",
      "abstract": "Recent advances in end-to-end spoken language models (SLMs) have significantly improved the ability of AI systems to engage in natural spoken interactions. However, most existing models treat speech merely as a vehicle for linguistic content, often overlooking the rich paralinguistic and speaker characteristic cues embedded in human speech, such as dialect, age, emotion, and non-speech vocalizations. In this work, we introduce GOAT-SLM, a novel spoken language model with paralinguistic and speaker characteristic awareness, designed to extend spoken language modeling beyond text semantics. GOAT-SLM adopts a dual-modality head architecture that decouples linguistic modeling from acoustic realization, enabling robust language understanding while supporting expressive and adaptive speech generation. To enhance model efficiency and versatility, we propose a modular, staged training strategy that progressively aligns linguistic, paralinguistic, and speaker characteristic information using large-scale speech-text corpora. Experimental results on TELEVAL, a multi-dimensional evaluation benchmark, demonstrate that GOAT-SLM achieves well-balanced performance across both semantic and non-semantic tasks, and outperforms existing open-source models in handling emotion, dialectal variation, and age-sensitive interactions. This work highlights the importance of modeling beyond linguistic content and advances the development of more natural, adaptive, and socially aware spoken language systems.",
      "authors": [
        "Hongjie Chen",
        "Zehan Li",
        "Yaodong Song",
        "Wenming Deng",
        "Yitong Yao",
        "Yuxin Zhang",
        "Hang Lv",
        "Xuechao Zhu",
        "Jian Kang",
        "Jie Lian",
        "Jie Li",
        "Chao Wang",
        "Shuangyong Song",
        "Yongxiang Li",
        "Zhongjiang He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:10:29+00:00",
          "link": "https://arxiv.org/abs/2507.18119v1",
          "size": "1835kb",
          "version": "v1"
        }
      ],
      "title": "GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18119",
        "HTML": "https://arxiv.org/html/2507.18119v1",
        "PDF": "https://arxiv.org/pdf/2507.18119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Though this paper deals with a novel spoken language model, it primarily addresses model architecture and training strategies rather than contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18122",
      "abstract": "Recent work has shown that language models can self-improve by maximizing their own confidence in their predictions, without relying on external verifiers or reward signals. In this work, we study the test-time scaling of language models for mathematical reasoning tasks, where the model's own confidence is used to select the most promising attempts. Surprisingly, we find that we can achieve significant performance gains by continuing only the most promising attempt, selected by the model's prefix-confidence. We systematically evaluate prefix-confidence scaling on five mathematical reasoning datasets: the school-level GSM8K and MATH500, and the competition-level AMC23, AIME24, and AIME25. We find that prefix-confidence scaling with prefixes of only 32 tokens achieves a better accuracy-compute trade-off than majority voting. Moreover, prefix-confidence scaling appears less susceptible than BoN to length biases. Finally, we also evaluate test-time training with prefix-confidence and find that, while outperforming the base model, it does not improve over prefix-confidence scaling.",
      "authors": [
        "Matthias Otth",
        "Jonas H\\\"ubotter",
        "Ido Hakimi",
        "Andreas Krause"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:17:39+00:00",
          "link": "https://arxiv.org/abs/2507.18122v1",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "title": "Maximizing Prefix-Confidence at Test-Time Efficiently Improves Mathematical Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18122",
        "PDF": "https://arxiv.org/pdf/2507.18122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates scaling language models' confidence for mathematical reasoning, which is focused on evaluation and model improvement at test-time, not on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18123",
      "abstract": "The rapid development of COVID-19 vaccines has showcased the global communitys ability to combat infectious diseases. However, the need for post-licensure surveillance systems has grown due to the limited window for safety data collection in clinical trials and early widespread implementation. This study aims to employ Natural Language Processing techniques and Active Learning to rapidly develop a classifier that detects potential vaccine safety issues from emergency department notes. ED triage notes, containing expert, succinct vital patient information at the point of entry to health systems, can significantly contribute to timely vaccine safety signal surveillance. While keyword-based classification can be effective, it may yield false positives and demand extensive keyword modifications. This is exacerbated by the infrequency of vaccination-related ED presentations and their similarity to other reasons for ED visits. NLP offers a more accurate and efficient alternative, albeit requiring annotated data, which is often scarce in the medical field. Active learning optimizes the annotation process and the quality of annotated data, which can result in faster model implementation and improved model performance. This work combines active learning, data augmentation, and active learning and evaluation techniques to create a classifier that is used to enhance vaccine safety surveillance from ED triage notes.",
      "authors": [
        "Sedigh Khademi",
        "Christopher Palmer",
        "Muhammad Javed",
        "Hazel Clothier",
        "Jim Buttery",
        "Gerardo Luis Dimaguila",
        "Jim Black"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:18:34+00:00",
          "link": "https://arxiv.org/abs/2507.18123v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18123",
        "HTML": "https://arxiv.org/html/2507.18123v1",
        "PDF": "https://arxiv.org/pdf/2507.18123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study uses NLP and active learning for vaccine safety signal detection, which involves text classification and annotation, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18130",
      "abstract": "Natural language-driven no-code development allows users to specify software functionality using natural language (NL) instead of editing source code, promising increased productivity and democratized development. Large language models (LLMs) show potential in enabling this paradigm. In this context, software documentation acts as an NL specification for functionality. This work introduces NoCode-bench, a benchmark designed to evaluate LLMs on real-world NL-driven feature addition tasks, consisting of 634 tasks across 10 projects and 114k code changes. Each task pairs documentation updates with corresponding code implementations, validated by developer-written test cases. A subset of 114 high-quality, human-verified instances, NoCode-bench Verified, ensures reliable evaluation. Our experiments reveal that, despite high token usage, the best LLMs achieve a task success rate of only 15.79%, highlighting challenges in cross-file editing, codebase understanding, and tool calling. These findings indicate that LLMs are not yet ready for fully NL-driven no-code development. NoCode-bench lays the foundation for future advances in this area.",
      "authors": [
        "Le Deng",
        "Zhonghao Jiang",
        "Jialun Cao",
        "Michael Pradel and Zhongxin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:38:19+00:00",
          "link": "https://arxiv.org/abs/2507.18130v1",
          "size": "1000kb",
          "version": "v1"
        }
      ],
      "title": "NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18130",
        "HTML": "https://arxiv.org/html/2507.18130v1",
        "PDF": "https://arxiv.org/pdf/2507.18130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces NoCode-bench, a benchmark for evaluating LLMs in natural language-driven development. Although data processing is involved in creating a dataset, the focus is on evaluating LLMs on software tasks, not directly on LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18131",
      "abstract": "Model order reduction simplifies high-dimensional dynamical systems by deriving lower-dimensional models that preserve essential system characteristics. These techniques are crucial to controller design for complex systems while significantly reducing computational costs. Nevertheless, constructing effective reduced-order models (ROMs) poses considerable challenges, particularly for dynamical systems characterized by highly nonlinear terms. These challenges are further exacerbated when the actual system model is unavailable, a scenario frequently encountered in real-world applications. In this work, we propose a data-driven framework for the construction of ROMs for both continuous- and discrete-time nonlinear dynamical systems with unknown mathematical models. By leveraging two sets of data collected from the system, referred to as two input-state trajectories, we first construct a data-based closed-loop representation of the system. We then establish a similarity relation between the output trajectories of the original system and those of its data-driven ROM employing the notion of simulation functions (SFs), thereby enabling a formal characterization of their closeness. To achieve this, we propose data-dependent semidefinite programs as sufficient conditions to simultaneously construct both ROMs and SFs, while offering correctness guarantees. We demonstrate that the obtained data-driven ROMs can be employed for synthesizing controllers that ensure the unknown system satisfies high-level logic properties. This is accomplished by first designing controllers for the data-driven ROMs and then translating the results back to the original system through an interface function. We evaluate the efficacy of our data-driven findings through four benchmark case studies involving unknown dynamics with highly nonlinear terms.",
      "authors": [
        "Behrad Samari",
        "Henrik Sandberg",
        "Karl H. Johansson",
        "Abolfazl Lavaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:45:19+00:00",
          "link": "https://arxiv.org/abs/2507.18131v1",
          "size": "2918kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Model Order Reduction for Continuous- and Discrete-Time Nonlinear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18131",
        "PDF": "https://arxiv.org/pdf/2507.18131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses data-driven model order reduction for nonlinear systems, which involves processing trajectory data. However, it is not related to LLM training data processing, pretraining, or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18135",
      "abstract": "In the medical image analysis field, precise quantification of curve tortuosity plays a critical role in the auxiliary diagnosis and pathological assessment of various diseases. In this study, we propose a novel framework for tortuosity quantification and demonstrate its effectiveness through the evaluation of meibomian gland atrophy uniformity,serving as a representative application scenario.\n  We introduce an information entropy-based tortuosity quantification framework that integrates probability modeling with entropy theory and incorporates domain transformation of curve data. Unlike traditional methods such as curvature or arc-chord ratio, this approach evaluates the tortuosity of a target curve by comparing it to a designated reference curve. Consequently, it is more suitable for tortuosity assessment tasks in medical data where biologically plausible reference curves are available, providing a more robust and objective evaluation metric without relying on idealized straight-line comparisons.\n  First, we conducted numerical simulation experiments to preliminarily assess the stability and validity of the method. Subsequently, the framework was applied to quantify the spatial uniformity of meibomian gland atrophy and to analyze the difference in this uniformity between \\textit{Demodex}-negative and \\textit{Demodex}-positive patient groups. The results demonstrated a significant difference in tortuosity-based uniformity between the two groups, with an area under the curve of 0.8768, sensitivity of 0.75, and specificity of 0.93. These findings highlight the clinical utility of the proposed framework in curve tortuosity analysis and its potential as a generalizable tool for quantitative morphological evaluation in medical diagnostics.",
      "authors": [
        "Kesheng Wang",
        "Xiaoyu Chen",
        "Chunlei He",
        "Fenfen Li",
        "Xinxin Yu",
        "Dexing Kong",
        "Shoujun Huang",
        "Qi Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:51:10+00:00",
          "link": "https://arxiv.org/abs/2507.18135v1",
          "size": "1930kb",
          "version": "v1"
        }
      ],
      "title": "Information Entropy-Based Framework for Quantifying Tortuosity in Meibomian Gland Uneven Atrophy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18135",
        "HTML": "https://arxiv.org/html/2507.18135v1",
        "PDF": "https://arxiv.org/pdf/2507.18135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for quantifying tortuosity in medical images using information entropy. It does not address LLM training data processing or associated operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18138",
      "abstract": "This paper presents a novel approach that combines the advantages of both model-based and learning-based frameworks to achieve robust locomotion. The residual modules are integrated with each corresponding part of the model-based framework, a footstep planner and dynamic model designed using heuristics, to complement performance degradation caused by a model mismatch. By utilizing a modular structure and selecting the appropriate learning-based method for each residual module, our framework demonstrates improved control performance in environments with high uncertainty, while also achieving higher learning efficiency compared to baseline methods. Moreover, we observed that our proposed methodology not only enhances control performance but also provides additional benefits, such as making nominal controllers more robust to parameter tuning. To investigate the feasibility of our framework, we demonstrated residual modules combined with model predictive control in a real quadrupedal robot. Despite uncertainties beyond the simulation, the robot successfully maintains balance and tracks the commanded velocity.",
      "authors": [
        "Min-Gyu Kim",
        "Dongyun Kang",
        "Hajun Kim and Hae-Won Park"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:00:20+00:00",
          "link": "https://arxiv.org/abs/2507.18138v1",
          "size": "2191kb",
          "version": "v1"
        }
      ],
      "title": "A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18138",
        "HTML": "https://arxiv.org/html/2507.18138v1",
        "PDF": "https://arxiv.org/pdf/2507.18138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a modular learning framework for robust locomotion in robotics, focusing on enhancing control techniques. It does not pertain to LLM training data processing in any capacity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18139",
      "abstract": "The growing need for intelligent, adaptive, and energy-efficient autonomous systems across fields such as robotics, mobile agents (e.g., UAVs), and self-driving vehicles is driving interest in neuromorphic computing. By drawing inspiration from biological neural systems, neuromorphic approaches offer promising pathways to enhance the perception, decision-making, and responsiveness of autonomous platforms. This paper surveys recent progress in neuromorphic algorithms, specialized hardware, and cross-layer optimization strategies, with a focus on their deployment in real-world autonomous scenarios. Special attention is given to event-based dynamic vision sensors and their role in enabling fast, efficient perception. The discussion highlights new methods that improve energy efficiency, robustness, adaptability, and reliability through the integration of spiking neural networks into autonomous system architectures. We integrate perspectives from machine learning, robotics, neuroscience, and neuromorphic engineering to offer a comprehensive view of the state of the field. Finally, emerging trends and open challenges are explored, particularly in the areas of real-time decision-making, continual learning, and the development of secure, resilient autonomous systems.",
      "authors": [
        "Alberto Marchisio and Muhammad Shafique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:01:52+00:00",
          "link": "https://arxiv.org/abs/2507.18139v1",
          "size": "1387kb",
          "version": "v1"
        }
      ],
      "title": "Neuromorphic Computing for Embodied Intelligence in Autonomous Systems: Current Trends, Challenges, and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18139",
        "HTML": "https://arxiv.org/html/2507.18139v1",
        "PDF": "https://arxiv.org/pdf/2507.18139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neuromorphic computing for autonomous systems, covering topics like neuromorphic algorithms, hardware, and optimization strategies. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18140",
      "abstract": "Recent progress in Multi-modal Large Language Models (MLLMs) has enabled step-by-step multi-modal mathematical reasoning by performing visual operations based on the textual instructions. A promising approach uses code as an intermediate representation to precisely express and manipulate the images in the reasoning steps. However, existing evaluations focus mainly on text-only reasoning outputs, leaving the MLLM's ability to perform accurate visual operations via code largely unexplored. This work takes a first step toward addressing that gap by evaluating MLLM's code-based capabilities in multi-modal mathematical reasoning.Specifically, our framework focuses on two key evaluation aspects: (1) Multi-modal Code Generation (MCG) evaluates the model's ability to accurately understand and construct visualizations from scratch. (2) Multi-modal Code Editing (MCE) assesses the model's capacity for fine-grained operations, which include three types: Deletion, Modification and Annotation. To evaluate the above tasks, we incorporate a dataset that covers the five most popular types of mathematical figures, including geometric diagrams, function plots, and three types of statistical charts, to provide a comprehensive and effective measurement of existing MLLMs. Our experimental evaluation involves nine mainstream MLLMs, and the results reveal that existing models still lag significantly behind human performance in performing fine-grained visual operations.",
      "authors": [
        "Xiaoyuan Li",
        "Moxin Li",
        "Wenjie Wang",
        "Rui Men",
        "Yichang Zhang",
        "Fuli Feng",
        "Dayiheng Liu",
        "Junyang Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:03:11+00:00",
          "link": "https://arxiv.org/abs/2507.18140v1",
          "size": "1051kb",
          "version": "v1"
        }
      ],
      "title": "MathOPEval: A Fine-grained Evaluation Benchmark for Visual Operations of MLLMs in Mathematical Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18140",
        "HTML": "https://arxiv.org/html/2507.18140v1",
        "PDF": "https://arxiv.org/pdf/2507.18140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces MathOPEval, a benchmark for evaluating mathematical reasoning in multi-modal LLMs, involving datasets of mathematical figures. While it discusses dataset use, the primary focus is model evaluation, not data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18141",
      "abstract": "This work focuses on a compositional data-driven approach to verify incremental global asymptotic stability (delta-GAS) over interconnected homogeneous networks of degree one with unknown mathematical dynamics. Our proposed approach leverages the concept of incremental input-to-state stability (delta-ISS) of subsystems, characterized by delta-ISS Lyapunov functions. To implement our data-driven scheme, we initially reframe the delta-ISS Lyapunov conditions as a robust optimization program (ROP). However, due to the presence of unknown subsystem dynamics in the ROP constraints, we develop a scenario optimization program (SOP) by gathering data from trajectories of each unknown subsystem. We solve the SOP and construct a delta-ISS Lyapunov function for each subsystem with unknown dynamics. We then leverage a small-gain compositional condition to facilitate the construction of an incremental Lyapunov function for an unknown interconnected network with unknown dynamics based on its data-driven delta-ISS Lyapunov functions of individual subsystems, while providing correctness guarantees. We demonstrate that our data-driven compositional approach aligns sample complexity with subsystem granularity, resulting in a linear increase in required data as the number of subsystems rises. In contrast, the existing monolithic approach in the literature exhibits exponential growth in sample complexity with increasing number of subsystems, rendering it impractical for real-world applications. To validate the effectiveness of our compositional data-driven approach, we apply it to an unknown nonlinear homogeneous network of degree one, comprising 10000 subsystems. By gathering data from each unknown subsystem, we demonstrate that the interconnected network is delta-GAS with a correctness guarantee.",
      "authors": [
        "Mahdieh Zaker",
        "David Angeli",
        "Abolfazl Lavaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:03:13+00:00",
          "link": "https://arxiv.org/abs/2507.18141v1",
          "size": "1130kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Incremental GAS Certificate of Nonlinear Homogeneous Networks: A Formal Modular Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18141",
        "PDF": "https://arxiv.org/pdf/2507.18141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a data-driven approach for verifying stability in nonlinear networks, focusing on data-driven methods for control systems and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18143",
      "abstract": "Large language models (LLMs) are emerging as valuable tools to support clinicians in routine decision-making. HIV management is a compelling use case due to its complexity, including diverse treatment options, comorbidities, and adherence challenges. However, integrating LLMs into clinical practice raises concerns about accuracy, potential harm, and clinician acceptance. Despite their promise, AI applications in HIV care remain underexplored, and LLM benchmarking studies are scarce. This study evaluates the current capabilities of LLMs in HIV management, highlighting their strengths and limitations. We introduce HIVMedQA, a benchmark designed to assess open-ended medical question answering in HIV care. The dataset consists of curated, clinically relevant questions developed with input from an infectious disease physician. We evaluated seven general-purpose and three medically specialized LLMs, applying prompt engineering to enhance performance. Our evaluation framework incorporates both lexical similarity and an LLM-as-a-judge approach, extended to better reflect clinical relevance. We assessed performance across key dimensions: question comprehension, reasoning, knowledge recall, bias, potential harm, and factual accuracy. Results show that Gemini 2.5 Pro consistently outperformed other models across most dimensions. Notably, two of the top three models were proprietary. Performance declined as question complexity increased. Medically fine-tuned models did not always outperform general-purpose ones, and larger model size was not a reliable predictor of performance. Reasoning and comprehension were more challenging than factual recall, and cognitive biases such as recency and status quo were observed. These findings underscore the need for targeted development and evaluation to ensure safe, effective LLM integration in clinical care.",
      "authors": [
        "Gonzalo Cardenal Antolin",
        "Jacques Fellay",
        "Bashkim Jaha",
        "Roger Kouyos",
        "Niko Beerenwinkel",
        "Diane Duroux"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:06:30+00:00",
          "link": "https://arxiv.org/abs/2507.18143v1",
          "size": "1938kb",
          "version": "v1"
        }
      ],
      "title": "HIVMedQA: Benchmarking large language models for HIV medical decision support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18143",
        "HTML": "https://arxiv.org/html/2507.18143v1",
        "PDF": "https://arxiv.org/pdf/2507.18143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces HIVMedQA, a benchmarking dataset for assessing large language models in medical decision support. However, it focuses on evaluating LLM performance in clinical settings, not on the processing or generation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18144",
      "abstract": "Low-light image enhancement aims to improve the visibility of degraded images to better align with human visual perception. While diffusion-based methods have shown promising performance due to their strong generative capabilities. However, their unidirectional modelling of degradation often struggles to capture the complexity of real-world degradation patterns, leading to structural inconsistencies and pixel misalignments. To address these challenges, we propose a bidirectional diffusion optimization mechanism that jointly models the degradation processes of both low-light and normal-light images, enabling more precise degradation parameter matching and enhancing generation quality. Specifically, we perform bidirectional diffusion-from low-to-normal light and from normal-to-low light during training and introduce an adaptive feature interaction block (AFI) to refine feature representation. By leveraging the complementarity between these two paths, our approach imposes an implicit symmetry constraint on illumination attenuation and noise distribution, facilitating consistent degradation learning and improving the models ability to perceive illumination and detail degradation. Additionally, we design a reflection-aware correction module (RACM) to guide color restoration post-denoising and suppress overexposed regions, ensuring content consistency and generating high-quality images that align with human visual perception. Extensive experiments on multiple benchmark datasets demonstrate that our method outperforms state-of-the-art methods in both quantitative and qualitative evaluations while generalizing effectively to diverse degradation scenarios. Code at https://github.com/hejh8/BidDiff",
      "authors": [
        "Jinhong He",
        "Minglong Xue",
        "Zhipu Liu",
        "Mingliang Zhou",
        "Aoxiang Ning",
        "Palaiahnakote Shivakumara"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:21:23+00:00",
          "link": "https://arxiv.org/abs/2507.18144v1",
          "size": "7344kb",
          "version": "v1"
        }
      ],
      "title": "Degradation-Consistent Learning via Bidirectional Diffusion for Low-Light Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18144",
        "HTML": "https://arxiv.org/html/2507.18144v1",
        "PDF": "https://arxiv.org/pdf/2507.18144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with low-light image enhancement using bidirectional diffusion techniques, focusing on image processing and enhancement rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18145",
      "abstract": "We study the expressive power of graph neural networks (GNNs) with mean as the aggregation function. In the non-uniform setting, we show that such GNNs have exactly the same expressive power as ratio modal logic, which has modal operators expressing that at least a certain ratio of the successors of a vertex satisfies a specified property. The non-uniform expressive power of mean GNNs is thus higher than that of GNNs with max aggregation, but lower than for sum aggregation--the latter are characterized by modal logic and graded modal logic, respectively. In the uniform setting, we show that the expressive power relative to MSO is exactly that of alternation-free modal logic, under the natural assumptions that combination functions are continuous and classification functions are thresholds. This implies that, relative to MSO and in the uniform setting, mean GNNs are strictly less expressive than sum GNNs and max GNNs. When any of the assumptions is dropped, the expressive power increases.",
      "authors": [
        "Moritz Sch\\\"onherr and Carsten Lutz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:21:49+00:00",
          "link": "https://arxiv.org/abs/2507.18145v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Logical Characterizations of GNNs with Mean Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18145",
        "HTML": "https://arxiv.org/html/2507.18145v1",
        "PDF": "https://arxiv.org/pdf/2507.18145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the expressive power of graph neural networks (GNNs) with mean aggregation and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18150",
      "abstract": "Nuclear reactors are often modeled as inflexible, baseload generators with fixed downtimes and restrictive ramping limits. In practice, however, a reactor's operational flexibility is closely tied to it's fuel cycle stage and the associated reactivity margin. A key physical constraint to power maneuverability is xenon poisoning, caused by an increase in neutron absorbing xenon concentration following a power ramp down. This can delay or even prevent subsequent power ramp up due to suppressed core reactivity. Additionally, if a reactor is shutdown during periods of low reactivity, restart times can vary significantly due to these xenon transients, leading to longer downtimes. This work introduces a physics informed, metaheuristic modeling approach that embeds fuel cycle dynamics directly with a unit commitment (UC) framework. The framework tracks reactivity margin, dynamically activates xenon related constraints, and endogenously implements refueling outages based on the core conditions. By capturing intra-cycle reactivity evolution and the conditional onset of xenon poisoning, the formulation allows for operation dependent nuclear dispatch that reflects both regulatory limits and physical behavior. When applied to a representative reactor fleet operating in distinct modes of operation -- ranging from baseload to part load -- the framework reveals that flexible operation can slow reactivity degradation and extend fuel cycles. The results show that fuel cycle aware flexibility modeling is critical for accurate scheduling of nuclear reactors and offers a tractable pathway to integrate nuclear power in energy system models.",
      "authors": [
        "Shiny Choudhury",
        "Michael Davidson",
        "George Tynan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:32:38+00:00",
          "link": "https://arxiv.org/abs/2507.18150v1",
          "size": "3773kb",
          "version": "v1"
        }
      ],
      "title": "Unit Commitment Framework for Nuclear Reactors with Reactivity Decline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18150",
        "HTML": "https://arxiv.org/html/2507.18150v1",
        "PDF": "https://arxiv.org/pdf/2507.18150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a unit commitment framework for nuclear reactors, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18151",
      "abstract": "Adults with Attention Deficit Hyperactivity Disorder (ADHD) often experience communication challenges, primarily due to executive dysfunction and emotional dysregulation, even after years of social integration. While existing interventions predominantly target children through structured or intrusive methods, adults lack tools that translate clinical strategies into daily communication support. To address this gap, we present Understood, a Mixed Reality (MR) system implemented on Microsoft HoloLens 2, designed to assist adults with ADHD in real-world communication. Through formative semi-structured interviews and a design workshop, we identified critical communication barriers and derived design goals for the system. Understood combines three key features: (1) real-time conversation summarization to reduce cognitive load, (2) context-aware subsequent word suggestions during moments of disfluency, and (3) topic shifting detection and reminding to mitigate off-topic transitions. A within-subjects user study and expert interviews demonstrate that Understood effectively supports communication with high usability, offering a complement to therapist-mediated interventions.",
      "authors": [
        "Shizhen Zhang",
        "Shengxin Li",
        "Quan Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:33:59+00:00",
          "link": "https://arxiv.org/abs/2507.18151v1",
          "size": "23291kb",
          "version": "v1"
        }
      ],
      "title": "Understood: Real-Time Communication Support for Adults with ADHD Using Mixed Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18151",
        "HTML": "https://arxiv.org/html/2507.18151v1",
        "PDF": "https://arxiv.org/pdf/2507.18151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a Mixed Reality system to assist adults with ADHD in communication. It does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18153",
      "abstract": "Class-imbalanced graph node classification is a practical yet underexplored research problem. Although recent studies have attempted to address this issue, they typically assume clean and reliable labels when processing class-imbalanced graphs. This assumption often violates the nature of real-world graphs, where labels frequently contain noise. Given this gap, this paper systematically investigates robust node classification for class-imbalanced graphs with noisy labels. We propose GraphALP, a novel Graph Augmentation framework based on Large language models (LLMs) and Pseudo-labeling techniques. Specifically, we design an LLM-based oversampling method to generate synthetic minority nodes, producing label-accurate minority nodes to alleviate class imbalance. Based on the class-balanced graphs, we develop a dynamically weighted pseudo-labeling method to obtain high-confidence pseudo labels to reduce label noise ratio. Additionally, we implement a secondary LLM-guided oversampling mechanism to mitigate potential class distribution skew caused by pseudo labels. Experimental results show that GraphALP achieves superior performance over state-of-the-art methods on class-imbalanced graphs with noisy labels.",
      "authors": [
        "Riting Xia",
        "Rucong Wang",
        "Yulin Liu",
        "Anchen Li",
        "Xueyan Liu",
        "Yan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.18153v1",
          "size": "1903kb",
          "version": "v1"
        }
      ],
      "title": "When Noisy Labels Meet Class Imbalance on Graphs: A Graph Augmentation Method with LLM and Pseudo Label",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18153",
        "PDF": "https://arxiv.org/pdf/2507.18153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a graph augmentation framework using LLMs and pseudo-labeling for node classification, involving data generation (synthetic nodes). However, its main focus is on graph-based node classification, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18155",
      "abstract": "Despite recent progress in 3D head avatar generation, balancing identity preservation, i.e., reconstruction, with novel poses and expressions, i.e., animation, remains a challenge. Existing methods struggle to adapt Gaussians to varying geometrical deviations across facial regions, resulting in suboptimal quality. To address this, we propose GeoAvatar, a framework for adaptive geometrical Gaussian Splatting. GeoAvatar leverages Adaptive Pre-allocation Stage (APS), an unsupervised method that segments Gaussians into rigid and flexible sets for adaptive offset regularization. Then, based on mouth anatomy and dynamics, we introduce a novel mouth structure and the part-wise deformation strategy to enhance the animation fidelity of the mouth. Finally, we propose a regularization loss for precise rigging between Gaussians and 3DMM faces. Moreover, we release DynamicFace, a video dataset with highly expressive facial motions. Extensive experiments show the superiority of GeoAvatar compared to state-of-the-art methods in reconstruction and novel animation scenarios.",
      "authors": [
        "SeungJun Moon",
        "Hah Min Lew",
        "Seungeun Lee",
        "Ji-Su Kang",
        "Gyeong-Moon Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:41:40+00:00",
          "link": "https://arxiv.org/abs/2507.18155v1",
          "size": "15860kb",
          "version": "v1"
        }
      ],
      "title": "GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18155",
        "HTML": "https://arxiv.org/html/2507.18155v1",
        "PDF": "https://arxiv.org/pdf/2507.18155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a 3D head avatar generation framework and a related video dataset, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18157",
      "abstract": "Due to the merits of high efficiency and strong security against timing and side-channel attacks, ChaCha has been widely applied in real-time communication and data streaming scenarios. However, with the rapid development of AI-assisted cryptanalysis and quantum computing technologies, there are serious challenges to the secure implementation of ChaCha cipher. To further strengthen the security of ChaCha cipher, we propose an improved variant based on quantum random numbers, i.e., Quantum Random Number Enhanced ChaCha (QRE-ChaCha). Specifically, the design XORs the initial constants with quantum random numbers and periodically injects quantum random numbers into selected state words during odd rounds to enhance diffusion. Compared with the original ChaCha, the present variant shows stronger resistance to differential attacks and generates a keystream with statistical randomness, thereby offering increased robustness against both classical and quantum attacks. To evaluate the security and performance of the present ChaCha, our analysis proceeds in three main parts. Firstly, we analyze its theoretical security in terms of quantum randomness and attack testing, and conduct differential cryptanalysis with an automated search method based on the Boolean satisfiability problem (SAT). Secondly, we subject the keystream generated by the cipher to randomness tests using the NIST statistical test suite and the GM/T 0005-2021 randomness testing standard. Finally, we assess its encryption and decryption performance by measuring its encryption speed on files of various sizes. According to the results, the present ChaCha is significantly improved to resist differential attacks while maintaining the high efficiency of the original ChaCha cipher, and its keystream successfully passes statistical randomness tests using the NIST and GM/T 0005-2021 standards, meeting cryptographic application requirements.",
      "authors": [
        "Chao Liu",
        "Shuai Zhao",
        "Chenhao Jia",
        "Gengran Hu and Tingting Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:50:17+00:00",
          "link": "https://arxiv.org/abs/2507.18157v1",
          "size": "236kb",
          "version": "v1"
        }
      ],
      "title": "An Improved ChaCha Algorithm Based on Quantum Random Number",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18157",
        "HTML": "https://arxiv.org/html/2507.18157v1",
        "PDF": "https://arxiv.org/pdf/2507.18157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving the ChaCha algorithm using quantum random numbers, which is related to cryptography, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18158",
      "abstract": "We consider the problem of designing learning-based reactive power controllers that perform voltage regulation in distribution grids while ensuring closed-loop system stability. In contrast to existing methods, where the provably stable controllers are restricted to be decentralized, we propose a unified design framework that enables the controllers to take advantage of an arbitrary communication infrastructure on top of the physical power network. This allows the controllers to incorporate information beyond their local bus, covering existing methods as a special case and leading to less conservative constraints on the controller design. We then provide a design procedure to construct input convex neural network (ICNN) based controllers that satisfy the identified stability constraints by design under arbitrary communication scenarios, and train these controllers using supervised learning. Simulation results on the the University of California, San Diego (UCSD) microgrid testbed illustrate the effectiveness of the framework and highlight the role of communication in improving control performance.",
      "authors": [
        "Zhenyi Yuan",
        "Jie Feng",
        "Yuanyuan Shi",
        "Jorge Cort\\'es"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:53:37+00:00",
          "link": "https://arxiv.org/abs/2507.18158v1",
          "size": "3261kb",
          "version": "v1"
        }
      ],
      "title": "Stability Constrained Voltage Control in Distribution Grids with Arbitrary Communication Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18158",
        "HTML": "https://arxiv.org/html/2507.18158v1",
        "PDF": "https://arxiv.org/pdf/2507.18158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about reactive power control in distribution grids using learning-based controllers, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18159",
      "abstract": "Metadata play a crucial role in adopting the FAIR principles for research software and enables findability and reusability. However, creating high-quality metadata can be resource-intensive for researchers and research software engineers. To address this challenge, we developed the Software Metadata Extraction and Curation Software (SMECS) which integrates the extraction of metadata from existing sources together with a user-friendly interface for metadata curation. SMECS extracts metadata from online repositories such as GitHub and presents it to researchers through an interactive interface for further curation and export as a CodeMeta file. The usability of SMECS was evaluated through usability experiments which confirmed that SMECS provides a satisfactory user experience. SMECS supports the FAIRification of research software by simplifying metadata creation.",
      "authors": [
        "Stephan Ferenz",
        "Aida Jafarbigloo",
        "Oliver Werth",
        "Astrid Nie{\\ss}e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:53:46+00:00",
          "link": "https://arxiv.org/abs/2507.18159v1",
          "size": "237kb",
          "version": "v1"
        }
      ],
      "title": "SMECS: A Software Metadata Extraction and Curation Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18159",
        "HTML": "https://arxiv.org/html/2507.18159v1",
        "PDF": "https://arxiv.org/pdf/2507.18159"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While this paper discusses the extraction and curation of metadata, it does not relate to LLM training data processing, but rather to software metadata management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18160",
      "abstract": "In this paper, we present a subsystem, using Unmanned Aerial Vehicles (UAV), for search and rescue missions, focusing on people detection, face recognition and tracking of identified individuals. The proposed solution integrates a UAV with ROS2 framework, that utilizes multiple convolutional neural networks (CNN) for search missions. System identification and PD controller deployment are performed for autonomous UAV navigation. The ROS2 environment utilizes the YOLOv11 and YOLOv11-pose CNNs for tracking purposes, and the dlib library CNN for face recognition. The system detects a specific individual, performs face recognition and starts tracking. If the individual is not yet known, the UAV operator can manually locate the person, save their facial image and immediately initiate the tracking process. The tracking process relies on specific keypoints identified on the human body using the YOLOv11-pose CNN model. These keypoints are used to track a specific individual and maintain a safe distance. To enhance accurate tracking, system identification is performed, based on measurement data from the UAVs IMU. The identified system parameters are used to design PD controllers that utilize YOLOv11-pose to estimate the distance between the UAVs camera and the identified individual. The initial experiments, conducted on 14 known individuals, demonstrated that the proposed subsystem can be successfully used in real time. The next step involves implementing the system on a large experimental UAV for field use and integrating autonomous navigation with GPS-guided control for rescue operations planning.",
      "authors": [
        "Luka \\v{S}iktar",
        "Branimir \\'Caran",
        "Bojan \\v{S}ekoranja and Marko \\v{S}vaco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:54:45+00:00",
          "link": "https://arxiv.org/abs/2507.18160v1",
          "size": "530kb",
          "version": "v1"
        }
      ],
      "title": "Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18160",
        "PDF": "https://arxiv.org/pdf/2507.18160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with autonomous UAV navigation using computer vision and CNNs for search and rescue missions, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18165",
      "abstract": "Visual analytics (VA) is typically applied to complex data, thus requiring complex tools. While visual analytics empowers analysts in data analysis, analysts may get lost in the complexity occasionally. This highlights the need for intelligent assistance mechanisms. However, even the latest LLM-assisted VA systems only provide help when explicitly requested by the user, making them insufficiently intelligent to offer suggestions when analysts need them the most. We propose a ProactiveVA framework in which LLM-powered UI agent monitors user interactions and delivers context-aware assistance proactively. To design effective proactive assistance, we first conducted a formative study analyzing help-seeking behaviors in user interaction logs, identifying when users need proactive help, what assistance they require, and how the agent should intervene. Based on this analysis, we distilled key design requirements in terms of intent recognition, solution generation, interpretability and controllability. Guided by these requirements, we develop a three-stage UI agent pipeline including perception, reasoning, and acting. The agent autonomously perceives users' needs from VA interaction logs, providing tailored suggestions and intuitive guidance through interactive exploration of the system. We implemented the framework in two representative types of VA systems, demonstrating its generalizability, and evaluated the effectiveness through an algorithm evaluation, case and expert study and a user study. We also discuss current design trade-offs of proactive VA and areas for further exploration.",
      "authors": [
        "Yuheng Zhao",
        "Xueli Shu",
        "Liwen Fan",
        "Lin Gao",
        "Yu Zhang",
        "Siming Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:02:35+00:00",
          "link": "https://arxiv.org/abs/2507.18165v1",
          "size": "8779kb",
          "version": "v1"
        }
      ],
      "title": "ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18165",
        "HTML": "https://arxiv.org/html/2507.18165v1",
        "PDF": "https://arxiv.org/pdf/2507.18165"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a UI agent for visual analytics that provides proactive assistance using LLMs, but it does not deal with LLM training data processing, such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18169",
      "abstract": "Recommender systems shape music listening worldwide due to their widespread adoption in online platforms. Growing concerns about representational harms that these systems may cause are nowadays part of the scientific and public debate, wherein music listener perspectives are oftentimes reported and discussed from a cognitive-behaviorism perspective, but rarely contextualised under a psychosocial and cultural lens. We proceed in this direction, by interviewing a group of Italian music listeners and analysing their narratives through Emotional Textual Analysis. Thanks to this, we identify shared cultural repertoires that reveal people's complex relationship with listening practices: even when familiar with online platforms, listeners may still lack a critical understanding of recommender systems. Moreover, representational issues, particularly gender disparities, seem not yet fully grasped in the context of online music listening. This study underscores the need for interdisciplinary research to address representational harms, and the role of algorithmic awareness and digital literacy in developing trustworthy recommender systems.",
      "authors": [
        "Lorenzo Porcaro and Chiara Monaldi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:10:29+00:00",
          "link": "https://arxiv.org/abs/2507.18169v1",
          "size": "130kb",
          "version": "v1"
        }
      ],
      "title": "Recommender systems, representativeness, and online music: A psychosocial analysis of Italian listeners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18169",
        "HTML": "https://arxiv.org/html/2507.18169v1",
        "PDF": "https://arxiv.org/pdf/2507.18169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While this paper discusses representational harms in recommender systems, it is centered around a psychosocial analysis and not involved in LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18171",
      "abstract": "Despite the widespread use of Transformer-based text embedding models in NLP tasks, surprising 'sticky tokens' can undermine the reliability of embeddings. These tokens, when repeatedly inserted into sentences, pull sentence similarity toward a certain value, disrupting the normal distribution of embedding distances and degrading downstream performance. In this paper, we systematically investigate such anomalous tokens, formally defining them and introducing an efficient detection method, Sticky Token Detector (STD), based on sentence and token filtering. Applying STD to 40 checkpoints across 14 model families, we discover a total of 868 sticky tokens. Our analysis reveals that these tokens often originate from special or unused entries in the vocabulary, as well as fragmented subwords from multilingual corpora. Notably, their presence does not strictly correlate with model size or vocabulary size. We further evaluate how sticky tokens affect downstream tasks like clustering and retrieval, observing significant performance drops of up to 50%. Through attention-layer analysis, we show that sticky tokens disproportionately dominate the model's internal representations, raising concerns about tokenization robustness. Our findings show the need for better tokenization strategies and model design to mitigate the impact of sticky tokens in future text embedding applications.",
      "authors": [
        "Kexin Chen",
        "Dongxia Wang",
        "Yi Liu",
        "Haonan Zhang",
        "Wenhai Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:13:16+00:00",
          "link": "https://arxiv.org/abs/2507.18171v1",
          "size": "5348kb",
          "version": "v1"
        }
      ],
      "title": "Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18171",
        "PDF": "https://arxiv.org/pdf/2507.18171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper identifies 'sticky tokens' in text embeddings and suggests improvements in tokenization strategies but does not focus primarily on LLM training data processing such as dataset collection or generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18173",
      "abstract": "Leveraging the complementary characteristics of visible (RGB) and infrared (IR) imagery offers significant potential for improving object detection. In this paper, we propose WaveMamba, a cross-modality fusion method that efficiently integrates the unique and complementary frequency features of RGB and IR decomposed by Discrete Wavelet Transform (DWT). An improved detection head incorporating the Inverse Discrete Wavelet Transform (IDWT) is also proposed to reduce information loss and produce the final detection results. The core of our approach is the introduction of WaveMamba Fusion Block (WMFB), which facilitates comprehensive fusion across low-/high-frequency sub-bands. Within WMFB, the Low-frequency Mamba Fusion Block (LMFB), built upon the Mamba framework, first performs initial low-frequency feature fusion with channel swapping, followed by deep fusion with an advanced gated attention mechanism for enhanced integration. High-frequency features are enhanced using a strategy that applies an ``absolute maximum\" fusion approach. These advancements lead to significant performance gains, with our method surpassing state-of-the-art approaches and achieving average mAP improvements of 4.5% on four benchmarks.",
      "authors": [
        "Haodong Zhu",
        "Wenhao Dong",
        "Linlin Yang",
        "Hong Li",
        "Yuguang Yang",
        "Yangyang Ren",
        "Qingcheng Zhu",
        "Zichao Feng",
        "Changbai Li",
        "Shaohui Lin",
        "Runqi Wang",
        "Xiaoyan Luo",
        "Baochang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:16:15+00:00",
          "link": "https://arxiv.org/abs/2507.18173v1",
          "size": "18440kb",
          "version": "v1"
        }
      ],
      "title": "WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18173",
        "HTML": "https://arxiv.org/html/2507.18173v1",
        "PDF": "https://arxiv.org/pdf/2507.18173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a method for RGB-Infrared object detection through wavelet-driven fusion techniques, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18174",
      "abstract": "Object detection and classification are crucial tasks across various application domains, particularly in the development of safe and reliable Advanced Driver Assistance Systems (ADAS). Existing deep learning-based methods such as Convolutional Neural Networks (CNNs), Single Shot Detectors (SSDs), and You Only Look Once (YOLO) have demonstrated high performance in terms of accuracy and computational speed when deployed on Field-Programmable Gate Arrays (FPGAs). However, despite these advances, state-of-the-art YOLO-based object detection and classification systems continue to face challenges in achieving resource efficiency suitable for edge FPGA platforms. To address this limitation, this paper presents a resource-efficient real-time object detection and classification system based on YOLOv5 optimized for FPGA deployment. The proposed system is trained on the COCO and GTSRD datasets and implemented on the Xilinx Kria KV260 FPGA board. Experimental results demonstrate a classification accuracy of 99%, with a power consumption of 3.5W and a processing speed of 9 frames per second (FPS). These findings highlight the effectiveness of the proposed approach in enabling real-time, resource-efficient object detection and classification for edge computing applications.",
      "authors": [
        "Rashed Al Amin",
        "Roman Obermaisser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:17:37+00:00",
          "link": "https://arxiv.org/abs/2507.18174v1",
          "size": "976kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Object Detection and Classification using YOLO for Edge FPGAs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18174",
        "PDF": "https://arxiv.org/pdf/2507.18174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on real-time object detection and classification using YOLO for edge FPGAs, which is not related to LLM training data processing. It involves model deployment and optimization on hardware, rather than data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18176",
      "abstract": "Addressing performance degradation in 3D LiDAR semantic segmentation due to domain shifts (e.g., sensor type, geographical location) is crucial for autonomous systems, yet manual annotation of target data is prohibitive. This study addresses the challenge using Unsupervised Domain Adaptation (UDA) and introduces a novel two-stage framework to tackle it. Initially, unsupervised contrastive learning at the segment level is used to pre-train a backbone network, enabling it to learn robust, domain-invariant features without labels. Subsequently, a multi-model pseudo-labeling strategy is introduced, utilizing an ensemble of diverse state-of-the-art architectures (including projection, voxel, hybrid, and cylinder-based methods). Predictions from these models are aggregated via hard voting to generate high-quality, refined pseudo-labels for the unlabeled target domain, mitigating single-model biases. The contrastively pre-trained network is then fine-tuned using these robust pseudo-labels. Experiments adapting from SemanticKITTI to unlabeled target datasets (SemanticPOSS, SemanticSlamantic) demonstrate significant improvements in segmentation accuracy compared to direct transfer and single-model UDA approaches. These results highlight the effectiveness of combining contrastive pre-training with refined ensemble pseudo-labeling for bridging complex domain gaps without requiring target domain annotations.",
      "authors": [
        "Abhishek Kaushik",
        "Norbert Haala",
        "Uwe Soergel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:21:43+00:00",
          "link": "https://arxiv.org/abs/2507.18176v1",
          "size": "548kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18176",
        "PDF": "https://arxiv.org/pdf/2507.18176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses unsupervised domain adaptation for 3D LiDAR semantic segmentation using contrastive learning and pseudo-labeling, unrelated to LLM training data processing. It focuses on domain adaptation techniques for a specific task rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18177",
      "abstract": "In data-scarce scenarios, deep learning models often overfit to noise and irrelevant patterns, which limits their ability to generalize to unseen samples. To address these challenges in medical image segmentation, we introduce Diff-UMamba, a novel architecture that combines the UNet framework with the mamba mechanism for modeling long-range dependencies. At the heart of Diff-UMamba is a Noise Reduction Module (NRM), which employs a signal differencing strategy to suppress noisy or irrelevant activations within the encoder. This encourages the model to filter out spurious features and enhance task-relevant representations, thereby improving its focus on clinically meaningful regions. As a result, the architecture achieves improved segmentation accuracy and robustness, particularly in low-data settings. Diff-UMamba is evaluated on multiple public datasets, including MSD (lung and pancreas) and AIIB23, demonstrating consistent performance gains of 1-3% over baseline methods across diverse segmentation tasks. To further assess performance under limited-data conditions, additional experiments are conducted on the BraTS-21 dataset by varying the proportion of available training samples. The approach is also validated on a small internal non-small cell lung cancer (NSCLC) dataset for gross tumor volume (GTV) segmentation in cone beam CT (CBCT), where it achieves a 4-5% improvement over the baseline.",
      "authors": [
        "Dhruv Jain",
        "Romain Modzelewski",
        "Romain H\\'erault",
        "Clement Chatelain",
        "Eva Torfeh",
        "Sebastien Thureau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:23:11+00:00",
          "link": "https://arxiv.org/abs/2507.18177v1",
          "size": "17256kb",
          "version": "v1"
        }
      ],
      "title": "Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18177",
        "HTML": "https://arxiv.org/html/2507.18177v1",
        "PDF": "https://arxiv.org/pdf/2507.18177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a novel architecture for tumor segmentation under limited data conditions, emphasizing model architecture and noise reduction techniques. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18178",
      "abstract": "While large language models (LLMs) leverage both knowledge and reasoning during inference, the capacity to distinguish between them plays a pivotal role in model analysis, interpretability, and development. Inspired by dual-system cognitive theory, we propose a cognition attribution framework to decouple the contribution of knowledge and reasoning. In particular, the cognition of LLMs is decomposed into two distinct yet complementary phases: knowledge retrieval (Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs are prompted to generate answers under two different cognitive modes, fast thinking and slow thinking, respectively. The performance under different cognitive modes is analyzed to quantify the contribution of knowledge and reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results reveal: (1) reasoning adjustment is domain-specific, benefiting reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and potentially imparing knowledge-intensive domains. (2) Parameter scaling improves both knowledge and reasoning, with knowledge improvements being more pronounced. Additionally, parameter scaling make LLMs reasoning significantly more prudent, while moderately more intelligent. (3) Knowledge primarily resides in lower network layers, while reasoning operates in higher layers. Our framework not only helps understand LLMs from a \"decoupling\" perspective, but also provides new insights into existing research, including scaling laws, hierarchical knowledge editing, and limitations of small-model reasoning.",
      "authors": [
        "Mutian Yang",
        "Jiandong Gao",
        "and Ji Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:24:52+00:00",
          "link": "https://arxiv.org/abs/2507.18178v1",
          "size": "3293kb",
          "version": "v1"
        }
      ],
      "title": "Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18178",
        "HTML": "https://arxiv.org/html/2507.18178v1",
        "PDF": "https://arxiv.org/pdf/2507.18178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the decoupling of knowledge and reasoning in LLMs using cognitive dual-system theory, with a focus on model analysis and interpretability. It does not address training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18179",
      "abstract": "This work presents a method to maximize power-efficiency of fixed point multiplier units by decomposing them into sub-components. First, an encoder block converts the operands from a two's complement to a sign magnitude representation, followed by a multiplier module which performs the compute operation and outputs the resulting value in the original format. This allows to leverage the power-efficiency of the Sign Magnitude encoding for the multiplication. To ensure the computing format is not altered, those two components are synthesized and optimized separately. Our method leads to significant power savings for input values centered around zero, as commonly encountered in AI workloads. Under a realistic input stream with values normally distributed with a standard deviation of 3.0, post-synthesis simulations of the 4-bit multiplier design show up to 12.9% lower switching activity compared to synthesis without decomposition. Those gains are achieved while ensuring compliance into any production-ready system as the overall circuit stays logic-equivalent. With the compliance lifted and a slightly smaller input range of -7 to +7, switching activity reductions can reach up to 33%. Additionally, we demonstrate that synthesis optimization methods based on switching-activity-driven design space exploration can yield a further 5-10% improvement in power-efficiency compared to a power agnostic approach.",
      "authors": [
        "Felix Arnold",
        "Maxence Bouvier",
        "Ryan Amaudruz",
        "Renzo Andri",
        "Lukas Cavigelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Hardware Architecture (cs.AR)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:26:33+00:00",
          "link": "https://arxiv.org/abs/2507.18179v1",
          "size": "611kb",
          "version": "v1"
        }
      ],
      "title": "Explicit Sign-Magnitude Encoders Enable Power-Efficient Multipliers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18179",
        "HTML": "https://arxiv.org/html/2507.18179v1",
        "PDF": "https://arxiv.org/pdf/2507.18179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a method for enhancing power efficiency in fixed-point multipliers, focusing on hardware optimization. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18182",
      "abstract": "Large Language Models (LLMs) can achieve inflated scores on multiple-choice tasks by exploiting inherent biases in option positions or labels, rather than demonstrating genuine understanding. This study introduces SCOPE, an evaluation framework designed to measure and mitigate such selection bias in a dataset-independent manner. By repeatedly invoking a null prompt that lacks semantic content, SCOPE estimates each model's unique position-bias distribution. It then redistributes the answer slot according to the inverse-bias distribution, thereby equalizing the lucky-rate, the probability of selecting the correct answer by chance. Furthermore, it prevents semantically similar distractors from being placed adjacent to the answer, thereby blocking near-miss guesses based on superficial proximity cues. Across multiple benchmark experiments, SCOPE consistently outperformed existing debiasing methods in terms of stable performance improvements and showed clearer confidence distributions over correct options. This framework thus offers a new standard for enhancing the fairness and reliability of LLM evaluations.",
      "authors": [
        "Wonjun Jeong",
        "Dongseok Kim",
        "Taegkeun Whangbo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:28:17+00:00",
          "link": "https://arxiv.org/abs/2507.18182v1",
          "size": "329kb",
          "version": "v1"
        }
      ],
      "title": "SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18182",
        "HTML": "https://arxiv.org/html/2507.18182v1",
        "PDF": "https://arxiv.org/pdf/2507.18182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an evaluation method (SCOPE) aimed at addressing biases in LLM evaluation, but it doesn't address data processing aspects pertinent to LLM training or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18183",
      "abstract": "Training deep neural networks on real-world datasets is often hampered by the presence of noisy labels, which can be memorized by over-parameterized models, leading to significant degradation in generalization performance. While existing methods for learning with noisy labels (LNL) have made considerable progress, they fundamentally suffer from static snapshot evaluations and fail to leverage the rich temporal dynamics of learning evolution. In this paper, we propose ChronoSelect (chrono denoting its temporal nature), a novel framework featuring an innovative four-stage memory architecture that compresses prediction history into compact temporal distributions. Our unique sliding update mechanism with controlled decay maintains only four dynamic memory units per sample, progressively emphasizing recent patterns while retaining essential historical knowledge. This enables precise three-way sample partitioning into clean, boundary, and noisy subsets through temporal trajectory analysis and dual-branch consistency. Theoretical guarantees prove the mechanism's convergence and stability under noisy conditions. Extensive experiments demonstrate ChronoSelect's state-of-the-art performance across synthetic and real-world benchmarks.",
      "authors": [
        "Jianchao Wang",
        "Qingfeng Li",
        "Pengcheng Zheng",
        "Xiaorong Pu",
        "Yazhou Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:29:21+00:00",
          "link": "https://arxiv.org/abs/2507.18183v1",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "title": "ChronoSelect: Robust Learning with Noisy Labels via Dynamics Temporal Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18183",
        "HTML": "https://arxiv.org/html/2507.18183v1",
        "PDF": "https://arxiv.org/pdf/2507.18183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework (ChronoSelect) for mitigating noisy labels in deep learning model training, focusing primarily on training dynamics and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18184",
      "abstract": "MatSSL is a streamlined self-supervised learning (SSL) architecture that employs Gated Feature Fusion at each stage of the backbone to integrate multi-level representations effectively. Current micrograph analysis of metallic materials relies on supervised methods, which require retraining for each new dataset and often perform inconsistently with only a few labeled samples. While SSL offers a promising alternative by leveraging unlabeled data, most existing methods still depend on large-scale datasets to be effective. MatSSL is designed to overcome this limitation. We first perform self-supervised pretraining on a small-scale, unlabeled dataset and then fine-tune the model on multiple benchmark datasets. The resulting segmentation models achieve 69.13% mIoU on MetalDAM, outperforming the 66.73% achieved by an ImageNet-pretrained encoder, and delivers consistently up to nearly 40% improvement in average mIoU on the Environmental Barrier Coating benchmark dataset (EBC) compared to models pretrained with MicroNet. This suggests that MatSSL enables effective adaptation to the metallographic domain using only a small amount of unlabeled data, while preserving the rich and transferable features learned from large-scale pretraining on natural images.",
      "authors": [
        "Hoang Hai Nam Nguyen",
        "Phan Nguyen Duc Hieu",
        "and Ho Won Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:32:41+00:00",
          "link": "https://arxiv.org/abs/2507.18184v1",
          "size": "2908kb",
          "version": "v1"
        }
      ],
      "title": "MatSSL: Robust Self-Supervised Representation Learning for Metallographic Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18184",
        "HTML": "https://arxiv.org/html/2507.18184v1",
        "PDF": "https://arxiv.org/pdf/2507.18184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a self-supervised learning architecture for image segmentation within the metallographic domain. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18190",
      "abstract": "Root Cause Analysis (RCA) in telecommunication networks is a critical task, yet it presents a formidable challenge for Artificial Intelligence (AI) due to its complex, graph-based reasoning requirements and the scarcity of realistic benchmarks.",
      "authors": [
        "Keyu Wu and Qianjin Yu and Manlin Mei and Ruiting Liu and Jun Wang and Kailai Zhang and Yelun Bao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:40:08+00:00",
          "link": "https://arxiv.org/abs/2507.18190v1",
          "size": "1532kb",
          "version": "v1"
        }
      ],
      "title": "TN-AutoRCA: Benchmark Construction and Agentic Framework for Self-Improving Alarm-Based Root Cause Analysis in Telecommunication Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18190",
        "HTML": "https://arxiv.org/html/2507.18190v1",
        "PDF": "https://arxiv.org/pdf/2507.18190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses root cause analysis in telecommunication networks, building frameworks for this purpose, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18192",
      "abstract": "Recent advances in text-to-image synthesis largely benefit from sophisticated sampling strategies and classifier-free guidance (CFG) to ensure high-quality generation. However, CFG's reliance on two forward passes, especially when combined with intricate sampling algorithms, results in prohibitively high inference costs. To address this, we introduce TeEFusion (\\textbf{Te}xt \\textbf{E}mbeddings \\textbf{Fusion}), a novel and efficient distillation method that directly incorporates the guidance magnitude into the text embeddings and distills the teacher model's complex sampling strategy. By simply fusing conditional and unconditional text embeddings using linear operations, TeEFusion reconstructs the desired guidance without adding extra parameters, simultaneously enabling the student model to learn from the teacher's output produced via its sophisticated sampling approach. Extensive experiments on state-of-the-art models such as SD3 demonstrate that our method allows the student to closely mimic the teacher's performance with a far simpler and more efficient sampling strategy. Consequently, the student model achieves inference speeds up to 6$\\times$ faster than the teacher model, while maintaining image quality at levels comparable to those obtained through the teacher's complex sampling approach. The code is publicly available at \\href{https://github.com/AIDC-AI/TeEFusion}{github.com/AIDC-AI/TeEFusion}.",
      "authors": [
        "Minghao Fu",
        "Guo-Hua Wang",
        "Xiaohao Chen",
        "Qing-Guo Chen",
        "Zhao Xu",
        "Weihua Luo",
        "Kaifu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:45:40+00:00",
          "link": "https://arxiv.org/abs/2507.18192v1",
          "size": "2358kb",
          "version": "v1"
        }
      ],
      "title": "TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18192",
        "HTML": "https://arxiv.org/html/2507.18192v1",
        "PDF": "https://arxiv.org/pdf/2507.18192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving inference efficiency in text-to-image models using text embedding techniques but does not address any aspect of LLM training data processing."
      },
      "models": [
        {
          "model_path": "AIDC-AI/TeEFusion",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/AIDC-AI/TeEFusion"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.18194",
      "abstract": "Low-altitude economy (LAE) is an emerging business model, which heavily relies on integrated sensing and communications (ISAC), mobile edge computing (MEC), and covert communications. This paper investigates the convert transmission design in MEC-based networked ISAC systems towards LAE, where an MEC server coordinates multiple access points to simultaneously receive computation tasks from multiple unmanned aerial vehicles (UAVs), locate a target in a sensing area, and maintain UAVs' covert transmission against multiple wardens. We first derive closed-form expressions for the detection error probability (DEP) at wardens. Then, we formulate a total energy consumption minimization problem by optimizing communication, sensing, and computation resources as well as UAV trajectories, subject to the requirements on quality of MEC services, DEP, and radar signal-to-interference-and-noise ratio, and the causality of UAV trajectories. An alternating optimization based algorithm is proposed to handle the considered problem, which decomposes it into two subproblems: joint optimization of communication, sensing, and computation resources, and UAV trajectory optimization. The former is addressed by a successive convex approximation based algorithm, while the latter is solved via a trust-region based algorithm. Simulations validate the effectiveness of the proposed algorithm compared with various benchmarks, and reveal the trade-offs among communication, sensing, and computation in LAE systems.",
      "authors": [
        "Weihao Mao",
        "Yang Lu",
        "Bo Ai",
        "and Tony Q. S. Quek"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:53:08+00:00",
          "link": "https://arxiv.org/abs/2507.18194v1",
          "size": "1637kb",
          "version": "v1"
        }
      ],
      "title": "Covert Communications in MEC-Based Networked ISAC Systems Towards Low-Altitude Economy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18194",
        "HTML": "https://arxiv.org/html/2507.18194v1",
        "PDF": "https://arxiv.org/pdf/2507.18194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates communication strategies in mobile edge computing systems and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18196",
      "abstract": "To achieve full autonomous driving, a good understanding of the surrounding environment is necessary. Especially predicting the future states of other traffic participants imposes a non-trivial challenge. Current SotA-models already show promising results when trained on real datasets (e.g. Argoverse2, NuScenes). Problems arise when these models are deployed to new/unseen areas. Typically, performance drops significantly, indicating that the models lack generalization. In this work, we introduce a new Graph Neural Network (GNN) that utilizes a heterogeneous graph consisting of traffic participants and vectorized road network. Latter, is used to classify goals, i.e. endpoints of the predicted trajectories, in a multi-staged approach, leading to a better generalization to unseen scenarios. We show the effectiveness of the goal selection process via cross-dataset evaluation, i.e. training on Argoverse2 and evaluating on NuScenes.",
      "authors": [
        "Daniel Grimm",
        "Ahmed Abouelazm",
        "J. Marius Z\\\"ollner"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:54:17+00:00",
          "link": "https://arxiv.org/abs/2507.18196v1",
          "size": "530kb",
          "version": "v1"
        }
      ],
      "title": "Goal-based Trajectory Prediction for improved Cross-Dataset Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18196",
        "HTML": "https://arxiv.org/html/2507.18196v1",
        "PDF": "https://arxiv.org/pdf/2507.18196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a graph neural network for trajectory prediction in autonomous driving, focusing on model generalization, but it does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18197",
      "abstract": "Business process modeling is used by most organizations as an essential framework for ensuring efficiency and effectiveness of the work and workflow performed by its employees and for ensuring the alignment of such work with its strategic goals. For organizations that are compliant or near-compliant with ISO 9001, this approach involves the detailed mapping of processes, sub-processes, activities, and tasks. ISO30401 is a Management System Standard, introduced in 2018, establishing universal requirements for the set up of a Knowledge Management System in an organization. As ``ISO30401 implementers'' we regularly face the challenge of explaining our clients how the knowledge development, transformation and conveyances activities depicted in ISO30401 do integrate with existing operational processes. This article recaps process modelling principles in the context of ISO9001 and explores, based on our experience, how an ISO30401-compliant Knowledge Management System (KMS) entwines with all other processes of an Integrated Management System and in particular how it can be implemented by deploying the mechanisms of the SECI model through the steps of PDCA cycles.",
      "authors": [
        "Aline Belloni",
        "Patrick Prieur"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:54:19+00:00",
          "link": "https://arxiv.org/abs/2507.18197v1",
          "size": "1720kb",
          "version": "v1"
        }
      ],
      "title": "Integrating an ISO30401-compliant Knowledge management system with existing business processes of an organization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18197",
        "PDF": "https://arxiv.org/pdf/2507.18197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses integrating a knowledge management system with business processes, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18198",
      "abstract": "In this paper, we compare four different semantics for disjunction in Answer Set Programming that, unlike stable models, do not adhere to the principle of model minimality. Two of these approaches, Cabalar and Mu\\~niz' \\emph{Justified Models} and Doherty and Szalas' \\emph{Strongly Supported Models}, directly provide an alternative non-minimal semantics for disjunction. The other two, Aguado et al's \\emph{Forks} and Shen and Eiter's \\emph{Determining Inference} (DI) semantics, actually introduce a new disjunction connective, but are compared here as if they constituted new semantics for the standard disjunction operator. We are able to prove that three of these approaches (Forks, Justified Models and a reasonable relaxation of the DI semantics) actually coincide, constituting a common single approach under different definitions. Moreover, this common semantics always provides a superset of the stable models of a program (in fact, modulo any context) and is strictly stronger than the fourth approach (Strongly Supported Models), that actually treats disjunctions as in classical logic.",
      "authors": [
        "Felicidad Aguado",
        "Pedro Cabalar",
        "Brais Mu\\~niz",
        "Gilberto P\\'erez and Concepci\\'on Vidal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:54:37+00:00",
          "link": "https://arxiv.org/abs/2507.18198v1",
          "size": "53kb",
          "version": "v1"
        }
      ],
      "title": "Comparing Non-minimal Semantics for Disjunction in Answer Set Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18198",
        "HTML": "https://arxiv.org/html/2507.18198v1",
        "PDF": "https://arxiv.org/pdf/2507.18198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores different semantics for disjunction in Answer Set Programming and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18201",
      "abstract": "With the evolution of process approaches within organizations, the increasing importance of quality management systems (like ISO 9001) and the recent introduction of ISO 30401 for knowledge management, we examine how these different elements converge within the framework of an Integrated Management System. The article specifically demonstrates how an ISO30401-compliant knowledge management system can be implemented by deploying the mechanisms of the SECI model through the steps of the PDCA cycle as applied in the processes of the integrated management system.",
      "authors": [
        "Patrick Prieur",
        "Aline Belloni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:56:11+00:00",
          "link": "https://arxiv.org/abs/2507.18201v1",
          "size": "4782kb",
          "version": "v1"
        }
      ],
      "title": "Integrating an ISO 30401-compliant Knowledge Management System with the processes of an Integrated Management System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18201",
        "PDF": "https://arxiv.org/pdf/2507.18201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the integration of knowledge management systems with quality management standards, specifically ISO standards, without any relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18202",
      "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by providing external knowledge for accurate and up-to-date responses. However, this reliance on external sources exposes a security risk, attackers can inject poisoned documents into the knowledge base to steer the generation process toward harmful or misleading outputs. In this paper, we propose Gradient-based Masked Token Probability (GMTP), a novel defense method to detect and filter out adversarially crafted documents. Specifically, GMTP identifies high-impact tokens by examining gradients of the retriever's similarity function. These key tokens are then masked, and their probabilities are checked via a Masked Language Model (MLM). Since injected tokens typically exhibit markedly low masked-token probabilities, this enables GMTP to easily detect malicious documents and achieve high-precision filtering. Experiments demonstrate that GMTP is able to eliminate over 90% of poisoned content while retaining relevant documents, thus maintaining robust retrieval and generation performance across diverse datasets and adversarial settings.",
      "authors": [
        "San Kim",
        "Jonghwi Kim",
        "Yejin Jeon",
        "Gary Geunbae Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:58:41+00:00",
          "link": "https://arxiv.org/abs/2507.18202v1",
          "size": "948kb",
          "version": "v1"
        }
      ],
      "title": "Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18202",
        "HTML": "https://arxiv.org/html/2507.18202v1",
        "PDF": "https://arxiv.org/pdf/2507.18202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper presents a method for detecting poisoned documents in Retrieval-Augmented Generation pipelines, it does not contribute to data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18203",
      "abstract": "Instruction-tuning enhances the ability of large language models (LLMs) to follow user instructions more accurately, improving usability while reducing harmful outputs. However, this process may increase the model's dependence on user input, potentially leading to the unfiltered acceptance of misinformation and the generation of hallucinations. Existing studies primarily highlight that LLMs are receptive to external information that contradict their parametric knowledge, but little research has been conducted on the direct impact of instruction-tuning on this phenomenon. In our study, we investigate the impact of instruction-tuning on LLM's susceptibility to misinformation. Our analysis reveals that instruction-tuned LLMs are significantly more likely to accept misinformation when it is presented by the user. A comparison with base models shows that instruction-tuning increases reliance on user-provided information, shifting susceptibility from the assistant role to the user role. Furthermore, we explore additional factors influencing misinformation susceptibility, such as the role of the user in prompt structure, misinformation length, and the presence of warnings in the system prompt. Our findings underscore the need for systematic approaches to mitigate unintended consequences of instruction-tuning and enhance the reliability of LLMs in real-world applications.",
      "authors": [
        "Kyubeen Han",
        "Junseo Jang",
        "Hongjin Kim",
        "Geunyeong Jeong",
        "Harksoo Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:58:47+00:00",
          "link": "https://arxiv.org/abs/2507.18203v1",
          "size": "215kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Impact of Instruction-Tuning on LLM's Susceptibility to Misinformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18203",
        "HTML": "https://arxiv.org/html/2507.18203v1",
        "PDF": "https://arxiv.org/pdf/2507.18203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the effects of instruction-tuning on LLMs, focusing on susceptibility to misinformation. Though it relates to fine-tuning, its primary concern is model performance and reliability rather than data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18204",
      "abstract": "The integration of renewable sources is essential for decarbonizing heat production in district energy networks. Beyond biomass-based solutions, solar thermal energy, with or without heat pumps, presents a significant opportunity. However, system performance is highly dependent on outdoor and setpoint temperatures. This study aims to optimize system design using a multi-criteria approach that considers techno-economic and environmental (CO2) factors. A Mixed-Integer Linear Programming (MILP) model is developed, incorporating temperature discretization for problem linearization and capturing key dynamic characteristics of heat generators. The model improves convergence, reducing a 19% MIP gap in 26 hours to 10% in 12 hours by dissipating 6% excess solar heat. A multi-scenario analysis under two carbon taxation levels and different CO2 emission cases revealed solar integration up to 11,932 m${}^2$ but increased gas reliance (50%) and TES losses (49%). Wood boiler inclusion reduced solar dependency, covering 45% of heat, lowered LCOH, but limited renewable penetration. Higher carbon taxes boosted solar adoption but faced storage inefficiencies, while biomass enhanced cost efficiency and system stability.",
      "authors": [
        "Hamza Mettali (CETHIL,INSA Lyon,AIS)",
        "Rousset Fran\\c{c}ois (CETHIL)",
        "Eric Bideaux (AIS)",
        "Clausse Marc (CETHIL)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:59:36+00:00",
          "link": "https://arxiv.org/abs/2507.18204v1",
          "size": "855kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Integration Of Heat-Pump And Solar Thermal Energy In The Pre-heating Loop Of Wood And Gas Boiler Based District Heating System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18204",
        "PDF": "https://arxiv.org/pdf/2507.18204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses energy integration for district heating systems, involving solar and heat pump technologies, with no connection to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18205",
      "abstract": "Model-based testing (MBT) derives test suites from a behavioural specification of the system under test. In practice, engineers favour simple models, such as labelled transition systems (LTSs). However, to deal with quiescence - the absence of observable output - in practice, a time-out needs to be set to conclude observation of quiescence. Timed MBT exists, but it typically relies on the full arsenal of timed automata (TA).\n  We present a lifting operator $\\chi^{\\scriptstyle M}\\!$ that adds timing without the TA overhead: given an LTS, $\\chi^{\\scriptstyle M}\\!$ introduces a single clock for a user chosen time bound $M>0$ to declare quiescence. In the timed automaton, the clock is used to model that outputs should happen before the clock reaches value $M$, while quiescence occurs exactly at time $M$. This way we provide a formal basis for the industrial practice of choosing a time-out to conclude quiescence. Our contributions are threefold: (1) an implementation conforms under $\\mathbf{ioco}$ if and only if its lifted version conforms under timed $\\mathbf{tioco_M}$ (2) applying $\\chi^{\\scriptstyle M}\\!$ before or after the standard $\\mathbf{ioco}$ test-generation algorithm yields the same set of tests, and (3) the lifted TA test suite and the original LTS test suite deliver identical verdicts for every implementation.",
      "authors": [
        "Laura Brand\\'an Briones and Marcus Gerhold and Petra van den Bos and Mari\\\"elle Stoelinga"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:01:37+00:00",
          "link": "https://arxiv.org/abs/2507.18205v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Time for Quiescence: Modelling quiescent behaviour in testing via time-outs in timed automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18205",
        "HTML": "https://arxiv.org/html/2507.18205v1",
        "PDF": "https://arxiv.org/pdf/2507.18205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses model-based testing for quiescence using timed automata, which does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18206",
      "abstract": "A fundamental requirement for full autonomy in mobile robots is accurate navigation even in situations where satellite navigation or cameras are unavailable. In such practical situations, relying only on inertial sensors will result in navigation solution drift due to the sensors' inherent noise and error terms. One of the emerging solutions to mitigate drift is to maneuver the robot in a snake-like slithering motion to increase the inertial signal-to-noise ratio, allowing the regression of the mobile robot position. In this work, we propose MoRPI-PINN as a physics-informed neural network framework for accurate inertial-based mobile robot navigation. By embedding physical laws and constraints into the training process, MoRPI-PINN is capable of providing an accurate and robust navigation solution. Using real-world experiments, we show accuracy improvements of over 85% compared to other approaches. MoRPI-PINN is a lightweight approach that can be implemented even on edge devices and used in any typical mobile robot application.",
      "authors": [
        "Arup Kumar Sahoo and Itzik Klein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:02:13+00:00",
          "link": "https://arxiv.org/abs/2507.18206v1",
          "size": "1596kb",
          "version": "v1"
        }
      ],
      "title": "MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18206",
        "HTML": "https://arxiv.org/html/2507.18206v1",
        "PDF": "https://arxiv.org/pdf/2507.18206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on achieving accurate inertial-based navigation for mobile robots using a physics-informed neural network. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18212",
      "abstract": "Layer pruning has emerged as a promising technique for compressing large language models (LLMs) while achieving acceleration proportional to the pruning ratio. In this work, we identify that removing any layer induces a significant magnitude gap in hidden states, resulting in substantial performance degradation. To address this issue, we propose Prune&Comp, a novel plug-and-play layer pruning scheme that leverages magnitude compensation to mitigate such gaps in a training-free manner. Specifically, we first estimate the magnitude gap caused by layer removal and then eliminate this gap by rescaling the remaining weights offline, with zero runtime overhead incurred. We further demonstrate the advantages of Prune&Comp through an iterative pruning strategy. When integrated with an iterative prune-and-compensate loop, Prune&Comp consistently enhances existing layer pruning metrics. For instance, when 5 layers of LLaMA-3-8B are pruned using the prevalent block influence metric, Prune&Comp nearly halves the perplexity and retains 93.19\\% of the original model's question-answering performance, outperforming the baseline by 4.01%.",
      "authors": [
        "Xinrui Chen",
        "Hongxing Zhang",
        "Fanyi Zeng",
        "Yongxian Wei",
        "Yizhi Wang",
        "Xitong Ling",
        "Guanghao Li",
        "Chun Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:07:20+00:00",
          "link": "https://arxiv.org/abs/2507.18212v1",
          "size": "510kb",
          "version": "v1"
        }
      ],
      "title": "Prune&Comp: Free Lunch for Layer-Pruned LLMs via Iterative Pruning with Magnitude Compensation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18212",
        "HTML": "https://arxiv.org/html/2507.18212v1",
        "PDF": "https://arxiv.org/pdf/2507.18212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a layer pruning scheme, Prune&Comp, for LLMs, focusing on model compression and acceleration, without addressing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18214",
      "abstract": "Leveraging the powerful capabilities of diffusion models has yielded quite effective results in medical image segmentation tasks. However, existing methods typically transfer the original training process directly without specific adjustments for segmentation tasks. Furthermore, the commonly used pre-trained diffusion models still have deficiencies in feature extraction. Based on these considerations, we propose LEAF, a medical image segmentation model grounded in latent diffusion models. During the fine-tuning process, we replace the original noise prediction pattern with a direct prediction of the segmentation map, thereby reducing the variance of segmentation results. We also employ a feature distillation method to align the hidden states of the convolutional layers with the features from a transformer-based vision encoder. Experimental results demonstrate that our method enhances the performance of the original diffusion model across multiple segmentation datasets for different disease types. Notably, our approach does not alter the model architecture, nor does it increase the number of parameters or computation during the inference phase, making it highly efficient.",
      "authors": [
        "Qilin Huang",
        "Tianyu Lin",
        "Zhiguang Chen",
        "Fudan Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:08:04+00:00",
          "link": "https://arxiv.org/abs/2507.18214v1",
          "size": "572kb",
          "version": "v1"
        }
      ],
      "title": "LEAF: Latent Diffusion with Efficient Encoder Distillation for Aligned Features in Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18214",
        "HTML": "https://arxiv.org/html/2507.18214v1",
        "PDF": "https://arxiv.org/pdf/2507.18214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces LEAF, a model for medical image segmentation based on latent diffusion models, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18215",
      "abstract": "Information security is facing increasingly severe challenges, and traditional protection means are difficult to cope with complex and changing threats. In recent years, as an emerging intelligent technology, large language models (LLMs) have shown a broad application prospect in the field of information security. In this paper, we focus on the key role of LLM in information security, systematically review its application progress in malicious behavior prediction, network threat analysis, system vulnerability detection, malicious code identification, and cryptographic algorithm optimization, and explore its potential in enhancing security protection performance. Based on neural networks and Transformer architecture, this paper analyzes the technical basis of large language models and their advantages in natural language processing tasks. It is shown that the introduction of large language modeling helps to improve the detection accuracy and reduce the false alarm rate of security systems. Finally, this paper summarizes the current application results and points out that it still faces challenges in model transparency, interpretability, and scene adaptability, among other issues. It is necessary to explore further the optimization of the model structure and the improvement of the generalization ability to realize a more intelligent and accurate information security protection system.",
      "authors": [
        "Chang Gong and Zhongwen Li and Xiaoqi Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:09:36+00:00",
          "link": "https://arxiv.org/abs/2507.18215v1",
          "size": "6067kb",
          "version": "v1"
        }
      ],
      "title": "Information Security Based on LLM Approaches: A Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18215",
        "HTML": "https://arxiv.org/html/2507.18215v1",
        "PDF": "https://arxiv.org/pdf/2507.18215"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper reviews the use of LLMs in information security, including applications like malicious behavior prediction. It mentions the role of LLMs but does not significantly delve into LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18219",
      "abstract": "Federated Graph Learning (FGL) is a distributed learning paradigm that enables collaborative training over large-scale subgraphs located on multiple local systems. However, most existing FGL approaches rely on synchronous communication, which leads to inefficiencies and is often impractical in real-world deployments. Meanwhile, current asynchronous federated learning (AFL) methods are primarily designed for conventional tasks such as image classification and natural language processing, without accounting for the unique topological properties of graph data. Directly applying these methods to graph learning can possibly result in semantic drift and representational inconsistency in the global model. To address these challenges, we propose FedSA-GCL, a semi-asynchronous federated framework that leverages both inter-client label distribution divergence and graph topological characteristics through a novel ClusterCast mechanism for efficient training. We evaluate FedSA-GCL on multiple real-world graph datasets using the Louvain and Metis split algorithms, and compare it against 9 baselines. Extensive experiments demonstrate that our method achieves strong robustness and outstanding efficiency, outperforming the baselines by an average of 2.92% with the Louvain and by 3.4% with the Metis.",
      "authors": [
        "Zhongzheng Yuan",
        "Lianshuai Guo",
        "Xunkai Li",
        "Yinlin Zhu",
        "Wenyu Wang",
        "Meixia Qu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:15:07+00:00",
          "link": "https://arxiv.org/abs/2507.18219v1",
          "size": "9617kb",
          "version": "v1"
        }
      ],
      "title": "FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18219",
        "HTML": "https://arxiv.org/html/2507.18219v1",
        "PDF": "https://arxiv.org/pdf/2507.18219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on federated graph learning and communication in distributed systems, particularly addressing inefficiencies in asynchronous federated learning methods. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18220",
      "abstract": "The sparse identification of nonlinear dynamics (SINDy) approach can discover the governing equations of dynamical systems based on measurement data, where the dynamical model is identified as the sparse linear combination of the given basis functions. A major challenge in SINDy is the design of a library, which is a set of candidate basis functions, as the appropriate library is not trivial for many dynamical systems. To overcome this difficulty, this study proposes SINDy with library optimization mechanism (SINDy-LOM), which is a combination of the sparse regression technique and the novel learning strategy of the library. In the proposed approach, the basis functions are parametrized. The SINDy-LOM approach involves a two-layer optimization architecture: the inner-layer, in which the data-driven model is extracted as the sparse linear combination of the candidate basis functions, and the outer-layer, in which the basis functions are optimized from the viewpoint of the recursive long-term (RLT) prediction accuracy; thus, the library design is reformulated as the optimization of the parametrized basis functions. The resulting SINDy-LOM model has good interpretability and usability, as the proposed approach yields the parsimonious model. The library optimization mechanism significantly reduces user burden. The RLT perspective improves the reliability of the resulting model compared with the traditional SINDy approach that can only ensure the one-step-ahead prediction accuracy. The validity of the proposed approach is demonstrated by applying it to a diesel engine airpath system, which is a well-known complex industrial system.",
      "authors": [
        "Ansei Yonezawa",
        "Heisei Yonezawa",
        "Shuichi Yahagi",
        "Itsuro Kajiwara",
        "Shinya Kijimoto",
        "Hikaru Taniuchi",
        "Kentaro Murakami"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:15:26+00:00",
          "link": "https://arxiv.org/abs/2507.18220v1",
          "size": "2035kb",
          "version": "v1"
        }
      ],
      "title": "Sparse identification of nonlinear dynamics with library optimization mechanism: Recursive long-term prediction perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18220",
        "PDF": "https://arxiv.org/pdf/2507.18220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses sparse identification of nonlinear dynamics through optimization of basis functions for dynamical systems, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18223",
      "abstract": "This paper introduces a GenAI-empowered approach to automated development of automotive software, with emphasis on autonomous and Advanced Driver Assistance Systems (ADAS) capabilities. The process starts with requirements as input, while the main generated outputs are test scenario code for simulation environment, together with implementation of desired ADAS capabilities targeting hardware platform of the vehicle connected to testbench. Moreover, we introduce additional steps for requirements consistency checking leveraging Model-Driven Engineering (MDE). In the proposed workflow, Large Language Models (LLMs) are used for model-based summarization of requirements (Ecore metamodel, XMI model instance and OCL constraint creation), test scenario generation, simulation code (Python) and target platform code generation (C++). Additionally, Retrieval Augmented Generation (RAG) is adopted to enhance test scenario generation from autonomous driving regulations-related documents. Our approach aims shorter compliance and re-engineering cycles, as well as reduced development and testing time when it comes to ADAS-related capabilities.",
      "authors": [
        "Nenad Petrovic",
        "Fengjunjie Pan",
        "Vahid Zolfaghari",
        "Krzysztof Lebioda",
        "Andre Schamschurko",
        "Alois Knoll"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:17:13+00:00",
          "link": "https://arxiv.org/abs/2507.18223v1",
          "size": "552kb",
          "version": "v1"
        }
      ],
      "title": "GenAI for Automotive Software Development: From Requirements to Wheels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18223",
        "HTML": "https://arxiv.org/html/2507.18223v1",
        "PDF": "https://arxiv.org/pdf/2507.18223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper uses LLMs for model-based summarization and test scenario generation in automotive software development. While it involves data processing with LLMs, its primary focus is on software development for automotive applications rather than on improving LLM training data processing directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18224",
      "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have emerged as a powerful solution for dealing with complex problems across diverse domains. The effectiveness of MAS is critically dependent on its collaboration topology, which has become a focal point for automated design research. However, existing approaches are fundamentally constrained by their reliance on a template graph modification paradigm with a predefined set of agents and hard-coded interaction structures, significantly limiting their adaptability to task-specific requirements. To address these limitations, we reframe MAS design as a conditional autoregressive graph generation task, where both the system composition and structure are designed jointly. We propose ARG-Designer, a novel autoregressive model that operationalizes this paradigm by constructing the collaboration graph from scratch. Conditioned on a natural language task query, ARG-Designer sequentially and dynamically determines the required number of agents, selects their appropriate roles from an extensible pool, and establishes the optimal communication links between them. This generative approach creates a customized topology in a flexible and extensible manner, precisely tailored to the unique demands of different tasks. Extensive experiments across six diverse benchmarks demonstrate that ARG-Designer not only achieves state-of-the-art performance but also enjoys significantly greater token efficiency and enhanced extensibility. The source code of ARG-Designer is available at https://github.com/Shiy-Li/ARG-Designer.",
      "authors": [
        "Shiyuan Li",
        "Yixin Liu",
        "Qingsong Wen",
        "Chengqi Zhang",
        "Shirui Pan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:17:41+00:00",
          "link": "https://arxiv.org/abs/2507.18224v1",
          "size": "812kb",
          "version": "v1"
        }
      ],
      "title": "Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18224",
        "HTML": "https://arxiv.org/html/2507.18224v1",
        "PDF": "https://arxiv.org/pdf/2507.18224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on designing multi-agent communication topologies using autoregressive graph generation, which involves LLMs but is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18225",
      "abstract": "While test-time adaptation (TTA) methods effectively address domain shifts by dynamically adapting pre-trained models to target domain data during online inference, their application to 3D point clouds is hindered by their irregular and unordered structure. Current 3D TTA methods often rely on computationally expensive spatial-domain optimizations and may require additional training data. In contrast, we propose Graph Spectral Domain Test-Time Adaptation (GSDTTA), a novel approach for 3D point cloud classification that shifts adaptation to the graph spectral domain, enabling more efficient adaptation by capturing global structural properties with fewer parameters. Point clouds in target domain are represented as outlier-aware graphs and transformed into graph spectral domain by Graph Fourier Transform (GFT). For efficiency, adaptation is performed by optimizing only the lowest 10% of frequency components, which capture the majority of the point cloud's energy. An inverse GFT (IGFT) is then applied to reconstruct the adapted point cloud with the graph spectral-driven point shift. This process is enhanced by an eigenmap-guided self-training strategy that iteratively refines both the spectral adjustments and the model parameters. Experimental results and ablation studies on benchmark datasets demonstrate the effectiveness of GSDTTA, outperforming existing TTA methods for 3D point cloud classification.",
      "authors": [
        "Xin Wei",
        "Qin Yang",
        "Yijie Fang",
        "Mingrui Zhu",
        "Nannan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:18:39+00:00",
          "link": "https://arxiv.org/abs/2507.18225v1",
          "size": "1237kb",
          "version": "v1"
        }
      ],
      "title": "3D Test-time Adaptation via Graph Spectral Driven Point Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18225",
        "HTML": "https://arxiv.org/html/2507.18225v1",
        "PDF": "https://arxiv.org/pdf/2507.18225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses test-time adaptation methods for 3D point cloud classification, which involves domain adaptation techniques and graph spectral approaches, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18231",
      "abstract": "Integrating inverse rendering with multi-view photometric stereo (MVPS) yields more accurate 3D reconstructions than the inverse rendering approaches that rely on fixed environment illumination. However, efficient inverse rendering with MVPS remains challenging. To fill this gap, we introduce the Gaussian Splatting for Multi-view Photometric Stereo (PS-GS), which efficiently and jointly estimates the geometry, materials, and lighting of the object that is illuminated by diverse directional lights (multi-light). Our method first reconstructs a standard 2D Gaussian splatting model as the initial geometry. Based on the initialization model, it then proceeds with the deferred inverse rendering by the full rendering equation containing a lighting-computing multi-layer perceptron. During the whole optimization, we regularize the rendered normal maps by the uncalibrated photometric stereo estimated normals. We also propose the 2D Gaussian ray-tracing for single directional light to refine the incident lighting. The regularizations and the use of multi-view and multi-light images mitigate the ill-posed problem of inverse rendering. After optimization, the reconstructed object can be used for novel-view synthesis, relighting, and material and shape editing. Experiments on both synthetic and real datasets demonstrate that our method outperforms prior works in terms of reconstruction accuracy and computational efficiency.",
      "authors": [
        "Yixiao Chen",
        "Bin Liang",
        "Hanzhi Guo",
        "Yongqing Cheng",
        "Jiayi Zhao",
        "Dongdong Weng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:22:02+00:00",
          "link": "https://arxiv.org/abs/2507.18231v1",
          "size": "1338kb",
          "version": "v1"
        }
      ],
      "title": "PS-GS: Gaussian Splatting for Multi-View Photometric Stereo",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18231",
        "HTML": "https://arxiv.org/html/2507.18231v1",
        "PDF": "https://arxiv.org/pdf/2507.18231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Gaussian Splatting for Multi-View Photometric Stereo, aimed at improving 3D reconstructions for photometric applications. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18235",
      "abstract": "Simulating electromagnetic fields across broad frequency ranges is challenging due to numerical instabilities at low frequencies. This work extends a stabilized two-step formulation of Maxwell's equations to the time-domain. Using a Galerkin discretization in space, we apply two different time-discretization schemes that are tailored to the first- and second-order in time partial differential equations of the two-step solution procedure used here. To address the low-frequency instability, we incorporate a generalized tree-cotree gauge that removes the singularity of the curl-curl operator, ensuring robustness even in the static limit. Numerical results on academic and application-oriented 3D problems confirm stability, accuracy, and the method's applicability to nonlinear, temperature-dependent materials.",
      "authors": [
        "Leon Herles",
        "Mario Mally",
        "J\\\"org Ostrowski",
        "Sebastian Sch\\\"ops",
        "Melina Merkel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:24:03+00:00",
          "link": "https://arxiv.org/abs/2507.18235v1",
          "size": "1970kb",
          "version": "v1"
        }
      ],
      "title": "A stabilized Two-Step Formulation of Maxwell's Equations in the time-domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18235",
        "PDF": "https://arxiv.org/pdf/2507.18235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work deals with numerical techniques for simulating electromagnetic fields and extends a stabilized formulation of Maxwell\u2019s equations. It is not relevant to the topic of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18237",
      "abstract": "Feature-level fusion shows promise in collaborative perception (CP) through balanced performance and communication bandwidth trade-off. However, its effectiveness critically relies on input feature quality. The acquisition of high-quality features faces domain gaps from hardware diversity and deployment conditions, alongside temporal misalignment from transmission delays. These challenges degrade feature quality with cumulative effects throughout the collaborative network. In this paper, we present the Domain-And-Time Alignment (DATA) network, designed to systematically align features while maximizing their semantic representations for fusion. Specifically, we propose a Consistency-preserving Domain Alignment Module (CDAM) that reduces domain gaps through proximal-region hierarchical downsampling and observability-constrained discriminator. We further propose a Progressive Temporal Alignment Module (PTAM) to handle transmission delays via multi-scale motion modeling and two-stage compensation. Building upon the aligned features, an Instance-focused Feature Aggregation Module (IFAM) is developed to enhance semantic representations. Extensive experiments demonstrate that DATA achieves state-of-the-art performance on three typical datasets, maintaining robustness with severe communication delays and pose errors. The code will be released at https://github.com/ChengchangTian/DATA.",
      "authors": [
        "Chengchang Tian",
        "Jianwei Ma",
        "Yan Huang",
        "Zhanye Chen",
        "Honghao Wei",
        "Hui Zhang",
        "Wei Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:24:29+00:00",
          "link": "https://arxiv.org/abs/2507.18237v1",
          "size": "8421kb",
          "version": "v1"
        }
      ],
      "title": "DATA: Domain-And-Time Alignment for High-Quality Feature Fusion in Collaborative Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18237",
        "HTML": "https://arxiv.org/html/2507.18237v1",
        "PDF": "https://arxiv.org/pdf/2507.18237"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for feature fusion in collaborative perception, discussing domain and temporal alignment. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18238",
      "abstract": "We derive multiple program logics, including correctness, incorrectness, and relational Hoare logic, from the axioms of imperative categories: uniformly traced distributive copy-discard categories. We introduce an internal language for imperative multicategories, on top of which we derive combinators for an adaptation of Dijkstra's guarded command language. Rules of program logics are derived from this internal language.",
      "authors": [
        "Filippo Bonchi",
        "Elena Di Lavore",
        "Mario Rom\\'an",
        "Sam Staton"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:25:26+00:00",
          "link": "https://arxiv.org/abs/2507.18238v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "Program Logics via Distributive Monoidal Categories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18238",
        "PDF": "https://arxiv.org/pdf/2507.18238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper derives program logics from categorical axioms and focuses on theoretical aspects of programming languages. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18242",
      "abstract": "Despite their theoretical appeal, totally corrective boosting methods based on linear programming have received limited empirical attention. In this paper, we conduct the first large-scale experimental study of six LP-based boosting formulations, including two novel methods, NM-Boost and QRLP-Boost, across 20 diverse datasets. We evaluate the use of both heuristic and optimal base learners within these formulations, and analyze not only accuracy, but also ensemble sparsity, margin distribution, anytime performance, and hyperparameter sensitivity. We show that totally corrective methods can outperform or match state-of-the-art heuristics like XGBoost and LightGBM when using shallow trees, while producing significantly sparser ensembles. We further show that these methods can thin pre-trained ensembles without sacrificing performance, and we highlight both the strengths and limitations of using optimal decision trees in this context.",
      "authors": [
        "Fabian Akkerman",
        "Julien Ferry",
        "Christian Artigues",
        "Emmanuel Hebrard",
        "Thibaut Vidal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:30:37+00:00",
          "link": "https://arxiv.org/abs/2507.18242v1",
          "size": "1639kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Revisited: Benchmarking and Advancing LP-Based Ensemble Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18242",
        "HTML": "https://arxiv.org/html/2507.18242v1",
        "PDF": "https://arxiv.org/pdf/2507.18242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking ensemble methods for boosting models using linear programming, which is unrelated to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18243",
      "abstract": "In recent years, foundation models for monocular depth estimation have received increasing attention. Current methods mainly address typical daylight conditions, but their effectiveness notably decreases in low-light environments. There is a lack of robust foundational models for monocular depth estimation specifically designed for low-light scenarios. This largely stems from the absence of large-scale, high-quality paired depth datasets for low-light conditions and the effective parameter-efficient fine-tuning (PEFT) strategy. To address these challenges, we propose DepthDark, a robust foundation model for low-light monocular depth estimation. We first introduce a flare-simulation module and a noise-simulation module to accurately simulate the imaging process under nighttime conditions, producing high-quality paired depth datasets for low-light conditions. Additionally, we present an effective low-light PEFT strategy that utilizes illumination guidance and multiscale feature fusion to enhance the model's capability in low-light environments. Our method achieves state-of-the-art depth estimation performance on the challenging nuScenes-Night and RobotCar-Night datasets, validating its effectiveness using limited training data and computing resources.",
      "authors": [
        "Longjian Zeng",
        "Zunjie Zhu",
        "Rongfeng Lu",
        "Ming Lu",
        "Bolun Zheng",
        "Chenggang Yan",
        "Anke Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:32:53+00:00",
          "link": "https://arxiv.org/abs/2507.18243v1",
          "size": "5726kb",
          "version": "v1"
        }
      ],
      "title": "DepthDark: Robust Monocular Depth Estimation for Low-Light Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18243",
        "HTML": "https://arxiv.org/html/2507.18243v1",
        "PDF": "https://arxiv.org/pdf/2507.18243"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses monocular depth estimation in low-light environments by creating synthetic depth datasets. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18246",
      "abstract": "We show that, when the actions of a Mazurkiewicz trace are considered not merely as atomic (i.e., mere names) but transformations from a specified type of inputs to a specified type of outputs, we obtain a novel notion of presentation for effectful categories (also known as generalised Freyd categories), a well-known algebraic structure in the semantics of side-effecting computation. Like the usual representation of traces as graphs, our notion of presentation gives rise to a graphical calculus for effectful categories. We use our presentations to give a construction of the commuting tensor product of free effectful categories, capturing the combination of systems in which the actions of each must commute with one another, while still permitting exchange of resources",
      "authors": [
        "Matthew Earnshaw",
        "Chad Nester",
        "Mario Rom\\'an"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:35:44+00:00",
          "link": "https://arxiv.org/abs/2507.18246v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "Resourceful Traces for Commuting Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18246",
        "HTML": "https://arxiv.org/html/2507.18246v1",
        "PDF": "https://arxiv.org/pdf/2507.18246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algebraic structures in the semantics of side-effecting computations, which is not related to the data processing required for training large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18248",
      "abstract": "The use of robotics, computer vision, and their applications is becoming increasingly widespread in various fields, including medicine. Many face detection algorithms have found applications in neurosurgery, ophthalmology, and plastic surgery. A common challenge in using these algorithms is variable lighting conditions and the flexibility of detection positions to identify and precisely localize patients. The proposed experiment tests the MediaPipe algorithm for detecting facial landmarks in a controlled setting, using a robotic arm that automatically adjusts positions while the surgical light and the phantom remain in a fixed position. The results of this study demonstrate that the improved accuracy of facial landmark detection under surgical lighting significantly enhances the detection performance at larger yaw and pitch angles. The increase in standard deviation/dispersion occurs due to imprecise detection of selected facial landmarks. This analysis allows for a discussion on the potential integration of the MediaPipe algorithm into medical procedures.",
      "authors": [
        "Ines Frajtag",
        "Marko \\v{S}vaco",
        "Filip \\v{S}uligoj"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:40:47+00:00",
          "link": "https://arxiv.org/abs/2507.18248v1",
          "size": "3066kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of facial landmark localization performance in a surgical setting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18248",
        "HTML": "https://arxiv.org/html/2507.18248v1",
        "PDF": "https://arxiv.org/pdf/2507.18248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on facial landmark localization in surgical settings and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18249",
      "abstract": "Digitalization of power grids have made them increasingly susceptible to cyber-attacks in the past decade. Iterative cybersecurity testing is indispensable to counter emerging attack vectors and to ensure dependability of critical infrastructure. Furthermore, these can be used to evaluate cybersecurity configuration, effectiveness of the cybersecurity measures against various attack vectors, as well as to train smart grid cybersecurity experts defending the system. Enabling extensive experiments narrows the gap between academic research and production environment. A high-fidelity cyber range is vital as it is often infeasible to conduct such experiments and training using production environment. However, the design and implementation of cyber range requires extensive domain knowledge of physical and cyber aspect of the infrastructure. Furthermore, costs incurred for setup and maintenance of cyber range are significant. Moreover, most existing smart grid cyber ranges are designed as a one-off, proprietary system, and are limited in terms of configurability, accessibility, portability, and reproducibility. To address these challenges, an automated Smart grid Cyber Range generation framework is presented in this paper. Initially a human-/machine-friendly, XML-based modeling language called Smart Grid Modeling Language was defined, which incorporates IEC 61850 System Configuration Language files. Subsequently, a toolchain to parse SG-ML model files and automatically instantiate a functional smart grid cyber range was developed. The developed SG-ML models can be easily shared and/or modified to reproduce or customize for any cyber range. The application of Auto-SGCR is demonstrated through case studies with large-scale substation models. The toolchain along with example SG-ML models have been open-sourced.",
      "authors": [
        "Muhammad M. Roomi",
        "S. M. Suhail Hussain",
        "Ee-Chien Chang",
        "David M. Nicol",
        "and Daisuke Mashima"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:44:03+00:00",
          "link": "https://arxiv.org/abs/2507.18249v1",
          "size": "14414kb",
          "version": "v1"
        }
      ],
      "title": "Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18249",
        "HTML": "https://arxiv.org/html/2507.18249v1",
        "PDF": "https://arxiv.org/pdf/2507.18249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for generating smart grid cyber ranges using IEC 61850 standards. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18251",
      "abstract": "We study the fair division problem of allocating $m$ indivisible goods to $n$ agents with additive personalized bi-valued utilities. Specifically, each agent $i$ assigns one of two positive values $a_i > b_i > 0$ to each good, indicating that agent $i$'s valuation of any good is either $a_i$ or $b_i$. For convenience, we denote the value ratio of agent $i$ as $r_i = a_i / b_i$.\n  We give a characterization to all the Pareto-optimal allocations. Our characterization implies a polynomial-time algorithm to decide if a given allocation is Pareto-optimal in the case each $r_i$ is an integer. For the general case (where $r_i$ may be fractional), we show that this decision problem is coNP-complete. Our result complements the existing results: this decision problem is coNP-complete for tri-valued utilities (where each agent's value for each good belongs to $\\{a,b,c\\}$ for some prescribed $a>b>c\\geq0$), and this decision problem belongs to P for bi-valued utilities (where $r_i$ in our model is the same for each agent).\n  We further show that an EFX allocation always exists and can be computed in polynomial time under the personalized bi-valued utilities setting, which extends the previous result on bi-valued utilities. We propose the open problem of whether an EFX and Pareto-optimal allocation always exists (and can be computed in polynomial time).",
      "authors": [
        "Jiarong Jin and Biaoshuai Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:49:50+00:00",
          "link": "https://arxiv.org/abs/2507.18251v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "On Pareto-Optimal and Fair Allocations with Personalized Bi-Valued Utilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18251",
        "HTML": "https://arxiv.org/html/2507.18251v1",
        "PDF": "https://arxiv.org/pdf/2507.18251"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on fair division problems and algorithmic solutions in the context of allocations with personalized bi-valued utilities. It does not address LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18252",
      "abstract": "Eye-tracking data reveals valuable insights into users' cognitive states but is difficult to analyze due to its structured, non-linguistic nature. While large language models (LLMs) excel at reasoning over text, they struggle with temporal and numerical data. This paper presents a multimodal human-AI collaborative framework designed to enhance cognitive pattern extraction from eye-tracking signals. The framework includes: (1) a multi-stage pipeline using horizontal and vertical segmentation alongside LLM reasoning to uncover latent gaze patterns; (2) an Expert-Model Co-Scoring Module that integrates expert judgment with LLM output to generate trust scores for behavioral interpretations; and (3) a hybrid anomaly detection module combining LSTM-based temporal modeling with LLM-driven semantic analysis. Our results across several LLMs and prompt strategies show improvements in consistency, interpretability, and performance, with up to 50% accuracy in difficulty prediction tasks. This approach offers a scalable, interpretable solution for cognitive modeling and has broad potential in adaptive learning, human-computer interaction, and educational analytics.",
      "authors": [
        "Dongyang Guo",
        "Yasmeen Abdrabou",
        "Enkeleda Thaqi",
        "Enkelejda Kasneci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:49:53+00:00",
          "link": "https://arxiv.org/abs/2507.18252v1",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Behavioral Patterns Analysis with Eye-Tracking and LLM-Based Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18252",
        "HTML": "https://arxiv.org/html/2507.18252v1",
        "PDF": "https://arxiv.org/pdf/2507.18252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a multimodal framework combining eye-tracking and LLM reasoning. While it includes LLM-based processing, it focuses primarily on cognitive pattern extraction rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18253",
      "abstract": "Of growing concern in privacy scholarship is artificial intelligence (AI), as a powerful producer of inferences. Taken to its limits, AI may be presumed capable of inferring \"everything from everything,\" thereby making untenable any normative scheme, including privacy theory and privacy regulation, which rests on protecting privacy based on categories of data - sensitive versus non-sensitive, private versus public. Discarding data categories as a normative anchoring in privacy and data protection as a result of an unconditional acceptance of AI's inferential capacities is what we call privacy nihilism. An ethically reasoned response to AI inferences requires a sober consideration of AI capabilities rather than issuing an epistemic carte blanche. We introduce the notion of conceptual overfitting to expose how privacy nihilism turns a blind eye toward flawed epistemic practices in AI development. Conceptual overfitting refers to the adoption of norms of convenience that simplify the development of AI models by forcing complex constructs to fit data that are conceptually under-representative or even irrelevant. While conceptual overfitting serves as a helpful device to counter normative suggestions grounded in hyperbolic AI capability claims, AI inferences shake any privacy regulation that hinges protections based on restrictions around data categories. We propose moving away from privacy frameworks that focus solely on data type, neglecting all other factors. Theories like contextual integrity evaluate the normative value of privacy across several parameters, including the type of data, the actors involved in sharing it, and the purposes for which the information is used.",
      "authors": [
        "Severin Engelmann",
        "Helen Nissenbaum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:52:18+00:00",
          "link": "https://arxiv.org/abs/2507.18253v1",
          "size": "404kb",
          "version": "v1"
        }
      ],
      "title": "Countering Privacy Nihilism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18253",
        "PDF": "https://arxiv.org/pdf/2507.18253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses privacy concerns and AI inference capabilities but does not address LLM training data processing or any related data operations, focusing instead on theoretical privacy issues."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18255",
      "abstract": "Recent advancements in multi-view scene reconstruction have been significant, yet existing methods face limitations when processing streams of input images. These methods either rely on time-consuming offline optimization or are restricted to shorter sequences, hindering their applicability in real-time scenarios. In this work, we propose LONG3R (LOng sequence streaming 3D Reconstruction), a novel model designed for streaming multi-view 3D scene reconstruction over longer sequences. Our model achieves real-time processing by operating recurrently, maintaining and updating memory with each new observation. We first employ a memory gating mechanism to filter relevant memory, which, together with a new observation, is fed into a dual-source refined decoder for coarse-to-fine interaction. To effectively capture long-sequence memory, we propose a 3D spatio-temporal memory that dynamically prunes redundant spatial information while adaptively adjusting resolution along the scene. To enhance our model's performance on long sequences while maintaining training efficiency, we employ a two-stage curriculum training strategy, each stage targeting specific capabilities. Experiments demonstrate that LONG3R outperforms state-of-the-art streaming methods, particularly for longer sequences, while maintaining real-time inference speed. Project page: https://zgchen33.github.io/LONG3R/.",
      "authors": [
        "Zhuoguang Chen and Minghui Qin and Tianyuan Yuan and Zhe Liu and Hang Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:55:20+00:00",
          "link": "https://arxiv.org/abs/2507.18255v1",
          "size": "1397kb",
          "version": "v1"
        }
      ],
      "title": "LONG3R: Long Sequence Streaming 3D Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18255",
        "HTML": "https://arxiv.org/html/2507.18255v1",
        "PDF": "https://arxiv.org/pdf/2507.18255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces LONG3R, a model for real-time 3D reconstruction from image streams, and focuses on improvements in processing efficiency and memory management for this task, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18260",
      "abstract": "Infrared small target detection (ISTD) plays a vital role in numerous practical applications. In pursuit of determining the performance boundaries, researchers employ large and expensive manual-labeling data for representation learning. Nevertheless, this approach renders the state-of-the-art ISTD methods highly fragile in real-world challenges. In this paper, we first study the variation in detection performance across several mainstream methods under various scarcity -- namely, the absence of high-quality infrared data -- that challenge the prevailing theories about practical ISTD. To address this concern, we introduce the Gaussian Agnostic Representation Learning. Specifically, we propose the Gaussian Group Squeezer, leveraging Gaussian sampling and compression for non-uniform quantization. By exploiting a diverse array of training samples, we enhance the resilience of ISTD models against various challenges. Then, we introduce two-stage diffusion models for real-world reconstruction. By aligning quantized signals closely with real-world distributions, we significantly elevate the quality and fidelity of the synthetic samples. Comparative evaluations against state-of-the-art detection methods in various scarcity scenarios demonstrate the efficacy of the proposed approach.",
      "authors": [
        "Junyao Li",
        "Yahao Lu",
        "Xingyuan Guo",
        "Xiaoyu Xian",
        "Tiantian Wang",
        "Yukai Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:03:33+00:00",
          "link": "https://arxiv.org/abs/2507.18260v1",
          "size": "6056kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Gaussian Agnostic Representation Learning with Diffusion Priors for Enhanced Infrared Small Target Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18260",
        "HTML": "https://arxiv.org/html/2507.18260v1",
        "PDF": "https://arxiv.org/pdf/2507.18260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the use of Gaussian Agnostic Representation Learning and diffusion models for infrared small target detection. It does not contribute to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18262",
      "abstract": "Semantics-driven 3D spatial constraints align highlevel semantic representations with low-level action spaces, facilitating the unification of task understanding and execution in robotic manipulation. The synergistic reasoning of Multimodal Large Language Models (MLLMs) and Vision Foundation Models (VFMs) enables cross-modal 3D spatial constraint construction. Nevertheless, existing methods have three key limitations: (1) coarse semantic granularity in constraint modeling, (2) lack of real-time closed-loop planning, (3) compromised robustness in semantically diverse environments. To address these challenges, we propose ReSem3D, a unified manipulation framework for semantically diverse environments, leveraging the synergy between VFMs and MLLMs to achieve fine-grained visual grounding and dynamically constructs hierarchical 3D spatial constraints for real-time manipulation. Specifically, the framework is driven by hierarchical recursive reasoning in MLLMs, which interact with VFMs to automatically construct 3D spatial constraints from natural language instructions and RGB-D observations in two stages: part-level extraction and region-level refinement. Subsequently, these constraints are encoded as real-time optimization objectives in joint space, enabling reactive behavior to dynamic disturbances. Extensive simulation and real-world experiments are conducted in semantically rich household and sparse chemical lab environments. The results demonstrate that ReSem3D performs diverse manipulation tasks under zero-shot conditions, exhibiting strong adaptability and generalization. Code and videos at https://resem3d.github.io.",
      "authors": [
        "Chenyu Su",
        "Weiwei Shang",
        "Chen Qian",
        "Fei Zhang",
        "Shuang Cong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:07:31+00:00",
          "link": "https://arxiv.org/abs/2507.18262v1",
          "size": "19363kb",
          "version": "v1"
        }
      ],
      "title": "ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18262",
        "HTML": "https://arxiv.org/html/2507.18262v1",
        "PDF": "https://arxiv.org/pdf/2507.18262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robotic manipulation and 3D spatial constraints using Multimodal Large Language Models, which doesn't involve any discussion of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18263",
      "abstract": "Direct speech translation (ST) has garnered increasing attention nowadays, yet the accurate translation of terminology within utterances remains a great challenge. In this regard, current studies mainly concentrate on leveraging various translation knowledge into ST models. However, these methods often struggle with interference from irrelevant noise and can not fully utilize the translation knowledge. To address these issues, in this paper, we propose a novel Locate-and-Focus method for terminology translation. It first effectively locates the speech clips containing terminologies within the utterance to construct translation knowledge, minimizing irrelevant information for the ST model. Subsequently, it associates the translation knowledge with the utterance and hypothesis from both audio and textual modalities, allowing the ST model to better focus on translation knowledge during translation. Experimental results across various datasets demonstrate that our method effectively locates terminologies within utterances and enhances the success rate of terminology translation, while maintaining robust general translation performance.",
      "authors": [
        "Suhang Wu",
        "Jialong Tang",
        "Chengyi Yang",
        "Pei Zhang",
        "Baosong Yang",
        "Junhui Li",
        "Junfeng Yao",
        "Min Zhang",
        "Jinsong Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:07:59+00:00",
          "link": "https://arxiv.org/abs/2507.18263v1",
          "size": "1299kb",
          "version": "v1"
        }
      ],
      "title": "Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18263",
        "HTML": "https://arxiv.org/html/2507.18263v1",
        "PDF": "https://arxiv.org/pdf/2507.18263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method for enhancing terminology translation in speech language models, discussing aspects of processing translation knowledge. Although it involves data processing, its primary focus is on improving model translation performance rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18264",
      "abstract": "Solving the problem of Optical Character Recognition (OCR) on printed text for Latin and its derivative scripts can now be considered settled due to the volumes of research done on English and other High-Resourced Languages (HRL). However, for Low-Resourced Languages (LRL) that use unique scripts, it remains an open problem. This study presents a comparative analysis of the zero-shot performance of six distinct OCR engines on two LRLs: Sinhala and Tamil. The selected engines include both commercial and open-source systems, aiming to evaluate the strengths of each category. The Cloud Vision API, Surya, Document AI, and Tesseract were evaluated for both Sinhala and Tamil, while Subasa OCR and EasyOCR were examined for only one language due to their limitations. The performance of these systems was rigorously analysed using five measurement techniques to assess accuracy at both the character and word levels. According to the findings, Surya delivered the best performance for Sinhala across all metrics, with a WER of 2.61%. Conversely, Document AI excelled across all metrics for Tamil, highlighted by a very low CER of 0.78%. In addition to the above analysis, we also introduce a novel synthetic Tamil OCR benchmarking dataset.",
      "authors": [
        "Nevidu Jayatilleke",
        "Nisansa de Silva"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:08:43+00:00",
          "link": "https://arxiv.org/abs/2507.18264v1",
          "size": "9527kb",
          "version": "v1"
        }
      ],
      "title": "Zero-shot OCR Accuracy of Low-Resourced Languages: A Comparative Analysis on Sinhala and Tamil",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18264",
        "HTML": "https://arxiv.org/html/2507.18264v1",
        "PDF": "https://arxiv.org/pdf/2507.18264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces a synthetic dataset for Tamil OCR benchmarking, which could be seen as a contribution to data creation. However, it focuses primarily on OCR evaluation rather than LLM pretraining or fine-tuning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18267",
      "abstract": "Embodied Artificial Intelligence Robots (EAIR) is an emerging and rapidly evolving technological domain. Ensuring their program correctness is fundamental to their successful deployment. However, a general and in-depth understanding of EAIR system bugs remains lacking, which hinders the development of practices and techniques to tackle EAIR system bugs.\n  To bridge this gap, we conducted the first systematic study of 885 EAIR system bugs collected from 80 EAIR system projects to investigate their symptoms, underlying causes, and module distribution. Our analysis takes considerable effort, which classifies these bugs into 18 underlying causes, 15 distinct symptoms, and identifies 13 affected modules. It reveals several new interesting findings and implications which help shed light on future research on tackling or repairing EAIR system bugs. First, among the 15 identified symptoms, our findings highlight 8 symptoms specific to EAIR systems, which is characterized by severe functional failures and potential physical hazards. Second, within the 18 underlying causes, we define 8 EAIR-specific causes, the majority of which stem from the intricate issues of AI- agent reasoning and decision making. Finally, to facilitate precise and efficient bug prediction, detection, and repair, we constructed a mapping between underlying causes and the modules in which they most frequently occur, which enables researchers to focus diagnostic efforts on the modules most susceptible to specific bug types.",
      "authors": [
        "Zeqin Liao",
        "Zibin Zheng",
        "Peifan Reng",
        "Henglong Liang",
        "Zixu Gao",
        "Zhixiang Chen",
        "Wei Li",
        "Yuhong Nan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:11:45+00:00",
          "link": "https://arxiv.org/abs/2507.18267v1",
          "size": "871kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18267",
        "HTML": "https://arxiv.org/html/2507.18267v1",
        "PDF": "https://arxiv.org/pdf/2507.18267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study on bugs in Embodied AI Robots does not address LLM training data processing but rather focuses on software bug analysis in AI robotics systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18268",
      "abstract": "The modern trend in High-Performance Computing (HPC) involves the use of accelerators such as Graphics Processing Units (GPUs) alongside Central Processing Units (CPUs) to speed up numerical operations in various applications. Leading manufacturers such as NVIDIA, Intel, and AMD are constantly advancing these architectures, augmenting them with features such as mixed precision, enhanced memory hierarchies, and specialised accelerator silicon blocks (e.g., Tensor Cores on GPU or AMX/SME engines on CPU) to enhance compute performance. At the same time, significant efforts in software development are aimed at optimizing the use of these innovations, seeking to improve usability and accessibility. This work contributes to the state-of-the-art of OpenFOAM development by presenting a working Proof-Of-Concept application built using modern ISO C++ parallel constructs. This approach, combined with an appropriate compiler runtime stack, like the one provided by the NVIDIA HPC SDK, makes it possible to accelerate well-defined kernels, allowing multi-core execution and GPU offloading using a single codebase. The study demonstrates that it is possible to increase the performance of the OpenFOAM laplacianFoam application by offloading the computations on NVIDIA GPUs using the C++ parallel construct.",
      "authors": [
        "Giulio Malenza",
        "Giovanni Stabile",
        "Filippo Spiga",
        "Robert Birke",
        "Marco Aldinucci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Mathematical Software (cs.MS)",
        "Performance (cs.PF)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:12:00+00:00",
          "link": "https://arxiv.org/abs/2507.18268v1",
          "size": "796kb",
          "version": "v1"
        }
      ],
      "title": "Building an Accelerated OpenFOAM Proof-of-Concept Application using Modern C++",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18268",
        "HTML": "https://arxiv.org/html/2507.18268v1",
        "PDF": "https://arxiv.org/pdf/2507.18268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about improving computational performance in OpenFOAM using modern C++ for HPC applications. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18269",
      "abstract": "To extend healthy life expectancy in an aging society, it is crucial to prevent various diseases at pre-disease states. Although dynamical network biomarker theory has been developed for pre-disease detection, mathematical frameworks for pre-disease treatment have not been well established. Here I propose a control theory-based approach for pre-disease treatment, named Markov chain sparse control (MCSC), where time evolution of a probability distribution on a Markov chain is described as a discrete-time linear system. By designing a sparse controller, a few candidate states for intervention are identified. The validity of MCSC is demonstrated using numerical simulations and real-data analysis.",
      "authors": [
        "Makito Oku"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:12:01+00:00",
          "link": "https://arxiv.org/abs/2507.18269v1",
          "size": "2969kb",
          "version": "v1"
        }
      ],
      "title": "Designing efficient interventions for pre-disease states using control theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18269",
        "HTML": "https://arxiv.org/html/2507.18269v1",
        "PDF": "https://arxiv.org/pdf/2507.18269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a control theory-based approach for pre-disease treatment, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18276",
      "abstract": "Articulated objects pose diverse manipulation challenges for robots. Since their internal structures are not directly observable, robots must adaptively explore and refine actions to generate successful manipulation trajectories. While existing works have attempted cross-category generalization in adaptive articulated object manipulation, two major challenges persist: (1) the geometric diversity of real-world articulated objects complicates visual perception and understanding, and (2) variations in object functions and mechanisms hinder the development of a unified adaptive manipulation strategy. To address these challenges, we propose AdaRPG, a novel framework that leverages foundation models to extract object parts, which exhibit greater local geometric similarity than entire objects, thereby enhancing visual affordance generalization for functional primitive skills. To support this, we construct a part-level affordance annotation dataset to train the affordance model. Additionally, AdaRPG utilizes the common knowledge embedded in foundation models to reason about complex mechanisms and generate high-level control codes that invoke primitive skill functions based on part affordance inference. Simulation and real-world experiments demonstrate AdaRPG's strong generalization ability across novel articulated object categories.",
      "authors": [
        "Xiaojie Zhang",
        "Yuanfei Wang",
        "Ruihai Wu",
        "Kunqi Xu",
        "Yu Li",
        "Liuyu Xiang",
        "Hao Dong",
        "Zhaofeng He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:25:58+00:00",
          "link": "https://arxiv.org/abs/2507.18276v1",
          "size": "6986kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18276",
        "HTML": "https://arxiv.org/html/2507.18276v1",
        "PDF": "https://arxiv.org/pdf/2507.18276"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for articulated object manipulation and involves creating a dataset for part-level affordance annotation. However, it does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18281",
      "abstract": "The Persistent Perfect phylogeny, also known as Dollo-1, has been introduced as a generalization of the well-known perfect phylogenetic model for binary characters to deal with the potential loss of characters. The problem of deciding the existence of a Persistent Perfect phylogeny can be reduced to the one of recognizing a class of bipartite graphs whose nodes are species and characters. Thus an interesting question is solving directly the problem of recognizing such graphs. We present a polynomial-time algorithm for deciding Persistent Perfect phylogeny existence in maximal graphs, where no character's species set is contained within another character's species set. Our solution, that relies only on graph properties, narrows the gap between the linear-time simple algorithm for Perfect Phylogeny and the NP-hardness results for the Dollo-$k$ phylogeny with $k>1$.",
      "authors": [
        "Paola Bonizzoni",
        "Gianluca Della Vedova",
        "Mauricio Soto Gomez",
        "Gabriella Trucco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:31:42+00:00",
          "link": "https://arxiv.org/abs/2507.18281v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "On recognizing graphs representing Persistent Perfect Phylogenies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18281",
        "HTML": "https://arxiv.org/html/2507.18281v1",
        "PDF": "https://arxiv.org/pdf/2507.18281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses problems related to phylogenetic graph recognition and algorithms, which lacks any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18282",
      "abstract": "An algorithm named EigenWave is described to compute eigenvalues and eigenvectors of elliptic boundary value problems. The algorithm, based on the recently developed WaveHoltz scheme, solves a related time-dependent wave equation as part of an iteration. At each iteration, the solution to the wave equation is filtered in time. As the iteration progresses, the filtered solution generally contains relatively larger and larger proportions of eigenmodes whose eigenvalues are near a chosen target frequency (target eigenvalue). The ability to choose an arbitrary target frequency enables the computation of eigenvalues anywhere in the spectrum, without the need to invert an indefinite matrix, as is common with other approaches. Furthermore, the iteration can be embedded within a matrix-free Arnoldi algorithm, which enables the efficient computation of multiple eigenpairs near the target frequency. For efficiency, the time-dependent wave equation can be solved with implicit time-stepping and only about $10$ time-steps per-period are needed, independent of the mesh spacing. When the (definite) implicit time-stepping equations are solved with a multigrid algorithm, the cost of the resulting EigenWave scheme scales linearly with the number of grid points $N$ as the mesh is refined, giving an optimal $O(N)$ algorithm. The approach is demonstrated by finding eigenpairs of the Laplacian in complex geometry using overset grids. Results in two and three space dimensions are presented using second-order and fourth-order accurate approximations.",
      "authors": [
        "Daniel Appelo and Jeffrey W. Banks and William D. Henshaw and Ngan Le and Donald W. Schwendeman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:33:18+00:00",
          "link": "https://arxiv.org/abs/2507.18282v1",
          "size": "7110kb",
          "version": "v1"
        }
      ],
      "title": "EigenWave: An Optimal O(N) Method for Computing Eigenvalues and Eigenvectors by Time-Filtering the Wave Equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18282",
        "PDF": "https://arxiv.org/pdf/2507.18282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes an algorithm for computing eigenvalues and eigenvectors, with no relation to LLM training or data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18284",
      "abstract": "Autonomous traffic agents (ATAs) are expected to act in ways tat are not only safe, but also aligned with stakeholder values across legal, social, and moral dimensions. In this paper, we adopt an established formal model of conflict from epistemic game theory to support the development of such agents. We focus on value conflicts-situations in which agents face competing goals rooted in value-laden situations and show how conflict analysis can inform key phases of the design process. This includes value elicitation, capability specification, explanation, and adaptive system refinement. We elaborate and apply the concept of Value-Aligned Operational Design Domains (VODDs) to structure autonomy in accordance with contextual value priorities. Our approach shifts the emphasis from solving moral dilemmas at runtime to anticipating and structuring value-sensitive behaviour during development.",
      "authors": [
        "Astrid Rakow and Joe Collenette and Maike Schwammberger and Marija Slavkovik and Gleifer Vs Alves"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:37:00+00:00",
          "link": "https://arxiv.org/abs/2507.18284v1",
          "size": "734kb",
          "version": "v1"
        }
      ],
      "title": "Designing Value-Aligned Traffic Agents through Conflict Sensitivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18284",
        "HTML": "https://arxiv.org/html/2507.18284v1",
        "PDF": "https://arxiv.org/pdf/2507.18284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on designing value-aligned autonomous traffic agents using conflict analysis, unrelated to data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18287",
      "abstract": "Periodontitis and dental caries are common oral diseases affecting billions globally. While observational studies suggest links between these conditions and lung cancer, causality remains uncertain. This study used two sample Mendelian randomization (MR) to explore causal relationships between dental traits (periodontitis, dental caries) and lung cancer subtypes, and to assess mediation by pulmonary function. Genetic instruments were derived from the largest available genome wide association studies, including data from 487,823 dental caries and 506,594 periodontitis cases, as well as lung cancer data from the Transdisciplinary Research of Cancer in Lung consortium. Inverse variance weighting was the main analytical method; lung function mediation was assessed using the delta method. The results showed a significant positive causal effect of dental caries on overall lung cancer and its subtypes. Specifically, a one standard deviation increase in dental caries incidence was associated with a 188.0% higher risk of squamous cell lung carcinoma (OR = 2.880, 95% CI = 1.236--6.713, p = 0.014), partially mediated by declines in forced vital capacity (FVC) and forced expiratory volume in one second (FEV1), accounting for 5.124% and 5.890% of the total effect. No causal effect was found for periodontitis. These findings highlight a causal role of dental caries in lung cancer risk and support integrating dental care and pulmonary function monitoring into cancer prevention strategies.",
      "authors": [
        "Wenran Zhang",
        "Huihuan Luo",
        "Linda Wei",
        "Ping Nie",
        "Yiqun Wu",
        "Dedong Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:46:43+00:00",
          "link": "https://arxiv.org/abs/2507.18287v1",
          "size": "6658kb",
          "version": "v1"
        }
      ],
      "title": "Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18287",
        "HTML": "https://arxiv.org/html/2507.18287v1",
        "PDF": "https://arxiv.org/pdf/2507.18287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the causal relationship between dental caries and lung cancer using Mendelian randomization, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18289",
      "abstract": "Fuzzing a library requires experts to understand the library usage well and craft high-quality fuzz drivers, which is tricky and tedious. Therefore, many techniques have been proposed to automatically generate fuzz drivers. However, they fail to generate rational fuzz drivers due to the lack of adherence to proper library usage conventions, such as ensuring a resource is closed after being opened. To make things worse, existing library fuzzing techniques unconditionally execute each driver, resulting in numerous irrational drivers that waste computational resources while contributing little coverage and generating false positive bug reports.\n  To tackle these challenges, we propose a novel automatic library fuzzing technique, Scheduzz, an LLM-based library fuzzing technique. It leverages LLMs to understand rational usage of libraries and extract API combination constraints. To optimize computational resource utilization, a dual scheduling framework is implemented to efficiently manage API combinations and fuzz drivers. The framework models driver generation and the corresponding fuzzing campaign as an online optimization problem. Within the scheduling loop, multiple API combinations are selected to generate fuzz drivers, while simultaneously, various optimized fuzz drivers are scheduled for execution or suspension.\n  We implemented Scheduzz and evaluated it in 33 real-world libraries. Compared to baseline approaches, Scheduzz significantly reduces computational overhead and outperforms UTopia on 16 out of 21 libraries. It achieves 1.62x, 1.50x, and 1.89x higher overall coverage than the state-of-the-art techniques CKGFuzzer, Promptfuzz, and the handcrafted project OSS-Fuzz, respectively. In addition, Scheduzz discovered 33 previously unknown bugs in these well-tested libraries, 3 of which have been assigned CVEs.",
      "authors": [
        "Yan Li",
        "Wenzhang Yang",
        "Yuekun Wang",
        "Jian Gao",
        "Shaohua Wang",
        "Yinxing Xue",
        "Lijun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:51:11+00:00",
          "link": "https://arxiv.org/abs/2507.18289v1",
          "size": "961kb",
          "version": "v1"
        }
      ],
      "title": "Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18289",
        "HTML": "https://arxiv.org/html/2507.18289v1",
        "PDF": "https://arxiv.org/pdf/2507.18289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Scheduzz is a library fuzzing technique leveraging LLMs to generate fuzz drivers, focusing on optimization in fuzz testing rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18290",
      "abstract": "This chapter introduces a conceptual framework for qualitative risk assessment of AI, particularly in the context of the EU AI Act. The framework addresses the complexities of legal compliance and fundamental rights protection by itegrating definitional balancing and defeasible reasoning. Definitional balancing employs proportionality analysis to resolve conflicts between competing rights, while defeasible reasoning accommodates the dynamic nature of legal decision-making. Our approach stresses the need for an analysis of AI deployment scenarios and for identifying potential legal violations and multi-layered impacts on fundamental rights. On the basis of this analysis, we provide philosophical foundations for a logical account of AI risk analysis. In particular, we consider the basic building blocks for conceptually grasping the interaction between AI deployment scenarios and fundamental rights, incorporating in defeasible reasoning definitional balancing and arguments about the contextual promotion or demotion of rights. This layered approach allows for more operative models of assessment of both high-risk AI systems and General Purpose AI (GPAI) systems, emphasizing the broader applicability of the latter. Future work aims to develop a formal model and effective algorithms to enhance AI risk assessment, bridging theoretical insights with practical applications to support responsible AI governance.",
      "authors": [
        "Antonino Rotolo",
        "Beatrice Ferrigno",
        "Jose Miguel Angel Garcia Godinez",
        "Claudio Novelli",
        "Giovanni Sartor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:52:22+00:00",
          "link": "https://arxiv.org/abs/2507.18290v1",
          "size": "154kb",
          "version": "v1"
        }
      ],
      "title": "Foundations for Risk Assessment of AI in Protecting Fundamental Rights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18290",
        "HTML": "https://arxiv.org/html/2507.18290v1",
        "PDF": "https://arxiv.org/pdf/2507.18290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a framework for AI risk assessment, focusing on legal compliance and rights protection, without contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18293",
      "abstract": "Predictive Process Monitoring (PPM) enables forecasting future events or outcomes of ongoing business process instances based on event logs. However, deep learning PPM approaches are often limited by the low variability and small size of real-world event logs. To address this, we introduce SiamSA-PPM, a novel self-supervised learning framework that combines Siamese learning with Statistical Augmentation for Predictive Process Monitoring. It employs three novel statistically grounded transformation methods that leverage control-flow semantics and frequent behavioral patterns to generate realistic, semantically valid new trace variants. These augmented views are used within a Siamese learning setup to learn generalizable representations of process prefixes without the need for labeled supervision. Extensive experiments on real-life event logs demonstrate that SiamSA-PPM achieves competitive or superior performance compared to the SOTA in both next activity and final outcome prediction tasks. Our results further show that statistical augmentation significantly outperforms random transformations and improves variability in the data, highlighting SiamSA-PPM as a promising direction for training data enrichment in process prediction.",
      "authors": [
        "Sjoerd van Straten",
        "Alessandro Padella",
        "Marwan Hassani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:57:20+00:00",
          "link": "https://arxiv.org/abs/2507.18293v1",
          "size": "1347kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Data Augmentation and Siamese Learning for Predictive Process Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18293",
        "HTML": "https://arxiv.org/html/2507.18293v1",
        "PDF": "https://arxiv.org/pdf/2507.18293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces SiamSA-PPM, which uses data augmentation techniques to improve predictive process monitoring, a concept that can align with data generation for training AI models, but it is not specifically targeted at LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18294",
      "abstract": "Adapting LLMs to specific stylistic characteristics, like brand voice or authorial tones, is crucial for enterprise communication but challenging to achieve from corpora which lacks instruction-response formatting without compromising instruction adherence. We introduce StyleAdaptedLM, a framework that efficiently transfers stylistic traits to instruction-following models using Low-Rank Adaptation (LoRA). LoRA adapters are first trained on a base model with diverse unstructured stylistic corpora, then merged with a separate instruction-following model. This enables robust stylistic customization without paired data or sacrificing task performance. Experiments across multiple datasets and models demonstrate improved stylistic consistency while preserving instruction adherence, with human evaluations confirming brand-specific convention uptake. StyleAdaptedLM offers an efficient path for stylistic personalization in LLMs.",
      "authors": [
        "Pritika Ramu",
        "Apoorv Saxena",
        "Meghanath M Y",
        "Varsha Sankar",
        "Debraj Basu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:57:32+00:00",
          "link": "https://arxiv.org/abs/2507.18294v1",
          "size": "770kb",
          "version": "v1"
        }
      ],
      "title": "StyleAdaptedLM: Enhancing Instruction Following Models with Efficient Stylistic Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18294",
        "HTML": "https://arxiv.org/html/2507.18294v1",
        "PDF": "https://arxiv.org/pdf/2507.18294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces StyleAdaptedLM, a framework for stylistic transfer in LLMs, involving data processing for stylistic customization. However, it primarily focuses on model adaptation techniques rather than direct contributions to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18297",
      "abstract": "Due to the high computational load of modern numerical simulation, there is a demand for approaches that would reduce the size of discrete problems while keeping the accuracy reasonable. In this work, we present an original algorithm to coarsen an unstructured grid based on the concepts of differentiable physics. We achieve this by employing k-means clustering, autodifferentiation and stochastic minimization algorithms. We demonstrate performance of the designed algorithm on two PDEs: a linear parabolic equation which governs slightly compressible fluid flow in porous media and the wave equation. Our results show that in the considered scenarios, we reduced the number of grid points up to 10 times while preserving the modeled variable dynamics in the points of interest. The proposed approach can be applied to the simulation of an arbitrary system described by evolutionary partial differential equations.",
      "authors": [
        "Sergei Shumilin",
        "Alexander Ryabov",
        "Nikolay Yavich",
        "Evgeny Burnaev",
        "Vladimir Vanovskiy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:02:13+00:00",
          "link": "https://arxiv.org/abs/2507.18297v1",
          "size": "10729kb",
          "version": "v1"
        }
      ],
      "title": "Self-Supervised Coarsening of Unstructured Grid with Automatic Differentiation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18297",
        "HTML": "https://arxiv.org/html/2507.18297v1",
        "PDF": "https://arxiv.org/pdf/2507.18297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses coarsening of unstructured grids for numerical simulations using physics-based algorithms, with no mention of LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18300",
      "abstract": "Large multimodal models (LMMs) have garnered wide-spread attention and interest within the artificial intelligence research and industrial communities, owing to their remarkable capability in multimodal understanding, reasoning, and in-context learning, among others. While LMMs have demonstrated promising results in tackling multimodal tasks like image captioning, visual question answering, and visual grounding, the object detection capabilities of LMMs exhibit a significant gap compared to specialist detectors. To bridge the gap, we depart from the conventional methods of integrating heavy detectors with LMMs and propose LMM-Det, a simple yet effective approach that leverages a Large Multimodal Model for vanilla object Detection without relying on specialized detection modules. Specifically, we conduct a comprehensive exploratory analysis when a large multimodal model meets with object detection, revealing that the recall rate degrades significantly compared with specialist detection models. To mitigate this, we propose to increase the recall rate by introducing data distribution adjustment and inference optimization tailored for object detection. We re-organize the instruction conversations to enhance the object detection capabilities of large multimodal models. We claim that a large multimodal model possesses detection capability without any extra detection modules. Extensive experiments support our claim and show the effectiveness of the versatile LMM-Det. The datasets, models, and codes are available at https://github.com/360CVGroup/LMM-Det.",
      "authors": [
        "Jincheng Li",
        "Chunyu Xie",
        "Ji Ao",
        "Dawei Leng",
        "Yuhui Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:05:24+00:00",
          "link": "https://arxiv.org/abs/2507.18300v1",
          "size": "8318kb",
          "version": "v1"
        }
      ],
      "title": "LMM-Det: Make Large Multimodal Models Excel in Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18300",
        "HTML": "https://arxiv.org/html/2507.18300v1",
        "PDF": "https://arxiv.org/pdf/2507.18300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on improving object detection capabilities in large multimodal models, which does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18302",
      "abstract": "Language Models (LMs) typically adhere to a \"pre-training and fine-tuning\" paradigm, where a universal pre-trained model can be fine-tuned to cater to various specialized domains. Low-Rank Adaptation (LoRA) has gained the most widespread use in LM fine-tuning due to its lightweight computational cost and remarkable performance. Because the proportion of parameters tuned by LoRA is relatively small, there might be a misleading impression that the LoRA fine-tuning data is invulnerable to Membership Inference Attacks (MIAs). However, we identify that utilizing the pre-trained model can induce more information leakage, which is neglected by existing MIAs. Therefore, we introduce LoRA-Leak, a holistic evaluation framework for MIAs against the fine-tuning datasets of LMs. LoRA-Leak incorporates fifteen membership inference attacks, including ten existing MIAs, and five improved MIAs that leverage the pre-trained model as a reference. In experiments, we apply LoRA-Leak to three advanced LMs across three popular natural language processing tasks, demonstrating that LoRA-based fine-tuned LMs are still vulnerable to MIAs (e.g., 0.775 AUC under conservative fine-tuning settings). We also applied LoRA-Leak to different fine-tuning settings to understand the resulting privacy risks. We further explore four defenses and find that only dropout and excluding specific LM layers during fine-tuning effectively mitigate MIA risks while maintaining utility. We highlight that under the \"pre-training and fine-tuning\" paradigm, the existence of the pre-trained model makes MIA a more severe risk for LoRA-based LMs. We hope that our findings can provide guidance on data privacy protection for specialized LM providers.",
      "authors": [
        "Delong Ran",
        "Xinlei He",
        "Tianshuo Cong",
        "Anyu Wang",
        "Qi Li",
        "Xiaoyun Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:18:27+00:00",
          "link": "https://arxiv.org/abs/2507.18302v1",
          "size": "904kb",
          "version": "v1"
        }
      ],
      "title": "LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18302",
        "PDF": "https://arxiv.org/pdf/2507.18302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses membership inference attacks against models fine-tuned via LoRA, focusing on privacy concerns rather than making any contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18305",
      "abstract": "Large reasoning models (LRMs) have emerged as a significant advancement in artificial intelligence, representing a specialized class of large language models (LLMs) designed to tackle complex reasoning tasks. The defining characteristic of LRMs lies in their extensive chain-of-thought (CoT) reasoning capabilities. In this paper, we identify a previously unexplored attack vector against LRMs, which we term \"overthinking backdoors\". We advance this concept by proposing a novel tunable backdoor, which moves beyond simple on/off attacks to one where an attacker can precisely control the extent of the model's reasoning verbosity. Our attack is implemented through a novel data poisoning methodology. It pairs a tunable trigger-where the number of repetitions signals the desired intensity-with a correspondingly verbose CoT response. These responses are programmatically generated by instructing a teacher LLM to inject a controlled number of redundant refinement steps into a correct reasoning process. The approach preserves output correctness, which ensures stealth and establishes the attack as a pure resource-consumption vector. Extensive empirical results on various LRMs demonstrate that our method can reliably trigger a controllable, multi-fold increase in the length of the reasoning process, without degrading the final answer's correctness. Our source code is available at https://github.com/FZaKK/BadReasoner.",
      "authors": [
        "Biao Yi",
        "Zekun Fei",
        "Jianing Geng",
        "Tong Li",
        "Lihai Nie",
        "Zheli Liu",
        "and Yiming Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:24:35+00:00",
          "link": "https://arxiv.org/abs/2507.18305v1",
          "size": "852kb",
          "version": "v1"
        }
      ],
      "title": "BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18305",
        "HTML": "https://arxiv.org/html/2507.18305v1",
        "PDF": "https://arxiv.org/pdf/2507.18305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores security attack vectors in reasoning models and introduces data poisoning techniques, which do not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18309",
      "abstract": "This paper introduces a new approach to solving the thrust allocation problem using the maneuvering problem in the maritime domain for fully actuated vessels. The method uses a control Lyapunov function to create a nonlinear reference filter for the thruster forces. The filter ensures dynamic tracking of the optimal thrust allocation solution with rate limitation in the output thruster references. It further uses control barrier functions to ensure that the thruster force saturation limits are respected. The approach aims for simplicity and effectiveness, as well as smooth and dynamic thruster reference signals, in the implementation of thrust allocation for marine vessels.",
      "authors": [
        "Emir Cem Gezer",
        "Roger Skjetne"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:26:44+00:00",
          "link": "https://arxiv.org/abs/2507.18309v1",
          "size": "1142kb",
          "version": "v1"
        }
      ],
      "title": "Maneuvering-based Dynamic Thrust Allocation for Fully-Actuated Vessels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18309",
        "HTML": "https://arxiv.org/html/2507.18309v1",
        "PDF": "https://arxiv.org/pdf/2507.18309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on thrust allocation for fully actuated maritime vessels using control Lyapunov functions and control barrier functions, which has no connection to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18311",
      "abstract": "Large Vision-Language Models (LVLMs) have shown impressive capabilities across a range of tasks that integrate visual and textual understanding, such as image captioning and visual question answering. These models are trained on large-scale image and video datasets paired with text, enabling them to bridge visual perception and natural language processing. However, their application to scientific domains, especially in interpreting complex field data commonly used in the natural sciences, remains underexplored. In this work, we introduce FieldLVLM, a novel framework designed to improve large vision-language models' understanding of field data. FieldLVLM consists of two main components: a field-aware language generation strategy and a data-compressed multimodal model tuning. The field-aware language generation strategy leverages a special-purpose machine learning pipeline to extract key physical features from field data, such as flow classification, Reynolds number, and vortex patterns. This information is then converted into structured textual descriptions that serve as a dataset. The data-compressed multimodal model tuning focuses on LVLMs with these generated datasets, using a data compression strategy to reduce the complexity of field inputs and retain only the most informative values. This ensures compatibility with the models language decoder and guides its learning more effectively. Experimental results on newly proposed benchmark datasets demonstrate that FieldLVLM significantly outperforms existing methods in tasks involving scientific field data. Our findings suggest that this approach opens up new possibilities for applying large vision-language models to scientific research, helping bridge the gap between large models and domain-specific discovery.",
      "authors": [
        "Xiaomei Zhang",
        "Hanyu Zheng",
        "Xiangyu Zhu",
        "Jinghuan Wei",
        "Junhong Zou",
        "Zhen Lei",
        "Zhaoxiang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:28:53+00:00",
          "link": "https://arxiv.org/abs/2507.18311v1",
          "size": "14805kb",
          "version": "v1"
        }
      ],
      "title": "Improving Large Vision-Language Models' Understanding for Field Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18311",
        "HTML": "https://arxiv.org/html/2507.18311v1",
        "PDF": "https://arxiv.org/pdf/2507.18311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces FieldLVLM to improve vision-language model understanding through field-aware language generation and data compression strategies, the primary focus is on model performance enhancement, with only a partial discussion on dataset creation and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18313",
      "abstract": "Malware evolves rapidly, forcing machine learning (ML)-based detectors to adapt continuously. With antivirus vendors processing hundreds of thousands of new samples daily, datasets can grow to billions of examples, making full retraining impractical. Continual learning (CL) has emerged as a scalable alternative, enabling incremental updates without full data access while mitigating catastrophic forgetting. In this work, we analyze a critical yet overlooked issue in this context: security regression. Unlike forgetting, which manifests as a general performance drop on previously seen data, security regression captures harmful prediction changes at the sample level, such as a malware sample that was once correctly detected but evades detection after a model update. Although often overlooked, regressions pose serious risks in security-critical applications, as the silent reintroduction of previously detected threats in the system may undermine users' trust in the whole updating process. To address this issue, we formalize and quantify security regression in CL-based malware detectors and propose a regression-aware penalty to mitigate it. Specifically, we adapt Positive Congruent Training (PCT) to the CL setting, preserving prior predictive behavior in a model-agnostic manner. Experiments on the ELSA, Tesseract, and AZ-Class datasets show that our method effectively reduces regression across different CL scenarios while maintaining strong detection performance over time.",
      "authors": [
        "Daniele Ghiani",
        "Daniele Angioni",
        "Giorgio Piras",
        "Angelo Sotgiu",
        "Luca Minnei",
        "Srishti Gupta",
        "Maura Pintor",
        "Fabio Roli",
        "Battista Biggio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:31:23+00:00",
          "link": "https://arxiv.org/abs/2507.18313v1",
          "size": "2608kb",
          "version": "v1"
        }
      ],
      "title": "Regression-aware Continual Learning for Android Malware Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18313",
        "HTML": "https://arxiv.org/html/2507.18313v1",
        "PDF": "https://arxiv.org/pdf/2507.18313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work addresses continual learning for Android malware detection, focusing on security regression and positive congruent training techniques, without discussing LLM training data processing or datasets relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18315",
      "abstract": "Speech disfluencies play a role in perspective-taking and audience design in human-human communication (HHC), but little is known about their impact in human-machine dialogue (HMD). In an online Namer-Matcher task, sixty-one participants interacted with a speech agent using either fluent or disfluent speech. Participants completed a partner-modelling questionnaire (PMQ) both before and after the task. Post-interaction evaluations indicated that participants perceived the disfluent agent as more competent, despite no significant differences in pre-task ratings. However, no notable differences were observed in assessments of conversational flexibility or human-likeness. Our findings also reveal evidence of egocentric and allocentric language production when participants interact with speech agents. Interaction with disfluent speech agents appears to increase egocentric communication in comparison to fluent agents. Although the wide credibility intervals mean this effect is not clear-cut. We discuss potential interpretations of this finding, focusing on how disfluencies may impact partner models and language production in HMD.",
      "authors": [
        "Rhys Jacka",
        "Paola R. Pe\\~na",
        "Sophie Leonard",
        "\\'Eva Sz\\'ekely and Benjamin R. Cowan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:32:11+00:00",
          "link": "https://arxiv.org/abs/2507.18315v1",
          "size": "552kb",
          "version": "v1"
        }
      ],
      "title": "Talking to...uh...um...Machines: The Impact of Disfluent Speech Agents on Partner Models and Perspective Taking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18315",
        "HTML": "https://arxiv.org/html/2507.18315v1",
        "PDF": "https://arxiv.org/pdf/2507.18315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research centers on human-machine dialogue and the effects of disfluent speech, with no mention of data processing for LLMs or dataset-related contributions pertinent to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18316",
      "abstract": "Recent advances in automated test generation utilises language models to produce unit tests. While effective, language models tend to generate many incorrect tests with respect to both syntax and semantics. Although such incorrect tests can be easily detected and discarded, they constitute a \"missed opportunity\" -- if fixed, they are often valuable as they directly add testing value (they effectively target the underlying program logic to be tested) and indirectly form good seeds for generating additional tests. To this end, we propose a simple technique for repairing some of these incorrect tests through a combination of rule-based static analysis and re-prompting. We evaluate this simple approach, named YATE, on a set of 6 open-source projects and show that it can effectively produce tests that cover on average 32.06% more lines and kill 21.77% more mutants than a plain LLM-based method. We also compare YATE with four other LLM-based methods, namely HITS, SYMPROMPT, TESTSPARK and COVERUP and show that it produces tests that cover substantially more code. YATE achieves 22% higher line coverage, 20% higher branch coverage and kill 20% more mutants at a comparable cost (number of calls to LLMs).",
      "authors": [
        "Michael Konstantinou",
        "Renzo Degiovanni",
        "Jie M. Zhang",
        "Mark Harman",
        "Mike Papadakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:32:31+00:00",
          "link": "https://arxiv.org/abs/2507.18316v1",
          "size": "168kb",
          "version": "v1"
        }
      ],
      "title": "YATE: The Role of Test Repair in LLM-Based Unit Test Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18316",
        "HTML": "https://arxiv.org/html/2507.18316v1",
        "PDF": "https://arxiv.org/pdf/2507.18316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper outlines YATE, a method to repair incorrect unit tests generated by LLMs. Although it involves data processing for unit tests, the focus is on enhancing test generation rather than training data processing for language models specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18317",
      "abstract": "In robotic navigation, maintaining precise pose estimation and navigation in complex and dynamic environments is crucial. However, environmental challenges such as smoke, tunnels, and adverse weather can significantly degrade the performance of single-sensor systems like LiDAR or GPS, compromising the overall stability and safety of autonomous robots. To address these challenges, we propose AF-RLIO: an adaptive fusion approach that integrates 4D millimeter-wave radar, LiDAR, inertial measurement unit (IMU), and GPS to leverage the complementary strengths of these sensors for robust odometry estimation in complex environments. Our method consists of three key modules. Firstly, the pre-processing module utilizes radar data to assist LiDAR in removing dynamic points and determining when environmental conditions are degraded for LiDAR. Secondly, the dynamic-aware multimodal odometry selects appropriate point cloud data for scan-to-map matching and tightly couples it with the IMU using the Iterative Error State Kalman Filter. Lastly, the factor graph optimization module balances weights between odometry and GPS data, constructing a pose graph for optimization. The proposed approach has been evaluated on datasets and tested in real-world robotic environments, demonstrating its effectiveness and advantages over existing methods in challenging conditions such as smoke and tunnels.",
      "authors": [
        "Chenglong Qian",
        "Yang Xu",
        "Xiufang Shi",
        "Jiming Chen",
        "and Liang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:37:44+00:00",
          "link": "https://arxiv.org/abs/2507.18317v1",
          "size": "10356kb",
          "version": "v1"
        }
      ],
      "title": "AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18317",
        "HTML": "https://arxiv.org/html/2507.18317v1",
        "PDF": "https://arxiv.org/pdf/2507.18317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adaptive fusion of sensor data for robotics navigation, which is unrelated to LLM training data processing. It does not involve any aspect of data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18318",
      "abstract": "The present research is developed into the realm of industrial design engineering and additive manufacturing by introducing a parametric design model and adaptive mechanical analysis for a new lattice structure, with a focus on 3D additive manufacturing of complex parts. Focusing on the land-scape of complex parts additive manufacturing, this research proposes geometric parameterization, mechanical adaptive sizing, and numerical validation of a novel lattice structure to optimize the final printed part volume and mass, as well as its structural rigidity. The topology of the lattice structures exhibited pyramidal geometry. Complete parameterization of the lattice structure ensures that the known geometric parameters adjust to defined restrictions, enabling dynamic adaptability based on its load states and boundary conditions, thereby enhancing its mechanical performance. The core methodology integrates analytical automation with mechanical analysis by employing a model based in two-dimensional beam elements. The dimensioning of the lattice structure is analyzed using rigidity models of its sub-elements, providing an evaluation of its global structural behavior after applying the superposition principle. Numerical validation was performed to validate the proposed analytical model. This step ensures that the analytical model defined for dimensioning the lattice structure adjusts to its real mechanical behavior and allows its validation. The present manuscript aims to advance additive manufacturing methodologies by offering a systematic and adaptive approach to lattice structure design. Parametric and adaptive techniques foster new industrial design engineering methods, enabling the dynamic tailoring of lattice structures to meet their mechanical demands and enhance their overall efficiency and performance.",
      "authors": [
        "Jorge Manuel Mercado-Colmenero",
        "Daniel Diaz - Perete",
        "Miguel Angel Rubio- Paramio and Cristina Martin-Donate"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:38:42+00:00",
          "link": "https://arxiv.org/abs/2507.18318v1",
          "size": "908kb",
          "version": "v1"
        }
      ],
      "title": "Parametric design and adaptive sizing of lattice structures for 3d additive manufacturing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18318",
        "PDF": "https://arxiv.org/pdf/2507.18318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers on parametric design and additive manufacturing of lattice structures, not on training data processing for LLMs. There is no discussion on data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18319",
      "abstract": "Bug localisation, the study of developing methods to localise the files requiring changes to resolve bugs, has been researched for a long time to develop methods capable of saving developers' time. Recently, researchers are starting to consider issues outside of bugs. Nevertheless, most existing research into file localisation from issues focusses on bugs or uses other selection methods to ensure only certain types of issues are considered as part of the focus of the work. Our goal is to work on all issues at large, without any specific selection.\n  In this work, we provide a data pipeline for the creation of issue file localisation datasets, capable of dealing with arbitrary branching and merging practices. We provide a baseline performance evaluation for the file localisation problem using traditional information retrieval approaches. Finally, we use statistical analysis to investigate the influence of biases known in the bug localisation community on our dataset.\n  Our results show that methods designed using bug-specific heuristics perform poorly on general issue types, indicating a need for research into general purpose models. Furthermore, we find that there are small, but statistically significant differences in performance between different issue types. Finally, we find that the presence of identifiers have a small effect on performance for most issue types. Many results are project-dependent, encouraging the development of methods which can be tuned to project-specific characteristics.",
      "authors": [
        "Jesse Maarleveld",
        "Jiapan Guo",
        "Daniel Feitosa"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:42:13+00:00",
          "link": "https://arxiv.org/abs/2507.18319v1",
          "size": "158kb",
          "version": "v1"
        }
      ],
      "title": "Gotta catch 'em all! Towards File Localisation from Issues at Large",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18319",
        "HTML": "https://arxiv.org/html/2507.18319v1",
        "PDF": "https://arxiv.org/pdf/2507.18319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses file localisation from issues in software engineering. It does not pertain to LLM training data processing or any related data engineering tasks for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18320",
      "abstract": "The rapid adoption of battery-powered vehicles and energy storage systems over the past decade has made battery health monitoring increasingly critical. Batteries play a central role in the efficiency and safety of these systems, yet they inevitably degrade over time due to repeated charge-discharge cycles. This degradation leads to reduced energy efficiency and potential overheating, posing significant safety concerns. Accurate estimation of a State of Health (SoH) of battery is therefore essential for ensuring operational reliability and safety. Several machine learning architectures, such as LSTMs, transformers, and encoder-based models, have been proposed to estimate SoH from discharge cycle data. However, these models struggle with the irregularities inherent in real-world measurements: discharge readings are often recorded at non-uniform intervals, and the lengths of discharge cycles vary significantly. To address this, most existing approaches extract features from the sequences rather than processing them in full, which introduces information loss and compromises accuracy. To overcome these challenges, we propose a novel architecture: Time-Informed Dynamic Sequence Inverted Transformer (TIDSIT). TIDSIT incorporates continuous time embeddings to effectively represent irregularly sampled data and utilizes padded sequences with temporal attention mechanisms to manage variable-length inputs without discarding sequence information. Experimental results on the NASA battery degradation dataset show that TIDSIT significantly outperforms existing models, achieving over 50% reduction in prediction error and maintaining an SoH prediction error below 0.58%. Furthermore, the architecture is generalizable and holds promise for broader applications in health monitoring tasks involving irregular time-series data.",
      "authors": [
        "Janak M. Patel",
        "Milad Ramezankhani",
        "Anirudh Deodhar",
        "Dagnachew Birru"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:43:46+00:00",
          "link": "https://arxiv.org/abs/2507.18320v1",
          "size": "252kb",
          "version": "v1"
        }
      ],
      "title": "State of Health Estimation of Batteries Using a Time-Informed Dynamic Sequence-Inverted Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18320",
        "HTML": "https://arxiv.org/html/2507.18320v1",
        "PDF": "https://arxiv.org/pdf/2507.18320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on battery state of health estimation using a novel transformer architecture. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18323",
      "abstract": "Electrocardiogram (ECG) delineation, the segmentation of meaningful waveform features, is critical for clinical diagnosis. Despite recent advances using deep learning, progress has been limited by the scarcity of publicly available annotated datasets. Semi-supervised learning presents a promising solution by leveraging abundant unlabeled ECG data. In this study, we present the first systematic benchmark for semi-supervised semantic segmentation (SemiSeg) in ECG delineation. We curated and unified multiple public datasets, including previously underused sources, to support robust and diverse evaluation. We adopted five representative SemiSeg algorithms from computer vision, implemented them on two different architectures: the convolutional network and the transformer, and evaluated them in two different settings: in-domain and cross-domain. Additionally, we propose ECG-specific training configurations and augmentation strategies and introduce a standardized evaluation framework. Our results show that the transformer outperforms the convolutional network in semi-supervised ECG delineation. We anticipate that our benchmark will serve as a foundation for advancing semi-supervised ECG delineation methods and will facilitate further research in this domain.",
      "authors": [
        "Minje Park",
        "Jeonghwa Lim",
        "Taehyung Yu",
        "and Sunghoon Joo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:49:46+00:00",
          "link": "https://arxiv.org/abs/2507.18323v1",
          "size": "54kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18323",
        "HTML": "https://arxiv.org/html/2507.18323v1",
        "PDF": "https://arxiv.org/pdf/2507.18323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper involves dataset unification and evaluation for ECG data, it is specific to medical segmentation tasks and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18326",
      "abstract": "Efficient scalability of automated driving (AD) is key to reducing costs, enhancing safety, conserving resources, and maximizing impact. However, research focuses on specific vehicles and context, while broad deployment requires scalability across various configurations and environments. Differences in vehicle types, sensors, actuators, but also traffic regulations, legal requirements, cultural dynamics, or even ethical paradigms demand high flexibility of data-driven developed capabilities. In this paper, we address the challenge of scalable adaptation of generic capabilities to desired systems and environments. Our concept follows a two-stage fine-tuning process. In the first stage, fine-tuning to the specific environment takes place through a country-specific reward model that serves as an interface between technological adaptations and socio-political requirements. In the second stage, vehicle-specific transfer learning facilitates system adaptation and governs the validation of design decisions. In sum, our concept offers a data-driven process that integrates both technological and socio-political aspects, enabling effective scalability across technical, legal, cultural, and ethical differences.",
      "authors": [
        "Lars Ullrich",
        "Michael Buchholz",
        "Jonathan Petit",
        "Klaus Dietmayer and Knut Graichen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:51:55+00:00",
          "link": "https://arxiv.org/abs/2507.18326v1",
          "size": "2344kb",
          "version": "v1"
        }
      ],
      "title": "A Concept for Efficient Scalability of Automated Driving Allowing for Technical, Legal, Cultural, and Ethical Differences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18326",
        "PDF": "https://arxiv.org/pdf/2507.18326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on scalable adaptation for automated driving technology, which involves a data-driven process integrating technological and socio-political aspects, but it does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18327",
      "abstract": "The nuclear norm (NN) has been widely explored in matrix recovery problems, such as Robust PCA and matrix completion, leveraging the inherent global low-rank structure of the data. In this study, we introduce a new modified nuclear norm (MNN) framework, where the MNN family norms are defined by adopting suitable transformations and performing the NN on the transformed matrix. The MNN framework offers two main advantages: (1) it jointly captures both local information and global low-rankness without requiring trade-off parameter tuning; (2) Under mild assumptions on the transformation, we provided exact theoretical recovery guarantees for both Robust PCA and MC tasks-an achievement not shared by existing methods that combine local and global information. Thanks to its general and flexible design, MNN can accommodate various proven transformations, enabling a unified and effective approach to structured low-rank recovery. Extensive experiments demonstrate the effectiveness of our method. Code and supplementary material are available at https://github.com/andrew-pengjj/modified_nuclear_norm.",
      "authors": [
        "Jiangjun Peng",
        "Yisi Luo",
        "Xiangyong Cao",
        "Shuang Xu",
        "and Deyu Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:53:55+00:00",
          "link": "https://arxiv.org/abs/2507.18327v1",
          "size": "10216kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Low-rankness: Guaranteed Matrix Recovery via Modified Nuclear Norm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18327",
        "HTML": "https://arxiv.org/html/2507.18327v1",
        "PDF": "https://arxiv.org/pdf/2507.18327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a modified nuclear norm framework for matrix recovery tasks, such as Robust PCA and matrix completion, without relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18328",
      "abstract": "In this paper, we consider the fair access problem and the Age of Information (AoI) under 5G New Radio (NR) Vehicle-to-Infrastructure (V2I) Mode 2 in vehicular networks. Specifically, vehicles follow Mode 2 to communicate with Roadside Units (RSUs) to obtain accurate data for driving assistance.Nevertheless, vehicles often have different velocity when they are moving in adjacent lanes, leading to difference in RSU dwelltime and communication duration. This results in unfair access to network resources, potentially influencing driving safety. To ensure the freshness of received data, the AoI should be analyzed. Mode 2 introduces a novel preemption mechanism, necessitating simultaneous optimization of fair access and AoI to guarantee timely and relevant data delivery. We propose a joint optimization framework for vehicular network, defining a fairness index and employing Stochastic Hybrid Systems (SHS) to model AoI under preemption mechanism. By adaptively adjusting the selection window of Semi-Persistent Scheduling (SPS) in Mode 2, we address the optimization of fairness and AoI. We apply a large language model (LLM)-Based Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D) to solve this problem. Simulation results demonstrate the effectiveness of our scheme in balancing fair access and minimizing AoI.",
      "authors": [
        "Xiao Xu",
        "Qiong Wu",
        "Pingyi Fan",
        "Kezhi Wang",
        "Nan Cheng",
        "Wen Chen",
        "and Khaled B. Letaief"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:54:31+00:00",
          "link": "https://arxiv.org/abs/2507.18328v1",
          "size": "394kb",
          "version": "v1"
        }
      ],
      "title": "Enhanced Velocity-Adaptive Scheme: Joint Fair Access and Age of Information Optimization in Vehicular Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18328",
        "HTML": "https://arxiv.org/html/2507.18328v1",
        "PDF": "https://arxiv.org/pdf/2507.18328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses optimization of fair access and AoI in vehicular networks with a focus on communication and fairness, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18330",
      "abstract": "Aviation's climate impact includes not only CO2 emissions but also significant non-CO2 effects, especially from contrails. These ice clouds can alter Earth's radiative balance, potentially rivaling the warming effect of aviation CO2. Physics-based models provide useful estimates of contrail formation and climate impact, but their accuracy depends heavily on the quality of atmospheric input data and on assumptions used to represent complex processes like ice particle formation and humidity-driven persistence. Observational data from remote sensors, such as satellites and ground cameras, could be used to validate and calibrate these models. However, existing datasets don't explore all aspect of contrail dynamics and formation: they typically lack temporal tracking, and do not attribute contrails to their source flights. To address these limitations, we present the Ground Visible Camera Contrail Sequences (GVCCS), a new open data set of contrails recorded with a ground-based all-sky camera in the visible range. Each contrail is individually labeled and tracked over time, allowing a detailed analysis of its lifecycle. The dataset contains 122 video sequences (24,228 frames) and includes flight identifiers for contrails that form above the camera. As reference, we also propose a unified deep learning framework for contrail analysis using a panoptic segmentation model that performs semantic segmentation (contrail pixel identification), instance segmentation (individual contrail separation), and temporal tracking in a single architecture. By providing high-quality, temporally resolved annotations and a benchmark for model evaluation, our work supports improved contrail monitoring and will facilitate better calibration of physical models. This sets the groundwork for more accurate climate impact understanding and assessments.",
      "authors": [
        "Gabriel Jarry",
        "Ramon Dalmau",
        "Philippe Very",
        "Franck Ballerini",
        "Stephania-Denisa Bocu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:57:59+00:00",
          "link": "https://arxiv.org/abs/2507.18330v1",
          "size": "2181kb",
          "version": "v1"
        }
      ],
      "title": "GVCCS: A Dataset for Contrail Identification and Tracking on Visible Whole Sky Camera Sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18330",
        "HTML": "https://arxiv.org/html/2507.18330v1",
        "PDF": "https://arxiv.org/pdf/2507.18330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a dataset (GVCCS) for contrail identification and tracking with an emphasis on climate impact and contrail monitoring, lacking relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18331",
      "abstract": "This work presents SGCDet, a novel multi-view indoor 3D object detection framework based on adaptive 3D volume construction. Unlike previous approaches that restrict the receptive field of voxels to fixed locations on images, we introduce a geometry and context aware aggregation module to integrate geometric and contextual information within adaptive regions in each image and dynamically adjust the contributions from different views, enhancing the representation capability of voxel features. Furthermore, we propose a sparse volume construction strategy that adaptively identifies and selects voxels with high occupancy probabilities for feature refinement, minimizing redundant computation in free space. Benefiting from the above designs, our framework achieves effective and efficient volume construction in an adaptive way. Better still, our network can be supervised using only 3D bounding boxes, eliminating the dependence on ground-truth scene geometry. Experimental results demonstrate that SGCDet achieves state-of-the-art performance on the ScanNet, ScanNet200 and ARKitScenes datasets. The source code is available at https://github.com/RM-Zhang/SGCDet.",
      "authors": [
        "Runmin Zhang",
        "Zhu Yu",
        "Si-Yuan Cao",
        "Lingyu Zhu",
        "Guangyi Zhang",
        "Xiaokai Bai",
        "Hui-Liang Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:58:01+00:00",
          "link": "https://arxiv.org/abs/2507.18331v1",
          "size": "1749kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18331",
        "HTML": "https://arxiv.org/html/2507.18331v1",
        "PDF": "https://arxiv.org/pdf/2507.18331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for multi-view 3D object detection in indoor environments, focusing on adaptive 3D volume construction, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18333",
      "abstract": "Cooperative multi-agent reinforcement learning (MARL) is typically formalised as a Decentralised Partially Observable Markov Decision Process (Dec-POMDP), where agents must reason about the environment and other agents' behaviour. In practice, current model-free MARL algorithms use simple recurrent function approximators to address the challenge of reasoning about others using partial information. In this position paper, we argue that the empirical success of these methods is not due to effective Markov signal recovery, but rather to learning simple conventions that bypass environment observations and memory. Through a targeted case study, we show that co-adapting agents can learn brittle conventions, which then fail when partnered with non-adaptive agents. Crucially, the same models can learn grounded policies when the task design necessitates it, revealing that the issue is not a fundamental limitation of the learning models but a failure of the benchmark design. Our analysis also suggests that modern MARL environments may not adequately test the core assumptions of Dec-POMDPs. We therefore advocate for new cooperative environments built upon two core principles: (1) behaviours grounded in observations and (2) memory-based reasoning about other agents, ensuring success requires genuine skill rather than fragile, co-adapted agreements.",
      "authors": [
        "Kale-ab Abebe Tessera",
        "Leonard Hinckeldey",
        "Riccardo Zamboni",
        "David Abel",
        "Amos Storkey"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:59:42+00:00",
          "link": "https://arxiv.org/abs/2507.18333v1",
          "size": "1517kb",
          "version": "v1"
        }
      ],
      "title": "Remembering the Markov Property in Cooperative MARL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18333",
        "HTML": "https://arxiv.org/html/2507.18333v1",
        "PDF": "https://arxiv.org/pdf/2507.18333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is cooperative multi-agent reinforcement learning (MARL) and the Markov property, which does not pertain to processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18334",
      "abstract": "We address the problem of classifying bird species using their song recordings, a challenging task due to environmental noise, overlapping vocalizations, and missing labels. Existing models struggle with low-SNR or multi-species recordings. We hypothesize that birds can be classified by visualizing their pitch pattern, speed, and repetition, collectively called motifs. Deep learning models applied to spectrogram images help, but similar motifs across species cause confusion. To mitigate this, we embed frequency information into spectrograms using primary color additives. This enhances species distinction and improves classification accuracy. Our experiments show that the proposed approach achieves statistically significant gains over models without colorization and surpasses the BirdCLEF 2024 winner, improving F1 by 7.3%, ROC-AUC by 6.2%, and CMAP by 6.6%. These results demonstrate the effectiveness of incorporating frequency information via colorization.",
      "authors": [
        "Ezhini Rasendiran R",
        "Chandresh Kumar Maurya"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:05:17+00:00",
          "link": "https://arxiv.org/abs/2507.18334v1",
          "size": "801kb",
          "version": "v1"
        }
      ],
      "title": "Improving Bird Classification with Primary Color Additives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18334",
        "HTML": "https://arxiv.org/html/2507.18334v1",
        "PDF": "https://arxiv.org/pdf/2507.18334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with improving bird classification using primary color additives for audio spectrograms, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18337",
      "abstract": "We present our method for automatically marking Physics exams. The marking problem consists in assessing typed student answers for correctness with respect to a ground truth solution. This is a challenging problem that we seek to tackle using a combination of a computer algebra system, an SMT solver and a term rewriting system. A Large Language Model is used to interpret and remove errors from student responses and rewrite these in a machine readable format. Once formalized and language-aligned, the next step then consists in applying automated reasoning techniques for assessing student solution correctness. We consider two methods of automated theorem proving: off-the-shelf SMT solving and term rewriting systems tailored for physics problems involving trigonometric expressions. The development of the term rewrite system and establishing termination and confluence properties was not trivial, and we describe it in some detail in the paper. We evaluate our system on a rich pool of over 1500 real-world student exam responses from the 2023 Australian Physics Olympiad.",
      "authors": [
        "Peter Baumgartner and Lachlan McGinness"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:08:49+00:00",
          "link": "https://arxiv.org/abs/2507.18337v1",
          "size": "80kb",
          "version": "v1"
        }
      ],
      "title": "The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18337",
        "HTML": "https://arxiv.org/html/2507.18337v1",
        "PDF": "https://arxiv.org/pdf/2507.18337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs to interpret and correct student responses in Physics exams. While it involves using LLMs for data processing, it is not specifically focused on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18338",
      "abstract": "In machine translation (MT), when the source sentence includes a lexeme whose gender is not overtly marked, but whose target-language equivalent requires gender specification, the model must infer the appropriate gender from the context and/or external knowledge. Studies have shown that MT models exhibit biased behaviour, relying on stereotypes even when they clash with contextual information. We posit that apart from confidently translating using the correct gender when it is evident from the input, models should also maintain uncertainty about the gender when it is ambiguous. Using recently proposed metrics of semantic uncertainty, we find that models with high translation and gender accuracy on unambiguous instances do not necessarily exhibit the expected level of uncertainty in ambiguous ones. Similarly, debiasing has independent effects on ambiguous and unambiguous translation instances.",
      "authors": [
        "Ieva Raminta Stali\\=unait\\.e",
        "Julius Cheng",
        "Andreas Vlachos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:10:21+00:00",
          "link": "https://arxiv.org/abs/2507.18338v1",
          "size": "2091kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty Quantification for Evaluating Machine Translation Bias",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18338",
        "HTML": "https://arxiv.org/html/2507.18338v1",
        "PDF": "https://arxiv.org/pdf/2507.18338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on machine translation and quantifying uncertainty to evaluate gender bias, which is not connected to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18339",
      "abstract": "As systems become more complex, the demand for thorough testing and virtual prototyping grows. To simulate whole systems, multiple tools are usually needed to cover different parts. These parts include the hardware of a system and the environment with which the system interacts. The Functional Mock-up Interface (FMI) standard for co-simulation can be used to connect these tools.\n  The control part of modern systems is usually a computing unit, such as a System-on-a-Chip (SoC) or Microcontroller Unit (MCU), which executes software from a connected memory and interacts with peripherals. To develop software without requiring access to physical hardware, full-system simulators, the so-called Virtual Platforms (VPs), are commonly used. The IEEE-standardized framework for VP development is SystemC TLM. SystemC provides interfaces and concepts that enable modular design and model exchange. However, SystemC lacks native FMI support, which limits the integration into broader co-simulation environments.\n  This paper presents a novel framework to control and interact with SystemC-based VPs using the FMI. We present a case study showing how a simulated temperature sensor in a SystemC simulation can obtain temperature values from an external tool via FMI. This approach allows the unmodified target software to run on the VP and receive realistic environmental input data such as temperature, velocity, or acceleration values from other tools. Thus, extensive software testing and verification is enabled. By having tests ready and the software pre-tested using a VP once the physical hardware is available, certifications like ISO 26262 can be done earlier.",
      "authors": [
        "Nils Bosbach",
        "Meik Schmidt",
        "Lukas J\\\"unger",
        "Matthias Berthold",
        "Rainer Leupers"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:11:47+00:00",
          "link": "https://arxiv.org/abs/2507.18339v1",
          "size": "241kb",
          "version": "v1"
        }
      ],
      "title": "FMI Meets SystemC: A Framework for Cross-Tool Virtual Prototyping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18339",
        "PDF": "https://arxiv.org/pdf/2507.18339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on virtual prototyping using the Functional Mock-up Interface (FMI) for systems and hardware simulations, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18340",
      "abstract": "In-context learning (ICL) has become a classic approach for enabling LLMs to handle various tasks based on a few input-output examples. The effectiveness of ICL heavily relies on the quality of these examples, and previous works which focused on enhancing example retrieval capabilities have achieved impressive performances. However, two challenges remain in retrieving high-quality examples: (1) Difficulty in distinguishing cross-task data distributions, (2) Difficulty in making the fine-grained connection between retriever output and feedback from LLMs. In this paper, we propose a novel framework called TDR. TDR decouples the ICL examples from different tasks, which enables the retrieval module to retrieve examples specific to the target task within a multi-task dataset. Furthermore, TDR models fine-grained feedback from LLMs to supervise and guide the training of the retrieval module, which helps to retrieve high-quality examples. We conducted extensive experiments on a suite of 30 NLP tasks, the results demonstrate that TDR consistently improved results across all datasets and achieves state-of-the-art performance. Meanwhile, our approach is a plug-and-play method, which can be easily combined with various LLMs to improve example retrieval abilities for ICL. The code is available at https://github.com/Nnn-s/TDR.",
      "authors": [
        "Yifu Chen",
        "Bingchen Huang",
        "Zhiling Wang",
        "Yuanchao Du",
        "Junfeng Luo",
        "Lei Shen",
        "Zhineng chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:12:04+00:00",
          "link": "https://arxiv.org/abs/2507.18340v1",
          "size": "1294kb",
          "version": "v1"
        }
      ],
      "title": "TDR: Task-Decoupled Retrieval with Fine-Grained LLM Feedback for In-Context Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18340",
        "PDF": "https://arxiv.org/pdf/2507.18340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses improving in-context learning (ICL) example retrieval with a focus on task-decoupled retrieval and feedback from LLMs. It touches on data processing for fine-tuning but mainly addresses retrieval and task alignment, rather than introducing new training datasets or core data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18342",
      "abstract": "Transferring and integrating knowledge across first-person (egocentric) and third-person (exocentric) viewpoints is intrinsic to human intelligence, enabling humans to learn from others and convey insights from their own experiences. Despite rapid progress in multimodal large language models (MLLMs), their ability to perform such cross-view reasoning remains unexplored. To address this, we introduce EgoExoBench, the first benchmark for egocentric-exocentric video understanding and reasoning. Built from publicly available datasets, EgoExoBench comprises over 7,300 question-answer pairs spanning eleven sub-tasks organized into three core challenges: semantic alignment, viewpoint association, and temporal reasoning. We evaluate 13 state-of-the-art MLLMs and find that while these models excel on single-view tasks, they struggle to align semantics across perspectives, accurately associate views, and infer temporal dynamics in the ego-exo context. We hope EgoExoBench can serve as a valuable resource for research on embodied agents and intelligent assistants seeking human-like cross-view intelligence.",
      "authors": [
        "Yuping He",
        "Yifei Huang",
        "Guo Chen",
        "Baoqi Pei",
        "Jilan Xu",
        "Tong Lu",
        "Jiangmiao Pang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:14:49+00:00",
          "link": "https://arxiv.org/abs/2507.18342v1",
          "size": "16364kb",
          "version": "v1"
        }
      ],
      "title": "EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18342",
        "HTML": "https://arxiv.org/html/2507.18342v1",
        "PDF": "https://arxiv.org/pdf/2507.18342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for video understanding tasks, evaluating LLMs on first-person and third-person video reasoning. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18343",
      "abstract": "Propaganda detection on social media remains challenging due to task complexity and limited high-quality labeled data. This paper introduces a novel framework that combines human expertise with Large Language Model (LLM) assistance to improve both annotation consistency and scalability. We propose a hierarchical taxonomy that organizes 14 fine-grained propaganda techniques into three broader categories, conduct a human annotation study on the HQP dataset that reveals low inter-annotator agreement for fine-grained labels, and implement an LLM-assisted pre-annotation pipeline that extracts propagandistic spans, generates concise explanations, and assigns local labels as well as a global label. A secondary human verification study shows significant improvements in both agreement and time-efficiency. Building on this, we fine-tune smaller language models (SLMs) to perform structured annotation. Instead of fine-tuning on human annotations, we train on high-quality LLM-generated data, allowing a large model to produce these annotations and a smaller model to learn to generate them via knowledge distillation. Our work contributes towards the development of scalable and robust propaganda detection systems, supporting the idea of transparent and accountable media ecosystems in line with SDG 16. The code is publicly available at our GitHub repository.",
      "authors": [
        "Ariana Sahitaj",
        "Premtim Sahitaj",
        "Veronika Solopova",
        "Jiaao Li",
        "Sebastian M\\\"oller",
        "Vera Schmitt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:16:52+00:00",
          "link": "https://arxiv.org/abs/2507.18343v1",
          "size": "1374kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Annotation for Propaganda Detection: Integrating LLM Pre-Annotations with Human Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18343",
        "HTML": "https://arxiv.org/html/2507.18343v1",
        "PDF": "https://arxiv.org/pdf/2507.18343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a hybrid annotation approach for propaganda detection involving LLM-generated data, emphasizing an LLM-assisted pre-annotation process and training smaller models using these annotations. This directly relates to improving training data processing for supervised fine-tuning in LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18344",
      "abstract": "In this paper, we present a novel geometry-aware RGB-D Gaussian Splatting SLAM system, named G2S-ICP SLAM. The proposed method performs high-fidelity 3D reconstruction and robust camera pose tracking in real-time by representing each scene element using a Gaussian distribution constrained to the local tangent plane. This effectively models the local surface as a 2D Gaussian disk aligned with the underlying geometry, leading to more consistent depth interpretation across multiple viewpoints compared to conventional 3D ellipsoid-based representations with isotropic uncertainty. To integrate this representation into the SLAM pipeline, we embed the surface-aligned Gaussian disks into a Generalized ICP framework by introducing anisotropic covariance prior without altering the underlying registration formulation. Furthermore we propose a geometry-aware loss that supervises photometric, depth, and normal consistency. Our system achieves real-time operation while preserving both visual and geometric fidelity. Extensive experiments on the Replica and TUM-RGBD datasets demonstrate that G2S-ICP SLAM outperforms prior SLAM systems in terms of localization accuracy, reconstruction completeness, while maintaining the rendering quality.",
      "authors": [
        "Gyuhyeon Pak",
        "Hae Min Cho",
        "Euntai Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:17:37+00:00",
          "link": "https://arxiv.org/abs/2507.18344v1",
          "size": "4049kb",
          "version": "v1"
        }
      ],
      "title": "G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18344",
        "HTML": "https://arxiv.org/html/2507.18344v1",
        "PDF": "https://arxiv.org/pdf/2507.18344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a 3D SLAM system for high-fidelity 3D reconstruction and camera tracking, which is not related to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18346",
      "abstract": "HyperDeepONets were introduced in Lee, Cho and Hwang [ICLR, 2023] as an alternative architecture for operator learning, in which a hypernetwork generates the weights for the trunk net of a DeepONet. While this improves expressivity, it incurs high memory and computational costs due to the large number of output parameters required. In this work we introduce, in the physics-informed machine learning setting, a variation, PI-LoRA-HyperDeepONets, which leverage low-rank adaptation (LoRA) to reduce complexity by decomposing the hypernetwork's output layer weight matrix into two smaller low-rank matrices. This reduces the number of trainable parameters while introducing an extra regularization of the trunk networks' weights. Through extensive experiments on both ordinary and partial differential equations we show that PI-LoRA-HyperDeepONets achieve up to 70\\% reduction in parameters and consistently outperform regular HyperDeepONets in terms of predictive accuracy and generalization.",
      "authors": [
        "Etienne Zeudong",
        "Elsa Cardoso-Bihlo and Alex Bihlo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:19:25+00:00",
          "link": "https://arxiv.org/abs/2507.18346v1",
          "size": "2193kb",
          "version": "v1"
        }
      ],
      "title": "Low-rank adaptive physics-informed HyperDeepONets for solving differential equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18346",
        "HTML": "https://arxiv.org/html/2507.18346v1",
        "PDF": "https://arxiv.org/pdf/2507.18346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a variation of HyperDeepONets for solving differential equations, specifically through physics-informed deep learning. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18348",
      "abstract": "Bias in computer vision models remains a significant challenge, often resulting in unfair, unreliable, and non-generalizable AI systems. Although research into bias mitigation has intensified, progress continues to be hindered by fragmented implementations and inconsistent evaluation practices. Disparate datasets and metrics used across studies complicate reproducibility, making it difficult to fairly assess and compare the effectiveness of various approaches. To overcome these limitations, we introduce the Visual Bias Mitigator (VB-Mitigator), an open-source framework designed to streamline the development, evaluation, and comparative analysis of visual bias mitigation techniques. VB-Mitigator offers a unified research environment encompassing 12 established mitigation methods, 7 diverse benchmark datasets. A key strength of VB-Mitigator is its extensibility, allowing for seamless integration of additional methods, datasets, metrics, and models. VB-Mitigator aims to accelerate research toward fairness-aware computer vision models by serving as a foundational codebase for the research community to develop and assess their approaches. To this end, we also recommend best evaluation practices and provide a comprehensive performance comparison among state-of-the-art methodologies.",
      "authors": [
        "Ioannis Sarridis",
        "Christos Koutlis",
        "Symeon Papadopoulos",
        "and Christos Diou"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:20:00+00:00",
          "link": "https://arxiv.org/abs/2507.18348v1",
          "size": "241kb",
          "version": "v1"
        }
      ],
      "title": "VB-Mitigator: An Open-source Framework for Evaluating and Advancing Visual Bias Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18348",
        "HTML": "https://arxiv.org/html/2507.18348v1",
        "PDF": "https://arxiv.org/pdf/2507.18348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces VB-Mitigator, a framework for bias mitigation in computer vision, focusing on visual bias. It does not discuss language models or any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18352",
      "abstract": "The training of high-quality, robust machine learning models for speech-driven 3D facial animation requires a large, diverse dataset of high-quality audio-animation pairs. To overcome the lack of such a dataset, recent work has introduced large pre-trained speech encoders that are robust to variations in the input audio and, therefore, enable the facial animation model to generalize across speakers, audio quality, and languages. However, the resulting facial animation models are prohibitively large and lend themselves only to offline inference on a dedicated machine. In this work, we explore on-device, real-time facial animation models in the context of game development. We overcome the lack of large datasets by using hybrid knowledge distillation with pseudo-labeling. Given a large audio dataset, we employ a high-performing teacher model to train very small student models. In contrast to the pre-trained speech encoders, our student models only consist of convolutional and fully-connected layers, removing the need for attention context or recurrent updates. In our experiments, we demonstrate that we can reduce the memory footprint to up to 3.4 MB and required future audio context to up to 81 ms while maintaining high-quality animations. This paves the way for on-device inference, an important step towards realistic, model-driven digital characters.",
      "authors": [
        "Zhen Han",
        "Mattias Teye",
        "Derek Yadgaroff",
        "Judith B\\\"utepage"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:25:12+00:00",
          "link": "https://arxiv.org/abs/2507.18352v1",
          "size": "12590kb",
          "version": "v1"
        }
      ],
      "title": "Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18352",
        "HTML": "https://arxiv.org/html/2507.18352v1",
        "PDF": "https://arxiv.org/pdf/2507.18352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimizing facial animation models via hybrid knowledge distillation and pseudo-labeling, focusing on speech-driven models. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18354",
      "abstract": "Deformable convolution can adaptively change the shape of convolution kernel by learning offsets to deal with complex shape features. We propose a novel plug and play deformable convolutional module that uses attention and feedforward networks to learn offsets, so that the deformable patterns can capture long-distance global features. Compared with previously existing deformable convolutions, the proposed module learns the sub pixel displacement field and adaptively warps the feature maps across all channels rather than directly deforms the convolution kernel , which is equivalent to a relative deformation of the kernel sampling grids, achieving global feature deformation and the decoupling of kernel size and learning network. Considering that the fundus blood vessels have globally self similar complex edges, we design a deep learning model for fundus blood vessel segmentation, GDCUnet, based on the proposed convolutional module. Empirical evaluations under the same configuration and unified framework show that GDCUnet has achieved state of the art performance on public datasets. Further ablation experiments demonstrated that the proposed deformable convolutional module could more significantly learn the complex features of fundus blood vessels, enhancing the model representation and generalization capabilities.The proposed module is similar to the interface of conventional convolution, we suggest applying it to more machine vision tasks with complex global self similar features.",
      "authors": [
        "Lexuan Zhu",
        "Yuxuan Li",
        "Yuning Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:25:45+00:00",
          "link": "https://arxiv.org/abs/2507.18354v1",
          "size": "5808kb",
          "version": "v1"
        }
      ],
      "title": "Deformable Convolution Module with Globally Learned Relative Offsets for Fundus Vessel Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18354",
        "HTML": "https://arxiv.org/html/2507.18354v1",
        "PDF": "https://arxiv.org/pdf/2507.18354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a deformable convolution module for fundus vessel segmentation, focusing on machine vision tasks. It does not address LLMs or training data processing for them."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18360",
      "abstract": "The protection of personal data has become a central topic in software development, especially with the implementation of the General Data Protection Law (LGPD) in Brazil and the General Data Protection Regulation (GDPR) in the European Union. With the enforcement of these laws, certain software quality criteria have become mandatory, such as data anonymization, which is one of the main aspects addressed by these regulations. The aim of this article is to analyze data anonymization techniques and assess their effectiveness in ensuring compliance with legal requirements and the utility of the data for its intended purpose. Techniques such as aggregation, generalization, perturbation, and k-anonymity were investigated and applied to datasets containing personal and sensitive data. The analysis revealed significant variations in the effectiveness of each method, highlighting the need to balance privacy and data utility.",
      "authors": [
        "Andr\\'e Menolli",
        "Luiz Fernando Nunes and Thiago A. Coleti"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:31:28+00:00",
          "link": "https://arxiv.org/abs/2507.18360v1",
          "size": "248kb",
          "version": "v1"
        }
      ],
      "title": "Conformidade com os Requisitos Legais de Privacidade de Dados: Um Estudo sobre T\\'ecnicas de Anonimiza\\c{c}\\~ao",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18360",
        "HTML": "https://arxiv.org/html/2507.18360v1",
        "PDF": "https://arxiv.org/pdf/2507.18360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on techniques for data anonymization to comply with privacy regulations like GDPR and LGPD, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18361",
      "abstract": "We study the Hermitian hull of a particular family of generalized Reed-Solomon codes. The problem of computing the dimension of the hull is translated to a counting problem in a lattice. By solving this problem, we provide explicit formulas for the dimension of the hull, which determines the minimum number required of maximally entangled pairs for the associated entanglement-assisted quantum error-correcting codes. This flexible construction allows to obtain a wide range of entanglement-assisted quantum MDS codes, as well as new parameters.",
      "authors": [
        "Oisin Campion and Rodrigo San-Jos\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:33:08+00:00",
          "link": "https://arxiv.org/abs/2507.18361v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Hermitian hull of some GRS codes and new EAQMDS codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18361",
        "HTML": "https://arxiv.org/html/2507.18361v1",
        "PDF": "https://arxiv.org/pdf/2507.18361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the properties and construction of quantum error-correcting codes and GRS codes, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18365",
      "abstract": "Recommender systems (RecSys) have become an essential component of many web applications. The core of the system is a recommendation model trained on highly sensitive user-item interaction data. While privacy-enhancing techniques are actively studied in the research community, the real-world model development still depends on minimal privacy protection, e.g., via controlled access. Users of such systems should have the right to choose \\emph{not} to share highly sensitive interactions. However, there is no method allowing the user to know which interactions are more sensitive than others. Thus, quantifying the privacy risk of RecSys training data is a critical step to enabling privacy-aware RecSys model development and deployment. We propose a membership-inference attack (MIA)- based privacy scoring method, RecPS, to measure privacy risks at both the interaction and user levels. The RecPS interaction-level score definition is motivated and derived from differential privacy, which is then extended to the user-level scoring method. A critical component is the interaction-level MIA method RecLiRA, which gives high-quality membership estimation. We have conducted extensive experiments on well-known benchmark datasets and RecSys models to show the unique features and benefits of RecPS scoring in risk assessment and RecSys model unlearning. Our code is available at https://anonymous.4open.science/r/RsLiRA-4BD3/readme.md.",
      "authors": [
        "Jiajie He",
        "Yuechun Gu",
        "Keke Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:46:30+00:00",
          "link": "https://arxiv.org/abs/2507.18365v1",
          "size": "583kb",
          "version": "v1"
        }
      ],
      "title": "RecPS: Privacy Risk Scoring for Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18365",
        "PDF": "https://arxiv.org/pdf/2507.18365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a privacy risk scoring method for recommender systems, which involves quantifying the privacy risk of sensitive interaction data and is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18366",
      "abstract": "Accurate uncertainty quantification remains a key challenge for standard LLMs, prompting the adoption of Bayesian and ensemble-based methods. However, such methods typically necessitate computationally expensive sampling, involving multiple forward passes to effectively estimate predictive uncertainty.\n  In this paper, we introduce a novel approach enabling efficient and effective uncertainty estimation in LLMs without sacrificing performance. Specifically, we distill uncertainty-aware teacher models - originally requiring multiple forward passes - into compact student models sharing the same architecture but fine-tuned using Low-Rank Adaptation (LoRA). We compare two distinct distillation strategies: one in which the student employs traditional softmax-based outputs, and another in which the student leverages Dirichlet-distributed outputs to explicitly model epistemic uncertainty via evidential learning.\n  Empirical evaluations on classification datasets demonstrate that such students can achieve comparable or superior predictive and uncertainty quantification performance relative to their teacher models, while critically requiring only a single forward pass. To our knowledge, this is the first demonstration that immediate and robust uncertainty quantification can be achieved in LLMs through evidential distillation.",
      "authors": [
        "Lakshmana Sri Harsha Nemani",
        "P.K. Srijith",
        "Tomasz Ku\\'smierczyk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:46:40+00:00",
          "link": "https://arxiv.org/abs/2507.18366v1",
          "size": "349kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Uncertainty in LLMs through Evidential Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18366",
        "HTML": "https://arxiv.org/html/2507.18366v1",
        "PDF": "https://arxiv.org/pdf/2507.18366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes an approach to improve uncertainty quantification in LLMs using a distillation method. While not directly focused on data processing, it may involve aspects of data usage for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18368",
      "abstract": "Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step logic. In finance, however, professionals must not only converge on optimal decisions but also generate creative, plausible futures under uncertainty. We introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent thinking in LLMs for financial tasks.\n  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990 multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we evaluated 14 leading models and uncovered striking differences. Despite high fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models like DeepSeek-R1 and Cohere Command R+ rank among the top for generating actionable, insights suitable for investment decisions. ConDiFi provides a new perspective to assess reasoning capabilities essential to safe and strategic deployment of LLMs in finance.",
      "authors": [
        "Zhuang Qiang Bok and Watson Wei Khong Chua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:47:29+00:00",
          "link": "https://arxiv.org/abs/2507.18368v1",
          "size": "818kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18368",
        "PDF": "https://arxiv.org/pdf/2507.18368"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the ConDiFi benchmark for evaluating LLMs in financial scenarios, which focuses on reasoning capabilities rather than aspects of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18371",
      "abstract": "Advances in generative modeling have significantly enhanced digital content creation, extending from 2D images to complex 3D and 4D scenes. Despite substantial progress, producing high-fidelity and temporally consistent dynamic 4D content remains a challenge. In this paper, we propose MVG4D, a novel framework that generates dynamic 4D content from a single still image by combining multi-view synthesis with 4D Gaussian Splatting (4D GS). At its core, MVG4D employs an image matrix module that synthesizes temporally coherent and spatially diverse multi-view images, providing rich supervisory signals for downstream 3D and 4D reconstruction. These multi-view images are used to optimize a 3D Gaussian point cloud, which is further extended into the temporal domain via a lightweight deformation network. Our method effectively enhances temporal consistency, geometric fidelity, and visual realism, addressing key challenges in motion discontinuity and background degradation that affect prior 4D GS-based methods. Extensive experiments on the Objaverse dataset demonstrate that MVG4D outperforms state-of-the-art baselines in CLIP-I, PSNR, FVD, and time efficiency. Notably, it reduces flickering artifacts and sharpens structural details across views and time, enabling more immersive AR/VR experiences. MVG4D sets a new direction for efficient and controllable 4D generation from minimal inputs.",
      "authors": [
        "Xiaotian Chen",
        "DongFu Yin",
        "Fei Richard Yu",
        "Xuanchen Li",
        "Xinhao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:48:14+00:00",
          "link": "https://arxiv.org/abs/2507.18371v1",
          "size": "4452kb",
          "version": "v1"
        }
      ],
      "title": "MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18371",
        "HTML": "https://arxiv.org/html/2507.18371v1",
        "PDF": "https://arxiv.org/pdf/2507.18371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on MVG4D, a framework for generating 4D content from images, which pertains to generative modeling techniques and not to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18374",
      "abstract": "Effective human-AI collaboration for physical task completion has significant potential in both everyday activities and professional domains. AI agents equipped with informative guidance can enhance human performance, but evaluating such collaboration remains challenging due to the complexity of human-in-the-loop interactions. In this work, we introduce an evaluation framework and a multimodal dataset of human-AI interactions designed to assess how AI guidance affects procedural task performance, error reduction and learning outcomes. Besides, we develop an augmented reality (AR)-equipped AI agent that provides interactive guidance in real-world tasks, from cooking to battlefield medicine. Through human studies, we share empirical insights into AI-assisted human performance and demonstrate that AI-assisted collaboration improves task completion.",
      "authors": [
        "Filippos Bellos",
        "Yayuan Li",
        "Cary Shu",
        "Ruey Day",
        "Jeffrey M. Siskind",
        "Jason J. Corso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:50:46+00:00",
          "link": "https://arxiv.org/abs/2507.18374v1",
          "size": "7872kb",
          "version": "v1"
        }
      ],
      "title": "Towards Effective Human-in-the-Loop Assistive AI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18374",
        "HTML": "https://arxiv.org/html/2507.18374v1",
        "PDF": "https://arxiv.org/pdf/2507.18374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with human-in-the-loop assistive AI agents and evaluating human-AI interactions, focusing on AI systems rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18375",
      "abstract": "In recent years, quantitative complexity over semirings has been intensively investigated. An important problem in this context is to connect computational complexity with logical expressiveness. In this paper we improve on the model of \\emph{Semiring Turing Machines} (distinct from so called weighted Turing machines) introduced by Eiter \\& Kiesel (Semiring Reasoning Frameworks in AI and Their Computational Complexity, \\emph{J. Artif. Intell. Res.}, 2023). Our central result is a Fagin-style theorem for a new quantitative complexity class using a suitable weighted logical formalism. We show that the quantitative complexity class that we call \\NPnewinf{$\\mathcal{R}$}, where $\\mathcal{R}$ is a commutative semiring, can be captured using a version of weighted existential second-order logic that allows for predicates interpreted as semiring-annotated relations. This result provides a precise logical characterization of the power series that form the class \\NPnewinf{$\\mathcal{R}$}. We also give the exact relation between Eiter \\& Kiesel's version of NP, called \\NPoldinf{$\\mathcal{R}$}, and the class \\NPnewinf{$\\mathcal{R}$}. Incidentally, we are able to recapture all the complexity results by Eiter \\& Kiesel (2023) in our new model, connecting a quantitative version of NP to various counting complexity classes.",
      "authors": [
        "Guillermo Badia",
        "Manfred Droste",
        "Thomas Eiter",
        "Rafael Kiesel",
        "Carles Noguera",
        "Erik Paul"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:52:10+00:00",
          "link": "https://arxiv.org/abs/2507.18375v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "Fagin's Theorem for Semiring Turing Machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18375",
        "HTML": "https://arxiv.org/html/2507.18375v1",
        "PDF": "https://arxiv.org/pdf/2507.18375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents theoretical advancements in semiring Turing machines and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18376",
      "abstract": "With the global population growing and arable land resources becoming increasingly scarce,smart agriculture and precision agriculture have emerged as key directions for the future ofagricultural development.Artificial intelligence (AI) technologies, particularly deep learning models, have found widespread applications in areas such as crop monitoring and pest detection. As an emerging generative model, diffusion models have shown significant promise in tasks like agricultural image processing, data augmentation, and remote sensing. Compared to traditional generative adversarial networks (GANs), diffusion models offer superior training stability and generation quality, effectively addressing challenges such as limited agricultural data and imbalanced image samples. This paper reviews the latest advancements in the application of diffusion models in agriculture, focusing on their potential in crop pest and disease detection, remote sensing image enhancement, crop growth prediction, and agricultural resource management. Experimental results demonstrate that diffusion models significantly improve model accuracy and robustness in data augmentation, image generation, and denoising, especially in complex environments. Despite challenges related to computational efficiency and generalization capabilities, diffusion models are expected to play an increasingly important role in smart and precision agriculture as technology advances, providing substantial support for the sustainable development of global agriculture.",
      "authors": [
        "Xing Hua",
        "Haodong Chen",
        "Qianqian Duan",
        "Danfeng Hong",
        "Ruijiao Li",
        "Huiliang Shang",
        "Linghua Jiang",
        "Haima Yang and Dawei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:52:32+00:00",
          "link": "https://arxiv.org/abs/2507.18376v1",
          "size": "11952kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18376",
        "HTML": "https://arxiv.org/html/2507.18376v1",
        "PDF": "https://arxiv.org/pdf/2507.18376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on the use of diffusion models in smart agriculture, particularly in image processing and augmentation for crop monitoring and pest detection. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18382",
      "abstract": "Current approaches to pose generation rely heavily on intermediate representations, either through two-stage pipelines with quantization or autoregressive models that accumulate errors during inference. This fundamental limitation leads to degraded performance, particularly in long-term pose generation where maintaining temporal coherence is crucial. We propose a novel one-stage architecture that directly generates poses in continuous coordinate space from minimal context - a single RGB image and text description - while maintaining consistent distributions between training and inference. Our key innovation is eliminating the need for intermediate representations or token-based generation by operating directly on pose coordinates through a relative movement prediction mechanism that preserves spatial relationships, and a unified placeholder token approach that enables single-forward generation with identical behavior during training and inference. Through extensive experiments on Penn Action and First-Person Hand Action Benchmark (F-PHAB) datasets, we demonstrate that our approach significantly outperforms existing quantization-based and autoregressive methods, especially in long-term generation scenarios.",
      "authors": [
        "Yayuan Li",
        "Filippos Bellos",
        "Jason Corso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:57:22+00:00",
          "link": "https://arxiv.org/abs/2507.18382v1",
          "size": "3909kb",
          "version": "v1"
        }
      ],
      "title": "Towards Consistent Long-Term Pose Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18382",
        "HTML": "https://arxiv.org/html/2507.18382v1",
        "PDF": "https://arxiv.org/pdf/2507.18382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel architecture for pose generation that avoids intermediate representations, focusing primarily on pose consistency and generation. This does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18385",
      "abstract": "Full-body Human inverse rendering based on physically-based rendering aims to acquire high-quality materials, which helps achieve photo-realistic rendering under arbitrary illuminations. This task requires estimating multiple material maps and usually relies on the constraint of rendering result. The absence of constraints on the material maps makes inverse rendering an ill-posed task. Previous works alleviated this problem by building material dataset for training, but their simplified material data and rendering equation lead to rendering results with limited realism, especially that of skin. To further alleviate this problem, we construct a higher-quality dataset (OpenHumanBRDF) based on scanned real data and statistical material data. In addition to the normal, diffuse albedo, roughness, specular albedo, we produce displacement and subsurface scattering to enhance the realism of rendering results, especially for the skin. With the increase in prediction tasks for more materials, using an end-to-end model as in the previous work struggles to balance the importance among various material maps, and leads to model underfitting. Therefore, we design a model (HumanMaterial) with progressive training strategy to make full use of the supervision information of the material maps and improve the performance of material estimation. HumanMaterial first obtain the initial material results via three prior models, and then refine the results by a finetuning model. Prior models estimate different material maps, and each map has different significance for rendering results. Thus, we design a Controlled PBR Rendering (CPR) loss, which enhances the importance of the materials to be optimized during the training of prior models. Extensive experiments on OpenHumanBRDF dataset and real data demonstrate that our method achieves state-of-the-art performance.",
      "authors": [
        "Yu Jiang",
        "Jiahao Xia",
        "Jiongming Qin",
        "Yusen Wang",
        "Tuo Cao",
        "and Chunxia Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:59:42+00:00",
          "link": "https://arxiv.org/abs/2507.18385v1",
          "size": "40855kb",
          "version": "v1"
        }
      ],
      "title": "HumanMaterial: Human Material Estimation from a Single Image via Progressive Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18385",
        "HTML": "https://arxiv.org/html/2507.18385v1",
        "PDF": "https://arxiv.org/pdf/2507.18385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a dataset and model for human material estimation from images, employing a progressive training strategy. It is focused on image rendering tasks and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18391",
      "abstract": "Large language models (LLMs) have recently demonstrated remarkable progress in reasoning capabilities through reinforcement learning with verifiable rewards (RLVR). By leveraging simple rule-based rewards, RL effectively incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning trajectories, progressively guiding them toward correct answers. However, existing approaches remain largely heuristic and intuition-driven, limiting the development of principled methodologies. In this paper, we present a theoretical characterization of LLM reasoning grounded in information bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO), a framework that encourages reasoning trajectories to be both informative about the final correct answer and generalizable across diverse prompts. We derive a practical token-level surrogate objective and propose an efficient approximation, resulting in the lightweight IB regularization method. This technique integrates seamlessly into existing RL-based post-training frameworks without additional computational overhead, requiring only a one-line code modification. Empirically, we validate IB regularization across multiple mathematical reasoning benchmarks and RL algorithms, demonstrating consistent improvements in LLM reasoning performance.",
      "authors": [
        "Shiye Lei",
        "Zhihao Cheng",
        "Kai Jia",
        "Dacheng Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:14:25+00:00",
          "link": "https://arxiv.org/abs/2507.18391v1",
          "size": "214kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting LLM Reasoning via Information Bottleneck",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18391",
        "HTML": "https://arxiv.org/html/2507.18391v1",
        "PDF": "https://arxiv.org/pdf/2507.18391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores improvements in LLM reasoning using the information bottleneck principle within reinforcement learning frameworks. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18392",
      "abstract": "The evaluation of Large Language Models (LLMs) increasingly relies on other LLMs acting as judges. However, current evaluation paradigms typically yield a single score or ranking, answering which model is better but not why. While essential for benchmarking, these top-level scores obscure the specific, actionable reasons behind a model's performance. To bridge this gap, we introduce CLEAR, an interactive, open-source package for LLM-based error analysis. CLEAR first generates per-instance textual feedback, then it creates a set of system-level error issues, and quantifies the prevalence of each identified issue. Our package also provides users with an interactive dashboard that allows for a comprehensive error analysis through aggregate visualizations, applies interactive filters to isolate specific issues or score ranges, and drills down to the individual instances that exemplify a particular behavioral pattern. We demonstrate CLEAR analysis for RAG and Math benchmarks, and showcase its utility through a user case study.",
      "authors": [
        "Asaf Yehudai",
        "Lilach Eden",
        "Yotam Perlitz",
        "Roy Bar-Haim",
        "Michal Shmueli-Scheuer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:15:21+00:00",
          "link": "https://arxiv.org/abs/2507.18392v1",
          "size": "1369kb",
          "version": "v1"
        }
      ],
      "title": "CLEAR: Error Analysis via LLM-as-a-Judge Made Easy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18392",
        "HTML": "https://arxiv.org/html/2507.18392v1",
        "PDF": "https://arxiv.org/pdf/2507.18392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces CLEAR for LLM error analysis, focusing on providing insights into model performance rather than training data processing. It is concerned with evaluation rather than data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18393",
      "abstract": "This study proposes and evaluates the PAnoramic Learning Map (PALM), a learning analytics (LA) dashboard designed to address the scalability challenges of LA by integrating curriculum-level information. Traditional LA research has predominantly focused on individual courses or learners and often lacks a framework that considers the relationships between courses and the long-term trajectory of learning. To bridge this gap, PALM was developed to integrate multilayered educational data into a curriculum map, enabling learners to intuitively understand their learning records and academic progression. We conducted a system evaluation to assess PALM's effectiveness in two key areas: (1) its impact on students' awareness of their learning behaviors, and (2) its comparative performance against existing systems. The results indicate that PALM enhances learners' awareness of study planning and reflection, particularly by improving perceived behavioral control through the visual presentation of individual learning histories and statistical trends, which clarify the links between learning actions and outcomes. Although PALM requires ongoing refinement as a system, it received significantly higher evaluations than existing systems in terms of visual appeal and usability. By serving as an information resource with previously inaccessible insights, PALM enhances self-regulated learning and engagement, representing a significant step beyond conventional LA toward a comprehensive and scalable approach.",
      "authors": [
        "Mahiro Ozaki",
        "Li Chen",
        "Shotaro Naganuma",
        "Valdemar \\v{S}v\\'abensk\\'y",
        "Fumiya Okubo",
        "Atsushi Shimada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:17:47+00:00",
          "link": "https://arxiv.org/abs/2507.18393v1",
          "size": "4497kb",
          "version": "v1"
        }
      ],
      "title": "PALM: PAnoramic Learning Map Integrating Learning Analytics and Curriculum Map for Scalable Insights Across Courses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18393",
        "HTML": "https://arxiv.org/html/2507.18393v1",
        "PDF": "https://arxiv.org/pdf/2507.18393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development of a learning analytics dashboard (PALM) for educational data visualization and student awareness, which is unrelated to LLM training data processing activities such as dataset creation or data filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18396",
      "abstract": "In vehicle trajectory tracking tasks, the simplest approach is the Pure Pursuit (PP) Control. However, this single-point preview tracking strategy fails to consider vehicle model constraints, compromising driving safety. Model Predictive Control (MPC) as a widely adopted control method, optimizes control actions by incorporating mechanistic models and physical constraints. While its control performance critically depends on the accuracy of vehicle modeling. Traditional vehicle modeling approaches face inherent trade-offs between capturing nonlinear dynamics and maintaining computational efficiency, often resulting in reduced control performance. To address these challenges, this paper proposes Residual Koopman Model Predictive Control (RKMPC) framework. This method uses two linear MPC architecture to calculate control inputs: a Linear Model Predictive Control (LMPC) computes the baseline control input based on the vehicle kinematic model, and a neural network-based RKMPC calculates the compensation input. The final control command is obtained by adding these two components. This design preserves the reliability and interpretability of traditional mechanistic model while achieving performance optimization through residual modeling. This method has been validated on the Carsim-Matlab joint simulation platform and a physical 1:10 scale F1TENTH racing car. Experimental results show that RKMPC requires only 20% of the training data needed by traditional Koopman Model Predictive Control (KMPC) while delivering superior tracking performance. Compared to traditional LMPC, RKMPC reduces lateral error by 11.7%-22.1%, decreases heading error by 8.9%-15.8%, and improves front-wheel steering stability by up to 27.6%. The implementation code is available at: https://github.com/ZJU-DDRX/Residual Koopman.",
      "authors": [
        "Yonghao Fu",
        "Cheng Hu",
        "Haokun Xiong",
        "Zhangpeng Bao",
        "Wenyuan Du",
        "Edoardo Ghignone",
        "Michele Magno",
        "Lei Xie",
        "and Hongye Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:28:05+00:00",
          "link": "https://arxiv.org/abs/2507.18396v1",
          "size": "3780kb",
          "version": "v1"
        }
      ],
      "title": "Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18396",
        "HTML": "https://arxiv.org/html/2507.18396v1",
        "PDF": "https://arxiv.org/pdf/2507.18396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the Residual Koopman Model Predictive Control for vehicle dynamics optimization, focusing on control strategies and minimizing training data requirements. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18398",
      "abstract": "This paper investigates the application of Reinforcement Learning (RL) to optimise call routing in call centres to minimise client waiting time and staff idle time. Two methods are compared: a model-based approach using Value Iteration (VI) under known system dynamics, and a model-free approach using Proximal Policy Optimisation (PPO) that learns from experience. For the model-based approach, a theoretical model is used, while a simulation model combining Discrete Event Simulation (DES) with the OpenAI Gym environment is developed for model-free learning. Both models frame the problem as a Markov Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with Poisson client arrivals and exponentially distributed service and abandonment times. For policy evaluation, random, VI, and PPO policies are evaluated using the simulation model. After 1,000 test episodes, PPO consistently achives the highest rewards, along with the lowest client waiting time and staff idle time, despite requiring longer training time.",
      "authors": [
        "Kwong Ho Li and Wathsala Karunarathne"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:31:38+00:00",
          "link": "https://arxiv.org/abs/2507.18398v1",
          "size": "1251kb",
          "version": "v1"
        }
      ],
      "title": "Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18398",
        "PDF": "https://arxiv.org/pdf/2507.18398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates reinforcement learning techniques for optimizing call center operations, which does not involve any aspect of LLM training data processing operations like data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18401",
      "abstract": "We experience the world through multiple senses that work together to create a cohesive perception, whether in daily life or immersive technologies. Understanding this multisensory integration (MSI) requires examining the interactions between sensory modalities, each with unique temporal dynamics and characteristics. While most research focuses on unimodal or bimodal cues, the integration of three or more modalities remains underexplored. MSI studies must account for factors like cross-modal correspondence, congruence, cognitive load, and stimulus timing, which become increasingly complex as modalities multiply. This article examines these key factors and how they can be applied to 8 design effective MSI study protocols.",
      "authors": [
        "Andrew Jeyathasan and Swati Banerjee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:35:54+00:00",
          "link": "https://arxiv.org/abs/2507.18401v1",
          "size": "1446kb",
          "version": "v1"
        }
      ],
      "title": "Multisensory Integration and Sensory Substitution Across Vision, Audition, and Haptics: Answering the What, Which, and When in Study Protocols",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18401",
        "PDF": "https://arxiv.org/pdf/2507.18401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines multisensory integration and sensory substitution, which is related to human perception and sensory modalities, not data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18405",
      "abstract": "We introduce Iwin Transformer, a novel position-embedding-free hierarchical vision transformer, which can be fine-tuned directly from low to high resolution, through the collaboration of innovative interleaved window attention and depthwise separable convolution. This approach uses attention to connect distant tokens and applies convolution to link neighboring tokens, enabling global information exchange within a single module, overcoming Swin Transformer's limitation of requiring two consecutive blocks to approximate global attention. Extensive experiments on visual benchmarks demonstrate that Iwin Transformer exhibits strong competitiveness in tasks such as image classification (87.4 top-1 accuracy on ImageNet-1K), semantic segmentation and video action recognition. We also validate the effectiveness of the core component in Iwin as a standalone module that can seamlessly replace the self-attention module in class-conditional image generation. The concepts and methods introduced by the Iwin Transformer have the potential to inspire future research, like Iwin 3D Attention in video generation. The code and models are available at https://github.com/cominder/Iwin-Transformer.",
      "authors": [
        "Simin Huo",
        "Ning Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:45:48+00:00",
          "link": "https://arxiv.org/abs/2507.18405v1",
          "size": "5700kb",
          "version": "v1"
        }
      ],
      "title": "Iwin Transformer: Hierarchical Vision Transformer using Interleaved Windows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18405",
        "HTML": "https://arxiv.org/html/2507.18405v1",
        "PDF": "https://arxiv.org/pdf/2507.18405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Iwin Transformer for vision tasks like image classification, focusing on model architecture improvements and visual tasks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18406",
      "abstract": "Wikipedia serves as a globally accessible knowledge source with content in over 300 languages. Despite covering the same topics, the different versions of Wikipedia are written and updated independently. This leads to factual inconsistencies that can impact the neutrality and reliability of the encyclopedia and AI systems, which often rely on Wikipedia as a main training source. This study investigates cross-lingual inconsistencies in Wikipedia's structured content, with a focus on tabular data. We developed a methodology to collect, align, and analyze tables from Wikipedia multilingual articles, defining categories of inconsistency. We apply various quantitative and qualitative metrics to assess multilingual alignment using a sample dataset. These insights have implications for factual verification, multilingual knowledge interaction, and design for reliable AI systems leveraging Wikipedia content.",
      "authors": [
        "Silvia Cappa",
        "Lingxiao Kong",
        "Pille-Riin Peet",
        "Fanfu Wei",
        "Yuchen Zhou",
        "Jan-Christoph Kalo"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:46:14+00:00",
          "link": "https://arxiv.org/abs/2507.18406v1",
          "size": "2860kb",
          "version": "v1"
        }
      ],
      "title": "Factual Inconsistencies in Multilingual Wikipedia Tables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18406",
        "HTML": "https://arxiv.org/html/2507.18406v1",
        "PDF": "https://arxiv.org/pdf/2507.18406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cross-lingual factual inconsistencies in Wikipedia tables and methodologies for aligning and analyzing these. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18407",
      "abstract": "Medical image segmentation leverages topological connectivity theory to enhance edge precision and regional consistency. However, existing deep networks integrating connectivity often forcibly inject it as an additional feature module, resulting in coupled feature spaces with no standardized mechanism to quantify different feature strengths. To address these issues, we propose DCFFSNet (Dual-Connectivity Feature Fusion-Separation Network). It introduces an innovative feature space decoupling strategy. This strategy quantifies the relative strength between connectivity features and other features. It then builds a deep connectivity feature fusion-separation architecture. This architecture dynamically balances multi-scale feature expression. Experiments were conducted on the ISIC2018, DSB2018, and MoNuSeg datasets. On ISIC2018, DCFFSNet outperformed the next best model (CMUNet) by 1.3% (Dice) and 1.2% (IoU). On DSB2018, it surpassed TransUNet by 0.7% (Dice) and 0.9% (IoU). On MoNuSeg, it exceeded CSCAUNet by 0.8% (Dice) and 0.9% (IoU). The results demonstrate that DCFFSNet exceeds existing mainstream methods across all metrics. It effectively resolves segmentation fragmentation and achieves smooth edge transitions. This significantly enhances clinical usability.",
      "authors": [
        "Xun Ye",
        "Ruixiang Tang",
        "Mingda Zhang",
        "Jianglong Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:46:50+00:00",
          "link": "https://arxiv.org/abs/2507.18407v1",
          "size": "6401kb",
          "version": "v1"
        }
      ],
      "title": "DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18407",
        "HTML": "https://arxiv.org/html/2507.18407v1",
        "PDF": "https://arxiv.org/pdf/2507.18407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a medical image segmentation network and does not involve LLM training data processing, such as data engineering operations or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18413",
      "abstract": "Constraint Programming developed within Logic Programming in the Eighties; nowadays all Prolog systems encompass modules capable of handling constraint programming on finite domains demanding their solution to a constraint solver. This work focuses on a specific form of constraint, the so-called table constraint, used to specify conditions on the values of variables as an enumeration of alternative options. Since every condition on a set of finite domain variables can be ultimately expressed as a finite set of cases, Table can, in principle, simulate any other constraint. These characteristics make Table one of the most studied constraints ever, leading to a series of increasingly efficient propagation algorithms. Despite this, it is not uncommon to encounter real-world problems with hundreds or thousands of valid cases that are simply too many to be handled effectively with standard CPU-based approaches. In this paper, we deal with the Compact-Table (CT) algorithm, the state-of-the-art propagation algorithms for Table. We describe how CT can be enhanced by exploiting the massive computational power offered by modern GPUs to handle large Table constraints. In particular, we report on the design and implementation of GPU-accelerated CT, on its integration into an existing constraint solver, and on an experimental validation performed on a significant set of instances.",
      "authors": [
        "Enrico Santi and Fabio Tardivo and Agostino Dovier and Andrea Formisano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:53:49+00:00",
          "link": "https://arxiv.org/abs/2507.18413v1",
          "size": "399kb",
          "version": "v1"
        }
      ],
      "title": "GPU Accelerated Compact-Table Propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18413",
        "HTML": "https://arxiv.org/html/2507.18413v1",
        "PDF": "https://arxiv.org/pdf/2507.18413"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses GPU acceleration for constraint programming, specifically the Compact-Table algorithm. It is unrelated to LLM training data processing or dataset management for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18417",
      "abstract": "Opinions expressed in online finance-related textual data are having an increasingly profound impact on trading decisions and market movements. This trend highlights the vital role of sentiment analysis as a tool for quantifying the nature and strength of such opinions. With the rapid development of Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs) have become the de facto standard for financial sentiment analysis. However, the SFT paradigm can lead to memorization of the training data and often fails to generalize to unseen samples. This is a critical limitation in financial domains, where models must adapt to previously unobserved events and the nuanced, domain-specific language of finance. To this end, we introduce FinDPO, the first finance-specific LLM framework based on post-training human preference alignment via Direct Preference Optimization (DPO). The proposed FinDPO achieves state-of-the-art performance on standard sentiment classification benchmarks, outperforming existing supervised fine-tuned models by 11% on the average. Uniquely, the FinDPO framework enables the integration of a fine-tuned causal LLM into realistic portfolio strategies through a novel 'logit-to-score' conversion, which transforms discrete sentiment predictions into continuous, rankable sentiment scores (probabilities). In this way, simulations demonstrate that FinDPO is the first sentiment-based approach to maintain substantial positive returns of 67% annually and strong risk-adjusted performance, as indicated by a Sharpe ratio of 2.0, even under realistic transaction costs of 5 basis points (bps).",
      "authors": [
        "Giorgos Iacovides",
        "Wuyang Zhou",
        "Danilo Mandic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Statistical Finance (q-fin.ST)",
        "Trading and Market Microstructure (q-fin.TR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:57:05+00:00",
          "link": "https://arxiv.org/abs/2507.18417v1",
          "size": "412kb",
          "version": "v1"
        }
      ],
      "title": "FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18417",
        "HTML": "https://arxiv.org/html/2507.18417v1",
        "PDF": "https://arxiv.org/pdf/2507.18417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces FinDPO, a framework for financial sentiment analysis using supervised fine-tuned LLMs. It primarily focuses on sentiment analysis and preference optimization of language models, with only an indirect relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18418",
      "abstract": "Given two monads $S$, $T$ on a category where idempotents split, and a weak distributive law between them, one can build a combined monad $U$. Making explicit what this monad $U$ is requires some effort. When we already have an idea what $U$ should be, we show how to recognize that $U$ is indeed the combined monad obtained from $S$ and $T$: it suffices to exhibit what we call a distributing retraction of $ST$ onto $U$. We show that distributing retractions and weak distributive laws are in one-to-one correspondence, in a 2-categorical setting. We give three applications, where $S$ is the Smyth, Hoare or Plotkin hyperspace monad, $T$ is a monad of continuous valuations, and $U$ is a monad of previsions or of forks, depending on the case. As a byproduct, this allows us to describe the algebras of monads of superlinear, resp. sublinear previsions. In the category of compact Hausdorff spaces, the Plotkin hyperspace monad is sometimes known as the Vietoris monad, the monad of probability valuations coincides with the Radon monad, and we infer that the associated combined monad is the monad of normalized forks.",
      "authors": [
        "Jean Goubault-Larrecq"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:57:24+00:00",
          "link": "https://arxiv.org/abs/2507.18418v1",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "title": "Distributing Retractions, Weak Distributive Laws and Applications to Monads of Hyperspaces, Continuous Valuations and Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18418",
        "PDF": "https://arxiv.org/pdf/2507.18418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with category theory and monads, specifically discussing distributing retractions and weak distributive laws. It does not pertain to LLM training data processing or dataset construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18419",
      "abstract": "The increasing interest in vertical farming arises from its ability to ensure consistent, high-quality, and pest-free vegetable production while supporting synergies with energy systems and urban development. Accordingly, standardized design and operation guidelines are essential to improve energy efficiency and lower costs. This study analyzes the production performance and energy consumption of a vertical farming system, assessing its efficiency, sustainability, and economic viability. A total of 162 scenarios were evaluated by combining three levels of temperature, photosynthetic photon flux density (PPFD), and CO2 concentration across three distinct climatic zones, namely Norway, China, and Dubai, which also differ from a socio-environmental viewpoint. Two insulation thicknesses were also tested in each scenario. Results indicate that due to the heating, ventilation, and air conditioning and dehumidification (HVACD) system, neither the insulation layer nor the external climate significantly influences crop productivity. PPFD proved to be the dominant factor in crop growth (correlation: 0.85), followed by CO2 (0.36) and indoor temperature (0.22). PPFD also emerged as the primary driver of overall energy consumption (correlation: 0.73), as it affects both lighting and HVACD loads. Notably, the lowest specific energy consumption (SEC) coincided with the lowest crop productivity (55 kg/m2). The levelized cost of lettuce (LCoL), balancing productivity and energy use, identified the most cost-effective setup as 24C, 250 PPFD, 1400 ppm CO2, with insulation, consistent across all climates. Ultimately, only nearly decarbonized energy systems can support vertical farming without increasing CO2 emissions compared to imported lettuce.",
      "authors": [
        "Francesco Ceccanti",
        "Aldo Bischi",
        "Umberto Desideri",
        "Andrea Baccioli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T13:57:53+00:00",
          "link": "https://arxiv.org/abs/2507.18419v1",
          "size": "9038kb",
          "version": "v1"
        }
      ],
      "title": "Toward Sustainable Vertical Farming: Impacts of Environmental Factors and Energy Mix on Performance and Costs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18419",
        "PDF": "https://arxiv.org/pdf/2507.18419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the sustainability and energy efficiency of vertical farming systems, specifically analyzing environmental factors and their impact. It does not address any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18423",
      "abstract": "Despite the critical need for accurate flood prediction and water management, many regions lack sufficient river discharge observations, limiting the skill of rainfall-runoff analyses. Although numerous physically based and machine learning models exist, achieving high accuracy, interpretability, and computational efficiency under data-scarce conditions remains a major challenge. We address this challenge with a novel method, HYdrological Prediction with multi-model Ensemble and Reservoir computing (HYPER) that leverages multi-model ensemble and reservoir computing (RC). Our approach first applies Bayesian model averaging (BMA) to 43 \"uncalibrated\" catchment-based conceptual hydrological models. An RC model is then trained via linear regression to correct errors in the BMA output, a non-iterative process that ensures high computational efficiency. For ungauged basins, we infer the required BMA and RC weights by linking them to catchment attributes from gauged basins, creating a generalizable framework. We evaluated HYPER using data from 87 river basins in Japan. In a data-rich scenario, HYPER (median Kling-Gupta Efficiency, KGE, of 0.56) performed comparably to a benchmark LSTM (KGE 0.55) but required only 5% of its computational time. In a data-scarce scenario (23% of basins gauged), HYPER maintained robust performance (KGE 0.55) and lower uncertainty, whereas the LSTM's performance degraded significantly (KGE -0.04). These results reveal that individual conceptual hydrological models do not necessarily need to be calibrated when an effectively large ensemble is assembled and combined with machine-learning-based bias correction. HYPER provides a robust, efficient, and generalizable solution for discharge prediction, particularly in ungauged basins, making it applicable to a wide range of regions.",
      "authors": [
        "Mizuki Funato and Yohei Sawada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Geophysics (physics.geo-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:00:18+00:00",
          "link": "https://arxiv.org/abs/2507.18423v1",
          "size": "2444kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Model Ensemble and Reservoir Computing for River Discharge Prediction in Ungauged Basins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18423",
        "PDF": "https://arxiv.org/pdf/2507.18423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for river discharge prediction using multi-model ensemble and reservoir computing. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18424",
      "abstract": "Acquiring and annotating large datasets in ultrasound imaging is challenging due to low contrast, high noise, and susceptibility to artefacts. This process requires significant time and clinical expertise. Self-supervised learning (SSL) offers a promising solution by leveraging unlabelled data to learn useful representations, enabling improved segmentation performance when annotated data is limited. Recent state-of-the-art developments in SSL for video data include V-JEPA, a framework solely based on feature prediction, avoiding pixel level reconstruction or negative samples. We hypothesise that V-JEPA is well-suited to ultrasound imaging, as it is less sensitive to noisy pixel-level detail while effectively leveraging temporal information. To the best of our knowledge, this is the first study to adopt V-JEPA for ultrasound video data. Similar to other patch-based masking SSL techniques such as VideoMAE, V-JEPA is well-suited to ViT-based models. However, ViTs can underperform on small medical datasets due to lack of inductive biases, limited spatial locality and absence of hierarchical feature learning. To improve locality understanding, we propose a novel 3D localisation auxiliary task to improve locality in ViT representations during V-JEPA pre-training. Our results show V-JEPA with our auxiliary task improves segmentation performance significantly across various frozen encoder configurations, with gains up to 3.4\\% using 100\\% and up to 8.35\\% using only 10\\% of the training data.",
      "authors": [
        "Edward Ellis",
        "Robert Mendel",
        "Andrew Bulpitt",
        "Nasim Parsa",
        "Michael F Byrne",
        "Sharib Ali"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:01:02+00:00",
          "link": "https://arxiv.org/abs/2507.18424v1",
          "size": "1204kb",
          "version": "v1"
        }
      ],
      "title": "Self-Supervised Ultrasound-Video Segmentation with Feature Prediction and 3D Localised Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18424",
        "HTML": "https://arxiv.org/html/2507.18424v1",
        "PDF": "https://arxiv.org/pdf/2507.18424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on self-supervised learning techniques for segmentation in ultrasound-video data. It does not address any issues related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18428",
      "abstract": "Decision-making is a central yet under-defined goal in visualization research. While existing task models address decision processes, they often neglect the conditions framing a decision. To better support decision-making tasks, we propose a characterization scheme that describes decision problems through key properties of the data, users, and task context. This scheme helps visualization researchers specify decision-support claims more precisely and informs the design of appropriate visual encodings and interactions. We demonstrate the utility of our approach by applying it to characterize decision tasks targeted by existing design studies, highlighting opportunities for future research in decision-centric visualization.",
      "authors": [
        "Lena Cibulski and Stefan Bruckner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:07:20+00:00",
          "link": "https://arxiv.org/abs/2507.18428v1",
          "size": "35kb",
          "version": "v1"
        }
      ],
      "title": "Towards Understanding Decision Problems As a Goal of Visualization Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18428",
        "HTML": "https://arxiv.org/html/2507.18428v1",
        "PDF": "https://arxiv.org/pdf/2507.18428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses visualization design to support decision-making processes and does not deal with any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18429",
      "abstract": "Head pose estimation (HPE) plays a critical role in various computer vision applications such as human-computer interaction and facial recognition. In this paper, we propose a novel deep learning approach for head pose estimation with limited training data via non-linear manifold learning called NLML-HPE. This method is based on the combination of tensor decomposition (i.e., Tucker decomposition) and feed forward neural networks. Unlike traditional classification-based approaches, our method formulates head pose estimation as a regression problem, mapping input landmarks into a continuous representation of pose angles. To this end, our method uses tensor decomposition to split each Euler angle (yaw, pitch, roll) to separate subspaces and models each dimension of the underlying manifold as a cosine curve. We address two key challenges: 1. Almost all HPE datasets suffer from incorrect and inaccurate pose annotations. Hence, we generated a precise and consistent 2D head pose dataset for our training set by rotating 3D head models for a fixed set of poses and rendering the corresponding 2D images. 2. We achieved real-time performance with limited training data as our method accurately captures the nature of rotation of an object from facial landmarks. Once the underlying manifold for rotation around each axis is learned, the model is very fast in predicting unseen data. Our training and testing code is available online along with our trained models: https: //github.com/MahdiGhafoorian/NLML_HPE.",
      "authors": [
        "Mahdi Ghafourian",
        "Federico M. Sukno"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:08:33+00:00",
          "link": "https://arxiv.org/abs/2507.18429v1",
          "size": "864kb",
          "version": "v1"
        }
      ],
      "title": "NLML-HPE: Head Pose Estimation with Limited Data via Manifold Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18429",
        "HTML": "https://arxiv.org/html/2507.18429v1",
        "PDF": "https://arxiv.org/pdf/2507.18429"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel method for head pose estimation using manifold learning. It involves the creation of a dataset for pose estimation but is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18431",
      "abstract": "City council meetings are vital sites for civic participation where the public can speak directly to their local government. By addressing city officials and calling on them to take action, public commenters can potentially influence policy decisions spanning a broad range of concerns, from housing, to sustainability, to social justice. Yet studies of these meetings have often been limited by the availability of large-scale, geographically-diverse data. Relying on local governments' increasing use of YouTube and other technologies to archive their public meetings, we propose a framework that characterizes comments along two dimensions: the local concerns where concerns are situated (e.g., housing, election administration), and the societal concerns raised (e.g., functional democracy, anti-racism). Based on a large record of public comments we collect from 15 cities in Michigan, we produce data-driven taxonomies of the local concerns and societal concerns that these comments cover, and employ machine learning methods to scalably apply our taxonomies across the entire dataset. We then demonstrate how our framework allows us to examine the salient local concerns and societal concerns that arise in our data, as well as how these aspects interact.",
      "authors": [
        "Chang Ge",
        "Justine Zhang",
        "Haofei Xu",
        "Yanna Krupnikov",
        "Jenna Bednar",
        "Sabina Tomkins"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:10:04+00:00",
          "link": "https://arxiv.org/abs/2507.18431v1",
          "size": "314kb",
          "version": "v1"
        }
      ],
      "title": "What does the public want their local government to hear? A data-driven case study of public comments across the state of Michigan",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18431",
        "PDF": "https://arxiv.org/pdf/2507.18431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for analyzing public comments from city council meetings in Michigan, which is unrelated to LLM training data processing. It does not involve any direct contributions to dataset creation or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18436",
      "abstract": "Robotic-assisted dressing has the potential to significantly aid both patients as well as healthcare personnel, reducing the workload and improving the efficiency in clinical settings. While substantial progress has been made in robotic dressing assistance, prior works typically assume that garments are already unfolded and ready for use. However, in medical applications gowns and aprons are often stored in a folded configuration, requiring an additional unfolding step. In this paper, we introduce the pre-dressing step, the process of unfolding garments prior to assisted dressing. We leverage imitation learning for learning three manipulation primitives, including both high and low acceleration motions. In addition, we employ a visual classifier to categorise the garment state as closed, partly opened, and fully opened. We conduct an empirical evaluation of the learned manipulation primitives as well as their combinations. Our results show that highly dynamic motions are not effective for unfolding freshly unpacked garments, where the combination of motions can efficiently enhance the opening configuration.",
      "authors": [
        "David Blanco-Mulero",
        "J\\'ulia Borr\\`as",
        "Carme Torras"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:15:56+00:00",
          "link": "https://arxiv.org/abs/2507.18436v1",
          "size": "2219kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18436",
        "HTML": "https://arxiv.org/html/2507.18436v1",
        "PDF": "https://arxiv.org/pdf/2507.18436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study discusses robotic-assisted garment unfolding using imitation learning. It is unrelated to data processing for LLM training, focusing instead on robotic manipulation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18442",
      "abstract": "The cognitive and reasoning abilities of large language models (LLMs) have enabled remarkable progress in natural language processing. However, their performance in interpreting structured data, especially in tabular formats, remains limited. Although benchmarks for English tabular data are widely available, Arabic is still underrepresented because of the limited availability of public resources and its unique language features. To address this gap, we present AraTable, a novel and comprehensive benchmark designed to evaluate the reasoning and understanding capabilities of LLMs when applied to Arabic tabular data. AraTable consists of various evaluation tasks, such as direct question answering, fact verification, and complex reasoning, involving a wide range of Arabic tabular sources. Our methodology follows a hybrid pipeline, where initial content is generated by LLMs and subsequently filtered and verified by human experts to ensure high dataset quality. Initial analyses using AraTable show that, while LLMs perform adequately on simpler tabular tasks such as direct question answering, they continue to face significant cognitive challenges when tasks require deeper reasoning and fact verification. This indicates that there are substantial opportunities for future work to improve performance on complex tabular reasoning tasks. We also propose a fully automated evaluation framework that uses a self-deliberation mechanism and achieves performance nearly identical to that of human judges. This research provides a valuable, publicly available resource and evaluation framework that can help accelerate the development of foundational models for processing and analysing Arabic structured data.",
      "authors": [
        "Rana Alshaikh",
        "Israa Alghanmi",
        "Shelan Jeawak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:26:41+00:00",
          "link": "https://arxiv.org/abs/2507.18442v1",
          "size": "1857kb",
          "version": "v1"
        }
      ],
      "title": "AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18442",
        "HTML": "https://arxiv.org/html/2507.18442v1",
        "PDF": "https://arxiv.org/pdf/2507.18442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "AraTable is a newly created benchmark for evaluating LLMs' understanding and reasoning with Arabic tabular data. It involves generating, filtering, and verifying dataset content to ensure high quality, which is a significant contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18443",
      "abstract": "We consider the inverse problem of identifying the drift in an SDE from $n$ observations of its solution at $M+1$ distinct time points. We derive a corresponding MAP estimate, we prove differentiability properties as well as a so-called tangential cone condition for the forward operator, and we review the existing theory for related problems, which under a slightly stronger tangential cone condition would additionally yield convergence rates for the MAP estimate as $n\\to\\infty$. Numerical simulations in 1D indicate that such convergence rates indeed hold true.",
      "authors": [
        "Daniel Tenbrinck",
        "Nikolas Uesseler",
        "Philipp Wacker and Benedikt Wirth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:29:16+00:00",
          "link": "https://arxiv.org/abs/2507.18443v1",
          "size": "1399kb",
          "version": "v1"
        }
      ],
      "title": "On MAP estimates and source conditions for drift identification in SDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18443",
        "HTML": "https://arxiv.org/html/2507.18443v1",
        "PDF": "https://arxiv.org/pdf/2507.18443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on inverse problems in SDEs and MAP estimates, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18444",
      "abstract": "Visual Place Recognition (VPR) is crucial for robust mobile robot localization, yet it faces significant challenges in maintaining reliable performance under varying environmental conditions and viewpoints. To address this, we propose a novel framework that integrates Dual-Scale-Former (DSFormer), a Transformer-based cross-learning module, with an innovative block clustering strategy. DSFormer enhances feature representation by enabling bidirectional information transfer between dual-scale features extracted from the final two CNN layers, capturing both semantic richness and spatial details through self-attention for long-range dependencies within each scale and shared cross-attention for cross-scale learning. Complementing this, our block clustering strategy repartitions the widely used San Francisco eXtra Large (SF-XL) training dataset from multiple distinct perspectives, optimizing data organization to further bolster robustness against viewpoint variations. Together, these innovations not only yield a robust global embedding adaptable to environmental changes but also reduce the required training data volume by approximately 30\\% compared to previous partitioning methods. Comprehensive experiments demonstrate that our approach achieves state-of-the-art performance across most benchmark datasets, surpassing advanced reranking methods like DELG, Patch-NetVLAD, TransVPR, and R2Former as a global retrieval solution using 512-dim global descriptors, while significantly improving computational efficiency.",
      "authors": [
        "Haiyang Jiang",
        "Songhao Piao",
        "Chao Gao",
        "Lei Yu",
        "Liguo Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:29:30+00:00",
          "link": "https://arxiv.org/abs/2507.18444v1",
          "size": "231kb",
          "version": "v1"
        }
      ],
      "title": "DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18444",
        "HTML": "https://arxiv.org/html/2507.18444v1",
        "PDF": "https://arxiv.org/pdf/2507.18444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses a block clustering strategy to optimize data organization for Visual Place Recognition, the main focus is on transformer architecture and feature representation, not LLM-specific training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18447",
      "abstract": "Understanding a driver's behavior and intentions is important for potential risk assessment and early accident prevention. Safety and driver assistance systems can be tailored to individual drivers' behavior, significantly enhancing their effectiveness. However, existing datasets are limited in describing and explaining general vehicle movements based on external visual evidence. This paper introduces a benchmark, PDB-Eval, for a detailed understanding of Personalized Driver Behavior, and aligning Large Multimodal Models (MLLMs) with driving comprehension and reasoning. Our benchmark consists of two main components, PDB-X and PDB-QA. PDB-X can evaluate MLLMs' understanding of temporal driving scenes. Our dataset is designed to find valid visual evidence from the external view to explain the driver's behavior from the internal view. To align MLLMs' reasoning abilities with driving tasks, we propose PDB-QA as a visual explanation question-answering task for MLLM instruction fine-tuning. As a generic learning task for generative models like MLLMs, PDB-QA can bridge the domain gap without harming MLLMs' generalizability. Our evaluation indicates that fine-tuning MLLMs on fine-grained descriptions and explanations can effectively bridge the gap between MLLMs and the driving domain, which improves zero-shot performance on question-answering tasks by up to 73.2%. We further evaluate the MLLMs fine-tuned on PDB-X in Brain4Cars' intention prediction and AIDE's recognition tasks. We observe up to 12.5% performance improvements on the turn intention prediction task in Brain4Cars, and consistent performance improvements up to 11.0% on all tasks in AIDE.",
      "authors": [
        "Junda Wu",
        "Jessica Echterhoff",
        "Kyungtae Han",
        "Amr Abdelraouf",
        "Rohit Gupta",
        "and Julian McAuley"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:33:06+00:00",
          "link": "https://arxiv.org/abs/2507.18447v1",
          "size": "3002kb",
          "version": "v1"
        }
      ],
      "title": "PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18447",
        "HTML": "https://arxiv.org/html/2507.18447v1",
        "PDF": "https://arxiv.org/pdf/2507.18447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces PDB-Eval, a benchmark for evaluating and fine-tuning multimodal models on personalized driving behavior, specifically focusing on MLLM instruction fine-tuning involving data processing, making it relevant for LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18448",
      "abstract": "Punctuation restoration enhances the readability of text and is critical for post-processing tasks in Automatic Speech Recognition (ASR), especially for low-resource languages like Bangla. In this study, we explore the application of transformer-based models, specifically XLM-RoBERTa-large, to automatically restore punctuation in unpunctuated Bangla text. We focus on predicting four punctuation marks: period, comma, question mark, and exclamation mark across diverse text domains. To address the scarcity of annotated resources, we constructed a large, varied training corpus and applied data augmentation techniques. Our best-performing model, trained with an augmentation factor of alpha = 0.20%, achieves an accuracy of 97.1% on the News test set, 91.2% on the Reference set, and 90.2% on the ASR set.\n  Results show strong generalization to reference and ASR transcripts, demonstrating the model's effectiveness in real-world, noisy scenarios. This work establishes a strong baseline for Bangla punctuation restoration and contributes publicly available datasets and code to support future research in low-resource NLP.",
      "authors": [
        "Md Obyedullahil Mamun",
        "Md Adyelullahil Mamun",
        "Arif Ahmad",
        "Md. Imran Hossain Emu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:33:13+00:00",
          "link": "https://arxiv.org/abs/2507.18448v1",
          "size": "404kb",
          "version": "v1"
        }
      ],
      "title": "Restoring Rhythm: Punctuation Restoration Using Transformer Models for Bangla, a Low-Resource Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18448",
        "HTML": "https://arxiv.org/html/2507.18448v1",
        "PDF": "https://arxiv.org/pdf/2507.18448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper creates a large annotated training corpus and applies data augmentation for punctuation restoration in Bangla, contributing to dataset creation and improving data quality, which is central to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18449",
      "abstract": "The advancement of the Internet of Things (IoT) and Artificial Intelligence has catalyzed the evolution of Digital Twins (DTs) from conceptual ideas to more implementable realities. Yet, transitioning from academia to industry is complex due to the absence of standardized frameworks. This paper builds upon the authors' previously established functional and informational requirements supporting standardized DT development, focusing on a crucial aspect: transferability. While existing DT research primarily centers on asset transfer, the significance of \"sim-to-real transfer\" and \"real-to-sim transfer\"--transferring knowledge between simulations and real-world operations--is vital for comprehensive lifecycle management in DTs. A key challenge in this process is calibrating the \"reality gap,\" the discrepancy between simulated predictions and actual outcomes. Our research investigates the impact of integrating a single Reality Gap Analysis (RGA) module into an existing DT framework to effectively manage both sim-to-real and real-to-sim transfers. This integration is facilitated by data pipelines that connect the RGA module with the existing components of the DT framework, including the historical repository and the simulation model. A case study on a pedestrian bridge at Carnegie Mellon University showcases the performance of different levels of integration of our approach with an existing framework. With full implementation of an RGA module and a complete data pipeline, our approach is capable of bidirectional knowledge transfer between simulations and real-world operations without compromising efficiency.",
      "authors": [
        "Sizhe Ma",
        "Katherine A. Flanigan",
        "and Mario Berg\\'es"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T12:56:36+00:00",
          "link": "https://arxiv.org/abs/2507.18449v1",
          "size": "602kb",
          "version": "v1"
        }
      ],
      "title": "Digital Twin Technologies in Predictive Maintenance: Enabling Transferability via Sim-to-Real and Real-to-Sim Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18449",
        "PDF": "https://arxiv.org/pdf/2507.18449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses digital twin technologies focusing on sim-to-real and real-to-sim transfer, with no mention of LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18450",
      "abstract": "The visualization of multi-dimensional data with interpretable methods remains limited by capabilities for both high-dimensional lossless visualizations that do not suffer from occlusion and that are computationally capable by parameterized visualization. This paper proposes a low to high dimensional data supporting framework using lossless Concentric Coordinates that are a more compact generalization of Parallel Coordinates along with former Circular Coordinates. These are forms of the General Line Coordinate visualizations that can directly support machine learning algorithm visualization and facilitate human interaction.",
      "authors": [
        "Alice Williams and Boris Kovalerchuk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T22:22:05+00:00",
          "link": "https://arxiv.org/abs/2507.18450v1",
          "size": "1078kb",
          "version": "v1"
        }
      ],
      "title": "High-Dimensional Data Classification in Concentric Coordinates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18450",
        "PDF": "https://arxiv.org/pdf/2507.18450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on visualization techniques for high-dimensional data, specifically using concentric coordinates, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18451",
      "abstract": "Generating clinical synthetic text represents an effective solution for common clinical NLP issues like sparsity and privacy. This paper aims to conduct a systematic review on generating synthetic medical free-text by formulating quantitative analysis to three research questions concerning (i) the purpose of generation, (ii) the techniques, and (iii) the evaluation methods. We searched PubMed, ScienceDirect, Web of Science, Scopus, IEEE, Google Scholar, and arXiv databases for publications associated with generating synthetic medical unstructured free-text. We have identified 94 relevant articles out of 1,398 collected ones. A great deal of attention has been given to the generation of synthetic medical text from 2018 onwards, where the main purpose of such a generation is towards text augmentation, assistive writing, corpus building, privacy-preserving, annotation, and usefulness. Transformer architectures were the main predominant technique used to generate the text, especially the GPTs. On the other hand, there were four main aspects of evaluation, including similarity, privacy, structure, and utility, where utility was the most frequent method used to assess the generated synthetic medical text. Although the generated synthetic medical text demonstrated a moderate possibility to act as real medical documents in different downstream NLP tasks, it has proven to be a great asset as augmented, complementary to the real documents, towards improving the accuracy and overcoming sparsity/undersampling issues. Yet, privacy is still a major issue behind generating synthetic medical text, where more human assessments are needed to check for the existence of any sensitive information. Despite that, advances in generating synthetic medical text will considerably accelerate the adoption of workflows and pipeline development, discarding the time-consuming legalities of data transfer.",
      "authors": [
        "Basel Alshaikhdeeb",
        "Ahmed Abdelmonem Hemedan",
        "Soumyabrata Ghosh",
        "Irina Balaur",
        "and Venkata Satagopam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:35:16+00:00",
          "link": "https://arxiv.org/abs/2507.18451v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Generation of Synthetic Clinical Text: A Systematic Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18451",
        "PDF": "https://arxiv.org/pdf/2507.18451"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper reviews techniques for generating synthetic clinical text, which involves data generation and augmentation, directly impacting training data processing for LLM fine-tuning, especially in clinical NLP applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18452",
      "abstract": "Recent advances in Large language models (LLMs) have shown remarkable capabilities across textual and multimodal domains. In parallel, diffusion-based language models have emerged as a promising alternative to the autoregressive paradigm, offering improved controllability, bidirectional context modeling, and robust generation. However, their application to the audio modality remains underexplored. In this work, we introduce \\textbf{DIFFA}, the first diffusion-based Large Audio-Language Model designed to perform spoken language understanding. DIFFA integrates a frozen diffusion language model with a lightweight dual-adapter architecture that bridges speech understanding and natural language reasoning. We employ a two-stage training pipeline: first, aligning semantic representations via an ASR objective; then, learning instruction-following abilities through synthetic audio-caption pairs automatically generated by prompting LLMs. Despite being trained on only 960 hours of ASR and 127 hours of synthetic instruction data, DIFFA demonstrates competitive performance on major benchmarks, including MMSU, MMAU, and VoiceBench, outperforming several autoregressive open-source baselines. Our results reveal the potential of diffusion-based language models for efficient and scalable audio understanding, opening a new direction for speech-driven AI. Our code will be available at https://github.com/NKU-HLT/DIFFA.git.",
      "authors": [
        "Jiaming Zhou",
        "Hongjie Chen",
        "Shiwan Zhao",
        "Jian Kang",
        "Jie Li",
        "Enzhi Wang",
        "Yujie Guo",
        "Haoqin Sun",
        "Hui Wang",
        "Aobo Kong",
        "Yong Qin",
        "Xuelong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:35:52+00:00",
          "link": "https://arxiv.org/abs/2507.18452v1",
          "size": "194kb",
          "version": "v1"
        }
      ],
      "title": "DIFFA: Large Language Diffusion Models Can Listen and Understand",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18452",
        "HTML": "https://arxiv.org/html/2507.18452v1",
        "PDF": "https://arxiv.org/pdf/2507.18452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a diffusion-based model for audio understanding, it mentions the use of synthetic audio-caption pairs for training. However, data processing is not the main focus, and the main contribution lies in model architecture."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18454",
      "abstract": "Utilizing CPUs to serve large language models (LLMs) is a resource-friendly alternative to GPU serving. Existing CPU-based solutions ignore workload differences between the prefill and the decode phases of LLM inference, applying a static per-NUMA (Non-Uniform Memory Access) node model partition and utilizing vendor libraries for operator-level execution, which is suboptimal. We propose Sandwich, a hardware-centric CPU-based LLM serving engine that uses different execution plans for the prefill and decode phases and optimizes them separately.\n  We evaluate Sandwich across diverse baselines and datasets on five CPU platforms, including x86 with AVX-2 and AVX-512, as well as ARM with NEON. Sandwich achieves an average 2.01x throughput improvement and 90% satisfactory time-to-first-token (TTFT) and time-per-output-token (TPOT) latencies with up to 3.40x lower requirements in single sequence serving, and significant improvement in Goodput in continuous-batching serving. The GEMM kernels generated by Sandwich outperform representative vendor kernels and other dynamic shape solutions, achieving performance comparable to static compilers with three orders of magnitude less kernel tuning costs.",
      "authors": [
        "Juntao Zhao",
        "Jiuru Li",
        "Chuan Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T06:37:29+00:00",
          "link": "https://arxiv.org/abs/2507.18454v1",
          "size": "507kb",
          "version": "v1"
        }
      ],
      "title": "Sandwich: Separating Prefill-Decode Compilation for Efficient CPU LLM Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18454",
        "HTML": "https://arxiv.org/html/2507.18454v1",
        "PDF": "https://arxiv.org/pdf/2507.18454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses CPU-based LLM serving optimizations, dealing with inference performance rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18455",
      "abstract": "In common law systems, legal professionals such as lawyers and judges rely on precedents to build their arguments. As the volume of cases has grown massively over time, effectively retrieving prior cases has become essential. Prior case retrieval (PCR) is an information retrieval (IR) task that aims to automatically identify the most relevant court cases for a specific query from a large pool of potential candidates. While IR methods have seen several paradigm shifts over the last few years, the vast majority of PCR methods continue to rely on traditional IR methods, such as BM25. The state-of-the-art deep learning IR methods have not been successful in PCR due to two key challenges: i. Lengthy legal text limitation; when using the powerful BERT-based transformer models, there is a limit of input text lengths, which inevitably requires to shorten the input via truncation or division with a loss of legal context information. ii. Lack of legal training data; due to data privacy concerns, available PCR datasets are often limited in size, making it difficult to train deep learning-based models effectively. In this research, we address these challenges by leveraging LLM-based text embedders in PCR. LLM-based embedders support longer input lengths, and since we use them in an unsupervised manner, they do not require training data, addressing both challenges simultaneously. In this paper, we evaluate state-of-the-art LLM-based text embedders in four PCR benchmark datasets and show that they outperform BM25 and supervised transformer-based models.",
      "authors": [
        "Damith Premasiri",
        "Tharindu Ranasinghe",
        "Ruslan Mitkov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:36:10+00:00",
          "link": "https://arxiv.org/abs/2507.18455v1",
          "size": "5601kb",
          "version": "v1"
        }
      ],
      "title": "LLM-based Embedders for Prior Case Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18455",
        "HTML": "https://arxiv.org/html/2507.18455v1",
        "PDF": "https://arxiv.org/pdf/2507.18455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on prior case retrieval in the legal domain using LLM-based embedders without mentioning LLM training data processing, data collection, or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18457",
      "abstract": "Adversarial robustness in LiDAR-based 3D object detection is a critical research area due to its widespread application in real-world scenarios. While many digital attacks manipulate point clouds or meshes, they often lack physical realizability, limiting their practical impact. Physical adversarial object attacks remain underexplored and suffer from poor reproducibility due to inconsistent setups and hardware differences. To address this, we propose a device-agnostic, standardized framework that abstracts key elements of physical adversarial object attacks, supports diverse methods, and provides open-source code with benchmarking protocols in simulation and real-world settings. Our framework enables fair comparison, accelerates research, and is validated by successfully transferring simulated attacks to a physical LiDAR system. Beyond the framework, we offer insights into factors influencing attack success and advance understanding of adversarial robustness in real-world LiDAR perception.",
      "authors": [
        "Luo Cheng",
        "Hanwei Zhang",
        "Lijun Zhang",
        "Holger Hermanns"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:37:00+00:00",
          "link": "https://arxiv.org/abs/2507.18457v1",
          "size": "15327kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18457",
        "HTML": "https://arxiv.org/html/2507.18457v1",
        "PDF": "https://arxiv.org/pdf/2507.18457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses adversarial attacks in LiDAR-based detection, emphasizing robustness against physical attacks rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18459",
      "abstract": "The rapid growth of global data volumes has created a demand for scalable distributed systems that can maintain a high quality of service. Data replication is a widely used technique that provides fault tolerance, improved performance and higher availability. Traditional implementations often rely on threshold-based activation mechanisms, which can vary depending on workload changes and system architecture. System administrators typically bear the responsibility of adjusting these thresholds. To address this challenge, reinforcement learning can be used to dynamically adapt to workload changes and different architectures. In this paper, we propose a novel data replication strategy for cloud systems that employs reinforcement learning to automatically learn system characteristics and adapt to workload changes. The strategy's aim is to provide satisfactory Quality of Service while optimizing a trade-off between provider profit and environmental impact. We present the architecture behind our solution and describe the reinforcement learning model by defining the states, actions and rewards.",
      "authors": [
        "Amir Najjar",
        "Riad Mokadem",
        "Jean-Marc Pierson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:37:15+00:00",
          "link": "https://arxiv.org/abs/2507.18459v1",
          "size": "166kb",
          "version": "v1"
        }
      ],
      "title": "Towards Designing an Energy Aware Data Replication Strategy for Cloud Systems Using Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18459",
        "HTML": "https://arxiv.org/html/2507.18459v1",
        "PDF": "https://arxiv.org/pdf/2507.18459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research proposes an energy-aware data replication strategy in cloud systems using reinforcement learning, unrelated to LLM training data processing or the creation of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18462",
      "abstract": "In recent years, Compressed Sensing (CS) has gained significant interest as a technique for acquiring high-resolution sensory data using fewer measurements than traditional Nyquist sampling requires. At the same time, autonomous robotic platforms such as drones and rovers have become increasingly popular tools for remote sensing and environmental monitoring tasks, including measurements of temperature, humidity, and air quality. Within this context, this paper presents, to the best of our knowledge, the first investigation into how the structure of CS measurement matrices can be exploited to design optimized sampling trajectories for robotic environmental data collection. We propose a novel Monte Carlo optimization framework that generates measurement matrices designed to minimize both the robot's traversal path length and the signal reconstruction error within the CS framework. Central to our approach is the application of Dictionary Learning (DL) to obtain a data-driven sparsifying transform, which enhances reconstruction accuracy while further reducing the number of samples that the robot needs to collect. We demonstrate the effectiveness of our method through experiments reconstructing $NO_2$ pollution maps over the Gulf region. The results indicate that our approach can reduce robot travel distance to less than $10\\%$ of a full-coverage path, while improving reconstruction accuracy by over a factor of five compared to traditional CS methods based on DCT and polynomial dictionaries, as well as by a factor of two compared to previously-proposed Informative Path Planning (IPP) methods.",
      "authors": [
        "Alghalya Al-Hajri",
        "Ejmen Al-Ubejdij",
        "Aiman Erbad",
        "Ali Safa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:39:01+00:00",
          "link": "https://arxiv.org/abs/2507.18462v1",
          "size": "2520kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Monte-Carlo Compressed Sensing and Dictionary Learning Method for the Efficient Path Planning of Remote Sensing Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18462",
        "HTML": "https://arxiv.org/html/2507.18462v1",
        "PDF": "https://arxiv.org/pdf/2507.18462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study involves remote sensing robots and compressed sensing techniques for path planning, with no mention of LLM training data processing, data quality, or related dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18466",
      "abstract": "We consider the solution of full column-rank least squares problems by means of normal equations that are preconditioned, symmetrically or non-symmetrically, with a randomized preconditioner. With an effective preconditioner, the solutions from the preconditioned normal equations are almost as accurate as those from the QR-based Matlab backslash (mldivide) command -- even for highly illconditioned matrices. This means the accuracy of the preconditioned normal equations depends on the residual of the original least squares problem. We present non-intuitive but realistic perturbation bounds for the relative error in the computed solutions and show that, with an effective preconditioner, these bounds are essentially equal to the perturbation bound for the original least squares problem. Probabilitistic condition number bounds corroborate the effectiveness of the randomized preconditioner computed with small amounts of sampling.",
      "authors": [
        "Ilse C.F. Ipsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:41:02+00:00",
          "link": "https://arxiv.org/abs/2507.18466v1",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "title": "Solution of Least Squares Problems with Randomized Preconditioned Normal Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18466",
        "HTML": "https://arxiv.org/html/2507.18466v1",
        "PDF": "https://arxiv.org/pdf/2507.18466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with solving least squares problems using randomized preconditioned normal equations. It does not relate to any data processing operations or techniques aimed at improving LLM training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18467",
      "abstract": "Echo-State Networks (ESNs) distil a key neurobiological insight: richly recurrent but fixed circuitry combined with adaptive linear read-outs can transform temporal streams with remarkable efficiency. Yet fundamental questions about stability, memory and expressive power remain fragmented across disciplines. We present a unified, dynamical-systems treatment that weaves together functional analysis, random attractor theory and recent neuroscientific findings. First, on compact multivariate input alphabets we prove that the Echo-State Property (wash-out of initial conditions) together with global Lipschitz dynamics necessarily yields the Fading-Memory Property (geometric forgetting of remote inputs). Tight algebraic tests translate activation-specific Lipschitz constants into certified spectral-norm bounds, covering both saturating and rectifying nonlinearities. Second, employing a Stone-Weierstrass strategy we give a streamlined proof that ESNs with polynomial reservoirs and linear read-outs are dense in the Banach space of causal, time-invariant fading-memory filters, extending universality to stochastic inputs. Third, we quantify computational resources via memory-capacity spectrum, show how topology and leak rate redistribute delay-specific capacities, and link these trade-offs to Lyapunov spectra at the \\textit{edge of chaos}. Finally, casting ESNs as skew-product random dynamical systems, we establish existence of singleton pullback attractors and derive conditional Lyapunov bounds, providing a rigorous analogue to cortical criticality. The analysis yields concrete design rules-spectral radius, input gain, activation choice-grounded simultaneously in mathematics and neuroscience, and clarifies why modest-sized reservoirs often rival fully trained recurrent networks in practice.",
      "authors": [
        "Pradeep Singh",
        "Lavanya Sankaranarayanan",
        "Balasubramanian Raman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Chaotic Dynamics (nlin.CD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:41:18+00:00",
          "link": "https://arxiv.org/abs/2507.18467v1",
          "size": "20kb",
          "version": "v1"
        }
      ],
      "title": "Contraction, Criticality, and Capacity: A Dynamical-Systems Perspective on Echo-State Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18467",
        "HTML": "https://arxiv.org/html/2507.18467v1",
        "PDF": "https://arxiv.org/pdf/2507.18467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a dynamical-systems perspective on Echo-State Networks, which does not involve data processing or the improvement of data quality for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18473",
      "abstract": "Vehicle-to-everything (V2X) communication plays a crucial role in autonomous driving, enabling cooperation between vehicles and infrastructure. While simulation has significantly contributed to various autonomous driving tasks, its potential for data generation and augmentation in V2X scenarios remains underexplored. In this paper, we introduce CRUISE, a comprehensive reconstruction-and-synthesis framework designed for V2X driving environments. CRUISE employs decomposed Gaussian Splatting to accurately reconstruct real-world scenes while supporting flexible editing. By decomposing dynamic traffic participants into editable Gaussian representations, CRUISE allows for seamless modification and augmentation of driving scenes. Furthermore, the framework renders images from both ego-vehicle and infrastructure views, enabling large-scale V2X dataset augmentation for training and evaluation. Our experimental results demonstrate that: 1) CRUISE reconstructs real-world V2X driving scenes with high fidelity; 2) using CRUISE improves 3D detection across ego-vehicle, infrastructure, and cooperative views, as well as cooperative 3D tracking on the V2X-Seq benchmark; and 3) CRUISE effectively generates challenging corner cases.",
      "authors": [
        "Haoran Xu",
        "Saining Zhang",
        "Peishuo Li",
        "Baijun Ye",
        "Xiaoxue Chen",
        "Huan-ang Gao",
        "Jv Zheng",
        "Xiaowei Song",
        "Ziqiao Peng",
        "Run Miao",
        "Jinrang Jia",
        "Yifeng Shi",
        "Guangqi Yi",
        "Hang Zhao",
        "Hao Tang",
        "Hongyang Li",
        "Kaicheng Yu",
        "Hao Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:48:44+00:00",
          "link": "https://arxiv.org/abs/2507.18473v1",
          "size": "17000kb",
          "version": "v1"
        }
      ],
      "title": "CRUISE: Cooperative Reconstruction and Editing in V2X Scenarios using Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18473",
        "HTML": "https://arxiv.org/html/2507.18473v1",
        "PDF": "https://arxiv.org/pdf/2507.18473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The CRUISE framework involves data augmentation for V2X scenarios, which can indirectly contribute to training data processing for LLMs. However, the primary focus is on simulations and autonomous driving data, rather than direct LLM data processing improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18476",
      "abstract": "Code review is one of the key processes in the software development lifecycle and is essential to maintain code quality. However, manual code review is subjective and time consuming. Given its rule-based nature, code review is well suited for automation. In recent years, significant efforts have been made to automate this process with the help of artificial intelligence. Recent developments in Large Language Models (LLMs) have also emerged as a promising tool in this area, but these models often lack the logical reasoning capabilities needed to fully understand and evaluate code. To overcome this limitation, this study proposes a hybrid approach that integrates symbolic reasoning techniques with LLMs to automate the code review process. We tested our approach using the CodexGlue dataset, comparing several models, including CodeT5, CodeBERT, and GraphCodeBERT, to assess the effectiveness of combining symbolic reasoning and prompting techniques with LLMs. Our results show that this approach improves the accuracy and efficiency of automated code review.",
      "authors": [
        "Busra Icoz",
        "Goksel Biricik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:50:27+00:00",
          "link": "https://arxiv.org/abs/2507.18476v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "Automated Code Review Using Large Language Models with Symbolic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18476",
        "HTML": "https://arxiv.org/html/2507.18476v1",
        "PDF": "https://arxiv.org/pdf/2507.18476"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses automated code review with the integration of symbolic reasoning in LLMs, with a focus on software development rather than on the preprocessing or enhancement of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18478",
      "abstract": "Recent technological advancements and the prevalence of technology in day to day activities have caused a major increase in the likelihood of the involvement of digital evidence in more and more legal investigations. Consumer-grade hardware is growing more powerful, with expanding memory and storage sizes and enhanced processor capabilities. Forensics investigators often have to sift through gigabytes of data during an ongoing investigation making the process tedious. Memory forensics, disk analysis all are well supported by state of the art tools that significantly lower the effort required to be put in by a forensic investigator by providing string searches, analyzing images file etc. During the course of the investigation a lot of false positives are identified that need to be lowered. This work presents Scout, a digital forensics framework that performs preliminary evidence processing and prioritizing using large language models. Scout deploys foundational language models to identify relevant artifacts from a large number of potential evidence files (disk images, captured network packets, memory dumps etc.) which would have taken longer to get identified. Scout employs text based large language models can easily process files with textual information. For the forensic analysis of multimedia files like audio, image, video, office documents etc. multimodal models are employed by Scout. Scout was able to identify and realize the evidence file that were of potential interest for the investigator.",
      "authors": [
        "Shariq Murtuza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:54:14+00:00",
          "link": "https://arxiv.org/abs/2507.18478v1",
          "size": "514kb",
          "version": "v1"
        }
      ],
      "title": "Scout: Leveraging Large Language Models for Rapid Digital Evidence Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18478",
        "PDF": "https://arxiv.org/pdf/2507.18478"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a digital forensics framework utilizing LLMs for evidence processing in investigations, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18479",
      "abstract": "Prerequisite skills - foundational competencies required before mastering more advanced concepts - are important for supporting effective learning, assessment, and skill-gap analysis. Traditionally curated by domain experts, these relationships are costly to maintain and difficult to scale. This paper investigates whether large language models (LLMs) can predict prerequisite skills in a zero-shot setting, using only natural language descriptions and without task-specific fine-tuning. We introduce ESCO-PrereqSkill, a benchmark dataset constructed from the ESCO taxonomy, comprising 3,196 skills and their expert-defined prerequisite links. Using a standardized prompting strategy, we evaluate 13 state-of-the-art LLMs, including GPT-4, Claude 3, Gemini, LLaMA 4, Qwen2, and DeepSeek, across semantic similarity, BERTScore, and inference latency. Our results show that models such as LLaMA4-Maverick, Claude-3-7-Sonnet, and Qwen2-72B generate predictions that closely align with expert ground truth, demonstrating strong semantic reasoning without supervision. These findings highlight the potential of LLMs to support scalable prerequisite skill modeling for applications in personalized learning, intelligent tutoring, and skill-based recommender systems.",
      "authors": [
        "Ngoc Luyen Le",
        "Marie-H\\'el\\`ene Abel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:54:45+00:00",
          "link": "https://arxiv.org/abs/2507.18479v1",
          "size": "211kb",
          "version": "v1"
        }
      ],
      "title": "How Well Do LLMs Predict Prerequisite Skills? Zero-Shot Comparison to Expert-Defined Concepts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18479",
        "HTML": "https://arxiv.org/html/2507.18479v1",
        "PDF": "https://arxiv.org/pdf/2507.18479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates how LLMs predict prerequisite skills in a zero-shot setting. It does not contribute to LLM training data processing, but rather evaluates model performance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18480",
      "abstract": "IEEE 802.11 networks continuously adapt to meet the stringent requirements of emerging applications like cloud gaming, eXtended Reality (XR), and video streaming services, which require high throughput, low latency, and high reliability. To address these challenges, Coordinated Spatial Reuse (Co-SR) can potentially contribute to optimizing spectrum resource utilization. This mechanism is expected to enable simultaneous transmissions, thereby boosting spectral efficiency in dense environments and increasing the overall network performance. In this paper, we shed light on the performance of Co-SR for Wi-Fi 8 networks. For that, we propose an implementation of Co-SR aligned with ongoing Wi-Fi 8 standardization efforts. The evaluation is done on a Wi-Fi simulator, which allows us to study the performance of the proposed Co-SR mechanisms in relevant scenarios. The results obtained in a Wireless Local Area Network (WLAN) consisting of four APs show delay reduction with Co-SR ranging from 31% to 95% when compared to Distributed Coordination Function (DCF).",
      "authors": [
        "David Nunez",
        "Francesc Wilhelmi",
        "Lorenzo Galati-Giordano",
        "Giovanni Geraci and Boris Bellalta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:55:17+00:00",
          "link": "https://arxiv.org/abs/2507.18480v1",
          "size": "242kb",
          "version": "v1"
        }
      ],
      "title": "Improving Wi-Fi 8 Latency with Coordinated Spatial Reuse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18480",
        "HTML": "https://arxiv.org/html/2507.18480v1",
        "PDF": "https://arxiv.org/pdf/2507.18480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses Wi-Fi network performance optimization, specifically with Coordinated Spatial Reuse, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18481",
      "abstract": "Anomaly detection in medical images is an important yet challenging task due to the diversity of possible anomalies and the practical impossibility of collecting comprehensively annotated data sets. In this work, we tackle unsupervised medical anomaly detection proposing a modernized autoencoder-based framework, the Q-Former Autoencoder, that leverages state-of-the-art pretrained vision foundation models, such as DINO, DINOv2 and Masked Autoencoder. Instead of training encoders from scratch, we directly utilize frozen vision foundation models as feature extractors, enabling rich, multi-stage, high-level representations without domain-specific fine-tuning. We propose the usage of the Q-Former architecture as the bottleneck, which enables the control of the length of the reconstruction sequence, while efficiently aggregating multiscale features. Additionally, we incorporate a perceptual loss computed using features from a pretrained Masked Autoencoder, guiding the reconstruction towards semantically meaningful structures. Our framework is evaluated on four diverse medical anomaly detection benchmarks, achieving state-of-the-art results on BraTS2021, RESC, and RSNA. Our results highlight the potential of vision foundation model encoders, pretrained on natural images, to generalize effectively to medical image analysis tasks without further fine-tuning. We release the code and models at https://github.com/emirhanbayar/QFAE.",
      "authors": [
        "Francesco Dalmonte and Emirhan Bayar and Emre Akbas and Mariana-Iuliana Georgescu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:55:33+00:00",
          "link": "https://arxiv.org/abs/2507.18481v1",
          "size": "2248kb",
          "version": "v1"
        }
      ],
      "title": "Q-Former Autoencoder: A Modern Framework for Medical Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18481",
        "HTML": "https://arxiv.org/html/2507.18481v1",
        "PDF": "https://arxiv.org/pdf/2507.18481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on unsupervised medical anomaly detection with a new autoencoder framework, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18483",
      "abstract": "Accurate detection of Plasmodium falciparum in Giemsa-stained blood smears is an essential component of reliable malaria diagnosis, especially in developing countries. Deep learning-based object detection methods have demonstrated strong potential for automated Malaria diagnosis, but their adoption is limited by the scarcity of datasets with detailed instance-level annotations. In this work, we present an enhanced version of the publicly available NIH malaria dataset, with detailed bounding box annotations in COCO format to support object detection training. We validated the revised annotations by training a Faster R-CNN model to detect infected and non-infected red blood cells, as well as white blood cells. Cross-validation on the original dataset yielded F1 scores of up to 0.88 for infected cell detection. These results underscore the importance of annotation volume and consistency, and demonstrate that automated annotation refinement combined with targeted manual correction can produce training data of sufficient quality for robust detection performance. The updated annotations set is publicly available via GitHub: https://github.com/MIRA-Vision-Microscopy/malaria-thin-smear-coco.",
      "authors": [
        "Frauke Wilm",
        "Luis Carlos Rivera Monroy",
        "Mathias \\\"Ottl",
        "Lukas M\\\"urdter",
        "Leonid Mill",
        "Andreas Maier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:56:18+00:00",
          "link": "https://arxiv.org/abs/2507.18483v1",
          "size": "6195kb",
          "version": "v1"
        }
      ],
      "title": "A COCO-Formatted Instance-Level Dataset for Plasmodium Falciparum Detection in Giemsa-Stained Blood Smears",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18483",
        "HTML": "https://arxiv.org/html/2507.18483v1",
        "PDF": "https://arxiv.org/pdf/2507.18483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents an enhanced malaria dataset with detailed annotations in COCO format for training deep learning models. It creates a new dataset for robust object detection, which is a core aspect of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18484",
      "abstract": "Adversarial attacks in 3D environments have emerged as a critical threat to the reliability of visual perception systems, particularly in safety-sensitive applications such as identity verification and autonomous driving. These attacks employ adversarial patches and 3D objects to manipulate deep neural network (DNN) predictions by exploiting vulnerabilities within complex scenes. Existing defense mechanisms, such as adversarial training and purification, primarily employ passive strategies to enhance robustness. However, these approaches often rely on pre-defined assumptions about adversarial tactics, limiting their adaptability in dynamic 3D settings. To address these challenges, we introduce Reinforced Embodied Active Defense (Rein-EAD), a proactive defense framework that leverages adaptive exploration and interaction with the environment to improve perception robustness in 3D adversarial contexts. By implementing a multi-step objective that balances immediate prediction accuracy with predictive entropy minimization, Rein-EAD optimizes defense strategies over a multi-step horizon. Additionally, Rein-EAD involves an uncertainty-oriented reward-shaping mechanism that facilitates efficient policy updates, thereby reducing computational overhead and supporting real-world applicability without the need for differentiable environments. Comprehensive experiments validate the effectiveness of Rein-EAD, demonstrating a substantial reduction in attack success rates while preserving standard accuracy across diverse tasks. Notably, Rein-EAD exhibits robust generalization to unseen and adaptive attacks, making it suitable for real-world complex tasks, including 3D object classification, face recognition and autonomous driving.",
      "authors": [
        "Xiao Yang",
        "Lingxuan Wu",
        "Lizhong Wang",
        "Chengyang Ying",
        "Hang Su",
        "Jun Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:56:21+00:00",
          "link": "https://arxiv.org/abs/2507.18484v1",
          "size": "40353kb",
          "version": "v1"
        }
      ],
      "title": "Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18484",
        "HTML": "https://arxiv.org/html/2507.18484v1",
        "PDF": "https://arxiv.org/pdf/2507.18484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a defense framework for visual perception systems in adversarial 3D environments. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18487",
      "abstract": "In this conference contribution, we present some initial results on switching memristive devices exhibiting fractional-order behavior using current pulses. In our model, it is assumed that the evolution of a state variable follows a fractional-order differential equation involving a Caputo-type derivative. A study of Joule losses demonstrates that the best switching strategy minimizing these losses depends on the fractional derivative's order and the power exponent in the equation of motion. It is found that when the order of the fractional derivative exceeds half of the power exponent, the best approach is to employ a wide pulse. Conversely, when this condition is not met, Joule losses are minimized by applying a zero current followed by a narrow current pulse of the highest allowable amplitude. These findings are explored further in the context of multi-pulse control. Our research lays the foundation for the advancement of the next generation of energy-efficient neuromorphic computing architectures that more closely mimic their biological counterparts.",
      "authors": [
        "Nathan Astin and Yuriy V. Pershin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:01:05+00:00",
          "link": "https://arxiv.org/abs/2507.18487v1",
          "size": "648kb",
          "version": "v1"
        }
      ],
      "title": "Low-power switching of memristors exhibiting fractional-order dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18487",
        "HTML": "https://arxiv.org/html/2507.18487v1",
        "PDF": "https://arxiv.org/pdf/2507.18487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores memristive devices and their switching behavior under fractional-order dynamics for neuromorphic computing, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18489",
      "abstract": "The efficiency and scalability of graph convolution networks (GCNs) in training recommender systems remain critical challenges, hindering their practical deployment in real-world scenarios. In the multimodal recommendation (MMRec) field, training GCNs requires more expensive time and space costs and exacerbates the gap between different modalities, resulting in sub-optimal recommendation accuracy. This paper critically points out the inherent challenges associated with adopting GCNs during the training phase in MMRec, revealing that GCNs inevitably create unhelpful and even harmful pairs during model optimization and isolate different modalities. To this end, we propose FastMMRec, a highly efficient multimodal recommendation framework that deploys graph convolutions exclusively during the testing phase, bypassing their use in training. We demonstrate that adopting GCNs solely in the testing phase significantly improves the model's efficiency and scalability while alleviating the modality isolation problem often caused by using GCNs during the training phase. We conduct extensive experiments on three public datasets, consistently demonstrating the performance superiority of FastMMRec over competitive baselines while achieving efficiency and scalability.",
      "authors": [
        "Jinfeng Xu",
        "Zheyu Chen",
        "Shuo Yang",
        "Jinze Li",
        "Edith C. H. Ngai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:02:22+00:00",
          "link": "https://arxiv.org/abs/2507.18489v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "The Best is Yet to Come: Graph Convolution in the Testing Phase for Multimodal Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18489",
        "HTML": "https://arxiv.org/html/2507.18489v1",
        "PDF": "https://arxiv.org/pdf/2507.18489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the challenges of using graph convolution networks in multimodal recommendation systems, but it does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18491",
      "abstract": "We present a fast multipole method (FMM) for solving Maxwell's equations in three-dimensional (3-D) layered media, based on the magnetic vector potential $\\boldsymbol A$ under the Lorenz gauge, to derive the layered dyadic Green's function. The dyadic Green's function is represented using three scalar Helmholtz layered Green's functions, with all interface-induced reaction field components expressed through a unified integral representation. By introducing equivalent polarization images for sources and effective locations for targets to reflect the actual transmission distance of different reaction field components, multiple expansions (MEs) and local expansions (LEs) are derived for the far-field governed by actual transmission distance. To further enhance computational efficiency and numerical stability, we employ a Chebyshev polynomial expansion of the associated Legendre functions to speed up the calculation of multipole-to-local (M2L) expansion translations. Finally, leveraging the FMM framework of the Helmholtz equation in 3-D layered media, we develop a FMM for the dyadic Green's function of Maxwell's equations in layered media. Numerical experiments demonstrate the $\\mathcal O(N\\log N)$-complexity of the resulting FMM method, and rapid convergence for interactions of low-frequency electromagnetic wave sources in 3-D layered media.",
      "authors": [
        "Heng Yuan",
        "Bo Wang",
        "Wenzhong Zhang",
        "Wei Cai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:04:12+00:00",
          "link": "https://arxiv.org/abs/2507.18491v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Fast Multipole Method for Maxwell's Equations in Layered Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18491",
        "HTML": "https://arxiv.org/html/2507.18491v1",
        "PDF": "https://arxiv.org/pdf/2507.18491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a fast multipole method for solving Maxwell's equations in layered media, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18492",
      "abstract": "Water utilities aim to reduce the high electrical costs of Water Distribution Networks (WDNs), primarily driven by pumping. However, pump scheduling is challenging due to model uncertainties and water demand forecast errors. This paper presents a Robust Model Predictive Control (RMPC) method for optimal and reliable pump scheduling, extending a previous efficient robust control method tailored to our model. A linear model with bounded additive disturbances is used to represent tank water level evolution, with uncertainty bounds derived from WDN simulation and demand data. At each time step, a pump scheduling policy, affine in past disturbances, is optimized to satisfy system constraints over a prediction horizon. The resulting policies are then applied in a receding horizon fashion. The optimization problem is formulated to require $\\mathcal{O}(N^6)$ computations per iteration with an interior-point method, which is reduced to $\\mathcal{O}(N^3)$ by reformulating it into a sparse form. When evaluated on a model representing the water distribution network of Randers, a medium-sized town in Denmark, the method surpasses nominal and constraint-tightening model predictive control (MPC) approaches in terms of meeting constraints and provides comparable economic outcomes.",
      "authors": [
        "Mirhan \\\"Urkmez",
        "Carsten Kalles{\\o}e",
        "Jan Dimon Bendtsen",
        "Eric C. Kerrigan",
        "John Leth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:04:53+00:00",
          "link": "https://arxiv.org/abs/2507.18492v1",
          "size": "132kb",
          "version": "v1"
        }
      ],
      "title": "A Robust Predictive Control Method for Pump Scheduling in Water Distribution Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18492",
        "HTML": "https://arxiv.org/html/2507.18492v1",
        "PDF": "https://arxiv.org/pdf/2507.18492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a predictive control method for pump scheduling in water distribution networks, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18493",
      "abstract": "Linear observed systems on groups encode the geometry of a variety of practical state estimation problems. In this paper, we propose a unified observer framework for a class of linear observed systems by restricting a bi-invariant system on a Lie group to its normal subgroup. This structural property powerfully enables a system immersion of the original system into a linear time-varying system. Leveraging the immersion, an observer is constructed by first designing a Kalman-like observer for the immersed system and then reconstructing the group-valued state via optimization. Under a rank condition, global exponential stability (GES) is achieved provided one global optimum of the reconstruction optimization is found, reflecting the topological difficulties inherent to the non-Euclidean state space. Semi-global stability is guaranteed when input biases are jointly estimated. The theory is applied to the GES observer design for two-frame systems, capable of modeling a family of navigation problems. Two non-trivial examples are provided to illustrate implementation details.",
      "authors": [
        "Changwu Liu and Yuan Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:05:23+00:00",
          "link": "https://arxiv.org/abs/2507.18493v1",
          "size": "253kb",
          "version": "v1"
        }
      ],
      "title": "Global Observer Design for a Class of Linear Observed Systems on Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18493",
        "HTML": "https://arxiv.org/html/2507.18493v1",
        "PDF": "https://arxiv.org/pdf/2507.18493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on observer design for linear observed systems and does not address aspects of LLM training data processing, such as dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18498",
      "abstract": "Recent advances in autonomous driving are moving towards mapless approaches, where High-Definition (HD) maps are generated online directly from sensor data, reducing the need for expensive labeling and maintenance. However, the reliability of these online-generated maps remains uncertain. While incorporating map uncertainty into downstream trajectory prediction tasks has shown potential for performance improvements, current strategies provide limited insights into the specific scenarios where this uncertainty is beneficial. In this work, we first analyze the driving scenarios in which mapping uncertainty has the greatest positive impact on trajectory prediction and identify a critical, previously overlooked factor: the agent's kinematic state. Building on these insights, we propose a novel Proprioceptive Scenario Gating that adaptively integrates map uncertainty into trajectory prediction based on forecasts of the ego vehicle's future kinematics. This lightweight, self-supervised approach enhances the synergy between online mapping and trajectory prediction, providing interpretability around where uncertainty is advantageous and outperforming previous integration methods. Additionally, we introduce a Covariance-based Map Uncertainty approach that better aligns with map geometry, further improving trajectory prediction. Extensive ablation studies confirm the effectiveness of our approach, achieving up to 23.6% improvement in mapless trajectory prediction performance over the state-of-the-art method using the real-world nuScenes driving dataset. Our code, data, and models are publicly available at https://github.com/Ethan-Zheng136/Map-Uncertainty-for-Trajectory-Prediction.",
      "authors": [
        "Zongzheng Zhang",
        "Xuchong Qiu",
        "Boran Zhang",
        "Guantian Zheng",
        "Xunjiang Gu",
        "Guoxuan Chi",
        "Huan-ang Gao",
        "Leichen Wang",
        "Ziming Liu",
        "Xinrun Li",
        "Igor Gilitschenski",
        "Hongyang Li",
        "Hang Zhao",
        "Hao Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:13:11+00:00",
          "link": "https://arxiv.org/abs/2507.18498v1",
          "size": "1062kb",
          "version": "v1"
        }
      ],
      "title": "Delving into Mapping Uncertainty for Mapless Trajectory Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18498",
        "HTML": "https://arxiv.org/html/2507.18498v1",
        "PDF": "https://arxiv.org/pdf/2507.18498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses trajectory prediction for autonomous vehicles, involving map uncertainty and kinematic state, without discussing LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18502",
      "abstract": "This paper studies the experimental comparison of two different whole-body control formulations for humanoid robots: inverse dynamics whole-body control (ID-WBC) and passivity-based whole-body control (PB-WBC). The two controllers fundamentally differ from each other as the first is formulated in task acceleration space and the latter is in task force space with passivity considerations. Even though both control methods predict stability under ideal conditions in closed-loop dynamics, their robustness against joint friction, sensor noise, unmodeled external disturbances, and non-perfect contact conditions is not evident. Therefore, we analyze and experimentally compare the two controllers on a humanoid robot platform through swing foot position and orientation control, squatting with and without unmodeled additional weights, and jumping. We also relate the observed performance and characteristic differences with the controller formulations and highlight each controller's advantages and disadvantages.",
      "authors": [
        "Sait Sovukluk",
        "Grazia Zambella",
        "Tobias Egle",
        "and Christian Ott"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:18:31+00:00",
          "link": "https://arxiv.org/abs/2507.18502v1",
          "size": "6124kb",
          "version": "v1"
        }
      ],
      "title": "Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18502",
        "HTML": "https://arxiv.org/html/2507.18502v1",
        "PDF": "https://arxiv.org/pdf/2507.18502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates whole-body control formulations for humanoid robots, without touching on LLM training data processing or any relevant data management techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18503",
      "abstract": "In goal-directed visual tasks, human perception is guided by both top-down and bottom-up cues. At the same time, foveal vision plays a crucial role in directing attention efficiently. Modern research on bio-inspired computational attention models has taken advantage of advancements in deep learning by utilizing human scanpath data to achieve new state-of-the-art performance. In this work, we assess the performance of SemBA-FAST, i.e. Semantic-based Bayesian Attention for Foveal Active visual Search Tasks, a top-down framework designed for predicting human visual attention in target-present visual search. SemBA-FAST integrates deep object detection with a probabilistic semantic fusion mechanism to generate attention maps dynamically, leveraging pre-trained detectors and artificial foveation to update top-down knowledge and improve fixation prediction sequentially. We evaluate SemBA-FAST on the COCO-Search18 benchmark dataset, comparing its performance against other scanpath prediction models. Our methodology achieves fixation sequences that closely match human ground-truth scanpaths. Notably, it surpasses baseline and other top-down approaches and competes, in some cases, with scanpath-informed models. These findings provide valuable insights into the capabilities of semantic-foveal probabilistic frameworks for human-like attention modelling, with implications for real-time cognitive computing and robotics.",
      "authors": [
        "Jo\\~ao Luzio",
        "Alexandre Bernardino",
        "Plinio Moreno"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:19:23+00:00",
          "link": "https://arxiv.org/abs/2507.18503v1",
          "size": "8145kb",
          "version": "v1"
        }
      ],
      "title": "Human Scanpath Prediction in Target-Present Visual Search with Semantic-Foveal Bayesian Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18503",
        "HTML": "https://arxiv.org/html/2507.18503v1",
        "PDF": "https://arxiv.org/pdf/2507.18503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around human scanpath prediction in visual search tasks, which is unrelated to LLM training data processing or any operations like data filtering or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18504",
      "abstract": "Large Language Models (LLMs) have shown strong potential for tabular data generation by modeling textualized feature-value pairs. However, tabular data inherently exhibits sparse feature-level dependencies, where many feature interactions are structurally insignificant. This creates a fundamental mismatch as LLMs' self-attention mechanism inevitably distributes focus across all pairs, diluting attention on critical relationships, particularly in datasets with complex dependencies or semantically ambiguous features. To address this limitation, we propose GraDe (Graph-Guided Dependency Learning), a novel method that explicitly integrates sparse dependency graphs into LLMs' attention mechanism. GraDe employs a lightweight dynamic graph learning module guided by externally extracted functional dependencies, prioritizing key feature interactions while suppressing irrelevant ones. Our experiments across diverse real-world datasets demonstrate that GraDe outperforms existing LLM-based approaches by up to 12% on complex datasets while achieving competitive results with state-of-the-art approaches in synthetic data quality. Our method is minimally intrusive yet effective, offering a practical solution for structure-aware tabular data modeling with LLMs.",
      "authors": [
        "Zheyu Zhang",
        "Shuo Yang",
        "Bardh Prenkaj",
        "Gjergji Kasneci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:22:27+00:00",
          "link": "https://arxiv.org/abs/2507.18504v1",
          "size": "512kb",
          "version": "v1"
        }
      ],
      "title": "Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18504",
        "PDF": "https://arxiv.org/pdf/2507.18504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a novel method for tabular data generation using language models. While it involves data generation, it doesn't specifically address training data processing for LLMs but focuses on modeling feature dependencies in tabular data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18509",
      "abstract": "Coinduction is a widely used technique for establishing behavioural equivalence of programs in higher-order languages. In recent years, the rise of languages with quantitative (e.g.~probabilistic) features has led to extensions of coinductive methods to more refined types of behavioural conformances, most notably notions of behavioural distance. To guarantee soundness of coinductive reasoning, one needs to show that the behavioural conformance at hand forms a program congruence, i.e. it is suitably compatible with the operations of the language. This is usually achieved by a complex proof technique known as \\emph{Howe's method}, which needs to be carefully adapted to both the specific language and the targeted notion of behavioural conformance. We develop a uniform categorical approach to Howe's method that features two orthogonal dimensions of abstraction: (1) the underlying higher-order language is modelled by an \\emph{abstract higher-order specification} (AHOS), a novel and very general categorical account of operational semantics, and (2) notions of behavioural conformance (such as relations or metrics) are modelled via fibrations over the base category of an AHOS. Our main result is a fundamental congruence theorem at this level of generality: Under natural conditions on the categorical ingredients and the operational rules of a language modelled by an AHOS, the greatest behavioural (bi)conformance on its operational model forms a congruence. We illustrate our theory by deriving congruence of bisimilarity and behavioural pseudometrics for probabilistic higher-order languages.",
      "authors": [
        "Henning Urbat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:28:08+00:00",
          "link": "https://arxiv.org/abs/2507.18509v1",
          "size": "103kb",
          "version": "v1"
        }
      ],
      "title": "Higher-Order Behavioural Conformances via Fibrations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18509",
        "PDF": "https://arxiv.org/pdf/2507.18509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a categorical approach to coinduction in higher-order languages and abstracts operational semantics. It is unrelated to the LLM training data processing as it does not address data engineering or quality improvement for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18510",
      "abstract": "Spatial interaction in 3D environments requires balancing efficiency and precision, which requires dynamic tracking speed adjustments. However, existing techniques often couple tracking speed adjustments directly with hand movements, reducing interaction flexibility. Inspired by the natural friction control inherent in the physical world, we introduce ForcePinch, a novel force-responsive spatial interaction method that enables users to intuitively modulate pointer tracking speed and smoothly transition between rapid and precise movements by varying their pinching force. To implement this concept, we developed a hardware prototype integrating a pressure sensor with a customizable mapping function that translates pinching force into tracking speed adjustments. We conducted a user study with 20 participants performing well-established 1D, 2D, and 3D object manipulation tasks, comparing ForcePinch against the distance-responsive technique Go-Go and speed-responsive technique PRISM. Results highlight distinctive characteristics of the force-responsive approach across different interaction contexts. Drawing on these findings, we highlight the contextual meaning and versatility of force-responsive interactions through four illustrative examples, aiming to inform and inspire future spatial interaction design.",
      "authors": [
        "Chenyang Zhang",
        "Tiffany S Ma",
        "John Andrews",
        "Eric J Gonzalez",
        "Mar Gonzalez-Franco",
        "Yalong Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:28:44+00:00",
          "link": "https://arxiv.org/abs/2507.18510v1",
          "size": "7609kb",
          "version": "v1"
        }
      ],
      "title": "ForcePinch: Force-Responsive Spatial Interaction for Tracking Speed Control in XR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18510",
        "HTML": "https://arxiv.org/html/2507.18510v1",
        "PDF": "https://arxiv.org/pdf/2507.18510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores a new interaction method in 3D environments. It focuses on interaction design and hardware for XR, unrelated to LLM training data processing or data engineering efforts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18512",
      "abstract": "Sparse autoencoders (SAEs) have emerged as a powerful technique for extracting human-interpretable features from neural networks activations. Previous works compared different models based on SAE-derived features but those comparisons have been restricted to models within the same modality. We propose a novel indicator allowing quantitative comparison of models across SAE features, and use it to conduct a comparative study of visual, textual and multimodal encoders. We also propose to quantify the Comparative Sharedness of individual features between different classes of models. With these two new tools, we conduct several studies on 21 encoders of the three types, with two significantly different sizes, and considering generalist and domain specific datasets. The results allow to revisit previous studies at the light of encoders trained in a multimodal context and to quantify to which extent all these models share some representations or features. They also suggest that visual features that are specific to VLMs among vision encoders are shared with text encoders, highlighting the impact of text pretraining. The code is available at https://github.com/CEA-LIST/SAEshareConcepts",
      "authors": [
        "Cl\\'ement Cornet and Romaric Besan\\c{c}on and Herv\\'e Le Borgne"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:33:31+00:00",
          "link": "https://arxiv.org/abs/2507.18512v1",
          "size": "378kb",
          "version": "v1"
        }
      ],
      "title": "Explaining How Visual, Textual and Multimodal Encoders Share Concepts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18512",
        "PDF": "https://arxiv.org/pdf/2507.18512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper investigates multimodal encoders and shared features from sparse autoencoders. While it provides insights into encoder training, it lacks focus on LLM training data processing or creation of new datasets, making its relevance to core data processing limited."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18513",
      "abstract": "Object detection is one of the main applications of computer vision in remote sensing imagery. Despite its increasing availability, the sheer volume of remote sensing data poses a challenge when detecting rare objects across large geographic areas. Paradoxically, this common challenge is crucial to many applications, such as estimating environmental impact of certain human activities at scale. In this paper, we propose to address the problem by investigating the methane production and emissions of bio-digesters in France. We first introduce a novel dataset containing bio-digesters, with small training and validation sets, and a large test set with a high imbalance towards observations without objects since such sites are rare. We develop a part-based method that considers essential bio-digester sub-elements to boost initial detections. To this end, we apply our method to new, unseen regions to build an inventory of bio-digesters. We then compute geostatistical estimates of the quantity of methane produced that can be attributed to these infrastructures in a given area at a given time.",
      "authors": [
        "Adhemar de Senneville",
        "Xavier Bou",
        "Thibaud Ehret",
        "Rafael Grompone",
        "Jean Louis Bonne",
        "Nicolas Dumelie",
        "Thomas Lauvaux and Gabriele Facciolo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:33:55+00:00",
          "link": "https://arxiv.org/abs/2507.18513v1",
          "size": "30163kb",
          "version": "v1"
        }
      ],
      "title": "Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18513",
        "HTML": "https://arxiv.org/html/2507.18513v1",
        "PDF": "https://arxiv.org/pdf/2507.18513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies object detection in remote sensing imagery related to methane monitoring. It introduces a new dataset, but this dataset isn't connected to LLM training or processing, as it deals with environmental monitoring data rather than LLM-specific data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18514",
      "abstract": "This paper investigates the semantics-aware remote estimation of a finite-state Markov chain. We employ the maximum a posteriori (MAP) estimator and aim to devise a transmission policy to optimize estimation performance subject to a transmission frequency constraint. We leverage two metrics, namely the Age of Consecutive Error (AoCE) and the Age of Information (AoI), to quantify, respectively, the significance of estimation error at the transmitter and the predictability of outdated information at the receiver. The optimal transmission problem is formulated as a constrained Markov decision process (CMDP) with unbounded costs. We show the existence of an optimal simple mixture policy, which randomly selects between two deterministic switching policies with a fixed probability. Notably, each switching policy triggers a transmission only when the AoCE exceeds a threshold value that depends on both the AoI and the instantaneous estimation error. We further derive sufficient conditions under which the switching policy reduces to a simple threshold policy; that is, it admits identical thresholds for all estimation errors. Leveraging these results, we develop an efficient structure-aware algorithm, Insec-SPI, that computes the optimal policy with reduced computation overhead. Our results demonstrate that incorporating both AoI and AoCE yields significantly improved estimation quality compared to using either metric alone.",
      "authors": [
        "Jiping Luo",
        "Nikolaos Pappas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:36:27+00:00",
          "link": "https://arxiv.org/abs/2507.18514v1",
          "size": "677kb",
          "version": "v1"
        }
      ],
      "title": "On the Role of Age and Semantics of Information in Remote Estimation of Markov Sources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18514",
        "HTML": "https://arxiv.org/html/2507.18514v1",
        "PDF": "https://arxiv.org/pdf/2507.18514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on remote estimation of Markov chains and optimizing transmission policies based on Age of Information metrics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18515",
      "abstract": "Code completion, a crucial task in software engineering that enhances developer productivity, has seen substantial improvements with the rapid advancement of large language models (LLMs). In recent years, retrieval-augmented generation (RAG) has emerged as a promising method to enhance the code completion capabilities of LLMs, which leverages relevant context from codebases without requiring model retraining. While existing studies have demonstrated the effectiveness of RAG on public repositories and benchmarks, the potential distribution shift between open-source and closed-source codebases presents unique challenges that remain unexplored. To mitigate the gap, we conduct an empirical study to investigate the performance of widely-used RAG methods for code completion in the industrial-scale codebase of WeChat, one of the largest proprietary software systems. Specifically, we extensively explore two main types of RAG methods, namely identifier-based RAG and similarity-based RAG, across 26 open-source LLMs ranging from 0.5B to 671B parameters. For a more comprehensive analysis, we employ different retrieval techniques for similarity-based RAG, including lexical and semantic retrieval. Based on 1,669 internal repositories, we achieve several key findings: (1) both RAG methods demonstrate effectiveness in closed-source repositories, with similarity-based RAG showing superior performance, (2) the effectiveness of similarity-based RAG improves with more advanced retrieval techniques, where BM25 (lexical retrieval) and GTE-Qwen (semantic retrieval) achieve superior performance, and (3) the combination of lexical and semantic retrieval techniques yields optimal results, demonstrating complementary strengths. Furthermore, we conduct a developer survey to validate the practical utility of RAG methods in real-world development environments.",
      "authors": [
        "Zezhou Yang",
        "Ting Peng",
        "Cuiyun Gao",
        "Chaozheng Wang",
        "Hailiang Huang",
        "Yuetang Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:36:31+00:00",
          "link": "https://arxiv.org/abs/2507.18515v1",
          "size": "327kb",
          "version": "v1"
        }
      ],
      "title": "A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18515",
        "HTML": "https://arxiv.org/html/2507.18515v1",
        "PDF": "https://arxiv.org/pdf/2507.18515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses retrieval-augmented generation (RAG) techniques to improve code completion, focusing mainly on RAG methods rather than directly on LLM training data processing. It only indirectly addresses data processing through retrieval techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18517",
      "abstract": "In this work, we address the problem of semantic object segmentation using foundation models. We investigate whether foundation models, trained on a large number and variety of objects, can perform object segmentation without fine-tuning on specific images containing everyday objects, but in highly cluttered visual scenes. The ''in the wild'' context is driven by the target application of vision guided upper limb neuroprostheses. We propose a method for generating prompts based on gaze fixations to guide the Segment Anything Model (SAM) in our segmentation scenario, and fine-tune it on egocentric visual data. Evaluation results of our approach show an improvement of the IoU segmentation quality metric by up to 0.51 points on real-world challenging data of Grasping-in-the-Wild corpus which is made available on the RoboFlow Platform (https://universe.roboflow.com/iwrist/grasping-in-the-wild)",
      "authors": [
        "Bolutife Atoki",
        "Jenny Benois-Pineau",
        "Renaud P\\'eteri",
        "Fabien Baldacci",
        "Aymar de Rugy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:40:44+00:00",
          "link": "https://arxiv.org/abs/2507.18517v1",
          "size": "3815kb",
          "version": "v1"
        }
      ],
      "title": "Object segmentation in the wild with foundation models: application to vision assisted neuro-prostheses for upper limbs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18517",
        "HTML": "https://arxiv.org/html/2507.18517v1",
        "PDF": "https://arxiv.org/pdf/2507.18517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses object segmentation and vision models, focusing on segmentation in cluttered environments without specific reference to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18518",
      "abstract": "Vector Database (VDB) can efficiently index and search high-dimensional vector embeddings from unstructured data, crucially enabling fast semantic similarity search essential for modern AI applications like generative AI and recommendation systems. Since current VDB service providers predominantly use proprietary black-box models, users are forced to expose raw query text to them via API in exchange for the vector retrieval services. Consequently, if query text involves confidential records from finance or healthcare domains, this mechanism inevitably leads to critical leakage of user's sensitive information. To address this issue, we introduce STEER (\\textbf{S}ecure \\textbf{T}ransformed \\textbf{E}mbedding v\\textbf{E}ctor\\textbf{ R}etrieval), a private vector retrieval framework that leverages the alignment relationship between the semantic spaces of different embedding models to derive approximate embeddings for the query text. STEER performs the retrieval using the approximate embeddings within the original VDB and requires no modifications to the server side. Our theoretical and experimental analyses demonstrate that STEER effectively safeguards query text privacy while maintaining the retrieval accuracy. Even though approximate embeddings are approximations of the embeddings from proprietary models, they still prevent the providers from recovering the query text through Embedding Inversion Attacks (EIAs). Extensive experimental results show that Recall@100 of STEER can basically achieve a decrease of less than 5\\%. Furthermore, even when searching within a text corpus of millions of entries, STEER achieves a Recall@20 accuracy 20\\% higher than current baselines.",
      "authors": [
        "Ruiqi He",
        "Zekun Fei",
        "Jiaqi Li",
        "Xinyuan Zhu",
        "Biao Yi",
        "Siyi Lv",
        "Weijie Liu",
        "Zheli Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:41:34+00:00",
          "link": "https://arxiv.org/abs/2507.18518v1",
          "size": "11709kb",
          "version": "v1"
        }
      ],
      "title": "Transform Before You Query: A Privacy-Preserving Approach for Vector Retrieval with Embedding Space Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18518",
        "HTML": "https://arxiv.org/html/2507.18518v1",
        "PDF": "https://arxiv.org/pdf/2507.18518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a privacy-preserving framework for vector retrieval, focusing on query privacy and embedding space alignment, which does not directly contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18519",
      "abstract": "Bisimulation metric has long been regarded as an effective control-related representation learning technique in various reinforcement learning tasks. However, in this paper, we identify two main issues with the conventional bisimulation metric: 1) an inability to represent certain distinctive scenarios, and 2) a reliance on predefined weights for differences in rewards and subsequent states during recursive updates. We find that the first issue arises from an imprecise definition of the reward gap, whereas the second issue stems from overlooking the varying importance of reward difference and next-state distinctions across different training stages and task settings. To address these issues, by introducing a measure for state-action pairs, we propose a revised bisimulation metric that features a more precise definition of reward gap and novel update operators with adaptive coefficient. We also offer theoretical guarantees of convergence for our proposed metric and its improved representation distinctiveness. In addition to our rigorous theoretical analysis, we conduct extensive experiments on two representative benchmarks, DeepMind Control and Meta-World, demonstrating the effectiveness of our approach.",
      "authors": [
        "Leiji Zhang",
        "Zeyu Wang",
        "Xin Li and Yao-Hui Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:42:22+00:00",
          "link": "https://arxiv.org/abs/2507.18519v1",
          "size": "1936kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Bisimulation Metric for Robust Representations in Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18519",
        "HTML": "https://arxiv.org/html/2507.18519v1",
        "PDF": "https://arxiv.org/pdf/2507.18519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on reinforcement learning and the modification of bisimulation metrics, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18521",
      "abstract": "Graph Neural Networks (GNNs) have demonstrated significant success in learning from graph-structured data but often struggle on heterophilous graphs, where connected nodes differ in features or class labels. This limitation arises from indiscriminate neighbor aggregation and insufficient incorporation of higher-order structural patterns. To address these challenges, we propose GLANCE (Graph Logic Attention Network with Cluster Enhancement), a novel framework that integrates logic-guided reasoning, dynamic graph refinement, and adaptive clustering to enhance graph representation learning. GLANCE combines a logic layer for interpretable and structured embeddings, multi-head attention-based edge pruning for denoising graph structures, and clustering mechanisms for capturing global patterns. Experimental results in benchmark datasets, including Cornell, Texas, and Wisconsin, demonstrate that GLANCE achieves competitive performance, offering robust and interpretable solutions for heterophilous graph scenarios. The proposed framework is lightweight, adaptable, and uniquely suited to the challenges of heterophilous graphs.",
      "authors": [
        "Zhongtian Sun",
        "Anoushka Harit",
        "Alexandra Cristea",
        "Christl A. Donnelly and Pietro Li\\`o"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:45:26+00:00",
          "link": "https://arxiv.org/abs/2507.18521v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "GLANCE: Graph Logic Attention Network with Cluster Enhancement for Heterophilous Graph Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18521",
        "HTML": "https://arxiv.org/html/2507.18521v1",
        "PDF": "https://arxiv.org/pdf/2507.18521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses graph neural networks and heterophilous graphs, without any mention of LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18522",
      "abstract": "3D semantic occupancy prediction is one of the crucial tasks of autonomous driving. It enables precise and safe interpretation and navigation in complex environments. Reliable predictions rely on effective sensor fusion, as different modalities can contain complementary information. Unlike conventional methods that depend on dense grid representations, our approach, GaussianFusionOcc, uses semantic 3D Gaussians alongside an innovative sensor fusion mechanism. Seamless integration of data from camera, LiDAR, and radar sensors enables more precise and scalable occupancy prediction, while 3D Gaussian representation significantly improves memory efficiency and inference speed. GaussianFusionOcc employs modality-agnostic deformable attention to extract essential features from each sensor type, which are then used to refine Gaussian properties, resulting in a more accurate representation of the environment. Extensive testing with various sensor combinations demonstrates the versatility of our approach. By leveraging the robustness of multi-modal fusion and the efficiency of Gaussian representation, GaussianFusionOcc outperforms current state-of-the-art models.",
      "authors": [
        "Tomislav Pavkovi\\'c",
        "Mohammad-Ali Nikouei Mahani",
        "Johannes Niedermayer",
        "Johannes Betz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:46:38+00:00",
          "link": "https://arxiv.org/abs/2507.18522v1",
          "size": "40532kb",
          "version": "v1"
        }
      ],
      "title": "GaussianFusionOcc: A Seamless Sensor Fusion Approach for 3D Occupancy Prediction Using 3D Gaussians",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18522",
        "HTML": "https://arxiv.org/html/2507.18522v1",
        "PDF": "https://arxiv.org/pdf/2507.18522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a sensor fusion approach for 3D occupancy prediction in autonomous driving, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18523",
      "abstract": "Moral foundation detection is crucial for analyzing social discourse and developing ethically-aligned AI systems. While large language models excel across diverse tasks, their performance on specialized moral reasoning remains unclear.\n  This study provides the first comprehensive comparison between state-of-the-art LLMs and fine-tuned transformers across Twitter and Reddit datasets using ROC, PR, and DET curve analysis.\n  Results reveal substantial performance gaps, with LLMs exhibiting high false negative rates and systematic under-detection of moral content despite prompt engineering efforts. These findings demonstrate that task-specific fine-tuning remains superior to prompting for moral reasoning applications.",
      "authors": [
        "Maciej Skorski and Alina Landowska"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:49:06+00:00",
          "link": "https://arxiv.org/abs/2507.18523v1",
          "size": "4798kb",
          "version": "v1"
        }
      ],
      "title": "The Moral Gap of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18523",
        "PDF": "https://arxiv.org/pdf/2507.18523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates LLMs in moral foundation detection, mentioning fine-tuning, but its primary focus is on moral reasoning and comparison of LLMs' performance rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18531",
      "abstract": "Intent-oriented controlled video captioning aims to generate targeted descriptions for specific targets in a video based on customized user intent. Current Large Visual Language Models (LVLMs) have gained strong instruction following and visual comprehension capabilities. Although the LVLMs demonstrated proficiency in spatial and temporal understanding respectively, it was not able to perform fine-grained spatial control in time sequences in direct response to instructions. This substantial spatio-temporal gap complicates efforts to achieve fine-grained intention-oriented control in video. Towards this end, we propose a novel IntentVCNet that unifies the temporal and spatial understanding knowledge inherent in LVLMs to bridge the spatio-temporal gap from both prompting and model perspectives. Specifically, we first propose a prompt combination strategy designed to enable LLM to model the implicit relationship between prompts that characterize user intent and video sequences. We then propose a parameter efficient box adapter that augments the object semantic information in the global visual context so that the visual token has a priori information about the user intent. The final experiment proves that the combination of the two strategies can further enhance the LVLM's ability to model spatial details in video sequences, and facilitate the LVLMs to accurately generate controlled intent-oriented captions. Our proposed method achieved state-of-the-art results in several open source LVLMs and was the runner-up in the IntentVC challenge. Our code is available on https://github.com/thqiu0419/IntentVCNet.",
      "authors": [
        "Tianheng Qiu",
        "Jingchun Gao",
        "Jingyu Li",
        "Huiyi Leong",
        "Xuan Huang",
        "Xi Wang",
        "Xiaocheng Zhang",
        "Kele Xu",
        "Lan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:58:36+00:00",
          "link": "https://arxiv.org/abs/2507.18531v1",
          "size": "858kb",
          "version": "v1"
        }
      ],
      "title": "IntentVCNet: Bridging Spatio-Temporal Gaps for Intention-Oriented Controllable Video Captioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18531",
        "HTML": "https://arxiv.org/html/2507.18531v1",
        "PDF": "https://arxiv.org/pdf/2507.18531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with video captioning using LVLMs and focuses on spatial and temporal understanding rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18532",
      "abstract": "This paper presents COT-AD, a comprehensive Dataset designed to enhance cotton crop analysis through computer vision. Comprising over 25,000 images captured throughout the cotton growth cycle, with 5,000 annotated images, COT-AD includes aerial imagery for field-scale detection and segmentation and high-resolution DSLR images documenting key diseases. The annotations cover pest and disease recognition, vegetation, and weed analysis, addressing a critical gap in cotton-specific agricultural datasets. COT-AD supports tasks such as classification, segmentation, image restoration, enhancement, deep generative model-based cotton crop synthesis, and early disease management, advancing data-driven crop management",
      "authors": [
        "Akbar Ali",
        "Mahek Vyas",
        "Soumyaratna Debnath",
        "Chanda Grover Kamra",
        "Jaidev Sanjay Khalane",
        "Reuben Shibu Devanesan",
        "Indra Deep Mastan",
        "Subramanian Sankaranarayanan",
        "Pankaj Khanna",
        "Shanmuganathan Raman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:58:39+00:00",
          "link": "https://arxiv.org/abs/2507.18532v1",
          "size": "36350kb",
          "version": "v1"
        }
      ],
      "title": "COT-AD: Cotton Analysis Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18532",
        "HTML": "https://arxiv.org/html/2507.18532v1",
        "PDF": "https://arxiv.org/pdf/2507.18532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces the COT-AD dataset specifically for cotton crop analysis, focusing on computer vision tasks such as segmentation and disease management. It does not pertain to LLM training data processing for NLP models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18533",
      "abstract": "We introduce C2G-KD, a data-free knowledge distillation framework where a class-conditional generator is trained to produce synthetic samples guided by a frozen teacher model and geometric constraints derived from PCA. The generator never observes real training data but instead learns to activate the teacher's output through a combination of semantic and structural losses. By constraining generated samples to lie within class-specific PCA subspaces estimated from as few as two real examples per class, we preserve topological consistency and diversity. Experiments on MNIST show that even minimal class structure is sufficient to bootstrap useful synthetic training pipelines.",
      "authors": [
        "Magnus Bengtsson",
        "Kenneth \\\"Ostberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:00:32+00:00",
          "link": "https://arxiv.org/abs/2507.18533v1",
          "size": "194kb",
          "version": "v1"
        }
      ],
      "title": "C2G-KD: PCA-Constrained Generator for Data-Free Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18533",
        "HTML": "https://arxiv.org/html/2507.18533v1",
        "PDF": "https://arxiv.org/pdf/2507.18533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a data-free knowledge distillation framework, where a generator creates synthetic examples guided by a teacher model. It involves synthetic data generation but the focus is not explicitly on LLM training data processing; rather, it relates to model training techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18534",
      "abstract": "EDM elucidates the unified design space of diffusion models, yet its fixed noise patterns restricted to pure Gaussian noise, limit advancements in image restoration. Our study indicates that forcibly injecting Gaussian noise corrupts the degraded images, overextends the image transformation distance, and increases restoration complexity. To address this problem, our proposed EDA Elucidates the Design space of Arbitrary-noise-based diffusion models. Theoretically, EDA expands the freedom of noise pattern while preserving the original module flexibility of EDM, with rigorous proof that increased noise complexity incurs no additional computational overhead during restoration. EDA is validated on three typical tasks: MRI bias field correction (global smooth noise), CT metal artifact reduction (global sharp noise), and natural image shadow removal (local boundary-aware noise). With only 5 sampling steps, EDA outperforms most task-specific methods and achieves state-of-the-art performance in bias field correction and shadow removal.",
      "authors": [
        "Xingyu Qiu",
        "Mengying Yang",
        "Xinghua Ma",
        "Dong Liang",
        "Yuzhen Li",
        "Fanding Li",
        "Gongning Luo",
        "Wei Wang",
        "Kuanquan Wang",
        "Shuo Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:01:34+00:00",
          "link": "https://arxiv.org/abs/2507.18534v1",
          "size": "1415kb",
          "version": "v1"
        }
      ],
      "title": "Elucidating the Design Space of Arbitrary-Noise-Based Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18534",
        "HTML": "https://arxiv.org/html/2507.18534v1",
        "PDF": "https://arxiv.org/pdf/2507.18534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes improvements in diffusion models for image restoration, focusing on noise pattern alterations. It is unrelated to LLM training data processing or NLP tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18537",
      "abstract": "Scaling visual generation models is essential for real-world content creation, yet requires substantial training and computational expenses. Alternatively, test-time scaling has garnered growing attention due to resource efficiency and promising performance. In this work, we present TTS-VAR, the first general test-time scaling framework for visual auto-regressive (VAR) models, modeling the generation process as a path searching problem. To dynamically balance computational efficiency with exploration capacity, we first introduce an adaptive descending batch size schedule throughout the causal generation process. Besides, inspired by VAR's hierarchical coarse-to-fine multi-scale generation, our framework integrates two key components: (i) At coarse scales, we observe that generated tokens are hard for evaluation, possibly leading to erroneous acceptance of inferior samples or rejection of superior samples. Noticing that the coarse scales contain sufficient structural information, we propose clustering-based diversity search. It preserves structural variety through semantic feature clustering, enabling later selection on samples with higher potential. (ii) In fine scales, resampling-based potential selection prioritizes promising candidates using potential scores, which are defined as reward functions incorporating multi-scale generation history. Experiments on the powerful VAR model Infinity show a notable 8.7% GenEval score improvement (from 0.69 to 0.75). Key insights reveal that early-stage structural features effectively influence final quality, and resampling efficacy varies across generation scales. Code is available at https://github.com/ali-vilab/TTS-VAR.",
      "authors": [
        "Zhekai Chen",
        "Ruihang Chu",
        "Yukang Chen",
        "Shiwei Zhang",
        "Yujie Wei",
        "Yingya Zhang",
        "Xihui Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:04:55+00:00",
          "link": "https://arxiv.org/abs/2507.18537v1",
          "size": "4389kb",
          "version": "v1"
        }
      ],
      "title": "TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18537",
        "HTML": "https://arxiv.org/html/2507.18537v1",
        "PDF": "https://arxiv.org/pdf/2507.18537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for test-time scaling in visual auto-regressive generation models. It is focused on visual model efficiency improvements and does not engage with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18538",
      "abstract": "Artificial intelligence (AI) and machine learning (ML) models are rapidly permeating the 5G Radio Access Network (RAN), powering beam management, channel state information (CSI) feedback, positioning, and mobility prediction. However, without a standardized life-cycle management (LCM) framework, challenges, such as model drift, vendor lock-in, and limited transparency, hinder large-scale adoption. 3GPP Releases 16-20 progressively evolve AI/ML from experimental features to managed, interoperable network functions. Beginning with the Network Data Analytics Function (NWDAF) in Rel-16, subsequent releases introduced standardized interfaces for model transfer, execution, performance monitoring, and closed-loop control, culminating in Rel-20's two-sided CSI-compression Work Item and vendor-agnostic LCM profile. This article reviews the resulting five-block LCM architecture, KPI-driven monitoring mechanisms, and inter-vendor collaboration schemes, while identifying open challenges in resource-efficient monitoring, environment drift detection, intelligent decision-making, and flexible model training. These developments lay the foundation for AI-native transceivers as a key enabler for 6G.",
      "authors": [
        "Chu-Hsiang Huang",
        "Chao-Kai Wen",
        "and Geoffrey Ye Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:04:59+00:00",
          "link": "https://arxiv.org/abs/2507.18538v1",
          "size": "1856kb",
          "version": "v1"
        }
      ],
      "title": "AI/ML Life Cycle Management for Interoperable AI Native RAN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18538",
        "HTML": "https://arxiv.org/html/2507.18538v1",
        "PDF": "https://arxiv.org/pdf/2507.18538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses AI/ML life cycle management in 5G RAN networks, focusing on AI model interoperability and management in telecommunications. It does not relate to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18539",
      "abstract": "K\\\"onig's lemma is a fundamental result about trees with countless applications in mathematics and computer science. In contrapositive form, it states that if a tree is finitely branching and well-founded (i.e. has no infinite paths), then it is finite. We present a coalgebraic version of K\\\"onig's lemma featuring two dimensions of generalization: from finitely branching trees to coalgebras for a finitary endofunctor H, and from the base category of sets to a locally finitely presentable category C, such as the category of posets, nominal sets, or convex sets. Our coalgebraic K\\\"onig's lemma states that, under mild assumptions on C and H, every well-founded coalgebra for H is the directed join of its well-founded subcoalgebras with finitely generated state space -- in particular, the category of well-founded coalgebras is locally presentable. As applications, we derive versions of K\\\"onig's lemma for graphs in a topos as well as for nominal and convex transition systems. Additionally, we show that the key construction underlying the proof gives rise to two simple constructions of the initial algebra (equivalently, the final recursive coalgebra) for the functor H: The initial algebra is both the colimit of all well-founded and of all recursive coalgebras with finitely presentable state space. Remarkably, this result holds even in settings where well-founded coalgebras form a proper subclass of recursive ones. The first construction of the initial algebra is entirely new, while for the second one our approach yields a short and transparent new correctness proof.",
      "authors": [
        "Henning Urbat and Thorsten Wi{\\ss}mann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:06:54+00:00",
          "link": "https://arxiv.org/abs/2507.18539v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "Well-Founded Coalgebras Meet K\\\"onig's Lemma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18539",
        "PDF": "https://arxiv.org/pdf/2507.18539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a coalgebraic version of K\\\"onig's lemma and applications in mathematics and computer science, which is not related to LLM training data processing or any aspect of data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18541",
      "abstract": "3D Gaussian Splatting (3DGS) has emerged as a core technique for 3D representation. Its effectiveness largely depends on precise camera poses and accurate point cloud initialization, which are often derived from pretrained Multi-View Stereo (MVS) models. However, in unposed reconstruction task from hundreds of outdoor images, existing MVS models may struggle with memory limits and lose accuracy as the number of input images grows. To address this limitation, we propose a novel unposed 3DGS reconstruction framework that integrates pretrained MVS priors with the probabilistic Procrustes mapping strategy. The method partitions input images into subsets, maps submaps into a global space, and jointly optimizes geometry and poses with 3DGS. Technically, we formulate the mapping of tens of millions of point clouds as a probabilistic Procrustes problem and solve a closed-form alignment. By employing probabilistic coupling along with a soft dustbin mechanism to reject uncertain correspondences, our method globally aligns point clouds and poses within minutes across hundreds of images. Moreover, we propose a joint optimization framework for 3DGS and camera poses. It constructs Gaussians from confidence-aware anchor points and integrates 3DGS differentiable rendering with an analytical Jacobian to jointly refine scene and poses, enabling accurate reconstruction and pose estimation. Experiments on Waymo and KITTI datasets show that our method achieves accurate reconstruction from unposed image sequences, setting a new state of the art for unposed 3DGS reconstruction.",
      "authors": [
        "Chong Cheng",
        "Zijian Wang",
        "Sicheng Yu",
        "Yu Hu",
        "Nanjie Yao",
        "Hao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:08:01+00:00",
          "link": "https://arxiv.org/abs/2507.18541v1",
          "size": "7173kb",
          "version": "v1"
        }
      ],
      "title": "Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18541",
        "HTML": "https://arxiv.org/html/2507.18541v1",
        "PDF": "https://arxiv.org/pdf/2507.18541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses unposed 3DGS reconstruction in computer vision, specifically focusing on image processing and geometric alignment, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18542",
      "abstract": "Biomedical Named Entity Recognition presents significant challenges due to the complexity of biomedical terminology and inconsistencies in annotation across datasets. This paper introduces SRU-NER (Slot-based Recurrent Unit NER), a novel approach designed to handle nested named entities while integrating multiple datasets through an effective multi-task learning strategy. SRU-NER mitigates annotation gaps by dynamically adjusting loss computation to avoid penalizing predictions of entity types absent in a given dataset. Through extensive experiments, including a cross-corpus evaluation and human assessment of the model's predictions, SRU-NER achieves competitive performance in biomedical and general-domain NER tasks, while improving cross-domain generalization.",
      "authors": [
        "Jo\\~ao Ruano",
        "Gon\\c{c}alo M. Correia",
        "Leonor Barreiros",
        "Afonso Mendes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:08:15+00:00",
          "link": "https://arxiv.org/abs/2507.18542v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "Effective Multi-Task Learning for Biomedical Named Entity Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18542",
        "HTML": "https://arxiv.org/html/2507.18542v1",
        "PDF": "https://arxiv.org/pdf/2507.18542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a model for biomedical named entity recognition using a multi-task learning strategy, primarily concerning model architecture and task design, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18546",
      "abstract": "Information extraction (IE) is fundamental to numerous NLP applications, yet existing solutions often require specialized models for different tasks or rely on computationally expensive large language models. We present GLiNER2, a unified framework that enhances the original GLiNER architecture to support named entity recognition, text classification, and hierarchical structured data extraction within a single efficient model. Built pretrained transformer encoder architecture, GLiNER2 maintains CPU efficiency and compact size while introducing multi-task composition through an intuitive schema-based interface. Our experiments demonstrate competitive performance across extraction and classification tasks with substantial improvements in deployment accessibility compared to LLM-based alternatives. We release GLiNER2 as an open-source pip-installable library with pre-trained models and documentation at https://github.com/fastino-ai/GLiNER2.",
      "authors": [
        "Urchade Zaratiana",
        "Gil Pasternak",
        "Oliver Boyd",
        "George Hurn-Maloney",
        "Ash Lewis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:11:14+00:00",
          "link": "https://arxiv.org/abs/2507.18546v1",
          "size": "455kb",
          "version": "v1"
        }
      ],
      "title": "GLiNER2: An Efficient Multi-Task Information Extraction System with Schema-Driven Interface",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18546",
        "HTML": "https://arxiv.org/html/2507.18546v1",
        "PDF": "https://arxiv.org/pdf/2507.18546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces GLiNER2, an information extraction system emphasizing multi-task learning and efficiency, focusing on model architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18549",
      "abstract": "Diverse learning algorithms, optimization methods, and natural selection share a common mathematical structure, despite their apparent differences. Here I show that a simple notational partitioning of change by the Price equation reveals a universal force-metric-bias (FMB) law: $\\Delta\\mathbf{\\theta} = \\mathbf{M}\\,\\mathbf{f} + \\mathbf{b} + \\mathbf{\\xi}$. The force $\\mathbf{f}$ drives improvement in parameters, $\\Delta\\mathbf{\\theta}$, through the covariance between the parameters and performance. The metric $\\mathbf{M}$ rescales movement by inverse curvature. The bias $\\mathbf{b}$ adds momentum or changes in the frame of reference. The noise $\\mathbf{\\xi}$ enables exploration. This framework unifies natural selection, Bayesian updating, Newton's method, stochastic gradient descent, stochastic Langevin dynamics, Adam optimization, and most other algorithms as special cases of the same underlying process. The Price equation also reveals why Fisher information, Kullback-Leibler divergence, and d'Alembert's principle arise naturally in learning dynamics. By exposing this common structure, the FMB law provides a principled foundation for understanding, comparing, and designing learning algorithms across disciplines.",
      "authors": [
        "Steven A. Frank"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:13:56+00:00",
          "link": "https://arxiv.org/abs/2507.18549v1",
          "size": "561kb",
          "version": "v1"
        }
      ],
      "title": "The Price equation reveals a universal force-metric-bias law of algorithmic learning and natural selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18549",
        "PDF": "https://arxiv.org/pdf/2507.18549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a mathematical framework applicable to various learning algorithms, including natural selection and optimization methods. It does not address LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18550",
      "abstract": "Concept probing has recently garnered increasing interest as a way to help interpret artificial neural networks, dealing both with their typically large size and their subsymbolic nature, which ultimately renders them unfeasible for direct human interpretation. Concept probing works by training additional classifiers to map the internal representations of a model into human-defined concepts of interest, thus allowing humans to peek inside artificial neural networks. Research on concept probing has mainly focused on the model being probed or the probing model itself, paying limited attention to the data required to train such probing models. In this paper, we address this gap. Focusing on concept probing in the context of image classification tasks, we investigate the effect of the data used to train probing models on their performance. We also make available concept labels for two widely used datasets.",
      "authors": [
        "Manuel de Sousa Ribeiro",
        "Afonso Leote and Jo\\~ao Leite"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:18:46+00:00",
          "link": "https://arxiv.org/abs/2507.18550v1",
          "size": "2216kb",
          "version": "v1"
        }
      ],
      "title": "On the Performance of Concept Probing: The Influence of the Data (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18550",
        "HTML": "https://arxiv.org/html/2507.18550v1",
        "PDF": "https://arxiv.org/pdf/2507.18550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on concept probing in neural networks, particularly in the context of image classification, and does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18551",
      "abstract": "Intraoperative registration of real-time ultrasound (iUS) to preoperative Magnetic Resonance Imaging (MRI) remains an unsolved problem due to severe modality-specific differences in appearance, resolution, and field-of-view. To address this, we propose a novel 3D cross-modal keypoint descriptor for MRI-iUS matching and registration. Our approach employs a patient-specific matching-by-synthesis approach, generating synthetic iUS volumes from preoperative MRI. This enables supervised contrastive training to learn a shared descriptor space.\n  A probabilistic keypoint detection strategy is then employed to identify anatomically salient and modality-consistent locations. During training, a curriculum-based triplet loss with dynamic hard negative mining is used to learn descriptors that are i) robust to iUS artifacts such as speckle noise and limited coverage, and ii) rotation-invariant . At inference, the method detects keypoints in MR and real iUS images and identifies sparse matches, which are then used to perform rigid registration. Our approach is evaluated using 3D MRI-iUS pairs from the ReMIND dataset. Experiments show that our approach outperforms state-of-the-art keypoint matching methods across 11 patients, with an average precision of $69.8\\%$. For image registration, our method achieves a competitive mean Target Registration Error of 2.39 mm on the ReMIND2Reg benchmark.\n  Compared to existing iUS-MR registration approach, our framework is interpretable, requires no manual initialization, and shows robustness to iUS field-of-view variation. Code is available at https://github.com/morozovdd/CrossKEY.",
      "authors": [
        "Daniil Morozov",
        "Reuben Dorent",
        "Nazim Haouchine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:19:08+00:00",
          "link": "https://arxiv.org/abs/2507.18551v1",
          "size": "6540kb",
          "version": "v1"
        }
      ],
      "title": "A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18551",
        "HTML": "https://arxiv.org/html/2507.18551v1",
        "PDF": "https://arxiv.org/pdf/2507.18551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for MR-US image registration using a 3D keypoint descriptor. It does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18552",
      "abstract": "This paper introduces VideoMind, a video-centric omni-modal dataset designed for deep video content cognition and enhanced multi-modal feature representation. The dataset comprises 103K video samples (3K reserved for testing), each paired with audio and systematically detailed textual descriptions. Specifically, every video and its audio is described across three hierarchical layers (factual, abstract, and intent), progressing from surface to depth. It contains over 22 million words, averaging ~225 words per sample. VideoMind's key distinction from existing datasets is its provision of intent expressions, which require contextual integration across the entire video and are not directly observable. These deep-cognitive expressions are generated using a Chain-of-Thought (COT) approach, prompting the mLLM through step-by-step reasoning. Each description includes annotations for subject, place, time, event, action, and intent, supporting downstream recognition tasks. Crucially, we establish a gold-standard benchmark with 3,000 manually validated samples for evaluating deep-cognitive video understanding. We design hybrid-cognitive retrieval experiments, scored by multi-level retrieval metrics, to appropriately assess deep video comprehension. Evaluation results for models (e.g., InternVideo, VAST, UMT-L) are released. VideoMind serves as a powerful benchmark for fine-grained cross-modal alignment and advances fields requiring in-depth video understanding, such as emotion and intent recognition. The data is publicly available on GitHub, HuggingFace, and OpenDataLab, https://github.com/cdx-cindy/VideoMind.",
      "authors": [
        "Baoyao Yang",
        "Wanyun Li",
        "Dixin Chen",
        "Junxiang Chen",
        "Wenbin Yao",
        "Haifeng Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:19:43+00:00",
          "link": "https://arxiv.org/abs/2507.18552v1",
          "size": "3194kb",
          "version": "v1"
        }
      ],
      "title": "VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18552",
        "HTML": "https://arxiv.org/html/2507.18552v1",
        "PDF": "https://arxiv.org/pdf/2507.18552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces the VideoMind dataset aimed at video understanding tasks, it is primarily focused on video and multimodal data processing rather than directly contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18553",
      "abstract": "Quantizing the weights of large language models (LLMs) from 16-bit to lower bitwidth is the de facto approach to deploy massive transformers onto more affordable accelerators. GPTQ emerged as one of the standard methods for one-shot post-training quantization at LLM scale. Yet, its inner workings are described as a sequence of ad-hoc algebraic updates that obscure any geometric meaning or worst-case guarantees. In this work, we show that, when executed back-to-front (from the last to first dimension) for a linear layer, GPTQ is mathematically identical to Babai's nearest plane algorithm for the classical closest vector problem (CVP) on a lattice defined by the Hessian matrix of the layer's inputs. This equivalence is based on a sophisticated mathematical argument, and has two analytical consequences: (i) the GPTQ error propagation step gains an intuitive geometric interpretation; (ii) GPTQ inherits the error upper bound of Babai's algorithm under the no-clipping condition. Taken together, these results place GPTQ on firm theoretical footing and open the door to importing decades of progress in lattice algorithms towards the design of future quantization algorithms for billion-parameter models.",
      "authors": [
        "Jiale Chen",
        "Torsten Hoefler",
        "Dan Alistarh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:22:18+00:00",
          "link": "https://arxiv.org/abs/2507.18553v1",
          "size": "80kb",
          "version": "v1"
        }
      ],
      "title": "The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18553",
        "HTML": "https://arxiv.org/html/2507.18553v1",
        "PDF": "https://arxiv.org/pdf/2507.18553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores weight quantization for LLM deployment, focusing on algorithmic optimization techniques rather than data processing or datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18555",
      "abstract": "Fisher information matrices and neural tangent kernels (NTK) for 2-layer ReLU networks with random hidden weight are argued. We discuss the relation between both notions as a linear transformation and show that spectral decomposition of NTK with concrete forms of eigenfunctions with major eigenvalues. We also obtain an approximation formula of the functions presented by the 2-layer neural networks.",
      "authors": [
        "Jun'ichi Takeuchia",
        "Yoshinari Takeishia",
        "Noboru Muratab",
        "Kazushi Mimurac",
        "Ka Long Keith Hod",
        "Hiroshi Nagaoka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:26:52+00:00",
          "link": "https://arxiv.org/abs/2507.18555v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Neural Tangent Kernels and Fisher Information Matrices for Simple ReLU Networks with Random Hidden Weights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18555",
        "HTML": "https://arxiv.org/html/2507.18555v1",
        "PDF": "https://arxiv.org/pdf/2507.18555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses neural tangent kernels and Fisher information matrices for ReLU networks, focusing on theoretical aspects of neural networks rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18558",
      "abstract": "The poultry industry has been driven by broiler chicken production and has grown into the world's largest animal protein sector. Automated detection of chicken carcasses on processing lines is vital for quality control, food safety, and operational efficiency in slaughterhouses and poultry processing plants. However, developing robust deep learning models for tasks like instance segmentation in these fast-paced industrial environments is often hampered by the need for laborious acquisition and annotation of large-scale real-world image datasets. We present the first pipeline generating photo-realistic, automatically labeled synthetic images of chicken carcasses. We also introduce a new benchmark dataset containing 300 annotated real-world images, curated specifically for poultry segmentation research. Using these datasets, this study investigates the efficacy of synthetic data and automatic data annotation to enhance the instance segmentation of chicken carcasses, particularly when real annotated data from the processing line is scarce. A small real dataset with varying proportions of synthetic images was evaluated in prominent instance segmentation models. Results show that synthetic data significantly boosts segmentation performance for chicken carcasses across all models. This research underscores the value of synthetic data augmentation as a viable and effective strategy to mitigate data scarcity, reduce manual annotation efforts, and advance the development of robust AI-driven automated detection systems for chicken carcasses in the poultry processing industry.",
      "authors": [
        "Yihong Feng",
        "Chaitanya Pallerla",
        "Xiaomin Lin",
        "Pouya Sohrabipour Sr",
        "Philip Crandall",
        "Wan Shou",
        "Yu She",
        "Dongyi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:33:04+00:00",
          "link": "https://arxiv.org/abs/2507.18558v1",
          "size": "2447kb",
          "version": "v1"
        }
      ],
      "title": "Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18558",
        "HTML": "https://arxiv.org/html/2507.18558v1",
        "PDF": "https://arxiv.org/pdf/2507.18558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on synthetic data augmentation for enhancing instance segmentation of chicken carcasses in the poultry industry, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18559",
      "abstract": "On heterogeneous memory (HM) where fast memory (i.e., CPU-attached DRAM) and slow memory (e.g., remote NUMA memory, RDMA-connected memory, Persistent Memory (PM)) coexist, optimizing the placement of tree-structure indexes (e.g., B+tree) is crucial to achieving high performance while enjoying memory expansion. Nowadays, CXL-based heterogeneous memory (CXL-HM) is emerging due to its high efficiency and memory semantics. Prior tree-structure index placement schemes for HM cannot effectively boost performance on CXL-HM, as they fail to adapt to the changes in hardware characteristics and semantics. Additionally, existing CXL-HM page-level data placement schemes are not efficient for tree-structure indexes due to the granularity mismatch between the tree nodes and the page.\n  In this paper, we argue for a CXL native, tree-structure aware data placement scheme to optimize tree-structure indexes on CXL-HM. Our key insight is that the placement of tree-structure indexes on CXL-HM should match the tree's inherent characteristics with CXL-HM features. We present SINLK, a tree-structure aware, node-grained data placement scheme for tree-structure indexes on CXL-HM. With SINLK, developers can easily adapt existing tree-structure indexes to CXL-HM. We have integrated the B+tree and radix tree with SINLK to demonstrate its effectiveness. Evaluations show that SINLK improves throughput by up to 71% and reduces P99 latency by up to 81% compared with state-of-the-art data placement schemes (e.g., MEMTIS) and HM-optimized tree-structure indexes in YCSB and real-world workloads.",
      "authors": [
        "Haoru Zhao and Mingkai Dong and Fangnuo Wu and Haibo Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:34:55+00:00",
          "link": "https://arxiv.org/abs/2507.18559v1",
          "size": "1041kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Tree-structure Indexes for CXL-based Heterogeneous Memory with SINLK",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18559",
        "HTML": "https://arxiv.org/html/2507.18559v1",
        "PDF": "https://arxiv.org/pdf/2507.18559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses optimizing tree-structure indexes for CXL-based heterogeneous memory, which is about memory management optimization rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18561",
      "abstract": "As AI becomes prevalent in high-risk domains and decision-making, it is essential to test for potential harms and biases. This urgency is reflected by the global emergence of AI regulations that emphasise fairness and adequate testing, with some mandating independent bias audits. However, procuring the necessary data for fairness testing remains a significant challenge. Particularly in industry settings, legal and privacy concerns restrict the collection of demographic data required to assess group disparities, and auditors face practical and cultural challenges in gaining access to data. Further, internal historical datasets are often insufficiently representative to identify real-world biases. This work focuses on evaluating classifier fairness when complete datasets including demographics are inaccessible. We propose leveraging separate overlapping datasets to construct complete synthetic data that includes demographic information and accurately reflects the underlying relationships between protected attributes and model features. We validate the fidelity of the synthetic data by comparing it to real data, and empirically demonstrate that fairness metrics derived from testing on such synthetic data are consistent with those obtained from real data. This work, therefore, offers a path to overcome real-world data scarcity for fairness testing, enabling independent, model-agnostic evaluation of fairness, and serving as a viable substitute where real data is limited.",
      "authors": [
        "Varsha Ramineni",
        "Hossein A. Rahmani",
        "Emine Yilmaz",
        "David Barber"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:35:42+00:00",
          "link": "https://arxiv.org/abs/2507.18561v1",
          "size": "181kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Internal Data: Constructing Complete Datasets for Fairness Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18561",
        "HTML": "https://arxiv.org/html/2507.18561v1",
        "PDF": "https://arxiv.org/pdf/2507.18561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper makes a contribution to data processing by proposing methods to construct synthetic datasets for fairness testing, addressing issues of data scarcity which is a core aspect of improving data quality for model evaluations, including LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18562",
      "abstract": "Multimodal Machine Translation (MMT) has demonstrated the significant help of visual information in machine translation. However, existing MMT methods face challenges in leveraging the modality gap by enforcing rigid visual-linguistic alignment whilst being confined to inference within their trained multimodal domains. In this work, we construct novel multimodal scene graphs to preserve and integrate modality-specific information and introduce GIIFT, a two-stage Graph-guided Inductive Image-Free MMT framework that uses a cross-modal Graph Attention Network adapter to learn multimodal knowledge in a unified fused space and inductively generalize it to broader image-free translation domains. Experimental results on the Multi30K dataset of English-to-French and English-to-German tasks demonstrate that our GIIFT surpasses existing approaches and achieves the state-of-the-art, even without images during inference. Results on the WMT benchmark show significant improvements over the image-free translation baselines, demonstrating the strength of GIIFT towards inductive image-free inference.",
      "authors": [
        "Jiafeng Xiong",
        "Yuting Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:36:47+00:00",
          "link": "https://arxiv.org/abs/2507.18562v1",
          "size": "3253kb",
          "version": "v1"
        }
      ],
      "title": "GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18562",
        "PDF": "https://arxiv.org/pdf/2507.18562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal machine translation using a graph-guided framework, which is unrelated to LLM training data processing. It does not address dataset creation, data quality improvement, or any data engineering operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18565",
      "abstract": "This paper presents a novel deep learning-based approach for simultaneous age and gender classification from facial images, designed to enhance the effectiveness of targeted advertising campaigns. We propose a custom Convolutional Neural Network (CNN) architecture, optimized for both tasks, which leverages the inherent correlation between age and gender information present in facial features. Unlike existing methods that often treat these tasks independently, our model learns shared representations, leading to improved performance. The network is trained on a large, diverse dataset of facial images, carefully pre-processed to ensure robustness against variations in lighting, pose, and image quality. Our experimental results demonstrate a significant improvement in gender classification accuracy, achieving 95%, and a competitive mean absolute error of 5.77 years for age estimation. Critically, we analyze the performance across different age groups, identifying specific challenges in accurately estimating the age of younger individuals. This analysis reveals the need for targeted data augmentation and model refinement to address these biases. Furthermore, we explore the impact of different CNN architectures and hyperparameter settings on the overall performance, providing valuable insights for future research.",
      "authors": [
        "Muhammad Imran Zaman",
        "Nisar Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:41:26+00:00",
          "link": "https://arxiv.org/abs/2507.18565v1",
          "size": "593kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18565",
        "PDF": "https://arxiv.org/pdf/2507.18565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a deep learning approach for age and gender classification from facial images for targeted advertising, focusing on CNN architecture and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18566",
      "abstract": "A morph is created by combining two (or more) face images from two (or more) identities to create a composite image that is highly similar to both constituent identities, allowing the forged morph to be biometrically associated with more than one individual. Morph Attack Detection (MAD) can be used to detect a morph, but does not reveal the constituent images. Demorphing - the process of deducing the constituent images - is thus vital to provide additional evidence about a morph. Existing demorphing methods suffer from the morph replication problem, where the outputs tend to look very similar to the morph itself, or assume that train and test morphs are generated using the same morph technique. The proposed method overcomes these issues. The method decomposes a morph in latent space allowing it to demorph images created from unseen morph techniques and face styles. We train our method on morphs created from synthetic faces and test on morphs created from real faces using arbitrary morph techniques. Our method outperforms existing methods by a considerable margin and produces high fidelity demorphed face images.",
      "authors": [
        "Nitish Shukla",
        "Arun Ross"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:41:47+00:00",
          "link": "https://arxiv.org/abs/2507.18566v1",
          "size": "13811kb",
          "version": "v1"
        }
      ],
      "title": "Facial Demorphing from a Single Morph Using a Latent Conditional GAN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18566",
        "HTML": "https://arxiv.org/html/2507.18566v1",
        "PDF": "https://arxiv.org/pdf/2507.18566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on facial demorphing using a GAN-based method, aimed at detecting morphing in images, not on data processing for language models or their training data pipelines."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18567",
      "abstract": "The ACL2 Workshop series is the major technical forum for users of the ACL2 theorem proving system to present research related to the ACL2 theorem prover and its applications. ACL2 is an industrial-strength automated reasoning system, the latest in the Boyer-Moore family of theorem provers. The 2005 ACM Software System Award was awarded to Boyer, Kaufmann, and Moore for their work on ACL2 and the other theorem provers in the Boyer-Moore family.",
      "authors": [
        "Ruben Gamboa",
        "Panagiotis Manolios"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:42:15+00:00",
          "link": "https://arxiv.org/abs/2507.18567v1",
          "size": "3kb",
          "version": "v1"
        }
      ],
      "title": "Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18567",
        "PDF": "https://arxiv.org/pdf/2507.18567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This entry is about the proceedings of a workshop on the ACL2 theorem prover, which is unrelated to LLM data processing or training operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18569",
      "abstract": "Distribution Matching Distillation (DMD) is a promising score distillation technique that compresses pre-trained teacher diffusion models into efficient one-step or multi-step student generators. Nevertheless, its reliance on the reverse Kullback-Leibler (KL) divergence minimization potentially induces mode collapse (or mode-seeking) in certain applications. To circumvent this inherent drawback, we propose Adversarial Distribution Matching (ADM), a novel framework that leverages diffusion-based discriminators to align the latent predictions between real and fake score estimators for score distillation in an adversarial manner. In the context of extremely challenging one-step distillation, we further improve the pre-trained generator by adversarial distillation with hybrid discriminators in both latent and pixel spaces. Different from the mean squared error used in DMD2 pre-training, our method incorporates the distributional loss on ODE pairs collected from the teacher model, and thus providing a better initialization for score distillation fine-tuning in the next stage. By combining the adversarial distillation pre-training with ADM fine-tuning into a unified pipeline termed DMDX, our proposed method achieves superior one-step performance on SDXL compared to DMD2 while consuming less GPU time. Additional experiments that apply multi-step ADM distillation on SD3-Medium, SD3.5-Large, and CogVideoX set a new benchmark towards efficient image and video synthesis.",
      "authors": [
        "Yanzuo Lu",
        "Yuxi Ren",
        "Xin Xia",
        "Shanchuan Lin",
        "Xing Wang",
        "Xuefeng Xiao",
        "Andy J. Ma",
        "Xiaohua Xie",
        "Jian-Huang Lai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:45:05+00:00",
          "link": "https://arxiv.org/abs/2507.18569v1",
          "size": "31227kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial Distribution Matching for Diffusion Distillation Towards Efficient Image and Video Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18569",
        "HTML": "https://arxiv.org/html/2507.18569v1",
        "PDF": "https://arxiv.org/pdf/2507.18569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a technique for diffusion distillation in the context of efficient image and video synthesis, which does not pertain to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18570",
      "abstract": "This paper presents a novel hybrid tokenization strategy that enhances the performance of DNA Language Models (DLMs) by combining 6-mer tokenization with Byte Pair Encoding (BPE-600). Traditional k-mer tokenization is effective at capturing local DNA sequence structures but often faces challenges, including uneven token distribution and a limited understanding of global sequence context. To address these limitations, we propose merging unique 6mer tokens with optimally selected BPE tokens generated through 600 BPE cycles. This hybrid approach ensures a balanced and context-aware vocabulary, enabling the model to capture both short and long patterns within DNA sequences simultaneously. A foundational DLM trained on this hybrid vocabulary was evaluated using next-k-mer prediction as a fine-tuning task, demonstrating significantly improved performance. The model achieved prediction accuracies of 10.78% for 3-mers, 10.1% for 4-mers, and 4.12% for 5-mers, outperforming state-of-the-art models such as NT, DNABERT2, and GROVER. These results highlight the ability of the hybrid tokenization strategy to preserve both the local sequence structure and global contextual information in DNA modeling. This work underscores the importance of advanced tokenization methods in genomic language modeling and lays a robust foundation for future applications in downstream DNA sequence analysis and biological research.",
      "authors": [
        "Ganesh Sapkota and Md Hasibur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:45:23+00:00",
          "link": "https://arxiv.org/abs/2507.18570v1",
          "size": "4323kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Tokenization Strategy for DNA Language Model using Byte Pair Encoding and K-MER Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18570",
        "HTML": "https://arxiv.org/html/2507.18570v1",
        "PDF": "https://arxiv.org/pdf/2507.18570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel hybrid tokenization strategy for DNA Language Models, which is not directly related to LLM training data processing, pretraining, or fine-tuning as specified for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18572",
      "abstract": "Poster designing can benefit from synchronous feedback from target audiences. However, gathering audiences with diverse perspectives and reconciling them on design edits can be challenging. Recent generative AI models present opportunities to simulate human-like interactions, but it is unclear how they may be used for feedback processes in design. We introduce PosterMate, a poster design assistant that facilitates collaboration by creating audience-driven persona agents constructed from marketing documents. PosterMate gathers feedback from each persona agent regarding poster components, and stimulates discussion with the help of a moderator to reach a conclusion. These agreed-upon edits can then be directly integrated into the poster design. Through our user study (N=12), we identified the potential of PosterMate to capture overlooked viewpoints, while serving as an effective prototyping tool. Additionally, our controlled online evaluation (N=100) revealed that the feedback from an individual persona agent is appropriate given its persona identity, and the discussion effectively synthesizes the different persona agents' perspectives.",
      "authors": [
        "Donghoon Shin",
        "Daniel Lee",
        "Gary Hsieh",
        "Gromit Yeuk-Yin Chan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:46:25+00:00",
          "link": "https://arxiv.org/abs/2507.18572v1",
          "size": "6016kb",
          "version": "v1"
        }
      ],
      "title": "PosterMate: Audience-driven Collaborative Persona Agents for Poster Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18572",
        "HTML": "https://arxiv.org/html/2507.18572v1",
        "PDF": "https://arxiv.org/pdf/2507.18572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research on PosterMate centers around collaborative design and feedback processes for poster design, not on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18575",
      "abstract": "Transformer-based methods have demonstrated remarkable capabilities in 3D semantic segmentation through their powerful attention mechanisms, but the quadratic complexity limits their modeling of long-range dependencies in large-scale point clouds. While recent Mamba-based approaches offer efficient processing with linear complexity, they struggle with feature representation when extracting 3D features. However, effectively combining these complementary strengths remains an open challenge in this field. In this paper, we propose HybridTM, the first hybrid architecture that integrates Transformer and Mamba for 3D semantic segmentation. In addition, we propose the Inner Layer Hybrid Strategy, which combines attention and Mamba at a finer granularity, enabling simultaneous capture of long-range dependencies and fine-grained local features. Extensive experiments demonstrate the effectiveness and generalization of our HybridTM on diverse indoor and outdoor datasets. Furthermore, our HybridTM achieves state-of-the-art performance on ScanNet, ScanNet200, and nuScenes benchmarks. The code will be made available at https://github.com/deepinact/HybridTM.",
      "authors": [
        "Xinyu Wang",
        "Jinghua Hou",
        "Zhe Liu",
        "Yingying Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:48:50+00:00",
          "link": "https://arxiv.org/abs/2507.18575v1",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "title": "HybridTM: Combining Transformer and Mamba for 3D Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18575",
        "HTML": "https://arxiv.org/html/2507.18575v1",
        "PDF": "https://arxiv.org/pdf/2507.18575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model combining Transformer and Mamba architectures for 3D semantic segmentation, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18576",
      "abstract": "We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha' moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI.",
      "authors": [
        "Shanghai AI Lab: Yicheng Bao",
        "Guanxu Chen",
        "Mingkang Chen",
        "Yunhao Chen",
        "Chiyu Chen",
        "Lingjie Chen",
        "Sirui Chen",
        "Xinquan Chen",
        "Jie Cheng",
        "Yu Cheng",
        "Dengke Deng",
        "Yizhuo Ding",
        "Dan Ding",
        "Xiaoshan Ding",
        "Yi Ding",
        "Zhichen Dong",
        "Lingxiao Du",
        "Yuyu Fan",
        "Xinshun Feng",
        "Yanwei Fu",
        "Yuxuan Gao",
        "Ruijun Ge",
        "Tianle Gu",
        "Lujun Gui",
        "Jiaxuan Guo",
        "Qianxi He",
        "Yuenan Hou",
        "Xuhao Hu",
        "Hong Huang",
        "Kaichen Huang",
        "Shiyang Huang",
        "Yuxian Jiang",
        "Shanzhe Lei",
        "Jie Li",
        "Lijun Li",
        "Hao Li",
        "Juncheng Li",
        "Xiangtian Li",
        "Yafu Li",
        "Lingyu Li",
        "Xueyan Li",
        "Haotian Liang",
        "Dongrui Liu",
        "Qihua Liu",
        "Zhixuan Liu",
        "Bangwei Liu",
        "Huacan Liu",
        "Yuexiao Liu",
        "Zongkai Liu",
        "Chaochao Lu",
        "Yudong Lu",
        "Xiaoya Lu",
        "Zhenghao Lu",
        "Qitan Lv",
        "Caoyuan Ma",
        "Jiachen Ma",
        "Xiaoya Ma",
        "Zhongtian Ma",
        "Lingyu Meng",
        "Ziqi Miao",
        "Yazhe Niu",
        "Yuezhang Peng",
        "Yuan Pu",
        "Han Qi",
        "Chen Qian",
        "Xingge Qiao",
        "Jingjing Qu",
        "Jiashu Qu",
        "Wanying Qu",
        "Wenwen Qu",
        "Xiaoye Qu",
        "Qihan Ren",
        "Qingnan Ren",
        "Qingyu Ren",
        "Jing Shao",
        "Wenqi Shao",
        "Shuai Shao",
        "Dongxing Shi",
        "Xin Song",
        "Xinhao Song",
        "Yan Teng",
        "Xuan Tong",
        "Yingchun Wang",
        "Xuhong Wang",
        "Shujie Wang",
        "Xin Wang",
        "Yige Wang",
        "Yixu Wang",
        "Yuanfu Wang",
        "Futing Wang",
        "Ruofan Wang",
        "Wenjie Wang",
        "Yajie Wang",
        "Muhao Wei",
        "Xiaoyu Wen",
        "Fenghua Weng",
        "Yuqi Wu",
        "Yingtong Xiong",
        "Xingcheng Xu",
        "Chao Yang",
        "Yue Yang",
        "Yang Yao",
        "Yulei Ye",
        "Zhenyun Yin",
        "Yi Yu",
        "Bo Zhang",
        "Qiaosheng Zhang",
        "Jinxuan Zhang",
        "Yexin Zhang",
        "Yinqiang Zheng",
        "Hefeng Zhou",
        "Zhanhui Zhou",
        "Pengyu Zhu",
        "Qingzi Zhu",
        "Yubo Zhu",
        "Bowen Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:49:19+00:00",
          "link": "https://arxiv.org/abs/2507.18576v1",
          "size": "15435kb",
          "version": "v1"
        }
      ],
      "title": "SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\\circ}$ Law",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18576",
        "HTML": "https://arxiv.org/html/2507.18576v1",
        "PDF": "https://arxiv.org/pdf/2507.18576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper introduces SafeWork-R1, a multimodal reasoning model with safety enhancements, it primarily focuses on post-training reinforcement learning. It does not specifically address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18578",
      "abstract": "Diffusion Large Language Models (DLLMs) have emerged as a compelling alternative to Autoregressive models, designed for fast parallel generation. However, existing DLLMs are plagued by a severe quality-speed trade-off, where faster parallel decoding leads to significant performance degradation. We attribute this to the irreversibility of standard decoding in DLLMs, which is easily polarized into the wrong decoding direction along with early error context accumulation. To resolve this, we introduce Wide-In, Narrow-Out (WINO), a training-free decoding algorithm that enables revokable decoding in DLLMs. WINO employs a parallel draft-and-verify mechanism, aggressively drafting multiple tokens while simultaneously using the model's bidirectional context to verify and re-mask suspicious ones for refinement. Verified in open-source DLLMs like LLaDA and MMaDA, WINO is shown to decisively improve the quality-speed trade-off. For instance, on the GSM8K math benchmark, it accelerates inference by 6$\\times$ while improving accuracy by 2.58%; on Flickr30K captioning, it achieves a 10$\\times$ speedup with higher performance. More comprehensive experiments are conducted to demonstrate the superiority and provide an in-depth understanding of WINO.",
      "authors": [
        "Feng Hong",
        "Geng Yu",
        "Yushi Ye",
        "Haicheng Huang",
        "Huangjie Zheng",
        "Ya Zhang",
        "Yanfeng Wang",
        "Jiangchao Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:51:33+00:00",
          "link": "https://arxiv.org/abs/2507.18578v1",
          "size": "885kb",
          "version": "v1"
        }
      ],
      "title": "Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18578",
        "PDF": "https://arxiv.org/pdf/2507.18578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a decoding algorithm (WINO) for Diffusion Large Language Models to improve quality-speed trade-offs. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18580",
      "abstract": "This paper presents our system for CCL25-Eval Task 10, addressing Fine-Grained Chinese Hate Speech Recognition (FGCHSR). We propose a novel SRAG-MAV framework that synergistically integrates task reformulation(TR), Self-Retrieval-Augmented Generation (SRAG), and Multi-Round Accumulative Voting (MAV). Our method reformulates the quadruplet extraction task into triplet extraction, uses dynamic retrieval from the training set to create contextual prompts, and applies multi-round inference with voting to improve output stability and performance. Our system, based on the Qwen2.5-7B model, achieves a Hard Score of 26.66, a Soft Score of 48.35, and an Average Score of 37.505 on the STATE ToxiCN dataset, significantly outperforming baselines such as GPT-4o (Average Score 15.63) and fine-tuned Qwen2.5-7B (Average Score 35.365). The code is available at https://github.com/king-wang123/CCL25-SRAG-MAV.",
      "authors": [
        "Jiahao Wang",
        "Ramen Liu",
        "Longhui Zhang",
        "Jing Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:56:38+00:00",
          "link": "https://arxiv.org/abs/2507.18580v1",
          "size": "446kb",
          "version": "v1"
        }
      ],
      "title": "System Report for CCL25-Eval Task 10: SRAG-MAV for Fine-Grained Chinese Hate Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18580",
        "HTML": "https://arxiv.org/html/2507.18580v1",
        "PDF": "https://arxiv.org/pdf/2507.18580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a system for Chinese Hate Speech Recognition and focuses on model performance evaluation. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18581",
      "abstract": "As DRAM density increases, Rowhammer becomes more severe due to heightened charge leakage, reducing the number of activations needed to induce bit flips. The DDR5 standard addresses this threat with in-DRAM per-row activation counters (PRAC) and the Alert Back-Off (ABO) signal to trigger mitigation. However, PRAC adds performance overhead by incrementing counters during the precharge phase, and recovery refreshes stalls the entire memory channel, even if only one bank is under attack.\n  We propose PRACtical, a performance-optimized approach to PRAC+ABO that maintains the same security guarantees. First, we reduce counter update latency by introducing a centralized increment circuit, enabling overlap between counter updates and subsequent row activations in other subarrays. Second, we enhance the $RFM_{ab}$ mitigation by enabling bank-level granularity: instead of stalling the entire channel, only affected banks are paused. This is achieved through a DRAM-resident register that identifies attacked banks.\n  PRACtical improves performance by 8% on average (up to 20%) over the state-of-the-art, reduces energy by 19%, and limits performance degradation from aggressive performance attacks to less than 6%, all while preserving Rowhammer protection.",
      "authors": [
        "Ravan Nazaraliyev",
        "Saber Ganjisaffar",
        "Nurlan Nazaraliyev",
        "Nael Abu-Ghazaleh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:58:44+00:00",
          "link": "https://arxiv.org/abs/2507.18581v1",
          "size": "927kb",
          "version": "v1"
        }
      ],
      "title": "PRACtical: Subarray-Level Counter Update and Bank-Level Recovery Isolation for Efficient PRAC Rowhammer Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18581",
        "HTML": "https://arxiv.org/html/2507.18581v1",
        "PDF": "https://arxiv.org/pdf/2507.18581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses Rowhammer mitigation in DRAM and focuses on performance optimization techniques. It does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18583",
      "abstract": "Electronic Health Records (EHRs) are pivotal in clinical practices, yet their retrieval remains a challenge mainly due to semantic gap issues. Recent advancements in dense retrieval offer promising solutions but existing models, both general-domain and biomedical-domain, fall short due to insufficient medical knowledge or mismatched training corpora. This paper introduces \\texttt{DR.EHR}, a series of dense retrieval models specifically tailored for EHR retrieval. We propose a two-stage training pipeline utilizing MIMIC-IV discharge summaries to address the need for extensive medical knowledge and large-scale training data. The first stage involves medical entity extraction and knowledge injection from a biomedical knowledge graph, while the second stage employs large language models to generate diverse training data. We train two variants of \\texttt{DR.EHR}, with 110M and 7B parameters, respectively. Evaluated on the CliniQ benchmark, our models significantly outperforms all existing dense retrievers, achieving state-of-the-art results. Detailed analyses confirm our models' superiority across various match and query types, particularly in challenging semantic matches like implication and abbreviation. Ablation studies validate the effectiveness of each pipeline component, and supplementary experiments on EHR QA datasets demonstrate the models' generalizability on natural language questions, including complex ones with multiple entities. This work significantly advances EHR retrieval, offering a robust solution for clinical applications.",
      "authors": [
        "Zhengyun Zhao",
        "Huaiyuan Ying",
        "Yue Zhong",
        "Sheng Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:02:46+00:00",
          "link": "https://arxiv.org/abs/2507.18583v1",
          "size": "188kb",
          "version": "v1"
        }
      ],
      "title": "DR.EHR: Dense Retrieval for Electronic Health Record with Knowledge Injection and Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18583",
        "HTML": "https://arxiv.org/html/2507.18583v1",
        "PDF": "https://arxiv.org/pdf/2507.18583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces \texttt{DR.EHR}, a dense retrieval system for Electronic Health Records, involving knowledge injection and synthetic data generation. It employs data engineering techniques, especially in generating large-scale training data, contributing directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18584",
      "abstract": "Despite the impressive performance of large language models (LLMs) in general domains, they often underperform in specialized domains. Existing approaches typically rely on data synthesis methods and yield promising results by using unlabeled data to capture domain-specific features. However, these methods either incur high computational costs or suffer from performance limitations, while also demonstrating insufficient generalization across different tasks. To address these challenges, we propose AQuilt, a framework for constructing instruction-tuning data for any specialized domains from corresponding unlabeled data, including Answer, Question, Unlabeled data, Inspection, Logic, and Task type. By incorporating logic and inspection, we encourage reasoning processes and self-inspection to enhance model performance. Moreover, customizable task instructions enable high-quality data generation for any task. As a result, we construct a dataset of 703k examples to train a powerful data synthesis model. Experiments show that AQuilt is comparable to DeepSeek-V3 while utilizing just 17% of the production cost. Further analysis demonstrates that our generated data exhibits higher relevance to downstream tasks. Source code, models, and scripts are available at https://github.com/Krueske/AQuilt.",
      "authors": [
        "Xiaopeng Ke and Hexuan Deng and Xuebo Liu and Jun Rao and Zhenxi Song and Jun Yu and Min Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:03:27+00:00",
          "link": "https://arxiv.org/abs/2507.18584v1",
          "size": "3764kb",
          "version": "v1"
        }
      ],
      "title": "AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18584",
        "HTML": "https://arxiv.org/html/2507.18584v1",
        "PDF": "https://arxiv.org/pdf/2507.18584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes AQuilt, a framework for constructing instruction-tuning datasets for specialized domains from unlabeled data. It involves creating a dataset of 703k examples and discusses data synthesis for improving LLM training data, making it a core contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18594",
      "abstract": "Low-light image enhancement remains a challenging task, particularly in preserving object edge continuity and fine structural details under extreme illumination degradation. In this paper, we propose a novel model, DRWKV (Detailed Receptance Weighted Key Value), which integrates our proposed Global Edge Retinex (GER) theory, enabling effective decoupling of illumination and edge structures for enhanced edge fidelity. Secondly, we introduce Evolving WKV Attention, a spiral-scanning mechanism that captures spatial edge continuity and models irregular structures more effectively. Thirdly, we design the Bilateral Spectrum Aligner (Bi-SAB) and a tailored MS2-Loss to jointly align luminance and chrominance features, improving visual naturalness and mitigating artifacts. Extensive experiments on five LLIE benchmarks demonstrate that DRWKV achieves leading performance in PSNR, SSIM, and NIQE while maintaining low computational complexity. Furthermore, DRWKV enhances downstream performance in low-light multi-object tracking tasks, validating its generalization capabilities.",
      "authors": [
        "Xuecheng Bai",
        "Yuxiang Wang",
        "Boyu Hu",
        "Qinyuan Jie",
        "Chuanzhi Xu",
        "Hongru Xiao",
        "Kechen Li",
        "Vera Chung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:24:59+00:00",
          "link": "https://arxiv.org/abs/2507.18594v1",
          "size": "2555kb",
          "version": "v1"
        }
      ],
      "title": "DRWKV: Focusing on Object Edges for Low-Light Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18594",
        "HTML": "https://arxiv.org/html/2507.18594v1",
        "PDF": "https://arxiv.org/pdf/2507.18594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses low-light image enhancement and proposes a model for that task. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18597",
      "abstract": "Processing spatial data is a key component in many learning tasks for autonomous driving such as motion forecasting, multi-agent simulation, and planning. Prior works have demonstrated the value in using SE(2) invariant network architectures that consider only the relative poses between objects (e.g. other agents, scene features such as traffic lanes). However, these methods compute the relative poses for all pairs of objects explicitly, requiring quadratic memory. In this work, we propose a mechanism for SE(2) invariant scaled dot-product attention that requires linear memory relative to the number of objects in the scene. Our SE(2) invariant transformer architecture enjoys the same scaling properties that have benefited large language models in recent years. We demonstrate experimentally that our approach is practical to implement and improves performance compared to comparable non-invariant architectures.",
      "authors": [
        "Ethan Pronovost",
        "Neha Boloor",
        "Peter Schleede",
        "Noureldin Hendy",
        "Andres Morales",
        "Nicholas Roy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:28:57+00:00",
          "link": "https://arxiv.org/abs/2507.18597v1",
          "size": "1122kb",
          "version": "v1"
        }
      ],
      "title": "Linear Memory SE(2) Invariant Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18597",
        "HTML": "https://arxiv.org/html/2507.18597v1",
        "PDF": "https://arxiv.org/pdf/2507.18597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an SE(2) invariant transformer for spatial data, focusing on memory efficiency and architecture for autonomous driving tasks, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18603",
      "abstract": "Generating novel and functional protein sequences is critical to a wide range of applications in biology. Recent advancements in conditional diffusion models have shown impressive empirical performance in protein generation tasks. However, reliable generations of protein remain an open research question in de novo protein design, especially when it comes to conditional diffusion models. Considering the biological function of a protein is determined by multi-level structures, we propose a novel multi-level conditional diffusion model that integrates both sequence-based and structure-based information for efficient end-to-end protein design guided by specified functions. By generating representations at different levels simultaneously, our framework can effectively model the inherent hierarchical relations between different levels, resulting in an informative and discriminative representation of the generated protein. We also propose a Protein-MMD, a new reliable evaluation metric, to evaluate the quality of generated protein with conditional diffusion models. Our new metric is able to capture both distributional and functional similarities between real and generated protein sequences while ensuring conditional consistency. We experiment with the benchmark datasets, and the results on conditional protein generation tasks demonstrate the efficacy of the proposed generation framework and evaluation metric.",
      "authors": [
        "Zinan Ling",
        "Yi Shi",
        "Da Yan",
        "Yang Zhou",
        "Bo Hui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:34:02+00:00",
          "link": "https://arxiv.org/abs/2507.18603v1",
          "size": "8379kb",
          "version": "v1"
        }
      ],
      "title": "Demystify Protein Generation with Hierarchical Conditional Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18603",
        "HTML": "https://arxiv.org/html/2507.18603v1",
        "PDF": "https://arxiv.org/pdf/2507.18603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses protein sequence generation using hierarchical conditional diffusion models, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18607",
      "abstract": "Large language models (LLMs) produce high-dimensional embeddings that capture rich semantic and syntactic relationships between words, sentences, and concepts. Investigating the topological structures of LLM embedding spaces via mapper graphs enables us to understand their underlying structures. Specifically, a mapper graph summarizes the topological structure of the embedding space, where each node represents a topological neighborhood (containing a cluster of embeddings), and an edge connects two nodes if their corresponding neighborhoods overlap. However, manually exploring these embedding spaces to uncover encoded linguistic properties requires considerable human effort. To address this challenge, we introduce a framework for semi-automatic annotation of these embedding properties. To organize the exploration process, we first define a taxonomy of explorable elements within a mapper graph such as nodes, edges, paths, components, and trajectories. The annotation of these elements is executed through two types of customizable LLM-based agents that employ perturbation techniques for scalable and automated analysis. These agents help to explore and explain the characteristics of mapper elements and verify the robustness of the generated explanations. We instantiate the framework within a visual analytics workspace and demonstrate its effectiveness through case studies. In particular, we replicate findings from prior research on BERT's embedding properties across various layers of its architecture and provide further observations into the linguistic properties of topological neighborhoods.",
      "authors": [
        "Xinyuan Yan",
        "Rita Sevastjanova",
        "Sinie van der Ben",
        "Mennatallah El-Assady",
        "Bei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:43:40+00:00",
          "link": "https://arxiv.org/abs/2507.18607v1",
          "size": "10778kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Mapper: Charting LLM Embedding Spaces Using Perturbation-Based Explanation and Verification Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18607",
        "HTML": "https://arxiv.org/html/2507.18607v1",
        "PDF": "https://arxiv.org/pdf/2507.18607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a framework for exploring LLM embedding spaces, it focuses on explanation and verification of the embeddings, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18612",
      "abstract": "Satisfiability Modulo Theory (SMT) solvers have advanced automated reasoning, solving complex formulas across discrete and continuous domains. Recent progress in propositional model counting motivates extending SMT capabilities toward model counting, especially for hybrid SMT formulas. Existing approaches, like bit-blasting, are limited to discrete variables, highlighting the challenge of counting solutions projected onto the discrete domain in hybrid formulas.\n  We introduce pact, an SMT model counter for hybrid formulas that uses hashing-based approximate model counting to estimate solutions with theoretical guarantees. pact makes a logarithmic number of SMT solver calls relative to the projection variables, leveraging optimized hash functions. pact achieves significant performance improvements over baselines on a large suite of benchmarks. In particular, out of 14,202 instances, pact successfully finished on 603 instances, while Baseline could only finish on 13 instances.",
      "authors": [
        "Arijit Shaw",
        "Kuldeep S. Meel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:48:13+00:00",
          "link": "https://arxiv.org/abs/2507.18612v1",
          "size": "138kb",
          "version": "v1"
        }
      ],
      "title": "Approximate SMT Counting Beyond Discrete Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18612",
        "HTML": "https://arxiv.org/html/2507.18612v1",
        "PDF": "https://arxiv.org/pdf/2507.18612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an SMT model counter for hybrid formulas, concerning mathematical logic and automated reasoning, without discussing LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18616",
      "abstract": "Zero-shot Image Captioning (ZIC) increasingly utilizes synthetic datasets generated by text-to-image (T2I) models to mitigate the need for costly manual annotation. However, these T2I models often produce images that exhibit semantic misalignments with their corresponding input captions (e.g., missing objects, incorrect attributes), resulting in noisy synthetic image-caption pairs that can hinder model training. Existing dataset pruning techniques are largely designed for removing noisy text in web-crawled data. However, these methods are ill-suited for the distinct challenges of synthetic data, where captions are typically well-formed, but images may be inaccurate representations. To address this gap, we introduce SynC, a novel framework specifically designed to refine synthetic image-caption datasets for ZIC. Instead of conventional filtering or regeneration, SynC focuses on reassigning captions to the most semantically aligned images already present within the synthetic image pool. Our approach employs a one-to-many mapping strategy by initially retrieving multiple relevant candidate images for each caption. We then apply a cycle-consistency-inspired alignment scorer that selects the best image by verifying its ability to retrieve the original caption via image-to-text retrieval. Extensive evaluations demonstrate that SynC consistently and significantly improves performance across various ZIC models on standard benchmarks (MS-COCO, Flickr30k, NoCaps), achieving state-of-the-art results in several scenarios. SynC offers an effective strategy for curating refined synthetic data to enhance ZIC.",
      "authors": [
        "Si-Woo Kim",
        "MinJu Jeon",
        "Ye-Chan Kim",
        "Soeun Lee",
        "Taewhan Kim",
        "Dong-Jin Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:53:26+00:00",
          "link": "https://arxiv.org/abs/2507.18616v1",
          "size": "745kb",
          "version": "v1"
        }
      ],
      "title": "SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18616",
        "HTML": "https://arxiv.org/html/2507.18616v1",
        "PDF": "https://arxiv.org/pdf/2507.18616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "SynC introduces a method for refining synthetic image-caption datasets for zero-shot image captioning, which relates to data refinement. However, it focuses on image-caption alignment rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18618",
      "abstract": "Prompt optimization improves the reasoning abilities of large language models (LLMs) without requiring parameter updates to the target model. Following heuristic-based \"Think step by step\" approaches, the field has evolved in two main directions: while one group of methods uses textual feedback to elicit improved prompts from general-purpose LLMs in a training-free way, a concurrent line of research relies on numerical rewards to train a special prompt model, tailored for providing optimal prompts to the target model. In this paper, we introduce the Textual Reward Prompt framework (TRPrompt), which unifies these approaches by directly incorporating textual feedback into training of the prompt model. Our framework does not require prior dataset collection and is being iteratively improved with the feedback on the generated prompts. When coupled with the capacity of an LLM to internalize the notion of what a \"good\" prompt is, the high-resolution signal provided by the textual rewards allows us to train a prompt model yielding state-of-the-art query-specific prompts for the problems from the challenging math datasets GSMHard and MATH.",
      "authors": [
        "Andreea Nica",
        "Ivan Zakazov",
        "Nicolas Mario Baldwin",
        "Saibo Geng",
        "Robert West"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:54:44+00:00",
          "link": "https://arxiv.org/abs/2507.18618v1",
          "size": "2374kb",
          "version": "v1"
        }
      ],
      "title": "TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18618",
        "HTML": "https://arxiv.org/html/2507.18618v1",
        "PDF": "https://arxiv.org/pdf/2507.18618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on prompt optimization using textual rewards without requiring dataset collection or large-scale data processing operations, thus it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18619",
      "abstract": "Children with hearing impairments face ongoing challenges in language and motor development. This study explores how multi-sensory feedback technology based on virtual reality (VR), integrating auditory, visual, and tactile stimuli, can enhance rehabilitation outcomes. Using functional near-infrared spectroscopy (fNIRS) technology, we assessed cortical activation patterns in children during pitch-matching tasks across different interaction modes. Our findings aim to provide evidence for designing personalized, interactive rehabilitation systems that enhance cognitive engagement and motor control in children with hearing impairments.",
      "authors": [
        "Yichen Yu",
        "Qiaoran Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:55:37+00:00",
          "link": "https://arxiv.org/abs/2507.18619v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "MeloKids: Multisensory VR System to Enhance Speech and Motor Coordination in Children with Hearing Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18619",
        "HTML": "https://arxiv.org/html/2507.18619v1",
        "PDF": "https://arxiv.org/pdf/2507.18619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores VR-based rehabilitation systems for children with hearing impairments, which is unrelated to LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18622",
      "abstract": "Ensuring reproducibility of research is an integral part of good scientific practice. One way to support this is through provenance: information about research workflows from data gathering to researchers' sensemaking processes leading to published results. This is highly important in disciplines such as geosciences, where researchers use software for interactive and immersive visualizations of geospatial data, doing virtual measurements in simulated fieldwork on 3D models. We evaluated a provenance management tool, which allows recording of interactions with a virtual fieldwork tool and annotating different states of the visualization. The user study investigated how researchers used this Digital Lab Book (DLB) and whether perceived ease of use and perceived usefulness differed between groups in immersive or non-immersive settings. Participants perceived the DLB as both useful and easy to use. While there were indications of differences in perceived ease of use (higher for immersive setting), usage patterns showed no significant group differences.",
      "authors": [
        "Armin Bernstetter",
        "Tom Kwasnitschka",
        "Isabella Peters"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:56:06+00:00",
          "link": "https://arxiv.org/abs/2507.18622v1",
          "size": "1986kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of a Provenance Management Tool for Immersive Virtual Fieldwork",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18622",
        "HTML": "https://arxiv.org/html/2507.18622v1",
        "PDF": "https://arxiv.org/pdf/2507.18622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on provenance management for reproducibility in virtual fieldwork, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18623",
      "abstract": "The ability to adapt to physical actions and constraints in an environment is crucial for embodied agents (e.g., robots) to effectively collaborate with humans. Such physically grounded human-AI collaboration must account for the increased complexity of the continuous state-action space and constrained dynamics caused by physical constraints. In this paper, we introduce \\textit{Moving Out}, a new human-AI collaboration benchmark that resembles a wide range of collaboration modes affected by physical attributes and constraints, such as moving heavy items together and maintaining consistent actions to move a big item around a corner. Using Moving Out, we designed two tasks and collected human-human interaction data to evaluate models' abilities to adapt to diverse human behaviors and unseen physical attributes. To address the challenges in physical environments, we propose a novel method, BASS (Behavior Augmentation, Simulation, and Selection), to enhance the diversity of agents and their understanding of the outcome of actions. Our experiments show that BASS outperforms state-of-the-art models in AI-AI and human-AI collaboration. The project page is available at \\href{https://live-robotics-uva.github.io/movingout_ai/}{https://live-robotics-uva.github.io/movingout\\_ai/}.",
      "authors": [
        "Xuhui Kang",
        "Sung-Wook Lee",
        "Haolin Liu",
        "Yuyan Wang",
        "Yen-Ling Kuo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:57:18+00:00",
          "link": "https://arxiv.org/abs/2507.18623v1",
          "size": "1924kb",
          "version": "v1"
        }
      ],
      "title": "Moving Out: Physically-grounded Human-AI Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18623",
        "HTML": "https://arxiv.org/html/2507.18623v1",
        "PDF": "https://arxiv.org/pdf/2507.18623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for human-AI physical collaboration and discusses methods for understanding physical interactions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18624",
      "abstract": "Language models must be adapted to understand and follow user instructions. Reinforcement learning is widely used to facilitate this -- typically using fixed criteria such as \"helpfulness\" and \"harmfulness\". In our work, we instead propose using flexible, instruction-specific criteria as a means of broadening the impact that reinforcement learning can have in eliciting instruction following. We propose \"Reinforcement Learning from Checklist Feedback\" (RLCF). From instructions, we extract checklists and evaluate how well responses satisfy each item - using both AI judges and specialized verifier programs - then combine these scores to compute rewards for RL. We compare RLCF with other alignment methods applied to a strong instruction following model (Qwen2.5-7B-Instruct) on five widely-studied benchmarks -- RLCF is the only method to improve performance on every benchmark, including a 4-point boost in hard satisfaction rate on FollowBench, a 6-point increase on InFoBench, and a 3-point rise in win rate on Arena-Hard. These results establish checklist feedback as a key tool for improving language models' support of queries that express a multitude of needs.",
      "authors": [
        "Vijay Viswanathan",
        "Yanchao Sun",
        "Shuang Ma",
        "Xiang Kong",
        "Meng Cao",
        "Graham Neubig",
        "Tongshuang Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:58:00+00:00",
          "link": "https://arxiv.org/abs/2507.18624v1",
          "size": "120kb",
          "version": "v1"
        }
      ],
      "title": "Checklists Are Better Than Reward Models For Aligning Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18624",
        "HTML": "https://arxiv.org/html/2507.18624v1",
        "PDF": "https://arxiv.org/pdf/2507.18624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses using checklist feedback for reinforcement learning to align LLMs, focusing on model behavior rather than on the processing or creation of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18625",
      "abstract": "Graphical user interface (UI) software has undergone a fundamental transformation from traditional two-dimensional (2D) desktop/web/mobile interfaces to spatial three-dimensional (3D) environments. While existing work has made remarkable success in automated 2D software generation, such as HTML/CSS and mobile app interface code synthesis, the generation of 3D software still remains under-explored. Current methods for 3D software generation usually generate the 3D environments as a whole and cannot modify or control specific elements in the software. Furthermore, these methods struggle to handle the complex spatial and semantic constraints inherent in the real world. To address the challenges, we present Scenethesis, a novel requirement-sensitive 3D software synthesis approach that maintains formal traceability between user specifications and generated 3D software. Scenethesis is built upon ScenethesisLang, a domain-specific language that serves as a granular constraint-aware intermediate representation (IR) to bridge natural language requirements and executable 3D software. It serves both as a comprehensive scene description language enabling fine-grained modification of 3D software elements and as a formal constraint-expressive specification language capable of expressing complex spatial constraints. By decomposing 3D software synthesis into stages operating on ScenethesisLang, Scenethesis enables independent verification, targeted modification, and systematic constraint satisfaction. Our evaluation demonstrates that Scenethesis accurately captures over 80% of user requirements and satisfies more than 90% of hard constraints while handling over 100 constraints simultaneously. Furthermore, Scenethesis achieves a 42.8% improvement in BLIP-2 visual evaluation scores compared to the state-of-the-art method.",
      "authors": [
        "Shuqing Li",
        "Anson Y. Lam",
        "Yun Peng",
        "Wenxuan Wang",
        "Michael R. Lyu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:58:03+00:00",
          "link": "https://arxiv.org/abs/2507.18625v1",
          "size": "827kb",
          "version": "v1"
        }
      ],
      "title": "3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18625",
        "HTML": "https://arxiv.org/html/2507.18625v1",
        "PDF": "https://arxiv.org/pdf/2507.18625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a 3D software synthesis approach using a domain-specific language for graphical user interfaces, with no relation to LLM training data processing or data operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18627",
      "abstract": "This project presents the development of a gait recognition system using Tiny Machine Learning (Tiny ML) and Inertial Measurement Unit (IMU) sensors. The system leverages the XIAO-nRF52840 Sense microcontroller and the LSM6DS3 IMU sensor to capture motion data, including acceleration and angular velocity, from four distinct activities: walking, stationary, going upstairs, and going downstairs. The data collected is processed through Edge Impulse, an edge AI platform, which enables the training of machine learning models that can be deployed directly onto the microcontroller for real-time activity classification.The data preprocessing step involves extracting relevant features from the raw sensor data using techniques such as sliding windows and data normalization, followed by training a Deep Neural Network (DNN) classifier for activity recognition. The model achieves over 80% accuracy on a test dataset, demonstrating its ability to classify the four activities effectively. Additionally, the platform enables anomaly detection, further enhancing the robustness of the system. The integration of Tiny ML ensures low-power operation, making it suitable for battery-powered or energy-harvesting devices.",
      "authors": [
        "Jiahang Zhang",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:59:08+00:00",
          "link": "https://arxiv.org/abs/2507.18627v1",
          "size": "392kb",
          "version": "v1"
        }
      ],
      "title": "Gait Recognition Based on Tiny ML and IMU Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18627",
        "HTML": "https://arxiv.org/html/2507.18627v1",
        "PDF": "https://arxiv.org/pdf/2507.18627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is about gait recognition using Tiny ML and IMU sensors, focusing on hardware and small-scale machine learning applications, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18630",
      "abstract": "In this research, the design and optimization of a novel leaf-shaped antenna inspired by natural leaf structures for radio frequency energy transfer is presented. The objectives of this study are to develop a bio-inspired antenna, optimize its performance through impedance matching for the 915 MHz frequency band, and evaluate its efficiency in capturing RF energy. The design process involves selecting an appropriate leaf shape, modeling the antenna using AutoCAD and HFSS software, and fabricating a printed circuit board (PCB) prototype. Simulations and physical tests are conducted to optimize the antennas performance, achieving an S11 parameter of nearly -20 dB at 915 MHz, indicating effective energy capture. Experimental results demonstrate the antennas ability to power a device at distances up to 200 cm, with charging times reflecting its efficiency. The study concludes that the bio-inspired design of the proposed antenna improves RF energy transfer. Future work should focus on testing the antennas penetration through concrete and developing a feedback system for autonomous alignment.",
      "authors": [
        "Junbin Zhong",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:59:22+00:00",
          "link": "https://arxiv.org/abs/2507.18630v1",
          "size": "1131kb",
          "version": "v1"
        }
      ],
      "title": "Design and optimization of a novel leaf-shape antenna for RF energy transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18630",
        "HTML": "https://arxiv.org/html/2507.18630v1",
        "PDF": "https://arxiv.org/pdf/2507.18630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is focused on RF energy transfer using a bio-inspired antenna design, lacking any connection to LLM training data processing or contributions to dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18631",
      "abstract": "With rapid advancement and increasing accessibility of LLMs, fine-tuning aligned models has become a critical step for adapting them to real-world applications, which makes the safety of this fine-tuning process more important than ever. However, recent studies have highlighted a critical challenge: even when fine-tuning with seemingly benign downstream datasets, the safety of aligned LLMs can be compromised, making them more susceptible to malicious instructions. In this paper, we show that fine-tuning datasets often contain samples with safety-degrading features that are not easily identifiable on the surface. These samples can significantly degrade the safety alignment of LLMs during fine-tuning. To address this issue, we propose LARF, a \\textbf{L}ayer-\\textbf{A}ware \\textbf{R}epresentation \\textbf{F}iltering method. This method identifies safety-sensitive layers within the LLM and leverages their representations to detect which data samples in the post-training dataset contain safety-degrading features. Experimental results demonstrate that LARF can effectively identify benign data with safety-degrading features. After removing such data, the safety alignment degradation caused by fine-tuning is mitigated. Please see our code at \\href{https://github.com/LLLeoLi/LARF}{https://github.com/LLLeoLi/LARF}.",
      "authors": [
        "Hao Li",
        "Lijun Li",
        "Zhenghao Lu",
        "Xianyi Wei",
        "Rui Li",
        "Jing Shao",
        "Lei Sha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:59:24+00:00",
          "link": "https://arxiv.org/abs/2507.18631v1",
          "size": "909kb",
          "version": "v1"
        }
      ],
      "title": "Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18631",
        "HTML": "https://arxiv.org/html/2507.18631v1",
        "PDF": "https://arxiv.org/pdf/2507.18631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper proposes a method called LARF for filtering fine-tuning data to preserve the safety alignment of LLMs, directly addressing data quality improvement in LLM fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18632",
      "abstract": "Zero-shot domain adaptation is a method for adapting a model to a target domain without utilizing target domain image data. To enable adaptation without target images, existing studies utilize CLIP's embedding space and text description to simulate target-like style features. Despite the previous achievements in zero-shot domain adaptation, we observe that these text-driven methods struggle to capture complex real-world variations and significantly increase adaptation time due to their alignment process. Instead of relying on text descriptions, we explore solutions leveraging image data, which provides diverse and more fine-grained style cues. In this work, we propose SIDA, a novel and efficient zero-shot domain adaptation method leveraging synthetic images. To generate synthetic images, we first create detailed, source-like images and apply image translation to reflect the style of the target domain. We then utilize the style features of these synthetic images as a proxy for the target domain. Based on these features, we introduce Domain Mix and Patch Style Transfer modules, which enable effective modeling of real-world variations. In particular, Domain Mix blends multiple styles to expand the intra-domain representations, and Patch Style Transfer assigns different styles to individual patches. We demonstrate the effectiveness of our method by showing state-of-the-art performance in diverse zero-shot adaptation scenarios, particularly in challenging domains. Moreover, our approach achieves high efficiency by significantly reducing the overall adaptation time.",
      "authors": [
        "Ye-Chan Kim",
        "SeungJu Cha",
        "Si-Woo Kim",
        "Taewhan Kim",
        "Dong-Jin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:59:36+00:00",
          "link": "https://arxiv.org/abs/2507.18632v1",
          "size": "930kb",
          "version": "v1"
        }
      ],
      "title": "SIDA: Synthetic Image Driven Zero-shot Domain Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18632",
        "HTML": "https://arxiv.org/html/2507.18632v1",
        "PDF": "https://arxiv.org/pdf/2507.18632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on zero-shot domain adaptation using synthetic images to model target domain variations. It does not address any aspect of LLM training data processing, as it deals primarily with image data and domain adaptation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18633",
      "abstract": "A common and controversial use of text-to-image models is to generate pictures by explicitly naming artists, such as \"in the style of Greg Rutkowski\". We introduce a benchmark for prompted-artist recognition: predicting which artist names were invoked in the prompt from the image alone. The dataset contains 1.95M images covering 110 artists and spans four generalization settings: held-out artists, increasing prompt complexity, multiple-artist prompts, and different text-to-image models. We evaluate feature similarity baselines, contrastive style descriptors, data attribution methods, supervised classifiers, and few-shot prototypical networks. Generalization patterns vary: supervised and few-shot models excel on seen artists and complex prompts, whereas style descriptors transfer better when the artist's style is pronounced; multi-artist prompts remain the most challenging. Our benchmark reveals substantial headroom and provides a public testbed to advance the responsible moderation of text-to-image models. We release the dataset and benchmark to foster further research: https://graceduansu.github.io/IdentifyingPromptedArtists/",
      "authors": [
        "Grace Su",
        "Sheng-Yu Wang",
        "Aaron Hertzmann",
        "Eli Shechtman",
        "Jun-Yan Zhu",
        "Richard Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:59:44+00:00",
          "link": "https://arxiv.org/abs/2507.18633v1",
          "size": "2631kb",
          "version": "v1"
        }
      ],
      "title": "Identifying Prompted Artist Names from Generated Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18633",
        "HTML": "https://arxiv.org/html/2507.18633v1",
        "PDF": "https://arxiv.org/pdf/2507.18633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for identifying prompted artist names from generated images, focusing on text-to-image models and artist recognition tasks. It does not relate to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "cmu-gil/PromptedArtistIdentificationDataset",
          "downloads": "2175",
          "likes": "1",
          "link": "https://huggingface.co/datasets/cmu-gil/PromptedArtistIdentificationDataset"
        },
        {
          "dataset_name": "cmu-gil/PromptedArtistIdentificationDataset-ViewSamples",
          "downloads": "12",
          "likes": "0",
          "link": "https://huggingface.co/datasets/cmu-gil/PromptedArtistIdentificationDataset-ViewSamples"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.18634",
      "abstract": "We present Captain Cinema, a generation framework for short movie generation. Given a detailed textual description of a movie storyline, our approach firstly generates a sequence of keyframes that outline the entire narrative, which ensures long-range coherence in both the storyline and visual appearance (e.g., scenes and characters). We refer to this step as top-down keyframe planning. These keyframes then serve as conditioning signals for a video synthesis model, which supports long context learning, to produce the spatio-temporal dynamics between them. This step is referred to as bottom-up video synthesis. To support stable and efficient generation of multi-scene long narrative cinematic works, we introduce an interleaved training strategy for Multimodal Diffusion Transformers (MM-DiT), specifically adapted for long-context video data. Our model is trained on a specially curated cinematic dataset consisting of interleaved data pairs. Our experiments demonstrate that Captain Cinema performs favorably in the automated creation of visually coherent and narrative consistent short movies in high quality and efficiency. Project page: https://thecinema.ai",
      "authors": [
        "Junfei Xiao",
        "Ceyuan Yang",
        "Lvmin Zhang",
        "Shengqu Cai",
        "Yang Zhao",
        "Yuwei Guo",
        "Gordon Wetzstein",
        "Maneesh Agrawala",
        "Alan Yuille",
        "and Lu Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2507.18634v1",
          "size": "46911kb",
          "version": "v1"
        }
      ],
      "title": "Captain Cinema: Towards Short Movie Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18634",
        "HTML": "https://arxiv.org/html/2507.18634v1",
        "PDF": "https://arxiv.org/pdf/2507.18634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for generating short movies using keyframe planning and video synthesis. It involves video generation and cinematic data but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16641",
      "abstract": "A reinforcement learning (RL) framework is introduced for the efficient synthesis of quantum circuits that generate specified target quantum states from a fixed initial state, addressing a central challenge in both the NISQ era and future fault-tolerant quantum computing. The approach utilizes tabular Q-learning, based on action sequences, within a discretized quantum state space, to effectively manage the exponential growth of the space dimension. The framework introduces a hybrid reward mechanism, combining a static, domain-informed reward that guides the agent toward the target state with customizable dynamic penalties that discourage inefficient circuit structures such as gate congestion and redundant state revisits. By leveraging sparse matrix representations and state-space discretization, the method enables scalable navigation of high-dimensional environments while minimizing computational overhead. Benchmarking on graph-state preparation tasks for up to seven qubits, we demonstrate that the algorithm consistently discovers minimal-depth circuits with optimized gate counts. Moreover, extending the framework to a universal gate set for arbitrary quantum states, it still produces minimal depth circuits, highlighting the algorithm's robustness and adaptability. The results confirm that this RL-driven approach efficiently explores the complex quantum state space and synthesizes near-optimal quantum circuits, providing a resource-efficient foundation for quantum circuit optimization.",
      "authors": [
        "Sara Giordano",
        "Kornikar Sen",
        "Miguel A. Martin-Delgado"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T14:39:20+00:00",
          "link": "https://arxiv.org/abs/2507.16641v1",
          "size": "2064kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16641",
        "HTML": "https://arxiv.org/html/2507.16641v1",
        "PDF": "https://arxiv.org/pdf/2507.16641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reinforcement learning for quantum circuit synthesis, which has no relation to LLM training data processing or any related data collection, generation, or enhancement techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17764",
      "abstract": "By integrating the generative strengths of diffusion models with the representation capabilities of frequency-domain attention, DFAM effectively enhances reconstruction performance under low-SNR condi-tions. Experimental results demonstrate that DFAM consistently outperforms both conventional reconstruction algorithms and recent learning-based approaches. These findings highlight the potential of DFAM as a promising solution to advance low-field MRI reconstruction, particularly in resource-constrained or underdeveloped clinical settings.",
      "authors": [
        "Xin Xie",
        "Yu Guan",
        "Zhuoxu Cui",
        "Dong Liang",
        "Qiegen Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:30:06+00:00",
          "link": "https://arxiv.org/abs/2507.17764v1",
          "size": "1987kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion-Assisted Frequency Attention Model for Whole-body Low-field MRI Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17764",
        "PDF": "https://arxiv.org/pdf/2507.17764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on MRI reconstruction using diffusion models and frequency-domain attention, with no contribution to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17765",
      "abstract": "From an application standpoint, speaker-role diarization (RD), such as doctor vs. patient, host vs. guest, etc. is often more useful than traditional speaker diarization (SD), which assigns generic labels like speaker-1, speaker-2 etc. In the context of joint automatic speech recognition (ASR) + SD (who spoke what?), recent end-to-end models employ an auxiliary SD transducer, synchronized with the ASR transducer, to predict speakers per word. In this paper, we extend this framework to RD with three key contributions: (1) we simplify the training via forced alignment and cross-entropy loss instead of RNNT loss, (2) we show that word prediction and role prediction require different amounts of predictor's context, leading to separate task-specific predictors, unlike existing shared-predictor models, and (3) we propose a way to leverage RD posterior activity to influence ASR decoding and reduce small-word deletion errors.",
      "authors": [
        "Arindam Ghosh",
        "Mark Fuhs",
        "Bongjun Kim",
        "Anurag Chowdhury",
        "Monika Woszczyna"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:23:47+00:00",
          "link": "https://arxiv.org/abs/2507.17765v1",
          "size": "382kb",
          "version": "v1"
        }
      ],
      "title": "ASR-Guided Speaker-Role Diarization and Diarization-Guided ASR Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17765",
        "HTML": "https://arxiv.org/html/2507.17765v1",
        "PDF": "https://arxiv.org/pdf/2507.17765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses improvements in speaker-role diarization and ASR decoding, which are not related to LLM training data processing operations or techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17775",
      "abstract": "Geometric deep learning is an emerging technique in Artificial Intelligence (AI) driven cheminformatics, however the unique implications of different Graph Neural Network (GNN) architectures are poorly explored, for this space. This study compared performances of Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs) and Graph Isomorphism Networks (GINs), applied to 7 different toxicological assay datasets of varying data abundance and endpoint, to perform binary classification of assay activation. Following pre-processing of molecular graphs, enforcement of class-balance and stratification of all datasets across 5 folds, Bayesian optimisations were carried out, for each GNN applied to each assay dataset (resulting in 21 unique Bayesian optimisations). Optimised GNNs performed at Area Under the Curve (AUC) scores ranging from 0.728-0.849 (averaged across all folds), naturally varying between specific assays and GNNs. GINs were found to consistently outperform GCNs and GATs, for the top 5 of 7 most data-abundant toxicological assays. GATs however significantly outperformed over the remaining 2 most data-scarce assays. This indicates that GINs are a more optimal architecture for data-abundant environments, whereas GATs are a more optimal architecture for data-scarce environments. Subsequent analysis of the explored higher-dimensional hyperparameter spaces, as well as optimised hyperparameter states, found that GCNs and GATs reached measurably closer optimised states with each other, compared to GINs, further indicating the unique nature of GINs as a GNN algorithm.",
      "authors": [
        "Alexander D. Kalian",
        "Lennart Otte",
        "Jaewook Lee",
        "Emilio Benfenati",
        "Jean-Lou C.M. Dorne",
        "Claire Potter",
        "Olivia J. Osborne",
        "Miao Guo",
        "Christer Hogstrand"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T11:38:11+00:00",
          "link": "https://arxiv.org/abs/2507.17775v1",
          "size": "2743kb",
          "version": "v1"
        }
      ],
      "title": "Comparison of Optimised Geometric Deep Learning Architectures, over Varying Toxicological Assay Data Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17775",
        "PDF": "https://arxiv.org/pdf/2507.17775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on comparing geometric deep learning architectures for toxicological assay datasets, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17776",
      "abstract": "In a recent paper, Kit Fine presents some striking results concerning the logical properties of (first-order) ignorance, second-order ignorance and Rumsfeld ignorance. However, Rumsfeld ignorance is definable in terms of ignorance, which makes some existing results and the axiomatization problem trivial. A main reason is that the accessibility relations for the implicit knowledge operator contained in the packaged operators of ignorance and Rumsfeld ignorance are the same. In this work, we assume the two accessibility relations to be different so that one of them is an arbitrary subset of the other. This will avoid the definability issue and retain most of the previous validities. The main results are axiomatizations over various proper bi-frame classes. Finally we apply our framework to analyze Fine's results.",
      "authors": [
        "Jie Fan"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Logic (math.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T14:25:53+00:00",
          "link": "https://arxiv.org/abs/2507.17776v1",
          "size": "102kb",
          "version": "v1"
        }
      ],
      "title": "Axiomatizing Rumsfeld Ignorance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17776",
        "HTML": "https://arxiv.org/html/2507.17776v1",
        "PDF": "https://arxiv.org/pdf/2507.17776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about axiomatizing Rumsfeld ignorance and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17779",
      "abstract": "Accurate segmentation of coronary arteries remains a significant challenge in clinical practice, hindering the ability to effectively diagnose and manage coronary artery disease. The lack of large, annotated datasets for model training exacerbates this issue, limiting the development of automated tools that could assist radiologists. To address this, we introduce CM-UNet, which leverages self-supervised pre-training on unannotated datasets and transfer learning on limited annotated data, enabling accurate disease detection while minimizing the need for extensive manual annotations. Fine-tuning CM-UNet with only 18 annotated images instead of 500 resulted in a 15.2% decrease in Dice score, compared to a 46.5% drop in baseline models without pre-training. This demonstrates that self-supervised learning can enhance segmentation performance and reduce dependence on large datasets. This is one of the first studies to highlight the importance of self-supervised learning in improving coronary artery segmentation from X-ray angiography, with potential implications for advancing diagnostic accuracy in clinical practice. By enhancing segmentation accuracy in X-ray angiography images, the proposed approach aims to improve clinical workflows, reduce radiologists' workload, and accelerate disease detection, ultimately contributing to better patient outcomes. The source code is publicly available at https://github.com/CamilleChallier/Contrastive-Masked-UNet.",
      "authors": [
        "Camille Challier",
        "Xiaowu Sun",
        "Thabo Mahendiran",
        "Ortal Senouf",
        "Bernard De Bruyne",
        "Denise Auberson",
        "Olivier M\\\"uller",
        "Stephane Fournier",
        "Pascal Frossard",
        "Emmanuel Abb\\'e and Dorina Thanou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:27:34+00:00",
          "link": "https://arxiv.org/abs/2507.17779v1",
          "size": "3425kb",
          "version": "v1"
        }
      ],
      "title": "CM-UNet: A Self-Supervised Learning-Based Model for Coronary Artery Segmentation in X-Ray Angiography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17779",
        "HTML": "https://arxiv.org/html/2507.17779v1",
        "PDF": "https://arxiv.org/pdf/2507.17779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with self-supervised learning for coronary artery segmentation in X-ray angiography, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17799",
      "abstract": "Voice disorders affect a significant portion of the population, and the ability to diagnose them using automated, non-invasive techniques would represent a substantial advancement in healthcare, improving the quality of life of patients. Recent studies have demonstrated that artificial intelligence models, particularly Deep Neural Networks (DNNs), can effectively address this task. However, due to their complexity, the decision-making process of such models often remain opaque, limiting their trustworthiness in clinical contexts. This paper investigates an alternative approach based on Explainable AI (XAI), a field that aims to improve the interpretability of DNNs by providing different forms of explanations. Specifically, this works focuses on concept-based models such as Concept Bottleneck Model (CBM) and Concept Embedding Model (CEM) and how they can achieve performance comparable to traditional deep learning methods, while offering a more transparent and interpretable decision framework.",
      "authors": [
        "Davide Ghia",
        "Gabriele Ciravegna",
        "Alkis Koudounas",
        "Marco Fantini",
        "Erika Crosetti",
        "Giovanni Succo",
        "Tania Cerquitelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:11:44+00:00",
          "link": "https://arxiv.org/abs/2507.17799v1",
          "size": "257kb",
          "version": "v1"
        }
      ],
      "title": "A Concept-based approach to Voice Disorder Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17799",
        "HTML": "https://arxiv.org/html/2507.17799v1",
        "PDF": "https://arxiv.org/pdf/2507.17799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses voice disorder detection using Explainable AI and concept-based models for interpretability, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17800",
      "abstract": "Multislice electron ptychography (MEP) is an inverse imaging technique that computationally reconstructs the highest-resolution images of atomic crystal structures from diffraction patterns. Available algorithms often solve this inverse problem iteratively but are both time consuming and produce suboptimal solutions due to their ill-posed nature. We develop MEP-Diffusion, a diffusion model trained on a large database of crystal structures specifically for MEP to augment existing iterative solvers. MEP-Diffusion is easily integrated as a generative prior into existing reconstruction methods via Diffusion Posterior Sampling (DPS). We find that this hybrid approach greatly enhances the quality of the reconstructed 3D volumes, achieving a 90.50% improvement in SSIM over existing methods.",
      "authors": [
        "Christian K. Belardi",
        "Chia-Hao Lee",
        "Yingheng Wang",
        "Justin Lovelace",
        "Kilian Q. Weinberger",
        "David A. Muller",
        "Carla P. Gomes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:35:25+00:00",
          "link": "https://arxiv.org/abs/2507.17800v1",
          "size": "1231kb",
          "version": "v1"
        }
      ],
      "title": "Improving Multislice Electron Ptychography with a Generative Prior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17800",
        "HTML": "https://arxiv.org/html/2507.17800v1",
        "PDF": "https://arxiv.org/pdf/2507.17800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops MEP-Diffusion, a diffusion model for electron ptychography, a method for reconstructing crystal structures. It's not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17804",
      "abstract": "The Galactic Center Excess (GCE) remains one of the defining mysteries uncovered by the Fermi $\\gamma$-ray Space Telescope. Although it may yet herald the discovery of annihilating dark matter, weighing against that conclusion are analyses showing the spatial structure of the emission appears more consistent with a population of dim point sources. Technical limitations have restricted prior analyses to studying the point-source hypothesis purely spatially. All spectral information that could help disentangle the GCE from the complex and uncertain astrophysical emission was discarded. We demonstrate that a neural network-aided simulation-based inference approach can overcome such limitations and thereby confront the point source explanation of the GCE with spatial and spectral data. The addition is profound: energy information drives the putative point sources to be significantly dimmer, indicating either the GCE is truly diffuse in nature or made of an exceptionally large number of sources. Quantitatively, for our best fit background model, the excess is essentially consistent with Poisson emission as predicted by dark matter. If the excess is instead due to point sources, our median prediction is ${\\cal O}(10^5)$ sources in the Galactic Center, or more than 35,000 sources at 90% confidence, both significantly larger than the hundreds of sources preferred by earlier point-source analyses of the GCE.",
      "authors": [
        "Florian List",
        "Yujin Park",
        "Nicholas L. Rodd",
        "Eve Schoen",
        "Florian Wolf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Phenomenology (hep-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:00:00+00:00",
          "link": "https://arxiv.org/abs/2507.17804v1",
          "size": "7661kb",
          "version": "v1"
        }
      ],
      "title": "On the Energy Distribution of the Galactic Center Excess' Sources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17804",
        "HTML": "https://arxiv.org/html/2507.17804v1",
        "PDF": "https://arxiv.org/pdf/2507.17804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on analyzing the Galactic Center Excess using spatial and spectral data, exploring hypotheses unrelated to LLMs or their training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17815",
      "abstract": "In mathematics or theoretical physics one is often interested in obtaining an exact analytic description of some data which can be produced, in principle, to arbitrary accuracy. For example, one might like to know the exact analytical form of a definite integral. Such problems are not well-suited to numerical symbolic regression, since typical numerical methods lead only to approximations. However, if one has some sense of the function space in which the analytic result should lie, it is possible to deduce the exact answer by judiciously sampling the data at a sufficient number of points with sufficient precision. We demonstrate how this can be done for the computation of Feynman integrals. We show that by combining high-precision numerical integration with analytic knowledge of the function space one can often deduce the exact answer using lattice reduction. A number of examples are given as well as an exploration of the trade-offs between number of datapoints, number of functional predicates, precision of the data, and compute. This method provides a bottom-up approach that neatly complements the top-down Landau-bootstrap approach of trying to constrain the exact answer using the analytic structure alone. Although we focus on the application to Feynman integrals, the techniques presented here are more general and could apply to a wide range of problems where an exact answer is needed and the function space is sufficiently well understood.",
      "authors": [
        "Oscar Barrera",
        "Aur\\'elien Dersy",
        "Rabia Husain",
        "Matthew D. Schwartz",
        "Xiaoyuan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Theory (hep-th)",
        "Numerical Analysis (cs.NA)",
        "High Energy Physics - Phenomenology (hep-ph)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:00:02+00:00",
          "link": "https://arxiv.org/abs/2507.17815v1",
          "size": "769kb",
          "version": "v1"
        }
      ],
      "title": "Analytic Regression of Feynman Integrals from High-Precision Numerical Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17815",
        "HTML": "https://arxiv.org/html/2507.17815v1",
        "PDF": "https://arxiv.org/pdf/2507.17815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a method for analytic regression of Feynman integrals, focusing on physics data, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17845",
      "abstract": "Biomedical Foundation Models (FMs) are rapidly transforming AI-enabled healthcare research and entering clinical validation. However, their susceptibility to learning non-biological technical features -- including variations in surgical/endoscopic techniques, laboratory procedures, and scanner hardware -- poses risks for clinical deployment. We present the first systematic investigation of pathology FM robustness to non-biological features. Our work (i) introduces measures to quantify FM robustness, (ii) demonstrates the consequences of limited robustness, and (iii) proposes a framework for FM robustification to mitigate these issues. Specifically, we developed PathoROB, a robustness benchmark with three novel metrics, including the robustness index, and four datasets covering 28 biological classes from 34 medical centers. Our experiments reveal robustness deficits across all 20 evaluated FMs, and substantial robustness differences between them. We found that non-robust FM representations can cause major diagnostic downstream errors and clinical blunders that prevent safe clinical adoption. Using more robust FMs and post-hoc robustification considerably reduced (but did not yet eliminate) the risk of such errors. This work establishes that robustness evaluation is essential for validating pathology FMs before clinical adoption and demonstrates that future FM development must integrate robustness as a core design principle. PathoROB provides a blueprint for assessing robustness across biomedical domains, guiding FM improvement efforts towards more robust, representative, and clinically deployable AI systems that prioritize biological information over technical artifacts.",
      "authors": [
        "Jonah K\\\"omen",
        "Edwin D. de Jong",
        "Julius Hense",
        "Hannah Marienwald",
        "Jonas Dippel",
        "Philip Naumann",
        "Eric Marcus",
        "Lukas Ruff",
        "Maximilian Alber",
        "Jonas Teuwen",
        "Frederick Klauschen",
        "Klaus-Robert M\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T16:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.17845v1",
          "size": "31174kb",
          "version": "v1"
        }
      ],
      "title": "Towards Robust Foundation Models for Digital Pathology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17845",
        "PDF": "https://arxiv.org/pdf/2507.17845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates robustness in biomedical foundation models, concentrating on clinical applications rather than on LLM training data processing or dataset improvements for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17869",
      "abstract": "Nitrogen (N) is one of the most crucial nutrients in vineyards, affecting plant growth and subsequent products such as wine and juice. Because soil N has high spatial and temporal variability, it is desirable to accurately estimate the N concentration of grapevine leaves and manage fertilization at the individual plant level to optimally meet plant needs. In this study, we used in-field hyperspectral images with wavelengths ranging from $400 to 1000nm of four different grapevine cultivars collected from distinct vineyards and over two growth stages during two growing seasons to develop models for predicting N concentration at the leaf-level and canopy-level. After image processing, two feature selection methods were employed to identify the optimal set of spectral bands that were responsive to leaf N concentrations. The selected spectral bands were used to train and test two different Machine Learning (ML) models, Gradient Boosting and XGBoost, for predicting nitrogen concentrations. The comparison of selected bands for both leaf-level and canopy-level datasets showed that most of the spectral regions identified by the feature selection methods were across both methods and the dataset types (leaf- and canopy-level datasets), particularly in the key regions, 500-525nm, 650-690nm, 750-800nm, and 900-950nm. These findings indicated the robustness of these spectral regions for predicting nitrogen content. The results for N prediction demonstrated that the ML model achieved an R square of 0.49 for canopy-level data and an R square of 0.57 for leaf-level data, despite using different sets of selected spectral bands for each analysis level. The study demonstrated the potential of using in-field hyperspectral imaging and the use of spectral data in integrated feature selection and ML techniques to monitor N status in vineyards.",
      "authors": [
        "Atif Bilal Asad",
        "Achyut Paudel",
        "Safal Kshetri",
        "Chenchen Kang",
        "Salik Ram Khanal",
        "Nataliya Shcherbatyuk",
        "Pierre Davadant",
        "R. Paul Schreiner",
        "Santosh Kalauni",
        "Manoj Karkee",
        "Markus Keller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T18:53:23+00:00",
          "link": "https://arxiv.org/abs/2507.17869v1",
          "size": "717kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Feature Selection and Machine Learning for Nitrogen Assessment in Grapevine Leaves using In-Field Hyperspectral Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17869",
        "HTML": "https://arxiv.org/html/2507.17869v1",
        "PDF": "https://arxiv.org/pdf/2507.17869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study uses hyperspectral imaging and machine learning for nitrogen assessment in grapevine leaves, not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17881",
      "abstract": "Multipactor is a nonlinear electron avalanche phenomenon that can severely impair the performance of high-power radio frequency (RF) devices and accelerator systems. Accurate prediction of multipactor susceptibility across different materials and operational regimes remains a critical yet computationally intensive challenge in accelerator component design and RF engineering. This study presents the first application of supervised machine learning (ML) for predicting multipactor susceptibility in two-surface planar geometries. A simulation-derived dataset spanning six distinct secondary electron yield (SEY) material profiles is used to train regression models - including Random Forest (RF), Extra Trees (ET), Extreme Gradient Boosting (XGBoost), and funnel-structured Multilayer Perceptrons (MLPs) - to predict the time-averaged electron growth rate, ${\\delta}_{avg}$. Performance is evaluated using Intersection over Union (IoU), Structural Similarity Index (SSIM), and Pearson correlation coefficient. Tree-based models consistently outperform MLPs in generalizing across disjoint material domains. MLPs trained using a scalarized objective function that combines IoU and SSIM during Bayesian hyperparameter optimization with 5-fold cross-validation outperform those trained with single-objective loss functions. Principal Component Analysis reveals that performance degradation for certain materials stems from disjoint feature-space distributions, underscoring the need for broader dataset coverage. This study demonstrates both the promise and limitations of ML-based multipactor prediction and lays the groundwork for accelerated, data-driven modeling in advanced RF and accelerator system design.",
      "authors": [
        "Asif Iqbal",
        "John Verboncoeur",
        "and Peng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Accelerator Physics (physics.acc-ph)",
        "Machine Learning (cs.LG)",
        "Applied Physics (physics.app-ph)",
        "Plasma Physics (physics.plasm-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:14:46+00:00",
          "link": "https://arxiv.org/abs/2507.17881v1",
          "size": "4070kb",
          "version": "v1"
        }
      ],
      "title": "A Supervised Machine Learning Framework for Multipactor Breakdown Prediction in High-Power Radio Frequency Devices and Accelerator Components: A Case Study in Planar Geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17881",
        "PDF": "https://arxiv.org/pdf/2507.17881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study applies machine learning for predicting electron phenomena in RF devices and does not involve any aspect of LLM training data processing, nor does it create or enhance datasets for such purposes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17897",
      "abstract": "Accurately predicting distributed cortical responses to naturalistic stimuli requires models that integrate visual, auditory and semantic information over time. We present a hierarchical multimodal recurrent ensemble that maps pretrained video, audio, and language embeddings to fMRI time series recorded while four subjects watched almost 80 hours of movies provided by the Algonauts 2025 challenge. Modality-specific bidirectional RNNs encode temporal dynamics; their hidden states are fused and passed to a second recurrent layer, and lightweight subject-specific heads output responses for 1000 cortical parcels. Training relies on a composite MSE-correlation loss and a curriculum that gradually shifts emphasis from early sensory to late association regions. Averaging 100 model variants further boosts robustness. The resulting system ranked third on the competition leaderboard, achieving an overall Pearson r = 0.2094 and the highest single-parcel peak score (mean r = 0.63) among all participants, with particularly strong gains for the most challenging subject (Subject 5). The approach establishes a simple, extensible baseline for future multimodal brain-encoding benchmarks.",
      "authors": [
        "Semih Eren and Deniz Kucukahmetler and Nico Scherf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T19:48:27+00:00",
          "link": "https://arxiv.org/abs/2507.17897v1",
          "size": "1026kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17897",
        "HTML": "https://arxiv.org/html/2507.17897v1",
        "PDF": "https://arxiv.org/pdf/2507.17897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research discusses a multimodal recurrent ensemble for predicting brain responses, relying on pretrained video, audio, and language embeddings. It does not address training data processing related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17911",
      "abstract": "Pseudo-healthy image inpainting is an essential preprocessing step for analyzing pathological brain MRI scans. Most current inpainting methods favor slice-wise 2D models for their high in-plane fidelity, but their independence across slices produces discontinuities in the volume. Fully 3D models alleviate this issue, but their high model capacity demands extensive training data for reliable, high-fidelity synthesis -- often impractical in medical settings. We address these limitations with a hierarchical diffusion framework by replacing direct 3D modeling with two perpendicular coarse-to-fine 2D stages. An axial diffusion model first yields a coarse, globally consistent inpainting; a coronal diffusion model then refines anatomical details. By combining perpendicular spatial views with adaptive resampling, our method balances data efficiency and volumetric consistency. Our experiments show our approach outperforms state-of-the-art baselines in both realism and volumetric consistency, making it a promising solution for pseudo-healthy image inpainting. Code is available at https://github.com/dou0000/3dMRI-Consistent-Inpaint.",
      "authors": [
        "Dou Hoon Kwark",
        "Shirui Luo",
        "Xiyue Zhu",
        "Yudu Li",
        "Zhi-Pei Liang",
        "Volodymyr Kindratenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:21:29+00:00",
          "link": "https://arxiv.org/abs/2507.17911v1",
          "size": "1070kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Diffusion Framework for Pseudo-Healthy Brain MRI Inpainting with Enhanced 3D Consistency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17911",
        "HTML": "https://arxiv.org/html/2507.17911v1",
        "PDF": "https://arxiv.org/pdf/2507.17911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a hierarchical diffusion framework for inpainting brain MRIs, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17913",
      "abstract": "Let $\\mathcal T_n$ denote the set of all labelled spanning trees of $K_n$. A family $\\mathcal F \\subset \\mathcal T_n$ is $t$-intersecting if for all $A, B \\in \\mathcal F$ the trees $A$ and $B$ share at least $t$ edges. In this paper, we determine for $n>n_0$ the size of the largest $t$-intersecting family $\\mathcal F\\subset \\mathcal T_n$ for all meaningful values of $t$ ($t\\le n-1$). This result is a rare instance when a complete $t$-intersection theorem for a given type of structures is known.",
      "authors": [
        "Elizaveta Iarovikova",
        "Andrey Kupavskii"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:23:34+00:00",
          "link": "https://arxiv.org/abs/2507.17913v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "A complete $t$-intersection theorem for families of spanning trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17913",
        "HTML": "https://arxiv.org/html/2507.17913v1",
        "PDF": "https://arxiv.org/pdf/2507.17913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with combinatorial structures in spanning trees, specifically a $t$-intersection theorem, and is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17921",
      "abstract": "Canonical correlation analysis (CCA) is a technique for finding correlated sets of features between two datasets. In this paper, we propose a novel extension of CCA to the online, streaming data setting: Sliding Window Informative Canonical Correlation Analysis (SWICCA). Our method uses a streaming principal component analysis (PCA) algorithm as a backend and uses these outputs combined with a small sliding window of samples to estimate the CCA components in real time. We motivate and describe our algorithm, provide numerical simulations to characterize its performance, and provide a theoretical performance guarantee. The SWICCA method is applicable and scalable to extremely high dimensions, and we provide a real-data example that demonstrates this capability.",
      "authors": [
        "Arvind Prasadan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)",
        "Statistics Theory (math.ST)",
        "Computation (stat.CO)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T20:35:15+00:00",
          "link": "https://arxiv.org/abs/2507.17921v1",
          "size": "4831kb",
          "version": "v1"
        }
      ],
      "title": "Sliding Window Informative Canonical Correlation Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17921",
        "HTML": "https://arxiv.org/html/2507.17921v1",
        "PDF": "https://arxiv.org/pdf/2507.17921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research proposes an extension of Canonical Correlation Analysis for streaming data. It is not related to the processing of training data for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17931",
      "abstract": "This article introduces an innovative interactive visualization tool designed to demystify quantum machine learning (QML) algorithms. Our work is inspired by the success of classical machine learning visualization tools, such as TensorFlow Playground, and aims to bridge the gap in visualization resources specifically for the field of QML. The article includes a comprehensive overview of relevant visualization metaphors from both quantum computing and classical machine learning, the development of an algorithm visualization concept, and the design of a concrete implementation as an interactive web application. By combining common visualization metaphors for the so-called data re-uploading universal quantum classifier as a representative QML model, this article aims to lower the entry barrier to quantum computing and encourage further innovation in the field. The accompanying interactive application is a proposal for the first version of a quantum machine learning playground for learning and exploring QML models.",
      "authors": [
        "Pascal Debus",
        "Sebastian Issel",
        "Kilian Tscharke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T21:08:29+00:00",
          "link": "https://arxiv.org/abs/2507.17931v1",
          "size": "8406kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Machine Learning Playground",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17931",
        "HTML": "https://arxiv.org/html/2507.17931v1",
        "PDF": "https://arxiv.org/pdf/2507.17931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a visualization tool for quantum machine learning algorithms, unrelated to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17971",
      "abstract": "Recent advances in deep learning have led to robust automated tools for segmentation of abdominal computed tomography (CT). Meanwhile, segmentation of magnetic resonance imaging (MRI) is substantially more challenging due to the inherent signal variability and the increased effort required for annotating training datasets. Hence, existing approaches are trained on limited sets of MRI sequences, which might limit their generalizability. To characterize the landscape of MRI abdominal segmentation tools, we present here a comprehensive benchmarking of the three state-of-the-art and open-source models: MRSegmentator, MRISegmentator-Abdomen, and TotalSegmentator MRI. Since these models are trained using labor-intensive manual annotation cycles, we also introduce and evaluate ABDSynth, a SynthSeg-based model purely trained on widely available CT segmentations (no real images). More generally, we assess accuracy and generalizability by leveraging three public datasets (not seen by any of the evaluated methods during their training), which span all major manufacturers, five MRI sequences, as well as a variety of subject conditions, voxel resolutions, and fields-of-view. Our results reveal that MRSegmentator achieves the best performance and is most generalizable. In contrast, ABDSynth yields slightly less accurate results, but its relaxed requirements in training data make it an alternative when the annotation budget is limited. The evaluation code and datasets are given for future benchmarking at https://github.com/deepakri201/AbdoBench, along with inference code and weights for ABDSynth.",
      "authors": [
        "Deepa Krishnaswamy",
        "Cosmin Ciausu",
        "Steve Pieper",
        "Ron Kikinis",
        "Benjamin Billot",
        "Andrey Fedorov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T22:37:26+00:00",
          "link": "https://arxiv.org/abs/2507.17971v1",
          "size": "15131kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking of Deep Learning Methods for Generic MRI Multi-OrganAbdominal Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17971",
        "HTML": "https://arxiv.org/html/2507.17971v1",
        "PDF": "https://arxiv.org/pdf/2507.17971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking deep learning methods for MRI multi-organ segmentation, which is unrelated to LLM training data processing. It does not address any aspects of data processing relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17980",
      "abstract": "Currently, identification of crystallization pathways in polymers is being carried out using molecular simulation-based data on a preset cut-off point on a single order parameter (OP) to define nucleated or crystallized regions. Aside from sensitivity to cut-off, each of these OPs introduces its own systematic biases. In this study, an integrated machine learning workflow is presented to accurately quantify crystallinity in polymeric systems using atomistic molecular dynamics data. Each atom is represented by a high-dimensional feature vector that combines geometric, thermodynamic-like, and symmetry-based descriptors. Low dimensional embeddings are employed to expose latent structural fingerprints within atomic environments. Subsequently, unsupervised clustering on the embeddings identified crystalline and amorphous atoms with high fidelity. After generating high quality labels with multidimensional data, we use supervised learning techniques to identify a minimal set of order parameters that can fully capture this label. Various tests were conducted to reduce the feature set, demonstrating that using only three order parameters is sufficient to recreate the crystallization labels. Based on these observed OPs, the crystallinity index (C-index) is defined as the logistic regression model's probability of crystallinity, remaining bimodal throughout the process and achieving over 0.98 classification performance (AUC). Notably, a model trained on one or a few snapshots enables efficient on-the-fly computation of crystallinity. Lastly, we demonstrate how the optimal C-index fit evolves during various stages of crystallization, supporting the hypothesis that entropy dominates early nucleation, while symmetry gains relevance later. This workflow provides a data-driven strategy for OP selection and a metric to monitor structural transformations in large-scale polymer simulations.",
      "authors": [
        "Elyar Tourani",
        "Brian J. Edwards",
        "Bamin Khomami"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T23:02:10+00:00",
          "link": "https://arxiv.org/abs/2507.17980v1",
          "size": "18364kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning Workflow for Analysis of High-Dimensional Order Parameter Space: A Case Study of Polymer Crystallization from Molecular Dynamics Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17980",
        "HTML": "https://arxiv.org/html/2507.17980v1",
        "PDF": "https://arxiv.org/pdf/2507.17980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a machine learning workflow for analyzing polymer crystallization in molecular dynamics simulations. It does not relate to LLM training data processing but instead focuses on enhancing material science simulations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17994",
      "abstract": "Chromatic metric pairs consist of a metric space and a coloring function partitioning a subset thereof into various colors. It is a natural extension of the notion of chromatic point sets studied in chromatic topological data analysis. A useful tool in the field is the six-pack, a collection of six persistence diagrams, summarizing homological information about how the colored subsets interact. We introduce a suitable generalization of the Gromov-Hausdorff distance to compare chromatic metric pairs. We show some basic properties and validate this definition by obtaining the stability of the six-pack with respect to that distance. We conclude by discussing its restriction to metric pairs and its role in the stability of the \\v{C}ech persistence diagrams.",
      "authors": [
        "Ond\\v{r}ej Draganov",
        "Sophie Rosenmeier",
        "Nicol\\`o Zava"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Metric Geometry (math.MG)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T00:02:29+00:00",
          "link": "https://arxiv.org/abs/2507.17994v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "Gromov-Hausdorff distance between chromatic metric pairs and stability of the six-pack",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17994",
        "PDF": "https://arxiv.org/pdf/2507.17994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with mathematical concepts in chromatic metric pairs and topological data analysis, unrelated to LLM training data processing. It does not address any data processing for training or fine-tuning language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18012",
      "abstract": "Dual-energy X-ray Computed Tomography (DECT) constitutes an advanced technology which enables automatic decomposition of materials in clinical images without manual segmentation using the dependency of the X-ray linear attenuation with energy. However, most methods perform material decomposition in the image domain as a post-processing step after reconstruction but this procedure does not account for the beam-hardening effect and it results in sub-optimal results. In this work, we propose a deep learning procedure called Dual-Energy Decomposition Model-based Diffusion (DEcomp-MoD) for quantitative material decomposition which directly converts the DECT projection data into material images. The algorithm is based on incorporating the knowledge of the spectral DECT model into the deep learning training loss and combining a score-based denoising diffusion learned prior in the material image domain. Importantly the inference optimization loss takes as inputs directly the sinogram and converts to material images through a model-based conditional diffusion model which guarantees consistency of the results. We evaluate the performance with both quantitative and qualitative estimation of the proposed DEcomp-MoD method on synthetic DECT sinograms from the low-dose AAPM dataset. Finally, we show that DEcomp-MoD outperform state-of-the-art unsupervised score-based model and supervised deep learning networks, with the potential to be deployed for clinical diagnosis.",
      "authors": [
        "Hang Xu",
        "Alexandre Bousse",
        "Alessandro Perelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:00:06+00:00",
          "link": "https://arxiv.org/abs/2507.18012v1",
          "size": "5513kb",
          "version": "v1"
        }
      ],
      "title": "Direct Dual-Energy CT Material Decomposition using Model-based Denoising Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18012",
        "HTML": "https://arxiv.org/html/2507.18012v1",
        "PDF": "https://arxiv.org/pdf/2507.18012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a model for material decomposition using CT data, with no relation to LLM training data processing, as it is situated entirely within the domain of medical imaging techniques and applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18021",
      "abstract": "We study the zeroth-order query complexity of log-concave sampling, specifically uniform sampling from convex bodies using membership oracles. We propose a simple variant of the proximal sampler that achieves the query complexity with matched R\\'enyi orders between the initial warmness and output guarantee. Specifically, for any $\\varepsilon>0$ and $q\\geq2$, the sampler, initialized at $\\pi_{0}$, outputs a sample whose law is $\\varepsilon$-close in $q$-R\\'enyi divergence to $\\pi$, the uniform distribution over a convex body in $\\mathbb{R}^{d}$, using $\\widetilde{O}(qM_{q}^{q/(q-1)}d^{2}\\,\\lVert\\operatorname{cov}\\pi\\rVert\\log\\frac{1}{\\varepsilon})$ membership queries, where $M_{q}=\\lVert\\text{d}\\pi_{0}/\\text{d}\\pi\\rVert_{L^{q}(\\pi)}$.\n  We further introduce a simple annealing scheme that produces a warm start in $q$-R\\'enyi divergence (i.e., $M_{q}=O(1)$) using $\\widetilde{O}(qd^{2}R^{3/2}\\,\\lVert\\operatorname{cov}\\pi\\rVert^{1/4})$ queries, where $R^{2}=\\mathbb{E}_{\\pi}[|\\cdot|^{2}]$. This interpolates between known complexities for warm-start generation in total variation and R\\'enyi-infinity divergence. To relay a R\\'enyi warmness across the annealing scheme, we establish hypercontractivity under simultaneous heat flow and translate it into an improved mixing guarantee for the proximal sampler under a logarithmic Sobolev inequality. These results extend naturally to general log-concave distributions accessible via evaluation oracles, incurring additional quadratic queries.",
      "authors": [
        "Yunbum Kook"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)",
        "Functional Analysis (math.FA)",
        "Probability (math.PR)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T01:31:49+00:00",
          "link": "https://arxiv.org/abs/2507.18021v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "Zeroth-order log-concave sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18021",
        "HTML": "https://arxiv.org/html/2507.18021v1",
        "PDF": "https://arxiv.org/pdf/2507.18021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the problem of log-concave sampling and query complexity, which pertains to optimization and sampling from convex bodies, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18030",
      "abstract": "Large-scale networked systems typically operate under resource constraints, and it is also difficult to exactly obtain the network structure between nodes. To address these issues, this paper investigates a sparse optimal control for infinite-dimensional linear systems and its application to networked systems where the network structure is represented by a limit function called a graphon that captures the overall connection pattern. The contributions of this paper are twofold: (i) To reduce computational complexity, we derive a sufficient condition under which the sparse optimal control can be obtained by solving its corresponding L1 optimization problem. Furthermore, we introduce a class of non-convex optimal control problems such that the optimal solution always coincides with a sparse optimal control, provided that the non-convex problems admit optimal solutions. (ii) We show that the sparse optimal control for large-scale finite-dimensional networked systems can be approximated by that of the corresponding limit graphon system, provided that the underlying graph is close to the limit graphon in the cut-norm topology. The effectiveness of the proposed approach is illustrated through numerical examples.",
      "authors": [
        "Takuya Ikeda",
        "Masaaki Nagahara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T02:04:54+00:00",
          "link": "https://arxiv.org/abs/2507.18030v1",
          "size": "900kb",
          "version": "v1"
        }
      ],
      "title": "Sparse optimal control for infinite-dimensional linear systems with applications to graphon control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18030",
        "HTML": "https://arxiv.org/html/2507.18030v1",
        "PDF": "https://arxiv.org/pdf/2507.18030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with sparse optimal control for infinite-dimensional linear systems, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18083",
      "abstract": "The process of bar formation, evolution and destruction is still a controversial topic regarding galaxy dynamics. Numerical simulations show that these phenomena strongly depend on physical and numerical parameters. In this work, we study the combined influence of the softening parameter, $\\epsilon$ and disc mass fraction, $m_{\\mathrm{d}}$ on the formation and evolution of bars in isolated disc-halo models via $N$-body simulations with different particle resolutions. Previous studies indicate that the bar strength depends on $m_{\\mathrm{d}}$ as $\\propto m_{\\mathrm{d}}^{-1}$, which is seen as a delay in bar formation. However, the distorsion parameter, $\\eta$, which measures the bar's momentum through time, shows that an increase in $m_{\\mathrm{d}}$ does not always induce a delay in bar formation. This suggests that $\\epsilon$ interact to either enhance or weaken the bar. Moreover, numerical heating dominates in models with small softening values, creating highly accelerated particles at the centre of discs, regardless of $m_{\\mathrm{d}}$ or resolution. These enhanced particle accelerations produce chaotic orbits for $\\epsilon \\leq 5\\,$pc, resulting in bar suppression due to collisional dynamics in the centre. In our high resolution models ($N \\approx 10^{7}$), small softening values are incapable of reproducing the bar instability. The role of disc mass is as follows: increasing $m_{\\mathrm{d}}$ for moderate $\\epsilon$ ($\\geq 10\\,$pc) reduces the amount of drift in the acceleration profile, without affecting the bar's behaviour. Models with lower $m_{\\mathrm{d}}$ values coupled with small softening values, have an excess of highly accelerated particles, introducing unwanted effects into otherwise reliable simulations. Finally, we show that the evolution of the disc's vertical acceleration profile is a reliable indicator of numerical heating introduced by $\\epsilon$ and the bar.",
      "authors": [
        "Alejandro L\\'opez G\\'omez",
        "Ruslan Gabbasov and Isaura Luisa Fuentes-Carrera"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Astrophysics of Galaxies (astro-ph.GA)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T04:27:50+00:00",
          "link": "https://arxiv.org/abs/2507.18083v1",
          "size": "3236kb",
          "version": "v1"
        }
      ],
      "title": "Numerical Study of Bar Suppression in Galaxy Models Due to Disc Heating",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18083",
        "PDF": "https://arxiv.org/pdf/2507.18083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses galaxy dynamics and bar formation in galaxies using numerical simulations. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18112",
      "abstract": "We address the challenge of parameter-efficient fine-tuning (PEFT) for three-dimensional (3D) U-Net-based denoising diffusion probabilistic models (DDPMs) in magnetic resonance imaging (MRI) image generation. Despite its practical significance, research on parameter-efficient representations of 3D convolution operations remains limited. To bridge this gap, we propose Tensor Volumetric Operator (TenVOO), a novel PEFT method specifically designed for fine-tuning DDPMs with 3D convolutional backbones. Leveraging tensor network modeling, TenVOO represents 3D convolution kernels with lower-dimensional tensors, effectively capturing complex spatial dependencies during fine-tuning with few parameters. We evaluate TenVOO on three downstream brain MRI datasets-ADNI, PPMI, and BraTS2021-by fine-tuning a DDPM pretrained on 59,830 T1-weighted brain MRI scans from the UK Biobank. Our results demonstrate that TenVOO achieves state-of-the-art performance in multi-scale structural similarity index measure (MS-SSIM), outperforming existing approaches in capturing spatial dependencies while requiring only 0.3% of the trainable parameters of the original model. Our code is available at: https://github.com/xiaovhua/tenvoo",
      "authors": [
        "Binghua Li",
        "Ziqing Chang",
        "Tong Liang",
        "Chao Li",
        "Toshihisa Tanaka",
        "Shigeki Aoki",
        "Qibin Zhao",
        "Zhe Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:51:51+00:00",
          "link": "https://arxiv.org/abs/2507.18112v1",
          "size": "506kb",
          "version": "v1"
        }
      ],
      "title": "Parameter-Efficient Fine-Tuning of 3D DDPM for MRI Image Generation Using Tensor Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18112",
        "HTML": "https://arxiv.org/html/2507.18112v1",
        "PDF": "https://arxiv.org/pdf/2507.18112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses parameter-efficient fine-tuning techniques for 3D MRI image generation, which may indirectly inform fine-tuning strategies in other domains, but it doesn't address data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18114",
      "abstract": "This paper develops a unified nonconvex optimization framework for the design of group-sparse feedback controllers in infinite-horizon linear-quadratic (LQ) problems. We address two prominent extensions of the classical LQ problem: the distributed LQ problem with fixed communication topology (DFT-LQ) and the sparse feedback LQ problem (SF-LQ), both of which are motivated by the need for scalable and structure-aware control in large-scale systems. Unlike existing approaches that rely on convex relaxations or are limited to block-diagonal structures, we directly formulate the controller synthesis as a finite-dimensional nonconvex optimization problem with group $\\ell_0$-norm regularization, capturing general sparsity patterns. We establish a connection between DFT-LQ and SF-LQ problems, showing that both can be addressed within our unified framework. Furthermore, we propose a penalty-based proximal alternating linearized minimization (PALM) algorithm and provide a rigorous convergence analysis under mild assumptions, overcoming the lack of coercivity in the objective function. The proposed method admits efficient solvers for all subproblems and guarantees global convergence to critical points. Our results fill a key gap in the literature by enabling the direct design of group-sparse feedback gains with theoretical guarantees, without resorting to convex surrogates or restrictive structural assumptions.",
      "authors": [
        "Lechen Feng",
        "Xun Li",
        "Yuan-Hua Ni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T05:55:28+00:00",
          "link": "https://arxiv.org/abs/2507.18114v1",
          "size": "132kb",
          "version": "v1"
        }
      ],
      "title": "Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control I: Penalty Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18114",
        "HTML": "https://arxiv.org/html/2507.18114v1",
        "PDF": "https://arxiv.org/pdf/2507.18114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is centered around nonconvex optimization for feedback control systems, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18118",
      "abstract": "A/B testing is widely used in modern technology companies for policy evaluation and product deployment, with the goal of comparing the outcomes under a newly-developed policy against a standard control. Various causal inference and reinforcement learning methods developed in the literature are applicable to A/B testing. This paper introduces a two-armed bandit framework designed to improve the power of existing approaches. The proposed procedure consists of three main steps: (i) employing doubly robust estimation to generate pseudo-outcomes, (ii) utilizing a two-armed bandit framework to construct the test statistic, and (iii) applying a permutation-based method to compute the $p$-value. We demonstrate the efficacy of the proposed method through asymptotic theories, numerical experiments and real-world data from a ridesharing company, showing its superior performance in comparison to existing methods.",
      "authors": [
        "Jinjuan Wang",
        "Qianglin Wen",
        "Yu Zhang",
        "Xiaodong Yan",
        "Chengchun Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:05:56+00:00",
          "link": "https://arxiv.org/abs/2507.18118v1",
          "size": "2137kb",
          "version": "v1"
        }
      ],
      "title": "A Two-armed Bandit Framework for A/B Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18118",
        "HTML": "https://arxiv.org/html/2507.18118v1",
        "PDF": "https://arxiv.org/pdf/2507.18118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a two-armed bandit framework for improving A/B testing methodologies, not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18126",
      "abstract": "This paper introduces a novel approach to synthesize healthy 3D brain tissue from masked input images, specifically focusing on the task of 'ASNR-MICCAI BraTS Local Synthesis of Tissue via Inpainting'. Our proposed method employs a U-Net-based architecture, which is designed to effectively reconstruct the missing or corrupted regions of brain MRI scans. To enhance our model's generalization capabilities and robustness, we implement a comprehensive data augmentation strategy that involves randomly masking healthy images during training. Our model is trained on the BraTS-Local-Inpainting dataset and demonstrates the exceptional performance in recovering healthy brain tissue. The evaluation metrics employed, including Structural Similarity Index (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Mean Squared Error (MSE), consistently yields impressive results. On the BraTS-Local-Inpainting validation set, our model achieved an SSIM score of 0.841, a PSNR score of 23.257, and an MSE score of 0.007. Notably, these evaluation metrics exhibit relatively low standard deviations, i.e., 0.103 for SSIM score, 4.213 for PSNR score and 0.007 for MSE score, which indicates that our model's reliability and consistency across various input scenarios. Our method also secured first place in the challenge.",
      "authors": [
        "Juexin Zhang",
        "Ying Weng",
        "Ke Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:26:46+00:00",
          "link": "https://arxiv.org/abs/2507.18126v1",
          "size": "873kb",
          "version": "v1"
        }
      ],
      "title": "U-Net Based Healthy 3D Brain Tissue Inpainting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18126",
        "HTML": "https://arxiv.org/html/2507.18126v1",
        "PDF": "https://arxiv.org/pdf/2507.18126"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a U-Net-based approach for 3D brain tissue inpainting, focusing on medical image processing, unassociated with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18133",
      "abstract": "Glioblastoma, a highly aggressive brain tumor with diverse molecular and pathological features, poses a diagnostic challenge due to its heterogeneity. Accurate diagnosis and assessment of this heterogeneity are essential for choosing the right treatment and improving patient outcomes. Traditional methods rely on identifying specific features in tissue samples, but deep learning offers a promising approach for improved glioblastoma diagnosis. In this paper, we present our approach to the BraTS-Path Challenge 2024. We leverage a pre-trained model and fine-tune it on the BraTS-Path training dataset. Our model demonstrates poor performance on the challenging BraTS-Path validation set, as rigorously assessed by the Synapse online platform. The model achieves an accuracy of 0.392229, a recall of 0.392229, and a F1-score of 0.392229, indicating a consistent ability to correctly identify instances under the target condition. Notably, our model exhibits perfect specificity of 0.898704, showing an exceptional capacity to correctly classify negative cases. Moreover, a Matthews Correlation Coefficient (MCC) of 0.255267 is calculated, to signify a limited positive correlation between predicted and actual values and highlight our model's overall predictive power. Our solution also achieves the second place during the testing phase.",
      "authors": [
        "Juexin Zhang",
        "Ying Weng",
        "Ke Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T06:47:23+00:00",
          "link": "https://arxiv.org/abs/2507.18133v1",
          "size": "4101kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning for Glioblastoma Morpho-pathological Features Identification: A BraTS-Pathology Challenge Solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18133",
        "HTML": "https://arxiv.org/html/2507.18133v1",
        "PDF": "https://arxiv.org/pdf/2507.18133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on applying deep learning for glioblastoma feature identification and does not contribute to LLM training data processing or related data engineering processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18161",
      "abstract": "The CHiME-7 and 8 distant speech recognition (DASR) challenges focus on multi-channel, generalizable, joint automatic speech recognition (ASR) and diarization of conversational speech. With participation from 9 teams submitting 32 diverse systems, these challenges have contributed to state-of-the-art research in the field. This paper outlines the challenges' design, evaluation metrics, datasets, and baseline systems while analyzing key trends from participant submissions. From this analysis it emerges that: 1) Most participants use end-to-end (e2e) ASR systems, whereas hybrid systems were prevalent in previous CHiME challenges. This transition is mainly due to the availability of robust large-scale pre-trained models, which lowers the data burden for e2e-ASR. 2) Despite recent advances in neural speech separation and enhancement (SSE), all teams still heavily rely on guided source separation, suggesting that current neural SSE techniques are still unable to reliably deal with complex scenarios and different recording setups. 3) All best systems employ diarization refinement via target-speaker diarization techniques. Accurate speaker counting in the first diarization pass is thus crucial to avoid compounding errors and CHiME-8 DASR participants especially focused on this part. 4) Downstream evaluation via meeting summarization can correlate weakly with transcription quality due to the remarkable effectiveness of large-language models in handling errors. On the NOTSOFAR-1 scenario, even systems with over 50\\% time-constrained minimum permutation WER can perform roughly on par with the most effective ones (around 11\\%). 5) Despite recent progress, accurately transcribing spontaneous speech in challenging acoustic environments remains difficult, even when using computationally intensive system ensembles.",
      "authors": [
        "Samuele Cornell and Christoph Boeddeker and Taejin Park and He Huang and Desh Raj and Matthew Wiesner and Yoshiki Masuyama and Xuankai Chang and Zhong-Qiu Wang and Stefano Squartini and Paola Garcia and Shinji Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T07:56:24+00:00",
          "link": "https://arxiv.org/abs/2507.18161v1",
          "size": "1446kb",
          "version": "v1"
        }
      ],
      "title": "Recent Trends in Distant Conversational Speech Recognition: A Review of CHiME-7 and 8 DASR Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18161",
        "PDF": "https://arxiv.org/pdf/2507.18161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews trends in distant conversational speech recognition challenges, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18166",
      "abstract": "Modern positioning relies on radio signals from global navigation satellite systems (GNSS). Their low receive power renders these radio signals susceptible to jamming attacks, in which malicious transmitters emit strong interference to disrupt signal acquisition. Moreover, GNSS are vulnerable to spoofing attacks, in which malicious transmitters mimic legitimate satellites by transmitting spurious GNSS signals. We propose SCHIEBER, a novel method for multi-antenna GNSS receivers that mitigates jammers as well as spoofers without requiring any prior knowledge of the receiver position or attack type: Jammers are mitigated during signal acquisition using a recently developed adaptive spatial filtering technique. Spoofers are identified and rejected after signal acquisition using a novel approach that tests the consistency of acquired signals by comparing their respective direction of arrival (DoA) and pseudorange estimates in a test that is invariant with respect to the unknown receiver position. We demonstrate the efficacy of our method using extensive simulations of a GPS L1 C/A system under spoofing and jamming attacks.",
      "authors": [
        "Jonas Elmiger and Gian Marti and Christoph Studer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:04:26+00:00",
          "link": "https://arxiv.org/abs/2507.18166v1",
          "size": "2202kb",
          "version": "v1"
        }
      ],
      "title": "GNSS Jammer and Spoofer Mitigation via Multi-Antenna Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18166",
        "HTML": "https://arxiv.org/html/2507.18166v1",
        "PDF": "https://arxiv.org/pdf/2507.18166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses methods for mitigating GNSS jammer and spoofer attacks through multi-antenna processing. It has no connection to LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18181",
      "abstract": "Large language model (LLM)-based automatic speech recognition (ASR) has recently attracted a lot of attention due to its high recognition accuracy and enhanced multi-dialect support. However, the high decoding latency of LLMs challenges the real-time ASR requirements. Although speculative decoding has been explored for better decoding efficiency, they usually ignore the key characteristics of the ASR task and achieve limited speedup. To further reduce the real-time ASR latency, in this paper, we propose a novel speculative decoding framework specialized for ASR, dubbed SpecASR. SpecASR is developed based on our core observation that ASR decoding is audio-conditioned, which results in high output alignment between small and large ASR models, even given output mismatches in intermediate decoding steps. Therefore, SpecASR features an adaptive draft sequence generation process that dynamically modifies the draft sequence length to maximize the token acceptance length. SpecASR further proposes a draft sequence recycling strategy that reuses the previously generated draft sequence to reduce the draft ASR model latency. Moreover, a two-pass sparse token tree generation algorithm is also proposed to balance the latency of draft and target ASR models. With extensive experimental results, we demonstrate SpecASR achieves 3.04x-3.79x and 1.25x-1.84x speedup over the baseline autoregressive decoding and speculative decoding, respectively, without any loss in recognition accuracy.",
      "authors": [
        "Linye Wei",
        "Shuzhang Zhong",
        "Songqiang Xu",
        "Runsheng Wang",
        "Ru Huang and Meng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T08:27:53+00:00",
          "link": "https://arxiv.org/abs/2507.18181v1",
          "size": "3359kb",
          "version": "v1"
        }
      ],
      "title": "SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18181",
        "HTML": "https://arxiv.org/html/2507.18181v1",
        "PDF": "https://arxiv.org/pdf/2507.18181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on speculative decoding frameworks for enhancing the decoding speed of LLM-based automatic speech recognition systems, which does not pertain to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18210",
      "abstract": "As one of the major challenges for the conservative smoothed particle hydrodynamics (SPH) method, the zero-order consistency issue, although thought to be mitigated by the particle regularization scheme, such as the transport velocity formulation, significantly damps the flow in a long channel for both laminar and turbulent simulations. Building on this finding, this paper not only thoroughly analyzes the damping reason in this pressure-driven channel flow, but also relates this problem with the excessive numerical dissipation in the gravity-driven free-surface flow. The common root cause of the non-physical numerical damping in the two typical flow scenarios, the zero-order gradient consistency residue, is exposed. The adverse influence of the background pressure on the residue for the two scenarios is revealed and discussed. To comprehensively understand the behavior of the residue and mitigate its potential adverse effects, we conduct both theoretical analysis and numerical experiments focusing on the key sensitive factors. For studying the residue-induced non-physical energy dissipation in the gravity-driven free-surface flow, the water depth and input dynamic pressure in the inviscid standing wave case are tested. To investigate the velocity loss in the pressure-driven channel flow, we examine the effects of the channel length, resolution, and outlet pressure. The state-of-the-art reverse kernel gradient correction technique is introduced for the two typical flows, and proved to be effective in reducing the residue effect, but we find its correction capability is fundamentally limited. Finally, the FDA nozzle, an engineering benchmark, is tested to demonstrate the residue influence in a complex geometry, highlighting the necessity of correction schemes in scenarios with unavoidable high background pressure.",
      "authors": [
        "Feng Wang and Xiangyu Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:05:03+00:00",
          "link": "https://arxiv.org/abs/2507.18210v1",
          "size": "4108kb",
          "version": "v1"
        }
      ],
      "title": "On zero-order consistency residue and background pressure for the conservative SPH fluid dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18210",
        "HTML": "https://arxiv.org/html/2507.18210v1",
        "PDF": "https://arxiv.org/pdf/2507.18210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses challenges in smoothed particle hydrodynamics (SPH) fluid dynamics, specifically numerical damping issues, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18229",
      "abstract": "The application of Reinforcement Learning (RL) to economic modeling reveals a fundamental conflict between the assumptions of equilibrium theory and the emergent behavior of learning agents. While canonical economic models assume atomistic agents act as `takers' of aggregate market conditions, a naive single-agent RL simulation incentivizes the agent to become a `manipulator' of its environment. This paper first demonstrates this discrepancy within a search-and-matching model with concave production, showing that a standard RL agent learns a non-equilibrium, monopsonistic policy. Additionally, we identify a parametric bias arising from the mismatch between economic discounting and RL's treatment of intertemporal costs. To address both issues, we propose a calibrated Mean-Field Reinforcement Learning framework that embeds a representative agent in a fixed macroeconomic field and adjusts the cost function to reflect economic opportunity costs. Our iterative algorithm converges to a self-consistent fixed point where the agent's policy aligns with the competitive equilibrium. This approach provides a tractable and theoretically sound methodology for modeling learning agents in economic systems within the broader domain of computational social science.",
      "authors": [
        "Zeqiang Zhang",
        "Ruxin Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Artificial Intelligence (cs.AI)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T09:21:02+00:00",
          "link": "https://arxiv.org/abs/2507.18229v1",
          "size": "1575kb",
          "version": "v1"
        }
      ],
      "title": "From Individual Learning to Market Equilibrium: Correcting Structural and Parametric Biases in RL Simulations of Economic Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18229",
        "HTML": "https://arxiv.org/html/2507.18229v1",
        "PDF": "https://arxiv.org/pdf/2507.18229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using reinforcement learning in economic models and addresses structural and parametric biases in RL simulations. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18288",
      "abstract": "Traditional Chinese medicine (TCM) tongue diagnosis, while clinically valuable, faces standardization challenges due to subjective interpretation and inconsistent imaging protocols, compounded by the lack of large-scale, annotated datasets for AI development. To address this gap, we present the first specialized dataset for AI-driven TCM tongue diagnosis, comprising 6,719 high-quality images captured under standardized conditions and annotated with 20 pathological symptom categories (averaging 2.54 clinically validated labels per image, all verified by licensed TCM practitioners). The dataset supports multiple annotation formats (COCO, TXT, XML) for broad usability and has been benchmarked using nine deep learning models (YOLOv5/v7/v8 variants, SSD, and MobileNetV2) to demonstrate its utility for AI development. This resource provides a critical foundation for advancing reliable computational tools in TCM, bridging the data shortage that has hindered progress in the field, and facilitating the integration of AI into both research and clinical practice through standardized, high-quality diagnostic data.",
      "authors": [
        "Xuebo Jin",
        "Longfei Gao",
        "Anshuo Tong",
        "Zhengyang Chen",
        "Jianlei Kong",
        "Ning Sun",
        "Huijun Ma",
        "Qiang Wang",
        "Yuting Bai",
        "Tingli Su"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T10:49:31+00:00",
          "link": "https://arxiv.org/abs/2507.18288v1",
          "size": "14920kb",
          "version": "v1"
        }
      ],
      "title": "TCM-Tongue: A Standardized Tongue Image Dataset with Pathological Annotations for AI-Assisted TCM Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18288",
        "PDF": "https://arxiv.org/pdf/2507.18288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper describes the creation of a dataset for AI-driven TCM tongue diagnosis, it is not specifically focused on LLM training data processing for pretraining or fine-tuning tasks, limiting its relevance to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18332",
      "abstract": "Dimensional analysis provides a universal framework for reducing physical complexity and reveal inherent laws. However, its application to high-dimensional systems still generates redundant dimensionless parameters, making it challenging to establish physically meaningful descriptions. Here, we introduce Hierarchical Dimensionless Learning (Hi-{\\pi}), a physics-data hybrid-driven method that combines dimensional analysis and symbolic regression to automatically discover key dimensionless parameter combination(s). We applied this method to classic examples in various research fields of fluid mechanics. For the Rayleigh-B\\'enard convection, this method accurately extracted two intrinsic dimensionless parameters: the Rayleigh number and the Prandtl number, validating its unified representation advantage across multiscale data. For the viscous flows in a circular pipe, the method automatically discovers two optimal dimensionless parameters: the Reynolds number and relative roughness, achieving a balance between accuracy and complexity. For the compressibility correction in subsonic flow, the method effectively extracts the classic compressibility correction formulation, while demonstrating its capability to discover hierarchical structural expressions through optimal parameter transformations.",
      "authors": [
        "Mingkun Xia",
        "Haitao Lin",
        "Weiwei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T11:59:10+00:00",
          "link": "https://arxiv.org/abs/2507.18332v1",
          "size": "2022kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Dimensionless Learning (Hi-{\\pi}): A physics-data hybrid-driven approach for discovering dimensionless parameter combinations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18332",
        "PDF": "https://arxiv.org/pdf/2507.18332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Hierarchical Dimensionless Learning for discovering dimensionless parameter combinations in physics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18350",
      "abstract": "In this paper, we propose a speech enhancement method us ing dual-path Multi-Channel Linear Prediction (MCLP) filters\n  and multi-norm beamforming. Specifically, the MCLP part in\n  the proposed method is designed with dual-path filters in both\n  time and frequency dimensions. For the beamforming part, we\n  minimize the power of the microphone array output as well as\n  the l1 norm of the denoised signals while preserving source sig nals from the target directions. An efficient method to select the\n  prediction orders in the dual-path filters is also proposed, which\n  is robust for signals with different reverberation time (T60) val ues and can be applied to other MCLP-based methods. Eval uations demonstrate that our proposed method outperforms the\n  baseline methods for speech enhancement, particularly in high\n  reverberation scenarios.",
      "authors": [
        "Chengyuan Qin",
        "Wenmeng Xiong",
        "Jing Zhou",
        "Maoshen Jia",
        "Changchun Bao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:22:45+00:00",
          "link": "https://arxiv.org/abs/2507.18350v1",
          "size": "522kb",
          "version": "v1"
        }
      ],
      "title": "Speech Enhancement with Dual-path Multi-Channel Linear Prediction Filter and Multi-norm Beamforming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18350",
        "HTML": "https://arxiv.org/html/2507.18350v1",
        "PDF": "https://arxiv.org/pdf/2507.18350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a speech enhancement method using dual-path Multi-Channel Linear Prediction filters and beamforming. It focuses on signal processing rather than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18362",
      "abstract": "The Diffusion Probabilistic Model (DPM) has demonstrated remarkable performance across a variety of generative tasks. The inherent randomness in diffusion models helps address issues such as blurring at the edges of medical images and labels, positioning Diffusion Probabilistic Models (DPMs) as a promising approach for lesion segmentation. However, we find that the current training and inference strategies of diffusion models result in an uneven distribution of attention across different timesteps, leading to longer training times and suboptimal solutions. To this end, we propose UniSegDiff, a novel diffusion model framework designed to address lesion segmentation in a unified manner across multiple modalities and organs. This framework introduces a staged training and inference approach, dynamically adjusting the prediction targets at different stages, forcing the model to maintain high attention across all timesteps, and achieves unified lesion segmentation through pre-training the feature extraction network for segmentation. We evaluate performance on six different organs across various imaging modalities. Comprehensive experimental results demonstrate that UniSegDiff significantly outperforms previous state-of-the-art (SOTA) approaches. The code is available at https://github.com/HUYILONG-Z/UniSegDiff.",
      "authors": [
        "Yilong Hu",
        "Shijie Chang",
        "Lihe Zhang",
        "Feng Tian",
        "Weibing Sun",
        "Huchuan Lu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:33:10+00:00",
          "link": "https://arxiv.org/abs/2507.18362v1",
          "size": "247kb",
          "version": "v1"
        }
      ],
      "title": "UniSegDiff: Boosting Unified Lesion Segmentation via a Staged Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18362",
        "HTML": "https://arxiv.org/html/2507.18362v1",
        "PDF": "https://arxiv.org/pdf/2507.18362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a diffusion model framework for medical image segmentation and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18372",
      "abstract": "Publicly releasing the specification of a model with its trained parameters means an adversary can attempt to reconstruct information about the training data via training data reconstruction attacks, a major vulnerability of modern machine learning methods. This paper makes three primary contributions: establishing a mathematical framework to express the problem, characterising the features of the training data that are vulnerable via a maximum mean discrepancy equivalance and outlining a score matching framework for reconstructing data in both Bayesian and non-Bayesian models, the former is a first in the literature.",
      "authors": [
        "George Wynne"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T12:49:41+00:00",
          "link": "https://arxiv.org/abs/2507.18372v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "On Reconstructing Training Data From Bayesian Posteriors and Trained Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18372",
        "HTML": "https://arxiv.org/html/2507.18372v1",
        "PDF": "https://arxiv.org/pdf/2507.18372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses training data reconstruction attacks, which is tangentially related to training data security rather than directly addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18433",
      "abstract": "Multimodal large models have shown great potential in automating pathology image analysis. However, current multimodal models for gastrointestinal pathology are constrained by both data quality and reasoning transparency: pervasive noise and incomplete annotations in public datasets predispose vision language models to factual hallucinations when generating diagnostic text, while the absence of explicit intermediate reasoning chains renders the outputs difficult to audit and thus less trustworthy in clinical practice. To address these issues, we construct a large scale gastrointestinal pathology dataset containing both microscopic descriptions and diagnostic conclusions, and propose a prompt argumentation strategy that incorporates lesion classification and anatomical site information. This design guides the model to better capture image specific features and maintain semantic consistency in generation. Furthermore, we employ a post training pipeline that combines supervised fine tuning with Group Relative Policy Optimization (GRPO) to improve reasoning quality and output structure. Experimental results on real world pathology report generation tasks demonstrate that our approach significantly outperforms state of the art open source and proprietary baselines in terms of generation quality, structural completeness, and clinical relevance. Our solution outperforms state of the art models with 18.7% higher clinical relevance, 32.4% improved structural completeness, and 41.2% fewer diagnostic errors, demonstrating superior accuracy and clinical utility compared to existing solutions.",
      "authors": [
        "Minxi Ouyang",
        "Lianghui Zhu",
        "Yaqing Bao",
        "Qiang Huang",
        "Jingli Ouyang",
        "Tian Guan",
        "Xitong Ling",
        "Jiawen Li",
        "Song Duan",
        "Wenbin Dai",
        "Li Zheng",
        "Xuemei Zhang",
        "Yonghong He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:12:20+00:00",
          "link": "https://arxiv.org/abs/2507.18433v1",
          "size": "10521kb",
          "version": "v1"
        }
      ],
      "title": "DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18433",
        "HTML": "https://arxiv.org/html/2507.18433v1",
        "PDF": "https://arxiv.org/pdf/2507.18433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper constructs a large-scale gastrointestinal pathology dataset and uses a post-training pipeline combining supervised fine-tuning. While it involves data construction, the focus is on improving model performance in pathology diagnosis rather than LLM training data processing for language tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18434",
      "abstract": "Stable multivariate Eulerian polynomials were introduced by Br\\\"and\\'en. Particularizing some variables, it is possible to extract real zero multivariate Eulerian polynomials from them. These real zero multivariate Eulerian polynomials can be fed into constructions of spectrahedral relaxations providing therefore approximations to the (Eulerian) rigidly convex sets defined by these polynomials. The accuracy of these approximations is measured through the behaviour in the diagonal, where the usual univariate Eulerian polynomials sit. In particular, in this sense, the accuracy of the global spectrahedral approximation produced by the spectrahedral relaxation can be measured in terms of bounds for the extreme roots of univariate Eulerian polynomials. The bounds thus obtained beat the previous bounds found in the literature. However, the bound explicitly studied and obtained before beat the previously known bounds by a quantity going to $0$ when $n$ goes to infinity. Here we use numerical experiments to construct a sequence of vectors providing a (linearized) bound whose difference with the previous known bounds is a growing exponential function (going therefore fast to infinity when $n$ grows). This allows us to establish a better (diagonal) measure of accuracy for the spectrahedral relaxation of the Eulerian rigidly convex sets. In particular, we will achieve this by linearizing through the sequence of vectors $\\{(y,(-2^{m-i})_{i=3}^{m},(0,\\frac{1}{2}),(1)_{i=1}^{m})\\in\\mathbb{R}^{n+1}\\}_{n=1}^{\\infty}$ for even $n=2m$.",
      "authors": [
        "Alejandro Gonz\\'alez Nevado"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:12:52+00:00",
          "link": "https://arxiv.org/abs/2507.18434v1",
          "size": "93kb",
          "version": "v1"
        }
      ],
      "title": "Guessing sequences of eigenvectors for LMPs defining spectrahedral relaxations of Eulerian rigidly convex sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18434",
        "HTML": "https://arxiv.org/html/2507.18434v1",
        "PDF": "https://arxiv.org/pdf/2507.18434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with mathematical constructs and spectrahedral relaxations for Eulerian polynomials, which neither relate to LLM training nor to data processing operations in the context of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18446",
      "abstract": "This paper presents a streaming extension for the Sortformer speaker diarization framework, whose key property is the arrival-time ordering of output speakers. The proposed approach employs an Arrival-Order Speaker Cache (AOSC) to store frame-level acoustic embeddings of previously observed speakers. Unlike conventional speaker-tracing buffers, AOSC orders embeddings by speaker index corresponding to their arrival time order, and is dynamically updated by selecting frames with the highest scores based on the model's past predictions. Notably, the number of stored embeddings per speaker is determined dynamically by the update mechanism, ensuring efficient cache utilization and precise speaker tracking. Experiments on benchmark datasets confirm the effectiveness and flexibility of our approach, even in low-latency setups. These results establish Streaming Sortformer as a robust solution for real-time multi-speaker tracking and a foundation for streaming multi-talker speech processing.",
      "authors": [
        "Ivan Medennikov",
        "Taejin Park",
        "Weiqing Wang",
        "He Huang",
        "Kunal Dhawan",
        "Jinhan Wang",
        "Jagadeesh Balam",
        "Boris Ginsburg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:30:48+00:00",
          "link": "https://arxiv.org/abs/2507.18446v1",
          "size": "746kb",
          "version": "v1"
        }
      ],
      "title": "Streaming Sortformer: Speaker Cache-Based Online Speaker Diarization with Arrival-Time Ordering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18446",
        "HTML": "https://arxiv.org/html/2507.18446v1",
        "PDF": "https://arxiv.org/pdf/2507.18446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a speaker diarization framework with no mention of LLMs or related training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18460",
      "abstract": "We present a novel discretization of coupled compressible fluid and thin deformable structures that provides sufficient and necessary leakproofness by preserving the path connectedness of the fluid domain. Our method employs a constrained Voronoi-based spatial partitioning combined with Godunov-style finite-volume time integration. The fluid domain is discretized into cells that conform exactly to the fluid-solid interface, allowing boundary conditions to be sharply resolved exactly at the interface. This enables direct force exchange between the fluid and solid while ensuring that no fluid leaks through the solid, even when arbitrarily thin. We validate our approach on a series of challenging scenarios -- including a balloon propelled by internal compressed air, a champagne cork ejecting after overcoming friction, and a supersonic asteroid -- demonstrating bidirectional energy transfer between fluid and solid.",
      "authors": [
        "Jonathan Panuelos",
        "Eitan Grinspun",
        "David Levin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Graphics (cs.GR)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T23:04:53+00:00",
          "link": "https://arxiv.org/abs/2507.18460v1",
          "size": "37265kb",
          "version": "v1"
        }
      ],
      "title": "Topology-Preserving Coupling of Compressible Fluids and Thin Deformables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18460",
        "HTML": "https://arxiv.org/html/2507.18460v1",
        "PDF": "https://arxiv.org/pdf/2507.18460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with fluid-structure interaction in physics simulations, specifically fluid and solid coupling, without any relevance to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18464",
      "abstract": "Learning from non-stationary data streams subject to concept drift requires models that can adapt on-the-fly while remaining resource-efficient. Existing adaptive ensemble methods often rely on coarse-grained adaptation mechanisms or simple voting schemes that fail to optimally leverage specialized knowledge. This paper introduces DriftMoE, an online Mixture-of-Experts (MoE) architecture that addresses these limitations through a novel co-training framework. DriftMoE features a compact neural router that is co-trained alongside a pool of incremental Hoeffding tree experts. The key innovation lies in a symbiotic learning loop that enables expert specialization: the router selects the most suitable expert for prediction, the relevant experts update incrementally with the true label, and the router refines its parameters using a multi-hot correctness mask that reinforces every accurate expert. This feedback loop provides the router with a clear training signal while accelerating expert specialization. We evaluate DriftMoE's performance across nine state-of-the-art data stream learning benchmarks spanning abrupt, gradual, and real-world drifts testing two distinct configurations: one where experts specialize on data regimes (multi-class variant), and another where they focus on single-class specialization (task-based variant). Our results demonstrate that DriftMoE achieves competitive results with state-of-the-art stream learning adaptive ensembles, offering a principled and efficient approach to concept drift adaptation. All code, data pipelines, and reproducibility scripts are available in our public GitHub repository: https://github.com/miguel-ceadar/drift-moe.",
      "authors": [
        "Miguel Aspis",
        "Sebasti\\'an A. Cajas Ord\\'onez",
        "Andr\\'es L. Su\\'arez-Cetrulo",
        "Ricardo Sim\\'on Carbajo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T14:39:20+00:00",
          "link": "https://arxiv.org/abs/2507.18464v1",
          "size": "1380kb",
          "version": "v1"
        }
      ],
      "title": "DriftMoE: A Mixture of Experts Approach to Handle Concept Drifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18464",
        "HTML": "https://arxiv.org/html/2507.18464v1",
        "PDF": "https://arxiv.org/pdf/2507.18464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on DriftMoE, a Mixture-of-Experts architecture for handling concept drifts in data stream learning, without addressing any aspect of LLM training data processing or improvement of data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18499",
      "abstract": "Following the example of Shor's algorithm for period-finding in the integers, we explore the hidden subgroup problem (HSP) for discrete infinite groups. On the hardness side, we show that HSP is NP-hard for the additive group of rational numbers, and for normal subgroups of non-abelian free groups. We also indirectly reduce a version of the short vector problem to HSP in $\\mathbb{Z}^k$ with pseudo-polynomial query cost. On the algorithm side, we generalize the Shor-Kitaev algorithm for HSP in $\\mathbb{Z}^k$ (with standard polynomial query cost) to the case where the hidden subgroup has deficient rank or equivalently infinite index. Finally, we outline a stretched exponential time algorithm for the abelian hidden shift problem (AHShP), extending prior work of the author as well as Regev and Peikert. It follows that HSP in any finitely generated, virtually abelian group also has a stretched exponential time algorithm.",
      "authors": [
        "Greg Kuperberg (UC Davis)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)",
        "Group Theory (math.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:16:20+00:00",
          "link": "https://arxiv.org/abs/2507.18499v1",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "title": "The hidden subgroup problem for infinite groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18499",
        "PDF": "https://arxiv.org/pdf/2507.18499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the hidden subgroup problem in infinite groups, which is unrelated to LLM training data processing or any associated data engineering practices."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18520",
      "abstract": "Pairwise Euclidean distance calculation is a fundamental step in many machine learning and data analysis algorithms. In real-world applications, however, these distances are frequently distorted by heteroskedastic noise$\\unicode{x2014}$a prevalent form of inhomogeneous corruption characterized by variable noise magnitudes across data observations. Such noise inflates the computed distances in a nontrivial way, leading to misrepresentations of the underlying data geometry. In this work, we address the tasks of estimating the noise magnitudes per observation and correcting the pairwise Euclidean distances under heteroskedastic noise. Perhaps surprisingly, we show that in general high-dimensional settings and without assuming prior knowledge on the clean data structure or noise distribution, both tasks can be performed reliably, even when the noise levels vary considerably. Specifically, we develop a principled, hyperparameter-free approach that jointly estimates the noise magnitudes and corrects the distances. We provide theoretical guarantees for our approach, establishing probabilistic bounds on the estimation errors of both noise magnitudes and distances. These bounds, measured in the normalized $\\ell_1$ norm, converge to zero at polynomial rates as both feature dimension and dataset size increase. Experiments on synthetic datasets demonstrate that our method accurately estimates distances in challenging regimes, significantly improving the robustness of subsequent distance-based computations. Notably, when applied to single-cell RNA sequencing data, our method yields noise magnitude estimates consistent with an established prototypical model, enabling accurate nearest neighbor identification that is fundamental to many downstream analyses.",
      "authors": [
        "Keyi Li",
        "Yuval Kluger",
        "Boris Landa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T15:45:23+00:00",
          "link": "https://arxiv.org/abs/2507.18520v1",
          "size": "2227kb",
          "version": "v1"
        }
      ],
      "title": "Euclidean Distance Deflation Under High-Dimensional Heteroskedastic Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18520",
        "HTML": "https://arxiv.org/html/2507.18520v1",
        "PDF": "https://arxiv.org/pdf/2507.18520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on correcting pairwise Euclidean distances under high-dimensional heteroskedastic noise, a topic not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18540",
      "abstract": "We develop a deep variational free energy framework to compute the equation of state of hydrogen in the warm dense matter region. This method parameterizes the variational density matrix of hydrogen nuclei and electrons at finite temperature using three deep generative models: a normalizing flow model that represents the Boltzmann distribution of the classical nuclei, an autoregressive transformer that models the distribution of electrons in excited states, and a permutational equivariant flow model that constructs backflow coordinates for electrons in Hartree-Fock orbitals. By jointly optimizing the three neural networks to minimize the variational free energy, we obtain the equation of state and related thermodynamic properties of dense hydrogen. We compare our results with other theoretical and experimental results on the deuterium Hugoniot curve, aiming to resolve existing discrepancies. The calculated results provide a valuable benchmark for deuterium in the warm dense matter region.",
      "authors": [
        "Zihang Li and Hao Xie and Xinyang Dong and Lei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:07:13+00:00",
          "link": "https://arxiv.org/abs/2507.18540v1",
          "size": "1113kb",
          "version": "v1"
        }
      ],
      "title": "Deep Variational Free Energy Calculation of Hydrogen Hugoniot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18540",
        "HTML": "https://arxiv.org/html/2507.18540v1",
        "PDF": "https://arxiv.org/pdf/2507.18540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a deep variational free energy framework for calculating the equation of state of hydrogen, which is related to physical chemistry and thermodynamics, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18560",
      "abstract": "This paper presents a novel hierarchical framework for portfolio optimization, integrating lightweight Large Language Models (LLMs) with Deep Reinforcement Learning (DRL) to combine sentiment signals from financial news with traditional market indicators. Our three-tier architecture employs base RL agents to process hybrid data, meta-agents to aggregate their decisions, and a super-agent to merge decisions based on market data and sentiment analysis. Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming equal-weighted and S&P 500 benchmarks. Key contributions include scalable cross-modal integration, a hierarchical RL structure for enhanced stability, and open-source reproducibility.",
      "authors": [
        "Benjamin Coriat",
        "Eric Benhamou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:35:24+00:00",
          "link": "https://arxiv.org/abs/2507.18560v1",
          "size": "725kb",
          "version": "v1"
        }
      ],
      "title": "HARLF: Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Financial Portfolio Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18560",
        "HTML": "https://arxiv.org/html/2507.18560v1",
        "PDF": "https://arxiv.org/pdf/2507.18560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a framework for financial portfolio optimization using a combination of lightweight LLMs and reinforcement learning. While this involves LLMs, the focus is on financial application rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18573",
      "abstract": "We develop a method of constructing structure-preserving integrators for Hamiltonian systems in Jacobi manifolds. Hamiltonian mechanics, rooted in symplectic and Poisson geometry, has long provided a foundation for modelling conservative systems in classical physics. Jacobi manifolds, generalizing both contact and Poisson manifolds, extend this theory and are suitable for incorporating time-dependent, dissipative and thermodynamic phenomena.\n  Building on recent advances in geometric integrators - specifically Poisson Hamiltonian Integrators (PHI), which preserve key features of Poisson systems - we propose a construction of Jacobi Hamiltonian Integrators. Our approach explores the correspondence between Jacobi and homogeneous Poisson manifolds, with the aim of extending the PHI techniques while ensuring preservation of the homogeneity structure.\n  This work develops the theoretical tools required for this generalization and outlines a numerical integration technique compatible with Jacobi dynamics. By focusing on the homogeneous Poisson perspective rather than on direct contact realizations, we provide a clear pathway for structure-preserving integration of time-dependent and dissipative systems within the Jacobi framework.",
      "authors": [
        "Ad\\'erito Ara\\'ujo",
        "Gon\\c{c}alo Inoc\\^encio Oliveira",
        "Jo\\~ao Nuno Mestre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Numerical Analysis (cs.NA)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Numerical Analysis (math.NA)",
        "Symplectic Geometry (math.SG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T16:47:16+00:00",
          "link": "https://arxiv.org/abs/2507.18573v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "Jacobi Hamiltonian Integrators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18573",
        "HTML": "https://arxiv.org/html/2507.18573v1",
        "PDF": "https://arxiv.org/pdf/2507.18573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses methods for structure-preserving integrators for Hamiltonian systems, which are unrelated to the processing of training data for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18577",
      "abstract": "The advent of foundation models (FMs) - large-scale pre-trained models with strong generalization capabilities - has opened new frontiers for financial engineering. While general-purpose FMs such as GPT-4 and Gemini have demonstrated promising performance in tasks ranging from financial report summarization to sentiment-aware forecasting, many financial applications remain constrained by unique domain requirements such as multimodal reasoning, regulatory compliance, and data privacy. These challenges have spurred the emergence of Financial Foundation Models (FFMs) - a new class of models explicitly designed for finance. This survey presents a comprehensive overview of FFMs, with a taxonomy spanning three key modalities: Financial Language Foundation Models (FinLFMs), Financial Time-Series Foundation Models (FinTSFMs), and Financial Visual-Language Foundation Models (FinVLFMs). We review their architectures, training methodologies, datasets, and real-world applications. Furthermore, we identify critical challenges in data availability, algorithmic scalability, and infrastructure constraints, and offer insights into future research opportunities. We hope this survey serves as both a comprehensive reference for understanding FFMs and a practical roadmap for future innovation. An updated collection of FFM-related publications and resources will be maintained on our website https://github.com/FinFM/Awesome-FinFMs.",
      "authors": [
        "Liyuan Chen",
        "Shuoling Liu",
        "Jiangpeng Yan",
        "Xiaoyu Wang",
        "Henglin Liu",
        "Chuang Li",
        "Kecheng Jiao",
        "Jixuan Ying",
        "Yang Veronica Liu",
        "Qiang Yang",
        "Xiu Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Finance (q-fin.CP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T16:06:38+00:00",
          "link": "https://arxiv.org/abs/2507.18577v1",
          "size": "1176kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Financial Engineering with Foundation Models: Progress, Applications, and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18577",
        "PDF": "https://arxiv.org/pdf/2507.18577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a survey on Financial Foundation Models and discusses various challenges in financial engineering. It does not contribute to LLM training data processing, as it focuses on applications, architecture, and challenges specific to finance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18587",
      "abstract": "Deep learning (DL) has emerged as a solution for precoding in massive multiple-input multiple-output (mMIMO) systems due to its capacity to learn the characteristics of the propagation environment. However, training such a model requires high-quality, local datasets at the deployment site, which are often difficult to collect. We propose a transformer-based foundation model for mMIMO precoding that seeks to minimize the energy consumption of the transmitter while dynamically adapting to per-user rate requirements. At equal energy consumption, zero-shot deployment of the proposed foundation model significantly outperforms zero forcing, and approaches weighted minimum mean squared error performance with 8x less complexity. To address model adaptation in data-scarce settings, we introduce a data augmentation method that finds training samples similar to the target distribution by computing the cosine similarity between the outputs of the pre-trained feature extractor. Our work enables the implementation of DL-based solutions in practice by addressing challenges of data availability and training complexity. Moreover, the ability to dynamically configure per-user rate requirements can be leveraged by higher level resource allocation and scheduling algorithms for greater control over energy efficiency, spectral efficiency and fairness.",
      "authors": [
        "J\\'er\\^ome Emery",
        "Ali Hasanzadeh Karkan",
        "Jean-Fran\\c{c}ois Frigon",
        "Fran\\c{c}ois Leduc-Primeau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:10:06+00:00",
          "link": "https://arxiv.org/abs/2507.18587v1",
          "size": "97kb",
          "version": "v1"
        }
      ],
      "title": "A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18587",
        "HTML": "https://arxiv.org/html/2507.18587v1",
        "PDF": "https://arxiv.org/pdf/2507.18587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a data augmentation method for a transformer-based model in mMIMO systems, but its primary focus is on model training and performance, not on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18606",
      "abstract": "Reinforcement learning (RL) provides a principled framework for decision-making in partially observable environments, which can be modeled as Markov decision processes and compactly represented through dynamic decision Bayesian networks. Recent advances demonstrate that inference on sparse Bayesian networks can be accelerated using quantum rejection sampling combined with amplitude amplification, leading to a computational speedup in estimating acceptance probabilities.\\\\ Building on this result, we introduce Quantum Bayesian Reinforcement Learning (QBRL), a hybrid quantum-classical look-ahead algorithm for model-based RL in partially observable environments. We present a rigorous, oracle-free time complexity analysis under fault-tolerant assumptions for the quantum device. Unlike standard treatments that assume a black-box oracle, we explicitly specify the inference process, allowing our bounds to more accurately reflect the true computational cost. We show that, for environments whose dynamics form a sparse Bayesian network, horizon-based near-optimal planning can be achieved sub-quadratically faster through quantum-enhanced belief updates.\n  Furthermore, we present numerical experiments benchmarking QBRL against its classical counterpart on simple yet illustrative decision-making tasks. Our results offer a detailed analysis of how the quantum computational advantage translates into decision-making performance, highlighting that the magnitude of the advantage can vary significantly across different deployment settings.",
      "authors": [
        "Gilberto Cunha",
        "Alexandra Ram\\^oa",
        "Andr\\'e Sequeira",
        "Michael de Oliveira",
        "Lu\\'is Barbosa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:42:30+00:00",
          "link": "https://arxiv.org/abs/2507.18606v1",
          "size": "1853kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid quantum-classical algorithm for near-optimal planning in POMDPs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18606",
        "HTML": "https://arxiv.org/html/2507.18606v1",
        "PDF": "https://arxiv.org/pdf/2507.18606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a hybrid quantum-classical algorithm for reinforcement learning in POMDPs, focusing on quantum computing and model-based RL, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18609",
      "abstract": "We extend the Deadzone-Adapted Disturbance Suppression (DADS) control to time-invariant systems with dynamic uncertainties that satisfy the matching condition and for which no bounds for the disturbance and the unknown parameters are known. This problem is equivalent to partial-state adaptive feedback, where the states modeling the dynamic uncertainty are unmeasured. We show that the DADS controller can bypass small-gain conditions and achieve robust regulation for systems in spite of the fact that the strength of the interconnections has no known bound. Moreover, no gain and state drift arise, regardless of the size of the disturbances and unknown parameters. Finally, the paper provides the detailed analysis of a control system where the unmeasured state (or the dynamic uncertainty) is infinite-dimensional and described by a reaction-diffusion Partial Differential Equation, where the diffusion coefficient and the reaction term are unknown. It is shown that even in the infinite-dimensional case, a DADS controller can be designed and guarantees robust regulation of the plant state.",
      "authors": [
        "Iasson Karafyllis and Miroslav Krstic"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:44:56+00:00",
          "link": "https://arxiv.org/abs/2507.18609v1",
          "size": "812kb",
          "version": "v1"
        }
      ],
      "title": "Partial-State DADS Control for Matched Unmodeled Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18609",
        "PDF": "https://arxiv.org/pdf/2507.18609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on control theory and extends disturbance suppression to dynamic systems. It does not relate to any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.18628",
      "abstract": "This report details the successful construction of an ultrasound imaging platform and the design and fabrication of a novel ultrasound endoscope probe. The projects primary objective was to establish a functional system for acquiring and processing ultrasound signals, specifically targeting minimally invasive endoscopic applications. The ultrasound imaging platform was primarily designed and developed based on Texas Instruments (TI) Evaluation Modules (EVMs). It enables the transmission of 32-channel high-voltage signals and the reception of echo signals, with on-chip signal amplification and acquisition capabilities. Furthermore, the platform integrates a complete Time Gain Control (TGC) imaging path and a ContinuousWave Doppler (CWD) path. In conjunction with host computer software, it supports imaging with linear array, convex array, and phased array probes. Concurrently, a 64-element, 5MHz center frequency, phased array linear ultrasound endoscopic probe was designed, aiming for miniaturization and optimal imaging performance. The fabrication and assembly of its matching layer, backing layer, 2-2 piezoelectric composite material, and electrodes were completed.",
      "authors": [
        "Yuan Zhang",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-24T17:59:16+00:00",
          "link": "https://arxiv.org/abs/2507.18628v1",
          "size": "2107kb",
          "version": "v1"
        }
      ],
      "title": "Design and fabrication of ultrasound linear array transducer used in ultrasound endoscope",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.18628",
        "HTML": "https://arxiv.org/html/2507.18628v1",
        "PDF": "https://arxiv.org/pdf/2507.18628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the design and fabrication of an ultrasound imaging platform, with no relevance to LLM training data processing or data operations for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "1611.04175",
      "abstract": "We introduce and study the weakly single-crossing domain on trees which is a generalization of the well-studied single-crossing domain in social choice theory. We design a polynomial-time algorithm for recognizing preference profiles which belong to this domain. We then develop an efficient elicitation algorithm for this domain which works even if the preferences can be accessed only sequentially and the underlying single-crossing tree structure is not known beforehand. We also prove matching lower bound on the query complexity of our elicitation algorithm when the number of voters is large compared to the number of candidates. We also prove a lower bound of $\\Omega(m^2\\log n)$ on the number of queries that any algorithm needs to ask to elicit single crossing profile when random queries are allowed. This resolves an open question in an earlier paper and proves optimality of their preference elicitation algorithm when random queries are allowed.",
      "authors": [
        "Palash Dey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2016-11-13T19:35:52+00:00",
          "link": "https://arxiv.org/abs/1611.04175v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2022-02-18T13:31:30+00:00",
          "link": "https://arxiv.org/abs/1611.04175v2",
          "size": "46kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T11:23:26+00:00",
          "link": "https://arxiv.org/abs/1611.04175v3",
          "size": "49kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T05:38:22+00:00",
          "link": "https://arxiv.org/abs/1611.04175v4",
          "size": "49kb",
          "version": "v4"
        }
      ],
      "title": "Recognizing and Eliciting Weakly Single Crossing Profiles on Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/1611.04175",
        "HTML": "https://arxiv.org/html/1611.04175v4",
        "PDF": "https://arxiv.org/pdf/1611.04175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the recognition and elicitation of weakly single-crossing profiles on trees in social choice theory, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Open-Ended Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "1808.02391",
      "abstract": "In this paper, we present continuous-stage partitioned Runge-Kutta (csPRK) methods for energy-preserving integration of Hamiltonian systems. A sufficient condition for the energy preservation of the csPRK methods is derived. It is shown that the presented condition contains the existing condition for energy-preserving continuous-stage Runge-Kutta methods as a special case. A noticeable and interesting result is that when we use the simplifying assumptions of order conditions and the normalized shifted Legendre polynomials for constructing high-order energy-preserving csPRK methods, both the Butcher \"weight\" coefficients $B_\\tau$ and $\\widehat{B}_\\tau$ must be equal to $1$. As illustrative examples, new energy-preserving integrators are acquired by virtue of the presented condition, and for the sake of verifying our theoretical results, some numerical experiments are reported.",
      "authors": [
        "Wensheng Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2018-08-07T14:16:42+00:00",
          "link": "https://arxiv.org/abs/1808.02391v1",
          "size": "2043kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T07:01:11+00:00",
          "link": "https://arxiv.org/abs/1808.02391v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T02:43:15+00:00",
          "link": "https://arxiv.org/abs/1808.02391v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "Energy-preserving continuous-stage partitioned Runge-Kutta methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/1808.02391",
        "PDF": "https://arxiv.org/pdf/1808.02391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents continuous-stage partitioned Runge-Kutta methods for energy preservation in Hamiltonian systems, not addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1808.08451",
      "abstract": "Many practical problems can be described by second-order system $\\ddot{q}=-M\\nabla U(q)$, in which people give special emphasis to some invariants with explicit physical meaning, such as energy, momentum, angular momentum, etc. However, conventional numerical integrators for such systems will fail to preserve any of these quantities which may lead to qualitatively incorrect numerical solutions. This paper is concerned with the development of energy-preserving continuous-stage Runge-Kutta-Nystr\\\"om (csRKN) methods for solving second-order systems. Sufficient conditions for csRKN methods to be energy-preserving are presented and it is proved that all the energy-preserving csRKN methods satisfying these sufficient conditions can be essentially induced by energy-preserving continuous-stage partitioned Runge-Kutta methods. Some illustrative examples are given and relevant numerical results are reported.",
      "authors": [
        "Wensheng Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2018-08-25T17:19:49+00:00",
          "link": "https://arxiv.org/abs/1808.08451v1",
          "size": "2646kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T06:36:17+00:00",
          "link": "https://arxiv.org/abs/1808.08451v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T02:41:25+00:00",
          "link": "https://arxiv.org/abs/1808.08451v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "Energy-preserving continuous-stage Runge-Kutta-Nystr\\\"om methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/1808.08451",
        "PDF": "https://arxiv.org/pdf/1808.08451"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with energy-preserving Runge-Kutta-Nystr\u00f6m methods for solving second-order systems, which has no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1909.03820",
      "abstract": "We study Boolean classification problems over relational background structures in the logical framework introduced by Grohe and Tur\\'an (TOCS 2004). It is known (Grohe and Ritzert, LICS 2017) that classifiers definable in first-order logic over structures of polylogarithmic degree can be learned in sublinear time, where the degree of the structure and the running time are measured in terms of the size of the structure. We generalise the results to the first-order logic with counting FOCN, which was introduced by Kuske and Schweikardt (LICS 2017) as an expressive logic generalising various other counting logics. Specifically, we prove that classifiers definable in FOCN over classes of structures of polylogarithmic degree can be consistently learned in sublinear time. This can be seen as a first step towards extending the learning framework to include numerical aspects of machine learning. We extend the result to agnostic probably approximately correct (PAC) learning for classes of structures of degree at most $(\\log \\log n)^c$ for some constant $c$. Moreover, we show that bounding the degree is crucial to obtain sublinear-time learning algorithms. That is, we prove that, for structures of unbounded degree, learning is not possible in sublinear time, even for classifiers definable in plain first-order logic.",
      "authors": [
        "Steffen van Bergerem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2019-09-09T12:57:29+00:00",
          "link": "https://arxiv.org/abs/1909.03820v1",
          "size": "28kb",
          "version": "v1"
        },
        {
          "date": "2024-03-23T22:14:50+00:00",
          "link": "https://arxiv.org/abs/1909.03820v2",
          "size": "138kb",
          "version": "v2"
        },
        {
          "date": "2025-01-29T18:49:49+00:00",
          "link": "https://arxiv.org/abs/1909.03820v3",
          "size": "157kb",
          "version": "v3"
        },
        {
          "date": "2025-06-11T14:23:07+00:00",
          "link": "https://arxiv.org/abs/1909.03820v4",
          "size": "158kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T10:00:10+00:00",
          "link": "https://arxiv.org/abs/1909.03820v5",
          "size": "160kb",
          "version": "v5"
        }
      ],
      "title": "Learning Concepts Definable in First-Order Logic with Counting",
      "links": {
        "Abstract": "https://arxiv.org/abs/1909.03820",
        "PDF": "https://arxiv.org/pdf/1909.03820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses learning classifiers definable in first-order logic with counting over relational structures, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "General Classification",
        "PAC learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2006.07841",
      "abstract": "The scarcity of class-labeled data is a ubiquitous bottleneck in many machine learning problems. While abundant unlabeled data typically exist and provide a potential solution, it is highly challenging to exploit them. In this paper, we address this problem by leveraging Positive-Unlabeled~(PU) classification and the conditional generation with extra unlabeled data \\emph{simultaneously}. We present a novel training framework to jointly target both PU classification and conditional generation when exposed to extra data, especially out-of-distribution unlabeled data, by exploring the interplay between them: 1) enhancing the performance of PU classifiers with the assistance of a novel Classifier-Noise-Invariant Conditional GAN~(CNI-CGAN) that is robust to noisy labels, 2) leveraging extra data with predicted labels from a PU classifier to help the generation. Theoretically, we prove the optimal condition of CNI-CGAN and experimentally, we conducted extensive evaluations on diverse datasets.",
      "authors": [
        "Bing Yu",
        "Ke Sun",
        "He Wang",
        "Zhouchen Lin",
        "Zhanxing Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2020-06-14T08:27:40+00:00",
          "link": "https://arxiv.org/abs/2006.07841v1",
          "size": "585kb",
          "version": "v1"
        },
        {
          "date": "2024-02-09T02:23:03+00:00",
          "link": "https://arxiv.org/abs/2006.07841v2",
          "size": "587kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T01:29:43+00:00",
          "link": "https://arxiv.org/abs/2006.07841v3",
          "size": "341kb",
          "version": "v3"
        }
      ],
      "title": "On Leveraging Unlabeled Data for Concurrent Positive-Unlabeled Classification and Robust Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2006.07841",
        "HTML": "https://arxiv.org/html/2006.07841v3",
        "PDF": "https://arxiv.org/pdf/2006.07841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with PU classification and conditional generation using unlabeled data, without addressing LLM training data processing, such as dataset creation or data engineering operations relevant to LLMs."
      },
      "conference": "classify-and-generate-reciprocally-1",
      "conference_url_abs": "https://openreview.net/forum?id=L4n9FPoQL1",
      "tasks": [
        "Classification",
        "General Classification",
        "Generative Adversarial Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2212.10678",
      "abstract": "Generated texts from large language models (LLMs) have been shown to exhibit a variety of harmful, human-like biases against various demographics. These findings motivate research efforts aiming to understand and measure such effects. This paper introduces a causal formulation for bias measurement in generative language models. Based on this theoretical foundation, we outline a list of desiderata for designing robust bias benchmarks. We then propose a benchmark called OccuGender, with a bias-measuring procedure to investigate occupational gender bias. We test several state-of-the-art open-source LLMs on OccuGender, including Llama, Mistral, and their instruction-tuned versions. The results show that these models exhibit substantial occupational gender bias. Lastly, we discuss prompting strategies for bias mitigation and an extension of our causal formulation to illustrate the generalizability of our framework. Our code and data https://github.com/chenyuen0103/gender-bias.",
      "authors": [
        "Yuen Chen",
        "Vethavikashini Chithrra Raghuram",
        "Justus Mattern",
        "Rada Mihalcea",
        "Zhijing Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-20T22:41:24+00:00",
          "link": "https://arxiv.org/abs/2212.10678v1",
          "size": "485kb",
          "version": "v1"
        },
        {
          "date": "2024-07-15T15:10:45+00:00",
          "link": "https://arxiv.org/abs/2212.10678v2",
          "size": "142kb",
          "version": "v2"
        },
        {
          "date": "2024-10-21T03:55:36+00:00",
          "link": "https://arxiv.org/abs/2212.10678v3",
          "size": "161kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T03:20:40+00:00",
          "link": "https://arxiv.org/abs/2212.10678v4",
          "size": "157kb",
          "version": "v4"
        }
      ],
      "title": "Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.10678",
        "HTML": "https://arxiv.org/html/2212.10678v4",
        "PDF": "https://arxiv.org/pdf/2212.10678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses bias measurement in LLMs through the creation of a benchmark, OccuGender. While it involves some data processing related to bias evaluation, the main focus is on measuring and mitigating bias, not on training data processing or dataset creation for LLM training."
      },
      "tasks": [
        "Benchmarking"
      ],
      "repo_urls": [
        "https://github.com/chenyuen0103/gender-bias"
      ],
      "source": "arXiv"
    },
    {
      "id": "2305.16901",
      "abstract": "One of the primary reasons behind the success of neural networks has been the emergence of an array of new, highly-successful optimizers, perhaps most importantly the Adam optimizer. It is widely used for training neural networks, yet notoriously hard to interpret. Lacking a clear physical intuition, Adam is difficult to generalize to manifolds. Some attempts have been made to directly apply parts of the Adam algorithm to manifolds or to find an underlying structure, but a full generalization has remained elusive.\n  In this work a new approach is presented that leverages the special structure of the manifolds which are relevant for optimization of neural networks, such as the Stiefel manifold, the symplectic Stiefel manifold and the Grassmann manifold: all of these are homogeneous spaces and as such admit a global tangent space representation - a common vector space (Lie subspace) in which all tangent spaces can easily be represented.\n  This global tangent space representation is used to perform all of the steps in the Adam optimizer and we are able to fully generalize the optimizer to manifolds without a projection step. The resulting algorithm is then applied to train a transformer for which orthogonality constraints are enforced up to machine precision and we observe significant speed-ups in the training process.",
      "authors": [
        "Benedikt Brantner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Differential Geometry (math.DG)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-26T13:14:05+00:00",
          "link": "https://arxiv.org/abs/2305.16901v1",
          "size": "147kb",
          "version": "v1"
        },
        {
          "date": "2023-12-19T09:41:25+00:00",
          "link": "https://arxiv.org/abs/2305.16901v2",
          "size": "237kb",
          "version": "v2"
        },
        {
          "date": "2024-09-30T08:27:36+00:00",
          "link": "https://arxiv.org/abs/2305.16901v3",
          "size": "455kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T06:08:33+00:00",
          "link": "https://arxiv.org/abs/2305.16901v4",
          "size": "531kb",
          "version": "v4"
        }
      ],
      "title": "Generalizing Adam to Manifolds for Efficiently Training Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.16901",
        "HTML": "https://arxiv.org/html/2305.16901v4",
        "PDF": "https://arxiv.org/pdf/2305.16901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generalizing the Adam optimizer to manifolds and applying it to train Transformers. It is concerned with optimization techniques rather than LLM training data processing."
      },
      "tasks": [
        "Physical Intuition"
      ],
      "repo_urls": [
        "https://github.com/juliagni/geometricmachinelearning.jl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2308.01358",
      "abstract": "In this paper, we investigate the impact of compression on stochastic gradient algorithms for machine learning, a technique widely used in distributed and federated learning. We underline differences in terms of convergence rates between several unbiased compression operators, that all satisfy the same condition on their variance, thus going beyond the classical worst-case analysis. To do so, we focus on the case of least-squares regression (LSR) and analyze a general stochastic approximation algorithm for minimizing quadratic functions relying on a random field. We consider weak assumptions on the random field, tailored to the analysis (specifically, expected H\\\"older regularity), and on the noise covariance, enabling the analysis of various randomizing mechanisms, including compression. We then extend our results to the case of federated learning.\n  More formally, we highlight the impact on the convergence of the covariance $\\mathfrak{C}_{\\mathrm{ania}}$ of the additive noise induced by the algorithm. We demonstrate despite the non-regularity of the stochastic field, that the limit variance term scales with $\\mathrm{Tr}(\\mathfrak{C}_{\\mathrm{ania}} H^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the number of iterations) generalizing the rate for the vanilla LSR case where it is $\\sigma^2 \\mathrm{Tr}(H H^{-1}) / K = \\sigma^2 d / K$ (Bach and Moulines, 2013). Then, we analyze the dependency of $\\mathfrak{C}_{\\mathrm{ania}}$ on the compression strategy and ultimately its impact on convergence, first in the centralized case, then in two heterogeneous FL frameworks.",
      "authors": [
        "Constantin Philippenko and Aymeric Dieuleveut"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-02T18:02:00+00:00",
          "link": "https://arxiv.org/abs/2308.01358v1",
          "size": "11195kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:23:22+00:00",
          "link": "https://arxiv.org/abs/2308.01358v2",
          "size": "11154kb",
          "version": "v2"
        }
      ],
      "title": "Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.01358",
        "HTML": "https://arxiv.org/html/2308.01358v2",
        "PDF": "https://arxiv.org/pdf/2308.01358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses the convergence rates of compressed stochastic gradient algorithms in distributed and federated learning settings. There is no focus on LLM training data processing such as data collection or quality improvement."
      },
      "tasks": [
        "Federated Learning",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2308.09954",
      "abstract": "Knowledge editing aims to correct outdated or inaccurate knowledge in neural networks. In this paper, we explore knowledge editing using easily accessible documents instead of manually labeled factual triples employed in earlier research. To advance this field, we establish the first evaluation benchmark, \\textit{DocTER}, featuring Documents containing counterfactual knowledge for editing. A comprehensive four-perspective evaluation is introduced: Edit Success, Locality, Reasoning, and Cross-lingual Transfer. To adapt conventional triplet-based knowledge editing methods for this task, we develop an Extract-then-Edit pipeline that extracts triples from documents before applying existing methods. Experiments on popular knowledge editing methods demonstrate that editing with documents presents significantly greater challenges than using triples. In document-based scenarios, even the best-performing in-context editing approach still lags behind by 10 points in editing success when compared to using gold triples. This observation also holds for both reasoning and cross-lingual test sets. We further analyze key factors influencing task performance, including the quality of extracted triples, the frequency and position of edited knowledge in documents, various methods for enhancing reasoning, and performance differences across various directions in cross-lingual knowledge editing, which provide valuable insights for future research.",
      "authors": [
        "Suhang Wu",
        "Ante Wang",
        "Minlong Peng",
        "Yujie Lin",
        "Wenbo Li",
        "Mingming Sun",
        "Jinsong Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-19T09:17:19+00:00",
          "link": "https://arxiv.org/abs/2308.09954v1",
          "size": "2920kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:16:48+00:00",
          "link": "https://arxiv.org/abs/2308.09954v2",
          "size": "1829kb",
          "version": "v2"
        }
      ],
      "title": "DocTER: Evaluating Document-based Knowledge Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.09954",
        "HTML": "https://arxiv.org/html/2308.09954v2",
        "PDF": "https://arxiv.org/pdf/2308.09954"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces an evaluation benchmark, DocTER, for document-based knowledge editing. Although it deals with data in terms of knowledge editing, it primarily focuses on evaluation methods rather than direct training data processing for LLMs."
      },
      "tasks": [
        "knowledge editing",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.03791",
      "abstract": "We introduce a new class of optimal-transport-regularized divergences, $D^c$, constructed via an infimal convolution between an information divergence, $D$, and an optimal-transport (OT) cost, $C$, and study their use in distributionally robust optimization (DRO). In particular, we propose the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These DRO-based methods are defined by minimizing the maximum expected loss over a $D^c$-neighborhood of the empirical distribution of the training data. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence; the addition of a principled and dynamical adversarial re-weighting on top of adversarial sample transport is a key innovation of $ARMOR_D$. $ARMOR_D$ can be viewed as a generalization of the best-performing loss functions and OT costs in the adversarial training literature; we demonstrate this flexibility by using $ARMOR_D$ to augment the UDR, TRADES, and MART methods and obtain improved performance on CIFAR-10 and CIFAR-100 image recognition. Specifically, augmenting with $ARMOR_D$ leads to 1.9\\% and 2.1\\% improvement against AutoAttack, a powerful ensemble of adversarial attacks, on CIFAR-10 and CIFAR-100 respectively. To foster reproducibility, we made the code accessible at https://github.com/star-ailab/ARMOR.",
      "authors": [
        "Jeremiah Birrell",
        "Reza Ebrahimi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-07T15:41:45+00:00",
          "link": "https://arxiv.org/abs/2309.03791v1",
          "size": "406kb",
          "version": "v1"
        },
        {
          "date": "2025-03-31T17:34:34+00:00",
          "link": "https://arxiv.org/abs/2309.03791v2",
          "size": "396kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T15:47:29+00:00",
          "link": "https://arxiv.org/abs/2309.03791v3",
          "size": "393kb",
          "version": "v3"
        }
      ],
      "title": "Optimal Transport Regularized Divergences: Application to Adversarial Robustness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.03791",
        "HTML": "https://arxiv.org/html/2309.03791v3",
        "PDF": "https://arxiv.org/pdf/2309.03791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces optimal transport regularized divergences focused on enhancing adversarial robustness. It concerns model robustness and adversarial training, not LLM training data processing."
      },
      "tasks": [
        "Adversarial Robustness",
        "Deep Learning",
        "Malware Detection"
      ],
      "repo_urls": [
        "https://github.com/star-ailab/armor"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.15951",
      "abstract": "As emerging applications demand increasingly higher throughput, IEEE standard 802.11be -- Extremely High Throughput (EHT), also known as Wi-Fi 7, was published on July 22, 2025. It can be used to meet the demand for the throughput of 4K/8K videos up to tens of Gbps and low-latency video applications such as virtual reality (VR) and augmented reality (AR). Wi-Fi 7 not only scales Wi-Fi 6 with doubled bandwidth, but also supports real-time applications, which brings revolutionary changes to Wi-Fi. In this article, we start by introducing the main objectives and timeline of Wi-Fi 7 and then list the latest key techniques which promote the performance improvement of Wi-Fi 7. Finally, we validate the most critical objectives of Wi-Fi 7 -- the potential up to 30 Gbps throughput and lower latency. System-level simulation results suggest that by combining the new techniques, Wi-Fi 7 achieves 30 Gbps throughput and lower latency than Wi-Fi 6.",
      "authors": [
        "Xiaoqian Liu",
        "Yuhan Dong",
        "Yiqing Li",
        "Yousi Lin and Ming Gan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-27T19:09:19+00:00",
          "link": "https://arxiv.org/abs/2309.15951v1",
          "size": "299kb",
          "version": "v1"
        },
        {
          "date": "2024-07-08T15:22:21+00:00",
          "link": "https://arxiv.org/abs/2309.15951v2",
          "size": "1816kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:19:47+00:00",
          "link": "https://arxiv.org/abs/2309.15951v3",
          "size": "155kb",
          "version": "v3"
        }
      ],
      "title": "IEEE 802.11be Wi-Fi 7: Feature Summary and Performance Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.15951",
        "HTML": "https://arxiv.org/html/2309.15951v3",
        "PDF": "https://arxiv.org/pdf/2309.15951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents the features and performance evaluation of Wi-Fi 7, which concerns networking technology and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.05407",
      "abstract": "Unsupervised domain adaptive segmentation typically relies on self-training using pseudo labels predicted by a pre-trained network on an unlabeled target dataset. However, the noisy nature of such pseudo-labels presents a major bottleneck in adapting a network to the distribution shift between source and target datasets. This challenge is exaggerated when the network encounters an incoming data stream in online fashion, where the network is constrained to adapt to incoming streams of target domain data in exactly one round of forward and backward passes. In this scenario, relying solely on inaccurate pseudo-labels can lead to low-quality segmentation, which is detrimental to medical image analysis where accuracy and precision are of utmost priority. We hypothesize that a small amount of pixel-level annotation obtained from an expert can address this problem, thereby enhancing the performance of domain adaptation of online streaming data, even in the absence of dedicated training data. We call our method ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation that adapts to each incoming data batch in an online setup, incorporating feedback from an expert through active learning. Through active learning, the most informative pixels in each image can be selected for expert annotation. However, the acquisition of pixel-level annotations across all images in a batch often leads to redundant information while increasing temporal overhead in online learning. To reduce the annotation acquisition time and make the adaptation process more online-friendly, we further propose a novel image-pruning strategy that selects the most useful subset of images from the current batch for active learning. Our proposed approach outperforms existing online adaptation approaches and produces competitive results compared to offline domain adaptive active learning methods.",
      "authors": [
        "Md Shazid Islam",
        "Sayak Nag",
        "Arindam Dutta",
        "Miraj Ahmed",
        "Fahim Faisal Niloy",
        "Amit K.Roy-Chowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-08T23:43:17+00:00",
          "link": "https://arxiv.org/abs/2312.05407v1",
          "size": "12984kb",
          "version": "v1"
        },
        {
          "date": "2024-10-15T13:27:42+00:00",
          "link": "https://arxiv.org/abs/2312.05407v2",
          "size": "30947kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T20:26:17+00:00",
          "link": "https://arxiv.org/abs/2312.05407v3",
          "size": "4527kb",
          "version": "v3"
        }
      ],
      "title": "ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.05407",
        "HTML": "https://arxiv.org/html/2312.05407v3",
        "PDF": "https://arxiv.org/pdf/2312.05407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses domain adaptation in medical image segmentation using expert guidance. It discusses adaptation strategies in segmentation tasks rather than training data processing for language models."
      },
      "tasks": [
        "Active Learning",
        "Domain Adaptation",
        "Federated Learning",
        "Image Segmentation",
        "Medical Image Analysis",
        "Medical Image Segmentation",
        "Privacy Preserving",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.12102",
      "abstract": "Effectively explaining decisions of black-box machine learning models is critical to responsible deployment of AI systems that rely on them. Recognizing their importance, the field of explainable AI (XAI) provides several techniques to generate these explanations. Yet, there is relatively little emphasis on the user (the explainee) in this growing body of work and most XAI techniques generate \"one-size-fits-all\" explanations. To bridge this gap and achieve a step closer towards human-centered XAI, we present I-CEE, a framework that provides Image Classification Explanations tailored to User Expertise. Informed by existing work, I-CEE explains the decisions of image classification models by providing the user with an informative subset of training data (i.e., example images), corresponding local explanations, and model decisions. However, unlike prior work, I-CEE models the informativeness of the example images to depend on user expertise, resulting in different examples for different users. We posit that by tailoring the example set to user expertise, I-CEE can better facilitate users' understanding and simulatability of the model. To evaluate our approach, we conduct detailed experiments in both simulation and with human participants (N = 100) on multiple datasets. Experiments with simulated users show that I-CEE improves users' ability to accurately predict the model's decisions (simulatability) compared to baselines, providing promising preliminary results. Experiments with human participants demonstrate that our method significantly improves user simulatability accuracy, highlighting the importance of human-centered XAI",
      "authors": [
        "Yao Rong",
        "Peizhu Qian",
        "Vaibhav Unhelkar",
        "Enkelejda Kasneci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-19T12:26:57+00:00",
          "link": "https://arxiv.org/abs/2312.12102v1",
          "size": "2880kb",
          "version": "v1"
        },
        {
          "date": "2024-01-10T15:22:23+00:00",
          "link": "https://arxiv.org/abs/2312.12102v2",
          "size": "2880kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T11:44:19+00:00",
          "link": "https://arxiv.org/abs/2312.12102v3",
          "size": "2861kb",
          "version": "v3"
        }
      ],
      "title": "I-CEE: Tailoring Explanations of Image Classification Models to User Expertise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.12102",
        "HTML": "https://arxiv.org/html/2312.12102v3",
        "PDF": "https://arxiv.org/pdf/2312.12102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for providing tailored explanations for image classification models, focusing on explainability and user expertise, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Informativeness"
      ],
      "repo_urls": [
        "https://github.com/yaorong0921/i-cee"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.01405",
      "abstract": "Do American presidents speak discernibly different from each other? If so, in what ways? And are these differences confined to any single medium of communication? To investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for assessing the distinctive ways in which presidents speak about their political opponents. Applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that Donald Trump's speech patterns diverge from those of all major party nominees for the presidency in recent history. Trump is significantly more distinctive than his fellow Republicans, whose uniqueness values appear closer to those of the Democrats. Contributing to these differences is Trump's employment of divisive and antagonistic language, particularly when targeting his political opponents. These differences hold across a variety of measurement strategies, arise on both the campaign trail and in official presidential addresses, and do not appear to be an artifact of secular changes in presidential communications.",
      "authors": [
        "Karen Zhou",
        "Alexander A. Meitus",
        "Milo Chase",
        "Grace Wang",
        "Anne Mykland",
        "William Howell",
        "Chenhao Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-02T19:00:17+00:00",
          "link": "https://arxiv.org/abs/2401.01405v1",
          "size": "427kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T23:44:10+00:00",
          "link": "https://arxiv.org/abs/2401.01405v2",
          "size": "429kb",
          "version": "v2"
        }
      ],
      "title": "Quantifying the Uniqueness and Divisiveness of Presidential Discourse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01405",
        "HTML": "https://arxiv.org/html/2401.01405v2",
        "PDF": "https://arxiv.org/pdf/2401.01405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a metric based on LLMs to study presidential discourse, but the main focus is on linguistic analysis rather than on training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2401.17256",
      "abstract": "Large language models (LLMs) are vulnerable to jailbreak attacks - resulting in harmful, unethical, or biased text generations. However, existing jailbreaking methods are computationally costly. In this paper, we propose the weak-to-strong jailbreaking attack, an efficient inference time attack for aligned LLMs to produce harmful text. Our key intuition is based on the observation that jailbroken and aligned models only differ in their initial decoding distributions. The weak-to-strong attack's key technical insight is using two smaller models (a safe and an unsafe one) to adversarially modify a significantly larger safe model's decoding probabilities. We evaluate the weak-to-strong attack on 5 diverse open-source LLMs from 3 organizations. The results show our method can increase the misalignment rate to over 99% on two datasets with just one forward pass per example. Our study exposes an urgent safety issue that needs to be addressed when aligning LLMs. As an initial attempt, we propose a defense strategy to protect against such attacks, but creating more advanced defenses remains challenging. The code for replicating the method is available at https://github.com/XuandongZhao/weak-to-strong",
      "authors": [
        "Xuandong Zhao",
        "Xianjun Yang",
        "Tianyu Pang",
        "Chao Du",
        "Lei Li",
        "Yu-Xiang Wang",
        "William Yang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-30T18:48:37+00:00",
          "link": "https://arxiv.org/abs/2401.17256v1",
          "size": "559kb",
          "version": "v1"
        },
        {
          "date": "2024-02-05T18:19:46+00:00",
          "link": "https://arxiv.org/abs/2401.17256v2",
          "size": "2147kb",
          "version": "v2"
        },
        {
          "date": "2025-06-12T17:32:02+00:00",
          "link": "https://arxiv.org/abs/2401.17256v3",
          "size": "277kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T16:36:46+00:00",
          "link": "https://arxiv.org/abs/2401.17256v4",
          "size": "277kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T18:43:18+00:00",
          "link": "https://arxiv.org/abs/2401.17256v5",
          "size": "276kb",
          "version": "v5"
        }
      ],
      "title": "Weak-to-Strong Jailbreaking on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.17256",
        "PDF": "https://arxiv.org/pdf/2401.17256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses vulnerability and defense strategies against jailbreak attacks on LLMs. It focuses on improving model alignment and security, not on data processing for LLM training or the creation of datasets."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/xuandongzhao/weak-to-strong"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.04379",
      "abstract": "We propose fine-tuning large language models for generation of stable materials. While unorthodox, fine-tuning large language models on text-encoded atomistic data is simple to implement yet reliable, with around 90% of sampled structures obeying physical constraints on atom positions and charges. Using energy above hull calculations from both learned ML potentials and gold-standard DFT calculations, we show that our strongest model (fine-tuned LLaMA-2 70B) can generate materials predicted to be metastable at about twice the rate (49% vs 28%) of CDVAE, a competing diffusion model. Because of text prompting's inherent flexibility, our models can simultaneously be used for unconditional generation of stable material, infilling of partial structures and text-conditional generation. Finally, we show that language models' ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data.",
      "authors": [
        "Nate Gruver",
        "Anuroop Sriram",
        "Andrea Madotto",
        "Andrew Gordon Wilson",
        "C. Lawrence Zitnick",
        "Zachary Ulissi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-06T20:35:28+00:00",
          "link": "https://arxiv.org/abs/2402.04379v1",
          "size": "985kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:36:04+00:00",
          "link": "https://arxiv.org/abs/2402.04379v2",
          "size": "984kb",
          "version": "v2"
        }
      ],
      "title": "Fine-Tuned Language Models Generate Stable Inorganic Materials as Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.04379",
        "HTML": "https://arxiv.org/html/2402.04379v2",
        "PDF": "https://arxiv.org/pdf/2402.04379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning LLMs with domain-specific data (atomistic text-encoded data) but does not address broader training data processing operations like data collection or dataset creation for LLMs in general."
      },
      "models": [
        {
          "model_path": "n0w0f/MatText-crystal-txt-llm-2m",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-crystal-txt-llm-2m"
        }
      ],
      "datasets": [
        {
          "dataset_name": "n0w0f/MatText",
          "downloads": "2254",
          "likes": "7",
          "link": "https://huggingface.co/datasets/n0w0f/MatText"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/facebookresearch/crystal-llm",
        "https://github.com/facebookresearch/crystal-text-llm",
        "https://github.com/facebookresearch/flowmm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.12118",
      "abstract": "Deep learning models achieve remarkable performance, yet their decision-making processes often remain opaque. In response, the field of eXplainable Artificial Intelligence (XAI) has grown significantly over the last decade, primarily focusing on feature attribution methods. Complementing this perspective, Data Attribution (DA) has emerged as a promising paradigm that shifts the focus from features to data provenance. However, existing DA approaches suffer from prohibitively high computational costs and memory demands. Additionally, current attribution methods exhibit low sparsity, hindering the discovery of decisive patterns in the data. We introduce DualXDA, a framework for sparse, efficient and explainable DA, comprised of two interlinked approaches for Dual Data Attribution (DualDA) and eXplainable Data Attribution (XDA): With DualDA, we propose efficient and effective DA, leveraging Support Vector Machine theory to provide fast and naturally sparse data attributions for AI predictions. We demonstrate that DualDA achieves high attribution quality, excels at solving a series of evaluated downstream tasks, while at the same time improving explanation time by a factor of up to 4,100,000$\\times$ compared to the original Influence Functions method, and up to 11,000$\\times$ compared to the method's most efficient approximation from literature. We further introduce XDA, a method for enhancing Data Attribution with capabilities from feature attribution methods to explain why training samples are relevant for the prediction of a test sample in terms of impactful features. Taken together, our contributions in DualXDA ultimately point towards a future of eXplainable AI applied at unprecedented scale, enabling transparent, efficient and novel analysis of even the largest neural architectures fostering a new generation of accountable AI systems. Code at https://github.com/gumityolcu/DualXDA.",
      "authors": [
        "Galip \\\"Umit Yolcu",
        "Moritz Weckbecker",
        "Thomas Wiegand",
        "Wojciech Samek",
        "Sebastian Lapuschkin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-19T13:13:16+00:00",
          "link": "https://arxiv.org/abs/2402.12118v1",
          "size": "4005kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:23:53+00:00",
          "link": "https://arxiv.org/abs/2402.12118v2",
          "size": "13776kb",
          "version": "v2"
        }
      ],
      "title": "DualXDA: Towards Sparse, Efficient and Explainable Data Attribution in Large AI Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.12118",
        "HTML": "https://arxiv.org/html/2402.12118v2",
        "PDF": "https://arxiv.org/pdf/2402.12118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concentrates on explainable AI and data attribution for neural predictions, not on data processing techniques or dataset generation for LLM training."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/gumityolcu/dualview_data_attribution_influence_estimation",
        "https://github.com/gumityolcu/dualview"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.02418",
      "abstract": "Gradient descent is commonly used to find minima in rough landscapes, particularly in recent machine learning applications. However, a theoretical understanding of why good solutions are found remains elusive, especially in strongly non-convex and high-dimensional settings. Here, we focus on the phase retrieval problem as a typical example, which has received a lot of attention recently in theoretical machine learning. We analyze the Hessian during gradient descent, identify a dynamical transition in its spectral properties, and relate it to the ability of escaping rough regions in the loss landscape. When the signal-to-noise ratio (SNR) is large enough, an informative negative direction exists in the Hessian at the beginning of the descent, i.e in the initial condition. While descending, a BBP transition in the spectrum takes place in finite time: the direction is lost, and the dynamics is trapped in a rugged region filled with marginally stable bad minima. Surprisingly, for finite system sizes, this window of negative curvature allows the system to recover the signal well before the theoretical SNR found for infinite sizes, emphasizing the central role of initialization and early-time dynamics for efficiently navigating rough landscapes.",
      "authors": [
        "Tony Bonnaire",
        "Giulio Biroli",
        "Chiara Cammarota"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-04T19:12:13+00:00",
          "link": "https://arxiv.org/abs/2403.02418v1",
          "size": "1252kb",
          "version": "v1"
        },
        {
          "date": "2024-09-23T09:00:09+00:00",
          "link": "https://arxiv.org/abs/2403.02418v2",
          "size": "1277kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T09:06:37+00:00",
          "link": "https://arxiv.org/abs/2403.02418v3",
          "size": "1146kb",
          "version": "v3"
        }
      ],
      "title": "The Role of the Time-Dependent Hessian in High-Dimensional Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.02418",
        "HTML": "https://arxiv.org/html/2403.02418v3",
        "PDF": "https://arxiv.org/pdf/2403.02418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on optimization methods in high-dimensional settings, particularly using the Hessian during gradient descent, without contributions to LLM training data processing."
      },
      "tasks": [
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.09554",
      "abstract": "Uninterrupted optical image time series are crucial for the timely monitoring of agricultural land changes, particularly in grasslands. However, the continuity of such time series is often disrupted by clouds. In response to this challenge, we propose an innovative deep learning method that integrates cloud-free optical (Sentinel-2) observations and weather-independent (Sentinel-1) Synthetic Aperture Radar (SAR) data. Our approach employs a hybrid architecture combining Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to generate continuous Normalized Difference Vegetation Index (NDVI) time series, highlighting the role of NDVI in the synergy between SAR and optical data. We demonstrate the significance of observation continuity by assessing the impact of the generated NDVI time series on the downstream task of grassland mowing event detection. We conducted our study in Lithuania, a country characterized by extensive cloud coverage, and compared our approach with alternative interpolation techniques (i.e., linear, Akima, quadratic). Our method outperformed these techniques, achieving an average Mean Absolute Error (MAE) of 0.024 and a coefficient of determination R^2 of 0.92. Additionally, our analysis revealed improvement in the performance of the mowing event detection, with F1-score up to 84% using two widely applied mowing detection methodologies. Our method also effectively mitigated sudden shifts and noise originating from cloudy observations, which are often missed by conventional cloud masks and adversely affect mowing detection precision.",
      "authors": [
        "Iason Tsardanidis",
        "Alkiviadis Koukos",
        "Vasileios Sitokonstantinou",
        "Thanassis Drivas",
        "Charalampos Kontoes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-14T16:41:26+00:00",
          "link": "https://arxiv.org/abs/2403.09554v1",
          "size": "17639kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:04:35+00:00",
          "link": "https://arxiv.org/abs/2403.09554v2",
          "size": "11514kb",
          "version": "v2"
        }
      ],
      "title": "Cloud gap-filling with deep learning for improved grassland monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.09554",
        "HTML": "https://arxiv.org/html/2403.09554v2",
        "PDF": "https://arxiv.org/pdf/2403.09554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a method for cloud gap-filling in optical image time series for grassland monitoring. It does not relate to LLM training data processing or dataset creation for language models."
      },
      "tasks": [
        "Deep Learning",
        "Event Detection",
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/agri-hub/deep-learning-for-cloud-gap-filling-on-normalized-difference-vegetation-index"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.18915",
      "abstract": "Few-shot temporal action localization (TAL) methods that adapt large models via single-prompt tuning often fail to produce precise temporal boundaries. This stems from the model learning a non-discriminative mean representation of an action from sparse data, which compromises generalization. We address this by proposing a new paradigm based on multi-prompt ensembles, where a set of diverse, learnable prompts for each action is encouraged to specialize on compositional sub-events. To enforce this specialization, we introduce PLOT-TAL, a framework that leverages Optimal Transport (OT) to find a globally optimal alignment between the prompt ensemble and the video's temporal features. Our method establishes a new state-of-the-art on the challenging few-shot benchmarks of THUMOS'14 and EPIC-Kitchens, without requiring complex meta-learning. The significant performance gains, particularly at high IoU thresholds, validate our hypothesis and demonstrate the superiority of learning distributed, compositional representations for precise temporal localization.",
      "authors": [
        "Edward Fish and Andrew Gilbert"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-27T18:08:14+00:00",
          "link": "https://arxiv.org/abs/2403.18915v1",
          "size": "2347kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:19:06+00:00",
          "link": "https://arxiv.org/abs/2403.18915v2",
          "size": "2322kb",
          "version": "v2"
        }
      ],
      "title": "PLOT-TAL: Prompt Learning with Optimal Transport for Few-Shot Temporal Action Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.18915",
        "HTML": "https://arxiv.org/html/2403.18915v2",
        "PDF": "https://arxiv.org/pdf/2403.18915"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for few-shot temporal action localization using prompt learning with optimal transport, focusing on model adaptation and ensemble methods for better temporal boundaries, rather than on LLM training data processing."
      },
      "tasks": [
        "Action Localization",
        "Diversity",
        "Few-Shot Learning",
        "Few Shot Temporal Action Localization",
        "Prompt Learning",
        "Temporal Action Localization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.11557",
      "abstract": "This work presents a motion retargeting approach for legged robots, aimed at transferring the dynamic and agile movements to robots from source motions. In particular, we guide the imitation learning procedures by transferring motions from source to target, effectively bridging the morphological disparities while ensuring the physical feasibility of the target system. In the first stage, we focus on motion retargeting at the kinematic level by generating kinematically feasible whole-body motions from keypoint trajectories. Following this, we refine the motion at the dynamic level by adjusting it in the temporal domain while adhering to physical constraints. This process facilitates policy training via reinforcement learning, enabling precise and robust motion tracking. We demonstrate that our approach successfully transforms noisy motion sources, such as hand-held camera videos, into robot-specific motions that align with the morphology and physical properties of the target robots. Moreover, we demonstrate terrain-aware motion retargeting to perform BackFlip on top of a box. We successfully deployed these skills to four robots with different dimensions and physical properties in the real world through hardware experiments.",
      "authors": [
        "Taerim Yoon",
        "Dongho Kang",
        "Seungmin Kim",
        "Jin Cheng",
        "Minsung Ahn",
        "Stelian Coros",
        "and Sungjoon Choi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-17T17:00:26+00:00",
          "link": "https://arxiv.org/abs/2404.11557v1",
          "size": "20300kb",
          "version": "v1"
        },
        {
          "date": "2024-09-23T04:41:58+00:00",
          "link": "https://arxiv.org/abs/2404.11557v2",
          "size": "44694kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:58:42+00:00",
          "link": "https://arxiv.org/abs/2404.11557v3",
          "size": "33732kb",
          "version": "v3"
        }
      ],
      "title": "Spatio-Temporal Motion Retargeting for Quadruped Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.11557",
        "HTML": "https://arxiv.org/html/2404.11557v3",
        "PDF": "https://arxiv.org/pdf/2404.11557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about motion retargeting for legged robots using imitation and reinforcement learning, aiming to adapt dynamic movements, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.14445",
      "abstract": "The rapid advancements in generative AI and large language models (LLMs) have opened up new avenues for producing synthetic data, particularly in the realm of structured tabular formats, such as product reviews. Despite the potential benefits, concerns regarding privacy leakage have surfaced, especially when personal information is utilized in the training datasets. In addition, there is an absence of a comprehensive evaluation framework capable of quantitatively measuring the quality of the generated synthetic data and their utility for downstream tasks. In response to this gap, we introduce SynEval, an open-source evaluation framework designed to assess the fidelity, utility, and privacy preservation of synthetically generated tabular data via a suite of diverse evaluation metrics. We validate the efficacy of our proposed framework - SynEval - by applying it to synthetic product review data generated by three state-of-the-art LLMs: ChatGPT, Claude, and Llama. Our experimental findings illuminate the trade-offs between various evaluation metrics in the context of synthetic data generation. Furthermore, SynEval stands as a critical instrument for researchers and practitioners engaged with synthetic tabular data,, empowering them to judiciously determine the suitability of the generated data for their specific applications, with an emphasis on upholding user privacy.",
      "authors": [
        "Yefeng Yuan",
        "Yuhong Liu",
        "Liang Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-20T08:08:28+00:00",
          "link": "https://arxiv.org/abs/2404.14445v1",
          "size": "235kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T03:19:19+00:00",
          "link": "https://arxiv.org/abs/2404.14445v2",
          "size": "235kb",
          "version": "v2"
        }
      ],
      "title": "A Multi-Faceted Evaluation Framework for Assessing Synthetic Data Generated by Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14445",
        "HTML": "https://arxiv.org/html/2404.14445v2",
        "PDF": "https://arxiv.org/pdf/2404.14445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces SynEval, an evaluation framework for synthetic data generated by LLMs, focusing on evaluating fidelity, utility, and privacy. Although it addresses aspects of synthetic data, the main focus is evaluation, not data processing."
      },
      "tasks": [
        "Synthetic Data Generation"
      ],
      "repo_urls": [
        "https://github.com/yefyuan/syneval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.16243",
      "abstract": "We present \\texttt{muRelBench}, a framework for synthetic benchmarks for weakly-relational abstract domains and their operations. This extensible microbenchmarking framework enables researchers to experimentally evaluate proposed algorithms for numerical abstract domains, such as closure,least-upper bound, and forget, enabling them to quickly prototype and validate performance improvements before considering more intensive experimentation. Additionally, the framework provides mechanisms for checking correctness properties for each of the benchmarks to ensure correctness within the synthetic benchmarks.",
      "authors": [
        "Kenny Ballou and Elena Sherman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-24T23:16:23+00:00",
          "link": "https://arxiv.org/abs/2404.16243v1",
          "size": "198kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T23:00:37+00:00",
          "link": "https://arxiv.org/abs/2404.16243v2",
          "size": "187kb",
          "version": "v2"
        }
      ],
      "title": "muRelBench: MicroBenchmarks for Zonotope Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16243",
        "HTML": "https://arxiv.org/html/2404.16243v2",
        "PDF": "https://arxiv.org/pdf/2404.16243"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a microbenchmarking framework for weakly-relational abstract domains and does not address any aspect of LLM training data processing or data-related improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.03572",
      "abstract": "This paper introduces RoboCar, an open-source research platform for autonomous driving developed at the University of Luxembourg. RoboCar provides a modular, cost-effective framework for the development of experimental Autonomous Driving Systems (ADS), utilizing the 2018 KIA Soul EV. The platform integrates a robust hardware and software architecture that aligns with the vehicle's existing systems, minimizing the need for extensive modifications. It supports various autonomous driving functions and has undergone real-world testing on public roads in Luxembourg City. This paper outlines the platform's architecture, integration challenges, and initial test results, offering insights into its application in advancing autonomous driving research. RoboCar is available to anyone at https://github.com/sntubix/robocar and is released under an open-source MIT license.",
      "authors": [
        "Mehdi Testouri",
        "Gamal Elghazaly",
        "Raphael Frank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-06T15:48:14+00:00",
          "link": "https://arxiv.org/abs/2405.03572v1",
          "size": "16850kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:30:54+00:00",
          "link": "https://arxiv.org/abs/2405.03572v2",
          "size": "12607kb",
          "version": "v2"
        }
      ],
      "title": "RoboCar: A Rapidly Deployable Open-Source Platform for Autonomous Driving Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.03572",
        "HTML": "https://arxiv.org/html/2405.03572v2",
        "PDF": "https://arxiv.org/pdf/2405.03572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces RoboCar, a platform for autonomous driving research. It does not involve any aspects of LLM pretraining or fine-tuning data processing."
      },
      "repo_urls": [
        "https://github.com/sntubix/robocar"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.06995",
      "abstract": "Automated deception detection is crucial for assisting humans in accurately assessing truthfulness and identifying deceptive behavior. Conventional contact-based techniques, like polygraph devices, rely on physiological signals to determine the authenticity of an individual's statements. Nevertheless, recent developments in automated deception detection have demonstrated that multimodal features derived from both audio and video modalities may outperform human observers on publicly available datasets. Despite these positive findings, the generalizability of existing audio-visual deception detection approaches across different scenarios remains largely unexplored. To close this gap, we present the first cross-domain audio-visual deception detection benchmark, that enables us to assess how well these methods generalize for use in real-world scenarios. We used widely adopted audio and visual features and different architectures for benchmarking, comparing single-to-single and multi-to-single domain generalization performance. To further exploit the impacts using data from multiple source domains for training, we investigate three types of domain sampling strategies, including domain-simultaneous, domain-alternating, and domain-by-domain for multi-to-single domain generalization evaluation. We also propose an algorithm to enhance the generalization performance by maximizing the gradient inner products between modality encoders, named ``MM-IDGM\". Furthermore, we proposed the Attention-Mixer fusion method to improve performance, and we believe that this new cross-domain benchmark will facilitate future research in audio-visual deception detection.",
      "authors": [
        "Xiaobao Guo",
        "Zitong Yu",
        "Nithish Muthuchamy Selvaraj",
        "Bingquan Shen",
        "Adams Wai-Kin Kong",
        "and Alex C. Kot"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-11T12:06:31+00:00",
          "link": "https://arxiv.org/abs/2405.06995v1",
          "size": "4247kb",
          "version": "v1"
        },
        {
          "date": "2024-10-05T07:32:03+00:00",
          "link": "https://arxiv.org/abs/2405.06995v2",
          "size": "5348kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T03:00:38+00:00",
          "link": "https://arxiv.org/abs/2405.06995v3",
          "size": "2907kb",
          "version": "v3"
        }
      ],
      "title": "Benchmarking Cross-Domain Audio-Visual Deception Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.06995",
        "HTML": "https://arxiv.org/html/2405.06995v3",
        "PDF": "https://arxiv.org/pdf/2405.06995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on cross-domain audio-visual deception detection, which does not relate to LLM training data processing or improvement strategies."
      },
      "tasks": [
        "Benchmarking",
        "Deception Detection",
        "Domain Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.12312",
      "abstract": "The widespread use of machine learning and data-driven algorithms for decision making has been steadily increasing over many years. \\emph{Bias} in the data can adversely affect this decision-making. We present a new mitigation strategy to address data bias. Our methods are explainable and come with mathematical guarantees of correctness. They can take advantage of new work on table discovery to find new tuples that can be added to a dataset to create real datasets that are unbiased or less biased. Our framework covers data with non-binary labels and with multiple sensitive attributes. Hence, we are able to measure and mitigate bias that does not appear over a single attribute (or feature), but only intersectionally, when considering a combination of attributes. We evaluate our techniques on publicly available datasets and provide a theoretical analysis of our results, highlighting novel insights into data bias.",
      "authors": [
        "Bruno Scarone",
        "Alfredo Viola",
        "Ren\\'ee J. Miller",
        "Ricardo Baeza-Yates"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T18:14:33+00:00",
          "link": "https://arxiv.org/abs/2405.12312v1",
          "size": "2518kb",
          "version": "v1"
        },
        {
          "date": "2024-09-10T20:35:29+00:00",
          "link": "https://arxiv.org/abs/2405.12312v2",
          "size": "461kb",
          "version": "v2"
        },
        {
          "date": "2024-11-01T20:45:41+00:00",
          "link": "https://arxiv.org/abs/2405.12312v3",
          "size": "461kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T05:01:33+00:00",
          "link": "https://arxiv.org/abs/2405.12312v4",
          "size": "376kb",
          "version": "v4"
        }
      ],
      "title": "A Principled Approach for Data Bias Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.12312",
        "HTML": "https://arxiv.org/html/2405.12312v4",
        "PDF": "https://arxiv.org/pdf/2405.12312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses data bias mitigation and improving data quality, it does not specifically target LLM training data processing, making its contribution peripheral."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.03674",
      "abstract": "We study the bidding problem in repeated uniform price multi-unit auctions from the perspective of a value-maximizing buyer. The buyer aims to maximize their cumulative value over $T$ rounds while adhering to per-round return-on-investment (RoI) constraints in a strategic (or adversarial) environment. Using an $m$-uniform bidding format, the buyer submits $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid $b_i$, with $m \\ll M$ in practice, where $M$ denotes the maximum demand of the buyer.\n  We introduce the notion of safe bidding strategies as those that satisfy the RoI constraints irrespective of competing bids. Despite the stringent requirement, we show that these strategies satisfy a mild no-overbidding condition, depend only on the valuation curve of the bidder, and the bidder can focus on a finite subset without loss of generality. Though the subset size is $O(M^m)$, we design a polynomial-time learning algorithm that achieves sublinear regret, both in full-information and bandit settings, relative to the hindsight-optimal safe strategy.\n  We assess the robustness of safe strategies against the hindsight-optimal strategy from a richer class. We define the richness ratio $\\alpha \\in (0,1]$ as the minimum ratio of the value of the optimal safe strategy to that of the optimal strategy from richer class and construct hard instances showing the tightness of $\\alpha$. Our algorithm achieves $\\alpha$-approximate sublinear regret against these stronger benchmarks. Simulations on semi-synthetic auction data show that empirical richness ratios significantly outperform the theoretical worst-case bounds. The proposed safe strategies and learning algorithm extend naturally to more nuanced buyer and competitor models.",
      "authors": [
        "Negin Golrezaei and Sourav Sahoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-06T01:29:47+00:00",
          "link": "https://arxiv.org/abs/2406.03674v1",
          "size": "581kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T04:35:29+00:00",
          "link": "https://arxiv.org/abs/2406.03674v2",
          "size": "1320kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T21:09:41+00:00",
          "link": "https://arxiv.org/abs/2406.03674v3",
          "size": "1030kb",
          "version": "v3"
        }
      ],
      "title": "Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03674",
        "HTML": "https://arxiv.org/html/2406.03674v3",
        "PDF": "https://arxiv.org/pdf/2406.03674"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the strategy for buyers in uniform price auctions and does not focus on training data processing for LLMs, nor does it contribute to data preprocessing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.12548",
      "abstract": "Personalized large language models (LLMs) have attracted great attention in many applications, such as emotional support and role-playing. However, existing works primarily focus on modeling explicit character profiles, while ignoring the underlying personality traits that truly shape behaviors and decision-making, hampering the development of more anthropomorphic and psychologically-grounded AI systems. In this paper, we explore the modeling of Big Five personality traits, which is the most widely used trait theory in psychology, and propose P-React, a mixture of experts (MoE)-based personalized LLM. Particularly, we integrate a Personality Specialization Loss (PSL) to better capture individual trait expressions, providing a more nuanced and psychologically grounded personality simulacrum. To facilitate research in this field, we curate OCEAN-Chat, a high-quality, human-verified dataset designed to train LLMs in expressing personality traits across diverse topics. Extensive experiments demonstrate the effectiveness of P-React in maintaining consistent and real personality.",
      "authors": [
        "Yuhao Dan",
        "Jie Zhou",
        "Qin Chen",
        "Junfeng Tian",
        "Liang He"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-18T12:25:13+00:00",
          "link": "https://arxiv.org/abs/2406.12548v1",
          "size": "768kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T04:02:00+00:00",
          "link": "https://arxiv.org/abs/2406.12548v2",
          "size": "707kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T16:54:18+00:00",
          "link": "https://arxiv.org/abs/2406.12548v3",
          "size": "707kb",
          "version": "v3"
        }
      ],
      "title": "P-React: Synthesizing Topic-Adaptive Reactions of Personality Traits via Mixture of Specialized LoRA Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.12548",
        "HTML": "https://arxiv.org/html/2406.12548v3",
        "PDF": "https://arxiv.org/pdf/2406.12548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper discusses the creation of the OCEAN-Chat dataset, the main focus is on modeling personality traits in LLMs through the newly proposed P-React model. The dataset creation aspect is a supporting element rather than the main contribution."
      },
      "tasks": [
        "Mixture-of-Experts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.17813",
      "abstract": "Concept drift is the phenomenon in which the underlying data distributions and statistical properties of a target domain change over time, leading to a degradation in model performance. Consequently, production models require continuous drift detection monitoring. Most drift detection methods to date are supervised, relying on ground-truth labels. However, they are inapplicable in many real-world scenarios, as true labels are often unavailable. Although recent efforts have proposed unsupervised drift detectors, many lack the accuracy required for reliable detection or are too computationally intensive for real-time use in high-dimensional, large-scale production environments. Moreover, they often fail to characterize or explain drift effectively.\n  To address these limitations, we propose \\textsc{DriftLens}, an unsupervised framework for real-time concept drift detection and characterization. Designed for deep learning classifiers handling unstructured data, \\textsc{DriftLens} leverages distribution distances in deep learning representations to enable efficient and accurate detection. Additionally, it characterizes drift by analyzing and explaining its impact on each label. Our evaluation across classifiers and data-types demonstrates that \\textsc{DriftLens} (i) outperforms previous methods in detecting drift in 15/17 use cases; (ii) runs at least 5 times faster; (iii) produces drift curves that align closely with actual drift (correlation $\\geq\\!0.85$); (iv) effectively identifies representative drift samples as explanations.",
      "authors": [
        "Salvatore Greco",
        "Bartolomeo Vacchetti",
        "Daniele Apiletti",
        "Tania Cerquitelli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-24T23:41:46+00:00",
          "link": "https://arxiv.org/abs/2406.17813v1",
          "size": "7664kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:10:45+00:00",
          "link": "https://arxiv.org/abs/2406.17813v2",
          "size": "28618kb",
          "version": "v2"
        }
      ],
      "title": "Unsupervised Concept Drift Detection from Deep Learning Representations in Real-time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17813",
        "HTML": "https://arxiv.org/html/2406.17813v2",
        "PDF": "https://arxiv.org/pdf/2406.17813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses concept drift detection in deep learning representations, focusing on unsupervised methods for drift detection rather than LLM training data processing or dataset development."
      },
      "tasks": [
        "Drift Detection"
      ],
      "repo_urls": [
        "https://github.com/grecosalvatore/drift-lens"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.17929",
      "abstract": "We study the problems of data compression, gambling and prediction of a sequence $x^n=x_1x_2...x_n$ from an alphabet ${\\cal X}$, in terms of regret and expected regret (redundancy) with respect to various smooth families of probability distributions. We evaluate the regret of Bayes mixture distributions compared to maximum likelihood, under the condition that the maximum likelihood estimate is in the interior of the parameter space. For general exponential families (including the non-i.i.d.\\ case) the asymptotically mimimax value is achieved when variants of the prior of Jeffreys are used. %under the condition that the maximum likelihood estimate is in the interior of the parameter space. Interestingly, we also obtain a modification of Jeffreys prior which has measure outside the given family of densities, to achieve minimax regret with respect to non-exponential type families. This modification enlarges the family using local exponential tilting (a fiber bundle). Our conditions are confirmed for certain non-exponential families, including curved families and mixture families (where either the mixture components or their weights of combination are parameterized) as well as contamination models. Furthermore for mixture families we show how to deal with the full simplex of parameters. These results also provide characterization of Rissanen's stochastic complexity.",
      "authors": [
        "Jun'ichi Takeuchi and Andrew R. Barron"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T20:40:52+00:00",
          "link": "https://arxiv.org/abs/2406.17929v1",
          "size": "170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:34:40+00:00",
          "link": "https://arxiv.org/abs/2406.17929v2",
          "size": "172kb",
          "version": "v2"
        }
      ],
      "title": "Asymptotically Minimax Regret by Bayes Mixtures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17929",
        "HTML": "https://arxiv.org/html/2406.17929v2",
        "PDF": "https://arxiv.org/pdf/2406.17929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on data compression, gambling, and prediction using Bayes mixture distributions and does not address LLM training data processing or dataset creation for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.02075",
      "abstract": "We present Label Anything, an innovative neural network architecture designed for few-shot semantic segmentation (FSS) that demonstrates remarkable generalizability across multiple classes with minimal examples required per class. Diverging from traditional FSS methods that predominantly rely on masks for annotating support images, Label Anything introduces varied visual prompts -- points, bounding boxes, and masks -- thereby enhancing the framework's versatility and adaptability. Unique to our approach, Label Anything is engineered for end-to-end training across multi-class FSS scenarios, efficiently learning from diverse support set configurations without retraining. This approach enables a \"universal\" application to various FSS challenges, ranging from $1$-way $1$-shot to complex $N$-way $K$-shot configurations while remaining agnostic to the specific number of class examples. This innovative training strategy reduces computational requirements and substantially improves the model's adaptability and generalization across diverse segmentation tasks. Our comprehensive experimental validation, particularly achieving state-of-the-art results on the COCO-$20^i$ benchmark, underscores Label Anything's robust generalization and flexibility. The source code is publicly available at: https://github.com/pasqualedem/LabelAnything.",
      "authors": [
        "Pasquale De Marinis",
        "Nicola Fanelli",
        "Raffaele Scaringi",
        "Emanuele Colonna",
        "Giuseppe Fiameni",
        "Gennaro Vessio and Giovanna Castellano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-02T09:08:06+00:00",
          "link": "https://arxiv.org/abs/2407.02075v1",
          "size": "45572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T10:46:04+00:00",
          "link": "https://arxiv.org/abs/2407.02075v2",
          "size": "15354kb",
          "version": "v2"
        }
      ],
      "title": "Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02075",
        "HTML": "https://arxiv.org/html/2407.02075v2",
        "PDF": "https://arxiv.org/pdf/2407.02075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a novel neural network architecture for few-shot semantic segmentation using visual prompts but does not contribute to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Few-Shot Semantic Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/pasqualedem/LabelAnything"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.09261",
      "abstract": "This paper presents the open-source stochastic model predictive control framework GRAMPC-S for nonlinear uncertain systems with chance constraints. It provides several uncertainty propagation methods to predict stochastic moments of the system state and can consider unknown parts of the system dynamics using Gaussian process regression. These methods are used to reformulate a stochastic MPC formulation as a deterministic one that is solved with GRAMPC. The performance of the presented framework is evaluated using examples from a wide range of technical areas. The experimental evaluation shows that GRAMPC-S can be used in practice for the control of nonlinear uncertain systems with sampling times in the millisecond range.",
      "authors": [
        "Daniel Landgraf",
        "Andreas V\\\"olz",
        "Knut Graichen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-12T13:43:19+00:00",
          "link": "https://arxiv.org/abs/2407.09261v1",
          "size": "300kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:29:14+00:00",
          "link": "https://arxiv.org/abs/2407.09261v2",
          "size": "300kb",
          "version": "v2"
        }
      ],
      "title": "A software framework for stochastic model predictive control of nonlinear continuous-time systems (GRAMPC-S)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09261",
        "PDF": "https://arxiv.org/pdf/2407.09261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a software framework for stochastic model predictive control and does not relate to LLM training data processing or operations such as data filtering or generation."
      },
      "tasks": [
        "Model Predictive Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.09468",
      "abstract": "The enduring legacy of Euclidean geometry underpins classical machine learning, which, for decades, has been primarily developed for data lying in Euclidean space. Yet, modern machine learning increasingly encounters richly structured data that is inherently nonEuclidean. This data can exhibit intricate geometric, topological and algebraic structure: from the geometry of the curvature of space-time, to topologically complex interactions between neurons in the brain, to the algebraic transformations describing symmetries of physical systems. Extracting knowledge from such non-Euclidean data necessitates a broader mathematical perspective. Echoing the 19th-century revolutions that gave rise to non-Euclidean geometry, an emerging line of research is redefining modern machine learning with non-Euclidean structures. Its goal: generalizing classical methods to unconventional data types with geometry, topology, and algebra. In this review, we provide an accessible gateway to this fast-growing field and propose a graphical taxonomy that integrates recent advances into an intuitive unified framework. We subsequently extract insights into current challenges and highlight exciting opportunities for future development in this field.",
      "authors": [
        "Mathilde Papillon",
        "Sophia Sanborn",
        "Johan Mathe",
        "Louisa Cornelis",
        "Abby Bertics",
        "Domas Buracas",
        "Hansen J Lillemark",
        "Christian Shewmake",
        "Fatih Dinc",
        "Xavier Pennec",
        "Nina Miolane"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-12T17:48:36+00:00",
          "link": "https://arxiv.org/abs/2407.09468v1",
          "size": "39167kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:41:43+00:00",
          "link": "https://arxiv.org/abs/2407.09468v2",
          "size": "44109kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09468",
        "HTML": "https://arxiv.org/html/2407.09468v2",
        "PDF": "https://arxiv.org/pdf/2407.09468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This review paper explores machine learning with geometric, topological, and algebraic structures but does not involve LLM training data processing or any related dataset operations."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/zhaoolee/garss"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.13066",
      "abstract": "We present an efficient and scalable algorithm for performing matrix-vector multiplications (\"matvecs\") for block Toeplitz matrices. Such matrices, which are shift-invariant with respect to their blocks, arise in the context of solving inverse problems governed by autonomous systems, and time-invariant systems in particular. In this article, we consider inverse problems that infer unknown parameters from observational data of a linear time-invariant dynamical system given in the form of partial differential equations (PDEs). Matrix-free Newton-conjugate-gradient methods are often the gold standard for solving these inverse problems, but they require numerous actions of the Hessian on a vector. Matrix-free adjoint-based Hessian matvecs require solution of a pair of linearized forward/adjoint PDE solves per Hessian action, which may be prohibitive for large-scale inverse problems. Time invariance of the forward PDE problem leads to a block Toeplitz structure of the discretized parameter-to-observable (p2o) map defining the mapping from inputs (parameters) to outputs (observables) of the PDEs. This block Toeplitz structure enables us to exploit two key properties: (1) compact storage of the p2o map and its adjoint; and (2) efficient fast Fourier transform (FFT)-based Hessian matvecs. The proposed algorithm is mapped onto large multi-GPU clusters and achieves more than 80 percent of peak bandwidth on NVIDIA A100 GPUs. Excellent weak scaling is shown for up to 48 A100 GPUs. For the targeted problems, the implementation executes Hessian matvecs within fractions of a second, which is orders of magnitude faster than can be achieved by conventional matrix-free Hessian matvecs via forward/adjoint PDE solves.",
      "authors": [
        "Sreeram Venkat",
        "Milinda Fernando",
        "Stefan Henneking",
        "Omar Ghattas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-18T00:23:38+00:00",
          "link": "https://arxiv.org/abs/2407.13066v1",
          "size": "299kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T21:34:52+00:00",
          "link": "https://arxiv.org/abs/2407.13066v2",
          "size": "53kb",
          "version": "v2"
        }
      ],
      "title": "Fast And Scalable FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices With Application to Linear Inverse Problems Governed by Autonomous Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.13066",
        "PDF": "https://arxiv.org/pdf/2407.13066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses FFT-based GPU-accelerated algorithms for specific matrix operations in the context of solving inverse problems in dynamical systems, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.19795",
      "abstract": "Domain generalizability is a crucial aspect of a deep learning model since it determines the capability of the model to perform well on data from unseen domains. However, research on the domain generalizability of deep learning models for vision-language tasks remains limited, primarily because of the lack of required datasets. To address these challenges, we propose VolDoGer: Vision-Language Dataset for Domain Generalization, a dedicated dataset designed for domain generalization that addresses three vision-language tasks: image captioning, visual question answering, and visual entailment. We constructed VolDoGer by extending LLM-based data annotation techniques to vision-language tasks, thereby alleviating the burden of recruiting human annotators. We evaluated the domain generalizability of various models, ranging from fine-tuned models to a recent multimodal large language model, through VolDoGer.",
      "authors": [
        "Juhwan Choi",
        "Junehyoung Kwon",
        "JungMin Yun",
        "Seunguk Yu",
        "YoungBin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T08:38:46+00:00",
          "link": "https://arxiv.org/abs/2407.19795v1",
          "size": "5848kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:08:59+00:00",
          "link": "https://arxiv.org/abs/2407.19795v2",
          "size": "2704kb",
          "version": "v2"
        }
      ],
      "title": "VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19795",
        "HTML": "https://arxiv.org/html/2407.19795v2",
        "PDF": "https://arxiv.org/pdf/2407.19795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces VolDoGer, a dataset for domain generalization in vision-language tasks, employing LLM-based data annotation techniques. It contributes to dataset creation and enhances data processing methods important for training LLMs."
      },
      "tasks": [
        "Deep Learning",
        "Domain Generalization",
        "Image Captioning",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Multimodal Large Language Model",
        "Question Answering",
        "Visual Entailment",
        "Visual Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.00970",
      "abstract": "Multimodal emotion recognition in conversation (MERC) seeks to identify the speakers' emotions expressed in each utterance, offering significant potential across diverse fields. The challenge of MERC lies in balancing speaker modeling and context modeling, encompassing both long-distance and short-distance contexts, as well as addressing the complexity of multimodal information fusion. Recent research adopts graph-based methods to model intricate conversational relationships effectively. Nevertheless, the majority of these methods utilize a fixed fully connected structure to link all utterances, relying on convolution to interpret complex context. This approach can inherently heighten the redundancy in contextual messages and excessive graph network smoothing, particularly in the context of long-distance conversations. To address this issue, we propose a framework that dynamically adjusts hypergraph connections by variational hypergraph autoencoder (VHGAE), and employs contrastive learning to mitigate uncertainty factors during the reconstruction process. Experimental results demonstrate the effectiveness of our proposal against the state-of-the-art methods on IEMOCAP and MELD datasets. We release the code to support the reproducibility of this work at https://github.com/yzjred/-HAUCL.",
      "authors": [
        "Zijian Yi",
        "Ziming Zhao",
        "Zhishu Shen",
        "Tiehua Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T01:30:18+00:00",
          "link": "https://arxiv.org/abs/2408.00970v1",
          "size": "3936kb",
          "version": "v1"
        },
        {
          "date": "2024-09-26T03:56:00+00:00",
          "link": "https://arxiv.org/abs/2408.00970v2",
          "size": "2838kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T02:27:58+00:00",
          "link": "https://arxiv.org/abs/2408.00970v3",
          "size": "2137kb",
          "version": "v3"
        }
      ],
      "title": "Multimodal Fusion via Hypergraph Autoencoder and Contrastive Learning for Emotion Recognition in Conversation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00970",
        "HTML": "https://arxiv.org/html/2408.00970v3",
        "PDF": "https://arxiv.org/pdf/2408.00970"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for multimodal emotion recognition in conversations using hypergraph autoencoders and contrastive learning, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.01162",
      "abstract": "Multiple instance learning (MIL) has emerged as a powerful framework for weakly supervised whole slide image (WSI) classification, enabling slide-level predictions without requiring detailed patch-level annotations. Despite its success, a critical limitation of current MIL methods lies in the underutilization of pre-training for the MIL aggregator. Most existing approaches initialize the aggregator randomly and train it from scratch, making performance highly sensitive to the quantity of labeled WSIs and ignoring the abundance of unlabeled WSIs commonly available in clinical settings. To address this, we propose PreMix, a novel framework that leverages a non-contrastive pre-training method, Barlow Twins, augmented with the Slide Mixing approach to generate additional positive pairs and enhance feature learning, particularly under limited labeled WSI conditions. Fine-tuning with Mixup and Manifold Mixup further enhances robustness by effectively handling the diverse sizes of gigapixel WSIs. Experimental results demonstrate that integrating PreMix as a plug-in module into HIPT yields an average F1 improvement of 4.7% over the baseline HIPT across various WSI training sizes and datasets. These findings underscore its potential to advance WSI classification with limited labeled data and its applicability to real-world histopathology practices. The code is available at https://github.com/bryanwong17/PreMix",
      "authors": [
        "Bryan Wong",
        "Mun Yong Yi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T10:24:35+00:00",
          "link": "https://arxiv.org/abs/2408.01162v1",
          "size": "6509kb",
          "version": "v1"
        },
        {
          "date": "2025-01-24T04:42:06+00:00",
          "link": "https://arxiv.org/abs/2408.01162v2",
          "size": "6507kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T03:53:21+00:00",
          "link": "https://arxiv.org/abs/2408.01162v3",
          "size": "5160kb",
          "version": "v3"
        }
      ],
      "title": "PreMix: Label-Efficient Multiple Instance Learning via Non-Contrastive Pre-training and Feature Mixing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01162",
        "HTML": "https://arxiv.org/html/2408.01162v3",
        "PDF": "https://arxiv.org/pdf/2408.01162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on multiple instance learning for image classification, employing pre-training techniques which do not relate to training data processing for LLMs."
      },
      "tasks": [
        "Active Learning",
        "image-classification",
        "Image Classification",
        "Multiple Instance Learning",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.05330",
      "abstract": "We address the problem of machine unlearning in neural information retrieval (IR), introducing a novel task termed Neural Machine UnRanking (NuMuR). This problem is motivated by growing demands for data privacy compliance and selective information removal in neural IR systems. Existing task- or model- agnostic unlearning approaches, primarily designed for classification tasks, are suboptimal for NuMuR due to two core challenges: (1) neural rankers output unnormalised relevance scores rather than probability distributions, limiting the effectiveness of traditional teacher-student distillation frameworks; and (2) entangled data scenarios, where queries and documents appear simultaneously across both forget and retain sets, may degrade retention performance in existing methods. To address these issues, we propose Contrastive and Consistent Loss (CoCoL), a dual-objective framework. CoCoL comprises (1) a contrastive loss that reduces relevance scores on forget sets while maintaining performance on entangled samples, and (2) a consistent loss that preserves accuracy on retain set. Extensive experiments on MS MARCO and TREC CAR datasets, across four neural IR models, demonstrate that CoCoL achieves substantial forgetting with minimal retain and generalisation performance loss. Our method facilitates more effective and controllable data removal than existing techniques.",
      "authors": [
        "Jingrui Hou and Axel Finke and Georgina Cosma"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-09T20:36:40+00:00",
          "link": "https://arxiv.org/abs/2408.05330v1",
          "size": "359kb",
          "version": "v1"
        },
        {
          "date": "2024-08-22T02:48:34+00:00",
          "link": "https://arxiv.org/abs/2408.05330v2",
          "size": "359kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T04:02:17+00:00",
          "link": "https://arxiv.org/abs/2408.05330v3",
          "size": "258kb",
          "version": "v3"
        }
      ],
      "title": "Neural Machine Unranking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05330",
        "HTML": "https://arxiv.org/html/2408.05330v3",
        "PDF": "https://arxiv.org/pdf/2408.05330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Neural Machine Unranking for neural information retrieval, focusing on data privacy and selective information removal, without contributing to LLM training data processing or dataset engineering."
      },
      "tasks": [
        "Information Retrieval",
        "Machine Unlearning",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/jingruihou/numur"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.10450",
      "abstract": "This paper presents Rummaging Using Mutual Information (RUMI), a method for online generation of robot action sequences to gather information about the pose of a known movable object in visually-occluded environments. Focusing on contact-rich rummaging, our approach leverages mutual information between the object pose distribution and robot trajectory for action planning. From an observed partial point cloud, RUMI deduces the compatible object pose distribution and approximates the mutual information of it with workspace occupancy in real time. Based on this, we develop an information gain cost function and a reachability cost function to keep the object within the robot's reach. These are integrated into a model predictive control (MPC) framework with a stochastic dynamics model, updating the pose distribution in a closed loop. Key contributions include a new belief framework for object pose estimation, an efficient information gain computation strategy, and a robust MPC-based control scheme. RUMI demonstrates superior performance in both simulated and real tasks compared to baseline methods.",
      "authors": [
        "Sheng Zhong",
        "Nima Fazeli",
        "Dmitry Berenson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-19T23:16:18+00:00",
          "link": "https://arxiv.org/abs/2408.10450v1",
          "size": "7803kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:51:36+00:00",
          "link": "https://arxiv.org/abs/2408.10450v2",
          "size": "5947kb",
          "version": "v2"
        }
      ],
      "title": "RUMI: Rummaging Using Mutual Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10450",
        "HTML": "https://arxiv.org/html/2408.10450v2",
        "PDF": "https://arxiv.org/pdf/2408.10450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on generating robot action sequences using mutual information for pose estimation, which is unrelated to LLM training data processing or creating datasets for language models."
      },
      "tasks": [
        "Model Predictive Control",
        "Object",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/um-arm-lab/pytorch_mppi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.10610",
      "abstract": "We revisit an old problem related to Autoregressive Moving Average (ARMA) models, on quantifying and bounding the approximation error between a true stationary process $X_t$ and an ARMA model $Y_t$. We take the transfer function representation of an ARMA model and show that the associated $L^{\\infty}$ norm provides a valid alternate norm that controls the $L^2$ norm and has structural properties comparable to the cepstral norm. We show that a certain subspace of stationary processes, which includes ARMA models, forms a Banach algebra under the $L^{\\infty}$ norm that respects the group structure of $H^{\\infty}$ transfer functions. The natural definition of invertibility in this algebra is consistent with the original definition of ARMA invertibility, and generalizes better to non-ARMA processes than Wiener's $\\ell^1$ condition. Finally, we calculate some explicit approximation bounds in the simpler context of continuous transfer functions, and critique some heuristic ideas on Pad\\'e approximations and parsimonious models.",
      "authors": [
        "Anand Ganesh",
        "Babhrubahan Bose",
        "Anand Rajagopalan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T07:42:42+00:00",
          "link": "https://arxiv.org/abs/2408.10610v1",
          "size": "279kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T11:03:26+00:00",
          "link": "https://arxiv.org/abs/2408.10610v2",
          "size": "284kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T06:00:26+00:00",
          "link": "https://arxiv.org/abs/2408.10610v3",
          "size": "58kb",
          "version": "v3"
        }
      ],
      "title": "On the Approximation of Stationary Processes using the ARMA Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10610",
        "HTML": "https://arxiv.org/html/2408.10610v3",
        "PDF": "https://arxiv.org/pdf/2408.10610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the approximation of stationary processes with ARMA models without any direct relation to LLM training data processing or dataset creation aimed at enhancing language models."
      },
      "tasks": [
        "LEMMA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.12635",
      "abstract": "The number of possible melodies is unfathomably large, yet despite this virtually unlimited potential for melodic variation, melodies from different societies can be surprisingly similar. The motor constraint hypothesis accounts for certain similarities, such as scalar motion and contour shape, but not for other major common features, such as repetition, song length, and scale size. Here we investigate the role of information constraints in shaping these hallmarks of melodies. We measure determinants of information rate in 62 corpora of Folk melodies spanning several continents, finding multiple trade-offs that all act to constrain the information rate across societies. By contrast, 39 corpora of Art music from Europe (including Turkey) show longer, more complex melodies, and increased complexity over time, suggesting different cultural-evolutionary selection pressures in Art and Folk music, possibly due to the use of written versus oral transmission. Our parameter-free model predicts the empirical scale degree distribution using information constraints on scalar motion, melody length, and, most importantly, information rate. These results provide strong evidence that information constraints during cultural transmission of music limit the number of notes in a scale, and suggests that a tendency for intermediate melodic complexity reflects a fundamental constraint on the cultural evolution of melody.",
      "authors": [
        "John M McBride",
        "Nahie Kim",
        "Yuri Nishikawa",
        "Mekhmed Saadakeev",
        "Marcus T Pearce",
        "Tsvi Tlusty"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Information Theory (cs.IT)",
        "Audio and Speech Processing (eess.AS)",
        "Information Theory (math.IT)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T14:33:11+00:00",
          "link": "https://arxiv.org/abs/2408.12635v1",
          "size": "7206kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T00:35:19+00:00",
          "link": "https://arxiv.org/abs/2408.12635v2",
          "size": "7485kb",
          "version": "v2"
        },
        {
          "date": "2025-06-23T09:17:03+00:00",
          "link": "https://arxiv.org/abs/2408.12635v3",
          "size": "6818kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T10:29:34+00:00",
          "link": "https://arxiv.org/abs/2408.12635v4",
          "size": "6895kb",
          "version": "v4"
        }
      ],
      "title": "Information and motor constraints shape melodic diversity across cultures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.12635",
        "HTML": "https://arxiv.org/html/2408.12635v4",
        "PDF": "https://arxiv.org/pdf/2408.12635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores melodic diversity across cultures and discusses information and motor constraints in music, which does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.14672",
      "abstract": "State-of-the-art semantic segmentation models are typically optimized in a data-driven fashion, minimizing solely per-pixel or per-segment classification objectives on their training data. This purely data-driven paradigm often leads to absurd segmentations, especially when the domain of input images is shifted from the one encountered during training. For instance, state-of-the-art models may assign the label \"road\" to a segment that is included by another segment that is respectively labeled as \"sky\". However, the ground truth of the existing dataset at hand dictates that such inclusion is not feasible. Our method, Infeasible Semantic Inclusions (InSeIn), first extracts explicit inclusion constraints that govern spatial class relations from the semantic segmentation training set at hand in an offline, data-driven fashion, and then enforces a morphological yet differentiable loss that penalizes violations of these constraints during training to promote prediction feasibility. InSeIn is a light-weight plug-and-play method, constitutes a novel step towards minimizing infeasible semantic inclusions in the predictions of learned segmentation models, and yields consistent and significant performance improvements over diverse state-of-the-art networks across the ADE20K, Cityscapes, and ACDC datasets. https://github.com/SHAMIK-97/InSeIn/tree/main",
      "authors": [
        "Shamik Basu",
        "Luc Van Gool",
        "Christos Sakaridis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-26T22:39:08+00:00",
          "link": "https://arxiv.org/abs/2408.14672v1",
          "size": "29444kb",
          "version": "v1"
        },
        {
          "date": "2024-09-11T17:26:06+00:00",
          "link": "https://arxiv.org/abs/2408.14672v2",
          "size": "29444kb",
          "version": "v2"
        },
        {
          "date": "2025-01-19T19:03:04+00:00",
          "link": "https://arxiv.org/abs/2408.14672v3",
          "size": "23123kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T17:16:41+00:00",
          "link": "https://arxiv.org/abs/2408.14672v4",
          "size": "22096kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T06:22:40+00:00",
          "link": "https://arxiv.org/abs/2408.14672v5",
          "size": "22095kb",
          "version": "v5"
        }
      ],
      "title": "Optimizing against Infeasible Inclusions from Data for Semantic Segmentation through Morphology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.14672",
        "HTML": "https://arxiv.org/html/2408.14672v5",
        "PDF": "https://arxiv.org/pdf/2408.14672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on semantic segmentation in computer vision with improvements via inclusion constraints, and does not address LLM training data processing."
      },
      "tasks": [
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/shamik-97/valeo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03872",
      "abstract": "Motivated by the challenge of moment recovery in hydrodynamic approximation in kinetic theory, we propose a data-driven approach for the hydrodynamic models. Inspired by continuous data assimilation, our method introduces a relaxation-based nudging system coupled with a novel discretization technique. This approach facilitates the simultaneous recovery of both the force term and a high-resolution solution from sparsely observed data. To address potential numerical artifacts, we use kernel regression to fit the observed data. We also analyze the convergence of the proposed nudging system under both full and partial data scenarios. When applied to moment systems, the source term involves the derivative of higher-order moments, our approach serves as a crucial step for data preparation in machine-learning based moment closure models. Multiple numerical experiments demonstrate the effectiveness of our algorithm, and we discuss its potential extension to high-dimensional systems.",
      "authors": [
        "Jingcheng Lu",
        "Kunlun Qi",
        "Li Wang",
        "Jeff Calder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-05T19:21:19+00:00",
          "link": "https://arxiv.org/abs/2409.03872v1",
          "size": "1131kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T02:46:05+00:00",
          "link": "https://arxiv.org/abs/2409.03872v2",
          "size": "924kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T19:34:15+00:00",
          "link": "https://arxiv.org/abs/2409.03872v3",
          "size": "924kb",
          "version": "v3"
        }
      ],
      "title": "Continuous data assimilation for hydrodynamics: consistent discretization and application to moment recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03872",
        "HTML": "https://arxiv.org/html/2409.03872v3",
        "PDF": "https://arxiv.org/pdf/2409.03872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a data-driven approach for hydrodynamic models inspired by continuous data assimilation, but it is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.05260",
      "abstract": "Given a video with $T$ frames, frame sampling is a task to select $N \\ll T$ frames, so as to maximize the performance of a fixed video classifier. Not just brute-force search, but most existing methods suffer from its vast search space of $\\binom{T}{N}$, especially when $N$ gets large. To address this challenge, we introduce a novel perspective of reducing the search space from $O(T^N)$ to $O(T)$. Instead of exploring the entire $O(T^N)$ space, our proposed semi-optimal policy selects the top $N$ frames based on the independently estimated value of each frame using per-frame confidence, significantly reducing the computational complexity. We verify that our semi-optimal policy can efficiently approximate the optimal policy, particularly under practical settings. Additionally, through extensive experiments on various datasets and model architectures, we demonstrate that learning our semi-optimal policy ensures stable and high performance regardless of the size of $N$ and $T$.",
      "authors": [
        "Junho Lee",
        "Jeongwoo Shin",
        "Seung Woo Ko",
        "Seongsu Ha",
        "Joonseok Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-09T01:11:47+00:00",
          "link": "https://arxiv.org/abs/2409.05260v1",
          "size": "31487kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T05:41:15+00:00",
          "link": "https://arxiv.org/abs/2409.05260v2",
          "size": "31488kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T12:58:54+00:00",
          "link": "https://arxiv.org/abs/2409.05260v3",
          "size": "31489kb",
          "version": "v3"
        }
      ],
      "title": "Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05260",
        "HTML": "https://arxiv.org/html/2409.05260v3",
        "PDF": "https://arxiv.org/pdf/2409.05260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses frame sampling in video classification to improve performance, which is outside the scope of LLM training data processing."
      },
      "tasks": [
        "Video Classification"
      ],
      "repo_urls": [
        "https://github.com/isno0907/sosampler"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.13725",
      "abstract": "Automated content moderation has long been used to help identify and filter undesired user-generated content online. But such systems have a history of incorrectly flagging content by and about marginalized identities for removal. Generative AI systems now use such filters to keep undesired generated content from being created by or shown to users. While a lot of focus has been given to making sure such systems do not produce undesired outcomes, considerably less attention has been paid to making sure appropriate text can be generated. From classrooms to Hollywood, as generative AI is increasingly used for creative or expressive text generation, whose stories will these technologies allow to be told, and whose will they suppress?\n  In this paper, we define and introduce measures of speech suppression, focusing on speech related to different identity groups incorrectly filtered by a range of content moderation APIs. Using both short-form, user-generated datasets traditional in content moderation and longer generative AI-focused data, including two datasets we introduce in this work, we create a benchmark for measurement of speech suppression for nine identity groups. Across one traditional and four generative AI-focused automated content moderation services tested, we find that identity-related speech is more likely to be incorrectly suppressed than other speech. We find that reasons for incorrect flagging behavior vary by identity based on stereotypes and text associations, with, e.g., disability-related content more likely to be flagged for self-harm or health-related reasons while non-Christian content is more likely to be flagged as violent or hateful. As generative AI systems are increasingly used for creative work, we urge further attention to how this may impact the creation of identity-related content.",
      "authors": [
        "Grace Proebsting",
        "Oghenefejiro Isaacs Anigboro",
        "Charlie M. Crawford",
        "Dana\\'e Metaxa",
        "Sorelle A. Friedler"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-09T14:34:51+00:00",
          "link": "https://arxiv.org/abs/2409.13725v1",
          "size": "2558kb",
          "version": "v1"
        },
        {
          "date": "2025-04-06T00:30:38+00:00",
          "link": "https://arxiv.org/abs/2409.13725v2",
          "size": "3323kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T16:32:14+00:00",
          "link": "https://arxiv.org/abs/2409.13725v3",
          "size": "3779kb",
          "version": "v3"
        }
      ],
      "title": "Identity-related Speech Suppression in Generative AI Content Moderation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.13725",
        "HTML": "https://arxiv.org/html/2409.13725v3",
        "PDF": "https://arxiv.org/pdf/2409.13725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses content moderation, including the introduction of two datasets for assessing speech suppression by identity group. While it relates to dataset creation, it does not directly address LLM training data processing, focusing instead on generative AI content moderation."
      },
      "tasks": [
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.02482",
      "abstract": "Software practitioners often encounter workplace unfairness, such as unequal recognition and gender bias. While the link between fairness and job satisfaction has been established in other fields, its relevance to software professionals remains underexplored. This study examines how fairness perceptions relate to job satisfaction among software practitioners, focusing on both general trends and demographic-specific differences. We conducted an online survey of 108 software practitioners, followed by ordinal logistic regression to analyze the relationship between fairness perceptions and job satisfaction in software engineering contexts, with moderation analysis examining how this relationship varies across demographic groups. Our findings indicate that all four fairness dimensions (namely distributive, procedural, interpersonal, and informational fairness) significantly affect overall job satisfaction and satisfaction with job security. Among these, interpersonal fairness has the biggest impact. The relationship between fairness and job satisfaction is stronger for female, ethnically underrepresented, less experienced practitioners, and those with work limitations. Fairness in authorship emerged as an important factor for job satisfaction collectively, while fairness in policy implementation, high-demand situations, and working hours impacted specific demographic groups. This study highlights the role of fairness among software practitioners, offering strategies for organizations to promote fair practices and targeted approaches for certain demographic groups.",
      "authors": [
        "Emeralda Sesari",
        "Federica Sarro",
        "Ayushi Rastogi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T13:40:00+00:00",
          "link": "https://arxiv.org/abs/2410.02482v1",
          "size": "1432kb",
          "version": "v1"
        },
        {
          "date": "2024-12-04T17:56:08+00:00",
          "link": "https://arxiv.org/abs/2410.02482v2",
          "size": "938kb",
          "version": "v2"
        },
        {
          "date": "2025-05-23T09:31:55+00:00",
          "link": "https://arxiv.org/abs/2410.02482v3",
          "size": "900kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T18:44:21+00:00",
          "link": "https://arxiv.org/abs/2410.02482v4",
          "size": "733kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T12:28:33+00:00",
          "link": "https://arxiv.org/abs/2410.02482v5",
          "size": "733kb",
          "version": "v5"
        }
      ],
      "title": "It is Giving Major Satisfaction: Why Fairness Matters for Software Practitioners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02482",
        "HTML": "https://arxiv.org/html/2410.02482v5",
        "PDF": "https://arxiv.org/pdf/2410.02482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores fairness in the software industry and its relation to job satisfaction, which does not involve LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02540",
      "abstract": "We present both $hp$-a priori and $hp$-a posteriori error analysis of a mixed-order hybrid high-order (HHO) method to approximate second-order elliptic problems on simplicial meshes. Our main result on the $hp$-a priori error analysis is a $\\frac12$-order $p$-suboptimal error estimate. This result is, to our knowledge, the first of this kind for hybrid nonconforming methods and matches the state-of-the-art for other nonconforming methods (as discontinuous Galerkin methods) with general (mixed Dirichlet/Neumann) boundary conditions. Our second main result is a residual-based $hp$-a posteriori upper error bound, comprising residual, normal flux jump, tangential jump, and stabilization estimators (plus data oscillation terms). The first three terms are $p$-optimal and only the latter is $\\frac12$-order $p$-suboptimal. This result is, to our knowledge, the first $hp$-a posteriori error estimate for HHO methods. A novel approach based on the partition-of-unity provided by hat basis functions and on local Helmholtz decompositions on vertex stars is devised to estimate the nonconforming error. Finally, we establish local lower error bounds. Remarkably, the normal flux jump estimator is only $\\frac12$-order $p$-suboptimal, as it can be bounded by the stabilization owing to the local conservation property of HHO methods. Numerical examples illustrate the theory.",
      "authors": [
        "Zhaonan Dong",
        "Alexandre Ern"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T14:45:10+00:00",
          "link": "https://arxiv.org/abs/2410.02540v1",
          "size": "1086kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:17:25+00:00",
          "link": "https://arxiv.org/abs/2410.02540v2",
          "size": "1199kb",
          "version": "v2"
        }
      ],
      "title": "$hp$-error analysis of mixed-order hybrid high-order methods for elliptic problems on simplicial meshes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02540",
        "HTML": "https://arxiv.org/html/2410.02540v2",
        "PDF": "https://arxiv.org/pdf/2410.02540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on $hp$-error analysis for elliptic problems using hybrid high-order methods, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.05094",
      "abstract": "Provenance in databases has been thoroughly studied for positive and for recursive queries, then for first-order (FO) queries, i.e., having negation but no recursion. Query evaluation can be understood as a two-player game where the opponents argue whether or not a tuple is in the query answer. This game-theoretic approach yields a natural provenance model for FO queries, unifying how and why-not provenance. Here, we study the fine-grain structure of game provenance. A game $G=(V,E)$ consists of positions $V$ and moves $E$ and can be solved by computing the well-founded model of a single, unstratifiable rule: \\[ \\text{win}(X) \\leftarrow \\text{move}(X, Y), \\neg \\, \\text{win}(Y). \\] In the solved game $G^{\\lambda}$, the value of a position $x\\,{\\in}\\,V$ is either won, lost, or drawn. This value is explained by the provenance $\\mathscr{P}$(x), i.e., certain (annotated) edges reachable from $x$. We identify seven edge types that give rise to new kinds of provenance, i.e., potential, actual, and primary, and demonstrate that \"not all moves are created equal\". We describe the new provenance types, show how they can be computed while solving games, and discuss applications, e.g., for abstract argumentation frameworks.",
      "authors": [
        "Shawn Bowers",
        "Yilin Xia",
        "Bertram Lud\\\"ascher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T14:48:56+00:00",
          "link": "https://arxiv.org/abs/2410.05094v1",
          "size": "462kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T21:57:22+00:00",
          "link": "https://arxiv.org/abs/2410.05094v2",
          "size": "296kb",
          "version": "v2"
        }
      ],
      "title": "On the Structure of Game Provenance and its Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05094",
        "HTML": "https://arxiv.org/html/2410.05094v2",
        "PDF": "https://arxiv.org/pdf/2410.05094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates game provenance in databases and its applications, not related to LLM training data processing or dataset operations."
      },
      "tasks": [
        "Abstract Argumentation",
        "Negation"
      ],
      "repo_urls": [
        "https://github.com/idaks/game-provenance-tapp24"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08989",
      "abstract": "Fine-tuning Large Language Models (LLMs) has proven effective for a variety of downstream tasks. However, as LLMs grow in size, the memory demands for backpropagation become increasingly prohibitive. Zeroth-order (ZO) optimization methods offer a memory-efficient alternative by using forward passes to estimate gradients, but the variance of gradient estimates typically scales linearly with the model's parameter dimension$\\unicode{x2013}$a significant issue for LLMs. In this paper, we propose the random Subspace Zeroth-order (SubZero) optimization to address the challenges posed by LLMs' high dimensionality. We introduce a low-rank perturbation tailored for LLMs that significantly reduces memory consumption while improving training performance. Additionally, we prove that our gradient estimation closely approximates the backpropagation gradient, exhibits lower variance than traditional ZO methods, and ensures convergence when combined with SGD. Experimental results show that SubZero enhances fine-tuning performance and achieves faster convergence compared to standard ZO approaches like MeZO across various language modeling tasks. Code is available at https://github.com/zimingyy/SubZero.",
      "authors": [
        "Ziming Yu",
        "Pan Zhou",
        "Sike Wang",
        "Jia Li",
        "Mi Tian",
        "Hua Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T17:01:43+00:00",
          "link": "https://arxiv.org/abs/2410.08989v1",
          "size": "146kb",
          "version": "v1"
        },
        {
          "date": "2024-11-22T15:08:59+00:00",
          "link": "https://arxiv.org/abs/2410.08989v2",
          "size": "193kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T16:21:10+00:00",
          "link": "https://arxiv.org/abs/2410.08989v3",
          "size": "432kb",
          "version": "v3"
        }
      ],
      "title": "Zeroth-Order Fine-Tuning of LLMs in Random Subspaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08989",
        "HTML": "https://arxiv.org/html/2410.08989v3",
        "PDF": "https://arxiv.org/pdf/2410.08989"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses fine-tuning of large language models using a new optimization method. While it relates to model fine-tuning, it primarily focuses on optimization methods rather than on the data processing aspects of LLM training."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/zimingyy/subzero"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12193",
      "abstract": "Real-time motion generation -- which is essential for achieving reactive and adaptive behavior -- under kinodynamic constraints for high-dimensional systems is a crucial yet challenging problem. We address this with a two-step approach: offline learning of a lower-dimensional trajectory manifold of task-relevant, constraint-satisfying trajectories, followed by rapid online search within this manifold. Extending the discrete-time Motion Manifold Primitives (MMP) framework, we propose Differentiable Motion Manifold Primitives (DMMP), a novel neural network architecture that encodes and generates continuous-time, differentiable trajectories, trained using data collected offline through trajectory optimizations, with a strategy that ensures constraint satisfaction -- absent in existing methods. Experiments on dynamic throwing with a 7-DoF robot arm demonstrate that DMMP outperforms prior methods in planning speed, task success, and constraint satisfaction.",
      "authors": [
        "Yonghyeon Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T03:29:33+00:00",
          "link": "https://arxiv.org/abs/2410.12193v1",
          "size": "2420kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:36:31+00:00",
          "link": "https://arxiv.org/abs/2410.12193v2",
          "size": "2180kb",
          "version": "v2"
        }
      ],
      "title": "Differentiable Motion Manifold Primitives for Reactive Motion Generation under Kinodynamic Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12193",
        "HTML": "https://arxiv.org/html/2410.12193v2",
        "PDF": "https://arxiv.org/pdf/2410.12193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on motion generation for high-dimensional systems and does not relate to LLM training data processing or data-related contributions for LLMs."
      },
      "tasks": [
        "Motion Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.13812",
      "abstract": "Transparency and explainability are two extremely important aspects to be considered when employing black-box machine learning models in high-stake applications. Providing counterfactual explanations is one way of fulfilling this requirement. However, this also poses a threat to the privacy of both the institution that is providing the explanation as well as the user who is requesting it. In this work, we propose multiple schemes inspired by private information retrieval (PIR) techniques which ensure the \\emph{user's privacy} when retrieving counterfactual explanations. We present a scheme which retrieves the \\emph{exact} nearest neighbor counterfactual explanation from a database of accepted points while achieving perfect (information-theoretic) privacy for the user. While the scheme achieves perfect privacy for the user, some leakage on the database is inevitable which we quantify using a mutual information based metric. Furthermore, we propose strategies to reduce this leakage to achieve an advanced degree of database privacy. We extend these schemes to incorporate user's preference on transforming their attributes, so that a more actionable explanation can be received. Since our schemes rely on finite field arithmetic, we empirically validate our schemes on real datasets to understand the trade-off between the accuracy and the finite field sizes. Finally, we present numerical results to support our theoretical findings, and compare the database leakage of the proposed schemes.",
      "authors": [
        "Mohamed Nomeir",
        "Pasan Dissanayake",
        "Shreya Meel",
        "Sanghamitra Dutta",
        "Sennur Ulukus"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T17:45:07+00:00",
          "link": "https://arxiv.org/abs/2410.13812v1",
          "size": "223kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:25:40+00:00",
          "link": "https://arxiv.org/abs/2410.13812v2",
          "size": "150kb",
          "version": "v2"
        }
      ],
      "title": "Private Counterfactual Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13812",
        "HTML": "https://arxiv.org/html/2410.13812v2",
        "PDF": "https://arxiv.org/pdf/2410.13812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses counterfactual retrieval methods prioritizing privacy, not related to the data processing operations or datasets involved in LLM training."
      },
      "tasks": [
        "counterfactual",
        "Counterfactual Explanation",
        "Information Retrieval",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.22128",
      "abstract": "We consider the problem of novel view synthesis from unposed images in a single feed-forward. Our framework capitalizes on fast speed, scalability, and high-quality 3D reconstruction and view synthesis capabilities of 3DGS, where we further extend it to offer a practical solution that relaxes common assumptions such as dense image views, accurate camera poses, and substantial image overlaps. We achieve this through identifying and addressing unique challenges arising from the use of pixel-aligned 3DGS: misaligned 3D Gaussians across different views induce noisy or sparse gradients that destabilize training and hinder convergence, especially when above assumptions are not met. To mitigate this, we employ pre-trained monocular depth estimation and visual correspondence models to achieve coarse alignments of 3D Gaussians. We then introduce lightweight, learnable modules to refine depth and pose estimates from the coarse alignments, improving the quality of 3D reconstruction and novel view synthesis. Furthermore, the refined estimates are leveraged to estimate geometry confidence scores, which assess the reliability of 3D Gaussian centers and condition the prediction of Gaussian parameters accordingly. Extensive evaluations on large-scale real-world datasets demonstrate that PF3plat sets a new state-of-the-art across all benchmarks, supported by comprehensive ablation studies validating our design choices. project page: https://cvlab-kaist.github.io/PF3plat/",
      "authors": [
        "Sunghwan Hong",
        "Jaewoo Jung",
        "Heeseong Shin",
        "Jisang Han",
        "Jiaolong Yang",
        "Chong Luo",
        "Seungryong Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-29T15:28:15+00:00",
          "link": "https://arxiv.org/abs/2410.22128v1",
          "size": "5313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:23:37+00:00",
          "link": "https://arxiv.org/abs/2410.22128v2",
          "size": "6747kb",
          "version": "v2"
        }
      ],
      "title": "PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.22128",
        "HTML": "https://arxiv.org/html/2410.22128v2",
        "PDF": "https://arxiv.org/pdf/2410.22128"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with novel view synthesis from unposed images and 3D reconstruction, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "3DGS",
        "3D Reconstruction",
        "Depth Estimation",
        "Monocular Depth Estimation",
        "Novel View Synthesis"
      ],
      "repo_urls": [
        "https://github.com/cvlab-kaist/PF3plat"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02650",
      "abstract": "Functional Near-Infrared Spectroscopy (fNIRS) has emerged as a valuable tool to investigate cognitive and emotional processes during learning. We focus specifically on game-integrated learning systems as the context for fNIRS-based brain data analysis. We selected game-integrated learning systems because such systems make learning more engaging, interactive, and immersive, all of which are critical features for adaptive learning design. The goal of this scoping review is to help researchers understand how fNIRS has been used so far to study brain activity in game-integrated learning systems. We also aim to show how brain data captured through fNIRS can support the development of adaptive learning systems by monitoring learners' cognitive states. Using the PRISMA-ScR framework, 1300 papers were screened, and 21 empirical studies were selected for in-depth analysis. Studies were categorized as affective/cognitive response studies or comparative studies, and further analyzed by learning platform, game device, fNIRS configuration, outcome measures, and study design. The findings reveal that game-integrated learning systems can be as effective as traditional methods in improving engagement and involvement. The findings also show that fNIRS offers valuable insights into cognitive states, but it has not yet been widely implemented in real-time adaptive systems. We identify key challenges in standardization and data interpretation and highlight the potential of fNIRS for developing brain-aware, interactive learning environments. This review offers insights to guide future research on using brain data to support adaptive learning and intelligent system design.",
      "authors": [
        "Shayla Sharmin",
        "Gael Lucero-Palacios",
        "Behdokht Kiafar",
        "Mohammad Fahim Abrar",
        "Mohammad Al-Ratrout",
        "Aditya Raikwar",
        "and Roghayeh Leila Barmaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T22:22:23+00:00",
          "link": "https://arxiv.org/abs/2411.02650v1",
          "size": "1230kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:16:19+00:00",
          "link": "https://arxiv.org/abs/2411.02650v2",
          "size": "159kb",
          "version": "v2"
        }
      ],
      "title": "A Scoping Review of Functional Near-Infrared Spectroscopy (fNIRS) Applications in Game-Based Learning Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02650",
        "HTML": "https://arxiv.org/html/2411.02650v2",
        "PDF": "https://arxiv.org/pdf/2411.02650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the use of fNIRS in game-based learning environments and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.06106",
      "abstract": "Variations in medical imaging modalities and individual anatomical differences pose challenges to cross-modality generalization in multi-modal tasks. Existing methods often concentrate exclusively on common anatomical patterns, thereby neglecting individual differences and consequently limiting their generalization performance. This paper emphasizes the critical role of learning individual-level invariance, i.e., personalized representation $\\mathbb{X}_h$, to enhance multi-modality generalization under both homogeneous and heterogeneous settings. It reveals that mappings from individual biological profile to different medical modalities remain static across the population, which is implied in the personalization process. We propose a two-stage approach: pre-training with invariant representation $\\mathbb{X}_h$ for personalization, then fine-tuning for diverse downstream tasks. We provide both theoretical and empirical evidence demonstrating the feasibility and advantages of personalization, showing that our approach yields greater generalizability and transferability across diverse multi-modal medical tasks compared to methods lacking personalization. Extensive experiments further validate that our approach significantly enhances performance in various generalization scenarios.",
      "authors": [
        "Zhaorui Tan",
        "Xi Yang",
        "Tan Pan",
        "Tianyi Liu",
        "Chen Jiang",
        "Xin Guo",
        "Qiufeng Wang",
        "Anh Nguyen",
        "Yuan Qi",
        "Kaizhu Huang",
        "Yuan Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-09T08:00:50+00:00",
          "link": "https://arxiv.org/abs/2411.06106v1",
          "size": "3823kb",
          "version": "v1"
        },
        {
          "date": "2024-11-13T03:19:47+00:00",
          "link": "https://arxiv.org/abs/2411.06106v2",
          "size": "3825kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T10:47:17+00:00",
          "link": "https://arxiv.org/abs/2411.06106v3",
          "size": "4858kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T03:38:33+00:00",
          "link": "https://arxiv.org/abs/2411.06106v4",
          "size": "4859kb",
          "version": "v4"
        }
      ],
      "title": "Towards a Universal 3D Medical Multi-modality Generalization via Learning Personalized Invariant Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06106",
        "HTML": "https://arxiv.org/html/2411.06106v4",
        "PDF": "https://arxiv.org/pdf/2411.06106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on medical imaging and personalized invariant representation for 3D multi-modality generalization, with no connection to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.06690",
      "abstract": "This paper presents a polarization-aware movable antenna (PAMA) framework that integrates polarization effects into the design and optimization of movable antennas (MAs). While MAs have proven effective at boosting wireless communication performance, existing studies primarily focus on phase variations caused by different propagation paths and leverage antenna movements to maximize channel gains. This narrow focus limits the full potential of MAs. In this work, we introduce a polarization-aware channel model rooted in electromagnetic theory, unveiling a defining advantage of MAs over other wireless technologies such as precoding: the ability to optimize polarization matching. This new understanding enables PAMA to extend the applicability of MAs beyond radio-frequency, multipath-rich scenarios to higher-frequency bands, such as mmWave, even with a single line-of-sight (LOS) path. Our findings demonstrate that incorporating polarization considerations into MAs significantly enhances efficiency, link reliability, and data throughput, paving the way for more robust and efficient future wireless networks.",
      "authors": [
        "Runxin Zhang and Yulin Shao and Yonina C. Eldar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T03:16:21+00:00",
          "link": "https://arxiv.org/abs/2411.06690v1",
          "size": "2359kb",
          "version": "v1"
        },
        {
          "date": "2025-04-02T16:28:51+00:00",
          "link": "https://arxiv.org/abs/2411.06690v2",
          "size": "2716kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T08:34:53+00:00",
          "link": "https://arxiv.org/abs/2411.06690v3",
          "size": "2647kb",
          "version": "v3"
        }
      ],
      "title": "Polarization Aware Movable Antenna",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06690",
        "HTML": "https://arxiv.org/html/2411.06690v3",
        "PDF": "https://arxiv.org/pdf/2411.06690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses movable antennas and polarization effects in wireless communication, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07037",
      "abstract": "As Large Language Models (LLMs) evolve in natural language processing (NLP), their ability to stably follow instructions in long-context inputs has become critical for real-world applications. However, existing benchmarks seldom focus on instruction-following in long-context scenarios or stability on different inputs. To bridge this gap, we introduce LIFBench, a scalable dataset designed to evaluate LLMs' instruction-following capabilities and stability across long contexts. LIFBench comprises three long-context scenarios and eleven diverse tasks, featuring 2,766 instructions generated through an automated expansion method across three dimensions: length, expression, and variables. For evaluation, we propose LIFEval, a rubric-based assessment method that enables precise, automated scoring of complex LLM responses without reliance on LLM-assisted assessments or human judgment. This method allows for a comprehensive analysis of model performance and stability from multiple perspectives. We conduct detailed experiments on 20 prominent LLMs across six length intervals. Our work contributes LIFBench and LIFEval as robust tools for assessing LLM performance in complex and long-context settings, offering valuable insights to guide future advancements in LLM development.",
      "authors": [
        "Xiaodong Wu",
        "Minhao Wang",
        "Yichen Liu",
        "Xiaoming Shi",
        "He Yan",
        "Xiangju Lu",
        "Junmin Zhu and Wei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T14:43:51+00:00",
          "link": "https://arxiv.org/abs/2411.07037v1",
          "size": "157kb",
          "version": "v1"
        },
        {
          "date": "2024-12-16T07:53:06+00:00",
          "link": "https://arxiv.org/abs/2411.07037v2",
          "size": "367kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T22:08:05+00:00",
          "link": "https://arxiv.org/abs/2411.07037v3",
          "size": "380kb",
          "version": "v3"
        }
      ],
      "title": "LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07037",
        "HTML": "https://arxiv.org/html/2411.07037v3",
        "PDF": "https://arxiv.org/pdf/2411.07037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces LIFBench, a dataset for evaluating LLMs' instruction-following capabilities and stability, but its main focus is on model evaluation rather than training data processing."
      },
      "tasks": [
        "Instruction Following"
      ],
      "repo_urls": [
        "https://github.com/sheldonwu0327/lif-bench-2024"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.08562",
      "abstract": "Machine unlearning in neural information retrieval (IR) systems requires removing specific data whilst maintaining model performance. Applying existing machine unlearning methods to IR may compromise retrieval effectiveness or inadvertently expose unlearning actions due to the removal of particular items from the retrieved results presented to users. We formalise corrective unranking, which extends machine unlearning in (neural) IR context by integrating substitute documents to preserve ranking integrity, and propose a novel teacher-student framework, Corrective unRanking Distillation (CuRD), for this task. CuRD (1) facilitates forgetting by adjusting the (trained) neural IR model such that its output relevance scores of to-be-forgotten samples mimic those of low-ranking, non-retrievable samples; (2) enables correction by fine-tuning the relevance scores for the substitute samples to match those of corresponding to-be-forgotten samples closely; (3) seeks to preserve performance on samples that are not targeted for forgetting. We evaluate CuRD on four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and TREC CAR datasets. Experiments with forget set sizes from 1 % and 20 % of the training dataset demonstrate that CuRD outperforms seven state-of-the-art baselines in terms of forgetting and correction while maintaining model retention and generalisation capabilities.",
      "authors": [
        "Jingrui Hou and Axel Finke and Georgina Cosma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T12:19:46+00:00",
          "link": "https://arxiv.org/abs/2411.08562v1",
          "size": "162kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:51:19+00:00",
          "link": "https://arxiv.org/abs/2411.08562v2",
          "size": "184kb",
          "version": "v2"
        }
      ],
      "title": "Neural Corrective Machine Unranking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08562",
        "PDF": "https://arxiv.org/pdf/2411.08562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on machine unlearning and corrective unranking in neural information retrieval systems, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Information Retrieval",
        "Machine Unlearning",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.10371",
      "abstract": "Event Causality Identification (ECI) has become an essential task in Natural Language Processing (NLP), focused on automatically detecting causal relationships between events within texts. This comprehensive survey systematically investigates fundamental concepts and models, developing a systematic taxonomy and critically evaluating diverse models. We begin by defining core concepts, formalizing the ECI problem, and outlining standard evaluation protocols. Our classification framework divides ECI models into two primary tasks: Sentence-level Event Causality Identification (SECI) and Document-level Event Causality Identification (DECI). For SECI, we review models employing feature pattern-based matching, machine learning classifiers, deep semantic encoding, prompt-based fine-tuning, and causal knowledge pre-training, alongside data augmentation strategies. For DECI, we focus on approaches utilizing deep semantic encoding, event graph reasoning, and prompt-based fine-tuning. Special attention is given to recent advancements in multi-lingual and cross-lingual ECI, as well as zero-shot ECI leveraging Large Language Models (LLMs). We analyze the strengths, limitations, and unresolved challenges associated with each approach. Extensive quantitative evaluations are conducted on four benchmark datasets to rigorously assess the performance of various ECI models. We conclude by discussing future research directions and highlighting opportunities to advance the field further.",
      "authors": [
        "Qing Cheng",
        "Zefan Zeng",
        "Xingchen Hu",
        "Yuehang Si",
        "Zhong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T17:19:42+00:00",
          "link": "https://arxiv.org/abs/2411.10371v1",
          "size": "5111kb",
          "version": "v1"
        },
        {
          "date": "2024-11-25T16:55:09+00:00",
          "link": "https://arxiv.org/abs/2411.10371v2",
          "size": "5159kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T07:35:00+00:00",
          "link": "https://arxiv.org/abs/2411.10371v3",
          "size": "9959kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T02:03:22+00:00",
          "link": "https://arxiv.org/abs/2411.10371v4",
          "size": "1123kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T07:53:24+00:00",
          "link": "https://arxiv.org/abs/2411.10371v5",
          "size": "1230kb",
          "version": "v5"
        }
      ],
      "title": "A Survey of Event Causality Identification: Taxonomy, Challenges, Assessment, and Prospects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10371",
        "HTML": "https://arxiv.org/html/2411.10371v5",
        "PDF": "https://arxiv.org/pdf/2411.10371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys event causality identification in NLP, mentioning prompt-based fine-tuning and data augmentation strategies. However, the main focus is not on LLM training data processing."
      },
      "tasks": [
        "Causal Inference",
        "Event Causality Identification",
        "Sentence"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.11596",
      "abstract": "The reconfiguration of electrical power distribution systems is a crucial optimization problem aimed at minimizing power losses by altering the system topology through the operation of interconnection switches. This problem, typically modelled as a mixed integer nonlinear program demands high computational resources for large scale networks and requires specialized radiality constraints for maintaining the tree like structure of distribution networks. This paper presents a comprehensive analysis that integrates and compares the computational burden associated with different radiality constraint formulations proposed in the specialized literature for the reconfiguration of distribution systems. By using consistent hardware and software setups, we evaluate the performance of these constraints across several well known test cases. Our findings reveal significant differences in computational efficiency depending on the chosen set of radiality constraints, providing valuable insights for optimizing reconfiguration strategies in practical distribution networks.",
      "authors": [
        "Pablo Cortes",
        "Alejandra Tabares",
        "Fredy Franco",
        "Astrid Xiomara Rodr\\'iguez",
        "David \\'Alvarez-Mart\\'inez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-18T14:18:18+00:00",
          "link": "https://arxiv.org/abs/2411.11596v1",
          "size": "964kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T15:37:44+00:00",
          "link": "https://arxiv.org/abs/2411.11596v2",
          "size": "845kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T22:42:38+00:00",
          "link": "https://arxiv.org/abs/2411.11596v3",
          "size": "845kb",
          "version": "v3"
        }
      ],
      "title": "Integrating and Comparing Radiality Constraints for Optimized Distribution System Reconfiguration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11596",
        "PDF": "https://arxiv.org/pdf/2411.11596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimization and radiality constraints for electrical power distribution systems, unrelated to LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.11662",
      "abstract": "Although randomization has long been used in distributed computing, formal methods for reasoning about probabilistic concurrent programs have lagged behind. No existing program logics can express specifications about the full distributions of outcomes resulting from programs that are both probabilistic and concurrent. To address this, we introduce Probabilistic Concurrent Outcome Logic (pcOL), which incorporates ideas from concurrent and probabilistic separation logics into Outcome Logic to introduce new compositional reasoning principles. At its core, pcOL reinterprets the rules of Concurrent Separation Logic in a setting where separation models probabilistic independence, so as to compositionally describe joint distributions over variables in concurrent threads. Reasoning about outcomes also proves crucial, as case analysis is often necessary to derive precise information about threads that rely on randomized shared state. We demonstrate pcOL on a variety of examples, including to prove almost sure termination for unbounded loops.",
      "authors": [
        "Noam Zilberstein",
        "Alexandra Silva",
        "Joseph Tassarotti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-18T15:38:36+00:00",
          "link": "https://arxiv.org/abs/2411.11662v1",
          "size": "85kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:31:35+00:00",
          "link": "https://arxiv.org/abs/2411.11662v2",
          "size": "117kb",
          "version": "v2"
        }
      ],
      "title": "Probabilistic Concurrent Reasoning in Outcome Logic: Independence, Conditioning, and Invariants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11662",
        "PDF": "https://arxiv.org/pdf/2411.11662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces probabilistic concurrent outcome logic for reasoning in probabilistic concurrent programs, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.12127",
      "abstract": "We propose a new and intuitive metric for aleatoric uncertainty quantification (UQ), the prevalence of class collisions defined as the same input being observed in different classes. We use the rate of class collisions to define the collision matrix, a novel and uniquely fine-grained measure of uncertainty. For a classification problem involving $K$ classes, the $K\\times K$ collision matrix $S$ measures the inherent difficulty in distinguishing between each pair of classes. We discuss several applications of the collision matrix, establish its fundamental mathematical properties, as well as show its relationship with existing UQ methods, including the Bayes error rate (BER). We also address the new problem of estimating the collision matrix using one-hot labeled data by proposing a series of innovative techniques to estimate $S$. First, we learn a pair-wise contrastive model which accepts two inputs and determines if they belong to the same class. We then show that this contrastive model (which is PAC learnable) can be used to estimate the Gramian matrix of $S$, defined as $G=S^TS$. Finally, we show that under reasonable assumptions, $G$ can be used to uniquely recover $S$, a new result on non-negative matrices which could be of independent interest. With a method to estimate $S$ established, we demonstrate how this estimate of $S$, in conjunction with the contrastive model, can be used to estimate the posterior class portability distribution of any point. Experimental results are also presented to validate our methods of estimating the collision matrix and class posterior distributions on several datasets.",
      "authors": [
        "Jesse Friedbaum",
        "Sudarshan Adiga",
        "Ravi Tandon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-18T23:41:27+00:00",
          "link": "https://arxiv.org/abs/2411.12127v1",
          "size": "2823kb",
          "version": "v1"
        },
        {
          "date": "2025-02-24T19:31:27+00:00",
          "link": "https://arxiv.org/abs/2411.12127v2",
          "size": "3583kb",
          "version": "v2"
        },
        {
          "date": "2025-05-20T17:03:47+00:00",
          "link": "https://arxiv.org/abs/2411.12127v3",
          "size": "3788kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T00:06:46+00:00",
          "link": "https://arxiv.org/abs/2411.12127v4",
          "size": "2302kb",
          "version": "v4"
        }
      ],
      "title": "Fine-Grained Uncertainty Quantification via Collisions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12127",
        "HTML": "https://arxiv.org/html/2411.12127v4",
        "PDF": "https://arxiv.org/pdf/2411.12127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on uncertainty quantification in classification tasks and proposes a metric for measuring aleatoric uncertainty, which does not contribute to LLM training data processing."
      },
      "tasks": [
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.14825",
      "abstract": "The sparsity theory of Ne\\v{s}et\\v{r}il and Ossona de Mendez provides generic combinatorial and algorithmic methods suitable for many classes of sparse graphs. As such, it has already driven major advances in model checking, parameterized complexity, and approximation algorithms. We show that this theory is equally well suited to the design of distributed algorithms, providing the first generic algorithmic results for distributed first-order (FO) model checking on graphs of bounded expansion. The latter form a rich graph family which subsumes planar, bounded-genus, bounded-treewidth, and bounded-degree graphs, as well as graphs excluding a fixed minor or topological minor, and sparse Erdos-R\\'enyi graphs (a.a.s).\n  Our main results are the following algorithmic meta-theorems for distributed algorithms in the standard CONGEST model on every graph class $\\mathcal{G}$ of bounded expansion.\n  First, we resolve an open problem originally posed by Ne\\v{s}et\\v{r}il and Ossona de Mendez (Distributed Computing 2016), and reiterated by Pilipczuk, Siebertz, and Toru\\'nczyk (LICS 2018). A formula $\\varphi(x)$ is local if the satisfaction of $\\varphi(x)$ depends only on the $r$-neighbourhood of its free variable $x$, for some fixed $r$. For instance, the formula '$x$ belongs to a triangle' is local. We show that, for every local FO formula $\\varphi(x)$, there exists a deterministic algorithm that, for every $n$-vertex graph $G\\in \\mathcal{G}$, identifies all vertices $v\\in V(G)$ such that $G\\models \\varphi(v)$, in $O(\\log n)$ rounds.\n  Second, we show that, for every FO formula $\\varphi$, there is a deterministic algorithm that, for every $n$-vertex graph $G\\in \\mathcal{G}$, decides whether $G\\models \\varphi$, in $\\mathcal{O}(D+\\log n)$ rounds, where $D$ is the diameter of $G$. The techniques extend to distributed counting, optimization, and certification problems.",
      "authors": [
        "L\\'elia Blin",
        "Fedor V. Fomin",
        "Pierre Fraigniaud",
        "Sylvain Gay",
        "Petr A. Golovach",
        "Pedro Montealegre",
        "Ivan Rapaport",
        "Ioan Todinca"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T09:53:58+00:00",
          "link": "https://arxiv.org/abs/2411.14825v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:51:48+00:00",
          "link": "https://arxiv.org/abs/2411.14825v2",
          "size": "91kb",
          "version": "v2"
        }
      ],
      "title": "Distributed Model Checking in Graphs Classes of Bounded Expansion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14825",
        "HTML": "https://arxiv.org/html/2411.14825v2",
        "PDF": "https://arxiv.org/pdf/2411.14825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on distributed model checking in graph classes of bounded expansion, which is a theoretical computer science topic unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.16319",
      "abstract": "Traditionally, algorithms that learn to segment object instances in 2D images have heavily relied on large amounts of human-annotated data. Only recently, novel approaches have emerged tackling this problem in an unsupervised fashion. Generally, these approaches first generate pseudo-masks and then train a class-agnostic detector. While such methods deliver the current state of the art, they often fail to correctly separate instances overlapping in 2D image space since only semantics are considered. To tackle this issue, we instead propose to cut the semantic masks in 3D to obtain the final 2D instances by utilizing a point cloud representation of the scene. Furthermore, we derive a Spatial Importance function, which we use to resharpen the semantics along the 3D borders of instances. Nevertheless, these pseudo-masks are still subject to mask ambiguity. To address this issue, we further propose to augment the training of a class-agnostic detector with three Spatial Confidence components aiming to isolate a clean learning signal. With these contributions, our approach outperforms competing methods across multiple standard benchmarks for unsupervised instance segmentation and object detection.",
      "authors": [
        "Leon Sick",
        "Dominik Engel",
        "Sebastian Hartwig",
        "Pedro Hermosilla",
        "Timo Ropinski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T12:11:27+00:00",
          "link": "https://arxiv.org/abs/2411.16319v1",
          "size": "30757kb",
          "version": "v1"
        },
        {
          "date": "2024-11-26T07:14:34+00:00",
          "link": "https://arxiv.org/abs/2411.16319v2",
          "size": "30757kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T08:15:11+00:00",
          "link": "https://arxiv.org/abs/2411.16319v3",
          "size": "57386kb",
          "version": "v3"
        }
      ],
      "title": "CutS3D: Cutting Semantics in 3D for 2D Unsupervised Instance Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16319",
        "HTML": "https://arxiv.org/html/2411.16319v3",
        "PDF": "https://arxiv.org/pdf/2411.16319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for 2D unsupervised instance segmentation using 3D semantics. It does not relate to LLM training data processing or any stages of LLM data preprocessing or dataset creation."
      },
      "tasks": [
        "Instance Segmentation",
        "object-detection",
        "Object Detection",
        "Semantic Segmentation",
        "Unsupervised Instance Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16786",
      "abstract": "Mixture-of-Experts-based (MoE-based) diffusion models demonstrate remarkable scalability in high-fidelity image generation, yet their reliance on expert parallelism introduces critical communication bottlenecks. State-of-the-art methods alleviate such overhead in parallel diffusion inference through computation-communication overlapping, termed displaced parallelism. However, we identify that these techniques induce severe *staleness*-the usage of outdated activations from previous timesteps that significantly degrades quality, especially in expert-parallel scenarios. We tackle this fundamental tension and propose DICE, a staleness-centric optimization framework with a three-fold approach: (1) Interweaved Parallelism introduces staggered pipelines, effectively halving step-level staleness for free; (2) Selective Synchronization operates at layer-level and protects layers vulnerable from staled activations; and (3) Conditional Communication, a token-level, training-free method that dynamically adjusts communication frequency based on token importance. Together, these strategies effectively reduce staleness, achieving 1.26x speedup with minimal quality degradation. Empirical results establish DICE as an effective and scalable solution. Our code is publicly available at https://github.com/Cobalt-27/DICE",
      "authors": [
        "Jiajun Luo",
        "Lizhuo Luo",
        "Jianru Xu",
        "Jiajun Song",
        "Rongwei Lu",
        "Chen Tang",
        "Zhi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T08:34:50+00:00",
          "link": "https://arxiv.org/abs/2411.16786v1",
          "size": "7624kb",
          "version": "v1"
        },
        {
          "date": "2025-03-30T09:21:10+00:00",
          "link": "https://arxiv.org/abs/2411.16786v2",
          "size": "8171kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T02:59:44+00:00",
          "link": "https://arxiv.org/abs/2411.16786v3",
          "size": "8360kb",
          "version": "v3"
        }
      ],
      "title": "Staleness-Centric Optimizations for Parallel Diffusion MoE Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16786",
        "HTML": "https://arxiv.org/html/2411.16786v3",
        "PDF": "https://arxiv.org/pdf/2411.16786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces optimizations for parallel diffusion model inference, focusing on staleness in high-fidelity image generation, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.17103",
      "abstract": "We study distributed load balancing in bipartite queueing systems where frontends route jobs to heterogeneous backends with workload-dependent service rates. The system's connectivity -- governed by compatibility constraints such as data residency or resource requirements -- is represented by an arbitrary bipartite graph. Each frontend operates independently without communication with other frontends, and the goal is to minimize the expected average latency of all jobs. We propose a closed-loop policy called the Greatest Marginal Service Rate (GMSR) policy that achieves effective coordination without requiring knowledge of arrival rates.\n  In a discrete-time stochastic model, we show that the behavior of our routing policy converges (almost surely) to the behavior of a fluid model, in the limit as job sizes tend to zero and job arrival rates are scaled so that the expected total volume of jobs arriving per unit time remains fixed. Then, in the fluid regime, we demonstrate that the policy attains an $\\epsilon$-suboptimal solution in $O(\\delta + \\log{1/\\epsilon})$ time from $\\delta$-suboptimal initial workloads, which implies global convergence to the centrally coordinated optimal routing. Finally, we analyze the fluid model when the system is overloaded. We show that GMSR lexicographically maximizes throughput, maximizes the number of stable backends, and minimizes their collective workload.",
      "authors": [
        "Wenxin Zhang",
        "Santiago R. Balseiro",
        "Robert Kleinberg",
        "Vahab Mirrokni",
        "Balasubramanian Sivan",
        "Bartek Wydrowski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-26T04:40:55+00:00",
          "link": "https://arxiv.org/abs/2411.17103v1",
          "size": "150kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:36:32+00:00",
          "link": "https://arxiv.org/abs/2411.17103v2",
          "size": "1254kb",
          "version": "v2"
        }
      ],
      "title": "Distributed Load Balancing with Workload-Dependent Service Rates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17103",
        "PDF": "https://arxiv.org/pdf/2411.17103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on distributed load balancing in queueing systems, which is unrelated to LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.03515",
      "abstract": "Diffusion models have been applied to 3D LiDAR scene completion due to their strong training stability and high completion quality. However, the slow sampling speed limits the practical application of diffusion-based scene completion models since autonomous vehicles require an efficient perception of surrounding environments. This paper proposes a novel distillation method tailored for 3D Li- DAR scene completion models, dubbed ScoreLiDAR, which achieves efficient yet high-quality scene completion. Score- LiDAR enables the distilled model to sample in significantly fewer steps after distillation. To improve completion quality, we also introduce a novel Structural Loss, which encourages the distilled model to capture the geometric structure of the 3D LiDAR scene. The loss contains a scene-wise term constraining the holistic structure and a point-wise term constraining the key landmark points and their relative configuration. Extensive experiments demonstrate that ScoreLiDAR significantly accelerates the completion time from 30.55 to 5.37 seconds per frame (>5x) on SemanticKITTI and achieves superior performance compared to state-of-the-art 3D LiDAR scene completion models. Our model and code are publicly available on https: //github.com/happyw1nd/ScoreLiDAR.",
      "authors": [
        "Shengyuan Zhang",
        "An Zhao",
        "Ling Yang",
        "Zejian Li",
        "Chenye Meng",
        "Haoran Xu",
        "Tianrun Chen",
        "AnYang Wei",
        "Perry Pengyun GU",
        "Lingyun Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T17:57:25+00:00",
          "link": "https://arxiv.org/abs/2412.03515v1",
          "size": "21560kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:55:16+00:00",
          "link": "https://arxiv.org/abs/2412.03515v2",
          "size": "12024kb",
          "version": "v2"
        }
      ],
      "title": "Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03515",
        "HTML": "https://arxiv.org/html/2412.03515v2",
        "PDF": "https://arxiv.org/pdf/2412.03515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a distillation method to improve the efficiency of 3D LiDAR scene completion models, involving diffusion models and scene structure loss. It is not related to LLM training data processing."
      },
      "models": [
        {
          "model_path": "happywind/ScoreLiDAR",
          "downloads": "0",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/happywind/ScoreLiDAR"
        }
      ],
      "tasks": [
        "Autonomous Vehicles"
      ],
      "repo_urls": [
        "https://github.com/happyw1nd/scorelidar"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03860",
      "abstract": "We consider a class of optimization problems over stochastic variables where the algorithm can learn information about the value of any variable through a series of costly steps; we model this information acquisition process as a Markov Decision Process (MDP). The algorithm's goal is to minimize the cost of its solution plus the cost of information acquisition, or alternately, maximize the value of its solution minus the cost of information acquisition. Such bandit superprocesses have been studied previously but solutions are known only for fairly restrictive special cases.\n  We develop a framework for approximate optimization of bandit superprocesses that applies to arbitrary acyclic MDPs with a matroid feasibility constraint. Our framework establishes a bound on the optimal cost through a novel cost amortization; it then couples this bound with a notion of local approximation that allows approximate solutions for each component MDP in the superprocess to be composed without loss into a global approximation.\n  We use this framework to obtain approximately optimal solutions for several variants of bandit superprocesses for both maximization and minimization. We obtain new approximations for combinatorial versions of the previously studied Pandora's Box with Optional Inspection and Pandora's Box with Partial Inspection; the less-studied Additive Pandora's Box problem; as well as a new problem that we call the Weighing Scale problem.",
      "authors": [
        "Shuchi Chawla",
        "Dimitris Christou",
        "Amit Harlev",
        "Ziv Scully"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T04:12:20+00:00",
          "link": "https://arxiv.org/abs/2412.03860v1",
          "size": "2325kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:02:16+00:00",
          "link": "https://arxiv.org/abs/2412.03860v2",
          "size": "2870kb",
          "version": "v2"
        }
      ],
      "title": "Combinatorial Selection with Costly Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03860",
        "HTML": "https://arxiv.org/html/2412.03860v2",
        "PDF": "https://arxiv.org/pdf/2412.03860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses optimization problems using bandit superprocesses and does not involve any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.09709",
      "abstract": "Transformers are gaining increasing attention across Natural Language Processing (NLP) application domains due to their outstanding accuracy. However, these data-intensive models add significant performance demands to the existing computing architectures. Systolic array architectures, adopted by commercial AI computing platforms like Google TPUs, offer energy-efficient data reuse but face throughput and energy penalties due to input-output synchronization via First-In-First-Out (FIFO) buffers. This paper proposes a novel scalable systolic array architecture featuring Diagonal-Input and Permutated weight stationary (DiP) dataflow for matrix multiplication acceleration. The proposed architecture eliminates the synchronization FIFOs required by state-of-the-art weight stationary systolic arrays. Beyond the area, power, and energy savings achieved by eliminating these FIFOs, DiP architecture maximizes the computational resource utilization, achieving up to 50\\% throughput improvement over conventional weight stationary architectures. Analytical models are developed for both weight stationary and DiP architectures, including latency, throughput, time to full PEs utilization (TFPU), and FIFOs overhead. A comprehensive hardware design space exploration using 22nm commercial technology demonstrates DiP's scalability advantages, achieving up to a 2.02x improvement in energy efficiency per area. Furthermore, DiP outperforms TPU-like architectures on transformer workloads from widely-used models, delivering energy improvement up to 1.81x and latency improvement up to 1.49x. At a 64x64 size with 4096 PEs, DiP achieves a peak throughput of 8.192 TOPS with energy efficiency 9.548 TOPS/W.",
      "authors": [
        "Ahmed J. Abdelmaksoud",
        "Shady Agwa",
        "Themis Prodromakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T20:06:45+00:00",
          "link": "https://arxiv.org/abs/2412.09709v1",
          "size": "13717kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:23:32+00:00",
          "link": "https://arxiv.org/abs/2412.09709v2",
          "size": "12137kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:16:42+00:00",
          "link": "https://arxiv.org/abs/2412.09709v3",
          "size": "12137kb",
          "version": "v3"
        }
      ],
      "title": "DiP: A Scalable, Energy-Efficient Systolic Array for Matrix Multiplication Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09709",
        "HTML": "https://arxiv.org/html/2412.09709v3",
        "PDF": "https://arxiv.org/pdf/2412.09709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a systolic array architecture for accelerating matrix multiplication in NLP models, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.09900",
      "abstract": "Machine learning (ML) algorithms play a critical role in decision-making across various domains, such as healthcare, finance, education, and law enforcement. However, concerns about fairness and bias in these systems have raised significant ethical and social challenges. To address these challenges, this research utilizes two prominent fairness libraries, Fairlearn by Microsoft and AIF360 by IBM. These libraries offer comprehensive frameworks for fairness analysis, providing tools to evaluate fairness metrics, visualize results, and implement bias mitigation algorithms. The study focuses on assessing and mitigating biases for unstructured datasets using Computer Vision (CV) and Natural Language Processing (NLP) models. The primary objective is to present a comparative analysis of the performance of mitigation algorithms from the two fairness libraries. This analysis involves applying the algorithms individually, one at a time, in one of the stages of the ML lifecycle, pre-processing, in-processing, or post-processing, as well as sequentially across more than one stage. The results reveal that some sequential applications improve the performance of mitigation algorithms by effectively reducing bias while maintaining the model's performance. Publicly available datasets from Kaggle were chosen for this research, providing a practical context for evaluating fairness in real-world machine learning workflows.",
      "authors": [
        "Ahmed Rashed",
        "Abdelkrim Kallich",
        "and Mohamed Eltayeb"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T06:35:55+00:00",
          "link": "https://arxiv.org/abs/2412.09900v1",
          "size": "811kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T00:59:26+00:00",
          "link": "https://arxiv.org/abs/2412.09900v2",
          "size": "235kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T21:24:40+00:00",
          "link": "https://arxiv.org/abs/2412.09900v3",
          "size": "2398kb",
          "version": "v3"
        }
      ],
      "title": "Analyzing Fairness of Computer Vision and Natural Language Processing Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09900",
        "HTML": "https://arxiv.org/html/2412.09900v3",
        "PDF": "https://arxiv.org/pdf/2412.09900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses bias mitigation and fairness in ML models, which can include NLP models, its primary focus is on fairness analysis rather than data processing techniques explicitly for LLM training."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10510",
      "abstract": "The proliferation of disinformation demands reliable and scalable fact-checking solutions. We present Dynamic Evidence-based FAct-checking with Multimodal Experts (DEFAME), a modular, zero-shot MLLM pipeline for open-domain, text-image claim verification. DEFAME operates in a six-stage process, dynamically selecting the tools and search depth to extract and evaluate textual and visual evidence. Unlike prior approaches that are text-only, lack explainability, or rely solely on parametric knowledge, DEFAME performs end-to-end verification, accounting for images in claims and evidence while generating structured, multimodal reports. Evaluation on the popular benchmarks VERITE, AVerITeC, and MOCHEG shows that DEFAME surpasses all previous methods, establishing itself as the new state-of-the-art fact-checking system for uni- and multimodal fact-checking. Moreover, we introduce a new multimodal benchmark, ClaimReview2024+, featuring claims after the knowledge cutoff of GPT-4o, avoiding data leakage. Here, DEFAME drastically outperforms the GPT-4o baselines, showing temporal generalizability and the potential for real-time fact-checking.",
      "authors": [
        "Tobias Braun",
        "Mark Rothermel",
        "Marcus Rohrbach",
        "Anna Rohrbach"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T19:11:18+00:00",
          "link": "https://arxiv.org/abs/2412.10510v1",
          "size": "2084kb",
          "version": "v1"
        },
        {
          "date": "2025-02-06T13:27:38+00:00",
          "link": "https://arxiv.org/abs/2412.10510v2",
          "size": "3211kb",
          "version": "v2"
        },
        {
          "date": "2025-06-05T17:10:20+00:00",
          "link": "https://arxiv.org/abs/2412.10510v3",
          "size": "2814kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T14:06:15+00:00",
          "link": "https://arxiv.org/abs/2412.10510v4",
          "size": "2824kb",
          "version": "v4"
        }
      ],
      "title": "DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10510",
        "HTML": "https://arxiv.org/html/2412.10510v4",
        "PDF": "https://arxiv.org/pdf/2412.10510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a fact-checking system that utilizes multimodal data for claim verification. It does not address any aspect directly related to LLM training data processing, such as data collection or dataset creation for pretraining or fine-tuning."
      },
      "datasets": [
        {
          "dataset_name": "MAI-Lab/ClaimReview2024plus",
          "downloads": "13",
          "likes": "1",
          "link": "https://huggingface.co/datasets/MAI-Lab/ClaimReview2024plus"
        }
      ],
      "tasks": [
        "Claim Verification",
        "Fact Checking"
      ],
      "repo_urls": [
        "https://github.com/multimodal-ai-lab/defame"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.13102",
      "abstract": "Evaluation plays a crucial role in the advancement of information retrieval (IR) models. However, current benchmarks, which are based on predefined domains and human-labeled data, face limitations in addressing evaluation needs for emerging domains both cost-effectively and efficiently. To address this challenge, we propose the Automated Heterogeneous Information Retrieval Benchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1) Automated. The testing data in AIR-Bench is automatically generated by large language models (LLMs) without human intervention. 2) Heterogeneous. The testing data in AIR-Bench is generated with respect to diverse tasks, domains and languages. 3) Dynamic. The domains and languages covered by AIR-Bench are constantly augmented to provide an increasingly comprehensive evaluation benchmark for community developers. We develop a reliable and robust data generation pipeline to automatically create diverse and high-quality evaluation datasets based on real-world corpora. Our findings demonstrate that the generated testing data in AIR-Bench aligns well with human-labeled testing data, making AIR-Bench a dependable benchmark for evaluating IR models. The resources in AIR-Bench are publicly available at https://github.com/AIR-Bench/AIR-Bench.",
      "authors": [
        "Jianlyu Chen",
        "Nan Wang",
        "Chaofan Li",
        "Bo Wang",
        "Shitao Xiao",
        "Han Xiao",
        "Hao Liao",
        "Defu Lian",
        "Zheng Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T17:15:21+00:00",
          "link": "https://arxiv.org/abs/2412.13102v1",
          "size": "321kb",
          "version": "v1"
        },
        {
          "date": "2024-12-18T07:06:07+00:00",
          "link": "https://arxiv.org/abs/2412.13102v2",
          "size": "321kb",
          "version": "v2"
        },
        {
          "date": "2024-12-20T05:42:38+00:00",
          "link": "https://arxiv.org/abs/2412.13102v3",
          "size": "322kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T02:12:07+00:00",
          "link": "https://arxiv.org/abs/2412.13102v4",
          "size": "325kb",
          "version": "v4"
        }
      ],
      "title": "AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13102",
        "HTML": "https://arxiv.org/html/2412.13102v4",
        "PDF": "https://arxiv.org/pdf/2412.13102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces AIR-Bench, which automates the generation of evaluation datasets using LLMs. It presents a new data generation pipeline for creating high-quality datasets to test models, making it relevant to the creation and processing of training data for LLMs."
      },
      "tasks": [
        "Information Retrieval",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/air-bench/air-bench"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.14019",
      "abstract": "Traditional causal discovery methods often rely on strong, untestable assumptions, which makes them unreliable in real applications. In this context, Large Language Models (LLMs) have emerged as a promising alternative for extracting causal knowledge from text-based metadata, which consolidates domain expertise. However, LLMs tend to be unreliable and prone to hallucinations, necessitating strategies that account for their limitations. One effective strategy is to use a consistency measure to assess reliability. Additionally, most text metadata does not clearly distinguish direct causal relationships from indirect ones, further complicating the discovery of a causal DAG. As a result, focusing on causal orders, rather than causal DAGs, emerges as a more practical and robust approach. We present a new method to derive a class of acyclic tournaments, which represent plausible causal orders, maximizing a consistency score derived from an LLM. Our approach starts by calculating pairwise consistency scores between variables, resulting in a semi-complete partially directed graph that consolidates these scores into an abstraction of the maximally consistent causal orders. Using this structure, we identify optimal acyclic tournaments, focusing on those that maximize consistency across all configurations. We subsequently show how both the abstraction and the class of causal orders can be used to estimate causal effects. We tested our method on both well-established benchmarks, as well as, real-world datasets from epidemiology and public health. Our results demonstrate the effectiveness of our approach in recovering the correct causal order.",
      "authors": [
        "Federico Baldo",
        "Simon Ferreira",
        "Charles K. Assaad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T16:37:51+00:00",
          "link": "https://arxiv.org/abs/2412.14019v1",
          "size": "345kb",
          "version": "v1"
        },
        {
          "date": "2025-02-09T16:40:38+00:00",
          "link": "https://arxiv.org/abs/2412.14019v2",
          "size": "335kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T11:38:53+00:00",
          "link": "https://arxiv.org/abs/2412.14019v3",
          "size": "53kb",
          "version": "v3"
        }
      ],
      "title": "Retrieving Classes of Causal Orders with Inconsistent Knowledge Bases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14019",
        "HTML": "https://arxiv.org/html/2412.14019v3",
        "PDF": "https://arxiv.org/pdf/2412.14019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper involves the use of LLMs, it is oriented towards causal discovery and creating causal orders from inconsistent knowledge bases, with no focus on LLM training data processing."
      },
      "tasks": [
        "Causal Discovery",
        "Epidemiology"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.14209",
      "abstract": "Explainable Artificial Intelligence seeks to make the reasoning processes of AI models transparent and interpretable, particularly in complex decision making environments. In the construction industry, where AI based decision support systems are increasingly adopted, limited attention has been paid to the integration of supporting evidence that underpins the reliability and accountability of AI generated outputs. The absence of such evidence undermines the validity of explanations and the trustworthiness of system recommendations. This paper addresses this gap by introducing a theoretical, evidence based means end framework developed through a narrative review. The framework offers an epistemic foundation for designing XAI enabled DSS that generate meaningful explanations tailored to users knowledge needs and decision contexts. It focuses on evaluating the strength, relevance, and utility of different types of evidence supporting AI generated explanations. While developed with construction professionals as primary end users, the framework is also applicable to developers, regulators, and project managers with varying epistemic goals.",
      "authors": [
        "Peter E.D. Love",
        "Jane Matthews",
        "Weili Fang",
        "and Hadi Mahamivanan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T13:02:05+00:00",
          "link": "https://arxiv.org/abs/2412.14209v1",
          "size": "710kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T06:11:52+00:00",
          "link": "https://arxiv.org/abs/2412.14209v2",
          "size": "875kb",
          "version": "v2"
        }
      ],
      "title": "Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14209",
        "PDF": "https://arxiv.org/pdf/2412.14209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the integration of evidence in AI systems within the construction industry, primarily focusing on explainable AI rather than any aspect of LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Explainable artificial intelligence"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.15669",
      "abstract": "We present a model for inferring where users look during interaction based on keypress data only. Given a key log, it outputs a scanpath that tells, moment-by-moment, how the user had moved eyes while entering those keys. The model can be used as a proxy for human data in cases where collecting real eye tracking data is expensive or impossible. Our technical insight is an inference architecture that considers the individual characteristics of the user, inferred as a low-dimensional parameter vector. We present a novel loss function for synchronizing inferred eye movements with the keypresses. Evaluations on touchscreen typing demonstrate accurate gaze inference.",
      "authors": [
        "Yujun Zhu",
        "Danqing Shi",
        "Hee-Seung Moon",
        "Antti Oulasvirta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T08:35:12+00:00",
          "link": "https://arxiv.org/abs/2412.15669v1",
          "size": "5547kb",
          "version": "v1"
        },
        {
          "date": "2025-02-13T19:25:17+00:00",
          "link": "https://arxiv.org/abs/2412.15669v2",
          "size": "7167kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T20:14:53+00:00",
          "link": "https://arxiv.org/abs/2412.15669v3",
          "size": "1116kb",
          "version": "v3"
        }
      ],
      "title": "WigglyEyes: Inferring Eye Movements from Keypress Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15669",
        "HTML": "https://arxiv.org/html/2412.15669v3",
        "PDF": "https://arxiv.org/pdf/2412.15669"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses inferring eye movements from keypress data, which does not involve any aspect of LLM training data processing or contribute to operations like data collection, filtering, or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.17934",
      "abstract": "In recent years, Unmanned Aerial Vehicles (UAVs) have been utilized as effective platforms for carrying Wi-Fi Access Points (APs) and cellular Base Stations (BSs), enabling low-cost, agile, and flexible wireless networks with high Quality of Service (QoS). The next generation of wireless communications will rely on increasingly higher frequencies, which are easily obstructed by obstacles. One of the most critical concepts yet to be fully addressed is positioning the UAV at optimal coordinates while accounting for obstacles. To ensure a line of sight (LoS) between UAVs and user equipment (UE), improve QoS, and establish reliable wireless links with maximum coverage, obstacles must be integrated into the proposed placement algorithms. This paper introduces a simulation-based measurement approach for characterizing an air-to-ground (AG) channel in a simple scenario. By considering obstacles, we present a novel perspective on channel characterization. The results, in terms of throughput, packet delivery, packet loss, and delay, are compared using the proposed positioning approach.",
      "authors": [
        "Kamal Shayegan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T19:45:21+00:00",
          "link": "https://arxiv.org/abs/2412.17934v1",
          "size": "642kb",
          "version": "v1"
        },
        {
          "date": "2024-12-30T11:14:58+00:00",
          "link": "https://arxiv.org/abs/2412.17934v2",
          "size": "643kb",
          "version": "v2"
        },
        {
          "date": "2025-02-14T14:31:57+00:00",
          "link": "https://arxiv.org/abs/2412.17934v3",
          "size": "643kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T11:10:54+00:00",
          "link": "https://arxiv.org/abs/2412.17934v4",
          "size": "644kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T15:13:16+00:00",
          "link": "https://arxiv.org/abs/2412.17934v5",
          "size": "644kb",
          "version": "v5"
        }
      ],
      "title": "UAV Communications: Impact of Obstacles on Channel Characteristics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17934",
        "PDF": "https://arxiv.org/pdf/2412.17934"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines UAV communications and the impact of obstacles on channel characteristics. It does not involve LLM training data processing, data quality improvement, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18003",
      "abstract": "We develop novel integrated learning and optimization (ILO) methodologies to solve economic dispatch (ED) and DC optimal power flow (DCOPF) problems for better economic operation. The optimization problem for ED is formulated with load being an unknown parameter while DCOPF consists of load and power transfer distribution factor (PTDF) matrix as unknown parameters. PTDF represents the incremental variations of real power on transmission lines which occur due to real power transfers between two regions. These values represent a linearized approximation of power flows over the transmission lines. We develop novel ILO formulations to solve post-hoc penalties in electricity market and line congestion problems using ED and DCOPF optimization formulations. Our proposed methodologies capture the real-time electricity market and line congestion behavior to train the regret function which eventually train unknown loads at different buses and line PTDF matrix to achieve the afore-mentioned post-hoc goals. The proposed methodology is compared to sequential learning and optimization (SLO) which train load and PTDF forecasts for accuracy rather than economic operation. Our experimentation prove the superiority of ILO in minimizing the post-hoc penalties in electricity markets and minimizing the line congestion thereby improving the economic operation with noticeable amount.",
      "authors": [
        "Imran Pervez",
        "Ricardo Pinto Lima",
        "Omar Knio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T21:53:06+00:00",
          "link": "https://arxiv.org/abs/2412.18003v1",
          "size": "7884kb",
          "version": "v1"
        },
        {
          "date": "2025-01-06T05:46:18+00:00",
          "link": "https://arxiv.org/abs/2412.18003v2",
          "size": "25757kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T06:25:26+00:00",
          "link": "https://arxiv.org/abs/2412.18003v3",
          "size": "8981kb",
          "version": "v3"
        }
      ],
      "title": "Integrated Learning and Optimization for Congestion Management and Profit Maximization in Real-Time Electricity Market",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18003",
        "PDF": "https://arxiv.org/pdf/2412.18003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on optimization methodologies for real-time electricity markets and congestion management. It does not address any aspects of LLM training data processing or dataset manipulation."
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01144",
      "abstract": "The rapidly increasing size of large language models (LLMs) presents significant challenges in memory usage and computational costs. Quantizing both weights and activations can address these issues, with hardware-supported fine-grained scaling emerging as a promising solution to mitigate outliers. However, existing methods struggle to capture nuanced block data distributions. We propose BlockDialect, a block-wise fine-grained mixed format technique that assigns a per-block optimal number format from a formatbook for better data representation. Additionally, we introduce DialectFP4, a formatbook of FP4 variants (akin to dialects) that adapt to diverse data distributions. To leverage this efficiently, we propose a two-stage approach for online DialectFP4 activation quantization. Importantly, DialectFP4 ensures energy efficiency by selecting representable values as scaled integers compatible with low-precision integer arithmetic. BlockDialect achieves 10.78% (7.48%) accuracy gain on the LLaMA3-8B (LLaMA2-7B) model compared to MXFP4 format with lower bit usage per data, while being only 5.45% (2.69%) below full precision even when quantizing full-path matrix multiplication. Focusing on how to represent over how to scale, our work presents a promising path for energy-efficient LLM inference.",
      "authors": [
        "Wonsuk Jang",
        "Thierry Tambe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T08:57:00+00:00",
          "link": "https://arxiv.org/abs/2501.01144v1",
          "size": "1734kb",
          "version": "v1"
        },
        {
          "date": "2025-01-03T09:27:46+00:00",
          "link": "https://arxiv.org/abs/2501.01144v2",
          "size": "1188kb",
          "version": "v2"
        },
        {
          "date": "2025-01-21T07:34:54+00:00",
          "link": "https://arxiv.org/abs/2501.01144v3",
          "size": "3382kb",
          "version": "v3"
        },
        {
          "date": "2025-07-01T03:02:26+00:00",
          "link": "https://arxiv.org/abs/2501.01144v4",
          "size": "2695kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T03:46:03+00:00",
          "link": "https://arxiv.org/abs/2501.01144v5",
          "size": "2696kb",
          "version": "v5"
        }
      ],
      "title": "BlockDialect: Block-wise Fine-grained Mixed Format Quantization for Energy-Efficient LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01144",
        "HTML": "https://arxiv.org/html/2501.01144v5",
        "PDF": "https://arxiv.org/pdf/2501.01144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantization techniques for improving energy efficiency during LLM inference, not on data processing for LLM training or fine-tuning stages."
      },
      "tasks": [
        "Quantization"
      ],
      "repo_urls": [
        "https://code.stanford.edu/tambe-lab/blockdialect"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06726",
      "abstract": "Sensing and edge artificial intelligence (AI) are envisioned as two essential and interconnected functions in sixth-generation (6G) mobile networks. On the one hand, sensing-empowered applications rely on powerful AI models to extract features and understand semantics from ubiquitous wireless sensors. On the other hand, the massive amount of sensory data serves as the fuel to continuously refine edge AI models. This deep integration of sensing and edge AI has given rise to a new task-oriented paradigm known as integrated sensing and edge AI (ISEA), which features a holistic design approach to communication, AI computation, and sensing for optimal sensing-task performance. In this article, we present a comprehensive survey for ISEA. We first provide technical preliminaries for sensing, edge AI, and new communication paradigms in ISEA. Then, we study several use cases of ISEA to demonstrate its practical relevance and introduce current standardization and industrial progress. Next, the design principles, metrics, tradeoffs, and architectures of ISEA are established, followed by a thorough overview of ISEA techniques, including digital air interface, over-the-air computation, and advanced signal processing. Its interplay with various 6G advancements, e.g., new physical-layer and networking techniques, are presented. Finally, we present future research opportunities in ISEA, including the integration of foundation models, convergence of ISEA and integrated sensing and communications (ISAC), ultra-low-latency ISEA, and practicality issues.",
      "authors": [
        "Zhiyan Liu",
        "Xu Chen",
        "Hai Wu",
        "Zhanwei Wang",
        "Xianhao Chen",
        "Dusit Niyato",
        "Kaibin Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T06:25:58+00:00",
          "link": "https://arxiv.org/abs/2501.06726v1",
          "size": "5049kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:54:25+00:00",
          "link": "https://arxiv.org/abs/2501.06726v2",
          "size": "10679kb",
          "version": "v2"
        }
      ],
      "title": "Integrated Sensing and Edge AI: Realizing Intelligent Perception in 6G",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06726",
        "HTML": "https://arxiv.org/html/2501.06726v2",
        "PDF": "https://arxiv.org/pdf/2501.06726"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys integrated sensing and edge AI in 6G, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.08698",
      "abstract": "The \\emph{coloring number} $\\mathrm{col}(G)$ of a graph $G$, which is equal to the \\emph{degeneracy} of $G$ plus one, provides a very useful measure for the uniform sparsity of $G$. The coloring number is generalized by three series of measures, the \\emph{generalized coloring numbers}. These are the \\emph{$r$-admissibility} $\\mathrm{adm}_r(G)$, the \\emph{strong $r$-coloring number} $\\mathrm{col}_r(G)$ and the \\emph{weak $r$-coloring number} $\\mathrm{wcol}_r(G)$, where $r$ is an integer parameter. The generalized coloring numbers measure the edge density of bounded-depth minors and thereby provide an even more uniform measure of sparsity of graphs. They have found many applications in graph theory and in particular play a key role in the theory of bounded expansion and nowhere dense graph classes introduced by Ne\\v{s}et\\v{r}il and Ossona de Mendez. We overview combinatorial and algorithmic applications of the generalized coloring numbers, emphasizing new developments in this area. We also present a simple proof for the existence of uniform orders and improve known bounds, e.g., for the weak coloring numbers on graphs with excluded topological minors.",
      "authors": [
        "Sebastian Siebertz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Logic in Computer Science (cs.LO)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T10:17:52+00:00",
          "link": "https://arxiv.org/abs/2501.08698v1",
          "size": "1427kb",
          "version": "v1"
        },
        {
          "date": "2025-01-16T16:38:59+00:00",
          "link": "https://arxiv.org/abs/2501.08698v2",
          "size": "1430kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T15:15:50+00:00",
          "link": "https://arxiv.org/abs/2501.08698v3",
          "size": "1424kb",
          "version": "v3"
        }
      ],
      "title": "On the generalized coloring numbers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08698",
        "HTML": "https://arxiv.org/html/2501.08698v3",
        "PDF": "https://arxiv.org/pdf/2501.08698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses generalized coloring numbers in graph theory, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.12040",
      "abstract": "Vehicle-to-everything communications-assisted autonomous driving has witnessed remarkable advancements in recent years, with pragmatic communications (PragComm) emerging as a promising paradigm for real-time collaboration among vehicles and other agents. Simultaneously, extensive research has explored the interplay between collaborative perception and decision-making in end-to-end driving frameworks. In this work, we revisit the collaborative driving problem and propose the Select2Drive framework to optimize the utilization of limited computational and communication resources. Particularly, to mitigate cumulative latency in perception and decision-making, Select2Drive introduces distributed predictive perception by formulating an active prediction paradigm and simplifying high-dimensional semantic feature prediction into a computation cost-efficient, motion-aware reconstruction. Given the ``less is more\" principle that an over-broadened perceptual horizon possibly confuses the decision module rather than contributing to it, Select2Drive utilizes area-of-importance-based PragComm to prioritize the communications of critical regions, thus boosting both communication efficiency and decision-making efficacy. Empirical evaluations on the V2Xverse and real-world DAIR-V2X demonstrate that Select2Drive achieves a $2.60$\\% and $1.99$\\% improvement in offline perception tasks under limited bandwidth (resp., pose error conditions). Moreover, it delivers at most $8.35$\\% and $2.65$\\% enhancement in closed-loop driving scores and route completion rates, particularly in scenarios characterized by dense traffic and high-speed dynamics.",
      "authors": [
        "Jiahao Huang",
        "Jianhang Zhu",
        "Rongpeng Li",
        "Zhifeng Zhao",
        "and Honggang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T11:01:40+00:00",
          "link": "https://arxiv.org/abs/2501.12040v1",
          "size": "25533kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T03:16:21+00:00",
          "link": "https://arxiv.org/abs/2501.12040v2",
          "size": "3921kb",
          "version": "v2"
        }
      ],
      "title": "Select2Drive: Pragmatic Communications for Real-Time Collaborative Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12040",
        "HTML": "https://arxiv.org/html/2501.12040v2",
        "PDF": "https://arxiv.org/pdf/2501.12040"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about pragmatic communications for autonomous driving, not about data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13724",
      "abstract": "This paper provides a dual domain derivation of the error exponent of maximum mutual information (MMI) decoding with constant composition codes, showing it coincides with that of maximum likelihood decoding for discrete memoryless channels. The analysis is further extended to joint source-channel coding, demonstrating that the generalized MMI decoder achieves the same random coding error exponent as the maximum a posteriori decoder.",
      "authors": [
        "AmirPouya Moeini and Albert Guill\\'en i F\\`abregas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T14:57:40+00:00",
          "link": "https://arxiv.org/abs/2501.13724v1",
          "size": "14kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:44:07+00:00",
          "link": "https://arxiv.org/abs/2501.13724v2",
          "size": "13kb",
          "version": "v2"
        }
      ],
      "title": "Dual-Domain Exponent of Maximum Mutual Information Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13724",
        "HTML": "https://arxiv.org/html/2501.13724v2",
        "PDF": "https://arxiv.org/pdf/2501.13724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with decoding methods in the context of communication channels, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.15480",
      "abstract": "We explore and evaluate the interactions between Behavioral Programming (BP) and a range of Artificial Intelligence (AI) and Formal Methods (FM) techniques. Our goal is to demonstrate that BP can serve as an abstraction that integrates various techniques, enabling a multifaceted analysis and a rich development process. Specifically, the paper examines how the BPpy framework, a Python-based implementation of BP, is enhanced by and enhances various FM and AI tools. We assess how integrating BP with tools such as Satisfiability Modulo Theory (SMT) solvers, symbolic and probabilistic model checking, and Deep Reinforcement Learning (DRL) allow us to scale the abilities of BP to model complex systems. Additionally, we illustrate how developers can leverage multiple tools within a single modeling and development task. The paper provides quantitative and qualitative evidence supporting the feasibility of our vision to create a comprehensive toolbox for harnessing AI and FM methods in a unified development framework.",
      "authors": [
        "Tom Yaacov",
        "Gera Weiss",
        "Adiel Ashrov",
        "Guy Katz and Jules Zisser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-26T10:52:13+00:00",
          "link": "https://arxiv.org/abs/2501.15480v1",
          "size": "1173kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:21:21+00:00",
          "link": "https://arxiv.org/abs/2501.15480v2",
          "size": "689kb",
          "version": "v2"
        }
      ],
      "title": "Exploring and Evaluating Interplays of BPpy with Deep Reinforcement Learning and Formal Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15480",
        "PDF": "https://arxiv.org/pdf/2501.15480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the integration of Behavioral Programming with AI and Formal Methods, including Deep Reinforcement Learning, but does not address any aspects of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/bthink-bgu/papers-2025-enase-bppyevaluation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.15916",
      "abstract": "This paper studies an online variant of the celebrated housing market problem, where each agent has a single house and seeks to exchange it for another based on her preferences. In this online setting, agents may arrive and depart at any time, meaning that not all agents are present on the housing market simultaneously. I extend the well known serial dictatorship and Gale s top trading cycle mechanisms to this online scenario, aiming to retain their desirable properties such as Pareto efficiency, individual rationality, and strategy proofness. These extensions also seek to prevent agents from strategically delaying their arrival or advancing their departure. I demonstrate that achieving all of these properties simultaneously is impossible in the online context, and I present several variants that achieve different subsets of these properties.",
      "authors": [
        "Julien Lesca"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T10:05:49+00:00",
          "link": "https://arxiv.org/abs/2501.15916v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T10:10:42+00:00",
          "link": "https://arxiv.org/abs/2501.15916v2",
          "size": "198kb",
          "version": "v2"
        }
      ],
      "title": "Online Housing Market",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15916",
        "HTML": "https://arxiv.org/html/2501.15916v2",
        "PDF": "https://arxiv.org/pdf/2501.15916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses an online variant of the housing market problem, concentrating on mechanisms for exchanging houses based on preferences, without any connection to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.17349",
      "abstract": "This paper presents a numerical function optimization framework designed for constrained optimization problems in robotics. The tool is designed with real-time considerations and is suitable for online trajectory and control input optimization problems. The proposed framework does not require any analytical representation of the problem and works with constrained block-box optimization functions. The method combines first-order gradient-based line search algorithms with constraint prioritization through nullspace projections onto constraint Jacobian space. The tool is implemented in C++ and provided online for community use, along with some numerical and robotic example implementations presented in this paper.",
      "authors": [
        "Sait Sovukluk and Christian Ott"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T23:51:44+00:00",
          "link": "https://arxiv.org/abs/2501.17349v1",
          "size": "6134kb",
          "version": "v1"
        },
        {
          "date": "2025-01-30T12:13:01+00:00",
          "link": "https://arxiv.org/abs/2501.17349v2",
          "size": "6134kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:22:31+00:00",
          "link": "https://arxiv.org/abs/2501.17349v3",
          "size": "6134kb",
          "version": "v3"
        }
      ],
      "title": "An Efficient Numerical Function Optimization Framework for Constrained Nonlinear Robotic Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17349",
        "HTML": "https://arxiv.org/html/2501.17349v3",
        "PDF": "https://arxiv.org/pdf/2501.17349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about a numerical function optimization framework for constrained nonlinear problems in robotics, which does not pertain to LLM training data processing or techniques."
      },
      "repo_urls": [
        "https://github.com/ssovukluk/enforcpp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17351",
      "abstract": "One of the essential aspects of humanoid robot running is determining the limb-swinging trajectories. During the flight phases, where the ground reaction forces are not available for regulation, the limb swinging trajectories are significant for the stability of the next stance phase. Due to the conservation of angular momentum, improper leg and arm swinging results in highly tilted and unsustainable body configurations at the next stance phase landing. In such cases, the robotic system fails to maintain locomotion independent of the stability of the center of mass trajectories. This problem is more apparent for fast and high flight time trajectories. This paper proposes a real-time nonlinear limb trajectory optimization problem for humanoid running. The optimization problem is tested on two different humanoid robot models, and the generated trajectories are verified using a running algorithm for both robots in a simulation environment.",
      "authors": [
        "Sait Sovukluk",
        "Robert Schuller",
        "Johannes Englsberger",
        "and Christian Ott"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T00:06:01+00:00",
          "link": "https://arxiv.org/abs/2501.17351v1",
          "size": "35126kb",
          "version": "v1"
        },
        {
          "date": "2025-01-30T12:32:12+00:00",
          "link": "https://arxiv.org/abs/2501.17351v2",
          "size": "35127kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:38:20+00:00",
          "link": "https://arxiv.org/abs/2501.17351v3",
          "size": "35127kb",
          "version": "v3"
        }
      ],
      "title": "Realtime Limb Trajectory Optimization for Humanoid Running Through Centroidal Angular Momentum Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17351",
        "HTML": "https://arxiv.org/html/2501.17351v3",
        "PDF": "https://arxiv.org/pdf/2501.17351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing limb trajectory for humanoid running using centroidal angular momentum dynamics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.00352",
      "abstract": "Reinforcement learning (RL) shows great potential for optimizing multi-vehicle cooperative driving strategies through the state-action-reward feedback loop, but it still faces challenges such as low sample efficiency. This paper proposes a differentiated reward method based on steady-state transition systems, which incorporates state transition gradient information into the reward design by analyzing traffic flow characteristics, aiming to optimize action selection and policy learning in multi-vehicle cooperative decision-making. The performance of the proposed method is validated in RL algorithms such as MAPPO, MADQN, and QMIX under varying autonomous vehicle penetration. The results show that the differentiated reward method significantly accelerates training convergence and outperforms centering reward and others in terms of traffic efficiency, safety, and action rationality. Additionally, the method demonstrates strong scalability and environmental adaptability, providing a novel approach for multi-agent cooperative decision-making in complex traffic scenarios.",
      "authors": [
        "Ye Han",
        "Lijun Zhang",
        "Dejian Meng",
        "Zhuang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T07:16:15+00:00",
          "link": "https://arxiv.org/abs/2502.00352v1",
          "size": "1699kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T06:12:24+00:00",
          "link": "https://arxiv.org/abs/2502.00352v2",
          "size": "1733kb",
          "version": "v2"
        }
      ],
      "title": "A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00352",
        "HTML": "https://arxiv.org/html/2502.00352v2",
        "PDF": "https://arxiv.org/pdf/2502.00352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning for multi-vehicle cooperative decision-making, specifically using a differentiated reward method, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01108",
      "abstract": "Photoplethysmography (PPG)-based foundation models are gaining traction due to the widespread use of PPG in biosignal monitoring and their potential to generalize across diverse health applications. In this paper, we introduce Pulse-PPG, the first open-source PPG foundation model trained exclusively on raw PPG data collected over a 100-day field study with 120 participants. Existing PPG foundation models are either open-source but trained on clinical data or closed-source, limiting their applicability in real-world settings. We evaluate Pulse-PPG across multiple datasets and downstream tasks, comparing its performance against a state-of-the-art foundation model trained on clinical data. Our results demonstrate that Pulse-PPG, trained on uncurated field data, exhibits superior generalization across clinical and mobile health applications in both lab and field settings. This suggests that exposure to real-world variability enables the model to learn fine-grained representations, making it more adaptable across tasks. Furthermore, pre-training on field data surprisingly outperforms its pre-training on clinical data in many tasks, reinforcing the importance of training on real-world, diverse datasets. To encourage further advancements in robust foundation models leveraging field data, we plan to release Pulse-PPG, providing researchers with a powerful resource for developing more generalizable PPG-based models.",
      "authors": [
        "Mithun Saha",
        "Maxwell A. Xu",
        "Wanting Mao",
        "Sameer Neupane",
        "James M. Rehg",
        "Santosh Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T06:56:40+00:00",
          "link": "https://arxiv.org/abs/2502.01108v1",
          "size": "5485kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T23:13:37+00:00",
          "link": "https://arxiv.org/abs/2502.01108v2",
          "size": "2216kb",
          "version": "v2"
        }
      ],
      "title": "Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01108",
        "HTML": "https://arxiv.org/html/2502.01108v2",
        "PDF": "https://arxiv.org/pdf/2502.01108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces Pulse-PPG, an open-source PPG foundation model dataset trained on uncurated field data, which could relate to dataset creation. However, it primarily addresses PPG biosignal monitoring, not LLM data processing."
      },
      "tasks": [
        "Photoplethysmography (PPG)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02452",
      "abstract": "Personalization of Large Vision-Language Models (LVLMs) involves customizing models to recognize specific users and object instances, and to generate contextually tailored responses. Existing approaches typically rely on time-consuming test-time training for each user or object, making them impractical for real-world deployment, a limitation reflected in current personalization benchmarks, which are focused on object-centric, single-concept evaluations. In this paper, we present a novel training-free approach to LVLM personalization and introduce a comprehensive real-world benchmark designed to rigorously evaluate various aspects of the personalization task. Our method leverages pre-trained vision foundation models to extract distinctive features, applies retrieval-augmented generation (RAG) techniques to identify instances within visual inputs, and employs visual prompting strategies to guide model outputs. Our model-agnostic vision toolkit enables efficient and flexible multi-concept personalization across both images and videos, without any additional training. We achieve state-of-the-art results, surpassing existing training-based methods.",
      "authors": [
        "Soroush Seifi",
        "Vaggelis Dorovatas",
        "Daniel Olmeda Reino",
        "Rahaf Aljundi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T16:19:20+00:00",
          "link": "https://arxiv.org/abs/2502.02452v1",
          "size": "29743kb",
          "version": "v1"
        },
        {
          "date": "2025-03-24T12:34:02+00:00",
          "link": "https://arxiv.org/abs/2502.02452v2",
          "size": "40434kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T13:59:57+00:00",
          "link": "https://arxiv.org/abs/2502.02452v3",
          "size": "41472kb",
          "version": "v3"
        }
      ],
      "title": "Personalization Toolkit: Training Free Personalization of Large Vision Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02452",
        "HTML": "https://arxiv.org/html/2502.02452v3",
        "PDF": "https://arxiv.org/pdf/2502.02452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a training-free personalization approach for Large Vision-Language Models (LVLMs), focusing on vision rather than language model training data processing."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation",
        "Visual Prompting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.03699",
      "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence with capabilities in reasoning, coding, and communication, driving innovation across industries. Their true potential depends on effective alignment to ensure correct, trustworthy and ethical behavior, addressing challenges like misinformation, hallucinations, bias and misuse. While existing Reinforcement Learning (RL)-based alignment methods are notoriously complex, direct optimization approaches offer a simpler alternative. In this work, we introduce a novel direct optimization approach for LLM alignment by drawing on established Information Retrieval (IR) principles. We present a systematic framework that bridges LLM alignment and IR methodologies, mapping LLM generation and reward models to IR's retriever-reranker paradigm. Building on this foundation, we propose LLM Alignment as Retriever Preference Optimization (LarPO), a new alignment method that enhances overall alignment quality. Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 % averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work opens new avenues for advancing LLM alignment by integrating IR foundations, offering a promising direction for future research.",
      "authors": [
        "Bowen Jin",
        "Jinsung Yoon",
        "Zhen Qin",
        "Ziqi Wang",
        "Wei Xiong",
        "Yu Meng",
        "Jiawei Han",
        "Sercan O. Arik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T01:22:06+00:00",
          "link": "https://arxiv.org/abs/2502.03699v1",
          "size": "255kb",
          "version": "v1"
        },
        {
          "date": "2025-06-09T19:53:37+00:00",
          "link": "https://arxiv.org/abs/2502.03699v2",
          "size": "201kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T21:26:26+00:00",
          "link": "https://arxiv.org/abs/2502.03699v3",
          "size": "211kb",
          "version": "v3"
        }
      ],
      "title": "LLM Alignment as Retriever Optimization: An Information Retrieval Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03699",
        "PDF": "https://arxiv.org/pdf/2502.03699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a new alignment method for LLMs using Information Retrieval principles. Although it deals with LLM alignment, it does not involve training data processing operations or dataset creation."
      },
      "tasks": [
        "Information Retrieval",
        "Misinformation",
        "Reinforcement Learning (RL)",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04757",
      "abstract": "Current Vision Language Models (VLMs) remain vulnerable to malicious prompts that induce harmful outputs. Existing safety benchmarks for VLMs primarily rely on automated evaluation methods, but these methods struggle to detect implicit harmful content or produce inaccurate evaluations. Therefore, we found that existing benchmarks have low levels of harmfulness, ambiguous data, and limited diversity in image-text pair combinations. To address these issues, we propose the ELITE benchmark, a high-quality safety evaluation benchmark for VLMs, underpinned by our enhanced evaluation method, the ELITE evaluator. The ELITE evaluator explicitly incorporates a toxicity score to accurately assess harmfulness in multimodal contexts, where VLMs often provide specific, convincing, but unharmful descriptions of images. We filter out ambiguous and low-quality image-text pairs from existing benchmarks using the ELITE evaluator and generate diverse combinations of safe and unsafe image-text pairs. Our experiments demonstrate that the ELITE evaluator achieves superior alignment with human evaluations compared to prior automated methods, and the ELITE benchmark offers enhanced benchmark quality and diversity. By introducing ELITE, we pave the way for safer, more robust VLMs, contributing essential tools for evaluating and mitigating safety risks in real-world applications.",
      "authors": [
        "Wonjun Lee",
        "Doehyeon Lee",
        "Eugene Choi",
        "Sangyoon Yu",
        "Ashkan Yousefpour",
        "Haon Park",
        "Bumsub Ham",
        "Suhyun Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T08:43:15+00:00",
          "link": "https://arxiv.org/abs/2502.04757v1",
          "size": "1659kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T04:39:28+00:00",
          "link": "https://arxiv.org/abs/2502.04757v2",
          "size": "1650kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T04:42:59+00:00",
          "link": "https://arxiv.org/abs/2502.04757v3",
          "size": "1663kb",
          "version": "v3"
        }
      ],
      "title": "ELITE: Enhanced Language-Image Toxicity Evaluation for Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04757",
        "HTML": "https://arxiv.org/html/2502.04757v3",
        "PDF": "https://arxiv.org/pdf/2502.04757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses the ELITE benchmark for evaluating vision language models, which involves filtering out ambiguous and low-quality image-text pairs, touching on data processing, but primarily focuses on safety evaluation rather than LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "kdst/ELITE",
          "downloads": "9",
          "likes": "2",
          "link": "https://huggingface.co/datasets/kdst/ELITE"
        }
      ],
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06764",
      "abstract": "Classifier-free guidance (CFG) is a key technique for improving conditional generation in diffusion models, enabling more accurate control while enhancing sample quality. It is natural to extend this technique to video diffusion, which generates video conditioned on a variable number of context frames, collectively referred to as history. However, we find two key challenges to guiding with variable-length history: architectures that only support fixed-size conditioning, and the empirical observation that CFG-style history dropout performs poorly. To address this, we propose the Diffusion Forcing Transformer (DFoT), a video diffusion architecture and theoretically grounded training objective that jointly enable conditioning on a flexible number of history frames. We then introduce History Guidance, a family of guidance methods uniquely enabled by DFoT. We show that its simplest form, vanilla history guidance, already significantly improves video generation quality and temporal consistency. A more advanced method, history guidance across time and frequency further enhances motion dynamics, enables compositional generalization to out-of-distribution history, and can stably roll out extremely long videos. Project website: https://boyuan.space/history-guidance",
      "authors": [
        "Kiwhan Song",
        "Boyuan Chen",
        "Max Simchowitz",
        "Yilun Du",
        "Russ Tedrake",
        "Vincent Sitzmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T18:44:25+00:00",
          "link": "https://arxiv.org/abs/2502.06764v1",
          "size": "13503kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T03:58:47+00:00",
          "link": "https://arxiv.org/abs/2502.06764v2",
          "size": "13503kb",
          "version": "v2"
        }
      ],
      "title": "History-Guided Video Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06764",
        "PDF": "https://arxiv.org/pdf/2502.06764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's main focus is on video diffusion models and improving video generation quality with history guidance, which does not relate to LLM training data processing."
      },
      "models": [
        {
          "model_path": "kiwhansong/DFoT",
          "downloads": "7806",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/kiwhansong/DFoT"
        }
      ],
      "tasks": [
        "Video Generation"
      ],
      "repo_urls": [
        "https://github.com/sensetime-fvg/opendwm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06785",
      "abstract": "Transformer networks have achieved remarkable success across diverse domains, leveraging a variety of architectural innovations, including residual connections. However, traditional residual connections, which simply sum the outputs of previous layers, can dilute crucial information. This work introduces DeepCrossAttention (DCA), an approach that enhances residual learning in transformers. DCA employs learnable, input-dependent weights to dynamically combine layer outputs, enabling the model to selectively focus on the most relevant information in any of the previous layers. Furthermore, DCA incorporates depth-wise cross-attention, allowing for richer interactions between layers at different depths. Our language modeling experiments show that DCA achieves improved perplexity for a given training time. Moreover, DCA obtains the same model quality up to 3x faster while adding a negligible number of parameters. Theoretical analysis confirms that DCA provides an improved trade-off between accuracy and model size when the ratio of collective layer ranks to the ambient dimension falls below a critical threshold.",
      "authors": [
        "Mike Heddes",
        "Adel Javanmard",
        "Kyriakos Axiotis",
        "Gang Fu",
        "MohammadHossein Bateni",
        "Vahab Mirrokni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T18:58:52+00:00",
          "link": "https://arxiv.org/abs/2502.06785v1",
          "size": "906kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T19:32:20+00:00",
          "link": "https://arxiv.org/abs/2502.06785v2",
          "size": "357kb",
          "version": "v2"
        }
      ],
      "title": "DeepCrossAttention: Supercharging Transformer Residual Connections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06785",
        "HTML": "https://arxiv.org/html/2502.06785v2",
        "PDF": "https://arxiv.org/pdf/2502.06785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on improving the transformer model's architecture with DeepCrossAttention for better residual connections, not involving any processes related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06788",
      "abstract": "Existing encoder-free vision-language models (VLMs) are rapidly narrowing the performance gap with their encoder-based counterparts, highlighting the promising potential for unified multimodal systems with structural simplicity and efficient deployment. We systematically clarify the performance gap between VLMs using pre-trained vision encoders, discrete tokenizers, and minimalist visual layers from scratch, deeply excavating the under-examined characteristics of encoder-free VLMs. We develop efficient strategies for encoder-free VLMs that rival mainstream encoder-based ones. After an in-depth investigation, we launch EVEv2.0, a new and improved family of encoder-free VLMs. We show that: (i) Properly decomposing and hierarchically associating vision and language within a unified model reduces interference between modalities. (ii) A well-designed training strategy enables effective optimization for encoder-free VLMs. Through extensive evaluation, our EVEv2.0 represents a thorough study for developing a decoder-only architecture across modalities, demonstrating superior data efficiency and strong vision-reasoning capability. Code is publicly available at: https://github.com/baaivision/EVE.",
      "authors": [
        "Haiwen Diao",
        "Xiaotong Li",
        "Yufeng Cui",
        "Yueze Wang",
        "Haoge Deng",
        "Ting Pan",
        "Wenxuan Wang",
        "Huchuan Lu",
        "Xinlong Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T18:59:58+00:00",
          "link": "https://arxiv.org/abs/2502.06788v1",
          "size": "2440kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T10:29:52+00:00",
          "link": "https://arxiv.org/abs/2502.06788v2",
          "size": "2441kb",
          "version": "v2"
        }
      ],
      "title": "EVEv2: Improved Baselines for Encoder-Free Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06788",
        "HTML": "https://arxiv.org/html/2502.06788v2",
        "PDF": "https://arxiv.org/pdf/2502.06788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the development of encoder-free vision-language models, mentioning data efficiency and training strategy, but doesn't directly contribute to LLM training data processing techniques or operations."
      },
      "models": [
        {
          "model_path": "BAAI/EVE-7B-HD-v2.0",
          "downloads": "14",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BAAI/EVE-7B-HD-v2.0"
        }
      ],
      "tasks": [
        "Decoder"
      ],
      "repo_urls": [
        "https://github.com/baaivision/eve"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12988",
      "abstract": "Previous approaches to persona simulation large language models (LLMs) have typically relied on learning basic biographical information, or using limited role-play dialogue datasets to capture a character's responses. However, a holistic representation of an individual goes beyond surface-level facts or conversations to deeper thoughts and thinking. In this work, we introduce CharacterBot, a model designed to replicate both the linguistic patterns and distinctive thought patterns as manifested in the textual works of a character. Using Lu Xun, a renowned Chinese writer as a case study, we propose four training tasks derived from his 17 essay collections. These include a pre-training task focused on mastering external linguistic structures and knowledge, as well as three fine-tuning tasks: multiple-choice question answering, generative question answering, and style transfer, each aligning the LLM with Lu Xun's internal ideation and writing style. To optimize learning across these tasks, we introduce a CharLoRA parameter updating mechanism, where a general linguistic style expert collaborates with other task-specific experts to better study both the language style and the understanding of deeper thoughts. We evaluate CharacterBot on three tasks for linguistic accuracy and opinion comprehension, demonstrating that it significantly outperforms the baselines on our adapted metrics. We hope this work inspires future research on deep character persona simulation LLMs while considering the importance of ethical standards.",
      "authors": [
        "Zixiao Wang",
        "Duzhen Zhang",
        "Ishita Agrawal",
        "Shen Gao",
        "Le Song",
        "Xiuying Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T16:11:54+00:00",
          "link": "https://arxiv.org/abs/2502.12988v1",
          "size": "432kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:00:49+00:00",
          "link": "https://arxiv.org/abs/2502.12988v2",
          "size": "299kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T12:42:50+00:00",
          "link": "https://arxiv.org/abs/2502.12988v3",
          "size": "299kb",
          "version": "v3"
        }
      ],
      "title": "Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12988",
        "HTML": "https://arxiv.org/html/2502.12988v3",
        "PDF": "https://arxiv.org/pdf/2502.12988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning techniques using personalized datasets from Lu Xun's essays for style imitation in LLMs. While it involves dataset adaptation and fine-tuning, the primary focus is on persona simulation rather than general LLM training data processing."
      },
      "tasks": [
        "Generative Question Answering",
        "Multiple-choice",
        "Question Answering",
        "Style Transfer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14400",
      "abstract": "Aligning Large Language Model (LLM) responses with human preferences is vital for building safe and controllable AI systems. While preference optimization methods based on Plackett-Luce (PL) and Bradley-Terry (BT) models have shown promise, they face challenges such as poor handling of harmful content, inefficient use of dispreferred responses, and, specifically for PL, high computational costs. To address these issues, we propose Hard Preference Sampling (HPS), a novel framework for robust and efficient human preference alignment. HPS introduces a training loss that prioritizes the most preferred response while rejecting all dispreferred and harmful ones. It emphasizes \"hard\" dispreferred responses -- those closely resembling preferred ones -- to enhance the model's rejection capabilities. By leveraging a single-sample Monte Carlo sampling strategy, HPS reduces computational overhead while maintaining alignment quality. Theoretically, HPS improves sample efficiency over existing PL methods and maximizes the reward margin between preferred and dispreferred responses, ensuring clearer distinctions. Experiments on HH-RLHF and PKU-Safety datasets validate HPS's effectiveness, achieving comparable BLEU and reward scores while greatly improving reward margins and thus reducing harmful content generation.",
      "authors": [
        "Xiandong Zou",
        "Wanyu Lin",
        "Yuchen Li",
        "Pan Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T09:37:41+00:00",
          "link": "https://arxiv.org/abs/2502.14400v1",
          "size": "310kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T10:36:07+00:00",
          "link": "https://arxiv.org/abs/2502.14400v2",
          "size": "314kb",
          "version": "v2"
        },
        {
          "date": "2025-05-29T02:52:13+00:00",
          "link": "https://arxiv.org/abs/2502.14400v3",
          "size": "312kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T10:00:09+00:00",
          "link": "https://arxiv.org/abs/2502.14400v4",
          "size": "312kb",
          "version": "v4"
        }
      ],
      "title": "HPS: Hard Preference Sampling for Human Preference Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14400",
        "HTML": "https://arxiv.org/html/2502.14400v4",
        "PDF": "https://arxiv.org/pdf/2502.14400"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a method (HPS) for aligning LLM responses with human preferences. While it introduces alignment techniques, it does not focus on data processing or dataset creation, which is the core of LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15487",
      "abstract": "Large Language Models (LLMs) are increasingly used in tasks requiring interpretive and inferential accuracy. In this paper, we introduce ExpliCa, a new dataset for evaluating LLMs in explicit causal reasoning. ExpliCa uniquely integrates both causal and temporal relations presented in different linguistic orders and explicitly expressed by linguistic connectives. The dataset is enriched with crowdsourced human acceptability ratings. We tested LLMs on ExpliCa through prompting and perplexity-based metrics. We assessed seven commercial and open-source LLMs, revealing that even top models struggle to reach 0.80 accuracy. Interestingly, models tend to confound temporal relations with causal ones, and their performance is also strongly influenced by the linguistic order of the events. Finally, perplexity-based scores and prompting performance are differently affected by model size.",
      "authors": [
        "Martina Miliani",
        "Serena Auriemma",
        "Alessandro Bondielli",
        "Emmanuele Chersoni",
        "Lucia Passaro",
        "Irene Sucameli",
        "Alessandro Lenci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T14:23:14+00:00",
          "link": "https://arxiv.org/abs/2502.15487v1",
          "size": "2697kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T07:15:45+00:00",
          "link": "https://arxiv.org/abs/2502.15487v2",
          "size": "2697kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T13:47:56+00:00",
          "link": "https://arxiv.org/abs/2502.15487v3",
          "size": "2885kb",
          "version": "v3"
        }
      ],
      "title": "ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15487",
        "HTML": "https://arxiv.org/html/2502.15487v3",
        "PDF": "https://arxiv.org/pdf/2502.15487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces ExpliCa, a new dataset specifically created to evaluate LLMs in explicit causal reasoning. This makes a direct contribution to the creation of datasets for fine-tuning and evaluation, aligning with LLM training data processing objectives."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.15610",
      "abstract": "Accurate identification of bioactive peptides (BPs) and protein post-translational modifications (PTMs) is essential for understanding protein function and advancing therapeutic discovery. However, most computational methods remain limited in their generalizability across diverse peptide functions. Here, we present PDeepPP, a unified deep learning framework that integrates pretrained protein language models with a hybrid transformer-convolutional architecture, enabling robust identification across diverse peptide classes and PTM sites. We curated comprehensive benchmark datasets and implemented strategies to address data imbalance, allowing PDeepPP to systematically extract both global and local sequence features. Through extensive analyses-including dimensionality reduction and comparison studies-PDeepPP demonstrates strong, interpretable peptide representations and achieves state-of-the-art performance in 25 of the 33 biological identification tasks. Notably, PDeepPP attains high accuracy in antimicrobial (0.9726) and phosphorylation site (0.9984) identification, with 99.5% specificity in glycosylation site prediction and substantial reduction in false negatives in antimalarial tasks. By enabling large-scale, accurate peptide analysis, PDeepPP supports biomedical research and the discovery of novel therapeutic targets for disease treatment. All code, datasets, and pretrained models are publicly available via GitHub:https://github.com/fondress/PDeepPP and Hugging Face:https://huggingface.co/fondress/PDeppPP.",
      "authors": [
        "Jixiu Zhai",
        "Tianchi Lu",
        "Haitian Zhong",
        "Ziyang Xu",
        "Yuhuan Liu",
        "Shengrui Xu",
        "Jingwan Wang and Dan Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T17:31:22+00:00",
          "link": "https://arxiv.org/abs/2502.15610v1",
          "size": "36495kb",
          "version": "v1"
        },
        {
          "date": "2025-04-17T17:52:57+00:00",
          "link": "https://arxiv.org/abs/2502.15610v2",
          "size": "36392kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T05:46:24+00:00",
          "link": "https://arxiv.org/abs/2502.15610v3",
          "size": "36315kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T08:48:10+00:00",
          "link": "https://arxiv.org/abs/2502.15610v4",
          "size": "36295kb",
          "version": "v4"
        }
      ],
      "title": "A general language model for peptide identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15610",
        "HTML": "https://arxiv.org/html/2502.15610v4",
        "PDF": "https://arxiv.org/pdf/2502.15610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on peptide identification using a deep learning framework integrating pretrained models with a transformer-convolutional architecture. It does not address training data processing for LLMs."
      },
      "models": [
        {
          "model_path": "fondress/PDeepPP",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/fondress/PDeepPP"
        }
      ],
      "tasks": [
        "Deep Learning",
        "Language Modeling",
        "Language Modelling",
        "model",
        "Specificity"
      ],
      "repo_urls": [
        "https://github.com/fondress/pdeeppp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16943",
      "abstract": "Unsupervised anomaly detection in brain images is crucial for identifying injuries and pathologies without access to labels. However, the accurate localization of anomalies in medical images remains challenging due to the inherent complexity and variability of brain structures and the scarcity of annotated abnormal data. To address this challenge, we propose a novel approach that incorporates masking within diffusion models, leveraging their generative capabilities to learn robust representations of normal brain anatomy. During training, our model processes only normal brain MRI scans and performs a forward diffusion process in the latent space that adds noise to the features of randomly-selected patches. Following a dual objective, the model learns to identify which patches are noisy and recover their original features. This strategy ensures that the model captures intricate patterns of normal brain structures while isolating potential anomalies as noise in the latent space. At inference, the model identifies noisy patches corresponding to anomalies and generates a normal counterpart for these patches by applying a reverse diffusion process. Our method surpasses existing unsupervised anomaly detection techniques, demonstrating superior performance in generating accurate normal counterparts and localizing anomalies. The code is available at hhttps://github.com/farzad-bz/MAD-AD.",
      "authors": [
        "Farzad Beizaee",
        "Gregory Lodygensky",
        "Christian Desrosiers",
        "Jose Dolz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T08:11:29+00:00",
          "link": "https://arxiv.org/abs/2502.16943v1",
          "size": "2223kb",
          "version": "v1"
        },
        {
          "date": "2025-03-20T21:42:00+00:00",
          "link": "https://arxiv.org/abs/2502.16943v2",
          "size": "433kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T18:22:22+00:00",
          "link": "https://arxiv.org/abs/2502.16943v3",
          "size": "433kb",
          "version": "v3"
        }
      ],
      "title": "MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16943",
        "HTML": "https://arxiv.org/html/2502.16943v3",
        "PDF": "https://arxiv.org/pdf/2502.16943"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for unsupervised anomaly detection in brain images using diffusion models. It does not contribute to training data processing for LLMs."
      },
      "models": [
        {
          "model_path": "farzadbz/Medical-VAE",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/farzadbz/Medical-VAE"
        }
      ],
      "tasks": [
        "Anatomy",
        "Anomaly Detection",
        "Unsupervised Anomaly Detection"
      ],
      "repo_urls": [
        "https://github.com/farzad-bz/mad-ad"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18639",
      "abstract": "The digitization of healthcare presents numerous challenges, including the complexity of biological systems, vast data generation, and the need for personalized treatment plans. Traditional computational methods often fall short, leading to delayed and sometimes ineffective diagnoses and treatments. Quantum Computing (QC) and Quantum Machine Learning (QML) offer transformative advancements with the potential to revolutionize medicine. This paper summarizes areas where QC promises unprecedented computational power, enabling faster, more accurate diagnostics, personalized treatments, and enhanced drug discovery processes. However, integrating quantum technologies into precision medicine also presents challenges, including errors in algorithms and high costs. We show that mathematically-based techniques for specifying, developing, and verifying software (formal methods) can enhance the reliability and correctness of QC. By providing a rigorous mathematical framework, formal methods help to specify, develop, and verify systems with high precision. In genomic data analysis, formal specification languages can precisely (1) define the behavior and properties of quantum algorithms designed to identify genetic markers associated with diseases. Model checking tools can systematically explore all possible states of the algorithm to (2) ensure it behaves correctly under all conditions, while theorem proving techniques provide mathematical (3) proof that the algorithm meets its specified properties, ensuring accuracy and reliability. Additionally, formal optimization techniques can (4) enhance the efficiency and performance of quantum algorithms by reducing resource usage, such as the number of qubits and gate operations. Therefore, we posit that formal methods can significantly contribute to enabling QC to realize its full potential as a game changer in precision medicine.",
      "authors": [
        "Markus Bertl",
        "Alan Mott",
        "Salvatore Sinno",
        "Bhavika Bhalgamiya"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Artificial Intelligence (cs.AI)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T20:59:22+00:00",
          "link": "https://arxiv.org/abs/2502.18639v1",
          "size": "488kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:47:46+00:00",
          "link": "https://arxiv.org/abs/2502.18639v2",
          "size": "216kb",
          "version": "v2"
        }
      ],
      "title": "Quantum Machine Learning in Precision Medicine and Drug Discovery -- A Game Changer for Tailored Treatments?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18639",
        "HTML": "https://arxiv.org/html/2502.18639v2",
        "PDF": "https://arxiv.org/pdf/2502.18639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the potential of quantum machine learning in precision medicine and drug discovery, which is not related to LLM training data processing."
      },
      "tasks": [
        "Automated Theorem Proving",
        "Drug Discovery",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18679",
      "abstract": "Supervised fine-tuning (SFT) has become a crucial step for aligning pretrained large language models (LLMs) using supervised datasets of input-output pairs. However, despite being supervised, SFT is inherently limited by its generative training objective. To address its limitations, the existing common strategy is to follow SFT with a separate phase of preference optimization (PO), which relies on either human-labeled preference data or a strong reward model to guide the learning process. In this paper, we address the limitations of SFT by exploring one of the most successful techniques in conventional supervised learning: discriminative learning. We introduce Discriminative Fine-Tuning (DFT), an improved variant of SFT, which mitigates the burden of collecting human-labeled preference data or training strong reward models. Unlike SFT that employs a generative approach and overlooks negative data, DFT adopts a discriminative paradigm that increases the probability of positive answers while suppressing potentially negative ones, aiming for data prediction instead of token prediction. Our contributions include: (i) a discriminative probabilistic framework for fine-tuning LLMs by explicitly modeling the discriminative likelihood of an answer among all possible outputs given an input; (ii) efficient algorithms to optimize this discriminative likelihood; and (iii) extensive experiments demonstrating DFT's effectiveness, achieving performance better than SFT and comparable to if not better than SFT$\\rightarrow$PO. The code can be found at https://github.com/Optimization-AI/DFT.",
      "authors": [
        "Siqi Guo",
        "Ilgee Hong",
        "Vicente Balmaseda",
        "Changlong Yu",
        "Liang Qiu",
        "Xin Liu",
        "Haoming Jiang",
        "Tuo Zhao",
        "Tianbao Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T22:38:55+00:00",
          "link": "https://arxiv.org/abs/2502.18679v1",
          "size": "179kb",
          "version": "v1"
        },
        {
          "date": "2025-05-12T22:10:13+00:00",
          "link": "https://arxiv.org/abs/2502.18679v2",
          "size": "1022kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T19:53:08+00:00",
          "link": "https://arxiv.org/abs/2502.18679v3",
          "size": "141kb",
          "version": "v3"
        }
      ],
      "title": "Discriminative Finetuning of Generative Large Language Models without Reward Models and Human Preference Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18679",
        "HTML": "https://arxiv.org/html/2502.18679v3",
        "PDF": "https://arxiv.org/pdf/2502.18679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a discriminative fine-tuning technique for LLMs which is an improvement to supervised fine-tuning. It indicates a focus on the optimization of learning strategies rather than on training data processing itself."
      },
      "models": [
        {
          "model_path": "siqi00/Mistral-7B-DFT2",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/siqi00/Mistral-7B-DFT2"
        },
        {
          "model_path": "siqi00/Mistral-7B-DFT",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/siqi00/Mistral-7B-DFT"
        }
      ],
      "datasets": [
        {
          "dataset_name": "siqi00/mistral_ultrafeedback_unhelpful_chatprompt_0.7_1.0_50_320",
          "downloads": "15",
          "likes": "0",
          "link": "https://huggingface.co/datasets/siqi00/mistral_ultrafeedback_unhelpful_chatprompt_0.7_1.0_50_320"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/optimization-ai/dft"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20144",
      "abstract": "Deploying digital pathology models across medical centers is challenging due to distribution shifts. Recent advances in domain generalization improve model transferability in terms of aggregated performance measured by the Area Under Curve (AUC). However, clinical regulations often require to control the transferability of other metrics, such as prescribed sensitivity levels. We introduce a novel approach to control the sensitivity of whole slide image (WSI) classification models, based on optimal transport and Multiple Instance Learning (MIL). Validated across multiple cohorts and tasks, our method enables robust sensitivity control with only a handful of calibration samples, providing a practical solution for reliable deployment of computational pathology systems.",
      "authors": [
        "Arthur Pignet",
        "John Klein",
        "Genevieve Robin",
        "Antoine Olivier"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T14:35:47+00:00",
          "link": "https://arxiv.org/abs/2502.20144v1",
          "size": "1541kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T08:39:21+00:00",
          "link": "https://arxiv.org/abs/2502.20144v2",
          "size": "1541kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T15:45:59+00:00",
          "link": "https://arxiv.org/abs/2502.20144v3",
          "size": "1539kb",
          "version": "v3"
        }
      ],
      "title": "Robust sensitivity control in digital pathology via tile score distribution matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20144",
        "HTML": "https://arxiv.org/html/2502.20144v3",
        "PDF": "https://arxiv.org/pdf/2502.20144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving digital pathology models using a novel approach for controlling sensitivity in WSI classification, unrelated to LLM training data processing."
      },
      "tasks": [
        "Domain Generalization",
        "Multiple Instance Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20158",
      "abstract": "Leveraging the effective visual-text alignment and static generalizability from CLIP, recent video learners adopt CLIP initialization with further regularization or recombination for generalization in open-vocabulary action recognition in-context. However, due to the static bias of CLIP, such video learners tend to overfit on shortcut static features, thereby compromising their generalizability, especially to novel out-of-context actions. To address this issue, we introduce Open-MeDe, a novel Meta-optimization framework with static Debiasing for Open-vocabulary action recognition. From a fresh perspective of generalization, Open-MeDe adopts a meta-learning approach to improve known-to-open generalizing and image-to-video debiasing in a cost-effective manner. Specifically, Open-MeDe introduces a cross-batch meta-optimization scheme that explicitly encourages video learners to quickly generalize to arbitrary subsequent data via virtual evaluation, steering a smoother optimization landscape. In effect, the free of CLIP regularization during optimization implicitly mitigates the inherent static bias of the video meta-learner. We further apply self-ensemble over the optimization trajectory to obtain generic optimal parameters that can achieve robust generalization to both in-context and out-of-context novel data. Extensive evaluations show that Open-MeDe not only surpasses state-of-the-art regularization methods tailored for in-context open-vocabulary action recognition but also substantially excels in out-of-context scenarios.Code is released at https://github.com/Mia-YatingYu/Open-MeDe.",
      "authors": [
        "Yating Yu",
        "Congqi Cao",
        "Yifan Zhang",
        "Yanning Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T14:56:58+00:00",
          "link": "https://arxiv.org/abs/2502.20158v1",
          "size": "3817kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:56:00+00:00",
          "link": "https://arxiv.org/abs/2502.20158v2",
          "size": "3161kb",
          "version": "v2"
        }
      ],
      "title": "Learning to Generalize without Bias for Open-Vocabulary Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20158",
        "HTML": "https://arxiv.org/html/2502.20158v2",
        "PDF": "https://arxiv.org/pdf/2502.20158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel optimization framework for open-vocabulary action recognition, emphasizing meta-learning and static bias mitigation, not related to LLM data processing."
      },
      "tasks": [
        "Action Recognition",
        "Meta-Learning",
        "Open Vocabulary Action Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01424",
      "abstract": "Research is a fundamental process driving the advancement of human civilization, yet it demands substantial time and effort from researchers. In recent years, the rapid development of artificial intelligence (AI) technologies has inspired researchers to explore how AI can accelerate and enhance research. To monitor relevant advancements, this paper presents a systematic review of the progress in this domain. Specifically, we organize the relevant studies into three main categories: hypothesis formulation, hypothesis validation, and manuscript publication. Hypothesis formulation involves knowledge synthesis and hypothesis generation. Hypothesis validation includes the verification of scientific claims, theorem proving, and experiment validation. Manuscript publication encompasses manuscript writing and the peer review process. Furthermore, we identify and discuss the current challenges faced in these areas, as well as potential future directions for research. Finally, we also offer a comprehensive overview of existing benchmarks and tools across various domains that support the integration of AI into the research process. We hope this paper serves as an introduction for beginners and fosters future research. Resources have been made publicly available at https://github.com/zkzhou126/AI-for-Research.",
      "authors": [
        "Zekun Zhou",
        "Xiaocheng Feng",
        "Lei Huang",
        "Xiachong Feng",
        "Ziyun Song",
        "Ruihan Chen",
        "Liang Zhao",
        "Weitao Ma",
        "Yuxuan Gu",
        "Baoxin Wang",
        "Dayong Wu",
        "Guoping Hu",
        "Ting Liu",
        "Bing Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T11:27:13+00:00",
          "link": "https://arxiv.org/abs/2503.01424v1",
          "size": "2506kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:06:25+00:00",
          "link": "https://arxiv.org/abs/2503.01424v2",
          "size": "1286kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T02:59:25+00:00",
          "link": "https://arxiv.org/abs/2503.01424v3",
          "size": "1286kb",
          "version": "v3"
        }
      ],
      "title": "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01424",
        "HTML": "https://arxiv.org/html/2503.01424v3",
        "PDF": "https://arxiv.org/pdf/2503.01424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper surveys AI-driven research support systems, focusing on hypothesis generation, validation, and publication, without specific contributions to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.04151",
      "abstract": "Recently, multi-view learning (MVL) has garnered significant attention due to its ability to fuse discriminative information from multiple views. However, real-world multi-view datasets are often heterogeneous and imperfect, which usually causes MVL methods designed for specific combinations of views to lack application potential and limits their effectiveness. To address this issue, we propose a novel robust MVL method (namely RML) with simultaneous representation fusion and alignment. Specifically, we introduce a simple yet effective multi-view transformer fusion network where we transform heterogeneous multi-view data into homogeneous word embeddings, and then integrate multiple views by the sample-level attention mechanism to obtain a fused representation. Furthermore, we propose a simulated perturbation based multi-view contrastive learning framework that dynamically generates the noise and unusable perturbations for simulating imperfect data conditions. The simulated noisy and unusable data obtain two distinct fused representations, and we utilize contrastive learning to align them for learning discriminative and robust representations. Our RML is self-supervised and can also be applied for downstream tasks as a regularization. In experiments, we employ it in multi-view unsupervised clustering, noise-label classification, and as a plug-and-play module for cross-modal hashing retrieval. Extensive comparison experiments and ablation studies validate RML's effectiveness. Code is available at https://github.com/SubmissionsIn/RML.",
      "authors": [
        "Jie Xu",
        "Na Zhao",
        "Gang Niu",
        "Masashi Sugiyama",
        "Xiaofeng Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T07:01:08+00:00",
          "link": "https://arxiv.org/abs/2503.04151v1",
          "size": "4640kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:25:16+00:00",
          "link": "https://arxiv.org/abs/2503.04151v2",
          "size": "3162kb",
          "version": "v2"
        }
      ],
      "title": "Robust Multi-View Learning via Representation Fusion of Sample-Level Attention and Alignment of Simulated Perturbation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04151",
        "HTML": "https://arxiv.org/html/2503.04151v2",
        "PDF": "https://arxiv.org/pdf/2503.04151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a robust multi-view learning model using representation fusion and alignment techniques, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06736",
      "abstract": "Safe real-time control of robotic manipulators in unstructured environments requires handling numerous safety constraints without compromising task performance. Traditional approaches, such as artificial potential fields (APFs), suffer from local minima, oscillations, and limited scalability, while model predictive control (MPC) can be computationally expensive. Control barrier functions (CBFs) offer a promising alternative due to their high level of robustness and low computational cost, but these safety filters must be carefully designed to avoid significant reductions in the overall performance of the manipulator. In this work, we introduce an Operational Space Control Barrier Function (OSCBF) framework that integrates safety constraints while preserving task-consistent behavior. Our approach scales to hundreds of simultaneous constraints while retaining real-time control rates, ensuring collision avoidance, singularity prevention, and workspace containment even in highly cluttered settings or during dynamic motions. By explicitly accounting for the task hierarchy in the CBF objective, we prevent degraded performance across both joint-space and operational-space tasks, when at the limit of safety. We validate performance in both simulation and hardware, and release our open-source high-performance code and media on our project webpage, https://stanfordasl.github.io/oscbf/",
      "authors": [
        "Daniel Morton and Marco Pavone"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T19:29:15+00:00",
          "link": "https://arxiv.org/abs/2503.06736v1",
          "size": "1705kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T06:00:33+00:00",
          "link": "https://arxiv.org/abs/2503.06736v2",
          "size": "4391kb",
          "version": "v2"
        }
      ],
      "title": "Safe, Task-Consistent Manipulation with Operational Space Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06736",
        "HTML": "https://arxiv.org/html/2503.06736v2",
        "PDF": "https://arxiv.org/pdf/2503.06736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for safe real-time control of robotic manipulators, focusing on control barrier functions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.07588",
      "abstract": "Efficient vision-language understanding of large Remote Sensing Images (RSIs) is meaningful but challenging. Current Large Vision-Language Models (LVLMs) typically employ limited pre-defined grids to process images, leading to information loss when handling gigapixel RSIs. Conversely, using unlimited grids significantly increases computational costs. To preserve image details while reducing computational complexity, we propose a text-guided token pruning method with Dynamic Image Pyramid (DIP) integration. Our method introduces: (i) a Region Focus Module (RFM) that leverages text-aware region localization capability to identify critical vision tokens, and (ii) a coarse-to-fine image tile selection and vision token pruning strategy based on DIP, which is guided by RFM outputs and avoids directly processing the entire large imagery. Additionally, existing benchmarks for evaluating LVLMs' perception ability on large RSI suffer from limited question diversity and constrained image sizes. We construct a new benchmark named LRS-VQA, which contains 7,333 QA pairs across 8 categories, with image length up to 27,328 pixels. Our method outperforms existing high-resolution strategies on four datasets using the same data. Moreover, compared to existing token reduction methods, our approach demonstrates higher efficiency under high-resolution settings. Dataset and code are in https://github.com/VisionXLab/LRS-VQA.",
      "authors": [
        "Junwei Luo",
        "Yingying Zhang",
        "Xue Yang",
        "Kang Wu",
        "Qi Zhu",
        "Lei Liang",
        "Jingdong Chen",
        "Yansheng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T17:51:16+00:00",
          "link": "https://arxiv.org/abs/2503.07588v1",
          "size": "5850kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T15:05:34+00:00",
          "link": "https://arxiv.org/abs/2503.07588v2",
          "size": "5850kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T07:44:45+00:00",
          "link": "https://arxiv.org/abs/2503.07588v3",
          "size": "4775kb",
          "version": "v3"
        }
      ],
      "title": "When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07588",
        "HTML": "https://arxiv.org/html/2503.07588v3",
        "PDF": "https://arxiv.org/pdf/2503.07588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a token pruning method for processing Large Vision-Language Models with Remote Sensing Images, which involves some data processing aspects. However, its main focus is on model efficiency and evaluation benchmarks rather than LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Token Reduction",
        "Visual Question Answering (VQA)"
      ],
      "repo_urls": [
        "https://github.com/visionxlab/lrs-vqa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07919",
      "abstract": "Modern web agents possess computer use abilities that allow them to interact with webpages by sending commands to a virtual keyboard and mouse. While such agents have considerable potential to assist human users with complex tasks, evaluating their capabilities in real-world settings poses a major challenge. To this end, we introduce BEARCUBS, a \"smallbut mighty\" benchmark of 111 information-seeking questions designed to evaluate a web agent's ability to search, browse, and identify factual information from the web. Unlike prior web agent benchmarks, solving BEARCUBS requires (1) accessing live web content rather than synthetic or simulated pages, which captures the unpredictability of real-world web interactions; and (2) performing a broad range of multimodal interactions (e.g., video understanding, 3D navigation) that cannot be bypassed via text-based workarounds. Each question in BEARCUBS has a corresponding short, unambiguous answer and a human-validated browsing trajectory, allowing for transparent evaluation of agent performance and strategies. A human study confirms that BEARCUBS questions are solvable but non-trivial (84.7% human accuracy), revealing domain knowledge gaps and overlooked details as common failure points. We find that ChatGPT Agent significantly outperforms other computer-using agents with an overall accuracy of 65.8% (compared to e.g., Operator's 23.4%), showcasing substantial progress in tasks involving real computer use, such as playing web games and navigating 3D environments. Nevertheless, closing the gap to human performance requires improvements in areas like fine control, complex data filtering, and execution speed. To facilitate future research, BEARCUBS will be updated periodically to replace invalid or contaminated questions, keeping the benchmark fresh for future generations of web agents.",
      "authors": [
        "Yixiao Song",
        "Katherine Thai",
        "Chau Minh Pham",
        "Yapei Chang",
        "Mazin Nadaf",
        "Mohit Iyyer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T23:50:30+00:00",
          "link": "https://arxiv.org/abs/2503.07919v1",
          "size": "1287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:50:49+00:00",
          "link": "https://arxiv.org/abs/2503.07919v2",
          "size": "1348kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T17:45:05+00:00",
          "link": "https://arxiv.org/abs/2503.07919v3",
          "size": "1391kb",
          "version": "v3"
        }
      ],
      "title": "BEARCUBS: A benchmark for computer-using web agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07919",
        "HTML": "https://arxiv.org/html/2503.07919v3",
        "PDF": "https://arxiv.org/pdf/2503.07919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating computer-using web agents, focusing on real-world agent interaction instead of any LLM training data processing tasks."
      },
      "tasks": [
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07926",
      "abstract": "In our daily life, we often encounter objects that are fragile and can be damaged by excessive grasping force, such as fruits. For these objects, it is paramount to grasp gently -- not using the maximum amount of force possible, but rather the minimum amount of force necessary. This paper proposes using visual, tactile, and auditory signals to learn to grasp and regrasp objects stably and gently. Specifically, we use audio signals as an indicator of gentleness during the grasping, and then train an end-to-end action-conditional model from raw visuo-tactile inputs that predicts both the stability and the gentleness of future grasping candidates, thus allowing the selection and execution of the most promising action. Experimental results on a multi-fingered hand over 1,500 grasping trials demonstrated that our model is useful for gentle grasping by validating the predictive performance (3.27% higher accuracy than the vision-only variant) and providing interpretations of their behavior. Finally, real-world experiments confirmed that the grasping performance with the trained multi-modal model outperformed other baselines (17% higher rate for stable and gentle grasps than vision-only). Our approach requires neither tactile sensor calibration nor analytical force modeling, drastically reducing the engineering effort to grasp fragile objects. Dataset and videos are available at https://lasr.org/research/gentle-grasping.",
      "authors": [
        "Ken Nakahara",
        "Roberto Calandra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T00:12:25+00:00",
          "link": "https://arxiv.org/abs/2503.07926v1",
          "size": "1058kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:08:12+00:00",
          "link": "https://arxiv.org/abs/2503.07926v2",
          "size": "1055kb",
          "version": "v2"
        }
      ],
      "title": "Learning Gentle Grasping Using Vision, Sound, and Touch",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07926",
        "HTML": "https://arxiv.org/html/2503.07926v2",
        "PDF": "https://arxiv.org/pdf/2503.07926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using multimodal signals for learning gentle grasping in robotics, which is outside the scope of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.08510",
      "abstract": "Class-Incremental Learning (CIL) enables learning systems to continuously adapt to evolving data streams. With the advancement of pre-training, leveraging pre-trained vision-language models (e.g., CLIP) offers a promising starting point for CIL. However, CLIP makes decisions by matching visual embeddings to class names, overlooking the rich contextual information conveyed through language. For instance, the concept of ``cat'' can be decomposed into features like tail, fur, and face for recognition. Besides, since the model is continually updated, these detailed features are overwritten in CIL, requiring external knowledge for compensation. In this paper, we introduce ExterNal knowledGe INjEction (ENGINE) for CLIP-based CIL. To enhance knowledge transfer from outside the dataset, we propose a dual-branch injection tuning framework that encodes informative knowledge from both visual and textual modalities. The visual branch is enhanced with data augmentation to enrich the visual features, while the textual branch leverages GPT-4 to rewrite discriminative descriptors. In addition to this on-the-fly knowledge injection, we also implement post-tuning knowledge by re-ranking the prediction results during inference. With the injected knowledge, the model can better capture informative features for downstream tasks as data evolves. Extensive experiments demonstrate the state-of-the-art performance of ENGINE. Code is available at: https://github.com/LAMDA-CL/ICCV25-ENGINE",
      "authors": [
        "Da-Wei Zhou",
        "Kai-Wen Li",
        "Jingyi Ning",
        "Han-Jia Ye",
        "Lijun Zhang",
        "De-Chuan Zhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T15:00:22+00:00",
          "link": "https://arxiv.org/abs/2503.08510v1",
          "size": "3043kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:04:36+00:00",
          "link": "https://arxiv.org/abs/2503.08510v2",
          "size": "3043kb",
          "version": "v2"
        }
      ],
      "title": "External Knowledge Injection for CLIP-Based Class-Incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08510",
        "HTML": "https://arxiv.org/html/2503.08510v2",
        "PDF": "https://arxiv.org/pdf/2503.08510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses knowledge injection into CLIP-based class-incremental learning systems, involving some data processing through augmentation and textual knowledge injection, but it primarily targets improving model learning and adaptation rather than LLM data processing."
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Data Augmentation",
        "Incremental Learning",
        "Re-Ranking",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/renaisscode/engine",
        "https://github.com/g-u-n/pycil"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08537",
      "abstract": "While automated chemical tools excel at specific tasks, they have struggled to capture the strategic thinking that characterizes expert chemical reasoning. Here we demonstrate that large language models (LLMs) can serve as powerful tools enabling chemical analysis. When integrated with traditional search algorithms, they enable a new approach to computer-aided synthesis that mirrors human expert thinking. Rather than using LLMs to directly manipulate chemical structures, we leverage their ability to evaluate chemical strategies and guide search algorithms toward chemically meaningful solutions. We demonstrate this paradigm through two fundamental challenges: strategy-aware retrosynthetic planning and mechanism elucidation. In retrosynthetic planning, our system allows chemists to specify desired synthetic strategies in natural language -- from protecting group strategies to global feasibility assessment -- and uses traditional or LLM-guided Monte Carlo Tree Search to find routes that satisfy these constraints. In mechanism elucidation, LLMs guide the search for plausible reaction mechanisms by combining chemical principles with systematic exploration. This approach shows strong performance across diverse chemical tasks, with newer and larger models demonstrating increasingly sophisticated chemical reasoning. Our approach establishes a new paradigm for computer-aided chemistry that combines the strategic understanding of LLMs with the precision of traditional chemical tools, opening possibilities for more intuitive and powerful chemical automation systems.",
      "authors": [
        "Andres M Bran",
        "Theo A Neukomm",
        "Daniel P Armstrong",
        "Zlatko Jon\\v{c}ev",
        "Philippe Schwaller"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T15:27:17+00:00",
          "link": "https://arxiv.org/abs/2503.08537v1",
          "size": "6062kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T19:39:27+00:00",
          "link": "https://arxiv.org/abs/2503.08537v2",
          "size": "8886kb",
          "version": "v2"
        }
      ],
      "title": "Chemical reasoning in LLMs unlocks strategy-aware synthesis planning and reaction mechanism elucidation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08537",
        "HTML": "https://arxiv.org/html/2503.08537v2",
        "PDF": "https://arxiv.org/pdf/2503.08537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applying LLMs to chemical analysis and synthesis planning, rather than on the data processing for training LLMs. It does not address any aspect of data processing operations for LLM pretraining or fine-tuning."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/schwallergroup/steer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10009",
      "abstract": "With the rise of artificial intelligence (AI), applying large language models (LLMs) to Operations Research (OR) problem-solving has attracted increasing attention. Most existing approaches attempt to improve OR problem-solving through prompt engineering or fine-tuning strategies for LLMs. However, these methods are fundamentally constrained by the limited capabilities of non-reasoning LLMs. To overcome these limitations, we propose OR-LLM-Agent, an AI agent built on reasoning LLMs for automated OR problem solving. The agent decomposes the task into three sequential stages: mathematical modeling, code generation, and debugging. Each task is handled by a dedicated sub-agent, which enables more targeted reasoning. We also construct BWOR, a high-quality dataset for evaluating LLM performance on OR tasks. Our analysis shows that existing benchmarks such as NL4OPT, MAMO, and IndustryOR suffer from certain issues, making them less suitable for reliably evaluating LLM performance. In contrast, BWOR provides a more consistent and discriminative assessment of model capabilities. Experimental results demonstrate that OR-LLM-Agent outperforms advanced methods, including GPT-o3, Gemini 2.5 Pro, and ORLM, by at least 7% in accuracy. These results demonstrate the effectiveness of task decomposition for OR problem solving.",
      "authors": [
        "Bowen Zhang",
        "Pengcheng Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T03:40:50+00:00",
          "link": "https://arxiv.org/abs/2503.10009v1",
          "size": "19871kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:09:58+00:00",
          "link": "https://arxiv.org/abs/2503.10009v2",
          "size": "15977kb",
          "version": "v2"
        }
      ],
      "title": "OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10009",
        "HTML": "https://arxiv.org/html/2503.10009v2",
        "PDF": "https://arxiv.org/pdf/2503.10009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the creation of the BWOR dataset for evaluating LLM performance on OR tasks, which is tangentially related to LLM training data. However, its main contribution revolves around the OR-LLM-Agent system for problem-solving, not on training data processing itself."
      },
      "tasks": [
        "AI Agent",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/bwz96sco/or_llm_agent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10029",
      "abstract": "Hand interactions are increasingly used as the primary input modality in immersive environments, but they are not always feasible due to situational impairments, motor limitations, and environmental constraints. Speech interfaces have been explored as an alternative to hand input in research and commercial solutions, but are limited to initiating basic hand gestures and system controls. We introduce HandProxy, a system that expands the affordances of speech interfaces to support expressive hand interactions. Instead of relying on predefined speech commands directly mapped to possible interactions, HandProxy enables users to control the movement of a virtual hand as an interaction proxy, allowing them to describe the intended interactions naturally while the system translates speech into a sequence of hand controls for real-time execution. A user study with 20 participants demonstrated that HandProxy effectively enabled diverse hand interactions in virtual environments, achieving a 100% task completion rate with an average of 1.09 attempts per speech command and 91.8% command execution accuracy, while supporting flexible, natural speech input with varying levels of control and granularity.",
      "authors": [
        "Chen Liang",
        "Yuxuan Liu",
        "Martez Mott",
        "Anhong Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T04:14:36+00:00",
          "link": "https://arxiv.org/abs/2503.10029v1",
          "size": "6027kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T02:21:56+00:00",
          "link": "https://arxiv.org/abs/2503.10029v2",
          "size": "6054kb",
          "version": "v2"
        }
      ],
      "title": "HandProxy: Expanding the Affordances of Speech Interfaces in Immersive Environments with a Virtual Proxy Hand",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10029",
        "HTML": "https://arxiv.org/html/2503.10029v2",
        "PDF": "https://arxiv.org/pdf/2503.10029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the HandProxy system for expanding speech interfaces by translating speech into hand movements in virtual environments. It does not relate to LLM training data processing or contribute to data operations for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11034",
      "abstract": "In this paper we develop a numerical method for solving an inverse scattering problem of estimating the scattering potential in a Schr\\\"{o}dinger equation from frequency domain measurements based on reduced order models (ROM). The ROM is a projection of Schr\\\"{o}dinger operator onto a subspace spanned by its solution snapshots at certain wavenumbers. Provided the measurements are performed at these wavenumbers, the ROM can be constructed in a data-driven manner from the measurements on a surface surrounding the scatterers. Once the ROM is computed, the scattering potential can be estimated using non-linear optimization that minimizes the ROM misfit. Such an approach typically outperforms the conventional methods based on data misfit minimization. We develop two variants of ROM-based algorithms for inverse scattering and test them on a synthetic example in two spatial dimensions.",
      "authors": [
        "Andreas Tataris and Tristan van Leeuwen and Alexander V. Mamonov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T03:03:34+00:00",
          "link": "https://arxiv.org/abs/2503.11034v1",
          "size": "860kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T20:31:27+00:00",
          "link": "https://arxiv.org/abs/2503.11034v2",
          "size": "836kb",
          "version": "v2"
        }
      ],
      "title": "Inverse scattering for Schr\\\"{o}dinger equation in the frequency domain via data-driven reduced order modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11034",
        "HTML": "https://arxiv.org/html/2503.11034v2",
        "PDF": "https://arxiv.org/pdf/2503.11034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is a numerical method for solving an inverse scattering problem via reduced order models. It is not related to LLM training data processing or any associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11937",
      "abstract": "Text-to-Image (T2I) Diffusion Models have achieved remarkable performance in generating high quality images. However, enabling precise control of continuous attributes, especially multiple attributes simultaneously, in a new domain (e.g., numeric values like eye openness or car width) with text-only guidance remains a significant challenge. To address this, we introduce the Attribute (Att) Adapter, a novel plug-and-play module designed to enable fine-grained, multi-attributes control in pretrained diffusion models. Our approach learns a single control adapter from a set of sample images that can be unpaired and contain multiple visual attributes. The Att-Adapter leverages the decoupled cross attention module to naturally harmonize the multiple domain attributes with text conditioning. We further introduce Conditional Variational Autoencoder (CVAE) to the Att-Adapter to mitigate overfitting, matching the diverse nature of the visual world. Evaluations on two public datasets show that Att-Adapter outperforms all LoRA-based baselines in controlling continuous attributes. Additionally, our method enables a broader control range and also improves disentanglement across multiple attributes, surpassing StyleGAN-based techniques. Notably, Att-Adapter is flexible, requiring no paired synthetic data for training, and is easily scalable to multiple attributes within a single model.",
      "authors": [
        "Wonwoong Cho",
        "Yan-Ying Chen",
        "Matthew Klenk",
        "David I. Inouye",
        "Yanxia Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T01:06:34+00:00",
          "link": "https://arxiv.org/abs/2503.11937v1",
          "size": "15532kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T13:42:51+00:00",
          "link": "https://arxiv.org/abs/2503.11937v2",
          "size": "15532kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T15:56:25+00:00",
          "link": "https://arxiv.org/abs/2503.11937v3",
          "size": "16033kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T13:24:21+00:00",
          "link": "https://arxiv.org/abs/2503.11937v4",
          "size": "16034kb",
          "version": "v4"
        }
      ],
      "title": "Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11937",
        "HTML": "https://arxiv.org/html/2503.11937v4",
        "PDF": "https://arxiv.org/pdf/2503.11937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing text-to-image diffusion models with an adapter for attribute control, not on LLM training data processing."
      },
      "models": [
        {
          "model_path": "WonwoongCho/Att-Adapter",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WonwoongCho/Att-Adapter"
        }
      ],
      "tasks": [
        "Attribute",
        "Disentanglement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12358",
      "abstract": "Recent research has highlighted the significance of natural language in enhancing the controllability of generative models. While various efforts have been made to leverage natural language for content generation, research on deep reinforcement learning (DRL) agents utilizing text-based instructions for procedural content generation remains limited. In this paper, we propose IPCGRL, an instruction-based procedural content generation method via reinforcement learning, which incorporates a sentence embedding model. IPCGRL fine-tunes task-specific embedding representations to effectively compress game-level conditions. We evaluate IPCGRL in a two-dimensional level generation task and compare its performance with a general-purpose embedding method. The results indicate that IPCGRL achieves up to a 21.4% improvement in controllability and a 17.2% improvement in generalizability for unseen instructions. Furthermore, the proposed method extends the modality of conditional input, enabling a more flexible and expressive interaction framework for procedural content generation.",
      "authors": [
        "In-Chang Baek",
        "Sung-Hyun Kim",
        "Seo-Young Lee",
        "Dong-Hyeon Kim",
        "Kyung-Joong Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-16T04:53:38+00:00",
          "link": "https://arxiv.org/abs/2503.12358v1",
          "size": "1285kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T05:22:24+00:00",
          "link": "https://arxiv.org/abs/2503.12358v2",
          "size": "1285kb",
          "version": "v2"
        },
        {
          "date": "2025-03-25T01:48:16+00:00",
          "link": "https://arxiv.org/abs/2503.12358v3",
          "size": "1285kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T14:14:52+00:00",
          "link": "https://arxiv.org/abs/2503.12358v4",
          "size": "2475kb",
          "version": "v4"
        }
      ],
      "title": "IPCGRL: Language-Instructed Reinforcement Learning for Procedural Level Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12358",
        "HTML": "https://arxiv.org/html/2503.12358v4",
        "PDF": "https://arxiv.org/pdf/2503.12358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses procedural content generation through language-instructed reinforcement learning, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Sentence",
        "Sentence Embedding",
        "Sentence-Embedding"
      ],
      "repo_urls": [
        "https://github.com/bic4907/insturcted_pcgrl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12972",
      "abstract": "Multimodal reasoning in Large Language Models (LLMs) struggles with incomplete knowledge and hallucination artifacts, challenges that textual Knowledge Graphs (KGs) only partially mitigate due to their modality isolation. While Multimodal Knowledge Graphs (MMKGs) promise enhanced cross-modal understanding, their practical construction is impeded by semantic narrowness of manual text annotations and inherent noise in visual-semantic entity linkages. In this paper, we propose Vision-align-to-Language integrated Knowledge Graph (VaLiK), a novel approach for constructing MMKGs that enhances LLMs reasoning through cross-modal information supplementation. Specifically, we cascade pre-trained Vision-Language Models (VLMs) to align image features with text, transforming them into descriptions that encapsulate image-specific information. Furthermore, we developed a cross-modal similarity verification mechanism to quantify semantic consistency, effectively filtering out noise introduced during feature alignment. Even without manually annotated image captions, the refined descriptions alone suffice to construct the MMKG. Compared to conventional MMKGs construction paradigms, our approach achieves substantial storage efficiency gains while maintaining direct entity-to-image linkage capability. Experimental results on multimodal reasoning tasks demonstrate that LLMs augmented with VaLiK outperform previous state-of-the-art models. Our code is published at https://github.com/Wings-Of-Disaster/VaLiK.",
      "authors": [
        "Junming Liu",
        "Siyuan Meng",
        "Yanting Gao",
        "Song Mao",
        "Pinlong Cai",
        "Guohang Yan",
        "Yirong Chen",
        "Zilin Bian",
        "Ding Wang",
        "Botian Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T09:31:14+00:00",
          "link": "https://arxiv.org/abs/2503.12972v1",
          "size": "8710kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:14:43+00:00",
          "link": "https://arxiv.org/abs/2503.12972v2",
          "size": "8875kb",
          "version": "v2"
        }
      ],
      "title": "Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12972",
        "HTML": "https://arxiv.org/html/2503.12972v2",
        "PDF": "https://arxiv.org/pdf/2503.12972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses creating a multimodal knowledge graph to improve LLM reasoning capabilities, which might involve some data processing, the main focus is on alignment techniques rather than directly on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.13176",
      "abstract": "Reconstructing clean, distractor-free 3D scenes from real-world captures remains a significant challenge, particularly in highly dynamic and cluttered settings such as egocentric videos. To tackle this problem, we introduce DeGauss, a simple and robust self-supervised framework for dynamic scene reconstruction based on a decoupled dynamic-static Gaussian Splatting design. DeGauss models dynamic elements with foreground Gaussians and static content with background Gaussians, using a probabilistic mask to coordinate their composition and enable independent yet complementary optimization. DeGauss generalizes robustly across a wide range of real-world scenarios, from casual image collections to long, dynamic egocentric videos, without relying on complex heuristics or extensive supervision. Experiments on benchmarks including NeRF-on-the-go, ADT, AEA, Hot3D, and EPIC-Fields demonstrate that DeGauss consistently outperforms existing methods, establishing a strong baseline for generalizable, distractor-free 3D reconstructionin highly dynamic, interaction-rich environments. Project page: https://batfacewayne.github.io/DeGauss.io/",
      "authors": [
        "Rui Wang",
        "Quentin Lohmeyer",
        "Mirko Meboldt",
        "Siyu Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T13:53:04+00:00",
          "link": "https://arxiv.org/abs/2503.13176v1",
          "size": "46345kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T13:32:00+00:00",
          "link": "https://arxiv.org/abs/2503.13176v2",
          "size": "44632kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T08:25:52+00:00",
          "link": "https://arxiv.org/abs/2503.13176v3",
          "size": "44632kb",
          "version": "v3"
        }
      ],
      "title": "DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for Distractor-free 3D Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13176",
        "HTML": "https://arxiv.org/html/2503.13176v3",
        "PDF": "https://arxiv.org/pdf/2503.13176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for 3D scene reconstruction with Gaussian Splatting, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.14501",
      "abstract": "Generative artificial intelligence has recently progressed from static image and video synthesis to 3D content generation, culminating in the emergence of 4D generation-the task of synthesizing temporally coherent dynamic 3D assets guided by user input. As a burgeoning research frontier, 4D generation enables richer interactive and immersive experiences, with applications ranging from digital humans to autonomous driving. Despite rapid progress, the field lacks a unified understanding of 4D representations, generative frameworks, basic paradigms, and the core technical challenges it faces. This survey provides a systematic and in-depth review of the 4D generation landscape. To comprehensively characterize 4D generation, we first categorize fundamental 4D representations and outline associated techniques for 4D generation. We then present an in-depth analysis of representative generative pipelines based on conditions and representation methods. Subsequently, we discuss how motion and geometry priors are integrated into 4D outputs to ensure spatio-temporal consistency under various control schemes. From an application perspective, this paper summarizes 4D generation tasks in areas such as dynamic object/scene generation, digital human synthesis, editable 4D content, and embodied AI. Furthermore, we summarize and multi-dimensionally compare four basic paradigms for 4D generation: End-to-End, Generated-Data-Based, Implicit-Distillation-Based, and Explicit-Supervision-Based. Concluding our analysis, we highlight five key challenges-consistency, controllability, diversity, efficiency, and fidelity-and contextualize these with current approaches.By distilling recent advances and outlining open problems, this work offers a comprehensive and forward-looking perspective to guide future research in 4D generation.",
      "authors": [
        "Qiaowei Miao",
        "Kehan Li",
        "Jinsheng Quan",
        "Zhiyuan Min",
        "Shaojie Ma",
        "Yichao Xu",
        "Yi Yang",
        "Ping Liu",
        "Yawei Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T17:59:51+00:00",
          "link": "https://arxiv.org/abs/2503.14501v1",
          "size": "4122kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T08:05:50+00:00",
          "link": "https://arxiv.org/abs/2503.14501v2",
          "size": "4158kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T02:45:53+00:00",
          "link": "https://arxiv.org/abs/2503.14501v3",
          "size": "6734kb",
          "version": "v3"
        }
      ],
      "title": "Advances in 4D Generation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14501",
        "HTML": "https://arxiv.org/html/2503.14501v3",
        "PDF": "https://arxiv.org/pdf/2503.14501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys advances in 4D generation and does not address data processing tasks or contributions related to LLM training data processing such as dataset creation or data preprocessing techniques."
      },
      "tasks": [
        "Autonomous Driving",
        "Computational Efficiency",
        "Scene Generation",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/miaoqiaowei/awesome-4d"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16743",
      "abstract": "We introduce an open-ended test grounded in algorithmic probability that can avoid benchmark contamination in the quantitative evaluation of frontier models in the context of their Artificial General Intelligence (AGI) and Superintelligence (ASI) claims. Unlike other tests, this test does not rely on statistical compression methods (such as GZIP or LZW), which are more closely related to Shannon entropy than to Kolmogorov complexity and are not able to test beyond simple pattern matching. The test challenges aspects of AI, in particular LLMs, related to features of intelligence of fundamental nature such as synthesis and model creation in the context of inverse problems (generating new knowledge from observation). We argue that metrics based on model abstraction and abduction (optimal Bayesian `inference') for predictive `planning' can provide a robust framework for testing intelligence, including natural intelligence (human and animal), narrow AI, AGI, and ASI. We found that LLM model versions tend to be fragile and incremental as a result of memorisation only with progress likely driven by the size of training data. The results were compared with a hybrid neurosymbolic approach that theoretically guarantees universal intelligence based on the principles of algorithmic probability and Kolmogorov complexity. The method outperforms LLMs in a proof-of-concept on short binary sequences. We prove that compression is equivalent and directly proportional to a system's predictive power and vice versa. That is, if a system can better predict it can better compress, and if it can better compress, then it can better predict. Our findings strengthen the suspicion regarding the fundamental limitations of LLMs, exposing them as systems optimised for the perception of mastery over human language.",
      "authors": [
        "Alberto Hern\\'andez-Espinosa",
        "Luan Ozelim",
        "Felipe S. Abrah\\~ao",
        "Hector Zenil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T23:11:30+00:00",
          "link": "https://arxiv.org/abs/2503.16743v1",
          "size": "14706kb",
          "version": "v1"
        },
        {
          "date": "2025-04-15T22:36:24+00:00",
          "link": "https://arxiv.org/abs/2503.16743v2",
          "size": "15262kb",
          "version": "v2"
        },
        {
          "date": "2025-04-22T22:30:20+00:00",
          "link": "https://arxiv.org/abs/2503.16743v3",
          "size": "15262kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T01:40:47+00:00",
          "link": "https://arxiv.org/abs/2503.16743v4",
          "size": "9254kb",
          "version": "v4"
        }
      ],
      "title": "SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16743",
        "HTML": "https://arxiv.org/html/2503.16743v4",
        "PDF": "https://arxiv.org/pdf/2503.16743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a test for evaluating intelligence in AI models based on algorithmic probability. It does not relate to training data processing for LLMs, such as data collection or dataset enhancements."
      },
      "tasks": [
        "Bayesian Inference"
      ],
      "repo_urls": [
        "https://github.com/AlgoDynLab/SuperintelligenceTest"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16870",
      "abstract": "Knowledge distillation can be a cost-effective technique to distill knowledge in Large Language Models, if the teacher output logits can be pre-computed and cached. However, successfully applying this to pre-training remains largely unexplored. In this work, we prove that naive approaches for sparse knowledge distillation such as caching Top-K probabilities, while intuitive, provide biased estimates of teacher probability distribution to the student, resulting in suboptimal performance and calibration. We propose an importance-sampling-based method `Random Sampling Knowledge Distillation', which provides unbiased estimates, preserves the gradient in expectation, and requires storing significantly sparser logits. Our method enables faster training of student models with marginal overhead (<10%) compared to cross-entropy based training, while maintaining competitive performance compared to full distillation, across a range of model sizes from 300M to 3B.",
      "authors": [
        "Anshumann",
        "Mohd Abbas Zaidi",
        "Akhil Kedia",
        "Jinwoo Ahn",
        "Taehwak Kwon",
        "Kangwook Lee",
        "Haejun Lee",
        "Joohyung Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T05:58:18+00:00",
          "link": "https://arxiv.org/abs/2503.16870v1",
          "size": "2327kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:30:12+00:00",
          "link": "https://arxiv.org/abs/2503.16870v2",
          "size": "2333kb",
          "version": "v2"
        }
      ],
      "title": "Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16870",
        "PDF": "https://arxiv.org/pdf/2503.16870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a method for knowledge distillation in LLMs which is more about improving model training techniques rather than directly processing training data; however, it touches on optimization relevant to knowledge transfer efficiency."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.17724",
      "abstract": "Backdoor attacks targeting text-to-image diffusion models have advanced rapidly. However, current backdoor samples often exhibit two key abnormalities compared to benign samples: 1) Semantic Consistency, where backdoor prompts tend to generate images with similar semantic content even with significant textual variations to the prompts; 2) Attention Consistency, where the trigger induces consistent structural responses in the cross-attention maps. These consistencies leave detectable traces for defenders, making backdoors easier to identify. In this paper, toward stealthy backdoor samples, we propose Trigger without Trace (TwT) by explicitly mitigating these consistencies. Specifically, our approach leverages syntactic structures as backdoor triggers to amplify the sensitivity to textual variations, effectively breaking down the semantic consistency. Besides, a regularization method based on Kernel Maximum Mean Discrepancy (KMMD) is proposed to align the distribution of cross-attention responses between backdoor and benign samples, thereby disrupting attention consistency. Extensive experiments demonstrate that our method achieves a 97.5% attack success rate while exhibiting stronger resistance to defenses. It achieves an average of over 98% backdoor samples bypassing three state-of-the-art detection mechanisms, revealing the vulnerabilities of current backdoor defense methods. The code is available at https://github.com/Robin-WZQ/TwT.",
      "authors": [
        "Jie Zhang",
        "Zhongqi Wang",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-22T10:41:46+00:00",
          "link": "https://arxiv.org/abs/2503.17724v1",
          "size": "24506kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T05:22:14+00:00",
          "link": "https://arxiv.org/abs/2503.17724v2",
          "size": "25424kb",
          "version": "v2"
        }
      ],
      "title": "Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17724",
        "HTML": "https://arxiv.org/html/2503.17724v2",
        "PDF": "https://arxiv.org/pdf/2503.17724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves backdoor attacks on text-to-image diffusion models, not LLMs, and does not discuss any aspect of data processing for training LLMs or dataset creation relevant to LLM training."
      },
      "tasks": [
        "Backdoor Attack"
      ],
      "repo_urls": [
        "https://github.com/robin-wzq/iba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18273",
      "abstract": "In recent years, Islamophobia has gained significant traction across Western societies, fueled by the rise of digital communication networks. This paper performs a large-scale analysis of specialized, semi-coded Islamophobic terms such as (muzrat, pislam, mudslime, mohammedan, muzzies) floated on extremist social platforms, i.e., 4Chan, Gab, Telegram, etc. Many of these terms appear lexically neutral or ambiguous outside of specific contexts, making them difficult for both human moderators and automated systems to reliably identify as hate speech. First, we use Large Language Models (LLMs) to show their ability to understand these terms. Second, Google Perspective API suggests that Islamophobic posts tend to receive higher toxicity scores than other categories of hate speech like Antisemitism. Finally, we use BERT topic modeling approach to extract different topics and Islamophobic discourse on these social platforms. Our findings indicate that LLMs understand these Out-Of-Vocabulary (OOV) slurs; however, further improvements in moderation strategies and algorithmic detection are necessary to address such discourse effectively. Our topic modeling also indicates that Islamophobic text is found across various political, conspiratorial, and far-right movements and is particularly directed against Muslim immigrants. Taken altogether, we performed one of the first studies on Islamophobic semi-coded terms and shed a global light on Islamophobia.",
      "authors": [
        "Raza Ul Mustafa",
        "Roi Dupart",
        "Gabrielle Smith",
        "Noman Ashraf",
        "Nathalie Japkowicz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T01:41:24+00:00",
          "link": "https://arxiv.org/abs/2503.18273v1",
          "size": "1704kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T00:22:47+00:00",
          "link": "https://arxiv.org/abs/2503.18273v2",
          "size": "595kb",
          "version": "v2"
        }
      ],
      "title": "Analyzing Islamophobic Discourse Using Semi-Coded Terms and LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18273",
        "HTML": "https://arxiv.org/html/2503.18273v2",
        "PDF": "https://arxiv.org/pdf/2503.18273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes Islamophobic discourse using LLMs and BERT for topic modeling but does not contribute to training data processing for LLM pretraining or fine-tuning, nor does it introduce new datasets or data engineering techniques for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.21676",
      "abstract": "Large language models accumulate vast knowledge during pre-training, yet the dynamics governing this acquisition remain poorly understood. This work investigates the learning dynamics of language models on a synthetic factual recall task, uncovering three key findings: First, language models learn in three phases, exhibiting a performance plateau before acquiring precise factual knowledge. Mechanistically, this plateau coincides with the formation of attention-based circuits that support recall. Second, the training data distribution significantly impacts learning dynamics, as imbalanced distributions lead to shorter plateaus. Finally, hallucinations emerge simultaneously with knowledge, and integrating new knowledge into the model through fine-tuning is challenging, as it quickly corrupts its existing parametric memories. Our results emphasize the importance of data distribution in knowledge acquisition and suggest novel data scheduling strategies to accelerate neural network training.",
      "authors": [
        "Nicolas Zucchet",
        "J\\\"org Bornschein",
        "Stephanie Chan",
        "Andrew Lampinen",
        "Razvan Pascanu",
        "Soham De"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-27T16:43:45+00:00",
          "link": "https://arxiv.org/abs/2503.21676v1",
          "size": "1053kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:04:20+00:00",
          "link": "https://arxiv.org/abs/2503.21676v2",
          "size": "1057kb",
          "version": "v2"
        }
      ],
      "title": "How do language models learn facts? Dynamics, curricula and hallucinations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21676",
        "HTML": "https://arxiv.org/html/2503.21676v2",
        "PDF": "https://arxiv.org/pdf/2503.21676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper investigates the learning dynamics of LLMs on a factual recall task and examines the impact of training data distribution on learning. While it touches on data distribution as it affects model training, the primary focus is on learning dynamics rather than directly on data processing operations like dataset creation or quality enhancement for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "alex-karev/biographies",
          "downloads": "90",
          "likes": "3",
          "link": "https://huggingface.co/datasets/alex-karev/biographies"
        }
      ],
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22351",
      "abstract": "Zero-shot depth estimation (DE) models exhibit strong generalization performance as they are trained on large-scale datasets. However, existing models struggle with high-resolution images due to the discrepancy in image resolutions of training (with smaller resolutions) and inference (for high resolutions). Processing them at full resolution leads to decreased estimation accuracy on depth with tremendous memory consumption, while downsampling to the training resolution results in blurred edges in the estimated depth images. Prevailing high-resolution depth estimation methods adopt a patch-based approach, which introduces depth discontinuity issues when reassembling the estimated depth patches, resulting in test-time inefficiency. Additionally, to obtain fine-grained depth details, these methods rely on synthetic datasets due to the real-world sparse ground truth depth, leading to poor generalizability. To tackle these limitations, we propose Patch Refine Once (PRO), an efficient and generalizable tile-based framework. Our PRO consists of two key components: (i) Grouped Patch Consistency Training that enhances test-time efficiency while mitigating the depth discontinuity problem by jointly processing four overlapping patches and enforcing a consistency loss on their overlapping regions within a single backpropagation step, and (ii) Bias Free Masking that prevents the DE models from overfitting to dataset-specific biases, enabling better generalization to real-world datasets even after training on synthetic data. Zero-shot evaluations on Booster, ETH3D, Middlebury 2014, and NuScenes demonstrate that our PRO can be seamlessly integrated into existing depth estimation models.",
      "authors": [
        "Byeongjun Kwon",
        "Munchurl Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T11:46:50+00:00",
          "link": "https://arxiv.org/abs/2503.22351v1",
          "size": "9577kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:14:19+00:00",
          "link": "https://arxiv.org/abs/2503.22351v2",
          "size": "8055kb",
          "version": "v2"
        }
      ],
      "title": "One Look is Enough: A Novel Seamless Patchwise Refinement for Zero-Shot Monocular Depth Estimation Models on High-Resolution Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22351",
        "HTML": "https://arxiv.org/html/2503.22351v2",
        "PDF": "https://arxiv.org/pdf/2503.22351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses zero-shot depth estimation models and proposes a framework for high-resolution images processing but does not relate to LLM training data processing or involve LLM dataset creation or improvements."
      },
      "tasks": [
        "Depth Estimation",
        "Monocular Depth Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22929",
      "abstract": "Face anti-spoofing (FAS) techniques aim to enhance the security of facial identity authentication by distinguishing authentic live faces from deceptive attempts. While two-class FAS methods risk overfitting to training attacks to achieve better performance, one-class FAS approaches handle unseen attacks well but are less robust to domain information entangled within the liveness features. To address this, we propose an Unsupervised Feature Disentanglement and Augmentation Network (\\textbf{UFDANet}), a one-class FAS technique that enhances generalizability by augmenting face images via disentangled features. The \\textbf{UFDANet} employs a novel unsupervised feature disentangling method to separate the liveness and domain features, facilitating discriminative feature learning. It integrates an out-of-distribution liveness feature augmentation scheme to synthesize new liveness features of unseen spoof classes, which deviate from the live class, thus enhancing the representability and discriminability of liveness features. Additionally, \\textbf{UFDANet} incorporates a domain feature augmentation routine to synthesize unseen domain features, thereby achieving better generalizability. Extensive experiments demonstrate that the proposed \\textbf{UFDANet} outperforms previous one-class FAS methods and achieves comparable performance to state-of-the-art two-class FAS methods.",
      "authors": [
        "Pei-Kai Huang",
        "Jun-Xiong Chong",
        "Ming-Tsung Hsu",
        "Fang-Yu Hsu",
        "Yi-Ting Lin",
        "Kai-Heng Chien",
        "Hao-Chiang Shao",
        "Chiou-Ting Hsu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T01:22:50+00:00",
          "link": "https://arxiv.org/abs/2503.22929v1",
          "size": "3261kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:38:58+00:00",
          "link": "https://arxiv.org/abs/2503.22929v2",
          "size": "1878kb",
          "version": "v2"
        }
      ],
      "title": "Unsupervised Feature Disentanglement and Augmentation Network for One-class Face Anti-spoofing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22929",
        "HTML": "https://arxiv.org/html/2503.22929v2",
        "PDF": "https://arxiv.org/pdf/2503.22929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on face anti-spoofing techniques using an unsupervised feature disentanglement and augmentation network. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Disentanglement",
        "Face Anti-Spoofing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23461",
      "abstract": "This paper explores the task of Complex Visual Text Generation (CVTG), which centers on generating intricate textual content distributed across diverse regions within visual images. In CVTG, image generation models often rendering distorted and blurred visual text or missing some visual text. To tackle these challenges, we propose TextCrafter, a novel multi-visual text rendering method. TextCrafter employs a progressive strategy to decompose complex visual text into distinct components while ensuring robust alignment between textual content and its visual carrier. Additionally, it incorporates a token focus enhancement mechanism to amplify the prominence of visual text during the generation process. TextCrafter effectively addresses key challenges in CVTG tasks, such as text confusion, omissions, and blurriness. Moreover, we present a new benchmark dataset, CVTG-2K, tailored to rigorously evaluate the performance of generative models on CVTG tasks. Extensive experiments demonstrate that our method surpasses state-of-the-art approaches.",
      "authors": [
        "Nikai Du",
        "Zhennan Chen",
        "Zhizhou Chen",
        "Shan Gao",
        "Xi Chen",
        "Zhengkai Jiang",
        "Jian Yang and Ying Tai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-30T14:36:55+00:00",
          "link": "https://arxiv.org/abs/2503.23461v1",
          "size": "7982kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T02:56:45+00:00",
          "link": "https://arxiv.org/abs/2503.23461v2",
          "size": "7982kb",
          "version": "v2"
        },
        {
          "date": "2025-06-13T05:41:41+00:00",
          "link": "https://arxiv.org/abs/2503.23461v3",
          "size": "9578kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T06:56:41+00:00",
          "link": "https://arxiv.org/abs/2503.23461v4",
          "size": "9579kb",
          "version": "v4"
        }
      ],
      "title": "TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23461",
        "HTML": "https://arxiv.org/html/2503.23461v4",
        "PDF": "https://arxiv.org/pdf/2503.23461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces TextCrafter for complex visual text generation and presents a new benchmark dataset, CVTG-2K. Although it does entail dataset creation, the focus is on visual text generation rather than direct improvements or processing for LLM training datasets."
      },
      "datasets": [
        {
          "dataset_name": "dnkdnk/CVTG-2K",
          "downloads": "18",
          "likes": "3",
          "link": "https://huggingface.co/datasets/dnkdnk/CVTG-2K"
        }
      ],
      "tasks": [
        "2k",
        "Image Generation",
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/nju-pcalab/textcrafter"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.02250",
      "abstract": "In this paper, we present a systematic method of design for human-swarm interaction interfaces, combining theoretical insights with empirical evaluation. We first derived ten design principles from existing literature, applying them to key information dimensions identified through goal-directed task analysis and developed a tablet-based interface for a target search task. We then conducted a user study with 31 participants where humans were required to guide a robotic swarm to a target in the presence of three types of hazards that pose a risk to the robots: Distributed, Moving, and Spreading. Performance was measured based on the proximity of the robots to the target and the number of deactivated robots at the end of the task. Results indicate that at least one robot was brought closer to the target in 98% of tasks, demonstrating the interface's success in fulfilling the primary objective of the task. Additionally, in nearly 67% of tasks, more than 50% of the robots reached the target. Moreover, particularly better performance was noted in moving hazards. Additionally, the interface appeared to help minimise robot deactivation, as evidenced by nearly 94% of tasks where participants managed to keep more than 50% of the robots active, ensuring that most of the swarm remained operational. However, its effectiveness varied across hazards, with robot deactivation being lowest in distributed hazard scenarios, suggesting that the interface provided the most support in these conditions.",
      "authors": [
        "Wasura D. Wattearachchi",
        "Erandi Lakshika",
        "Kathryn Kasmarik",
        "Michael Barlow"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T03:38:13+00:00",
          "link": "https://arxiv.org/abs/2504.02250v1",
          "size": "1170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:00:35+00:00",
          "link": "https://arxiv.org/abs/2504.02250v2",
          "size": "994kb",
          "version": "v2"
        }
      ],
      "title": "Designing Effective Human-Swarm Interaction Interfaces: Insights from a User Study on Task Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02250",
        "PDF": "https://arxiv.org/pdf/2504.02250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the design of human-swarm interaction interfaces and the results of a user study, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.02443",
      "abstract": "Performance-critical industrial applications, including large-scale program, network, and distributed system analyses, rely on fixed-point computations. The introduction of recursive common table expressions (CTEs) using the WITH RECURSIVE keyword in SQL:1999 extended the ability of relational database systems to handle fixed-point computations, unlocking significant performance advantages by allowing computation to move closer to the data. Yet with recursion, SQL becomes a Turing-complete programming language and, with that, unrecoverable safety and correctness risks. SQL itself lacks a fixed semantics, as the SQL specification is written in natural language, full of ambiguities that database vendors resolve in divergent ways. As a result, reasoning about the correctness of recursive SQL programs must rely on isolated mathematical properties of queries rather than wrestling a unified formal model out of a language with notoriously inconsistent semantics. To address these challenges, we propose a calculus that automatically derives mathematical properties from embedded recursive queries and, depending on the database backend, rejects queries that may lead to the three classes of recursive query errors - database errors, incorrect results, and non-termination. We introduce TyQL, a practical implementation in Scala for safe, recursive language-integrated query. Using Named-Tuples and type-level pattern matching, TyQL ensures query portability and safety, showing no performance penalty compared to raw SQL strings while unlocking a three-orders-of-magnitude speedup over non-recursive SQL queries.",
      "authors": [
        "Anna Herlihy",
        "Amir Shaikhha",
        "Anastasia Ailamaki",
        "Martin Odersky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T09:58:52+00:00",
          "link": "https://arxiv.org/abs/2504.02443v1",
          "size": "739kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:38:34+00:00",
          "link": "https://arxiv.org/abs/2504.02443v2",
          "size": "736kb",
          "version": "v2"
        }
      ],
      "title": "Language-Integrated Recursive Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02443",
        "HTML": "https://arxiv.org/html/2504.02443v2",
        "PDF": "https://arxiv.org/pdf/2504.02443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses recursive queries and their safety in SQL, focusing on fixed-point computations and performance improvement in database contexts, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03173",
      "abstract": "Privacy-Preserving Federated Learning (PPFL) allows multiple clients to collaboratively train a deep learning model by submitting hidden model updates. Nonetheless, PPFL is vulnerable to data poisoning attacks due to the distributed training nature of clients. Existing solutions have struggled to improve the performance of cross-silo PPFL in poisoned Non-IID data. To address the issues, this paper proposes a privacy-preserving federated prototype learning framework, named PPFPL, which enhances the cross-silo FL performance in poisoned Non-IID data while effectively resisting data poisoning attacks. Specifically, we adopt prototypes as client-submitted model updates to eliminate the impact of tampered data distribution on federated learning. Moreover, we utilize two servers to achieve Byzantine-robust aggregation by secure aggregation protocol, which greatly reduces the impact of malicious clients. Theoretical analyses confirm the convergence of PPFPL, and experimental results on publicly available datasets show that PPFPL is effective for resisting data poisoning attacks with Non-IID conditions.",
      "authors": [
        "Hongliang Zhang",
        "Jiguo Yu",
        "Fenghua Xu",
        "Chunqiang Hu",
        "Yongzhao Zhang",
        "Xiaofen Wang",
        "Zhongyuan Yu",
        "Xiaosong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T05:05:24+00:00",
          "link": "https://arxiv.org/abs/2504.03173v1",
          "size": "1488kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T04:29:57+00:00",
          "link": "https://arxiv.org/abs/2504.03173v2",
          "size": "1425kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T07:02:51+00:00",
          "link": "https://arxiv.org/abs/2504.03173v3",
          "size": "456kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T01:21:26+00:00",
          "link": "https://arxiv.org/abs/2504.03173v4",
          "size": "456kb",
          "version": "v4"
        }
      ],
      "title": "PPFPL: Cross-silo Privacy-preserving Federated Prototype Learning Against Data Poisoning Attacks on Non-IID Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03173",
        "HTML": "https://arxiv.org/html/2504.03173v4",
        "PDF": "https://arxiv.org/pdf/2504.03173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy-preserving federated learning and resisting data poisoning attacks, but it does not discuss LLM training data processing or contribute to dataset creation or quality improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03300",
      "abstract": "Human oversight requirements are a core component of the European AI Act and in AI governance. In this paper, we highlight key challenges in testing for compliance with these requirements. A central difficulty lies in balancing simple, but potentially ineffective checklist-based approaches with resource-intensive and context-sensitive empirical testing of the effectiveness of human oversight of AI. Questions regarding when to update compliance testing, the context-dependent nature of human oversight requirements, and difficult-to-operationalize standards further complicate compliance testing. We argue that these challenges illustrate broader challenges in the future of sociotechnical AI governance, i.e. a future that shifts from ensuring good technological products to good sociotechnical systems.",
      "authors": [
        "Markus Langer",
        "Veronika Lazar",
        "Kevin Baum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T09:26:59+00:00",
          "link": "https://arxiv.org/abs/2504.03300v1",
          "size": "540kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T10:13:15+00:00",
          "link": "https://arxiv.org/abs/2504.03300v2",
          "size": "265kb",
          "version": "v2"
        }
      ],
      "title": "On the Complexities of Testing for Compliance with Human Oversight Requirements in AI Regulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03300",
        "PDF": "https://arxiv.org/pdf/2504.03300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with testing compliance for human oversight in AI systems under regulatory frameworks and does not address LLM training data processing or related data engineering topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03737",
      "abstract": "The management of chronic heart failure presents significant challenges in modern healthcare, requiring continuous monitoring, early detection of exacerbations, and personalized treatment strategies. This paper presents the preliminary results of the PrediHealth research project conducted in this context. Specifically, it aims to address the challenges above by integrating telemedicine, mobile health solutions, and predictive analytics into a unified digital healthcare platform. We leveraged a web-based IoT platform, a telemonitoring kit with medical devices and environmental sensors, and AI-driven predictive models to support clinical decision-making. The project follows a structured methodology comprising research on emerging CPS/IoT technologies, system prototyping, predictive model development, and empirical validation.",
      "authors": [
        "Giuseppe De Filippo",
        "Simranjit Singh",
        "Gianpiero Sisto",
        "Marco Mazzotta",
        "Gianvito Mitrano",
        "Claudio Pascarelli",
        "Gianluca Fimiani",
        "Simone Romano",
        "Mariangela Lazoi",
        "Marina Garofano",
        "Alessia Bramanti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Other Computer Science (cs.OH)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T08:01:24+00:00",
          "link": "https://arxiv.org/abs/2504.03737v1",
          "size": "139kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T09:50:46+00:00",
          "link": "https://arxiv.org/abs/2504.03737v2",
          "size": "139kb",
          "version": "v2"
        },
        {
          "date": "2025-05-16T16:39:18+00:00",
          "link": "https://arxiv.org/abs/2504.03737v3",
          "size": "139kb",
          "version": "v3"
        },
        {
          "date": "2025-05-22T13:52:55+00:00",
          "link": "https://arxiv.org/abs/2504.03737v4",
          "size": "139kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T15:54:10+00:00",
          "link": "https://arxiv.org/abs/2504.03737v5",
          "size": "95kb",
          "version": "v5"
        }
      ],
      "title": "PrediHealth: Telemedicine and Predictive Algorithms for the Care and Prevention of Patients with Chronic Heart Failure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03737",
        "HTML": "https://arxiv.org/html/2504.03737v5",
        "PDF": "https://arxiv.org/pdf/2504.03737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the integration of telemedicine and predictive analytics for chronic heart failure management, without focus on LLM training data processing or dataset-related contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.04598",
      "abstract": "Robot pick and place systems have traditionally decoupled grasp, placement, and motion planning to build sequential optimization pipelines with the assumption that the individual components will be able to work together. However, this separation introduces sub-optimality, as grasp choices may limit or even prohibit feasible motions for a robot to reach the target placement pose, particularly in cluttered environments with narrow passages. To this end, we propose a forest-based planning framework to simultaneously find grasp configurations and feasible robot motions that explicitly satisfy downstream placement configurations paired with the selected grasps. Our proposed framework leverages a bidirectional sampling-based approach to build a start forest, rooted at the feasible grasp regions, and a goal forest, rooted at the feasible placement regions, to facilitate the search through randomly explored motions that connect valid pairs of grasp and placement trees. We demonstrate that the framework's inherent parallelism enables superlinear speedup, making it scalable for applications for redundant robot arms (e.g., 7 Degrees of Freedom) to work efficiently in highly cluttered environments. Extensive experiments in simulation demonstrate the robustness and efficiency of the proposed framework in comparison with multiple baselines under diverse scenarios.",
      "authors": [
        "Benjamin H. Leebron",
        "Kejia Ren",
        "Yiting Chen",
        "and Kaiyu Hang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-06T20:02:17+00:00",
          "link": "https://arxiv.org/abs/2504.04598v1",
          "size": "7223kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:48:42+00:00",
          "link": "https://arxiv.org/abs/2504.04598v2",
          "size": "3834kb",
          "version": "v2"
        }
      ],
      "title": "B4P: Simultaneous Grasp and Motion Planning for Object Placement via Parallelized Bidirectional Forests and Path Repair",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04598",
        "HTML": "https://arxiv.org/html/2504.04598v2",
        "PDF": "https://arxiv.org/pdf/2504.04598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While addressing simultaneous grasp and motion planning in robotic systems, the paper does not pertain to LLM training data processing or contribute to data operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.04704",
      "abstract": "The increasing size of the Key-Value (KV) cache during the Large Language Models long-context inference is the main obstacle for its balance between the deployment cost and task accuracy. To reduce the KV cache size in such scenarios, most previous efforts leveraged on the attention weight to evict non-critical cache tokens. But there is a trade-off in those methods, they usually require major modification of the inference infrastructure and significant computation overhead. Based on the fact that the Large Language models are autoregressive models, we propose LagKV, a KV compression strategy only relying on straight forward comparison among KV themselves. It is a totally attention free method which offers easy integration to the main stream inference platform and comparable performance comparing to other complicated KV compression methods. Results on RULER benchmark show that, our approach outperforms SnapKV and StreamingLLM in different compression ratios. Especially in the 64-digit passkey retrieval task, our method outperforms the attention weight based method $H_2O$ over $50\\%$ with same compression ratios. Our code is available at https://github.com/AI-Lab-China-Merchants-Bank/LagKV.",
      "authors": [
        "Manlai Liang",
        "JiaMing Zhang",
        "Xiong Li",
        "Jinlong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T03:22:15+00:00",
          "link": "https://arxiv.org/abs/2504.04704v1",
          "size": "164kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:25:51+00:00",
          "link": "https://arxiv.org/abs/2504.04704v2",
          "size": "313kb",
          "version": "v2"
        }
      ],
      "title": "LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04704",
        "HTML": "https://arxiv.org/html/2504.04704v2",
        "PDF": "https://arxiv.org/pdf/2504.04704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reducing the Key-Value cache size during LLM inference through a KV compression strategy. It does not address training data processing, pretraining, or fine-tuning of LLMs."
      },
      "models": [
        {
          "model_path": "CMB-AI-LAB/lagkv_cache",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/CMB-AI-LAB/lagkv_cache"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/ai-lab-china-merchants-bank/lagkv"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.05211",
      "abstract": "Establishing a communication system is hard because the intended meaning of a signal is unknown to its receiver when first produced, and the signaller also has no idea how that signal will be interpreted. Most theoretical accounts of the emergence of communication systems rely on feedback to reinforce behaviours that have led to successful communication in the past. However, providing such feedback requires already being able to communicate the meaning that was intended or interpreted. Therefore these accounts cannot explain how communication can be bootstrapped from non-communicative behaviours. Here we present a model that shows how a communication system, capable of expressing an unbounded number of meanings, can emerge as a result of individual behavioural differences in a large population without any pre-existing means to determine communicative success. The two key cognitive capabilities responsible for this outcome are behaving predictably in a given situation, and an alignment of psychological states ahead of signal production that derives from shared intentionality. Since both capabilities can exist independently of communication, our results are compatible with theories in which large flexible socially-learned communication systems like language are the product of a general but well-developed capacity for social cognition.",
      "authors": [
        "Richard A. Blythe and Casimir Fisch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Physics and Society (physics.soc-ph)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T15:58:49+00:00",
          "link": "https://arxiv.org/abs/2504.05211v1",
          "size": "454kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:44:57+00:00",
          "link": "https://arxiv.org/abs/2504.05211v2",
          "size": "537kb",
          "version": "v2"
        }
      ],
      "title": "Exploiting individual differences to bootstrap communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05211",
        "HTML": "https://arxiv.org/html/2504.05211v2",
        "PDF": "https://arxiv.org/pdf/2504.05211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the emergence of communication systems in large populations, with no mention of LLM training data processing or related data operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.10240",
      "abstract": "Circuit link prediction identifying missing component connections from incomplete netlists is crucial in analog circuit design automation. However, existing methods face three main challenges: 1) Insufficient use of topological patterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to the complexity of annotations hinders model generalization; 3) Limited adaptability to various netlist formats. We propose GNN-ACLP, a graph neural networks (GNNs) based method featuring three innovations to tackle these challenges. First, we introduce the SEAL (learning from Subgraphs, Embeddings, and Attributes for Link prediction) framework and achieve port-level accuracy in circuit link prediction. Second, we propose Netlist Babel Fish, a netlist format conversion tool leveraging retrieval-augmented generation (RAG) with a large language model (LLM) to improve the compatibility of netlist formats. Finally, we construct SpiceNetlist, a comprehensive dataset that contains 775 annotated circuits across 10 different component classes. Experiments demonstrate accuracy improvements of 16.08% on SpiceNetlist, 11.38% on Image2Net, and 16.01% on Masala-CHAI compared to the baseline in intra-dataset evaluation, while maintaining accuracy from 92.05% to 99.07% in cross-dataset evaluation, exhibiting robust feature transfer capabilities.",
      "authors": [
        "Guanyuan Pan",
        "Tiansheng Zhou",
        "Bingtao Ma",
        "Yaqi Wang",
        "Jianxiang Zhao",
        "Zhi Li",
        "Yugui Lin",
        "Pietro Lio",
        "Shuai Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T14:02:09+00:00",
          "link": "https://arxiv.org/abs/2504.10240v1",
          "size": "1140kb",
          "version": "v1"
        },
        {
          "date": "2025-05-18T07:38:47+00:00",
          "link": "https://arxiv.org/abs/2504.10240v2",
          "size": "6712kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T12:58:59+00:00",
          "link": "https://arxiv.org/abs/2504.10240v3",
          "size": "1708kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T11:31:03+00:00",
          "link": "https://arxiv.org/abs/2504.10240v4",
          "size": "1692kb",
          "version": "v4"
        }
      ],
      "title": "GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10240",
        "HTML": "https://arxiv.org/html/2504.10240v4",
        "PDF": "https://arxiv.org/pdf/2504.10240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a dataset called SpiceNetlist used for circuit link prediction, involving LLM tools for netlist format conversion. While it mentions dataset creation, it is primarily focused on analog circuit design and predictions using GNNs, not LLM-specific training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Link Prediction",
        "Prediction",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13101",
      "abstract": "Self-Supervised Learning (SSL) powers many current AI systems. As research interest and investment grow, the SSL design space continues to expand. The Platonic view of SSL, following the Platonic Representation Hypothesis (PRH), suggests that despite different methods and engineering approaches, all representations converge to the same Platonic ideal. However, this phenomenon lacks precise theoretical explanation. By synthesizing evidence from Identifiability Theory (IT), we show that the PRH can emerge in SSL. However, current IT cannot explain SSL's empirical success. To bridge the gap between theory and practice, we propose expanding IT into what we term Singular Identifiability Theory (SITh), a broader theoretical framework encompassing the entire SSL pipeline. SITh would allow deeper insights into the implicit data assumptions in SSL and advance the field towards learning more interpretable and generalizable representations. We highlight three critical directions for future research: 1) training dynamics and convergence properties of SSL; 2) the impact of finite samples, batch size, and data diversity; and 3) the role of inductive biases in architecture, augmentations, initialization schemes, and optimizers.",
      "authors": [
        "Patrik Reizinger",
        "Randall Balestriero",
        "David Klindt",
        "Wieland Brendel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T17:10:33+00:00",
          "link": "https://arxiv.org/abs/2504.13101v1",
          "size": "150kb",
          "version": "v1"
        },
        {
          "date": "2025-06-01T13:15:07+00:00",
          "link": "https://arxiv.org/abs/2504.13101v2",
          "size": "151kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T11:53:07+00:00",
          "link": "https://arxiv.org/abs/2504.13101v3",
          "size": "151kb",
          "version": "v3"
        }
      ],
      "title": "Position: An Empirically Grounded Identifiability Theory Will Accelerate Self-Supervised Learning Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13101",
        "PDF": "https://arxiv.org/pdf/2504.13101"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses developing a theoretical framework for self-supervised learning (SSL) but does not address any aspects of training data processing related to large language models (LLMs) specifically."
      },
      "tasks": [
        "Diversity",
        "Self-Supervised Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13180",
      "abstract": "Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about \"what\", \"where\", \"when\", and \"how\" of a video. We make our work fully reproducible by providing data, training recipes, code & models. https://github.com/facebookresearch/perception_models",
      "authors": [
        "Jang Hyun Cho",
        "Andrea Madotto",
        "Effrosyni Mavroudi",
        "Triantafyllos Afouras",
        "Tushar Nagarajan",
        "Muhammad Maaz",
        "Yale Song",
        "Tengyu Ma",
        "Shuming Hu",
        "Suyog Jain",
        "Miguel Martin",
        "Huiyu Wang",
        "Hanoona Rasheed",
        "Peize Sun",
        "Po-Yao Huang",
        "Daniel Bolya",
        "Nikhila Ravi",
        "Shashank Jain",
        "Tammy Stark",
        "Shane Moon",
        "Babak Damavandi",
        "Vivian Lee",
        "Andrew Westbury",
        "Salman Khan",
        "Philipp Kr\\\"ahenb\\\"uhl",
        "Piotr Doll\\'ar",
        "Lorenzo Torresani",
        "Kristen Grauman",
        "Christoph Feichtenhofer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2504.13180v1",
          "size": "41409kb",
          "version": "v1"
        },
        {
          "date": "2025-06-19T16:16:57+00:00",
          "link": "https://arxiv.org/abs/2504.13180v2",
          "size": "13281kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T19:22:35+00:00",
          "link": "https://arxiv.org/abs/2504.13180v3",
          "size": "13281kb",
          "version": "v3"
        }
      ],
      "title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13180",
        "PDF": "https://arxiv.org/pdf/2504.13180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset for video understanding using vision-language models, focusing on closing data gaps in visual understanding. It doesn't directly contribute to the LLM training data processing landscape but uses a similar methodology in dataset construction."
      },
      "models": [
        {
          "model_path": "facebook/Perception-LM-3B",
          "downloads": "442",
          "likes": "17",
          "trending_score": "0.0",
          "link": "https://huggingface.co/facebook/Perception-LM-3B"
        },
        {
          "model_path": "facebook/Perception-LM-1B",
          "downloads": "864",
          "likes": "30",
          "trending_score": "0.0",
          "link": "https://huggingface.co/facebook/Perception-LM-1B"
        },
        {
          "model_path": "facebook/Perception-LM-8B",
          "downloads": "324",
          "likes": "51",
          "trending_score": "0.0",
          "link": "https://huggingface.co/facebook/Perception-LM-8B"
        },
        {
          "model_path": "facebook/PE-Lang-L14-448",
          "downloads": "1477",
          "likes": "7",
          "trending_score": "0.0",
          "link": "https://huggingface.co/facebook/PE-Lang-L14-448"
        },
        {
          "model_path": "facebook/PE-Lang-G14-448",
          "downloads": "74",
          "likes": "13",
          "trending_score": "0.0",
          "link": "https://huggingface.co/facebook/PE-Lang-G14-448"
        },
        {
          "model_path": "timm/vit_pe_lang_gigantic_patch14_448.fb",
          "downloads": "108",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/timm/vit_pe_lang_gigantic_patch14_448.fb"
        },
        {
          "model_path": "timm/vit_pe_lang_large_patch14_448.fb",
          "downloads": "233",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/timm/vit_pe_lang_large_patch14_448.fb"
        }
      ],
      "datasets": [
        {
          "dataset_name": "facebook/PLM-Video-Human",
          "downloads": "859",
          "likes": "23",
          "link": "https://huggingface.co/datasets/facebook/PLM-Video-Human"
        },
        {
          "dataset_name": "facebook/PLM-Video-Auto",
          "downloads": "254",
          "likes": "14",
          "link": "https://huggingface.co/datasets/facebook/PLM-Video-Auto"
        },
        {
          "dataset_name": "facebook/PLM-Image-Auto",
          "downloads": "300",
          "likes": "15",
          "link": "https://huggingface.co/datasets/facebook/PLM-Image-Auto"
        },
        {
          "dataset_name": "facebook/PLM-VideoBench",
          "downloads": "619",
          "likes": "10",
          "link": "https://huggingface.co/datasets/facebook/PLM-VideoBench"
        }
      ],
      "tasks": [
        "Video Question Answering",
        "Video Understanding"
      ],
      "repo_urls": [
        "https://github.com/facebookresearch/perception_models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13784",
      "abstract": "Several reachability problems in finite automata, such as completeness of NFAs and synchronisation of total DFAs, correspond to fundamental properties of sets of nonnegative matrices. In particular, the two mentioned properties correspond to matrix mortality and ergodicity, which ask whether there exists a product of the input matrices that is equal to, respectively, the zero matrix and a matrix with a column of strictly positive entries only. The case where the input automaton is strongly connected (that is, the corresponding set of nonnegative matrices is irreducible) frequently appears in applications and often admits better properties than the general case. In this paper, we address the existence of such properties from the computational complexity point of view, and develop a versatile technique to show that several NL-complete problems remain NL-complete in the strongly connected case. In particular, we show that deciding if a binary total DFA is synchronising is NL-complete even if it is promised to be strongly connected, and that deciding completeness of a binary unambiguous NFA with very limited nondeterminism is NL-complete under the same promise.",
      "authors": [
        "Stefan Kiefer",
        "Andrew Ryzhikov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T16:34:41+00:00",
          "link": "https://arxiv.org/abs/2504.13784v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T22:45:15+00:00",
          "link": "https://arxiv.org/abs/2504.13784v2",
          "size": "26kb",
          "version": "v2"
        }
      ],
      "title": "The complexity of reachability problems in strongly connected finite automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13784",
        "HTML": "https://arxiv.org/html/2504.13784v2",
        "PDF": "https://arxiv.org/pdf/2504.13784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on computational complexity in reachability problems within finite automata, which is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.14928",
      "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue framework that efficiently assesses teaching capabilities through simulated dynamic educational scenarios, featuring specialized agents for teaching, learning, and evaluation. Testing 14 LLMs across major AI Organizations (OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13 disciplines and 10 difficulty levels reveals that teaching effectiveness does not correlate linearly with model scale or general reasoning capabilities - with some smaller open-source models outperforming larger commercial counterparts in teaching contexts. This finding highlights a critical gap in current evaluations that prioritize knowledge recall over interactive pedagogy. Our mixed-methods evaluation, combining quantitative metrics with qualitative analysis and expert case studies, identifies distinct pedagogical strengths employed by top-performing models (e.g., sophisticated questioning strategies, adaptive feedback mechanisms). Human expert evaluations show 78% agreement with our automated qualitative analysis of effective teaching behaviors, validating our methodology. EducationQ demonstrates that LLMs-as-teachers require specialized optimization beyond simple scaling, suggesting next-generation educational AI prioritize targeted enhancement of specific pedagogical effectiveness.",
      "authors": [
        "Yao Shi",
        "Rongkeng Liang",
        "Yong Xu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T07:48:20+00:00",
          "link": "https://arxiv.org/abs/2504.14928v1",
          "size": "5695kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:20:03+00:00",
          "link": "https://arxiv.org/abs/2504.14928v2",
          "size": "10233kb",
          "version": "v2"
        }
      ],
      "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14928",
        "HTML": "https://arxiv.org/html/2504.14928v2",
        "PDF": "https://arxiv.org/pdf/2504.14928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses a multi-agent dialogue framework for evaluating LLMs in educational settings, touching upon training data indirectly but primarily focusing on model evaluation and pedagogical interactions rather than training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.17723",
      "abstract": "Adversarial robustness verification is essential for ensuring the safe deployment of Large Language Models (LLMs) in runtime-critical applications. However, formal verification techniques remain computationally infeasible for modern LLMs due to their exponential runtime and white-box access requirements. This paper presents a case study adapting and extending the RoMA statistical verification framework to assess its feasibility as an online runtime robustness monitor for LLMs in black-box deployment settings. Our adaptation of RoMA analyzes confidence score distributions under semantic perturbations to provide quantitative robustness assessments with statistically validated bounds. Our empirical validation against formal verification baselines demonstrates that RoMA achieves comparable accuracy (within 1\\% deviation), and reduces verification times from hours to minutes. We evaluate this framework across semantic, categorial, and orthographic perturbation domains. Our results demonstrate RoMA's effectiveness for robustness monitoring in operational LLM deployments. These findings point to RoMA as a potentially scalable alternative when formal methods are infeasible, with promising implications for runtime verification in LLM-based systems.",
      "authors": [
        "Natan Levy",
        "Adiel Ashrov and Guy Katz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T16:36:19+00:00",
          "link": "https://arxiv.org/abs/2504.17723v1",
          "size": "203kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:03:09+00:00",
          "link": "https://arxiv.org/abs/2504.17723v2",
          "size": "174kb",
          "version": "v2"
        }
      ],
      "title": "Statistical Runtime Verification for LLMs via Robustness Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17723",
        "HTML": "https://arxiv.org/html/2504.17723v2",
        "PDF": "https://arxiv.org/pdf/2504.17723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robustness verification for LLMs and proposes a framework for runtime deployment in black-box settings, but it does not address data processing or improvements related to training datasets for LLMs."
      },
      "conference": "towards-robust-llms-an-adversarial-robustness",
      "conference_url_abs": "https://arxiv.org/abs/2504.17723",
      "tasks": [
        "Adversarial Robustness",
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/adielashrov/trust-ai-roma-for-llm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17897",
      "abstract": "Physical inactivity significantly contributes to obesity and other non-communicable diseases, yet efforts to increase population-wide physical activity levels have met with limited success. The built environment plays a pivotal role in encouraging active behaviors like walking. Walkability indices, which aggregate various environmental features, provide a valuable tool for promoting healthy, walkable environments. However, a standardized, high-resolution walkability index for Europe has been lacking. This study addresses that gap by developing a standardized, high-resolution walkability index for the entire European region. Seven core components were selected to define walkability: walkable street length, intersection density, green spaces, slope, public transport access, land use mix, and 15-minute walking isochrones. These were derived from harmonized, high-resolution datasets such as Sentinel-2, NASA's elevation models, OpenStreetMap, and CORINE Land Cover. A 100 m x 100 m hierarchical grid system and advanced geospatial methods, like network buffers and distance decay, were used at scale to efficiently model real-world density and proximity effects. The resulting index was weighted by population and analyzed at different spatial levels using visual mapping, spatial clustering, and correlation analysis. Findings revealed a distinct urban-to-rural gradient, with high walkability scores concentrated in compact urban centers rich in street connectivity and land use diversity. The index highlighted cities like Barcelona, Berlin, Munich, Paris, and Warsaw as walkability leaders. This standardized, high-resolution walkability index serves as a practical tool for researchers, planners, and policymakers aiming to support active living and public health across diverse European contexts.",
      "authors": [
        "Nishit Patel",
        "Hoang-Ha Nguyen",
        "Jet van de Geest",
        "Alfred Wagtendonk",
        "Mohan JS Raju",
        "Payam Dadvand",
        "Kees de Hoogh",
        "Marta Cirach",
        "Mark Nieuwenhuijsen",
        "Thao Minh Lam",
        "Jeroen Lakerveld"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T19:17:58+00:00",
          "link": "https://arxiv.org/abs/2504.17897v1",
          "size": "27034kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T12:35:51+00:00",
          "link": "https://arxiv.org/abs/2504.17897v2",
          "size": "41348kb",
          "version": "v2"
        }
      ],
      "title": "A Walk across Europe: Development of a high-resolution walkability index",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17897",
        "HTML": "https://arxiv.org/html/2504.17897v2",
        "PDF": "https://arxiv.org/pdf/2504.17897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study develops a high-resolution walkability index for Europe, emphasizing physical activity and environmental features. It does not relate to LLM training data processing or dataset construction for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.17999",
      "abstract": "Generative conversational interfaces powered by large language models (LLMs) typically stream output token-by-token at a rate determined by computational budget, often neglecting actual human reading speeds and the cognitive load associated with the content. This mismatch frequently leads to inefficient use of computational resources. For example, in cloud-based services, streaming content faster than users can read appears unnecessary, resulting in wasted computational resources and potential delays for other users, particularly during peak usage periods. To address this issue, we propose an adaptive streaming method that dynamically adjusts the pacing of LLM streaming output in real-time based on inferred cognitive load. Our approach estimates the cognitive load associated with streaming content and strategically slows down the stream during complex or information-rich segments, thereby freeing computational resources for other users. We conducted a statistical analysis and simulation based on a statistical model derived from data collected in a crowdsourced user study across various types of LLM-generated content. Our results show that this adaptive method can effectively reduce computational consumption while largely maintaining streaming speed above user's normal reading speed.",
      "authors": [
        "Chang Xiao",
        "Brenda Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T00:58:37+00:00",
          "link": "https://arxiv.org/abs/2504.17999v1",
          "size": "3225kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:50:43+00:00",
          "link": "https://arxiv.org/abs/2504.17999v2",
          "size": "3237kb",
          "version": "v2"
        }
      ],
      "title": "Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17999",
        "HTML": "https://arxiv.org/html/2504.17999v2",
        "PDF": "https://arxiv.org/pdf/2504.17999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an adaptive streaming method to adjust LLM streaming based on cognitive load but does not involve data processing for LLM training or dataset enhancement."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.19634",
      "abstract": "Labeling errors in remote sensing (RS) image segmentation datasets often remain implicit and subtle due to ambiguous class boundaries, mixed pixels, shadows, complex terrain features, and subjective annotator bias. Furthermore, the scarcity of annotated RS data due to high image acquisition and labeling costs complicates training noise-robust models. While sophisticated mechanisms such as label selection or noise correction might address this issue, they tend to increase training time and add implementation complexity. In this letter, we propose NSegment-a simple yet effective data augmentation solution to mitigate this issue. Unlike traditional methods, it applies elastic transformations only to segmentation labels, varying deformation intensity per sample in each training epoch to address annotation inconsistencies. Experimental results demonstrate that our approach improves the performance of RS image segmentation on various state-of-the-art models.",
      "authors": [
        "Yechan Kim",
        "DongHo Yoon",
        "SooYeon Kim",
        "Moongu Jeon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T09:49:35+00:00",
          "link": "https://arxiv.org/abs/2504.19634v1",
          "size": "1215kb",
          "version": "v1"
        },
        {
          "date": "2025-06-14T15:30:16+00:00",
          "link": "https://arxiv.org/abs/2504.19634v2",
          "size": "1991kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T15:35:04+00:00",
          "link": "https://arxiv.org/abs/2504.19634v3",
          "size": "1984kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T12:39:27+00:00",
          "link": "https://arxiv.org/abs/2504.19634v4",
          "size": "0kb",
          "version": "v4"
        }
      ],
      "title": "NSegment : Label-specific Deformations for Remote Sensing Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19634",
        "PDF": "https://arxiv.org/pdf/2504.19634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a data augmentation technique, NSegment, for remote sensing image segmentation. It focuses on label deformations for image datasets and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.20991",
      "abstract": "In our previous work, we presented the \\emph{Hypothesis Testing Lemma}, a key tool that establishes sufficient conditions for the existence of good deterministic identification (DI) codes for memoryless channels with finite output, but arbitrary input alphabets. In this work, we provide a full quantum analogue of this lemma, which shows that the existence of a DI code in the quantum setting follows from a suitable packing in a modified space of output quantum states. Specifically, we demonstrate that such a code can be constructed using product states derived from this packing. This result enables us to tighten the capacity lower bound for DI over quantum channels beyond the simultaneous decoding approach. In particular, we can now express these bounds solely in terms of the Minkowski dimension of a certain state space, giving us new insights to better understand the nature of the protocol, and the separation between simultaneous and non-simultaneous codes. We extend the discussion with a particular channel example for which we can construct an optimum code.",
      "authors": [
        "Pau Colomer",
        "Christian Deppe",
        "Holger Boche",
        "Andreas Winter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T17:57:36+00:00",
          "link": "https://arxiv.org/abs/2504.20991v1",
          "size": "92kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:26:03+00:00",
          "link": "https://arxiv.org/abs/2504.20991v2",
          "size": "85kb",
          "version": "v2"
        }
      ],
      "title": "Quantum Hypothesis Testing Lemma for Deterministic Identification over Quantum Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20991",
        "HTML": "https://arxiv.org/html/2504.20991v2",
        "PDF": "https://arxiv.org/pdf/2504.20991"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work deals with quantum hypothesis testing and deterministic identification over quantum channels, which does not involve LLM training data processing or dataset improvements in a language model context."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21603",
      "abstract": "Most organic liquids exhibit a pressure-dependent viscosity, making it crucial to consider this behavior in applications where pressures significantly exceed ambient conditions (e.g., geological carbon sequestration). Mathematical models describing flow through porous media while accounting for viscosity-pressure dependence are nonlinear (e.g., the Barus model). This nonlinearity complicates mathematical analysis and makes numerical solutions more time-intensive and prone to convergence issues. In this paper, we demonstrate that the Hopf-Cole transformation, originally developed for Burgers' equation, can recast the governing equations -- describing flow through porous media with pressure-dependent viscosity -- into a linear form. The transformed equations, resembling Darcy's equations in the transformed variables, enable (a) systematic mathematical analysis to establish uniqueness and maximum principles, (b) the derivation of a mechanics-based principle, and (c) the development of efficient numerical solutions using solvers optimized for Darcy equations. Notably, many properties of the linear Darcy equations naturally extend to nonlinear models that depend on pressure. For example, solutions to these nonlinear models adhere to a reciprocal relation analogous to that observed in Darcy's equations.",
      "authors": [
        "V. S. Maduri and K. B. Nakshatrala"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T13:00:59+00:00",
          "link": "https://arxiv.org/abs/2504.21603v1",
          "size": "1317kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:48:25+00:00",
          "link": "https://arxiv.org/abs/2504.21603v2",
          "size": "1317kb",
          "version": "v2"
        }
      ],
      "title": "Flow Through Porous Media: A Hopf-Cole Transformation Approach for Modeling Pressure-Dependent Viscosity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21603",
        "HTML": "https://arxiv.org/html/2504.21603v2",
        "PDF": "https://arxiv.org/pdf/2504.21603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses modeling pressure-dependent viscosity in porous media using a mathematical transformation approach. It does not relate to LLM training data processing or involve any relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21706",
      "abstract": "Detecting plant diseases is a crucial aspect of modern agriculture, as it plays a key role in maintaining crop health and increasing overall yield. Traditional approaches, though still valuable, often rely on manual inspection or conventional machine learning techniques, both of which face limitations in scalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as a promising alternative, offering advantages such as improved handling of long-range dependencies and better scalability for visual tasks. This review explores the application of ViTs in precision agriculture, covering a range of tasks. We begin by introducing the foundational architecture of ViTs and discussing their transition from Natural Language Processing (NLP) to Computer Vision. The discussion includes the concept of inductive bias in traditional models like Convolutional Neural Networks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive review of recent literature, focusing on key methodologies, datasets, and performance metrics. This study also includes a comparative analysis of CNNs and ViTs, along with a review of hybrid models and performance enhancements. Technical challenges such as data requirements, computational demands, and model interpretability are addressed, along with potential solutions. Finally, we outline future research directions and technological advancements that could further support the integration of ViTs in real-world agricultural settings. Our goal with this study is to offer practitioners and researchers a deeper understanding of how ViTs are poised to transform smart and precision agriculture.",
      "authors": [
        "Saber Mehdipour",
        "Seyed Abolghasem Mirroshandel",
        "Seyed Amirhossein Tabatabaei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T14:50:02+00:00",
          "link": "https://arxiv.org/abs/2504.21706v1",
          "size": "3459kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T14:20:35+00:00",
          "link": "https://arxiv.org/abs/2504.21706v2",
          "size": "3459kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T12:57:18+00:00",
          "link": "https://arxiv.org/abs/2504.21706v3",
          "size": "3462kb",
          "version": "v3"
        }
      ],
      "title": "Vision Transformers in Precision Agriculture: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21706",
        "HTML": "https://arxiv.org/html/2504.21706v3",
        "PDF": "https://arxiv.org/pdf/2504.21706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey paper focuses on the application of Vision Transformers in precision agriculture. It does not address LLM training data processing or involve any relevant data engineering or dataset creation for language models."
      },
      "tasks": [
        "Inductive Bias",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.01969",
      "abstract": "3D Anomaly Detection (AD) is a promising means of controlling the quality of manufactured products. However, existing methods typically require carefully training a task-specific model for each category independently, leading to high cost, low efficiency, and weak generalization. Therefore, this paper presents a novel unified model for Multi-Category 3D Anomaly Detection (MC3D-AD) that aims to utilize both local and global geometry-aware information to reconstruct normal representations of all categories. First, to learn robust and generalized features of different categories, we propose an adaptive geometry-aware masked attention module that extracts geometry variation information to guide mask attention. Then, we introduce a local geometry-aware encoder reinforced by the improved mask attention to encode group-level feature tokens. Finally, we design a global query decoder that utilizes point cloud position embeddings to improve the decoding process and reconstruction ability. This leads to local and global geometry-aware reconstructed feature tokens for the AD task. MC3D-AD is evaluated on two publicly available Real3D-AD and Anomaly-ShapeNet datasets, and exhibits significant superiority over current state-of-the-art single-category methods, achieving 3.1\\% and 9.3\\% improvement in object-level AUROC over Real3D-AD and Anomaly-ShapeNet, respectively. The code is available at https://github.com/iCAN-SZU/MC3D-AD.",
      "authors": [
        "Jiayi Cheng",
        "Can Gao",
        "Jie Zhou",
        "Jiajun Wen",
        "Tao Dai",
        "Jinbao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T02:38:10+00:00",
          "link": "https://arxiv.org/abs/2505.01969v1",
          "size": "2466kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:03:56+00:00",
          "link": "https://arxiv.org/abs/2505.01969v2",
          "size": "2961kb",
          "version": "v2"
        }
      ],
      "title": "MC3D-AD: A Unified Geometry-aware Reconstruction Model for Multi-category 3D Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01969",
        "HTML": "https://arxiv.org/html/2505.01969v2",
        "PDF": "https://arxiv.org/pdf/2505.01969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a unified model for 3D anomaly detection, focusing on geometry-aware reconstruction. It does not involve any LLM training data processing or relevant data engineering tasks related to language models."
      },
      "tasks": [
        "3D Anomaly Detection",
        "Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02581",
      "abstract": "The AI alignment problem, which focusses on ensuring that artificial intelligence (AI), including AGI and ASI, systems act according to human values, presents profound challenges. With the progression from narrow AI to Artificial General Intelligence (AGI) and Superintelligence, fears about control and existential risk have escalated. Here, we investigate whether embracing inevitable AI misalignment can be a contingent strategy to foster a dynamic ecosystem of competing agents as a viable path to steer them in more human-aligned trends and mitigate risks. We explore how misalignment may serve and should be promoted as a counterbalancing mechanism to team up with whichever agents are most aligned to human interests, ensuring that no single system dominates destructively. The main premise of our contribution is that misalignment is inevitable because full AI-human alignment is a mathematical impossibility from Turing-complete systems, which we also offer as a proof in this contribution, a feature then inherited to AGI and ASI systems. We introduce a change-of-opinion attack test based on perturbation and intervention analysis to study how humans and agents may change or neutralise friendly and unfriendly AIs through cooperation and competition. We show that open models are more diverse and that most likely guardrails implemented in proprietary models are successful at controlling some of the agents' range of behaviour with positive and negative consequences while closed systems are more steerable and can also be used against proprietary AI systems. We also show that human and AI intervention has different effects hence suggesting multiple strategies.",
      "authors": [
        "Alberto Hern\\'andez-Espinosa",
        "Felipe S. Abrah\\~ao",
        "Olaf Witkowski",
        "Hector Zenil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T11:33:18+00:00",
          "link": "https://arxiv.org/abs/2505.02581v1",
          "size": "4017kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T03:02:00+00:00",
          "link": "https://arxiv.org/abs/2505.02581v2",
          "size": "8060kb",
          "version": "v2"
        },
        {
          "date": "2025-05-15T01:23:57+00:00",
          "link": "https://arxiv.org/abs/2505.02581v3",
          "size": "9401kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T01:12:59+00:00",
          "link": "https://arxiv.org/abs/2505.02581v4",
          "size": "3909kb",
          "version": "v4"
        }
      ],
      "title": "Neurodivergent Influenceability as a Contingent Solution to the AI Alignment Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02581",
        "HTML": "https://arxiv.org/html/2505.02581v4",
        "PDF": "https://arxiv.org/pdf/2505.02581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the AI alignment problem and discusses agent behaviors and human-AI interaction strategies. It does not relate to data processing for LLM training."
      },
      "tasks": [
        "Experimental Design",
        "Mathematical Proofs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05086",
      "abstract": "On-device learning has emerged as a promising direction for AI development, particularly because of its potential to reduce latency issues and mitigate privacy risks associated with device-server communication, while improving energy efficiency. Despite these advantages, significant memory and computational constraints still represent major challenges for its deployment. Drawing on previous studies on low-rank decomposition methods that address activation memory bottlenecks in backpropagation, we propose a novel shortcut approach as an alternative. Our analysis and experiments demonstrate that our method can reduce activation memory usage, even up to $120.09\\times$ compared to vanilla training, while also reducing overall training FLOPs up to $1.86\\times$ when evaluated on traditional benchmarks.",
      "authors": [
        "Le-Trung Nguyen",
        "Ael Quelennec",
        "Van-Tam Nguyen",
        "Enzo Tartaglione"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T09:34:15+00:00",
          "link": "https://arxiv.org/abs/2505.05086v1",
          "size": "2109kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:52:22+00:00",
          "link": "https://arxiv.org/abs/2505.05086v2",
          "size": "1459kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05086",
        "HTML": "https://arxiv.org/html/2505.05086v2",
        "PDF": "https://arxiv.org/pdf/2505.05086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses on-device learning and proposes a shortcut approach for efficient computation, unrelated to LLM training data processing activities."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.10072",
      "abstract": "The introduction of 3D Gaussian blendshapes has enabled the real-time reconstruction of animatable head avatars from monocular video. Toonify, a StyleGAN-based method, has become widely used for facial image stylization. To extend Toonify for synthesizing diverse stylized 3D head avatars using Gaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB. In Stage 1 (stylized video generation), we adopt an improved StyleGAN to generate the stylized video from the input video frames, which overcomes the limitation of cropping aligned faces at a fixed resolution as preprocessing for normal StyleGAN. This process provides a more stable stylized video, which enables Gaussian blendshapes to better capture the high-frequency details of the video frames, facilitating the synthesis of high-quality animations in the next stage. In Stage 2 (Gaussian blendshapes synthesis), our method learns a stylized neutral head model and a set of expression blendshapes from the generated stylized video. By combining the neutral head model with expression blendshapes, ToonifyGB can efficiently render stylized avatars with arbitrary expressions. We validate the effectiveness of ToonifyGB on benchmark datasets using two representative styles: Arcane and Pixar.",
      "authors": [
        "Rui-Yang Ju",
        "Sheng-Yen Huang",
        "Yi-Ping Hung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T08:16:12+00:00",
          "link": "https://arxiv.org/abs/2505.10072v1",
          "size": "21809kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:15:16+00:00",
          "link": "https://arxiv.org/abs/2505.10072v2",
          "size": "25210kb",
          "version": "v2"
        }
      ],
      "title": "ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10072",
        "HTML": "https://arxiv.org/html/2505.10072v2",
        "PDF": "https://arxiv.org/pdf/2505.10072"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for generating 3D stylized head avatars using StyleGAN and Gaussian blendshapes, which is not related to LLM training data processing."
      },
      "tasks": [
        "Image Stylization",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18444",
      "abstract": "Identifier names are crucial components of code, serving as primary clues for developers to understand program behavior. This paper investigates the linguistic structure of identifier names by extending the concept of grammar patterns, which represent the part-of-speech (PoS) sequences underlying identifier phrases. The specific focus is on closed syntactic categories (e.g., prepositions, conjunctions, determiners), which are rarely studied in software engineering despite their central role in general natural language. To study these categories, the Closed Category Identifier Dataset (CCID), a new manually annotated dataset of 1,275 identifiers drawn from 30 open-source systems, is constructed and presented. The relationship between closed-category grammar patterns and program behavior is then analyzed using grounded-theory-inspired coding, statistical, and pattern analysis. The results reveal recurring structures that developers use to express concepts such as control flow, data transformation, temporal reasoning, and other behavioral roles through naming. This work contributes an empirical foundation for understanding how linguistic resources encode behavior in identifier names and supports new directions for research in naming, program comprehension, and education.",
      "authors": [
        "Christian D. Newman",
        "Anthony Peruma",
        "Eman Abdullah AlOmar",
        "Mahie Crabbe",
        "Syreen Banabilah",
        "Reem S. AlSuhaibani",
        "Michael J. Decker",
        "Farhad Akhbardeh",
        "Marcos Zampieri",
        "Mohamed Wiem Mkaouer",
        "Jonathan I. Maletic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T00:58:50+00:00",
          "link": "https://arxiv.org/abs/2505.18444v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T14:56:01+00:00",
          "link": "https://arxiv.org/abs/2505.18444v2",
          "size": "318kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T17:26:28+00:00",
          "link": "https://arxiv.org/abs/2505.18444v3",
          "size": "318kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T15:44:52+00:00",
          "link": "https://arxiv.org/abs/2505.18444v4",
          "size": "318kb",
          "version": "v4"
        }
      ],
      "title": "On the Structure and Semantics of Identifier Names Containing Closed Syntactic Category Words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18444",
        "HTML": "https://arxiv.org/html/2505.18444v4",
        "PDF": "https://arxiv.org/pdf/2505.18444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the linguistic structure of identifier names in code, focusing on grammar patterns and semantics without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20043",
      "abstract": "High Speed multi-vehicle Autonomous Racing will increase the safety and performance of road-going Autonomous Vehicles. Precise vehicle detection and dynamics estimation from a moving platform is a key requirement for planning and executing complex autonomous overtaking maneuvers. To address this requirement, we have developed a Latency-Aware EKF-based Multi Target Tracking algorithm fusing LiDAR and RADAR measurements. The algorithm explots the different sensor characteristics by explicitly integrating the Range Rate in the EKF Measurement Function, as well as a-priori knowledge of the racetrack during state prediction. It can handle Out-Of-Sequence Measurements via Reprocessing using a double State and Measurement Buffer, ensuring sensor delay compensation with no information loss. This algorithm has been implemented on Team PoliMOVE's autonomous racecar, and was proved experimentally by completing a number of fully autonomous overtaking maneuvers at speeds up to 275 km/h.",
      "authors": [
        "Marcello Cellina",
        "Matteo Corno and Sergio Matteo Savaresi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T14:28:13+00:00",
          "link": "https://arxiv.org/abs/2505.20043v1",
          "size": "721kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T10:23:00+00:00",
          "link": "https://arxiv.org/abs/2505.20043v2",
          "size": "721kb",
          "version": "v2"
        }
      ],
      "title": "Target Tracking via LiDAR-RADAR Sensor Fusion for Autonomous Racing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20043",
        "HTML": "https://arxiv.org/html/2505.20043v2",
        "PDF": "https://arxiv.org/pdf/2505.20043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses sensor fusion for target tracking in autonomous racing, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20147",
      "abstract": "The rapid progress of large language models (LLMs) has catalyzed the emergence of multimodal large language models (MLLMs) that unify visual understanding and image generation within a single framework. However, most existing MLLMs rely on autoregressive (AR) architectures, which impose inherent limitations on future development, such as the raster-scan order in image generation and restricted reasoning abilities in causal context modeling. In this work, we challenge the dominance of AR-based approaches by introducing FUDOKI, a unified multimodal model purely based on discrete flow matching, as an alternative to conventional AR paradigms. By leveraging metric-induced probability paths with kinetic optimal velocities, our framework goes beyond the previous masking-based corruption process, enabling iterative refinement with self-correction capability and richer bidirectional context integration during generation. To mitigate the high cost of training from scratch, we initialize FUDOKI from pre-trained AR-based MLLMs and adaptively transition to the discrete flow matching paradigm. Experimental results show that FUDOKI achieves performance comparable to state-of-the-art AR-based MLLMs across both visual understanding and image generation tasks, highlighting its potential as a foundation for next-generation unified multimodal models. Furthermore, we show that applying test-time scaling techniques to FUDOKI yields significant performance gains, further underscoring its promise for future enhancement through reinforcement learning.",
      "authors": [
        "Jin Wang and Yao Lai and Aoxue Li and Shifeng Zhang and Jiacheng Sun and Ning Kang and Chengyue Wu and Zhenguo Li and Ping Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T15:46:53+00:00",
          "link": "https://arxiv.org/abs/2505.20147v1",
          "size": "7173kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T13:23:56+00:00",
          "link": "https://arxiv.org/abs/2505.20147v2",
          "size": "7173kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T05:31:36+00:00",
          "link": "https://arxiv.org/abs/2505.20147v3",
          "size": "7173kb",
          "version": "v3"
        }
      ],
      "title": "FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20147",
        "HTML": "https://arxiv.org/html/2505.20147v3",
        "PDF": "https://arxiv.org/pdf/2505.20147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development of a multimodal model called FUDOKI, which uses discrete flow matching for visual understanding and image generation, without addressing any aspects of LLM training data processing."
      },
      "models": [
        {
          "model_path": "LucasJinWang/FUDOKI",
          "downloads": "18",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/LucasJinWang/FUDOKI"
        }
      ],
      "tasks": [
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20230",
      "abstract": "In this paper, we present a static code analysis strategy to extract logical schemas from NoSQL applications. Our solution is based on a model-driven reverse engineering process composed of a chain of platform-independent model transformations. The extracted schema conforms to the U-Schema unified metamodel, which can represent both NoSQL and relational schemas. To support this process, we define a metamodel capable of representing the core elements of object-oriented languages. Application code is first injected into a code model, from which a control flow model is derived. This, in turn, enables the generation of a model representing both data access operations and the structure of stored data. From these models, the U-Schema logical schema is inferred. Additionally, the extracted information can be used to identify refactoring opportunities. We illustrate this capability through the detection of join-like query patterns and the automated application of field duplication strategies to eliminate expensive joins. All stages of the process are described in detail, and the approach is validated through a round-trip experiment in which a application using a MongoDB store is automatically generated from a predefined schema. The inferred schema is then compared to the original to assess the accuracy of the extraction process.",
      "authors": [
        "Carlos J. Fernandez-Candel",
        "Anthony Cleve",
        "Jesus J. Garc\\'ia-Molina"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T17:08:03+00:00",
          "link": "https://arxiv.org/abs/2505.20230v1",
          "size": "643kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:28:28+00:00",
          "link": "https://arxiv.org/abs/2505.20230v2",
          "size": "618kb",
          "version": "v2"
        }
      ],
      "title": "Towards the Automated Extraction and Refactoring of NoSQL Schemas from Application Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20230",
        "HTML": "https://arxiv.org/html/2505.20230v2",
        "PDF": "https://arxiv.org/pdf/2505.20230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a method for extracting and refactoring NoSQL schemas from application code, which does not relate to LLM training data processing or involve any steps related to dataset creation or improvement for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20268",
      "abstract": "Reinforcement learning with outcome-based feedback faces a fundamental challenge: when rewards are only observed at trajectory endpoints, how do we assign credit to the right actions? This paper provides the first comprehensive analysis of this problem in online RL with general function approximation. We develop a provably sample-efficient algorithm achieving $\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$ sample complexity, where $C_{\\rm cov}$ is the coverability coefficient of the underlying MDP. By leveraging general function approximation, our approach works effectively in large or infinite state spaces where tabular methods fail, requiring only that value functions and reward functions can be represented by appropriate function classes. Our results also characterize when outcome-based feedback is statistically separated from per-step rewards, revealing an unavoidable exponential separation for certain MDPs. For deterministic MDPs, we show how to eliminate the completeness assumption, dramatically simplifying the algorithm. We further extend our approach to preference-based feedback settings, proving that equivalent statistical efficiency can be achieved even under more limited information. Together, these results constitute a theoretical foundation for understanding the statistical properties of outcome-based reinforcement learning.",
      "authors": [
        "Fan Chen",
        "Zeyu Jia",
        "Alexander Rakhlin",
        "Tengyang Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T17:44:08+00:00",
          "link": "https://arxiv.org/abs/2505.20268v1",
          "size": "118kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:21:12+00:00",
          "link": "https://arxiv.org/abs/2505.20268v2",
          "size": "129kb",
          "version": "v2"
        }
      ],
      "title": "Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20268",
        "HTML": "https://arxiv.org/html/2505.20268v2",
        "PDF": "https://arxiv.org/pdf/2505.20268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates online reinforcement learning algorithms with outcome-based feedback, focusing on statistical efficiency and sample complexity in RL, without any discussion on language model training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20658",
      "abstract": "Temporal Logic (TL), especially Signal Temporal Logic (STL), enables precise formal specification, making it widely used in cyber-physical systems such as autonomous driving and robotics. Automatically transforming NL into STL is an attractive approach to overcome the limitations of manual transformation, which is time-consuming and error-prone. However, due to the lack of datasets, automatic transformation currently faces significant challenges and has not been fully explored. In this paper, we propose an NL-STL dataset named STL-Diversity-Enhanced (STL-DivEn), which comprises 16,000 samples enriched with diverse patterns. To develop the dataset, we first manually create a small-scale seed set of NL-STL pairs. Next, representative examples are identified through clustering and used to guide large language models (LLMs) in generating additional NL-STL pairs. Finally, diversity and accuracy are ensured through rigorous rule-based filters and human validation. Furthermore, we introduce the Knowledge-Guided STL Transformation (KGST) framework, a novel approach for transforming natural language into STL, involving a generate-then-refine process based on external knowledge. Statistical analysis shows that the STL-DivEn dataset exhibits more diversity than the existing NL-STL dataset. Moreover, both metric-based and human evaluations indicate that our KGST approach outperforms baseline models in transformation accuracy on STL-DivEn and DeepSTL datasets.",
      "authors": [
        "Yue Fang and Zhi Jin and Jie An and Hongshen Chen and Xiaohong Chen and Naijun Zhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T03:07:25+00:00",
          "link": "https://arxiv.org/abs/2505.20658v1",
          "size": "746kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:02:40+00:00",
          "link": "https://arxiv.org/abs/2505.20658v2",
          "size": "631kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20658",
        "HTML": "https://arxiv.org/html/2505.20658v2",
        "PDF": "https://arxiv.org/pdf/2505.20658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper contributes a new NL-STL dataset and discusses a framework for converting natural language to logic expressions using LLMs, its main emphasis is on transformation techniques rather than LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03170",
      "abstract": "The risk of misusing text-to-image generative models for malicious uses, especially due to the open-source development of such models, has become a serious concern. As a risk mitigation strategy, attributing generative models with neural fingerprinting is emerging as a popular technique. There has been a plethora of recent work that aim for addressing neural fingerprinting. A trade-off between the attribution accuracy and generation quality of such models has been studied extensively. None of the existing methods yet achieved 100% attribution accuracy. However, any model with less than cent percent accuracy is practically non-deployable. In this work, we propose an accurate method to incorporate neural fingerprinting for text-to-image diffusion models leveraging the concepts of cyclic error correcting codes from the literature of coding theory.",
      "authors": [
        "Murthy L",
        "Subarna Tripathi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T18:52:40+00:00",
          "link": "https://arxiv.org/abs/2506.03170v1",
          "size": "7306kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:41:23+00:00",
          "link": "https://arxiv.org/abs/2506.03170v2",
          "size": "7406kb",
          "version": "v2"
        }
      ],
      "title": "PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03170",
        "HTML": "https://arxiv.org/html/2506.03170v2",
        "PDF": "https://arxiv.org/pdf/2506.03170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses neural fingerprinting for text-to-image diffusion models, addressing attribution accuracy rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03586",
      "abstract": "This paper investigates a joint beamforming and resource allocation problem in downlink reconfigurable intelligent surface (RIS)-assisted orthogonal frequency division multiplexing (OFDM) systems to minimize the average delay, where data packets for each user arrive at the base station (BS) stochastically. The sequential optimization problem is inherently a Markov decision process (MDP), thus falling within the remit of reinforcement learning. To effectively handle the mixed action space and reduce the state space dimensionality, a hybrid deep reinforcement learning (DRL) approach is proposed. Specifically, proximal policy optimization (PPO)-Theta is employed to optimize the RIS phase shift design, while PPO-N is responsible for subcarrier allocation decisions. The active beamforming at the BS is then derived from the jointly optimized RIS phase shifts and subcarrier allocation decisions. To further mitigate the curse of dimensionality associated with subcarrier allocation, a multi-agent strategy is introduced to optimize the subcarrier allocation indicators more efficiently. Moreover, to achieve more adaptive resource allocation and accurately capture the network dynamics, key factors closely related to average delay, such as the number of backlogged packets in buffers and current packet arrivals, are incorporated into the state space. Furthermore, a transfer learning framework is introduced to enhance the training efficiency and accelerate convergence. Simulation results demonstrate that the proposed algorithm significantly reduces the average delay, enhances resource allocation efficiency, and achieves superior system robustness and fairness compared to baseline methods.",
      "authors": [
        "Yu Ma",
        "Xiao Li",
        "Chongtao Guo",
        "Le Liang",
        "Michail Matthaiou",
        "Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T05:33:33+00:00",
          "link": "https://arxiv.org/abs/2506.03586v1",
          "size": "478kb",
          "version": "v1"
        },
        {
          "date": "2025-06-08T10:30:04+00:00",
          "link": "https://arxiv.org/abs/2506.03586v2",
          "size": "727kb",
          "version": "v2"
        },
        {
          "date": "2025-06-12T12:58:58+00:00",
          "link": "https://arxiv.org/abs/2506.03586v3",
          "size": "727kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T12:56:07+00:00",
          "link": "https://arxiv.org/abs/2506.03586v4",
          "size": "781kb",
          "version": "v4"
        }
      ],
      "title": "Beamforming and Resource Allocation for Delay Minimization in RIS-Assisted OFDM Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03586",
        "HTML": "https://arxiv.org/html/2506.03586v4",
        "PDF": "https://arxiv.org/pdf/2506.03586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is about beamforming and resource allocation in RIS-assisted OFDM systems to minimize delay, unrelated to any LLM training data processing topics."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Fairness",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03590",
      "abstract": "Failure triage in design functional verification is critical but time-intensive, relying on manual specification reviews, log inspections, and waveform analyses. While machine learning (ML) has improved areas like stimulus generation and coverage closure, its application to RTL-level simulation failure triage, particularly for large designs, remains limited. VCDiag offers an efficient, adaptable approach using VCD data to classify failing waveforms and pinpoint likely failure locations. In the largest experiment, VCDiag achieves over 94% accuracy in identifying the top three most likely modules. The framework introduces a novel signal selection and statistical compression approach, achieving over 120x reduction in raw data size while preserving features essential for classification. It can also be integrated into diverse Verilog/SystemVerilog designs and testbenches.",
      "authors": [
        "Minh Luu",
        "Surya Jasper",
        "Khoi Le",
        "Evan Pan",
        "Michael Quinn",
        "Aakash Tyagi",
        "Jiang Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T05:44:03+00:00",
          "link": "https://arxiv.org/abs/2506.03590v1",
          "size": "1317kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T02:56:18+00:00",
          "link": "https://arxiv.org/abs/2506.03590v2",
          "size": "1317kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T06:09:00+00:00",
          "link": "https://arxiv.org/abs/2506.03590v3",
          "size": "1332kb",
          "version": "v3"
        }
      ],
      "title": "VCDiag: Classifying Erroneous Waveforms for Failure Triage Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03590",
        "HTML": "https://arxiv.org/html/2506.03590v3",
        "PDF": "https://arxiv.org/pdf/2506.03590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents VCDiag for classifying erroneous waveforms to accelerate failure triage in design functional verification, which does not relate to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03654",
      "abstract": "Real-time object detection is a fundamental but challenging task in computer vision, particularly when computational resources are limited. Although YOLO-series models have set strong benchmarks by balancing speed and accuracy, the increasing need for richer global context modeling has led to the use of Transformer-based architectures. Nevertheless, Transformers have high computational complexity because of their self-attention mechanism, which limits their practicality for real-time and edge deployments. To overcome these challenges, recent developments in linear state space models, such as Mamba, provide a promising alternative by enabling efficient sequence modeling with linear complexity. Building on this insight, we propose MambaNeXt-YOLO, a novel object detection framework that balances accuracy and efficiency through three key contributions: (1) MambaNeXt Block: a hybrid design that integrates CNNs with Mamba to effectively capture both local features and long-range dependencies; (2) Multi-branch Asymmetric Fusion Pyramid Network (MAFPN): an enhanced feature pyramid architecture that improves multi-scale object detection across various object sizes; and (3) Edge-focused Efficiency: our method achieved 66.6% mAP at 31.9 FPS on the PASCAL VOC dataset without any pre-training and supports deployment on edge devices such as the NVIDIA Jetson Xavier NX and Orin NX.",
      "authors": [
        "Xiaochun Lei",
        "Siqi Wu",
        "Weilin Wu",
        "Zetao Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T07:46:24+00:00",
          "link": "https://arxiv.org/abs/2506.03654v1",
          "size": "202kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T05:07:11+00:00",
          "link": "https://arxiv.org/abs/2506.03654v2",
          "size": "202kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T17:28:09+00:00",
          "link": "https://arxiv.org/abs/2506.03654v3",
          "size": "202kb",
          "version": "v3"
        }
      ],
      "title": "MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03654",
        "HTML": "https://arxiv.org/html/2506.03654v3",
        "PDF": "https://arxiv.org/pdf/2506.03654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a real-time object detection framework, MambaNeXt-YOLO, focusing on efficiency and accuracy in object detection rather than LLM training data processing."
      },
      "tasks": [
        "Mamba",
        "Novel Object Detection",
        "Object",
        "object-detection",
        "Object Detection",
        "Real-Time Object Detection",
        "State Space Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05249",
      "abstract": "Transformer models have emerged as fundamental tools across various scientific and engineering disciplines, owing to their outstanding performance in diverse applications. Despite this empirical success, the theoretical foundations of Transformers remain relatively underdeveloped, particularly in understanding their training dynamics. Existing research predominantly examines isolated components--such as self-attention mechanisms and feedforward networks--without thoroughly investigating the interdependencies between these components, especially when residual connections are present. In this paper, we aim to bridge this gap by analyzing the convergence behavior of a structurally complete yet single-layer Transformer, comprising self-attention, a feedforward network, and residual connections. We demonstrate that, under appropriate initialization, gradient descent exhibits a linear convergence rate, where the convergence speed is determined by the minimum and maximum singular values of the output matrix from the attention layer. Moreover, our analysis reveals that residual connections serve to ameliorate the ill-conditioning of this output matrix, an issue stemming from the low-rank structure imposed by the softmax operation, thereby promoting enhanced optimization stability. We also extend our theoretical findings to a multi-layer Transformer architecture, confirming the linear convergence rate of gradient descent under suitable initialization. Empirical results corroborate our theoretical insights, illustrating the beneficial role of residual connections in promoting convergence stability.",
      "authors": [
        "Zhen Qin and Jinxin Zhou and Zhihui Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T17:10:22+00:00",
          "link": "https://arxiv.org/abs/2506.05249v1",
          "size": "265kb",
          "version": "v1"
        },
        {
          "date": "2025-07-05T03:47:35+00:00",
          "link": "https://arxiv.org/abs/2506.05249v2",
          "size": "266kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T16:56:37+00:00",
          "link": "https://arxiv.org/abs/2506.05249v3",
          "size": "262kb",
          "version": "v3"
        }
      ],
      "title": "On the Convergence of Gradient Descent on Learning Transformers with Residual Connections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05249",
        "HTML": "https://arxiv.org/html/2506.05249v3",
        "PDF": "https://arxiv.org/pdf/2506.05249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the theoretical training dynamics of Transformer architectures, discussing gradient descent convergence without any mention of LLM data processing or dataset generation techniques."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.05606",
      "abstract": "Can large language models (LLMs) accurately simulate the next web action of a specific user? While LLMs have shown promising capabilities in generating ``believable'' human behaviors, evaluating their ability to mimic real user behaviors remains an open challenge, largely due to the lack of high-quality, publicly available datasets that capture both the observable actions and the internal reasoning of an actual human user. To address this gap, we introduce OPERA, a novel dataset of Observation, Persona, Rationale, and Action collected from real human participants during online shopping sessions. OPERA is the first public dataset that comprehensively captures: user personas, browser observations, fine-grained web actions, and self-reported just-in-time rationales. We developed both an online questionnaire and a custom browser plugin to gather this dataset with high fidelity. Using OPERA, we establish the first benchmark to evaluate how well current LLMs can predict a specific user's next action and rationale with a given persona and <observation, action, rationale> history. This dataset lays the groundwork for future research into LLM agents that aim to act as personalized digital twins for human.",
      "authors": [
        "Ziyi Wang",
        "Yuxuan Lu",
        "Wenbo Li",
        "Amirali Amini",
        "Bo Sun",
        "Yakov Bart",
        "Weimin Lyu",
        "Jiri Gesi",
        "Tian Wang",
        "Jing Huang",
        "Yu Su",
        "Upol Ehsan",
        "Malihe Alikhani",
        "Toby Jia-Jun Li",
        "Lydia Chilton",
        "Dakuo Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T21:37:49+00:00",
          "link": "https://arxiv.org/abs/2506.05606v1",
          "size": "1319kb",
          "version": "v1"
        },
        {
          "date": "2025-06-16T17:32:08+00:00",
          "link": "https://arxiv.org/abs/2506.05606v2",
          "size": "1319kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T17:44:47+00:00",
          "link": "https://arxiv.org/abs/2506.05606v3",
          "size": "1509kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T06:52:49+00:00",
          "link": "https://arxiv.org/abs/2506.05606v4",
          "size": "1713kb",
          "version": "v4"
        }
      ],
      "title": "OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05606",
        "HTML": "https://arxiv.org/html/2506.05606v4",
        "PDF": "https://arxiv.org/pdf/2506.05606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the OPERA dataset, specifically developed for evaluating LLMs' ability to simulate human online shopping behavior. It involves data collection and creation of a novel dataset, which is a core aspect of training data processing."
      },
      "datasets": [
        {
          "dataset_name": "NEU-HAI/OPeRA",
          "downloads": "419",
          "likes": "3",
          "link": "https://huggingface.co/datasets/NEU-HAI/OPeRA"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.06021",
      "abstract": "Multi-solid systems are foundational to a wide range of real-world applications, yet modeling their complex interactions remains challenging. Existing deep learning methods predominantly rely on implicit modeling, where the factors influencing solid deformation are not explicitly represented but are instead indirectly learned. However, as the number of solids increases, these methods struggle to accurately capture intricate physical interactions. In this paper, we introduce a novel explicit modeling paradigm that incorporates factors influencing solid deformation through structured modules. Specifically, we present Unisoma, a unified and flexible Transformer-based model capable of handling variable numbers of solids. Unisoma directly captures physical interactions using contact modules and adaptive interaction allocation mechanism, and learns the deformation through a triplet relationship. Compared to implicit modeling techniques, explicit modeling is more well-suited for multi-solid systems with diverse coupling patterns, as it enables detailed treatment of each solid while preventing information blending and confusion. Experimentally, Unisoma achieves consistent state-of-the-art performance across seven well-established datasets and two complex multi-solid tasks. Code is avaiable at https://github.com/therontau0054/Unisoma.",
      "authors": [
        "Shilong Tao",
        "Zhe Feng",
        "Haonan Sun",
        "Zhanxing Zhu",
        "Yunhuai Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T12:12:02+00:00",
          "link": "https://arxiv.org/abs/2506.06021v1",
          "size": "5630kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T02:14:16+00:00",
          "link": "https://arxiv.org/abs/2506.06021v2",
          "size": "5630kb",
          "version": "v2"
        }
      ],
      "title": "Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06021",
        "HTML": "https://arxiv.org/html/2506.06021v2",
        "PDF": "https://arxiv.org/pdf/2506.06021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the modeling of multi-solid systems using a Transformer-based approach, without any discussion on LLM training data processing, collection, or quality improvement methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.06874",
      "abstract": "There is growing interest in understanding how people interact with large language models (LLMs) and whether such models elicit dependency or even addictive behaviour. Validated tools to assess the extent to which individuals may become dependent on LLMs are scarce and primarily build on classic behavioral addiction symptoms, adapted to the context of LLM use. We view this as a conceptual limitation, as the LLM-human relationship is more nuanced and warrants a fresh and distinct perspective. To address this gap, we developed and validated a new 12-item questionnaire to measure LLM dependency, referred to as LLM-D12. The scale was based on the authors' prior theoretical work, with items developed accordingly and responses collected from 526 participants in the UK. Exploratory and confirmatory factor analyses, performed on separate halves of the total sample using a split-sample approach, supported a two-factor structure: Instrumental Dependency (six items) and Relationship Dependency (six items). Instrumental Dependency reflects the extent to which individuals rely on LLMs to support or collaborate in decision-making and cognitive tasks. Relationship Dependency captures the tendency to perceive LLMs as socially meaningful, sentient, or companion-like entities. The two-factor structure demonstrated excellent internal consistency and clear discriminant validity. External validation confirmed both the conceptual foundation and the distinction between the two subscales. The psychometric properties and structure of our LLM-D12 scale were interpreted in light of the emerging view that dependency on LLMs does not necessarily indicate dysfunction but may still reflect reliance levels that could become problematic in certain contexts.",
      "authors": [
        "Ala Yankouskaya",
        "Areej B. Babiker",
        "Syeda W. F. Rizvi",
        "Sameha Alshakhsi",
        "Magnus Liebherr",
        "Raian Ali"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T17:42:21+00:00",
          "link": "https://arxiv.org/abs/2506.06874v1",
          "size": "748kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T21:23:04+00:00",
          "link": "https://arxiv.org/abs/2506.06874v2",
          "size": "748kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:00:31+00:00",
          "link": "https://arxiv.org/abs/2506.06874v3",
          "size": "1046kb",
          "version": "v3"
        }
      ],
      "title": "LLM-D12: A Dual-Dimensional Scale of Instrumental and Relational Dependencies on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06874",
        "PDF": "https://arxiv.org/pdf/2506.06874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around measuring human dependency on LLMs through a newly developed questionnaire, lacking any contribution to the processing or creation of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.08418",
      "abstract": "The radio map represents the spatial distribution of spectrum resources within a region, supporting efficient resource allocation and interference mitigation. However, it is difficult to construct a dense radio map as a limited number of samples can be measured in practical scenarios. While existing works have used deep learning to estimate dense radio maps from sparse samples, they are hard to integrate with the physical characteristics of the radio map. To address this challenge, we cast radio map estimation as the sparse signal recovery problem. A physical propagation model is further incorporated to decompose the problem into multiple factor optimization sub-problems, thereby reducing recovery complexity. Inspired by the existing compressive sensing methods, we propose the Radio Deep Unfolding Network (RadioDUN) to unfold the optimization process, achieving adaptive parameter adjusting and prior fitting in a learnable manner. To account for the radio propagation characteristics, we develop a dynamic reweighting module (DRM) to adaptively model the importance of each factor for the radio map. Inspired by the shadowing factor in the physical propagation model, we integrate obstacle-related factors to express the obstacle-induced signal stochastic decay. The shadowing loss is further designed to constrain the factor prediction and act as a supplementary supervised objective, which enhances the performance of RadioDUN. Extensive experiments have been conducted to demonstrate that the proposed method outperforms the state-of-the-art methods. Our code will be made publicly available upon publication.",
      "authors": [
        "Taiqin Chen",
        "Zikun Zhou",
        "Zheng Fang",
        "Wenzhen Zou",
        "Kangjun Liu",
        "Ke Chen",
        "Yongbing Zhang",
        "Yaowei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T03:46:20+00:00",
          "link": "https://arxiv.org/abs/2506.08418v1",
          "size": "1556kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:41:43+00:00",
          "link": "https://arxiv.org/abs/2506.08418v2",
          "size": "1556kb",
          "version": "v2"
        }
      ],
      "title": "RadioDUN: A Physics-Inspired Deep Unfolding Network for Radio Map Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08418",
        "HTML": "https://arxiv.org/html/2506.08418v2",
        "PDF": "https://arxiv.org/pdf/2506.08418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work addresses radio map estimation using deep learning, with no relevance to LLM training data processing operations or dataset generation for language models."
      },
      "tasks": [
        "Compressive Sensing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09027",
      "abstract": "The development of diffusion-based generative models over the past decade has largely proceeded independently of progress in representation learning. These diffusion models typically rely on regression-based objectives and generally lack explicit regularization. In this work, we propose \\textit{Dispersive Loss}, a simple plug-and-play regularizer that effectively improves diffusion-based generative models. Our loss function encourages internal representations to disperse in the hidden space, analogous to contrastive self-supervised learning, with the key distinction that it requires no positive sample pairs and therefore does not interfere with the sampling process used for regression. Compared to the recent method of representation alignment (REPA), our approach is self-contained and minimalist, requiring no pre-training, no additional parameters, and no external data. We evaluate Dispersive Loss on the ImageNet dataset across a range of models and report consistent improvements over widely used and strong baselines. We hope our work will help bridge the gap between generative modeling and representation learning.",
      "authors": [
        "Runqian Wang",
        "Kaiming He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T17:53:29+00:00",
          "link": "https://arxiv.org/abs/2506.09027v1",
          "size": "11355kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:55:00+00:00",
          "link": "https://arxiv.org/abs/2506.09027v2",
          "size": "11355kb",
          "version": "v2"
        }
      ],
      "title": "Diffuse and Disperse: Image Generation with Representation Regularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09027",
        "HTML": "https://arxiv.org/html/2506.09027v2",
        "PDF": "https://arxiv.org/pdf/2506.09027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a regularizer for image generation models, which does not pertain to LLM training data processing, as it focuses on representation learning within diffusion models."
      },
      "tasks": [
        "Image Generation",
        "regression",
        "Representation Learning",
        "Self-Supervised Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10377",
      "abstract": "Markov decision processes (MDPs) are a popular model for decision-making in the presence of uncertainty. The conventional view of MDPs in verification treats them as state transformers with probabilities defined over sequences of states and with schedulers making random choices. An alternative view, especially well-suited for modeling dynamical systems, defines MDPs as distribution transformers with schedulers distributing probability masses. Our main contribution is a unified semantical framework that accommodates these two views and two new ones. These four semantics of MDPs arise naturally through identifying different sources of randomness in an MDP (namely schedulers, configurations, and transitions) and providing different ways of interpreting these probabilities (called the chance and mass interpretations). These semantics are systematically unified through a mathematical construct called chance-mass (CM) classifier. As another main contribution, we study a reachability problem in each of the two new semantics, demonstrating their hardness and providing two algorithms for solving them.",
      "authors": [
        "Yun Chen Tsai and Kittiphon Phalakarn and S. Akshay and Ichiro Hasuo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T06:05:38+00:00",
          "link": "https://arxiv.org/abs/2506.10377v1",
          "size": "695kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T12:26:19+00:00",
          "link": "https://arxiv.org/abs/2506.10377v2",
          "size": "621kb",
          "version": "v2"
        }
      ],
      "title": "Chance and Mass Interpretations of Probabilities in Markov Decision Processes (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10377",
        "PDF": "https://arxiv.org/pdf/2506.10377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on semantics in Markov decision processes, a concept unrelated to LLM training data processing. It does not address any aspects of data processing for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.11790",
      "abstract": "Evaluating feature attribution methods represents a critical challenge in explainable AI (XAI), as researchers typically rely on perturbation-based metrics when ground truth is unavailable. However, recent work reveals that these evaluation metrics can show different performance across predicted classes within the same dataset. These \"class-dependent evaluation effects\" raise questions about whether perturbation analysis reliably measures attribution quality, with direct implications for XAI method development and evaluation trustworthiness. We investigate under which conditions these class-dependent effects arise by conducting controlled experiments with synthetic time series data where ground truth feature locations are known. We systematically vary feature types and class contrasts across binary classification tasks, then compare perturbation-based degradation scores with ground truth-based precision-recall metrics using multiple attribution methods. Our experiments demonstrate that class-dependent effects emerge with both evaluation approaches, even in simple scenarios with temporally localized features, triggered by basic variations in feature amplitude or temporal extent between classes. Most critically, we find that perturbation-based and ground truth metrics frequently yield contradictory assessments of attribution quality across classes, with weak correlations between evaluation approaches. These findings suggest that researchers should interpret perturbation-based metrics with care, as they may not always align with whether attributions correctly identify discriminating features. By showing this disconnect, our work points toward reconsidering what attribution evaluation actually measures and developing more rigorous evaluation methods that capture multiple dimensions of attribution quality.",
      "authors": [
        "Gregor Baer",
        "Isel Grau",
        "Chao Zhang",
        "Pieter Van Gorp"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T13:52:32+00:00",
          "link": "https://arxiv.org/abs/2506.11790v1",
          "size": "130kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:17:21+00:00",
          "link": "https://arxiv.org/abs/2506.11790v2",
          "size": "127kb",
          "version": "v2"
        }
      ],
      "title": "Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11790",
        "HTML": "https://arxiv.org/html/2506.11790v2",
        "PDF": "https://arxiv.org/pdf/2506.11790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates evaluation methods for feature attributions in explainable AI, specifically in time series data. It does not focus on training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13695",
      "abstract": "Recommender systems have been widely used in various large-scale user-oriented platforms for many years. However, compared to the rapid developments in the AI community, recommendation systems have not achieved a breakthrough in recent years. For instance, they still rely on a multi-stage cascaded architecture rather than an end-to-end approach, leading to computational fragmentation and optimization inconsistencies, and hindering the effective application of key breakthrough technologies from the AI community in recommendation scenarios.\n  To address these issues, we propose OneRec, which reshapes the recommendation system through an end-to-end generative approach and achieves promising results. Firstly, we have enhanced the computational FLOPs of the current recommendation model by 10 $\\times$ and have identified the scaling laws for recommendations within certain boundaries. Secondly, reinforcement learning techniques, previously difficult to apply for optimizing recommendations, show significant potential in this framework. Lastly, through infrastructure optimizations, we have achieved 23.7% and 28.8% Model FLOPs Utilization (MFU) on flagship GPUs during training and inference, respectively, aligning closely with the LLM community. This architecture significantly reduces communication and storage overhead, resulting in operating expense that is only 10.6% of traditional recommendation pipelines. Deployed in Kuaishou/Kuaishou Lite APP, it handles 25% of total queries per second, enhancing overall App Stay Time by 0.54% and 1.24%, respectively. Additionally, we have observed significant increases in metrics such as 7-day Lifetime, which is a crucial indicator of recommendation experience. We also provide practical lessons and insights derived from developing, optimizing, and maintaining a production-scale recommendation system with significant real-world impact.",
      "authors": [
        "Guorui Zhou",
        "Jiaxin Deng",
        "Jinghao Zhang",
        "Kuo Cai",
        "Lejian Ren",
        "Qiang Luo",
        "Qianqian Wang",
        "Qigen Hu",
        "Rui Huang",
        "Shiyao Wang",
        "Weifeng Ding",
        "Wuchao Li",
        "Xinchen Luo",
        "Xingmei Wang",
        "Zexuan Cheng",
        "Zixing Zhang",
        "Bin Zhang",
        "Boxuan Wang",
        "Chaoyi Ma",
        "Chengru Song",
        "Chenhui Wang",
        "Di Wang",
        "Dongxue Meng",
        "Fan Yang",
        "Fangyu Zhang",
        "Feng Jiang",
        "Fuxing Zhang",
        "Gang Wang",
        "Guowang Zhang",
        "Han Li",
        "Hengrui Hu",
        "Hezheng Lin",
        "Hongtao Cheng",
        "Hongyang Cao",
        "Huanjie Wang",
        "Jiaming Huang",
        "Jiapeng Chen",
        "Jiaqiang Liu",
        "Jinghui Jia",
        "Kun Gai",
        "Lantao Hu",
        "Liang Zeng",
        "Liao Yu",
        "Qiang Wang",
        "Qidong Zhou",
        "Shengzhe Wang",
        "Shihui He",
        "Shuang Yang",
        "Shujie Yang",
        "Sui Huang",
        "Tao Wu",
        "Tiantian He",
        "Tingting Gao",
        "Wei Yuan",
        "Xiao Liang",
        "Xiaoxiao Xu",
        "Xugang Liu",
        "Yan Wang",
        "Yi Wang",
        "Yiwu Liu",
        "Yue Song",
        "Yufei Zhang",
        "Yunfan Wu",
        "Yunfeng Zhao",
        "Zhanyu Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T16:58:55+00:00",
          "link": "https://arxiv.org/abs/2506.13695v1",
          "size": "7193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T03:28:48+00:00",
          "link": "https://arxiv.org/abs/2506.13695v2",
          "size": "7288kb",
          "version": "v2"
        }
      ],
      "title": "OneRec Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13695",
        "HTML": "https://arxiv.org/html/2506.13695v2",
        "PDF": "https://arxiv.org/pdf/2506.13695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an end-to-end generative approach for recommendation systems, focusing on computational efficiency and reinforcement learning techniques. It does not address LLM training data processing."
      },
      "tasks": [
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14516",
      "abstract": "This paper presents the RMIT--ADM+S winning system in the SIGIR 2025 LiveRAG Challenge. Our Generation-Retrieval-Augmented Generation (G-RAG) approach generates a hypothetical answer that is used during the retrieval phase, alongside the original question. G-RAG also incorporates a pointwise large language model (LLM)-based re-ranking step prior to final answer generation. We describe the system architecture and the rationale behind our design choices. In particular, a systematic evaluation using the Grid of Points approach and N-way ANOVA enabled a controlled comparison of multiple configurations, including query variant generation, question decomposition, rank fusion strategies, and prompting techniques for answer generation. The submitted system achieved the highest Borda score based on the aggregation of Coverage, Relatedness, and Quality scores from manual evaluations, ranking first in the SIGIR 2025 LiveRAG Challenge.",
      "authors": [
        "Kun Ran",
        "Shuoqi Sun",
        "Khoi Nguyen Dinh Anh",
        "Damiano Spina and Oleg Zendel"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T13:41:12+00:00",
          "link": "https://arxiv.org/abs/2506.14516v1",
          "size": "108kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T21:41:29+00:00",
          "link": "https://arxiv.org/abs/2506.14516v2",
          "size": "135kb",
          "version": "v2"
        }
      ],
      "title": "RMIT-ADM+S at the SIGIR 2025 LiveRAG Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14516",
        "HTML": "https://arxiv.org/html/2506.14516v2",
        "PDF": "https://arxiv.org/pdf/2506.14516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a system for a retrieval-augmented generation challenge, primarily involving system architecture and ranking strategies rather than any aspect of LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "LiveRAG/Reports",
          "downloads": "348",
          "likes": "2",
          "link": "https://huggingface.co/datasets/LiveRAG/Reports"
        }
      ],
      "tasks": [
        "Answer Generation",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Re-Ranking",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/rmit-ir/GRAG-LiveRAG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15690",
      "abstract": "The increasing use of synthetic data from the public Internet has enhanced data usage efficiency in large language model (LLM) training. However, the potential threat of model collapse remains insufficiently explored. Existing studies primarily examine model collapse in a single model setting or rely solely on statistical surrogates. In this work, we introduce LLM Web Dynamics (LWD), an efficient framework for investigating model collapse at the network level. By simulating the Internet with a retrieval-augmented generation (RAG) database, we analyze the convergence pattern of model outputs. Furthermore, we provide theoretical guarantees for this convergence by drawing an analogy to interacting Gaussian Mixture Models.",
      "authors": [
        "Tianyu Wang",
        "Akira Horiguchi",
        "Lingyou Pang",
        "Carey E. Priebe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T22:10:52+00:00",
          "link": "https://arxiv.org/abs/2506.15690v1",
          "size": "373kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T02:09:58+00:00",
          "link": "https://arxiv.org/abs/2506.15690v2",
          "size": "364kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T05:08:02+00:00",
          "link": "https://arxiv.org/abs/2506.15690v3",
          "size": "387kb",
          "version": "v3"
        }
      ],
      "title": "LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15690",
        "HTML": "https://arxiv.org/html/2506.15690v3",
        "PDF": "https://arxiv.org/pdf/2506.15690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a framework to analyze potential collapse in LLM outputs using Internet-simulated data, it does not specifically address training data processing operations for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16297",
      "abstract": "Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods. This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover, unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
      "authors": [
        "Heng Zhang",
        "Zikang Wan",
        "Danilo Vasconcellos Vargas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T13:17:30+00:00",
          "link": "https://arxiv.org/abs/2506.16297v1",
          "size": "6539kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T04:07:21+00:00",
          "link": "https://arxiv.org/abs/2506.16297v2",
          "size": "6539kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T09:52:06+00:00",
          "link": "https://arxiv.org/abs/2506.16297v3",
          "size": "6539kb",
          "version": "v3"
        }
      ],
      "title": "SyncMapV2: Robust and Adaptive Unsupervised Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16297",
        "HTML": "https://arxiv.org/html/2506.16297v3",
        "PDF": "https://arxiv.org/pdf/2506.16297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SyncMapV2 is focused on unsupervised segmentation in visual data and robustness against noise and corruption. It does not pertain to any LLM training data processing activities."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.16383",
      "abstract": "Argument Mining (AM), a critical subfield of Natural Language Processing (NLP), focuses on extracting argumentative structures from text. The advent of Large Language Models (LLMs) has profoundly transformed AM, enabling advanced in-context learning, prompt-based generation, and robust cross-domain adaptability. This survey systematically synthesizes recent advancements in LLM-driven AM. We provide a concise review of foundational theories and annotation frameworks, alongside a meticulously curated catalog of datasets. A key contribution is our comprehensive taxonomy of AM subtasks, elucidating how contemporary LLM techniques -- such as prompting, chain-of-thought reasoning, and retrieval augmentation -- have reconfigured their execution. We further detail current LLM architectures and methodologies, critically assess evaluation practices, and delineate pivotal challenges including long-context reasoning, interpretability, and annotation bottlenecks. Conclusively, we highlight emerging trends and propose a forward-looking research agenda for LLM-based computational argumentation, aiming to strategically guide researchers in this rapidly evolving domain.",
      "authors": [
        "Hao Li",
        "Viktor Schlegel",
        "Yizheng Sun",
        "Riza Batista-Navarro",
        "Goran Nenadic"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T15:12:58+00:00",
          "link": "https://arxiv.org/abs/2506.16383v1",
          "size": "113kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:25:12+00:00",
          "link": "https://arxiv.org/abs/2506.16383v2",
          "size": "249kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T15:45:07+00:00",
          "link": "https://arxiv.org/abs/2506.16383v3",
          "size": "386kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T07:27:25+00:00",
          "link": "https://arxiv.org/abs/2506.16383v4",
          "size": "718kb",
          "version": "v4"
        }
      ],
      "title": "Large Language Models in Argument Mining: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16383",
        "HTML": "https://arxiv.org/html/2506.16383v4",
        "PDF": "https://arxiv.org/pdf/2506.16383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys advancements in Argument Mining (AM) using LLMs and mentions datasets; however, it focuses more on methods and challenges in AM rather than explicit contributions to LLM training data processing."
      },
      "tasks": [
        "Argument Mining",
        "In-Context Learning",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16685",
      "abstract": "We address key challenges in Dataset Aggregation (DAgger) for real-world contact-rich manipulation: how to collect informative human correction data and how to effectively update policies with this new data. We introduce Compliant Residual DAgger (CR-DAgger), which contains two novel components: 1) a Compliant Intervention Interface that leverages compliance control, allowing humans to provide gentle, accurate delta action corrections without interrupting the ongoing robot policy execution; and 2) a Compliant Residual Policy formulation that learns from human corrections while incorporating force feedback and force control. Our system significantly enhances performance on precise contact-rich manipulation tasks using minimal correction data, improving base policy success rates by over 50\\% on two challenging tasks (book flipping and belt assembly) while outperforming both retraining-from-scratch and finetuning approaches. Through extensive real-world experiments, we provide practical guidance for implementing effective DAgger in real-world robot learning tasks. Result videos are available at: https://compliant-residual-dagger.github.io/",
      "authors": [
        "Xiaomeng Xu",
        "Yifan Hou",
        "Zeyi Liu",
        "Shuran Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T01:57:47+00:00",
          "link": "https://arxiv.org/abs/2506.16685v1",
          "size": "13201kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:54:15+00:00",
          "link": "https://arxiv.org/abs/2506.16685v2",
          "size": "13036kb",
          "version": "v2"
        }
      ],
      "title": "Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16685",
        "HTML": "https://arxiv.org/html/2506.16685v2",
        "PDF": "https://arxiv.org/pdf/2506.16685"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses challenges in Dataset Aggregation for robot manipulation, specifically focusing on collecting human correction data and updating policies, with no relevance to LLM training data processing."
      },
      "tasks": [
        "Contact-rich Manipulation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17606",
      "abstract": "We present Full-body WPT, wireless power networking around the human body using a meandered textile coil. Unlike traditional inductive systems that emit strong fields into the deep tissue inside the body, the meander coil enables localized generation of strong magnetic field constrained to the skin surface, even when scaled to the size of the human body. Such localized inductive system enhances both safety and efficiency of wireless power around the body. Furthermore, the use of low-loss conductive yarn achieve energy-efficient and lightweight design. We analyze the performance of our design through simulations and experimental prototypes, demonstrating high power transfer efficiency and adaptability to user movement and posture. Our system provides a safe and efficient distributed power network using meandered textile coils integrated into wearable materials, highlighting the potential of body-centric wireless power networking as a foundational layer for ubiquitous health monitoring, augmented reality, and human-machine interaction systems.",
      "authors": [
        "Ryo Takahashi",
        "Takashi Sato",
        "Wakako Yukita",
        "Tomoyuki Yokota",
        "Takao Someya",
        "Yoshihiro Kawahara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T06:03:06+00:00",
          "link": "https://arxiv.org/abs/2506.17606v1",
          "size": "3535kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:15:08+00:00",
          "link": "https://arxiv.org/abs/2506.17606v2",
          "size": "7366kb",
          "version": "v2"
        }
      ],
      "title": "Full-body WPT: wireless powering with meandered e-textiles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17606",
        "HTML": "https://arxiv.org/html/2506.17606v2",
        "PDF": "https://arxiv.org/pdf/2506.17606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a wireless power networking system using e-textiles, unrelated to LLM training data processing as it focuses on hardware design and wireless power transfer technologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17798",
      "abstract": "The integration of open-source third-party library dependencies in Java development introduces significant security risks when these libraries contain known vulnerabilities. Existing Software Composition Analysis (SCA) tools struggle to effectively detect vulnerable API usage from these libraries due to limitations in understanding API usage semantics and computational challenges in analyzing complex codebases, leading to inaccurate vulnerability alerts that burden development teams and delay critical security fixes.\n  To address these challenges, we proposed SAVANT by leveraging two insights: proof-of-vulnerability test cases demonstrate how vulnerabilities can be triggered in specific contexts, and Large Language Models (LLMs) can understand code semantics. SAVANT combines semantic preprocessing with LLM-powered context analysis for accurate vulnerability detection. SAVANT first segments source code into meaningful blocks while preserving semantic relationships, then leverages LLM-based reflection to analyze API usage context and determine actual vulnerability impacts. Our evaluation on 55 real-world applications shows that SAVANT achieves 83.8% precision, 73.8% recall, 69.0% accuracy, and 78.5% F1-score, outperforming state-of-the-art SCA tools.",
      "authors": [
        "Wang Lingxiang",
        "Quanzhi Fu",
        "Wenjia Song",
        "Gelei Deng",
        "Yi Liu",
        "Dan Williams",
        "Ying Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T19:48:13+00:00",
          "link": "https://arxiv.org/abs/2506.17798v1",
          "size": "468kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T02:36:20+00:00",
          "link": "https://arxiv.org/abs/2506.17798v2",
          "size": "468kb",
          "version": "v2"
        }
      ],
      "title": "SAVANT: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17798",
        "HTML": "https://arxiv.org/html/2506.17798v2",
        "PDF": "https://arxiv.org/pdf/2506.17798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses SAVANT for vulnerability detection using LLMs to understand code semantics, but it is not related to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19733",
      "abstract": "Reinforcement post training (RPT) has recently shown promise in improving the reasoning abilities of large language models (LLMs). However, it remains unclear how well these improvements generalize to new domains, as prior work evaluates RPT models on data from the same domains used for fine-tuning. To understand the generalizability of RPT, we conduct two studies. (1) Observational: We compare a wide range of open-weight RPT models against their corresponding base models across multiple domains, including both seen and unseen domains in their fine-tuning data. (2) Interventional: we fine-tune LLMs with RPT on single domains and evaluate their performance across multiple domains. Both studies converge on the same conclusion that, although RPT brings substantial gains on tasks similar to the fine-tuning data, the gains generalize inconsistently and can vanish on domains with different reasoning patterns.",
      "authors": [
        "Chuxuan Hu",
        "Yuxuan Zhu",
        "Antony Kellermann",
        "Caleb Biddulph",
        "Suppakit Waiwitlikhit",
        "Jason Benn",
        "Daniel Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T15:53:10+00:00",
          "link": "https://arxiv.org/abs/2506.19733v1",
          "size": "358kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T23:12:20+00:00",
          "link": "https://arxiv.org/abs/2506.19733v2",
          "size": "355kb",
          "version": "v2"
        }
      ],
      "title": "Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19733",
        "HTML": "https://arxiv.org/html/2506.19733v2",
        "PDF": "https://arxiv.org/pdf/2506.19733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on evaluating the transferability of reinforcement post-training gains in LLMs to new domains, with no mention of processing or handling training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19780",
      "abstract": "Large language models (LLMs) demonstrate strong generalization across a wide range of language tasks, but often generate outputs that misalign with human preferences. Reinforcement Learning from Human Feedback (RLHF) addresses this by optimizing models toward human preferences using a learned reward function and reinforcement learning, yielding improved alignment but suffering from high computational cost and instability. Direct Preference Optimization (DPO) simplifies the process by treating alignment as a classification task over binary preference pairs, reducing training overhead while achieving competitive performance. However, it assumes fixed, single-dimensional preferences and only supports pairwise supervision.\n  To address these limitations, we propose Multi-Preference Lambda-weighted Listwise DPO, which allows the model to learn from more detailed human feedback and flexibly balance multiple goals such as helpfulness, honesty, and fluency. Our method models full-ranked preference distributions rather than binary comparisons, enabling more informative learning signals. The lambda vector controls the relative importance of different alignment goals, allowing the model to generalize across diverse human objectives. During inference, lambda can be adjusted without retraining, providing controllable alignment behavior for downstream use. We also introduce a learned scheduler that dynamically samples performant lambda configurations to improve robustness.\n  Notably, our method requires only 20GB of GPU memory for training, making it suitable for compute-constrained settings such as academic labs, educational tools, or on-device assistants. Experiments on 1B-2B scale models show that our method consistently outperforms standard DPO on alignment benchmarks while enabling efficient, controllable, and fine-grained adaptation suitable for real-world deployment.",
      "authors": [
        "Yuhui Sun (University of Alberta)",
        "Xiyao Wang (University of Toronto)",
        "Zixi Li (Zhejiang University)",
        "Zhenlong Yuan (Institute of Computing Technology",
        "Chinese Academy of Sciences)",
        "and Jinman Zhao (University of Toronto)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T16:47:17+00:00",
          "link": "https://arxiv.org/abs/2506.19780v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T17:28:25+00:00",
          "link": "https://arxiv.org/abs/2506.19780v2",
          "size": "27kb",
          "version": "v2"
        },
        {
          "date": "2025-07-05T19:14:28+00:00",
          "link": "https://arxiv.org/abs/2506.19780v3",
          "size": "306kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T18:17:04+00:00",
          "link": "https://arxiv.org/abs/2506.19780v4",
          "size": "506kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T15:23:54+00:00",
          "link": "https://arxiv.org/abs/2506.19780v5",
          "size": "2682kb",
          "version": "v5"
        }
      ],
      "title": "Multi-Preference Lambda-weighted Listwise DPO for Small-Scale Model Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19780",
        "HTML": "https://arxiv.org/html/2506.19780v5",
        "PDF": "https://arxiv.org/pdf/2506.19780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper addresses alignment fine-tuning using Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO), its main focus is on improving model alignment rather than training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21678",
      "abstract": "We investigate a property that extends the Danos-Regnier correctness criterion for linear logic proof-structures. The property applies to the correctness graphs of a proof-structure: it states that any such graph is acyclic and the number of its connected components is exactly one more than the number of nodes bottom or weakening. This is known to be necessary but not sufficient in multiplicative exponential linear logic (MELL) to recover a sequent calculus proof from a proof-structure. We present a geometric condition on untyped proof-structures allowing us to turn this necessary property into a sufficient one: we can thus isolate fragments of MELL for which this property is indeed a correctness criterion. In a suitable fragment of multiplicative linear logic with units, the criterion yields a characterization of the equivalence induced by permutations of rules in sequent calculus.",
      "authors": [
        "Raffaele Di Donna",
        "Lorenzo Tortora de Falco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:02:20+00:00",
          "link": "https://arxiv.org/abs/2506.21678v1",
          "size": "392kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:03:54+00:00",
          "link": "https://arxiv.org/abs/2506.21678v2",
          "size": "515kb",
          "version": "v2"
        }
      ],
      "title": "On the role of connectivity in Linear Logic proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21678",
        "PDF": "https://arxiv.org/pdf/2506.21678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses connectivity in linear logic proofs and extends a correctness criterion for logical proof structures. It has no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23276",
      "abstract": "As large language models (LLMs) are increasingly deployed as autonomous agents, understanding their cooperation and social mechanisms is becoming increasingly important. In particular, how LLMs balance self-interest and collective well-being is a critical challenge for ensuring alignment, robustness, and safe deployment. In this paper, we examine the challenge of costly sanctioning in multi-agent LLM systems, where an agent must decide whether to invest its own resources to incentivize cooperation or penalize defection. To study this, we adapt a public goods game with institutional choice from behavioral economics, allowing us to observe how different LLMs navigate social dilemmas over repeated interactions. Our analysis reveals four distinct behavioral patterns among models: some consistently establish and sustain high levels of cooperation, others fluctuate between engagement and disengagement, some gradually decline in cooperative behavior over time, and others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we find that reasoning LLMs, such as the o1 series, struggle significantly with cooperation, whereas some traditional LLMs consistently achieve high levels of cooperation. These findings suggest that the current approach to improving LLMs, which focuses on enhancing their reasoning capabilities, does not necessarily lead to cooperation, providing valuable insights for deploying LLM agents in environments that require sustained collaboration. Our code is available at https://github.com/davidguzmanp/SanctSim",
      "authors": [
        "David Guzman Piedrahita",
        "Yongjin Yang",
        "Mrinmaya Sachan",
        "Giorgia Ramponi",
        "Bernhard Sch\\\"olkopf",
        "Zhijing Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:02:47+00:00",
          "link": "https://arxiv.org/abs/2506.23276v1",
          "size": "200kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:13:24+00:00",
          "link": "https://arxiv.org/abs/2506.23276v2",
          "size": "245kb",
          "version": "v2"
        }
      ],
      "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23276",
        "PDF": "https://arxiv.org/pdf/2506.23276"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on understanding the social dynamics and cooperation strategies of LLMs in multi-agent systems, specifically in public goods games. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23825",
      "abstract": "Benefiting from the advances in large language models and cross-modal alignment, existing multimodal large language models have achieved prominent performance in image and short video understanding. However, the understanding of long videos is still challenging, as their long-context nature results in significant computational and memory overhead. Most existing work treats long videos in the same way as short videos, which is inefficient for real-world applications and hard to generalize to even longer videos. To address these issues, we propose Flash-VStream, an efficient video language model capable of processing extremely long videos and responding to user queries in real time. Particularly, we design a Flash Memory module, containing a low-capacity context memory to aggregate long-context temporal information and model the distribution of information density, and a high-capacity augmentation memory to retrieve detailed spatial information based on this distribution. Compared to existing models, Flash-VStream achieves significant reductions in inference latency. Extensive experiments on long video benchmarks and comprehensive video benchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate the state-of-the-art performance and outstanding efficiency of our method. Code is available at https://github.com/IVGSZ/Flash-VStream.",
      "authors": [
        "Haoji Zhang",
        "Yiqin Wang",
        "Yansong Tang",
        "Yong Liu",
        "Jiashi Feng",
        "Xiaojie Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:17:49+00:00",
          "link": "https://arxiv.org/abs/2506.23825v1",
          "size": "15074kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:25:10+00:00",
          "link": "https://arxiv.org/abs/2506.23825v2",
          "size": "15084kb",
          "version": "v2"
        }
      ],
      "title": "Flash-VStream: Efficient Real-Time Understanding for Long Video Streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23825",
        "HTML": "https://arxiv.org/html/2506.23825v2",
        "PDF": "https://arxiv.org/pdf/2506.23825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Flash-VStream for real-time understanding of long video streams using multimodal large language models. It does not discuss training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00566",
      "abstract": "Zero-shot skeleton-based action recognition aims to classify unseen skeleton-based human actions without prior exposure to such categories during training. This task is extremely challenging due to the difficulty in generalizing from known to unknown actions. Previous studies typically use two-stage training: pre-training skeleton encoders on seen action categories using cross-entropy loss and then aligning pre-extracted skeleton and text features, enabling knowledge transfer to unseen classes through skeleton-text alignment and language models' generalization. However, their efficacy is hindered by 1) insufficient discrimination for skeleton features, as the fixed skeleton encoder fails to capture necessary alignment information for effective skeleton-text alignment; 2) the neglect of alignment bias between skeleton and unseen text features during testing. To this end, we propose a prototype-guided feature alignment paradigm for zero-shot skeleton-based action recognition, termed PGFA. Specifically, we develop an end-to-end cross-modal contrastive training framework to improve skeleton-text alignment, ensuring sufficient discrimination for skeleton features. Additionally, we introduce a prototype-guided text feature alignment strategy to mitigate the adverse impact of the distribution discrepancy during testing. We provide a theoretical analysis to support our prototype-guided text feature alignment strategy and empirically evaluate our overall PGFA on three well-known datasets. Compared with the top competitor SMIE method, our PGFA achieves absolute accuracy improvements of 22.96%, 12.53%, and 18.54% on the NTU-60, NTU-120, and PKU-MMD datasets, respectively.",
      "authors": [
        "Kai Zhou",
        "Shuhai Zhang",
        "Zeng You",
        "Jinwu Hu",
        "Mingkui Tan and Fei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T08:34:35+00:00",
          "link": "https://arxiv.org/abs/2507.00566v1",
          "size": "7109kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:56:39+00:00",
          "link": "https://arxiv.org/abs/2507.00566v2",
          "size": "7109kb",
          "version": "v2"
        }
      ],
      "title": "Zero-Shot Skeleton-Based Action Recognition With Prototype-Guided Feature Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00566",
        "HTML": "https://arxiv.org/html/2507.00566v2",
        "PDF": "https://arxiv.org/pdf/2507.00566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is on zero-shot skeleton-based action recognition, focusing on alignment between skeleton and text features. It does not involve LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00698",
      "abstract": "As the core operator of Transformers, Softmax Attention exhibits excellent global modeling capabilities. However, its quadratic complexity limits its applicability to vision tasks. In contrast, Linear Attention shares a similar formulation with Softmax Attention while achieving linear complexity, enabling efficient global information modeling. Nevertheless, Linear Attention suffers from a significant performance degradation compared to standard Softmax Attention. In this paper, we analyze the underlying causes of this issue based on the formulation of Linear Attention. We find that, unlike Softmax Attention, Linear Attention entirely disregards the magnitude information of the Query. This prevents the attention score distribution from dynamically adapting as the Query scales. As a result, despite its structural similarity to Softmax Attention, Linear Attention exhibits a significantly different attention score distribution. Based on this observation, we propose Magnitude-Aware Linear Attention (MALA), which modifies the computation of Linear Attention to fully incorporate the Query's magnitude. This adjustment allows MALA to generate an attention score distribution that closely resembles Softmax Attention while exhibiting a more well-balanced structure. We evaluate the effectiveness of MALA on multiple tasks, including image classification, object detection, instance segmentation, semantic segmentation, natural language processing, speech recognition, and image generation. Our MALA achieves strong results on all of these tasks. Code will be available at https://github.com/qhfan/MALA",
      "authors": [
        "Qihang Fan",
        "Huaibo Huang",
        "Yuang Ai",
        "ran He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T11:49:05+00:00",
          "link": "https://arxiv.org/abs/2507.00698v1",
          "size": "1473kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:37:55+00:00",
          "link": "https://arxiv.org/abs/2507.00698v2",
          "size": "1473kb",
          "version": "v2"
        }
      ],
      "title": "Rectifying Magnitude Neglect in Linear Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00698",
        "HTML": "https://arxiv.org/html/2507.00698v2",
        "PDF": "https://arxiv.org/pdf/2507.00698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes Magnitude-Aware Linear Attention for improving attention mechanisms in Transformers. It does not relate to any data processing operations or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01884",
      "abstract": "Current lifelong person re-identification (LReID) methods predominantly rely on fully labeled data streams. However, in real-world scenarios where annotation resources are limited, a vast amount of unlabeled data coexists with scarce labeled samples, leading to the Semi-Supervised LReID (Semi-LReID) problem where LReID methods suffer severe performance degradation. Existing LReID methods, even when combined with semi-supervised strategies, suffer from limited long-term adaptation performance due to struggling with the noisy knowledge occurring during unlabeled data utilization. In this paper, we pioneer the investigation of Semi-LReID, introducing a novel Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation framework (SPRED). Our key innovation lies in establishing a self-reinforcing cycle between dynamic prototype-guided pseudo-label generation and new-old knowledge collaborative purification to enhance the utilization of unlabeled data. Specifically, learnable identity prototypes are introduced to dynamically capture the identity distributions and generate high-quality pseudo-labels. Then, the dual-knowledge cooperation scheme integrates current model specialization and historical model generalization, refining noisy pseudo-labels. Through this cyclic design, reliable pseudo-labels are progressively mined to improve current-stage learning and ensure positive knowledge propagation over long-term learning. Experiments on the established Semi-LReID benchmarks show that our SPRED achieves state-of-the-art performance. Our source code is available at https://github.com/zhoujiahuan1991/ICCV2025-SPRED",
      "authors": [
        "Kunlun Xu",
        "Fan Zhuo",
        "Jiangmeng Li",
        "Xu Zou",
        "Jiahuan Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T16:53:39+00:00",
          "link": "https://arxiv.org/abs/2507.01884v1",
          "size": "3543kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T02:26:33+00:00",
          "link": "https://arxiv.org/abs/2507.01884v2",
          "size": "3543kb",
          "version": "v2"
        }
      ],
      "title": "Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01884",
        "HTML": "https://arxiv.org/html/2507.01884v2",
        "PDF": "https://arxiv.org/pdf/2507.01884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a semi-supervised learning problem in person re-identification, focusing on prototype evolution and pseudo-label generation, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02976",
      "abstract": "Large Language Models (LLMs) and their agentic frameworks are increasingly adopted to automate software development tasks such as issue resolution and program repair. While prior work has identified security risks in LLM-generated code, most evaluations have focused on synthetic or isolated settings, leaving open questions about the security of these systems in real-world development contexts. In this study, we present the first large-scale security analysis of LLM-generated patches using 20,000+ issues from the SWE-bench dataset. We evaluate patches produced by a standalone LLM (Llama 3.3) and compare them to developer-written patches. We also assess the security of patches generated by three top-performing agentic frameworks (OpenHands, AutoCodeRover, HoneyComb) on a subset of our data. Finally, we analyze a wide range of code, issue, and project-level factors to understand the conditions under which LLMs and agents are most likely to generate insecure code. Our findings reveal that the standalone LLM introduces nearly 9x more new vulnerabilities than developers, with many of these exhibiting unique patterns not found in developers' code. Agentic workflows also generate a significant number of vulnerabilities, particularly when granting LLMs more autonomy, potentially increasing the likelihood of misinterpreting project context or task requirements. We find that vulnerabilities are more likely to occur in LLM patches associated with a higher number of files, more lines of generated code, and GitHub issues that lack specific code snippets or information about the expected code behavior and steps to reproduce. These results suggest that contextual factors play a critical role in the security of the generated code and point toward the need for proactive risk assessment methods that account for both code and issue-level information to complement existing vulnerability detection tools.",
      "authors": [
        "Amirali Sajadi",
        "Kostadin Damevski",
        "Preetha Chatterjee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T21:10:19+00:00",
          "link": "https://arxiv.org/abs/2507.02976v1",
          "size": "354kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:50:13+00:00",
          "link": "https://arxiv.org/abs/2507.02976v2",
          "size": "377kb",
          "version": "v2"
        }
      ],
      "title": "Are AI-Generated Fixes Secure? Analyzing LLM and Agent Patches on SWE-bench",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02976",
        "HTML": "https://arxiv.org/html/2507.02976v2",
        "PDF": "https://arxiv.org/pdf/2507.02976"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the security evaluation of AI-generated code patches, analyzing patches for vulnerabilities, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02987",
      "abstract": "Building generalizable medical AI systems requires pretraining strategies that are data-efficient and domain-aware. Unlike internet-scale corpora, clinical datasets such as MIMIC-CXR offer limited image counts and scarce annotations, but exhibit rich internal structure through multi-view imaging. We propose a self-supervised framework that leverages the inherent structure of medical datasets. Specifically, we treat paired chest X-rays (i.e., frontal and lateral views) as natural positive pairs, learning to reconstruct each view from sparse patches while aligning their latent embeddings. Our method requires no textual supervision and produces informative representations. Evaluated on MIMIC-CXR, we show strong performance compared to supervised objectives and baselines being trained without leveraging structure. This work provides a lightweight, modality-agnostic blueprint for domain-specific pretraining where data is structured but scarce",
      "authors": [
        "Andrea Agostini",
        "Sonia Laguna",
        "Alain Ryser",
        "Samuel Ruiperez-Campillo",
        "Moritz Vandenhirtz",
        "Nicolas Deperrois",
        "Farhad Nooralahzadeh",
        "Michael Krauthammer",
        "Thomas M. Sutter",
        "Julia E. Vogt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T11:14:45+00:00",
          "link": "https://arxiv.org/abs/2507.02987v1",
          "size": "3596kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:45:03+00:00",
          "link": "https://arxiv.org/abs/2507.02987v2",
          "size": "3596kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T12:44:31+00:00",
          "link": "https://arxiv.org/abs/2507.02987v3",
          "size": "3596kb",
          "version": "v3"
        }
      ],
      "title": "Leveraging the Structure of Medical Data for Improved Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02987",
        "HTML": "https://arxiv.org/html/2507.02987v3",
        "PDF": "https://arxiv.org/pdf/2507.02987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses pretraining strategies for medical data using self-supervised learning with multi-view imaging, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03737",
      "abstract": "3D Gaussian Splatting (3DGS) has become a popular solution in SLAM due to its high-fidelity and real-time novel view synthesis performance. However, some previous 3DGS SLAM methods employ a differentiable rendering pipeline for tracking, lack geometric priors in outdoor scenes. Other approaches introduce separate tracking modules, but they accumulate errors with significant camera movement, leading to scale drift. To address these challenges, we propose a robust RGB-only outdoor 3DGS SLAM method: S3PO-GS. Technically, we establish a self-consistent tracking module anchored in the 3DGS pointmap, which avoids cumulative scale drift and achieves more precise and robust tracking with fewer iterations. Additionally, we design a patch-based pointmap dynamic mapping module, which introduces geometric priors while avoiding scale ambiguity. This significantly enhances tracking accuracy and the quality of scene reconstruction, making it particularly suitable for complex outdoor environments. Our experiments on the Waymo, KITTI, and DL3DV datasets demonstrate that S3PO-GS achieves state-of-the-art results in novel view synthesis and outperforms other 3DGS SLAM methods in tracking accuracy. Project page: https://3dagentworld.github.io/S3PO-GS/.",
      "authors": [
        "Chong Cheng",
        "Sicheng Yu",
        "Zijian Wang",
        "Yifan Zhou",
        "Hao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T17:56:43+00:00",
          "link": "https://arxiv.org/abs/2507.03737v1",
          "size": "11034kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:21:11+00:00",
          "link": "https://arxiv.org/abs/2507.03737v2",
          "size": "11034kb",
          "version": "v2"
        }
      ],
      "title": "Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03737",
        "HTML": "https://arxiv.org/html/2507.03737v2",
        "PDF": "https://arxiv.org/pdf/2507.03737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a SLAM method for monocular outdoor environments focusing on novel view synthesis and geometric priors, not on LLM or its training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04599",
      "abstract": "Existing text-to-image models often rely on parameter fine-tuning techniques such as Low-Rank Adaptation (LoRA) to customize visual attributes. However, when combining multiple LoRA models for content-style fusion tasks, unstructured modifications of weight matrices often lead to undesired feature entanglement between content and style attributes. We propose QR-LoRA, a novel fine-tuning framework leveraging QR decomposition for structured parameter updates that effectively separate visual attributes. Our key insight is that the orthogonal Q matrix naturally minimizes interference between different visual features, while the upper triangular R matrix efficiently encodes attribute-specific transformations. Our approach fixes both Q and R matrices while only training an additional task-specific $\\Delta R$ matrix. This structured design reduces trainable parameters to half of conventional LoRA methods and supports effective merging of multiple adaptations without cross-contamination due to the strong disentanglement properties between $\\Delta R$ matrices. Experiments demonstrate that QR-LoRA achieves superior disentanglement in content-style fusion tasks, establishing a new paradigm for parameter-efficient, disentangled fine-tuning in generative models. The project page is available at: https://luna-ai-lab.github.io/QR-LoRA/.",
      "authors": [
        "Jiahui Yang",
        "Yongjia Ma",
        "Donglin Di",
        "Hao Li",
        "Wei Chen",
        "Yan Xie",
        "Jianxun Cui",
        "Xun Yang",
        "Wangmeng Zuo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T01:31:01+00:00",
          "link": "https://arxiv.org/abs/2507.04599v1",
          "size": "48420kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:12:08+00:00",
          "link": "https://arxiv.org/abs/2507.04599v2",
          "size": "48421kb",
          "version": "v2"
        }
      ],
      "title": "QR-LoRA: Efficient and Disentangled Fine-tuning via QR Decomposition for Customized Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04599",
        "HTML": "https://arxiv.org/html/2507.04599v2",
        "PDF": "https://arxiv.org/pdf/2507.04599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a novel fine-tuning framework leveraging QR decomposition in generative models. It relates to fine-tuning, but focuses on parameter efficiency and disentanglement rather than data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04600",
      "abstract": "Real-world time series typically exhibit complex temporal variations, making the time series classification task notably challenging. Recent advancements have demonstrated the potential of multi-scale analysis approaches, which provide an effective solution for capturing these complex temporal patterns. However, existing multi-scale analysis-based time series prediction methods fail to eliminate redundant scale-shared features across multi-scale time series, resulting in the model over- or under-focusing on scale-shared features. To address this issue, we propose a novel end-to-end Disentangled Multi-Scale framework for Time Series classification (DisMS-TS). The core idea of DisMS-TS is to eliminate redundant shared features in multi-scale time series, thereby improving prediction performance. Specifically, we propose a temporal disentanglement module to capture scale-shared and scale-specific temporal representations, respectively. Subsequently, to effectively learn both scale-shared and scale-specific temporal representations, we introduce two regularization terms that ensure the consistency of scale-shared representations and the disparity of scale-specific representations across all temporal scales. Extensive experiments conducted on multiple datasets validate the superiority of DisMS-TS over its competitive baselines, with the accuracy improvement up to 9.71%.",
      "authors": [
        "Zhipeng Liu",
        "Peibo Duan",
        "Binwu Wang",
        "Xuan Tang",
        "Qi Chu",
        "Changsheng Zhang",
        "Yongsheng Huang",
        "Bin Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T01:35:55+00:00",
          "link": "https://arxiv.org/abs/2507.04600v1",
          "size": "979kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:29:08+00:00",
          "link": "https://arxiv.org/abs/2507.04600v2",
          "size": "979kb",
          "version": "v2"
        }
      ],
      "title": "DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04600",
        "HTML": "https://arxiv.org/html/2507.04600v2",
        "PDF": "https://arxiv.org/pdf/2507.04600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving time series classification through a new framework for multi-scale analysis, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06174",
      "abstract": "In recent years, the advancement of imitation learning has led to increased interest in teleoperating low-cost manipulators to collect demonstration data. However, most existing systems rely on unilateral control, which only transmits target position values. While this approach is easy to implement and suitable for slow, non-contact tasks, it struggles with fast or contact-rich operations due to the absence of force feedback. This work demonstrates that fast teleoperation with force feedback is feasible even with force-sensorless, low-cost manipulators by leveraging 4-channel bilateral control. Based on accurately identified manipulator dynamics, our method integrates nonlinear terms compensation, velocity and external force estimation, and variable gain corresponding to inertial variation. Furthermore, using data collected by 4-channel bilateral control, we show that incorporating force information into both the input and output of learned policies improves performance in imitation learning. These results highlight the practical effectiveness of our system for high-fidelity teleoperation and data collection on affordable hardware.",
      "authors": [
        "Koki Yamane",
        "Yunhan Li",
        "Masashi Konosu",
        "Koki Inami",
        "Junji Oaki",
        "Sho Sakaino",
        "Toshiaki Tsuji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:54:34+00:00",
          "link": "https://arxiv.org/abs/2507.06174v1",
          "size": "16600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:53:31+00:00",
          "link": "https://arxiv.org/abs/2507.06174v2",
          "size": "16657kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T16:43:46+00:00",
          "link": "https://arxiv.org/abs/2507.06174v3",
          "size": "16665kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T00:20:11+00:00",
          "link": "https://arxiv.org/abs/2507.06174v4",
          "size": "16835kb",
          "version": "v4"
        },
        {
          "date": "2025-07-24T00:40:26+00:00",
          "link": "https://arxiv.org/abs/2507.06174v5",
          "size": "16835kb",
          "version": "v5"
        }
      ],
      "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06174",
        "HTML": "https://arxiv.org/html/2507.06174v5",
        "PDF": "https://arxiv.org/pdf/2507.06174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses bilateral teleoperation and imitation learning for manipulators, focusing on control systems and force feedback, without any relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06646",
      "abstract": "We evaluate the performance of four common learned models utilizing INR and VAE structures for compressing phase-only holograms in holographic displays. The evaluated models include a vanilla MLP, SIREN, and FilmSIREN, with TAESD as the representative VAE model. Our experiments reveal that a pretrained image VAE, TAESD, with 2.2M parameters struggles with phase-only hologram compression, revealing the need for task-specific adaptations. Among the INRs, SIREN with 4.9k parameters achieves %40 compression with high quality in the reconstructed 3D images (PSNR = 34.54 dB). These results emphasize the effectiveness of INRs and identify the limitations of pretrained image compression VAEs for hologram compression task.",
      "authors": [
        "Zicong Peng",
        "Yicheng Zhan",
        "Josef Spjut",
        "Kaan Ak\\c{s}it"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:19:44+00:00",
          "link": "https://arxiv.org/abs/2507.06646v1",
          "size": "4304kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:01:37+00:00",
          "link": "https://arxiv.org/abs/2507.06646v2",
          "size": "4304kb",
          "version": "v2"
        }
      ],
      "title": "Assessing Learned Models for Phase-only Hologram Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06646",
        "HTML": "https://arxiv.org/html/2507.06646v2",
        "PDF": "https://arxiv.org/pdf/2507.06646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses phase-only hologram compression using learned models, which does not pertain to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06735",
      "abstract": "Image fusion aims to integrate complementary information across modalities to generate high-quality fused images, thereby enhancing the performance of high-level vision tasks. While global spatial modeling mechanisms show promising results, constructing long-range feature dependencies in the spatial domain incurs substantial computational costs. Additionally, the absence of ground-truth exacerbates the difficulty of capturing complementary features effectively. To tackle these challenges, we propose a Residual Prior-driven Frequency-aware Network, termed as RPFNet. Specifically, RPFNet employs a dual-branch feature extraction framework: the Residual Prior Module (RPM) extracts modality-specific difference information from residual maps, thereby providing complementary priors for fusion; the Frequency Domain Fusion Module (FDFM) achieves efficient global feature modeling and integration through frequency-domain convolution. Additionally, the Cross Promotion Module (CPM) enhances the synergistic perception of local details and global structures through bidirectional feature interaction. During training, we incorporate an auxiliary decoder and saliency structure loss to strengthen the model's sensitivity to modality-specific differences. Furthermore, a combination of adaptive weight-based frequency contrastive loss and SSIM loss effectively constrains the solution space, facilitating the joint capture of local details and global features while ensuring the retention of complementary information. Extensive experiments validate the fusion performance of RPFNet, which effectively integrates discriminative features, enhances texture details and salient objects, and can effectively facilitate the deployment of the high-level vision task.",
      "authors": [
        "Guan Zheng",
        "Xue Wang",
        "Wenhua Qian",
        "Peng Liu",
        "Runzhuo Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:48:00+00:00",
          "link": "https://arxiv.org/abs/2507.06735v1",
          "size": "6645kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:57:08+00:00",
          "link": "https://arxiv.org/abs/2507.06735v2",
          "size": "6642kb",
          "version": "v2"
        }
      ],
      "title": "Residual Prior-driven Frequency-aware Network for Image Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06735",
        "HTML": "https://arxiv.org/html/2507.06735v2",
        "PDF": "https://arxiv.org/pdf/2507.06735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a frequency-aware network for image fusion, focusing on integrating complementary image information, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07464",
      "abstract": "With the increasing deployment of intelligent CCTV systems in outdoor environments, there is a growing demand for face recognition systems optimized for challenging weather conditions. Adverse weather significantly degrades image quality, which in turn reduces recognition accuracy. Although recent face image restoration (FIR) models based on generative adversarial networks (GANs) and diffusion models have shown progress, their performance remains limited due to the lack of dedicated modules that explicitly address weather-induced degradations. This leads to distorted facial textures and structures. To address these limitations, we propose a novel GAN-based blind FIR framework that integrates two key components: local Statistical Facial Feature Transformation (SFFT) and Degradation-Agnostic Feature Embedding (DAFE). The local SFFT module enhances facial structure and color fidelity by aligning the local statistical distributions of low-quality (LQ) facial regions with those of high-quality (HQ) counterparts. Complementarily, the DAFE module enables robust statistical facial feature extraction under adverse weather conditions by aligning LQ and HQ encoder representations, thereby making the restoration process adaptive to severe weather-induced degradations. Experimental results demonstrate that the proposed degradation-agnostic SFFT model outperforms existing state-of-the-art FIR methods based on GAN and diffusion models, particularly in suppressing texture distortions and accurately reconstructing facial structures. Furthermore, both the SFFT and DAFE modules are empirically validated in enhancing structural fidelity and perceptual quality in face restoration under challenging weather scenarios.",
      "authors": [
        "Chang-Hwan Son"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:31:26+00:00",
          "link": "https://arxiv.org/abs/2507.07464v1",
          "size": "15947kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T12:13:12+00:00",
          "link": "https://arxiv.org/abs/2507.07464v2",
          "size": "2256kb",
          "version": "v2"
        }
      ],
      "title": "Degradation-Agnostic Statistical Facial Feature Transformation for Blind Face Restoration in Adverse Weather Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07464",
        "PDF": "https://arxiv.org/pdf/2507.07464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on degradation-agnostic face restoration for adverse weather conditions, which is not related to processing data for training large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07620",
      "abstract": "Reliable Uncertainty Quantification (UQ) and failure prediction remain open challenges for Vision-Language Models (VLMs). We introduce ViLU, a new Vision-Language Uncertainty quantification framework that contextualizes uncertainty estimates by leveraging all task-relevant textual representations. ViLU constructs an uncertainty-aware multi-modal representation by integrating the visual embedding, the predicted textual embedding, and an image-conditioned textual representation via cross-attention. Unlike traditional UQ methods based on loss prediction, ViLU trains an uncertainty predictor as a binary classifier to distinguish correct from incorrect predictions using a weighted binary cross-entropy loss, making it loss-agnostic. In particular, our proposed approach is well-suited for post-hoc settings, where only vision and text embeddings are available without direct access to the model itself. Extensive experiments on diverse datasets show the significant gains of our method compared to state-of-the-art failure prediction methods. We apply our method to standard classification datasets, such as ImageNet-1k, as well as large-scale image-caption datasets like CC12M and LAION-400M. Ablation studies highlight the critical role of our architecture and training in achieving effective uncertainty quantification. Our code is publicly available and can be found here: https://github.com/ykrmm/ViLU.",
      "authors": [
        "Marc Lafon",
        "Yannis Karmim",
        "Julio Silva-Rodr\\'iguez",
        "Paul Couairon",
        "Cl\\'ement Rambour",
        "Rapha\\\"el Fournier-Sniehotta",
        "Ismail Ben Ayed",
        "Jose Dolz",
        "Nicolas Thome"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:41:13+00:00",
          "link": "https://arxiv.org/abs/2507.07620v1",
          "size": "16787kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:41:56+00:00",
          "link": "https://arxiv.org/abs/2507.07620v2",
          "size": "16788kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T09:03:07+00:00",
          "link": "https://arxiv.org/abs/2507.07620v3",
          "size": "16789kb",
          "version": "v3"
        }
      ],
      "title": "ViLU: Learning Vision-Language Uncertainties for Failure Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07620",
        "HTML": "https://arxiv.org/html/2507.07620v3",
        "PDF": "https://arxiv.org/pdf/2507.07620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on uncertainty quantification and failure prediction in Vision-Language Models, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07769",
      "abstract": "Recent years have seen significant advancements in designing reinforcement learning (RL)-based agents for building energy management. While individual success is observed in simulated or controlled environments, the scalability of RL approaches in terms of efficiency and generalization across building dynamics and operational scenarios remains an open question. In this work, we formally characterize the generalization space for the cross-environment, multi-objective building energy management task, and formulate the multi-objective contextual RL problem. Such a formulation helps understand the challenges of transferring learned policies across varied operational contexts such as climate and heat convection dynamics under multiple control objectives such as comfort level and energy consumption. We provide a principled way to parameterize such contextual information in realistic building RL environments, and construct a novel benchmark to facilitate the evaluation of generalizable RL algorithms in practical building control tasks. Our results show that existing multi-objective RL methods are capable of achieving reasonable trade-offs between conflicting objectives. However, their performance degrades under certain environment variations, underscoring the importance of incorporating dynamics-dependent contextual information into the policy learning process.",
      "authors": [
        "Ruohong Liu",
        "Jack Umenberger",
        "Yize Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:54:38+00:00",
          "link": "https://arxiv.org/abs/2507.07769v1",
          "size": "631kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T10:44:28+00:00",
          "link": "https://arxiv.org/abs/2507.07769v2",
          "size": "628kb",
          "version": "v2"
        }
      ],
      "title": "BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07769",
        "HTML": "https://arxiv.org/html/2507.07769v2",
        "PDF": "https://arxiv.org/pdf/2507.07769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses reinforcement learning for building energy management and generalization across environments, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07893",
      "abstract": "Legal dispute analysis is crucial for intelligent legal assistance systems. However, current LLMs face significant challenges in understanding complex legal concepts, maintaining reasoning consistency, and accurately citing legal sources. This research presents a framework combining prompt engineering with multidimensional knowledge graphs to improve LLMs' legal dispute analysis. Specifically, the framework includes a three-stage hierarchical prompt structure (task definition, knowledge background, reasoning guidance) along with a three-layer knowledge graph (legal ontology, representation, instance layers). Additionally, four supporting methods enable precise legal concept retrieval: direct code matching, semantic vector similarity, ontology path reasoning, and lexical segmentation. Through extensive testing, results show major improvements: sensitivity increased by 9.9%-13.8%, specificity by 4.8%-6.7%, and citation accuracy by 22.4%-39.7%. As a result, the framework provides better legal analysis and understanding of judicial logic, thus offering a new technical method for intelligent legal assistance systems.",
      "authors": [
        "Mingda Zhang",
        "Na Zhao",
        "Jianglong Qing",
        "Qing xu",
        "Kaiwen Pan",
        "Ting luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:22:41+00:00",
          "link": "https://arxiv.org/abs/2507.07893v1",
          "size": "2555kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T14:41:16+00:00",
          "link": "https://arxiv.org/abs/2507.07893v2",
          "size": "2559kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T13:52:51+00:00",
          "link": "https://arxiv.org/abs/2507.07893v3",
          "size": "2560kb",
          "version": "v3"
        }
      ],
      "title": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07893",
        "HTML": "https://arxiv.org/html/2507.07893v3",
        "PDF": "https://arxiv.org/pdf/2507.07893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a framework combining prompt engineering and knowledge graphs for legal dispute analysis. While it involves LLMs, it mainly focuses on legal reasoning and not on LLM training data processing per se."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07966",
      "abstract": "We introduce a full-stack framework that scales up reasoning in vision-language models (VLMs) to long videos, leveraging reinforcement learning. We address the unique challenges of long video reasoning by integrating three critical components: (1) a large-scale dataset, LongVideo-Reason, comprising 104K long video QA pairs with high-quality reasoning annotations across diverse domains such as sports, games, and vlogs; (2) a two-stage training pipeline that extends VLMs with chain-of-thought supervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a training infrastructure for long video RL, named Multi-modal Reinforcement Sequence Parallelism (MR-SP), which incorporates sequence parallelism and a vLLM-based engine tailored for long video, using cached video embeddings for efficient rollout and prefilling. In our experiments, LongVILA-R1-7B achieves strong performance on video benchmarks, reaching 65.0% and 70.7% accuracy on VideoMME without and with subtitles, respectively, and consistently outperforming LongVILA-R1 across multiple benchmarks. Moreover, LongVILA-R1 shows steady performance improvements as the number of input video frames increases. Notably, our MR-SP system achieves up to 2.1x speedup on long video RL training. In addition, we release our training system for public availability that supports RL training on various modalities (video, text, and audio), various models (VILA and Qwen series), and even image and video generation models. On a single A100 node (8 GPUs), it supports RL training on hour-long videos (e.g., 3,600 frames / around 256k tokens).",
      "authors": [
        "Yukang Chen",
        "Wei Huang",
        "Baifeng Shi",
        "Qinghao Hu",
        "Hanrong Ye",
        "Ligeng Zhu",
        "Zhijian Liu",
        "Pavlo Molchanov",
        "Jan Kautz",
        "Xiaojuan Qi",
        "Sifei Liu",
        "Hongxu Yin",
        "Yao Lu",
        "Song Han"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:47:40+00:00",
          "link": "https://arxiv.org/abs/2507.07966v1",
          "size": "4929kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:20:41+00:00",
          "link": "https://arxiv.org/abs/2507.07966v2",
          "size": "5162kb",
          "version": "v2"
        }
      ],
      "title": "Scaling RL to Long Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07966",
        "HTML": "https://arxiv.org/html/2507.07966v2",
        "PDF": "https://arxiv.org/pdf/2507.07966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper presents a scaled-up VLM framework for long videos using reinforcement learning and mentions a large-scale dataset, but does not primarily focus on training data processing improvements in LLMs."
      },
      "models": [
        {
          "model_path": "Efficient-Large-Model/LongVILA-R1-7B",
          "downloads": "0",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Efficient-Large-Model/LongVILA-R1-7B"
        },
        {
          "model_path": "Perflow-Shuai/NVILA-Lite-8B-hf-preview-verl-cold-model",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Perflow-Shuai/NVILA-Lite-8B-hf-preview-verl-cold-model"
        }
      ],
      "datasets": [
        {
          "dataset_name": "LongVideo-Reason/longvideo-reason",
          "downloads": "412",
          "likes": "1",
          "link": "https://huggingface.co/datasets/LongVideo-Reason/longvideo-reason"
        },
        {
          "dataset_name": "LongVideo-Reason/longvideo_eval_videos",
          "downloads": "735",
          "likes": "0",
          "link": "https://huggingface.co/datasets/LongVideo-Reason/longvideo_eval_videos"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08017",
      "abstract": "Recent findings in mechanistic interpretability (MI), the field probing the inner workings of Large Language Models (LLMs), challenge the view that these models rely solely on superficial statistics. We offer an accessible synthesis of these findings that doubles as an introduction to MI while integrating these findings within a novel theoretical framework for thinking about machine understanding. We argue that LLMs develop internal structures that are functionally analogous to the kind of understanding that consists in seeing connections. To sharpen this idea, we propose a three-tiered conception of understanding. First, conceptual understanding emerges when a model forms \"features\" as directions in latent space, learning the connections between diverse manifestations of something. Second, state-of-the-world understanding emerges when a model learns contingent factual connections between features and dynamically tracks changes in the world. Third, principled understanding emerges when a model ceases to rely on a collection of memorized facts and discovers a \"circuit\" connecting these facts. However, these forms of understanding remain radically different from human understanding, as the phenomenon of \"parallel mechanisms\" shows. We conclude that the debate should move beyond the yes-or-no question of whether LLMs understand to investigate how their strange minds work and forge conceptions that fit them.",
      "authors": [
        "Pierre Beckmann and Matthieu Queloz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:26:31+00:00",
          "link": "https://arxiv.org/abs/2507.08017v1",
          "size": "427kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T11:46:41+00:00",
          "link": "https://arxiv.org/abs/2507.08017v2",
          "size": "417kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T12:23:53+00:00",
          "link": "https://arxiv.org/abs/2507.08017v3",
          "size": "417kb",
          "version": "v3"
        }
      ],
      "title": "Mechanistic Indicators of Understanding in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08017",
        "PDF": "https://arxiv.org/pdf/2507.08017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores mechanistic interpretability in LLMs, focusing on internal structures and machine understanding, but it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08513",
      "abstract": "Multimodal Large Language Models (MLLMs) struggle with accurately capturing camera-object relations, especially for object orientation, camera viewpoint, and camera shots. This stems from the fact that existing MLLMs are trained on images with limited diverse camera-object relations and corresponding textual descriptions. To address this, we propose a synthetic generation pipeline to create large-scale 3D visual instruction datasets. Our framework takes 3D assets as input and uses rendering and diffusion-based image generation models to create photorealistic images preserving precise camera-object relations. Additionally, large language models (LLMs) are used to generate text prompts for guiding visual instruction tuning and controlling image generation. We create Ultimate3D, a dataset of 240K VQAs with precise camera-object annotations, and corresponding benchmark. MLLMs fine-tuned on our proposed dataset outperform commercial models by a large margin, achieving an average accuracy improvement of 33.4% on camera-object relation recognition tasks. Our code, dataset, and benchmark will contribute to broad MLLM applications.",
      "authors": [
        "Liu He",
        "Xiao Zeng",
        "Yizhi Song",
        "Albert Y. C. Chen",
        "Lu Xia",
        "Shashwat Verma",
        "Sankalp Dayal",
        "Min Sun",
        "Cheng-Hao Kuo",
        "Daniel Aliaga"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:00:10+00:00",
          "link": "https://arxiv.org/abs/2507.08513v1",
          "size": "45607kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T22:34:55+00:00",
          "link": "https://arxiv.org/abs/2507.08513v2",
          "size": "45607kb",
          "version": "v2"
        }
      ],
      "title": "Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08513",
        "HTML": "https://arxiv.org/html/2507.08513v2",
        "PDF": "https://arxiv.org/pdf/2507.08513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a synthetic generation pipeline to create large-scale 3D visual instruction datasets for multimodal LLMs. This involves dataset creation and generation, contributing directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08621",
      "abstract": "Argument mining (AM) is an interdisciplinary research field that integrates insights from logic, philosophy, linguistics, rhetoric, law, psychology, and computer science. It involves the automatic identification and extraction of argumentative components, such as premises and claims, and the detection of relationships between them, such as support, attack, or neutrality. Recently, the field has advanced significantly, especially with the advent of large language models (LLMs), which have enhanced the efficiency of analyzing and extracting argument semantics compared to traditional methods and other deep learning models. There are many benchmarks for testing and verifying the quality of LLM, but there is still a lack of research and results on the operation of these models in publicly available argument classification databases. This paper presents a study of a selection of LLM's, using diverse datasets such as Args.me and UKP. The models tested include versions of GPT, Llama, and DeepSeek, along with reasoning-enhanced variants incorporating the Chain-of-Thoughts algorithm. The results indicate that ChatGPT-4o outperforms the others in the argument classification benchmarks. In case of models incorporated with reasoning capabilities, the Deepseek-R1 shows its superiority. However, despite their superiority, GPT-4o and Deepseek-R1 still make errors. The most common errors are discussed for all models. To our knowledge, the presented work is the first broader analysis of the mentioned datasets using LLM and prompt algorithms. The work also shows some weaknesses of known prompt algorithms in argument analysis, while indicating directions for their improvement. The added value of the work is the in-depth analysis of the available argument datasets and the demonstration of their shortcomings.",
      "authors": [
        "Marcin Pietro\\'n",
        "Rafa{\\l} Olszowski",
        "Jakub Gomu{\\l}ka",
        "Filip Gampel",
        "Andrzej Tomski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:23:40+00:00",
          "link": "https://arxiv.org/abs/2507.08621v1",
          "size": "1747kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:49:06+00:00",
          "link": "https://arxiv.org/abs/2507.08621v2",
          "size": "1792kb",
          "version": "v2"
        }
      ],
      "title": "A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08621",
        "HTML": "https://arxiv.org/html/2507.08621v2",
        "PDF": "https://arxiv.org/pdf/2507.08621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper's focus is on LLM-based argument classification evaluation, using existing datasets and analyzing their shortcomings, but it does not directly contribute to training data processing or creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09186",
      "abstract": "We introduce OpenCAMS (Open-Source Connected and Automated Mobility Co-Simulation Platform), an open-source, synchronized, and extensible co-simulation framework that tightly couples three best-in-class simulation tools: (i) SUMO, (ii) CARLA, and (iii) OMNeT++. OpenCAMS is designed to support advanced research in transportation safety, mobility, and cybersecurity by combining the strengths of each simulation domain. Specifically, SUMO provides large-scale, microscopic traffic modeling; CARLA offers high-fidelity 3D perception, vehicle dynamics, and control simulation; and OMNeT++ enables modular, event-driven network communication, such as cellular vehicle-to-everything (C-V2X). OpenCAMS employs a time-synchronized, bidirectional coupling architecture that ensures coherent simulation progression across traffic, perception, and communication domains while preserving modularity and reproducibility. For example, CARLA can simulate and render a subset of vehicles that require detailed sensor emulation and control logic; SUMO orchestrates network-wide traffic flow, vehicle routing, and traffic signal management; and OMNeT++ dynamically maps communication nodes to both mobile entities (e.g., vehicles) and static entities (e.g., roadside units) to enable C-V2X communication. While these three simulators form the foundational core of OpenCAMS, the platform is designed to be expandable and future-proof, allowing additional simulators to be integrated on top of this core without requiring fundamental changes to the system architecture. The OpenCAMS platform is fully open-source and publicly available through its GitHub repository https://github.com/minhaj6/carla-sumo-omnetpp-cosim, providing the research community with an accessible, flexible, and collaborative environment for advancing next-generation intelligent transportation systems.",
      "authors": [
        "Minhaj Uddin Ahmad",
        "Akid Abrar",
        "Sagar Dasgupta",
        "Mizanur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:10:37+00:00",
          "link": "https://arxiv.org/abs/2507.09186v1",
          "size": "3296kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T18:38:34+00:00",
          "link": "https://arxiv.org/abs/2507.09186v2",
          "size": "3296kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T17:21:57+00:00",
          "link": "https://arxiv.org/abs/2507.09186v3",
          "size": "3296kb",
          "version": "v3"
        }
      ],
      "title": "OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advancing Next-Generation Intelligent Transportation Systems Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09186",
        "HTML": "https://arxiv.org/html/2507.09186v3",
        "PDF": "https://arxiv.org/pdf/2507.09186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development of a co-simulation platform for intelligent transportation systems and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09305",
      "abstract": "Path smoothness is often overlooked in path imitation learning from expert demonstrations. In this paper, we introduce a novel learning method, termed deep angular A* (DAA*), by incorporating the proposed path angular freedom (PAF) into A* to improve path similarity through adaptive path smoothness. The PAF aims to explore the effect of move angles on path node expansion by finding the trade-off between their minimum and maximum values, allowing for high adaptiveness for imitation learning. DAA* improves path optimality by closely aligning with the reference path through joint optimization of path shortening and smoothing, which correspond to heuristic distance and PAF, respectively. Throughout comprehensive evaluations on 7 datasets, including 4 maze datasets, 2 video-game datasets, and a real-world drone-view dataset containing 2 scenarios, we demonstrate remarkable improvements of our DAA* over neural A* in path similarity between the predicted and reference paths with a shorter path length when the shortest path is plausible, improving by 9.0% SPR, 6.9% ASIM, and 3.9% PSIM. Furthermore, when jointly learning pathfinding with both path loss and path probability map loss, DAA* significantly outperforms the state-of-the-art TransPath by 6.3% SPR, 6.0% PSIM, and 3.7% ASIM. We also discuss the minor trade-off between path optimality and search efficiency where applicable. Our code and model weights are available at https://github.com/zwxu064/DAAStar.git.",
      "authors": [
        "Zhiwei Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:46:42+00:00",
          "link": "https://arxiv.org/abs/2507.09305v1",
          "size": "5270kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:36:50+00:00",
          "link": "https://arxiv.org/abs/2507.09305v2",
          "size": "5270kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T06:51:41+00:00",
          "link": "https://arxiv.org/abs/2507.09305v3",
          "size": "5270kb",
          "version": "v3"
        }
      ],
      "title": "DAA*: Deep Angular A Star for Image-based Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09305",
        "HTML": "https://arxiv.org/html/2507.09305v3",
        "PDF": "https://arxiv.org/pdf/2507.09305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a novel path planning algorithm for image-based path planning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09682",
      "abstract": "We propose a novel approach, OrQstrator, which is a modular framework for conducting quantum circuit optimization in the Noisy Intermediate-Scale Quantum (NISQ) era. Our framework is powered by Deep Reinforcement Learning (DRL). Our orchestration engine intelligently selects among three complementary circuit optimizers: A DRL-based circuit rewriter trained to reduce depth and gate count via learned rewrite sequences; a domain-specific optimizer that performs efficient local gate resynthesis and numeric optimization; a parameterized circuit instantiator that improves compilation by optimizing template circuits during gate set translation. These modules are coordinated by a central orchestration engine that learns coordination policies based on circuit structure, hardware constraints, and backend-aware performance features such as gate count, depth, and expected fidelity. The system outputs an optimized circuit for hardware-aware transpilation and execution, leveraging techniques from an existing state-of-the-art approach, called the NISQ Analyzer, to adapt to backend constraints.",
      "authors": [
        "Laura Baird and Armin Moin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:38:39+00:00",
          "link": "https://arxiv.org/abs/2507.09682v1",
          "size": "333kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T06:16:38+00:00",
          "link": "https://arxiv.org/abs/2507.09682v2",
          "size": "333kb",
          "version": "v2"
        }
      ],
      "title": "OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09682",
        "HTML": "https://arxiv.org/html/2507.09682v2",
        "PDF": "https://arxiv.org/pdf/2507.09682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum circuit optimization using machine learning techniques and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09712",
      "abstract": "In this paper, we propose a novel function named Rate Distortion-in-Distortion (RDD) function as an extension of the classical rate-distortion (RD) function, where the expected distortion constraint is replaced by a Gromov-type distortion. This distortion, integral to the Gromov-Wasserstein (GW) distance, effectively defines the similarity in spaces of possibly different dimensions even without a direct metric between them. While the RDD function qualifies as an informational RD function, encoding theorems substantiate its status as an operational RD function, thereby underscoring its potential applicability in real-world source coding. Due to the high computational complexity associated with Gromov-type distortion, in general, the RDD function cannot be evaluated analytically. Consequently, we develop an alternating mirror descent algorithm that significantly reduces computational complexity by employing decomposition, linearization, and relaxation techniques. Numerical results on classical sources and different grids demonstrate the effectiveness of the developed algorithm. By exploring the relationship between the RDD function and the RD function, we suggest that the RDD function may have potential applications in future scenarios.",
      "authors": [
        "Lingyi Chen and Haoran Tang and Shitong Wu and Jiakun Liu and Huihui Wu and Wenyi Zhang and Hao Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:15:21+00:00",
          "link": "https://arxiv.org/abs/2507.09712v1",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:33:56+00:00",
          "link": "https://arxiv.org/abs/2507.09712v2",
          "size": "298kb",
          "version": "v2"
        }
      ],
      "title": "RDD Function: A Tradeoff Between Rate and Distortion-in-Distortion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09712",
        "HTML": "https://arxiv.org/html/2507.09712v2",
        "PDF": "https://arxiv.org/pdf/2507.09712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a novel distortion function for source coding, unrelated to LLM training data processing or dataset-related improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09871",
      "abstract": "The grand goal of AI research, and particularly Self Supervised Learning (SSL), is to produce systems that can successfully solve any possible task. In contrast, current evaluation methods available to AI researchers typically rely on a fixed collection of hand-picked downstream benchmarks. Hence, a large amount of effort is put into designing and searching for large collection of evaluation tasks that can serve as a proxy of our grand goal. We argue that such a rigid evaluation protocol creates a silent bottleneck in AI research. To remedy that, we define a probabilistic space of downstream tasks obtained by adopting a distribution of tasks and by defining Task Priors. Under this view, one can evaluate a model's performance over the set of all possible downstream tasks. Our framework is the first to provide answers to key questions such as (i) what is the average performance of my model over all possible downstream tasks weighted by the probability to encounter each task? or (ii) what is the variance of my model's performance across all downstream tasks under the defined Task Priors? Beyond establishing a new standard for evaluation, we believe that Task Priors will accelerate the pace of research in SSL - where downstream task evaluation is the sole qualitative signal that researchers have access to.",
      "authors": [
        "Niket Patel",
        "Randall Balestriero"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:53:14+00:00",
          "link": "https://arxiv.org/abs/2507.09871v1",
          "size": "1155kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T20:53:29+00:00",
          "link": "https://arxiv.org/abs/2507.09871v2",
          "size": "1137kb",
          "version": "v2"
        }
      ],
      "title": "Task Priors: Enhancing Model Evaluation by Considering the Entire Space of Downstream Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09871",
        "HTML": "https://arxiv.org/html/2507.09871v2",
        "PDF": "https://arxiv.org/pdf/2507.09871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new evaluation framework for Self Supervised Learning by defining a probabilistic space of downstream tasks, without contribution to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10055",
      "abstract": "Direct and natural interaction is essential for intuitive human-robot collaboration, eliminating the need for additional devices such as joysticks, tablets, or wearable sensors. In this paper, we present a lightweight deep learning-based hand gesture recognition system that enables humans to control collaborative robots naturally and efficiently. This model recognizes eight distinct hand gestures with only 1,103 parameters and a compact size of 22 KB, achieving an accuracy of 93.5%. To further optimize the model for real-world deployment on edge devices, we applied quantization and pruning using TensorFlow Lite, reducing the final model size to just 7 KB. The system was successfully implemented and tested on a Universal Robot UR5 collaborative robot within a real-time robotic framework based on ROS2. The results demonstrate that even extremely lightweight models can deliver accurate and responsive hand gesture-based control for collaborative robots, opening new possibilities for natural human-robot interaction in constrained environments.",
      "authors": [
        "Muhtadin",
        "I Wayan Agus Darmawan",
        "Muhammad Hilmi Rusydiansyah",
        "I Ketut Eddy Purnama",
        "Chastine Fatichah",
        "Mauridhi Hery Purnomo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:40:24+00:00",
          "link": "https://arxiv.org/abs/2507.10055v1",
          "size": "1403kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:25:41+00:00",
          "link": "https://arxiv.org/abs/2507.10055v2",
          "size": "1013kb",
          "version": "v2"
        }
      ],
      "title": "Hand Gesture Recognition for Collaborative Robots Using Lightweight Deep Learning in Real-Time Robotic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10055",
        "PDF": "https://arxiv.org/pdf/2507.10055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a hand gesture recognition system for collaborative robots and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10062",
      "abstract": "Snapshot testing has emerged as a critical technique for UI validation in modern software development, yet it suffers from substantial maintenance overhead due to frequent UI changes causing test failures that require manual inspection to distinguish between genuine regressions and intentional design changes. This manual triage process becomes increasingly burdensome as applications evolve, creating a need for automated analysis solutions. This paper introduces LLMShot, a novel framework that leverages Vision-Language Models (VLMs) to automatically analyze snapshot test failures through semantic classification of UI changes. To evaluate LLMShot's effectiveness, we developed a comprehensive dataset using a feature-rich iOS application with configurable feature flags, creating realistic scenarios that produce authentic snapshot differences representative of real development workflows. Our evaluation using Gemma3 models demonstrates strong classification performance, with the 12B variant achieving over 84% recall in identifying failure root causes while the 4B model offers practical deployment advantages with acceptable performance for continuous integration environments. However, our exploration of selective ignore mechanisms revealed significant limitations in current prompting-based approaches for controllable visual reasoning. LLMShot represents the first automated approach to semantic snapshot test analysis, offering developers structured insights that can substantially reduce manual triage effort and advance toward more intelligent UI testing paradigms.",
      "authors": [
        "Erg\\\"un Batuhan Kaynak",
        "Mayasah Lami",
        "Sahand Moslemi",
        "Anil Koyuncu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:47:19+00:00",
          "link": "https://arxiv.org/abs/2507.10062v1",
          "size": "1041kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:58:01+00:00",
          "link": "https://arxiv.org/abs/2507.10062v2",
          "size": "1047kb",
          "version": "v2"
        }
      ],
      "title": "LLMShot: Reducing snapshot testing maintenance via LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10062",
        "HTML": "https://arxiv.org/html/2507.10062v2",
        "PDF": "https://arxiv.org/pdf/2507.10062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces LLMShot, a framework for analyzing snapshot test failures using Vision-Language Models, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10084",
      "abstract": "The Tibetan Plateau, known as the Asian Water Tower, faces significant water security challenges due to its high sensitivity to climate change. Advancing Earth observation for sustainable water monitoring is thus essential for building climate resilience in this region. This study proposes a two-stage transfer learning strategy using the SegFormer model to overcome domain shift and data scarcit--key barriers in developing robust AI for climate-sensitive applications. After pre-training on a diverse source domain, our model was fine-tuned for the arid Zhada Tulin area. Experimental results show a substantial performance boost: the Intersection over Union (IoU) for water body segmentation surged from 25.50% (direct transfer) to 64.84%. This AI-driven accuracy is crucial for disaster risk reduction, particularly in monitoring flash flood-prone systems. More importantly, the high-precision map reveals a highly concentrated spatial distribution of water, with over 80% of the water area confined to less than 20% of the river channel length. This quantitative finding provides crucial evidence for understanding hydrological processes and designing targeted water management and climate adaptation strategies. Our work thus demonstrates an effective technical solution for monitoring arid plateau regions and contributes to advancing AI-powered Earth observation for disaster preparedness in critical transboundary river headwaters.",
      "authors": [
        "Haonan Chen (Tibet University) and Xin Tong (Northwestern Polytechnical University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:11:33+00:00",
          "link": "https://arxiv.org/abs/2507.10084v1",
          "size": "27417kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:37:18+00:00",
          "link": "https://arxiv.org/abs/2507.10084v2",
          "size": "23173kb",
          "version": "v2"
        }
      ],
      "title": "A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10084",
        "HTML": "https://arxiv.org/html/2507.10084v2",
        "PDF": "https://arxiv.org/pdf/2507.10084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study utilizes transfer learning for water body segmentation in remote sensing imagery, focusing on climate-sensitive applications with no relevance to LLM training data or dataset processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10732",
      "abstract": "The most studied and accepted pseudometric for probabilistic processes is one based on the Kantorovich distance between distributions. It comes with many theoretical and motivating results, in particular it is the fixpoint of a given functional and defines a functor on (complete) pseudometric spaces.\n  Other notions of behavioural pseudometrics have also been proposed, one of them ($\\epsilon$-distance) based on $\\epsilon$-bisimulation. $\\epsilon$-Distance has the advantages that it is intuitively easy to understand, it relates systems that are conceptually close (for example, an imperfect implementation is close to its specification), and it comes equipped with a natural notion of $\\epsilon$-coupling. Finally, this distance is easy to compute.\n  We show that $\\epsilon$-distance is also the greatest fixpoint of a functional and provides a functor. The latter is obtained by replacing the Kantorovich distance in the lifting functor with the L\\'evy-Prokhorov distance. In addition, we show that $\\epsilon$-couplings and $\\epsilon$-bisimulations have an appealing coalgebraic characterization.",
      "authors": [
        "Jos\\'ee Desharnais and Ana Sokolova"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:54:51+00:00",
          "link": "https://arxiv.org/abs/2507.10732v1",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:20:02+00:00",
          "link": "https://arxiv.org/abs/2507.10732v2",
          "size": "107kb",
          "version": "v2"
        }
      ],
      "title": "$\\epsilon$-Distance via L\\'evy-Prokhorov Lifting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10732",
        "HTML": "https://arxiv.org/html/2507.10732v2",
        "PDF": "https://arxiv.org/pdf/2507.10732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The content of this paper is focused on theoretical pseudometrics related to systems and processes, without discussing any training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11554",
      "abstract": "Recent advancements in diffusion models (DMs) have been propelled by alignment methods that post-train models to better conform to human preferences. However, these approaches typically require computation-intensive training of a base model and a reward model, which not only incurs substantial computational overhead but may also compromise model accuracy and training efficiency. To address these limitations, we propose Inversion-DPO, a novel alignment framework that circumvents reward modeling by reformulating Direct Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts intractable posterior sampling in Diffusion-DPO with the deterministic inversion from winning and losing samples to noise and thus derive a new post-training paradigm. This paradigm eliminates the need for auxiliary reward models or inaccurate appromixation, significantly enhancing both precision and efficiency of training. We apply Inversion-DPO to a basic task of text-to-image generation and a challenging task of compositional image generation. Extensive experiments show substantial performance improvements achieved by Inversion-DPO compared to existing post-training methods and highlight the ability of the trained generative models to generate high-fidelity compositionally coherent images. For the post-training of compostitional image geneation, we curate a paired dataset consisting of 11,140 images with complex structural annotations and comprehensive scores, designed to enhance the compositional capabilities of generative models. Inversion-DPO explores a new avenue for efficient, high-precision alignment in diffusion models, advancing their applicability to complex realistic generation tasks. Our code is available at https://github.com/MIGHTYEZ/Inversion-DPO",
      "authors": [
        "Zejian Li",
        "Yize Li",
        "Chenye Meng",
        "Zhongni Liu",
        "Yang Ling",
        "Shengyuan Zhang",
        "Guang Yang",
        "Changyuan Yang",
        "Zhiyuan Yang",
        "Lingyun Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:59:28+00:00",
          "link": "https://arxiv.org/abs/2507.11554v1",
          "size": "37915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:25:36+00:00",
          "link": "https://arxiv.org/abs/2507.11554v2",
          "size": "37916kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T10:37:32+00:00",
          "link": "https://arxiv.org/abs/2507.11554v3",
          "size": "37915kb",
          "version": "v3"
        }
      ],
      "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11554",
        "HTML": "https://arxiv.org/html/2507.11554v3",
        "PDF": "https://arxiv.org/pdf/2507.11554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Inversion-DPO, a post-training framework for diffusion models and discusses dataset curation for training. However, the focus is more on model alignment and efficiency rather than LLM data processing."
      },
      "models": [
        {
          "model_path": "ezlee258258/Inversion-DPO",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ezlee258258/Inversion-DPO"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11936",
      "abstract": "Geometry problem solving is a key area of mathematical reasoning, which is widely involved in many important fields such as education, mathematical ability assessment of artificial intelligence, and multimodal ability assessment. In recent years, the rapid development of deep learning technology, especially the rise of multimodal large language models, has triggered a widespread research boom. This paper provides a survey of the applications of deep learning in geometry problem solving, including (i) a comprehensive summary of the relevant tasks in geometry problem solving; (ii) a thorough review of related deep learning methods; (iii) a detailed analysis of evaluation metrics and methods; and (iv) a critical discussion of the current challenges and future directions that can be explored. Our goal is to provide a comprehensive and practical reference of deep learning for geometry problem solving to promote further developments in this field. We create a continuously updated list of papers on GitHub: https://github.com/majianz/dl4gps.",
      "authors": [
        "Jianzhe Ma",
        "Wenxuan Wang",
        "Qin Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:03:08+00:00",
          "link": "https://arxiv.org/abs/2507.11936v1",
          "size": "342kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T12:18:01+00:00",
          "link": "https://arxiv.org/abs/2507.11936v2",
          "size": "342kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T06:15:29+00:00",
          "link": "https://arxiv.org/abs/2507.11936v3",
          "size": "343kb",
          "version": "v3"
        }
      ],
      "title": "A Survey of Deep Learning for Geometry Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11936",
        "HTML": "https://arxiv.org/html/2507.11936v3",
        "PDF": "https://arxiv.org/pdf/2507.11936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on the applications of deep learning for geometry problem solving and does not address any aspects of LLM training data processing, focusing instead on task summary, methods, and evaluation metrics in the geometry domain."
      },
      "datasets": [
        {
          "dataset_name": "Infi-MM/InfiMM-WebMath-40B",
          "downloads": "997",
          "likes": "67",
          "link": "https://huggingface.co/datasets/Infi-MM/InfiMM-WebMath-40B"
        },
        {
          "dataset_name": "Joschka/big_bench_hard",
          "downloads": "547",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Joschka/big_bench_hard"
        },
        {
          "dataset_name": "GML-FMGroup/VisNumBench",
          "downloads": "57",
          "likes": "1",
          "link": "https://huggingface.co/datasets/GML-FMGroup/VisNumBench"
        },
        {
          "dataset_name": "Can111/m500",
          "downloads": "78",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Can111/m500"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12006",
      "abstract": "Vision Transformers (ViTs) have significantly advanced computer vision, demonstrating strong performance across various tasks. However, the attention mechanism in ViTs makes each layer function as a low-pass filter, and the stacked-layer architecture in existing transformers suffers from frequency vanishing. This leads to the loss of critical details and textures. We propose a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly modulates the overall frequency response of ViTs and consists of two techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling (FreqScale). Since circuit theory uses low-pass filters as fundamental elements, we introduce AttInv, a method that generates complementary high-pass filtering by inverting the low-pass filter in the attention matrix, and dynamically combining the two. We further design FreqScale to weight different frequency components for fine-grained adjustments to the target response function. Through feature similarity analysis and effective rank evaluation, we demonstrate that our approach avoids representation collapse, leading to consistent performance improvements across various models, including SegFormer, DeiT, and MaskDINO. These improvements are evident in tasks such as semantic segmentation, object detection, and instance segmentation. Additionally, we apply our method to remote sensing detection, achieving state-of-the-art results in single-scale settings. The code is available at https://github.com/Linwei-Chen/FDAM.",
      "authors": [
        "Linwei Chen",
        "Lin Gu",
        "Ying Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.12006v1",
          "size": "1421kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:10:31+00:00",
          "link": "https://arxiv.org/abs/2507.12006v2",
          "size": "1421kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T09:57:56+00:00",
          "link": "https://arxiv.org/abs/2507.12006v3",
          "size": "1421kb",
          "version": "v3"
        }
      ],
      "title": "Frequency-Dynamic Attention Modulation for Dense Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12006",
        "HTML": "https://arxiv.org/html/2507.12006v3",
        "PDF": "https://arxiv.org/pdf/2507.12006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a vision transformer technique called Frequency-Dynamic Attention Modulation for improving performance in computer vision tasks. It does not involve data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12106",
      "abstract": "The efficient design and management of public green spaces is a key factor in promoting the health and well-being of urban population, as emphasized by the WHO, UNEP, and EEA. These areas serve as the \"green lungs\" of the urban ecosystem, playing a vital role in enhancing quality of life thanks to the provision of ecosystem services. In this context, the Smart Green City use case in Campobasso municipality, funded by the Italian Ministry of Enterprises (MIMIT), emerges as an innovative model for the sustainable management of green urban areas through the adoption of an advanced system of emerging technologies integrated and interoperable. The project integrates IoT systems and data-driven governance platforms, enabling real-time monitoring of the health status of trees and green areas via a Decision Support System (DSS). It also facilitates the collection and analysis of data from diverse sources, including weather conditions, air quality, soil moisture, pollution levels. The resulting cloud-based platform supports a holistic real time decision making for green urban managers, technical experts and operational staff. It enables intelligent control and management of urban green spaces using Tree Talker sensors, integrated with soil moisture and water potential monitoring systems. Thanks to predictive models based on machine learning algorithms and real time data provided by IoT sensors, irrigation of public parks can be optimized by providing suggestions on when and how much water to apply. Customized alerts layers are also activated warning users when monitored parameters, such as soil temperature, humidity, or water potential, exceed predefined thresholds. This Use Case demonstrates how digitalization, IoT sensors fusion and technological innovation can support sustainable urban governance, fostering environmental resilience and improving citizens quality of life.",
      "authors": [
        "Antonio Salis",
        "Gabriele Troina",
        "Gianluca Boanelli",
        "Marco Ottaviano",
        "Paola Fortini",
        "Soraya Versace"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:24:07+00:00",
          "link": "https://arxiv.org/abs/2507.12106v1",
          "size": "1194kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:06:54+00:00",
          "link": "https://arxiv.org/abs/2507.12106v2",
          "size": "1194kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:45:04+00:00",
          "link": "https://arxiv.org/abs/2507.12106v3",
          "size": "1146kb",
          "version": "v3"
        }
      ],
      "title": "Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12106",
        "PDF": "https://arxiv.org/pdf/2507.12106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about the integration of IoT systems for the management of urban green spaces and does not pertain to LLM training data processing in any capacity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12311",
      "abstract": "Ontology interoperability is one of the complicated issues that restricts the use of ontologies in knowledge graphs (KGs). Different ontologies with conflicting and overlapping concepts make it difficult to design, develop, and deploy an interoperable ontology for downstream tasks. We propose an ecosystem for ontology interoperability. The ecosystem employs three state-of-the-art semantic techniques in different phases of the ontology engineering life cycle: ontology design patterns (ODPs) in the design phase, ontology matching and versioning (OM\\&OV) in the develop phase, and ontology-compliant knowledge graphs (OCKGs) in the deploy phase, to achieve better ontology interoperability in real-world applications. A case study of sensor observation in the building domain validates the usefulness of the proposed ecosystem.",
      "authors": [
        "Zhangcheng Qiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:06:29+00:00",
          "link": "https://arxiv.org/abs/2507.12311v1",
          "size": "1158kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:19:49+00:00",
          "link": "https://arxiv.org/abs/2507.12311v2",
          "size": "1162kb",
          "version": "v2"
        }
      ],
      "title": "An Ecosystem for Ontology Interoperability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12311",
        "HTML": "https://arxiv.org/html/2507.12311v2",
        "PDF": "https://arxiv.org/pdf/2507.12311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on ontology interoperability in knowledge graphs and does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12558",
      "abstract": "Automatically generating concise, informative comments for source code can lighten documentation effort and accelerate program comprehension. Retrieval-augmented approaches first fetch code snippets with existing comments and then synthesize a new comment, yet retrieval and generation are typically optimized in isolation, allowing irrelevant neighbors topropagate noise downstream. To tackle the issue, we propose a novel approach named RAGSum with the aim of both effectiveness and efficiency in recommendations. RAGSum is built on top offuse retrieval and generation using a single CodeT5 backbone. We report preliminary results on a unified retrieval-generation framework built on CodeT5. A contrastive pre-training phase shapes code embeddings for nearest-neighbor search; these weights then seed end-to-end training with a composite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes comment-generation error. More importantly, a lightweight self-refinement loop is deployed to polish the final output. We evaluated theframework on three cross-language benchmarks (Java, Python, C), and compared it with three well-established baselines. The results show that our approach substantially outperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These findings indicate that tightly coupling retrieval and generationcan raise the ceiling for comment automation and motivateforthcoming replications and qualitative developer studies.",
      "authors": [
        "Tien P. T. Le",
        "Anh M. T. Bui",
        "Huy N. D. Pham",
        "Alessio Bucaioni",
        "Phuong T. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:12:27+00:00",
          "link": "https://arxiv.org/abs/2507.12558v1",
          "size": "3076kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:07:10+00:00",
          "link": "https://arxiv.org/abs/2507.12558v2",
          "size": "3076kb",
          "version": "v2"
        }
      ],
      "title": "When Retriever Meets Generator: A Joint Model for Code Comment Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12558",
        "HTML": "https://arxiv.org/html/2507.12558v2",
        "PDF": "https://arxiv.org/pdf/2507.12558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details a model for code comment generation using a retrieval and generation framework. It does not make contributions to the area of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12720",
      "abstract": "Language models (LMs) are challenging to adapt to new data distributions by simple finetuning. This is due to the rigidity of their subword tokenizers, which typically remain unchanged during adaptation. This inflexibility often leads to inefficient tokenization, causing overfragmentation of out-of-distribution domains, unseen languages, or scripts. In this work, we develop byte-level LMs with learnable tokenizers to make tokenization adaptive. Our models include a submodule that learns to predict boundaries between the input byte sequence, encoding it into variable-length segments. Existing tokenizer-free methods train this boundary predictor using an auxiliary loss that enforces a fixed compression rate across the training corpus, introducing a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective that enables significantly greater flexibility during adaptation. Evaluating across multiple multilingual benchmarks, morphologically diverse tasks, and domains, we demonstrate that FLEXITOKENS consistently reduces token over-fragmentation and achieves up to 10% improvements on downstream task performance compared to subword and other gradient-based tokenizers. Code and data for our experiments will be released at https://github.com/owos/flexitokens",
      "authors": [
        "Abraham Toluase Owodunni",
        "Orevaoghene Ahia",
        "Sachin Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:55:41+00:00",
          "link": "https://arxiv.org/abs/2507.12720v1",
          "size": "4293kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:40:42+00:00",
          "link": "https://arxiv.org/abs/2507.12720v2",
          "size": "4283kb",
          "version": "v2"
        }
      ],
      "title": "FLEXITOKENS: Flexible Tokenization for Evolving Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12720",
        "PDF": "https://arxiv.org/pdf/2507.12720"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing byte-level LMs with adaptive tokenization to address subword tokenizer issues rather than data processing operations such as data collection or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12901",
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated remarkable general reasoning capabilities, holding significant potential for applications in the financial domain, a field that requires robust and reliable reasoning. It has been demonstrated that distilling high-quality chain-of-thought (CoT) rationales from advanced general reasoning models offers a promising and efficient path to the financial reasoning model. However, existing CoT synthesis methods suffer from shallow CoT sampling, leaving the question of how to construct a well-designed knowledge space for finance reasoning unexplored. In this paper, we present Agentar-DeepFinance-100K, a large-scale financial reasoning dataset characterized by its systematic CoT synthesis optimization. We first introduce a comprehensive CoT synthesis pipeline featuring Multi-perspective Knowledge Extraction (MKE) and Self-Corrective Rewriting (SCR) to generate exhaustive and deep financial reasoning trajectories. Furthermore, a systematic investigation, termed CoT Cube, is conducted to analyze critical factors that influence CoT effectiveness, such as necessity, length and synthesizer, yielding valuable insights for high-quality financial CoT construction. Experiments demonstrate that models trained on our Agentar-DeepFinance-100K achieve significant improvements on financial benchmarks. We publicly release Agentar-DeepFinance-100K , hoping to advance the research in financial reasoning models.",
      "authors": [
        "Xiaoke Zhao",
        "Zhaowen Zhou",
        "Lin Chen",
        "Lihong Wang",
        "Zhiyi Huang",
        "Kaiyuan Zheng",
        "Yanjun Zheng",
        "Xiyang Du",
        "Longfei Liao",
        "Jiawei Liu",
        "Xiang Qi",
        "Bo Zhang",
        "Peng Zhang",
        "Wei Wang",
        "Zhe Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:40:45+00:00",
          "link": "https://arxiv.org/abs/2507.12901v1",
          "size": "776kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:50:24+00:00",
          "link": "https://arxiv.org/abs/2507.12901v2",
          "size": "861kb",
          "version": "v2"
        }
      ],
      "title": "Agentar-DeepFinance-100K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12901",
        "HTML": "https://arxiv.org/html/2507.12901v2",
        "PDF": "https://arxiv.org/pdf/2507.12901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces Agentar-DeepFinance-100K, a large financial dataset created through systematic CoT synthesis and discusses methods like Multi-perspective Knowledge Extraction for dataset construction, contributing directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13238",
      "abstract": "Analogies test a model's ability to infer implicit relationships between concepts, making them a key benchmark for evaluating reasoning capabilities. While large language models (LLMs) are widely evaluated for reasoning in English, their abilities in Indic languages remain understudied, limiting our understanding of whether these models generalize across languages. To address this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405 multiple-choice questions sourced from Indian government exams. We benchmark state-of-the-art multilingual LLMs using various prompting strategies and introduce a grounded Chain of Thought approach that leverages cognitive theories of analogical reasoning. This approach improves model performance on Hindi analogy questions. Our experiments show that models perform best with English prompts, irrespective of the prompting strategy. Our test set addresses the lack of a critical resource to evaluate LLM reasoning capabilities in Hindi.",
      "authors": [
        "Ashray Gupta and Rohan Joseph and Sunny Rai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:47:49+00:00",
          "link": "https://arxiv.org/abs/2507.13238v1",
          "size": "576kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T21:50:22+00:00",
          "link": "https://arxiv.org/abs/2507.13238v2",
          "size": "166kb",
          "version": "v2"
        }
      ],
      "title": "Multilingual LLMs Are Not Multilingual Thinkers: Evidence from Hindi Analogy Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13238",
        "PDF": "https://arxiv.org/pdf/2507.13238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The introduction of a Hindi analogy test set contributes to benchmarking LLM reasoning but does not significantly focus on broader training data processing for LLM model development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14314",
      "abstract": "Online news outlets operate predominantly on an advertising-based revenue model, compelling journalists to create headlines that are often scandalous, intriguing, and provocative -- commonly referred to as clickbait. Automatic detection of clickbait headlines is essential for preserving information quality and reader trust in digital media and requires both contextual understanding and world knowledge. For this task, particularly in less-resourced languages, it remains unclear whether fine-tuned methods or in-context learning (ICL) yield better results. In this paper, we compile CLIC, a novel dataset for clickbait detection of Croatian news headlines spanning a 20-year period and encompassing mainstream and fringe outlets. We fine-tune the BERTi\\'c model on this task and compare its performance to LLM-based ICL methods with prompts both in Croatian and English. Finally, we analyze the linguistic properties of clickbait. We find that nearly half of the analyzed headlines contain clickbait, and that finetuned models deliver better results than general LLMs.",
      "authors": [
        "Marija An{\\dj}eli\\'c",
        "Dominik \\v{S}ipek",
        "Laura Majer",
        "Jan \\v{S}najder"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.14314v1",
          "size": "142kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:10:17+00:00",
          "link": "https://arxiv.org/abs/2507.14314v2",
          "size": "142kb",
          "version": "v2"
        }
      ],
      "title": "What Makes You CLIC: Detection of Croatian Clickbait Headlines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14314",
        "HTML": "https://arxiv.org/html/2507.14314v2",
        "PDF": "https://arxiv.org/pdf/2507.14314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a novel dataset for Croatian clickbait detection, its primary focus is on evaluating model performance for clickbait detection tasks rather than LLM data processing or dataset creation for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14516",
      "abstract": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware metric function for time series self-supervised representation learning. Most Self-Supervised Learning (SSL) methods for signals commonly adopt distance-based objectives such as mean squared error (MSE), which are sensitive to amplitude, invariant to waveform polarity, and unbounded in scale. These properties hinder semantic alignment and reduce interpretability. SDSC addresses this by quantifying structural agreement between temporal signals based on the intersection of signed amplitudes, derived from the Dice Similarity Coefficient (DSC).Although SDSC is defined as a structure-aware metric, it can be used as a loss by subtracting from 1 and applying a differentiable approximation of the Heaviside function for gradient-based optimization. A hybrid loss formulation is also proposed to combine SDSC with MSE, improving stability and preserving amplitude where necessary. Experiments on forecasting and classification benchmarks demonstrate that SDSC-based pre-training achieves comparable or improved performance over MSE, particularly in in-domain and low-resource scenarios. The results suggest that structural fidelity in signal representations enhances the semantic representation quality, supporting the consideration of structure-aware metrics as viable alternatives to conventional distance-based methods.",
      "authors": [
        "Jeyoung Lee and Hochul Kang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:32:00+00:00",
          "link": "https://arxiv.org/abs/2507.14516v1",
          "size": "715kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:48:25+00:00",
          "link": "https://arxiv.org/abs/2507.14516v2",
          "size": "710kb",
          "version": "v2"
        }
      ],
      "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14516",
        "HTML": "https://arxiv.org/html/2507.14516v2",
        "PDF": "https://arxiv.org/pdf/2507.14516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a structure-aware metric for time series self-supervised representation learning, which does not relate to LLM training data processing in terms of data collection, generation, or quality improvement for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14562",
      "abstract": "This paper investigates the convergence rates of two Euler-type methods for a class of time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients. Building upon existing research, we adapt the backward Euler method to time-changed stochastic differential equations where both coefficients exhibit super-linear growth and introduce an explicit counterpart, the projected Euler method. It is shown that both methods achieve the optimal strong convergence rate of order 1/2 in the mean-square sense for this class of equations. Numerical simulations confirm the theoretical findings",
      "authors": [
        "Yuanling Niu",
        "Shuai Wang",
        "Ying Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:56:04+00:00",
          "link": "https://arxiv.org/abs/2507.14562v1",
          "size": "405kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T01:34:37+00:00",
          "link": "https://arxiv.org/abs/2507.14562v2",
          "size": "405kb",
          "version": "v2"
        }
      ],
      "title": "1/2 order convergence rate of Euler-type methods for time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14562",
        "HTML": "https://arxiv.org/html/2507.14562v2",
        "PDF": "https://arxiv.org/pdf/2507.14562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates convergence rates of numerical methods for stochastic differential equations, which is not relevant to LLM training data processing and does not involve data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14660",
      "abstract": "Recent large-scale events like election fraud and financial scams have shown how harmful coordinated efforts by human groups can be. With the rise of autonomous AI systems, there is growing concern that AI-driven groups could also cause similar harm. While most AI safety research focuses on individual AI systems, the risks posed by multi-agent systems (MAS) in complex real-world situations are still underexplored. In this paper, we introduce a proof-of-concept to simulate the risks of malicious MAS collusion, using a flexible framework that supports both centralized and decentralized coordination structures. We apply this framework to two high-risk fields: misinformation spread and e-commerce fraud. Our findings show that decentralized systems are more effective at carrying out malicious actions than centralized ones. The increased autonomy of decentralized systems allows them to adapt their strategies and cause more damage. Even when traditional interventions, like content flagging, are applied, decentralized groups can adjust their tactics to avoid detection. We present key insights into how these malicious groups operate and the need for better detection systems and countermeasures. Code is available at https://github.com/renqibing/RogueAgent.",
      "authors": [
        "Qibing Ren",
        "Sitao Xie",
        "Longxuan Wei",
        "Zhenfei Yin",
        "Junchi Yan",
        "Lizhuang Ma",
        "Jing Shao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:17:30+00:00",
          "link": "https://arxiv.org/abs/2507.14660v1",
          "size": "5181kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T06:00:02+00:00",
          "link": "https://arxiv.org/abs/2507.14660v2",
          "size": "5181kb",
          "version": "v2"
        }
      ],
      "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14660",
        "PDF": "https://arxiv.org/pdf/2507.14660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the risks of multi-agent collusion in social systems, focusing on simulation of malicious MAS collusion, which does not contribute to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14679",
      "abstract": "The exponential growth of spam text on the Internet necessitates robust detection mechanisms to mitigate risks such as information leakage and social instability. This work addresses two principal challenges: adversarial strategies employed by spammers and the scarcity of labeled data. We propose a novel spam-text detection framework GCC-Spam, which integrates three core innovations. First, a character similarity network captures orthographic and phonetic features to counter character-obfuscation attacks and furthermore produces sentence embeddings for downstream classification. Second, contrastive learning enhances discriminability by optimizing the latent-space distance between spam and normal texts. Third, a Generative Adversarial Network (GAN) generates realistic pseudo-spam samples to alleviate data scarcity while improving model robustness and classification accuracy. Extensive experiments on real-world datasets demonstrate that our model outperforms baseline approaches, achieving higher detection rates with significantly fewer labeled examples.",
      "authors": [
        "Zhijie Wang",
        "Zixin Xu",
        "Zhiyuan Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:09:48+00:00",
          "link": "https://arxiv.org/abs/2507.14679v1",
          "size": "1097kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:46:28+00:00",
          "link": "https://arxiv.org/abs/2507.14679v2",
          "size": "1097kb",
          "version": "v2"
        }
      ],
      "title": "GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14679",
        "HTML": "https://arxiv.org/html/2507.14679v2",
        "PDF": "https://arxiv.org/pdf/2507.14679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses spam detection challenges via innovative frameworks but does not involve training data processing or dataset creation related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14783",
      "abstract": "The advancement of general-purpose artificial intelligence relies on large language models (LLMs) that excel across a wide range of tasks, from structured reasoning to creative generation. However, post-training methods like Supervised Fine-Tuning (SFT) often struggle with generalization, favoring memorization over transferable learning. In this work, we introduce Omni-Thinker, a unified reinforcement learning (RL) framework that enhances LLM performance across diverse tasks by combining rule-based verifiable rewards with generative preference signals via LLM-as-a-Judge evaluations. Our approach enables consistent optimization across task types and scales RL-based training to subjective domains. We further investigate training strategies, demonstrating that a curriculum-based progression that orders tasks from structured to open-ended improves performance and reduces forgetting. Experimental results across four domains reveal that curriculum learning improves performance by 5.2% over joint training and 9.1% over model merging. These results highlight the importance of task-aware sampling and hybrid supervision in scaling RL-based post-training for general-purpose LLMs.",
      "authors": [
        "Derek Li and Jiaming Zhou",
        "Amirreza Kazemi",
        "Qianyi Sun",
        "Abbas Ghaddar",
        "Mohammad Ali Alomrani",
        "Liheng Ma",
        "Yu Luo",
        "Dong Li",
        "Feng Wen",
        "Jianye Hao",
        "Mark Coates",
        "Yingxue Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T01:50:16+00:00",
          "link": "https://arxiv.org/abs/2507.14783v1",
          "size": "839kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:25:54+00:00",
          "link": "https://arxiv.org/abs/2507.14783v2",
          "size": "836kb",
          "version": "v2"
        }
      ],
      "title": "Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14783",
        "HTML": "https://arxiv.org/html/2507.14783v2",
        "PDF": "https://arxiv.org/pdf/2507.14783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing LLMs using a reinforcement learning framework, with a focus on post-training through multi-task reinforcement learning. While it briefly touches upon improving LLM generalization, it does not primarily focus on the core aspects of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15103",
      "abstract": "We develop and analyze numerical methods for a stochastic Keller-Segel system perturbed by Stratonovich noise, which models chemotactic behavior under randomly fluctuating environmental conditions. The proposed fully discrete scheme couples a Crank-Nicolson time discretization with a splitting mixed finite element method in space. We rigorously prove the stability of the numerical scheme and establish strong convergence rates of order $O(k^{1/2} + k^{-1/2}h^2)$, where $k$ and $h$ denote the time and spatial step sizes, respectively. Notably, the presence of stochastic forcing leads to an inverse dependence on $k$ in the error estimates, distinguishing the convergence behavior from that of the deterministic case. Numerical experiments are presented to validate the theoretical results and demonstrate the effectiveness and accuracy of the proposed methods.",
      "authors": [
        "Liet Vo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:54:43+00:00",
          "link": "https://arxiv.org/abs/2507.15103v1",
          "size": "871kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T03:25:52+00:00",
          "link": "https://arxiv.org/abs/2507.15103v2",
          "size": "871kb",
          "version": "v2"
        }
      ],
      "title": "Analysis of fully discrete Crank-Nicolson finite element methods for a stochastic Keller-Segel chemotaxis system with gradient-type multiplicative noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15103",
        "HTML": "https://arxiv.org/html/2507.15103v2",
        "PDF": "https://arxiv.org/pdf/2507.15103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on numerical methods for solving a stochastic Keller-Segel system with noise and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15205",
      "abstract": "Emotion Recognition in Conversation (ERC) is a practical and challenging task. This paper proposes a novel multimodal approach, the Long-Short Distance Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it constructs a long-distance graph neural network and a short-distance graph neural network to obtain multimodal features of distant and nearby utterances, respectively. To ensure that long- and short-distance features are as distinct as possible in representation while enabling mutual influence between the two modules, we employ a Differential Regularizer and incorporate a BiAffine Module to facilitate feature interaction. In addition, we propose an Improved Curriculum Learning (ICL) to address the challenge of data imbalance. By computing the similarity between different emotions to emphasize the shifts in similar emotions, we design a \"weighted emotional shift\" metric and develop a difficulty measurer, enabling a training process that prioritizes learning easy samples before harder ones. Experimental results on the IEMOCAP and MELD datasets demonstrate that our model outperforms existing benchmarks.",
      "authors": [
        "Xinran Li",
        "Xiujuan Xu",
        "Jiaqi Qiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:12:54+00:00",
          "link": "https://arxiv.org/abs/2507.15205v1",
          "size": "2965kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T05:15:18+00:00",
          "link": "https://arxiv.org/abs/2507.15205v2",
          "size": "1301kb",
          "version": "v2"
        }
      ],
      "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15205",
        "HTML": "https://arxiv.org/html/2507.15205v2",
        "PDF": "https://arxiv.org/pdf/2507.15205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered on emotion recognition in conversations using graph neural networks and curriculum learning, with no discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15401",
      "abstract": "Facial expression recognition (FER) is a challenging task due to pervasive occlusion and dataset biases. Especially when facial information is partially occluded, existing FER models struggle to extract effective facial features, leading to inaccurate classifications. In response, we present ORSANet, which introduces the following three key contributions: First, we introduce auxiliary multi-modal semantic guidance to disambiguate facial occlusion and learn high-level semantic knowledge, which is two-fold: 1) we introduce semantic segmentation maps as dense semantics prior to generate semantics-enhanced facial representations; 2) we introduce facial landmarks as sparse geometric prior to mitigate intrinsic noises in FER, such as identity and gender biases. Second, to facilitate the effective incorporation of these two multi-modal priors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively fuse the landmark feature and semantics-enhanced representations within different scales. Third, we design a Dynamic Adversarial Repulsion Enhancement Loss (DARELoss) that dynamically adjusts the margins of ambiguous classes, further enhancing the model's ability to distinguish similar expressions. We further construct the first occlusion-oriented FER dataset to facilitate specialized robustness analysis on various real-world occlusion conditions, dubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER demonstrate that our proposed ORSANet achieves SOTA recognition performance. Code is publicly available at https://github.com/Wenyuzhy/ORSANet-master.",
      "authors": [
        "Huiyu Zhai",
        "Xingxing Yang",
        "Yalan Ye",
        "Chenyang Li",
        "Bin Fan",
        "Changze Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:04:29+00:00",
          "link": "https://arxiv.org/abs/2507.15401v1",
          "size": "1925kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:58:54+00:00",
          "link": "https://arxiv.org/abs/2507.15401v2",
          "size": "1915kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T08:24:01+00:00",
          "link": "https://arxiv.org/abs/2507.15401v3",
          "size": "1918kb",
          "version": "v3"
        }
      ],
      "title": "Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15401",
        "HTML": "https://arxiv.org/html/2507.15401v3",
        "PDF": "https://arxiv.org/pdf/2507.15401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on facial expression recognition with occlusions, presenting a new dataset for this purpose but not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15465",
      "abstract": "Computational workloads composing traditional Transformer models are starkly bifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic intensity, while feedforward layers are compute-bound. This dichotomy has long motivated research into specialized hardware to mitigate the MHA bottleneck.\n  This paper argues that recent architectural shifts, namely Multi-head Latent Attention (MLA) and Mixture-of-Experts (MoE), challenge the premise of specialized attention hardware. We make two key observations. First, the arithmetic intensity of MLA is over two orders of magnitude greater than that of MHA, shifting it close to a compute-bound regime well-suited for modern accelerators like GPUs. Second, by distributing MoE experts across a pool of accelerators, their arithmetic intensity can be tuned through batching to match that of the dense layers, creating a more balanced computational profile.\n  These findings reveal a diminishing need for specialized attention hardware. The central challenge for next-generation Transformers is no longer accelerating a single memory-bound layer. Instead, the focus must shift to designing balanced systems with sufficient compute, memory capacity, memory bandwidth, and high-bandwidth interconnects to manage the diverse demands of large-scale models.",
      "authors": [
        "Sungmin Yun and Seonyong Park and Hwayong Nam and Younjoo Lee and Gunjun Lee and Kwanhee Kyung and Sangpyo Kim and Nam Sung Kim and Jongmin Kim and Hyungyo Kim and Juhwan Cho and Seungmin Baek and Jung Ho Ahn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:18:33+00:00",
          "link": "https://arxiv.org/abs/2507.15465v1",
          "size": "1282kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T20:55:41+00:00",
          "link": "https://arxiv.org/abs/2507.15465v2",
          "size": "1295kb",
          "version": "v2"
        }
      ],
      "title": "The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15465",
        "HTML": "https://arxiv.org/html/2507.15465v2",
        "PDF": "https://arxiv.org/pdf/2507.15465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses architectural shifts in Transformer models focusing on computational workloads and systems design. It does not involve any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15504",
      "abstract": "Despite recent advances, Text-to-video retrieval (TVR) is still hindered by multiple inherent uncertainties, such as ambiguous textual queries, indistinct text-video mappings, and low-quality video frames. Although interactive systems have emerged to address these challenges by refining user intent through clarifying questions, current methods typically rely on heuristic or ad-hoc strategies without explicitly quantifying these uncertainties, limiting their effectiveness. Motivated by this gap, we propose UMIVR, an Uncertainty-Minimizing Interactive Text-to-Video Retrieval framework that explicitly quantifies three critical uncertainties-text ambiguity, mapping uncertainty, and frame uncertainty-via principled, training-free metrics: semantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon divergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based Frame Sampler (TQFS). By adaptively generating targeted clarifying questions guided by these uncertainty measures, UMIVR iteratively refines user queries, significantly reducing retrieval ambiguity. Extensive experiments on multiple benchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1 (69.2\\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby establishing an uncertainty-minimizing foundation for interactive TVR.",
      "authors": [
        "Bingqing Zhang",
        "Zhuo Cao",
        "Heming Du",
        "Yang Li",
        "Xue Li",
        "Jiajun Liu",
        "Sen Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.15504v1",
          "size": "1827kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T10:32:09+00:00",
          "link": "https://arxiv.org/abs/2507.15504v2",
          "size": "1851kb",
          "version": "v2"
        }
      ],
      "title": "Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15504",
        "HTML": "https://arxiv.org/html/2507.15504v2",
        "PDF": "https://arxiv.org/pdf/2507.15504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on text-to-video retrieval and introduces an uncertainty minimizing framework for improving query refinement. It does not discuss LLM training data processing or contribute to dataset creation or quality improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15511",
      "abstract": "We present, to our knowledge, the first deterministic, certificate-sensitive algorithm for a canonical NP-complete problem whose runtime provably adapts to the structure of each input. For a Subset-Sum instance $(S, t)$, let $\\Sigma(S)$ denote the set of distinct subset sums and define $U = |\\Sigma(S)|$. This set serves as an information-theoretically minimal witness, the instance-complexity (IC) certificate.\n  Our solver, IC-SubsetSum, enumerates every element of $\\Sigma(S)$ in deterministic time $O(U \\cdot n^2)$ and space $O(U \\cdot n)$. A randomized variant achieves expected runtime $O(U \\cdot n)$. The algorithm's complexity is thus directly governed by the certificate size, and this structure-sensitive performance is paired with a guaranteed worst-case runtime of $O^*(2^{n/2 - \\varepsilon})$ for some constant $\\varepsilon > 0$, the first such result to strictly outperform classical methods on every instance.\n  We revisit fine-grained reductions that rely on the classical $2^{n/2}$ hardness of SubsetSum and show that these arguments hold only for collision-free instances where $U$ is maximal. IC-SubsetSum reframes this barrier structurally and introduces a new paradigm for certificate-sensitive algorithms across NP-complete problems.",
      "authors": [
        "Jesus Salas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:26:38+00:00",
          "link": "https://arxiv.org/abs/2507.15511v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:54:46+00:00",
          "link": "https://arxiv.org/abs/2507.15511v2",
          "size": "25kb",
          "version": "v2"
        }
      ],
      "title": "Certificate-Sensitive Subset Sum: Realizing Instance Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15511",
        "HTML": "https://arxiv.org/html/2507.15511v2",
        "PDF": "https://arxiv.org/pdf/2507.15511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a deterministic algorithm for the subset sum problem, which is a canonical NP-complete problem. It does not relate to LLM training data processing or involve any data engineering operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15541",
      "abstract": "Surgical scene understanding is crucial for computer-assisted intervention systems, requiring visual comprehension of surgical scenes that involves diverse elements such as surgical tools, anatomical structures, and their interactions. To effectively represent the complex information in surgical scenes, graph-based approaches have been explored to structurally model surgical entities and their relationships. Previous surgical scene graph studies have demonstrated the feasibility of representing surgical scenes using graphs. However, certain aspects of surgical scenes-such as diverse combinations of tool-action-target and the identity of the hand operating the tool-remain underexplored in graph-based representations, despite their importance. To incorporate these aspects into graph representations, we propose Endoscapes-SG201 dataset, which includes annotations for tool-action-target combinations and hand identity. We also introduce SSG-Com, a graph-based method designed to learn and represent these critical elements. Through experiments on downstream tasks such as critical view of safety assessment and action triplet recognition, we demonstrated the importance of integrating these essential scene graph components, highlighting their significant contribution to surgical scene understanding. The code and dataset are available at https://github.com/ailab-kyunghee/SSG-Com",
      "authors": [
        "Jongmin Shin",
        "Enki Cho",
        "Ka Young Kim",
        "Jung Yong Kim",
        "Seong Tae Kim",
        "and Namkee Oh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:10:42+00:00",
          "link": "https://arxiv.org/abs/2507.15541v1",
          "size": "5719kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T00:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.15541v2",
          "size": "5719kb",
          "version": "v2"
        }
      ],
      "title": "Towards Holistic Surgical Scene Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15541",
        "HTML": "https://arxiv.org/html/2507.15541v2",
        "PDF": "https://arxiv.org/pdf/2507.15541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses surgical scene understanding using graph-based approaches and introduces a new dataset for surgical scenes. It focuses on visual comprehension in the medical field rather than processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15551",
      "abstract": "Recent progress on large language models (LLMs) has spurred interest in scaling up recommendation systems, yet two practical obstacles remain. First, training and serving cost on industrial Recommenders must respect strict latency bounds and high QPS demands. Second, most human-designed feature-crossing modules in ranking models were inherited from the CPU era and fail to exploit modern GPUs, resulting in low Model Flops Utilization (MFU) and poor scalability. We introduce RankMixer, a hardware-aware model design tailored towards a unified and scalable feature-interaction architecture. RankMixer retains the transformer's high parallelism while replacing quadratic self-attention with multi-head token mixing module for higher efficiency. Besides, RankMixer maintains both the modeling for distinct feature subspaces and cross-feature-space interactions with Per-token FFNs. We further extend it to one billion parameters with a Sparse-MoE variant for higher ROI. A dynamic routing strategy is adapted to address the inadequacy and imbalance of experts training. Experiments show RankMixer's superior scaling abilities on a trillion-scale production dataset. By replacing previously diverse handcrafted low-MFU modules with RankMixer, we boost the model MFU from 4.5\\% to 45\\%, and scale our ranking model parameters by 100x while maintaining roughly the same inference latency. We verify RankMixer's universality with online A/B tests across two core application scenarios (Recommendation and Advertisement). Finally, we launch 1B Dense-Parameters RankMixer for full traffic serving without increasing the serving cost, which improves user active days by 0.3\\% and total in-app usage duration by 1.08\\%.",
      "authors": [
        "Jie Zhu",
        "Zhifang Fan",
        "Xiaoxie Zhu",
        "Yuchen Jiang",
        "Hangyu Wang",
        "Xintian Han",
        "Haoran Ding",
        "Xinmin Wang",
        "Wenlin Zhao",
        "Zhen Gong",
        "Huizhi Yang",
        "Zheng Chai",
        "Zhe Chen",
        "Yuchao Zheng",
        "Qiwei Chen",
        "Feng Zhang",
        "Xun Zhou",
        "Peng Xu",
        "Xiao Yang",
        "Di Wu",
        "Zuotao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:28:55+00:00",
          "link": "https://arxiv.org/abs/2507.15551v1",
          "size": "606kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:19:32+00:00",
          "link": "https://arxiv.org/abs/2507.15551v2",
          "size": "606kb",
          "version": "v2"
        }
      ],
      "title": "RankMixer: Scaling Up Ranking Models in Industrial Recommenders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15551",
        "HTML": "https://arxiv.org/html/2507.15551v2",
        "PDF": "https://arxiv.org/pdf/2507.15551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving ranking models in industrial recommenders with a new model design. It does not address LLM training data processing or operations for enhancing LLM dataset quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15857",
      "abstract": "Autoregressive (AR) models have long dominated the landscape of large language models, driving progress across a wide range of tasks. Recently, diffusion-based language models have emerged as a promising alternative, though their advantages over AR models remain underexplored. In this paper, we systematically study masked diffusion models in data-constrained settings-where training involves repeated passes over limited data-and find that they significantly outperform AR models when compute is abundant but data is scarce. Diffusion models make better use of repeated data, achieving lower validation loss and superior downstream performance. We interpret this advantage as implicit data augmentation: masked diffusion exposes the model to a diverse distribution of token orderings and prediction tasks, unlike AR's fixed left-to-right factorization. We find new scaling laws for diffusion models and derive a closed-form expression for the critical compute threshold at which diffusion begins to outperform AR. These results suggest that when data, not compute, is the bottleneck, diffusion models offer a compelling alternative to the standard AR paradigm. Our code is available at: https://diffusion-scaling.github.io.",
      "authors": [
        "Mihir Prabhudesai",
        "Menging Wu",
        "Amir Zadeh",
        "Katerina Fragkiadaki",
        "Deepak Pathak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:59:57+00:00",
          "link": "https://arxiv.org/abs/2507.15857v1",
          "size": "5123kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T17:55:24+00:00",
          "link": "https://arxiv.org/abs/2507.15857v2",
          "size": "5125kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion Beats Autoregressive in Data-Constrained Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15857",
        "HTML": "https://arxiv.org/html/2507.15857v2",
        "PDF": "https://arxiv.org/pdf/2507.15857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the use of diffusion models over autoregressive models in data-constrained settings, focusing on model architecture and performance rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16068",
      "abstract": "Multi-robot coordination has traditionally relied on a mission-specific and expert-driven pipeline, where natural language mission descriptions are manually translated by domain experts into mathematical formulation, algorithm design, and executable code. This conventional process is labor-intensive, inaccessible to non-experts, and inflexible to changes in mission requirements. Here, we propose LAN2CB (Language to Collective Behavior), a novel framework that leverages large language models (LLMs) to streamline and generalize the multi-robot coordination pipeline. LAN2CB transforms natural language (NL) mission descriptions into executable Python code for multi-robot systems through two core modules: (1) Mission Analysis, which parses mission descriptions into behavior trees, and (2) Code Generation, which leverages the behavior tree and a structured knowledge base to generate robot control code. We further introduce a dataset of natural language mission descriptions to support development and benchmarking. Experiments in both simulation and real-world environments demonstrate that LAN2CB enables robust and flexible multi-robot coordination from natural language, significantly reducing manual engineering effort and supporting broad generalization across diverse mission types. Website: https://sites.google.com/view/lan-cb",
      "authors": [
        "Zhehui Huang",
        "Guangyao Shi",
        "Yuwei Wu",
        "Vijay Kumar",
        "and Gaurav S. Sukhatme"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T21:09:15+00:00",
          "link": "https://arxiv.org/abs/2507.16068v1",
          "size": "14445kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:25:12+00:00",
          "link": "https://arxiv.org/abs/2507.16068v2",
          "size": "9849kb",
          "version": "v2"
        }
      ],
      "title": "Compositional Coordination for Multi-Robot Teams with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16068",
        "HTML": "https://arxiv.org/html/2507.16068v2",
        "PDF": "https://arxiv.org/pdf/2507.16068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a dataset of natural language mission descriptions to support the Language to Collective Behavior framework, the main focus is on using LLMs for multi-robot coordination and code generation rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16182",
      "abstract": "We study the societal impact of pseudo-scientific assumptions for predicting the behavior of people in a straightforward application of machine learning to risk prediction in financial lending. This use case also exemplifies the impact of survival bias in loan return prediction. We analyze the models in terms of their accuracy and social cost, showing that the socially optimal model may not imply a significant accuracy loss for this downstream task. Our results are verified for commonly used learning methods and datasets. Our findings also show that there is a natural dynamic when training models that suffer survival bias where accuracy slightly deteriorates, and whose recall and precision improves with time. These results act as an illusion, leading the observer to believe that the system is getting better, when in fact the model is suffering from increasingly more unfairness and survival bias.",
      "authors": [
        "Bruno Scarone",
        "Ricardo Baeza-Yates"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T02:53:13+00:00",
          "link": "https://arxiv.org/abs/2507.16182v1",
          "size": "20868kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T06:01:17+00:00",
          "link": "https://arxiv.org/abs/2507.16182v2",
          "size": "20863kb",
          "version": "v2"
        }
      ],
      "title": "The Impact of Pseudo-Science in Financial Loans Risk Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16182",
        "HTML": "https://arxiv.org/html/2507.16182v2",
        "PDF": "https://arxiv.org/pdf/2507.16182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies the societal impact and accuracy concerning pseudo-scientific assumptions in financial loans risk prediction, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16214",
      "abstract": "Accurate and robust relative pose estimation is crucial for enabling challenging Active Debris Removal (ADR) missions targeting tumbling derelict satellites such as ESA's ENVISAT. This work presents a complete pipeline integrating advanced computer vision techniques with adaptive nonlinear filtering to address this challenge. A Convolutional Neural Network (CNN), enhanced with image preprocessing, detects structural markers (corners) from chaser imagery, whose 2D coordinates are converted to 3D measurements using camera modeling. These measurements are fused within an Unscented Kalman Filter (UKF) framework, selected for its ability to handle nonlinear relative dynamics, to estimate the full relative pose. Key contributions include the integrated system architecture and a dual adaptive strategy within the UKF: dynamic tuning of the measurement noise covariance compensates for varying CNN measurement uncertainty, while adaptive tuning of the process noise covariance, utilizing measurement residual analysis, accounts for unmodeled dynamics or maneuvers online. This dual adaptation enhances robustness against both measurement imperfections and dynamic model uncertainties. The performance of the proposed adaptive integrated system is evaluated through high-fidelity simulations using a realistic ENVISAT model, comparing estimates against ground truth under various conditions, including measurement outages. This comprehensive approach offers an enhanced solution for robust onboard relative navigation, significantly advancing the capabilities required for safe proximity operations during ADR missions.",
      "authors": [
        "Batu Candan and Simone Servadio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T04:13:03+00:00",
          "link": "https://arxiv.org/abs/2507.16214v1",
          "size": "5686kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:02:42+00:00",
          "link": "https://arxiv.org/abs/2507.16214v2",
          "size": "5684kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16214",
        "HTML": "https://arxiv.org/html/2507.16214v2",
        "PDF": "https://arxiv.org/pdf/2507.16214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on adaptive relative pose estimation for satellite missions, utilizing computer vision and neural networks, without mentioning any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16220",
      "abstract": "This study introduces LENS-DF, a novel and comprehensive recipe for training and evaluating audio deepfake detection and temporal localization under complicated and realistic audio conditions. The generation part of the recipe outputs audios from the input dataset with several critical characteristics, such as longer duration, noisy conditions, and containing multiple speakers, in a controllable fashion. The corresponding detection and localization protocol uses models. We conduct experiments based on self-supervised learning front-end and simple back-end. The results indicate that models trained using data generated with LENS-DF consistently outperform those trained via conventional recipes, demonstrating the effectiveness and usefulness of LENS-DF for robust audio deepfake detection and localization. We also conduct ablation studies on the variations introduced, investigating their impact on and relevance to realistic challenges in the field.",
      "authors": [
        "Xuechen Liu",
        "Wanying Ge",
        "Xin Wang",
        "Junichi Yamagishi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Cryptography and Security (cs.CR)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T04:31:13+00:00",
          "link": "https://arxiv.org/abs/2507.16220v1",
          "size": "255kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T01:25:18+00:00",
          "link": "https://arxiv.org/abs/2507.16220v2",
          "size": "255kb",
          "version": "v2"
        }
      ],
      "title": "LENS-DF: Deepfake Detection and Temporal Localization for Long-Form Noisy Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16220",
        "HTML": "https://arxiv.org/html/2507.16220v2",
        "PDF": "https://arxiv.org/pdf/2507.16220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on audio deepfake detection and temporal localization, utilizing a novel recipe for generating training data. It is specialized in audio signal processing and does not make any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16362",
      "abstract": "Chinese License Plate Recognition (CLPR) faces numerous challenges in unconstrained and complex environments, particularly due to perspective distortions caused by various shooting angles and the correction of single-line and double-line license plates. Considering the limited computational resources of edge devices, developing a low-complexity, end-to-end integrated network for both correction and recognition is essential for achieving real-time and efficient deployment. In this work, we propose a lightweight, unified network named LPTR-AFLNet for correcting and recognizing Chinese license plates, which combines a perspective transformation correction module (PTR) with an optimized license plate recognition network, AFLNet. The network leverages the recognition output as a weak supervisory signal to effectively guide the correction process, ensuring accurate perspective distortion correction. To enhance recognition accuracy, we introduce several improvements to LPRNet, including an improved attention module to reduce confusion among similar characters and the use of Focal Loss to address class imbalance during training. Experimental results demonstrate the exceptional performance of LPTR-AFLNet in rectifying perspective distortion and recognizing double-line license plate images, maintaining high recognition accuracy across various challenging scenarios. Moreover, on lower-mid-range GPUs platform, the method runs in less than 10 milliseconds, indicating its practical efficiency and broad applicability.",
      "authors": [
        "Guangzhu Xu",
        "Pengcheng Zuo",
        "Zhi Ke",
        "Bangjun Lei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T08:54:32+00:00",
          "link": "https://arxiv.org/abs/2507.16362v1",
          "size": "3070kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:30:07+00:00",
          "link": "https://arxiv.org/abs/2507.16362v2",
          "size": "3083kb",
          "version": "v2"
        }
      ],
      "title": "LPTR-AFLNet: Lightweight Integrated Chinese License Plate Rectification and Recognition Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16362",
        "HTML": "https://arxiv.org/html/2507.16362v2",
        "PDF": "https://arxiv.org/pdf/2507.16362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the correction and recognition of Chinese license plates using a lightweight network, dealing with perspective distortions in challenging environments. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16473",
      "abstract": "Large Language Models (LLMs) have shown remarkable reasoning ability through explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step textual explanations is computationally expensive and slow. To overcome this, we aim to develop a framework for efficient, implicit reasoning, where the model \"thinks\" in a latent space without generating explicit text for every step. We propose that these latent thoughts can be modeled as temporally-extended abstract actions, or options, within a hierarchical reinforcement learning framework. To effectively learn a diverse library of options as latent embeddings, we first introduce the Variational Markovian Option Critic (VMOC), an off-policy algorithm that uses variational inference within the HiT-MDP framework. To provide a rigorous foundation for using these options as an abstract reasoning space, we extend the theory of continuous MDP homomorphisms. This proves that learning a policy in the simplified, abstract latent space, for which VMOC is suited, preserves the optimality of the solution to the original, complex problem. Finally, we propose a cold-start procedure that leverages supervised fine-tuning (SFT) data to distill human reasoning demonstrations into this latent option space, providing a rich initialization for the model's reasoning capabilities. Extensive experiments demonstrate that our approach achieves strong performance on complex logical reasoning benchmarks and challenging locomotion tasks, validating our framework as a principled method for learning abstract skills for both language and control.",
      "authors": [
        "Chang Li",
        "Yaren Zhang",
        "Haoran Lv",
        "Qiong Cao",
        "Chao Xue",
        "Xiaodong He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T11:22:58+00:00",
          "link": "https://arxiv.org/abs/2507.16473v1",
          "size": "8489kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:23:56+00:00",
          "link": "https://arxiv.org/abs/2507.16473v2",
          "size": "8488kb",
          "version": "v2"
        }
      ],
      "title": "Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16473",
        "HTML": "https://arxiv.org/html/2507.16473v2",
        "PDF": "https://arxiv.org/pdf/2507.16473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The research introduces a framework incorporating supervised fine-tuning (SFT) data to initialize a reasoning model in a latent space. While this touches upon data processing concepts, the focus is more on model reasoning and not primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16632",
      "abstract": "This paper presents Step-Audio 2, an end-to-end multi-modal large language model designed for industry-strength audio understanding and speech conversation. By integrating a latent audio encoder and reasoning-centric reinforcement learning (RL), Step-Audio 2 achieves promising performance in automatic speech recognition (ASR) and audio understanding. To facilitate genuine end-to-end speech conversation, Step-Audio 2 incorporates the generation of discrete audio tokens into language modeling, significantly enhancing its responsiveness to paralinguistic information such as speaking styles and emotions. To effectively leverage the rich textual and acoustic knowledge in real-world data, Step-Audio 2 integrates retrieval-augmented generation (RAG) and is able to call external tools such as web search to mitigate hallucination and audio search to switch timbres. Trained on millions of hours of speech and audio data, Step-Audio 2 delivers intelligence and expressiveness across diverse conversational scenarios. Evaluation results demonstrate that Step-Audio 2 achieves state-of-the-art performance on various audio understanding and conversational benchmarks compared to other open-source and commercial solutions. Please visit https://github.com/stepfun-ai/Step-Audio2 for more information.",
      "authors": [
        "Boyong Wu",
        "Chao Yan",
        "Chen Hu",
        "Cheng Yi",
        "Chengli Feng",
        "Fei Tian",
        "Feiyu Shen",
        "Gang Yu",
        "Haoyang Zhang",
        "Jingbei Li",
        "Mingrui Chen",
        "Peng Liu",
        "Wang You",
        "Xiangyu Tony Zhang",
        "Xingyuan Li",
        "Xuerui Yang",
        "Yayue Deng",
        "Yechang Huang",
        "Yuxin Li",
        "Yuxin Zhang",
        "Zhao You",
        "Brian Li",
        "Changyi Wan",
        "Hanpeng Hu",
        "Jiangjie Zhen",
        "Siyu Chen",
        "Song Yuan",
        "Xuelin Zhang",
        "Yimin Jiang",
        "Yu Zhou",
        "Yuxiang Yang",
        "Bingxin Li",
        "Buyun Ma",
        "Changhe Song",
        "Dongqing Pang",
        "Guoqiang Hu",
        "Haiyang Sun",
        "Kang An",
        "Na Wang",
        "Shuli Gao",
        "Wei Ji",
        "Wen Li",
        "Wen Sun",
        "Xuan Wen",
        "Yong Ren",
        "Yuankai Ma",
        "Yufan Lu",
        "Bin Wang",
        "Bo Li",
        "Changxin Miao",
        "Che Liu",
        "Chen Xu",
        "Dapeng Shi",
        "Dingyuan Hu",
        "Donghang Wu",
        "Enle Liu",
        "Guanzhe Huang",
        "Gulin Yan",
        "Han Zhang",
        "Hao Nie",
        "Haonan Jia",
        "Hongyu Zhou",
        "Jianjian Sun",
        "Jiaoren Wu",
        "Jie Wu",
        "Jie Yang",
        "Jin Yang",
        "Junzhe Lin",
        "Kaixiang Li",
        "Lei Yang",
        "Liying Shi",
        "Li Zhou",
        "Longlong Gu",
        "Ming Li",
        "Mingliang Li",
        "Mingxiao Li",
        "Nan Wu",
        "Qi Han",
        "Qinyuan Tan",
        "Shaoliang Pang",
        "Shengjie Fan",
        "Siqi Liu",
        "Tiancheng Cao",
        "Wanying Lu",
        "Wenqing He",
        "Wuxun Xie",
        "Xu Zhao",
        "Xueqi Li",
        "Yanbo Yu",
        "Yang Yang",
        "Yi Liu",
        "Yifan Lu",
        "Yilei Wang",
        "Yuanhao Ding",
        "Yuanwei Liang",
        "Yuanwei Lu",
        "Yuchu Luo",
        "Yuhe Yin",
        "Yumeng Zhan",
        "Yuxiang Zhang",
        "Zidong Yang",
        "Zixin Zhang",
        "Binxing Jiao",
        "Daxin Jiang",
        "Heung-Yeung Shum",
        "Jiansheng Chen",
        "Jing Li",
        "Xiangyu Zhang",
        "Yibo Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T14:23:55+00:00",
          "link": "https://arxiv.org/abs/2507.16632v1",
          "size": "241kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:13:12+00:00",
          "link": "https://arxiv.org/abs/2507.16632v2",
          "size": "559kb",
          "version": "v2"
        }
      ],
      "title": "Step-Audio 2 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16632",
        "HTML": "https://arxiv.org/html/2507.16632v2",
        "PDF": "https://arxiv.org/pdf/2507.16632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a multi-modal audio understanding model, Step-Audio 2, focusing on audio and speech processing. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16680",
      "abstract": "Semantic communications focus on prioritizing the understanding of the meaning behind transmitted data and ensuring the successful completion of tasks that motivate the exchange of information. However, when devices rely on different languages, logic, or internal representations, semantic mismatches may occur, potentially hindering mutual understanding. This paper introduces a novel approach to addressing latent space misalignment in semantic communications, exploiting multiple-input multiple-output (MIMO) communications. Specifically, our method learns a MIMO precoder/decoder pair that jointly performs latent space compression and semantic channel equalization, mitigating both semantic mismatches and physical channel impairments. We explore two solutions: (i) a linear model, optimized by solving a biconvex optimization problem via the alternating direction method of multipliers (ADMM); (ii) a neural network-based model, which learns semantic MIMO precoder/decoder under transmission power budget and complexity constraints. Numerical results demonstrate the effectiveness of the proposed approach in a goal-oriented semantic communication scenario, illustrating the main trade-offs between accuracy, communication burden, and complexity of the solutions.",
      "authors": [
        "Mario Edoardo Pandolfo",
        "Simone Fiorellino",
        "Emilio Calvanese Strinati",
        "Paolo Di Lorenzo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T15:16:18+00:00",
          "link": "https://arxiv.org/abs/2507.16680v1",
          "size": "11048kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T12:38:41+00:00",
          "link": "https://arxiv.org/abs/2507.16680v2",
          "size": "11048kb",
          "version": "v2"
        }
      ],
      "title": "Latent Space Alignment for AI-Native MIMO Semantic Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16680",
        "HTML": "https://arxiv.org/html/2507.16680v2",
        "PDF": "https://arxiv.org/pdf/2507.16680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on semantic communications and MIMO systems, without addressing any issues related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16761",
      "abstract": "Faithfulness and interpretability are essential for deploying deep neural networks (DNNs) in safety-critical domains such as medical imaging. B-cos networks offer a promising solution by replacing standard linear layers with a weight-input alignment mechanism, producing inherently interpretable, class-specific explanations without post-hoc methods. While maintaining diagnostic performance competitive with state-of-the-art DNNs, standard B-cos models suffer from severe aliasing artifacts in their explanation maps, making them unsuitable for clinical use where clarity is essential. In this work, we address these limitations by introducing anti-aliasing strategies using FLCPooling (FLC) and BlurPool (BP) to significantly improve explanation quality. Our experiments on chest X-ray datasets demonstrate that the modified $\\text{B-cos}_\\text{FLC}$ and $\\text{B-cos}_\\text{BP}$ preserve strong predictive performance while providing faithful and artifact-free explanations suitable for clinical application in multi-class and multi-label settings. Code available at: GitHub repository (url: https://github.com/mkleinma/B-cos-medical-paper).",
      "authors": [
        "Marcel Kleinmann",
        "Shashank Agnihotri",
        "Margret Keuper"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T16:56:02+00:00",
          "link": "https://arxiv.org/abs/2507.16761v1",
          "size": "12706kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:58:44+00:00",
          "link": "https://arxiv.org/abs/2507.16761v2",
          "size": "12707kb",
          "version": "v2"
        }
      ],
      "title": "Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16761",
        "HTML": "https://arxiv.org/html/2507.16761v2",
        "PDF": "https://arxiv.org/pdf/2507.16761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is on improving interpretability in chest X-ray diagnosis using B-cos Networks, which does not involve LLM training data processing or contribute to dataset engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16802",
      "abstract": "Large Language Models (LLMs) exhibit considerable promise in financial applications; however, prevailing models frequently demonstrate limitations when confronted with scenarios that necessitate sophisticated reasoning capabilities, stringent trustworthiness criteria, and efficient adaptation to domain-specific requirements. We introduce the Agentar-Fin-R1 series of financial large language models (8B and 32B parameters), specifically engineered based on the Qwen3 foundation model to enhance reasoning capabilities, reliability, and domain specialization for financial applications. Our optimization approach integrates a high-quality, systematic financial task label system with a comprehensive multi-layered trustworthiness assurance framework. This framework encompasses high-quality trustworthy knowledge engineering, multi-agent trustworthy data synthesis, and rigorous data validation governance. Through label-guided automated difficulty-aware optimization, tow-stage training pipeline, and dynamic attribution systems, we achieve substantial improvements in training efficiency. Our models undergo comprehensive evaluation on mainstream financial benchmarks including Fineva, FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500 and GPQA-diamond. To thoroughly assess real-world deployment capabilities, we innovatively propose the Finova evaluation benchmark, which focuses on agent-level financial reasoning and compliance verification. Experimental results demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art performance on financial tasks but also exhibits exceptional general reasoning capabilities, validating its effectiveness as a trustworthy solution for high-stakes financial applications. The Finova bench is available at https://github.com/antgroup/Finova.",
      "authors": [
        "Yanjun Zheng",
        "Xiyang Du",
        "Longfei Liao",
        "Xiaoke Zhao",
        "Zhaowen Zhou",
        "Jingze Song",
        "Bo Zhang",
        "Jiawei Liu",
        "Xiang Qi",
        "Zhe Li",
        "Zhiqiang Zhang",
        "Wei Wang and Peng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T17:52:16+00:00",
          "link": "https://arxiv.org/abs/2507.16802v1",
          "size": "1913kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T17:47:01+00:00",
          "link": "https://arxiv.org/abs/2507.16802v2",
          "size": "1986kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T16:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.16802v3",
          "size": "1964kb",
          "version": "v3"
        }
      ],
      "title": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16802",
        "HTML": "https://arxiv.org/html/2507.16802v3",
        "PDF": "https://arxiv.org/pdf/2507.16802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper details the development of financial LLMs and touches on data synthesis and validation, its primary focus is on model architecture and evaluation, with only a brief mention of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16809",
      "abstract": "We propose LingBench++, a linguistically-informed benchmark and reasoning framework designed to evaluate large language models (LLMs) on complex linguistic tasks inspired by the International Linguistics Olympiad (IOL). Unlike prior benchmarks that focus solely on final answer accuracy, LingBench++ provides structured reasoning traces, stepwise evaluation protocols, and rich typological metadata across over 90 low-resource and cross-cultural languages. We further develop a multi-agent architecture integrating grammatical knowledge retrieval, tool-augmented reasoning, and deliberate hypothesis testing. Through systematic comparisons of baseline and our proposed agentic models, we demonstrate that models equipped with external knowledge sources and iterative reasoning outperform single-pass approaches in both accuracy and interpretability. LingBench++ offers a comprehensive foundation for advancing linguistically grounded, culturally informed, and cognitively plausible reasoning in LLMs.",
      "authors": [
        "Da-Chen Lian",
        "Ri-Sheng Huang",
        "Pin-Er Chen",
        "Chunki Lim",
        "You-Kuan Lin",
        "Guan-Yu Tseng",
        "Zi-Cheng Yang",
        "Zhen-Yu Lin",
        "Pin-Cheng Chen",
        "Shu-Kai Hsieh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T17:57:44+00:00",
          "link": "https://arxiv.org/abs/2507.16809v1",
          "size": "2883kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:51:13+00:00",
          "link": "https://arxiv.org/abs/2507.16809v2",
          "size": "2886kb",
          "version": "v2"
        }
      ],
      "title": "LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16809",
        "PDF": "https://arxiv.org/pdf/2507.16809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a linguistically-informed benchmark for evaluating LLMs, which partially involves data processing by structuring datasets and evaluating linguistic reasoning, but is primarily focused on model evaluation rather than data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16859",
      "abstract": "Fatigue detection plays a critical role in safety-critical applications such as aviation, mining, and long-haul transport. However, most existing methods rely on high-end sensors and controlled environments, limiting their applicability in real world settings. This paper formally defines a practical yet underexplored problem setting for real world fatigue detection, where systems operating with context-appropriate sensors aim to leverage knowledge from differently instrumented sources including those using impractical sensors deployed in controlled environments. To tackle this challenge, we propose a heterogeneous and multi-source fatigue detection framework that adaptively utilizes the available modalities in the target domain while benefiting from the diverse configurations present in source domains. Our experiments, conducted using a realistic field-deployed sensor setup and two publicly available datasets, demonstrate the practicality, robustness, and improved generalization of our approach, paving the practical way for effective fatigue monitoring in sensor-constrained scenarios.",
      "authors": [
        "Luobin Cui",
        "Yanlai Wu",
        "Tang Ying and Weikai Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:22:18+00:00",
          "link": "https://arxiv.org/abs/2507.16859v1",
          "size": "262kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T14:41:42+00:00",
          "link": "https://arxiv.org/abs/2507.16859v2",
          "size": "1879kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging multi-source and heterogeneous signals for fatigue detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16859",
        "HTML": "https://arxiv.org/html/2507.16859v2",
        "PDF": "https://arxiv.org/pdf/2507.16859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study discusses a heterogeneous and multi-source framework for fatigue detection using sensor data, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17248",
      "abstract": "Interacting with real-world objects in Mixed Reality (MR) often proves difficult when they are crowded, distant, or partially occluded, hindering straightforward selection and manipulation. We observe that these difficulties stem from performing interaction directly on physical objects, where input is tightly coupled to their physical constraints. Our key insight is to decouple interaction from these constraints by introducing proxies-abstract representations of real-world objects. We embody this concept in Reality Proxy, a system that seamlessly shifts interaction targets from physical objects to their proxies during selection. Beyond facilitating basic selection, Reality Proxy uses AI to enrich proxies with semantic attributes and hierarchical spatial relationships of their corresponding physical objects, enabling novel and previously cumbersome interactions in MR - such as skimming, attribute-based filtering, navigating nested groups, and complex multi object selections - all without requiring new gestures or menu systems. We demonstrate Reality Proxy's versatility across diverse scenarios, including office information retrieval, large-scale spatial navigation, and multi-drone control. An expert evaluation suggests the system's utility and usability, suggesting that proxy-based abstractions offer a powerful and generalizable interaction paradigm for future MR systems.",
      "authors": [
        "Xiaoan Liu",
        "Difan Jia",
        "Xianhao Carton Liu",
        "Mar Gonzalez-Franco",
        "Chen Zhu-Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:34:58+00:00",
          "link": "https://arxiv.org/abs/2507.17248v1",
          "size": "15905kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:13:36+00:00",
          "link": "https://arxiv.org/abs/2507.17248v2",
          "size": "18165kb",
          "version": "v2"
        }
      ],
      "title": "Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17248",
        "HTML": "https://arxiv.org/html/2507.17248v2",
        "PDF": "https://arxiv.org/pdf/2507.17248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents Reality Proxy, a system for interacting with real-world objects in MR using proxies, which does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17268",
      "abstract": "Polarization images facilitate image enhancement and 3D reconstruction tasks, but the limited accessibility of polarization cameras hinders their broader application. This gap drives the need for synthesizing photorealistic polarization images. The existing polarization simulator Mitsuba relies on a parametric polarization image formation model and requires extensive 3D assets covering shape and PBR materials, preventing it from generating large-scale photorealistic images. To address this problem, we propose PolarAnything, capable of synthesizing polarization images from a single RGB input with both photorealism and physical accuracy, eliminating the dependency on 3D asset collections. Drawing inspiration from the zero-shot performance of pretrained diffusion models, we introduce a diffusion-based generative framework with an effective representation strategy that preserves the fidelity of polarization properties. Experiments show that our model generates high-quality polarization images and supports downstream tasks like shape from polarization.",
      "authors": [
        "Kailong Zhang",
        "Youwei Lyu",
        "Heng Guo",
        "Si Li",
        "Zhanyu Ma",
        "Boxin Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:09:10+00:00",
          "link": "https://arxiv.org/abs/2507.17268v1",
          "size": "20195kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:33:14+00:00",
          "link": "https://arxiv.org/abs/2507.17268v2",
          "size": "20195kb",
          "version": "v2"
        }
      ],
      "title": "PolarAnything: Diffusion-based Polarimetric Image Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17268",
        "HTML": "https://arxiv.org/html/2507.17268v2",
        "PDF": "https://arxiv.org/pdf/2507.17268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PolarAnything focuses on synthesizing polarization images using diffusion-based techniques, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17289",
      "abstract": "This paper presents Compliance Brain Assistant (CBA), a conversational, agentic AI assistant designed to boost the efficiency of daily compliance tasks for personnel in enterprise environments. To strike a good balance between response quality and latency, we design a user query router that can intelligently choose between (i) FastTrack mode: to handle simple requests that only need additional relevant context retrieved from knowledge corpora; and (ii) FullAgentic mode: to handle complicated requests that need composite actions and tool invocations to proactively discover context across various compliance artifacts, and/or involving other APIs/models for accommodating requests. A typical example would be to start with a user query, use its description to find a specific entity and then use the entity's information to query other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on various real-world privacy/compliance-related queries targeting various personas. We found that CBA substantially improved upon the vanilla LLM's performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full routing-based design against the `fast-track only` and `full-agentic` modes and found that it had a better average match-rate and pass-rate while keeping the run-time approximately the same. This finding validated our hypothesis that the routing mechanism leads to a good trade-off between the two worlds.",
      "authors": [
        "Shitong Zhu",
        "Chenhao Fang",
        "Derek Larson",
        "Neel Reddy Pochareddy",
        "Rajeev Rao",
        "Sophie Zeng",
        "Yanqing Peng",
        "Wendy Summer",
        "Alex Goncalves",
        "Arya Pudota",
        "Herv\\'e Robert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:51:10+00:00",
          "link": "https://arxiv.org/abs/2507.17289v1",
          "size": "443kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:50:13+00:00",
          "link": "https://arxiv.org/abs/2507.17289v2",
          "size": "443kb",
          "version": "v2"
        }
      ],
      "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17289",
        "HTML": "https://arxiv.org/html/2507.17289v2",
        "PDF": "https://arxiv.org/pdf/2507.17289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Compliance Brain Assistant, an AI system for enterprise compliance tasks, focusing on AI response quality and latency, without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17311",
      "abstract": "Modern Earth science is at an inflection point. The vast, fragmented, and complex nature of Earth system data, coupled with increasingly sophisticated analytical demands, creates a significant bottleneck for rapid scientific discovery. Here we introduce EarthLink, the first AI agent designed as an interactive copilot for Earth scientists. It automates the end-to-end research workflow, from planning and code generation to multi-scenario analysis. Unlike static diagnostic tools, EarthLink can learn from user interaction, continuously refining its capabilities through a dynamic feedback loop. We validated its performance on a number of core scientific tasks of climate change, ranging from model-observation comparisons to the diagnosis of complex phenomena. In a multi-expert evaluation, EarthLink produced scientifically sound analyses and demonstrated an analytical competency that was rated as comparable to specific aspects of a human junior researcher's workflow. Additionally, its transparent, auditable workflows and natural language interface empower scientists to shift from laborious manual execution to strategic oversight and hypothesis generation. EarthLink marks a pivotal step towards an efficient, trustworthy, and collaborative paradigm for Earth system research in an era of accelerating global change. The system is accessible at our website https://earthlink.intern-ai.org.cn.",
      "authors": [
        "Zijie Guo",
        "Jiong Wang",
        "Xiaoyu Yue",
        "Wangxu Wei",
        "Zhe Jiang",
        "Wanghan Xu",
        "Ben Fei",
        "Wenlong Zhang",
        "Xinyu Gu",
        "Lijing Cheng",
        "Jing-Jia Luo",
        "Chao Li",
        "Yaqiang Wang",
        "Tao Chen",
        "Wanli Ouyang",
        "Fenghua Ling",
        "Lei Bai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:29:25+00:00",
          "link": "https://arxiv.org/abs/2507.17311v1",
          "size": "6344kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:12:15+00:00",
          "link": "https://arxiv.org/abs/2507.17311v2",
          "size": "6345kb",
          "version": "v2"
        }
      ],
      "title": "EarthLink: A Self-Evolving AI Agent for Climate Science",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17311",
        "HTML": "https://arxiv.org/html/2507.17311v2",
        "PDF": "https://arxiv.org/pdf/2507.17311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on EarthLink, an AI agent aiding Earth scientists, and does not address any aspect of LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17324",
      "abstract": "Virtual Reality (VR) has emerged as a transformative technology across industries, yet its security weaknesses, including vulnerabilities, are underinvestigated. This study investigates 334 VR projects hosted on GitHub, examining 1,681 software security weaknesses to understand: what types of weaknesses are prevalent in VR software; when and how weaknesses are introduced; how long they have survived; and how they have been removed. Due to the limited availability of VR software security weaknesses in public databases (e.g., the National Vulnerability Database or NVD), we prepare the first systematic dataset of VR software security weaknesses by introducing a novel framework to collect such weaknesses from GitHub commit data. Our empirical study on the dataset leads to useful insights, including: (i) VR weaknesses are heavily skewed toward user interface weaknesses, followed by resource-related weaknesses; (ii) VR development tools pose higher security risks than VR applications; (iii) VR security weaknesses are often introduced at the VR software birth time.",
      "authors": [
        "Yifan Xu",
        "Jinfu Chen",
        "Zhenyu Qi",
        "Huashan Chen",
        "Junyi Wang",
        "Pengfei Hu",
        "Feng Liu",
        "Sen He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:45:53+00:00",
          "link": "https://arxiv.org/abs/2507.17324v1",
          "size": "5265kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T03:05:47+00:00",
          "link": "https://arxiv.org/abs/2507.17324v2",
          "size": "5265kb",
          "version": "v2"
        }
      ],
      "title": "An Empirical Study on Virtual Reality Software Security Weaknesses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17324",
        "HTML": "https://arxiv.org/html/2507.17324v2",
        "PDF": "https://arxiv.org/pdf/2507.17324"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines security weaknesses in VR software, providing a dataset of security weaknesses. It does not contribute to LLM training data processing or related dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17332",
      "abstract": "The misaligned human texture across different human parts is one of the main limitations of existing 3D human reconstruction methods. Each human part, such as a jacket or pants, should maintain a distinct texture without blending into others. The structural coherence of human parts serves as a crucial cue to infer human textures in the invisible regions of a single image. However, most existing 3D human reconstruction methods do not explicitly exploit such part segmentation priors, leading to misaligned textures in their reconstructions. In this regard, we present PARTE, which utilizes 3D human part information as a key guide to reconstruct 3D human textures. Our framework comprises two core components. First, to infer 3D human part information from a single image, we propose a 3D part segmentation module (PartSegmenter) that initially reconstructs a textureless human surface and predicts human part labels based on the textureless surface. Second, to incorporate part information into texture reconstruction, we introduce a part-guided texturing module (PartTexturer), which acquires prior knowledge from a pre-trained image generation network on texture alignment of human parts. Extensive experiments demonstrate that our framework achieves state-of-the-art quality in 3D human reconstruction. The project page is available at https://hygenie1228.github.io/PARTE/.",
      "authors": [
        "Hyeongjin Nam",
        "Donghwan Kim",
        "Gyeongsik Moon",
        "Kyoung Mu Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:00:13+00:00",
          "link": "https://arxiv.org/abs/2507.17332v1",
          "size": "24474kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T02:16:29+00:00",
          "link": "https://arxiv.org/abs/2507.17332v2",
          "size": "24474kb",
          "version": "v2"
        }
      ],
      "title": "PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17332",
        "HTML": "https://arxiv.org/html/2507.17332v2",
        "PDF": "https://arxiv.org/pdf/2507.17332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for 3D human reconstruction using part-guided texturing. It does not contribute to LLM training data processing or involve related datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17347",
      "abstract": "In the field of food image processing, efficient semantic segmentation techniques are crucial for industrial applications. However, existing large-scale Transformer-based models (such as FoodSAM) face challenges in meeting practical deploymentrequirements due to their massive parameter counts and high computational resource demands. This paper introduces TUNable Adapter module (Swin-TUNA), a Parameter Efficient Fine-Tuning (PEFT) method that integrates multiscale trainable adapters into the Swin Transformer architecture, achieving high-performance food image segmentation by updating only 4% of the parameters. The core innovation of Swin-TUNA lies in its hierarchical feature adaptation mechanism: it designs separable convolutions in depth and dimensional mappings of varying scales to address the differences in features between shallow and deep networks, combined with a dynamic balancing strategy for tasks-agnostic and task-specific features. Experiments demonstrate that this method achieves mIoU of 50.56% and 74.94% on the FoodSeg103 and UECFoodPix Complete datasets, respectively, surpassing the fully parameterized FoodSAM model while reducing the parameter count by 98.7% (to only 8.13M). Furthermore, Swin-TUNA exhibits faster convergence and stronger generalization capabilities in low-data scenarios, providing an efficient solution for assembling lightweight food image.",
      "authors": [
        "Haotian Chen",
        "Zhiyong Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:28:25+00:00",
          "link": "https://arxiv.org/abs/2507.17347v1",
          "size": "2271kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T12:46:21+00:00",
          "link": "https://arxiv.org/abs/2507.17347v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17347",
        "PDF": "https://arxiv.org/pdf/2507.17347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a method for food image segmentation using parameter-efficient tuning. It does not pertain to LLM training data processing or any associated dataset techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17348",
      "abstract": "An ordinal classification (OC) problem corresponds to a special type of classification characterised by the presence of a natural order relationship among the classes. This type of problem can be found in a number of real-world applications, motivating the design and development of many ordinal methodologies over the last years. However, it is important to highlight that the development of the OC field suffers from one main disadvantage: the lack of a comprehensive set of datasets on which novel approaches to the literature have to be benchmarked. In order to approach this objective, this manuscript from the University of C\\'ordoba (UCO), which have previous experience on the OC field, provides the literature with a publicly available repository of tabular data for a robust validation of novel OC approaches, namely TOC-UCO (Tabular Ordinal Classification repository of the UCO). Specifically, this repository includes a set of $46$ tabular ordinal datasets, preprocessed under a common framework and ensured to have a reasonable number of patterns and an appropriate class distribution. We also provide the sources and preprocessing steps of each dataset, along with details on how to benchmark a novel approach using the TOC-UCO repository. For this, indices for $30$ different randomised train-test partitions are provided to facilitate the reproducibility of the experiments.",
      "authors": [
        "Rafael Ayll\\'on-Gavil\\'an",
        "David Guijo-Rubio",
        "Antonio Manuel G\\'omez-Orellana",
        "Francisco B\\'erchez-Moreno",
        "V\\'ictor Manuel Vargas-Yun and Pedro A. Guti\\'errez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:28:52+00:00",
          "link": "https://arxiv.org/abs/2507.17348v1",
          "size": "272kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T06:38:39+00:00",
          "link": "https://arxiv.org/abs/2507.17348v2",
          "size": "272kb",
          "version": "v2"
        }
      ],
      "title": "TOC-UCO: a comprehensive repository of tabular ordinal classification datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17348",
        "HTML": "https://arxiv.org/html/2507.17348v2",
        "PDF": "https://arxiv.org/pdf/2507.17348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a repository of tabular ordinal classification datasets. It is unrelated to LLM training data processing or pretraining or fine-tuning datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17432",
      "abstract": "In the Wyner-Ziv source coding problem, a source $X$ has to be encoded while the decoder has access to side information $Y$. This paper investigates the indirect setup, in which a latent source $S$, unobserved by both the encoder and the decoder, must also be reconstructed at the decoder. This scenario is increasingly relevant in the context of goal-oriented communications, where $S$ can represent semantic information obtained from $X$. This paper derives the indirect Wyner-Ziv rate-distortion function in asymptotic regime and provides an achievable region in finite block-length. Furthermore, a Blahut-Arimoto algorithm tailored for the indirect Wyner-Ziv setup, is proposed. This algorithm is then used to give a numerical evaluation of the achievable indirect rate-distortion region when $S$ is treated as a classification label.",
      "authors": [
        "Jiahui Wei",
        "Philippe Mary",
        "Elsa Dupraz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:42:58+00:00",
          "link": "https://arxiv.org/abs/2507.17432v1",
          "size": "186kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:10:03+00:00",
          "link": "https://arxiv.org/abs/2507.17432v2",
          "size": "191kb",
          "version": "v2"
        }
      ],
      "title": "Non-Asymptotic Achievable Rate-Distortion Region for Indirect Wyner-Ziv Source Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17432",
        "HTML": "https://arxiv.org/html/2507.17432v2",
        "PDF": "https://arxiv.org/pdf/2507.17432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a theoretical framework and algorithm related to the Wyner-Ziv source coding problem, which is not related to LLM training data processing or data operations for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17519",
      "abstract": "Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial software typically treat a Region of Interest (RoI) only as a 2D plane, ignoring important3D structure characteristics. This leads to incomplete 3Dreconstructions, especially around occluded or vertical surfaces. In this paper, we propose a modular algorithm that can extend commercial two-dimensional path planners to facilitate terrain-aware planning by adjusting altitude and camera orientations. To demonstrate it, we extend the well-known DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm and produce DARP-3D. We present simulation results in multiple 3D environments and a real-world flight test using DJI hardware. Compared to baseline, our approach consistently captures improved 3D reconstructions, particularly in areas with significant vertical features. An open-source implementation of the algorithm is available here:https://github.com/konskara/TerraPlan",
      "authors": [
        "Kostas Karakontis",
        "Thanos Petsanis",
        "Athanasios Ch. Kapoutsis",
        "Pavlos Ch. Kapoutsis",
        "Elias B. Kosmatopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:55:37+00:00",
          "link": "https://arxiv.org/abs/2507.17519v1",
          "size": "3134kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:45:43+00:00",
          "link": "https://arxiv.org/abs/2507.17519v2",
          "size": "3134kb",
          "version": "v2"
        }
      ],
      "title": "Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17519",
        "HTML": "https://arxiv.org/html/2507.17519v2",
        "PDF": "https://arxiv.org/pdf/2507.17519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on terrain-aware path planning for UAVs, which does not relate to LLM training data processing or any stages of language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17527",
      "abstract": "Simultaneous Interpretation (SI) represents one of the most daunting frontiers in the translation industry, with product-level automatic systems long plagued by intractable challenges: subpar transcription and translation quality, lack of real-time speech generation, multi-speaker confusion, and translated speech inflation, especially in long-form discourses. In this study, we introduce Seed-LiveInterpret 2.0, an end-to-end SI model that delivers high-fidelity, ultra-low-latency speech-to-speech generation with voice cloning capabilities. As a fully operational product-level solution, Seed-LiveInterpret 2.0 tackles these challenges head-on through our novel duplex speech-to-speech understanding-generating framework. Experimental results demonstrate that through large-scale pretraining and reinforcement learning, the model achieves a significantly better balance between translation accuracy and latency, validated by human interpreters to exceed 70% correctness in complex scenarios. Notably, Seed-LiveInterpret 2.0 outperforms commercial SI solutions by significant margins in translation quality, while slashing the average latency of cloned speech from nearly 10 seconds to a near-real-time 3 seconds, which is around a near 70% reduction that drastically enhances practical usability.",
      "authors": [
        "Shanbo Cheng",
        "Yu Bao",
        "Zhichao Huang",
        "Yu Lu",
        "Ningxin Peng",
        "Lu Xu",
        "Runsheng Yu",
        "Rong Cao",
        "Ting Han",
        "Zeyang Li",
        "Sitong Liu",
        "Shengtao Ma",
        "Shiguang Pan",
        "Jiongchen Xiao",
        "Nuo Xu",
        "Meng Yang",
        "Rong Ye",
        "Yiming Yu",
        "Ruofei Zhang",
        "Wanyi Zhang",
        "Wenhao Zhu",
        "Liehao Zou",
        "Lu Lu",
        "Yuxuan Wang",
        "Yonghui Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:07:41+00:00",
          "link": "https://arxiv.org/abs/2507.17527v1",
          "size": "1600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:11:00+00:00",
          "link": "https://arxiv.org/abs/2507.17527v2",
          "size": "1600kb",
          "version": "v2"
        }
      ],
      "title": "Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17527",
        "HTML": "https://arxiv.org/html/2507.17527v2",
        "PDF": "https://arxiv.org/pdf/2507.17527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper on Seed-LiveInterpret 2.0 focuses on simultaneous interpretation and speech-to-speech translation enhancements but mentions large-scale pretraining. However, it does not primarily address data processing aspects relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17596",
      "abstract": "While end-to-end autonomous driving models show promising results, their practical deployment is often hindered by large model sizes, a reliance on expensive LiDAR sensors and computationally intensive BEV feature representations. This limits their scalability, especially for mass-market vehicles equipped only with cameras. To address these challenges, we propose PRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving architecture operates using only camera data, without explicit BEV representation and forgoing the need for LiDAR. PRIX leverages a visual feature extractor coupled with a generative planning head to predict safe trajectories from raw pixel inputs directly. A core component of our architecture is the Context-aware Recalibration Transformer (CaRT), a novel module designed to effectively enhance multi-level visual features for more robust planning. We demonstrate through comprehensive experiments that PRIX achieves state-of-the-art performance on the NavSim and nuScenes benchmarks, matching the capabilities of larger, multimodal diffusion planners while being significantly more efficient in terms of inference speed and model size, making it a practical solution for real-world deployment. Our work is open-source and the code will be at https://maxiuw.github.io/prix.",
      "authors": [
        "Maciej K. Wozniak",
        "Lianhang Liu",
        "Yixi Cai",
        "Patric Jensfelt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:28:23+00:00",
          "link": "https://arxiv.org/abs/2507.17596v1",
          "size": "8181kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:04:42+00:00",
          "link": "https://arxiv.org/abs/2507.17596v2",
          "size": "8181kb",
          "version": "v2"
        }
      ],
      "title": "PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17596",
        "HTML": "https://arxiv.org/html/2507.17596v2",
        "PDF": "https://arxiv.org/pdf/2507.17596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PRIX discusses an architecture for autonomous driving using raw pixels for planning, with no focus on training data processing methods relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17702",
      "abstract": "Mixture-of-Experts (MoE) has become a dominant architecture for scaling Large Language Models (LLMs) efficiently by decoupling total parameters from computational cost. However, this decoupling creates a critical challenge: predicting the model capacity of a given MoE configurations (e.g., expert activation ratio and granularity) remains an unresolved problem. To address this gap, we introduce Efficiency Leverage (EL), a metric quantifying the computational advantage of an MoE model over a dense equivalent. We conduct a large-scale empirical study, training over 300 models up to 28B parameters, to systematically investigate the relationship between MoE architectural configurations and EL. Our findings reveal that EL is primarily driven by the expert activation ratio and the total compute budget, both following predictable power laws, while expert granularity acts as a non-linear modulator with a clear optimal range. We integrate these discoveries into a unified scaling law that accurately predicts the EL of an MoE architecture based on its configuration. To validate our derived scaling laws, we designed and trained Ling-mini-beta, a pilot model for Ling-2.0 series with only 0.85B active parameters, alongside a 6.1B dense model for comparison. When trained on an identical 1T high-quality token dataset, Ling-mini-beta matched the performance of the 6.1B dense model while consuming over 7x fewer computational resources, thereby confirming the accuracy of our scaling laws. This work provides a principled and empirically-grounded foundation for the scaling of efficient MoE models.",
      "authors": [
        "Changxin Tian",
        "Kunlong Chen",
        "Jia Liu",
        "Ziqi Liu",
        "Zhiqiang Zhang",
        "Jun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:10:23+00:00",
          "link": "https://arxiv.org/abs/2507.17702v1",
          "size": "7017kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:27:09+00:00",
          "link": "https://arxiv.org/abs/2507.17702v2",
          "size": "6963kb",
          "version": "v2"
        }
      ],
      "title": "Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17702",
        "HTML": "https://arxiv.org/html/2507.17702v2",
        "PDF": "https://arxiv.org/pdf/2507.17702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper investigates architecture efficiency for MoE language models, it does not make contributions to LLM training data processing such as data engineering or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17727",
      "abstract": "State-of-the-art visual under-canopy navigation methods are designed with deep learning-based perception models to distinguish traversable space from crop rows. While these models have demonstrated successful performance, they require large amounts of training data to ensure reliability in real-world field deployment. However, data collection is costly, demanding significant human resources for in-field sampling and annotation. To address this challenge, various data augmentation techniques are commonly employed during model training, such as color jittering, Gaussian blur, and horizontal flip, to diversify training data and enhance model robustness. In this paper, we hypothesize that utilizing only these augmentation techniques may lead to suboptimal performance, particularly in complex under-canopy environments with frequent occlusions, debris, and non-uniform spacing of crops. Instead, we propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut) which masks random regions out in input images that are spatially distributed around crop rows on the sides to encourage trained models to capture high-level contextual features even when fine-grained information is obstructed. Our extensive experiments with a public cornfield dataset demonstrate that masking-based augmentations are effective for simulating occlusions and significantly improving robustness in semantic keypoint predictions for visual navigation. In particular, we show that biasing the mask distribution toward crop rows in CA-Cut is critical for enhancing both prediction accuracy and generalizability across diverse environments achieving up to a 36.9% reduction in prediction error. In addition, we conduct ablation studies to determine the number of masks, the size of each mask, and the spatial distribution of masks to maximize overall performance.",
      "authors": [
        "Robel Mamo",
        "Taeyeong Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:41:55+00:00",
          "link": "https://arxiv.org/abs/2507.17727v1",
          "size": "3258kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T13:55:49+00:00",
          "link": "https://arxiv.org/abs/2507.17727v2",
          "size": "3258kb",
          "version": "v2"
        }
      ],
      "title": "CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17727",
        "HTML": "https://arxiv.org/html/2507.17727v2",
        "PDF": "https://arxiv.org/pdf/2507.17727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel data augmentation method for visual navigation in agriculture, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.10160",
      "abstract": "We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets, and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate accordingly. Our non-asymptotic excess risk bounds demonstrate that our estimator adapts effectively to both the structure of the target distribution and the covariate shift. This adaptation is quantified through a notion of effective sample size that reflects the value of labeled source data for the target regression task. Our estimator achieves the minimax optimal error rate up to a polylogarithmic factor, and we find that using pseudo-labels for model selection does not significantly hinder performance.",
      "authors": [
        "Kaizheng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-20T18:46:12+00:00",
          "link": "https://arxiv.org/abs/2302.10160v1",
          "size": "93kb",
          "version": "v1"
        },
        {
          "date": "2023-03-15T00:14:26+00:00",
          "link": "https://arxiv.org/abs/2302.10160v2",
          "size": "632kb",
          "version": "v2"
        },
        {
          "date": "2024-11-08T17:05:09+00:00",
          "link": "https://arxiv.org/abs/2302.10160v3",
          "size": "144kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T17:59:49+00:00",
          "link": "https://arxiv.org/abs/2302.10160v4",
          "size": "124kb",
          "version": "v4"
        }
      ],
      "title": "Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.10160",
        "HTML": "https://arxiv.org/html/2302.10160v4",
        "PDF": "https://arxiv.org/pdf/2302.10160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses kernel ridge regression under covariate shift, focusing on model adaptation rather than any data processing task specific to LLMs or the development of language model datasets."
      },
      "tasks": [
        "Imputation",
        "Missing Labels",
        "Model Selection",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/kw2934/krr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.01256",
      "abstract": "Differentially private stochastic gradient descent privatizes model training by injecting noise into each iteration, where the noise magnitude increases with the number of model parameters. Recent works suggest that we can reduce the noise by leveraging public data for private machine learning, by projecting gradients onto a subspace prescribed by the public data. However, given a choice of public datasets, it is not a priori clear which one may be most appropriate for the private task. We give an algorithm for selecting a public dataset by measuring a low-dimensional subspace distance between gradients of the public and private examples. We provide theoretical analysis demonstrating that the excess risk scales with this subspace distance. This distance is easy to compute and robust to modifications in the setting. Empirical evaluation shows that trained model accuracy is monotone in this distance.",
      "authors": [
        "Xin Gu",
        "Gautam Kamath",
        "Zhiwei Steven Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-02T13:36:28+00:00",
          "link": "https://arxiv.org/abs/2303.01256v1",
          "size": "2823kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:17:16+00:00",
          "link": "https://arxiv.org/abs/2303.01256v2",
          "size": "1110kb",
          "version": "v2"
        }
      ],
      "title": "Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.01256",
        "PDF": "https://arxiv.org/pdf/2303.01256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes an algorithm for selecting public datasets based on subspace distance, which could be useful for dataset selection. However, it primarily focuses on the context of privacy in machine learning rather than directly contributing to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2304.00945",
      "abstract": "We offer a new structural basis for the theory of 3-connected graphs, providing a unique decomposition of every such graph into parts that are either quasi 4-connected, wheels, or thickened $K_{3,m}$'s. Our construction is explicit, canonical, and has the following applications: we obtain a new theorem characterising all finite Cayley graphs as either essentially 4-connected, cycles, or complete graphs on at most four vertices, and we provide an automatic proof of Tutte's wheel theorem.",
      "authors": [
        "Johannes Carmesin and Jan Kurkofka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-03T13:08:10+00:00",
          "link": "https://arxiv.org/abs/2304.00945v1",
          "size": "402kb",
          "version": "v1"
        },
        {
          "date": "2024-04-10T17:27:16+00:00",
          "link": "https://arxiv.org/abs/2304.00945v2",
          "size": "453kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T22:14:58+00:00",
          "link": "https://arxiv.org/abs/2304.00945v3",
          "size": "371kb",
          "version": "v3"
        }
      ],
      "title": "Canonical Decompositions of 3-Connected Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.00945",
        "HTML": "https://arxiv.org/html/2304.00945v3",
        "PDF": "https://arxiv.org/pdf/2304.00945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a new structural decomposition for 3-connected graphs. It does not relate to LLM training data processing or make contributions towards data engineering or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.11283",
      "abstract": "Statistical agencies routinely use different strategies to protect the confidentiality of tabular data from those used to protect the individual records in publicly released microdata. Aggregation is assumed to make the resulting statistics inherently less disclosive than the microdata. The 2010 U.S. Census used different disclosure limitation rules for its tabular and microdata publications. We show that the assumption that these tabular data are inherently less disclosive than their underlying microdata is wrong. The 2010 Census published more than 150 billion statistics in 180 table sets, almost all at the most detailed geographic level -- individual census blocks. Using only 34 of the published table sets, we reconstructed microdata for five variables (census block, sex, age, race, and ethnicity). Using only published data, an attacker using our methods can verify that all records in 70% of all census blocks (97 million people) are perfectly reconstructed. We confirm through reidentification studies that an attacker can, within census blocks with perfect reconstruction accuracy, correctly infer the actual census response on race and ethnicity for 3.4 million vulnerable people (unique persons with race and ethnicity different from the modal person on the census block) with 95\\% accuracy. Next, we show that the more robust disclosure limitation framework used for the 2020 U.S. Census defends against attacks that are based on reconstruction. Finally, we show that available alternatives to the 2020 Census Disclosure Avoidance System would either fail to protect confidentiality or overly degrade the statistics' utility for the primary statutory use case: redrawing the boundaries of all the nation's legislative and voting districts in compliance with the 1965 Voting Rights Act. This is the full technical report. For the summary paper see https://doi.org/10.1162/99608f92.4a1ebf70.",
      "authors": [
        "John M. Abowd and Tamara Adams and Robert Ashmead and David Darais and Sourya Dey and Simson L. Garfinkel and Nathan Goldschlag and Daniel Kifer and Philip Leclerc and Ethan Lew and Scott Moore and Rolando A. Rodr\\'iguez and Ramy N. Tadros and Lars Vilhuber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Cryptography and Security (cs.CR)",
        "Econometrics (econ.EM)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-18T15:23:12+00:00",
          "link": "https://arxiv.org/abs/2312.11283v1",
          "size": "595kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:16:41+00:00",
          "link": "https://arxiv.org/abs/2312.11283v2",
          "size": "961kb",
          "version": "v2"
        }
      ],
      "title": "A Simulated Reconstruction and Reidentification Attack on the 2010 U.S. Census: Full Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.11283",
        "HTML": "https://arxiv.org/html/2312.11283v2",
        "PDF": "https://arxiv.org/pdf/2312.11283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on data confidentiality and privacy in the context of the U.S. Census data, exploring reconstruction and reidentification attacks, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.16109",
      "abstract": "Chest X-rays or chest radiography (CXR), commonly used for medical diagnostics, typically enables limited imaging compared to computed tomography (CT) scans, which offer more detailed and accurate three-dimensional data, particularly contrast-enhanced scans like CT Pulmonary Angiography (CTPA). However, CT scans entail higher costs, greater radiation exposure, and are less accessible than CXRs. In this work we explore cross-modal translation from a 2D low contrast-resolution X-ray input to a 3D high contrast and spatial-resolution CTPA scan. Driven by recent advances in generative AI, we introduce a novel diffusion-based approach to this task. We evaluate the models performance using both quantitative metrics and qualitative feedback from radiologists, ensuring diagnostic relevance of the generated images. Furthermore, we employ the synthesized 3D images in a classification framework and show improved AUC in a PE categorization task, using the initial CXR input. The proposed method is generalizable and capable of performing additional cross-modality translations in medical imaging. It may pave the way for more accessible and cost-effective advanced diagnostic tools. The code for this project is available: https://github.com/NoaCahan/X-ray2CTPA .",
      "authors": [
        "Noa Cahan",
        "Eyal Klang",
        "Galit Aviram",
        "Yiftach Barash",
        "Eli Konen",
        "Raja Giryes and Hayit Greenspan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-23T13:53:35+00:00",
          "link": "https://arxiv.org/abs/2406.16109v1",
          "size": "6486kb",
          "version": "v1"
        },
        {
          "date": "2024-06-25T06:47:07+00:00",
          "link": "https://arxiv.org/abs/2406.16109v2",
          "size": "6486kb",
          "version": "v2"
        },
        {
          "date": "2024-07-12T06:18:13+00:00",
          "link": "https://arxiv.org/abs/2406.16109v3",
          "size": "9037kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T07:00:31+00:00",
          "link": "https://arxiv.org/abs/2406.16109v4",
          "size": "9946kb",
          "version": "v4"
        }
      ],
      "title": "X-ray2CTPA: Leveraging Diffusion Models to Enhance Pulmonary Embolism Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.16109",
        "HTML": "https://arxiv.org/html/2406.16109v4",
        "PDF": "https://arxiv.org/pdf/2406.16109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on medical imaging and enhancing classification tasks using diffusion models, which is unrelated to LLM training data processing or dataset preparation for language models."
      },
      "tasks": [
        "Computed Tomography (CT)",
        "Diagnostic"
      ],
      "repo_urls": [
        "https://github.com/noacahan/x-ray2ctpa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.03605",
      "abstract": "Hyperspectral images~(HSIs) are often contaminated by a mixture of noise such as Gaussian noise, dead lines, stripes, and so on. In this paper, we propose a multi-scale low-rank tensor regularized $\\ell_{2,p}$ (MLTL2p) approach for HSI denoising and destriping, which consists of an orthogonal constrained minimization model and an iterative algorithm with convergence guarantees. The model of the proposed MLTL2p approach is built based on a new sparsity-enhanced Multi-scale Low-rank Tensor regularization and a tensor $\\ell_{2,p}$ norm with \\(p\\in (0,1)\\). The multi-scale low-rank regularization for HSI denoising utilizes the global and local spectral correlation as well as the spatial nonlocal self-similarity priors of HSIs. The corresponding low-rank constraints are formulated based on independent higher-order singular value decomposition with sparsity enhancement on its core tensor to prompt more low-rankness. The tensor $\\ell_{2,p}$ norm for HSI destriping is extended from the matrix $\\ell_{2,p}$ norm. A proximal block coordinate descent algorithm is proposed in the MLTL2p approach to solve the resulting nonconvex nonsmooth minimization with orthogonal constraints. We show any accumulation point of the sequence generated by the proposed algorithm converges to a first-order stationary point, which is defined using three equalities of substationarity, symmetry, and feasibility for orthogonal constraints. In the numerical experiments, we compare the proposed method with state-of-the-art methods including a deep learning based method, and test the methods on both simulated and real HSI datasets. Our proposed MLTL2p method demonstrates outperformance in terms of metrics such as mean peak signal-to-noise ratio as well as visual quality.",
      "authors": [
        "Xiaoxia Liu",
        "Shijie Yu",
        "Jian Lu",
        "Xiaojun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-04T03:33:19+00:00",
          "link": "https://arxiv.org/abs/2407.03605v1",
          "size": "6338kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T03:13:43+00:00",
          "link": "https://arxiv.org/abs/2407.03605v2",
          "size": "3647kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T06:25:42+00:00",
          "link": "https://arxiv.org/abs/2407.03605v3",
          "size": "3561kb",
          "version": "v3"
        }
      ],
      "title": "Orthogonal Constrained Minimization with Tensor $\\ell_{2,p}$ Regularization for HSI Denoising and Destriping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.03605",
        "HTML": "https://arxiv.org/html/2407.03605v3",
        "PDF": "https://arxiv.org/pdf/2407.03605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for denoising and destriping hyperspectral images, which is unrelated to LLM training data processing or dataset operations for pretraining or fine-tuning."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03803",
      "abstract": "OGRePy is a modern, open-source Python package designed to perform symbolic tensor calculations, with a particular focus on applications in general relativity. Built on an object-oriented architecture, OGRePy encapsulates tensors, metrics, and coordinate systems as self-contained objects, automatically handling raising and lowering of indices, coordinate transformations, contractions, partial or covariant derivatives, and all tensor operations. By leveraging the capabilities of SymPy and Jupyter Notebook, OGRePy provides a robust, user-friendly environment that facilitates both research and teaching in general relativity and differential geometry. This Python package reproduces the functionality of the popular Mathematica package OGRe, while greatly improving upon it by making use of Python's native object-oriented syntax. In this paper, we describe OGRePy's design and implementation, and discuss its potential for reuse across research and education in mathematics and physics.",
      "authors": [
        "Barak Shoshany"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Relativity and Quantum Cosmology (gr-qc)",
        "Mathematical Software (cs.MS)",
        "Symbolic Computation (cs.SC)",
        "Differential Geometry (math.DG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-05T03:40:27+00:00",
          "link": "https://arxiv.org/abs/2409.03803v1",
          "size": "761kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T19:45:19+00:00",
          "link": "https://arxiv.org/abs/2409.03803v2",
          "size": "4088kb",
          "version": "v2"
        }
      ],
      "title": "OGRePy: An Object-Oriented General Relativity Package for Python",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03803",
        "PDF": "https://arxiv.org/pdf/2409.03803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces OGRePy, a Python package for symbolic tensor calculations in general relativity, but it does not involve LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/bshoshany/ogrepy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.05345",
      "abstract": "Given $p$ samples, each of which may or may not be defective, group testing (GT) aims to determine their defect status by performing tests on $n < p$ `groups', where a group is formed by mixing a subset of the $p$ samples. Assuming that the number of defective samples is very small compared to $p$, GT algorithms have provided excellent recovery of the status of all $p$ samples with even a small number of groups. Most existing methods, however, assume that the group memberships are accurately specified. This assumption may not always be true in all applications, due to various resource constraints. Such errors could occur, eg, when a technician, preparing the groups in a laboratory, unknowingly mixes together an incorrect subset of samples as compared to what was specified. We develop a new GT method, the Debiased Robust Lasso Test Method (DRLT), that handles such group membership specification errors. The proposed DRLT method is based on an approach to debias, or reduce the inherent bias in, estimates produced by Lasso, a popular and effective sparse regression technique. We also provide theoretical upper bounds on the reconstruction error produced by our estimator. Our approach is then combined with two carefully designed hypothesis tests respectively for (i) the identification of defective samples in the presence of errors in group membership specifications, and (ii) the identification of groups with erroneous membership specifications. The DRLT approach extends the literature on bias mitigation of statistical estimators such as the LASSO, to handle the important case when some of the measurements contain outliers, due to factors such as group membership specification errors. We present numerical results which show that our approach outperforms several baselines and robust regression techniques for identification of defective samples as well as erroneously specified groups.",
      "authors": [
        "Shuvayan Banerjee",
        "Radhendushka Srivastava",
        "James Saunderson and Ajit Rajwade"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-09T06:03:23+00:00",
          "link": "https://arxiv.org/abs/2409.05345v1",
          "size": "1487kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T07:03:53+00:00",
          "link": "https://arxiv.org/abs/2409.05345v2",
          "size": "5876kb",
          "version": "v2"
        }
      ],
      "title": "Robust Non-adaptive Group Testing under Errors in Group Membership Specifications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05345",
        "HTML": "https://arxiv.org/html/2409.05345v2",
        "PDF": "https://arxiv.org/pdf/2409.05345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a group testing method for handling errors in sample grouping, which is unrelated to LLM training data processing, pretraining, fine-tuning, or any specific data processing operations for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.15087",
      "abstract": "Timely disease diagnosis is challenging due to increasing disease burdens and limited clinician availability. AI shows promise in diagnosis accuracy but faces real-world application issues due to insufficient validation in clinical workflows and diverse populations. This study addresses gaps in medical AI downstream accountability through a case study on age-related macular degeneration (AMD) diagnosis and severity classification. We designed and implemented an AI-assisted diagnostic workflow for AMD, comparing diagnostic performance with and without AI assistance among 24 clinicians from 12 institutions with real patient data sampled from the Age-Related Eye Disease Study (AREDS). Additionally, we demonstrated continual enhancement of an existing AI model by incorporating approximately 40,000 additional medical images (named AREDS2 dataset). The improved model was then systematically evaluated using both AREDS and AREDS2 test sets, as well as an external test set from Singapore. AI assistance markedly enhanced diagnostic accuracy and classification for 23 out of 24 clinicians, with the average F1-score increasing by 20% from 37.71 (Manual) to 45.52 (Manual + AI) (P-value < 0.0001), achieving an improvement of over 50% in some cases. In terms of efficiency, AI assistance reduced diagnostic times for 17 out of the 19 clinicians tracked, with time savings of up to 40%. Furthermore, a model equipped with continual learning showed robust performance across three independent datasets, recording a 29% increase in accuracy, and elevating the F1-score from 42 to 54 in the Singapore population.",
      "authors": [
        "Qingyu Chen",
        "Tiarnan D L Keenan",
        "Elvira Agron",
        "Alexis Allot",
        "Emily Guan",
        "Bryant Duong",
        "Amr Elsawy",
        "Benjamin Hou",
        "Cancan Xue",
        "Sanjeeb Bhandari",
        "Geoffrey Broadhead",
        "Chantal Cousineau-Krieger",
        "Ellen Davis",
        "William G Gensheimer",
        "David Grasic",
        "Seema Gupta",
        "Luis Haddock",
        "Eleni Konstantinou",
        "Tania Lamba",
        "Michele Maiberger",
        "Dimosthenis Mantopoulos",
        "Mitul C Mehta",
        "Ayman G Nahri",
        "Mutaz AL-Nawaflh",
        "Arnold Oshinsky",
        "Brittany E Powell",
        "Boonkit Purt",
        "Soo Shin",
        "Hillary Stiefel",
        "Alisa T Thavikulwat",
        "Keith James Wroblewski",
        "Tham Yih Chung",
        "Chui Ming Gemmy Cheung",
        "Ching-Yu Cheng",
        "Emily Y Chew",
        "Michelle R. Hribar",
        "Michael F. Chiang",
        "Zhiyong Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T15:01:09+00:00",
          "link": "https://arxiv.org/abs/2409.15087v1",
          "size": "1168kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T01:49:32+00:00",
          "link": "https://arxiv.org/abs/2409.15087v2",
          "size": "1098kb",
          "version": "v2"
        }
      ],
      "title": "AI Workflow, External Validation, and Development in Eye Disease Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15087",
        "PDF": "https://arxiv.org/pdf/2409.15087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study involves AI-assisted workflows for disease diagnosis, focusing on real-world application, validation, and continual learning in medical AI. It does not pertain to any aspect of LLM training data processing."
      },
      "tasks": [
        "Continual Learning",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.22074",
      "abstract": "In this paper, we present a novel method for pile-up removal of $pp$ interactions using variational inference with diffusion models, called vipr. Instead of using classification methods to identify which particles are from the primary collision, a generative model is trained to predict the constituents of the hard-scatter particle jets with pile-up removed. This results in an estimate of the full posterior over hard-scatter jet constituents, which has not yet been explored in the context of pile-up removal, yielding a clear advantage over existing methods especially in the presence of imperfect detector efficiency. We evaluate the performance of vipr in a sample of jets from simulated $t\\bar{t}$ events overlain with pile-up contamination. vipr outperforms softdrop and has comparable performance to puppiml in predicting the substructure of the hard-scatter jets over a wide range of pile-up scenarios.",
      "authors": [
        "Malte Algren",
        "Tobias Golling",
        "Christopher Pollard",
        "and John Andrew Raine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-29T14:33:52+00:00",
          "link": "https://arxiv.org/abs/2410.22074v1",
          "size": "5349kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T11:24:17+00:00",
          "link": "https://arxiv.org/abs/2410.22074v2",
          "size": "1048kb",
          "version": "v2"
        }
      ],
      "title": "Variational inference for pile-up removal at hadron colliders with diffusion models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.22074",
        "HTML": "https://arxiv.org/html/2410.22074v2",
        "PDF": "https://arxiv.org/pdf/2410.22074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores variational inference methods for particle collision analysis, a topic unrelated to LLM training data processing."
      },
      "tasks": [
        "Variational Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16354",
      "abstract": "To demonstrate supremacy of quantum computing, increasingly large-scale superconducting quantum computing chips are being designed and fabricated. However, the complexity of simulating quantum systems poses a significant challenge to computer-aided design of quantum chips, especially for large-scale chips. Harnessing the scalability of graph neural networks (GNNs), we here propose a parameter designing algorithm for large-scale superconducting quantum circuits. The algorithm depends on the so-called 'three-stair scaling' mechanism, which comprises two neural-network models: an evaluator supervisedly trained on small-scale circuits for applying to medium-scale circuits, and a designer unsupervisedly trained on medium-scale circuits for applying to large-scale ones. We demonstrate our algorithm in mitigating quantum crosstalk errors. Frequencies for both single- and two-qubit gates (corresponding to the parameters of nodes and edges) are considered simultaneously. Numerical results indicate that the well-trained designer achieves notable advantages in efficiency, effectiveness, and scalability. For example, for large-scale superconducting quantum circuits consisting of around 870 qubits, our GNNs-based algorithm achieves 51% of the errors produced by the state-of-the-art algorithm, with a time reduction from 90 min to 27 sec. Overall, a better-performing and more scalable algorithm for designing parameters of superconducting quantum chips is proposed, which initially demonstrates the advantages of applying GNNs in superconducting quantum chips.",
      "authors": [
        "Hao Ai and Yu-xi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T13:04:53+00:00",
          "link": "https://arxiv.org/abs/2411.16354v1",
          "size": "8059kb",
          "version": "v1"
        },
        {
          "date": "2025-02-07T13:28:59+00:00",
          "link": "https://arxiv.org/abs/2411.16354v2",
          "size": "8550kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T07:23:42+00:00",
          "link": "https://arxiv.org/abs/2411.16354v3",
          "size": "8605kb",
          "version": "v3"
        }
      ],
      "title": "Scalable Parameter Design for Superconducting Quantum Circuits with Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16354",
        "HTML": "https://arxiv.org/html/2411.16354v3",
        "PDF": "https://arxiv.org/pdf/2411.16354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study concerns the design of superconducting quantum circuits using graph neural networks and does not address any issues related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.04277",
      "abstract": "Solving hard optimization problems is one of the most promising application domains for quantum computers due to the ubiquity of such problems in industry and the availability of broadly applicable quantum speedups. However, the ability of near-term quantum computers to tackle industrial-scale optimization problems is limited by their size and the overheads of quantum error correction. Quantum Random Access Optimization (QRAO) has been proposed to reduce the space requirements of quantum optimization. However, to date QRAO has only been implemented using variational algorithms, which suffer from the need to train instance-specific variational parameters, making them difficult to scale. We propose and benchmark a non-variational approach to QRAO based on the Quantum Alternating Operator Ansatz (QAOA) for the MaxCut problem. We show that instance-independent ``fixed\" parameters achieve good performance, removing the need for variational parameter optimization. Additionally, we evaluate different design choices, such as various mixers, initial states, and QRAO-specific implementations of the QAOA cost operator, and identify a strategy that performs well in practice. Our results pave the way for the practical execution of QRAO on early fault-tolerant quantum computers.",
      "authors": [
        "Zichang He",
        "Rudy Raymond",
        "Ruslan Shaydulin",
        "Marco Pistoia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T18:25:31+00:00",
          "link": "https://arxiv.org/abs/2502.04277v1",
          "size": "1706kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:44:25+00:00",
          "link": "https://arxiv.org/abs/2502.04277v2",
          "size": "1575kb",
          "version": "v2"
        }
      ],
      "title": "Non-Variational Quantum Random Access Optimization with Alternating Operator Ansatz",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04277",
        "HTML": "https://arxiv.org/html/2502.04277v2",
        "PDF": "https://arxiv.org/pdf/2502.04277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum optimization and the Quantum Alternating Operator Ansatz, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.01075",
      "abstract": "Hallucinations are spurious structures not present in the ground truth, posing a critical challenge in medical image reconstruction, especially for data-driven conditional models. We hypothesize that combining an unconditional diffusion model with data consistency, trained on a diverse dataset, can reduce these hallucinations. Based on this, we propose DynamicDPS, a diffusion-based framework that integrates conditional and unconditional diffusion models to enhance low-quality medical images while systematically reducing hallucinations. Our approach first generates an initial reconstruction using a conditional model, then refines it with an adaptive diffusion-based inverse problem solver. DynamicDPS skips early stage in the reverse process by selecting an optimal starting time point per sample and applies Wolfe's line search for adaptive step sizes, improving both efficiency and image fidelity. Using diffusion priors and data consistency, our method effectively reduces hallucinations from any conditional model output. We validate its effectiveness in Image Quality Transfer for low-field MRI enhancement. Extensive evaluations on synthetic and real MR scans, including a downstream task for tissue volume estimation, show that DynamicDPS reduces hallucinations, improving relative volume estimation by over 15% for critical tissues while using only 5% of the sampling steps required by baseline diffusion models. As a model-agnostic and fine-tuning-free approach, DynamicDPS offers a robust solution for hallucination reduction in medical imaging. The code will be made publicly available upon publication.",
      "authors": [
        "Seunghoi Kim and Henry F. J. Tregidgo and Matteo Figini and Chen Jin and Sarang Joshi and Daniel C. Alexander"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T00:33:04+00:00",
          "link": "https://arxiv.org/abs/2503.01075v1",
          "size": "12213kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T02:11:36+00:00",
          "link": "https://arxiv.org/abs/2503.01075v2",
          "size": "3323kb",
          "version": "v2"
        }
      ],
      "title": "Tackling Hallucination from Conditional Models for Medical Image Reconstruction with DynamicDPS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01075",
        "HTML": "https://arxiv.org/html/2503.01075v2",
        "PDF": "https://arxiv.org/pdf/2503.01075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a diffusion-based framework to reduce hallucinations in medical image reconstruction, which is not related to LLM training data processing."
      },
      "tasks": [
        "Hallucination",
        "Image Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05245",
      "abstract": "Accurate analysis of prenatal ultrasound (US) is essential for early detection of developmental anomalies. However, operator dependency and technical limitations (e.g. intrinsic artefacts and effects, setting errors) can complicate image interpretation and the assessment of diagnostic uncertainty. We present L-FUSION (Laplacian Fetal US Segmentation with Integrated FoundatiON models), a framework that integrates uncertainty quantification through unsupervised, normative learning and large-scale foundation models for robust segmentation of fetal structures in normal and pathological scans. We propose to utilise the aleatoric logit distributions of Stochastic Segmentation Networks and Laplace approximations with fast Hessian estimations to estimate epistemic uncertainty only from the segmentation head. This enables us to achieve reliable abnormality quantification for instant diagnostic feedback. Combined with an integrated Dropout component, L-FUSION enables reliable differentiation of lesions from normal fetal anatomy with enhanced uncertainty maps and segmentation counterfactuals in US imaging. It improves epistemic and aleatoric uncertainty interpretation and removes the need for manual disease-labelling. Evaluations across multiple datasets show that L-FUSION achieves superior segmentation accuracy and consistent uncertainty quantification, supporting on-site decision-making and offering a scalable solution for advancing fetal ultrasound analysis in clinical settings.",
      "authors": [
        "Johanna P. M\\\"uller",
        "Robert Wright",
        "Thomas G. Day",
        "Lorenzo Venturini",
        "Samuel F. Budd",
        "Hadrien Reynaud",
        "Joseph V. Hajnal",
        "Reza Razavi",
        "Bernhard Kainz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T08:57:38+00:00",
          "link": "https://arxiv.org/abs/2503.05245v1",
          "size": "1616kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T10:11:17+00:00",
          "link": "https://arxiv.org/abs/2503.05245v2",
          "size": "1616kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T08:26:59+00:00",
          "link": "https://arxiv.org/abs/2503.05245v3",
          "size": "1613kb",
          "version": "v3"
        }
      ],
      "title": "L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05245",
        "HTML": "https://arxiv.org/html/2503.05245v3",
        "PDF": "https://arxiv.org/pdf/2503.05245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fetal ultrasound segmentation and uncertainty estimation, which is not related to LLM training data processing."
      },
      "tasks": [
        "Anatomy",
        "Diagnostic",
        "Segmentation",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05674",
      "abstract": "The Grad-Shafranov (GS) equation is a nonlinear elliptic partial differential equation that governs the ideal magnetohydrodynamic equilibrium of a tokamak plasma. Previous studies have demonstrated the existence of multiple solutions to the GS equation when solved in idealistic geometries with simplified plasma current density profiles and boundary conditions. Until now, the question of whether multiple equilibria might exist in real-world tokamak geometries with more complex current density profiles and integral free-boundary conditions (commonly used in production-level equilibrium codes) has remained unanswered. In this work, we discover multiple solutions to the static forward free-boundary GS problem in the MAST-U tokamak geometry using the validated evolutive equilibrium solver FreeGSNKE and the deflated continuation algorithm. By varying the plasma current, current density profile coefficients, or coil currents in the GS equation, we identify and characterise distinct equilibrium solutions, including both deeply and more shallowly confined plasma states. We suggest that the existence of even more equilibria is likely prohibited by the restrictive nature of the integral free-boundary condition, which globally couples poloidal fluxes on the computational boundary with those on the interior. We conclude by discussing the implications of these findings for wider equilibrium modelling and emphasise the need to explore whether multiple solutions are present in other equilibrium codes and tokamaks, as well as their potential impact on downstream simulations that rely on GS equilibria.",
      "authors": [
        "K. Pentland",
        "N. C. Amorisco",
        "P. E. Farrell",
        "C. J. Ham"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Plasma Physics (physics.plasm-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T18:34:41+00:00",
          "link": "https://arxiv.org/abs/2503.05674v1",
          "size": "2424kb",
          "version": "v1"
        },
        {
          "date": "2025-06-16T17:37:20+00:00",
          "link": "https://arxiv.org/abs/2503.05674v2",
          "size": "2425kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T17:27:24+00:00",
          "link": "https://arxiv.org/abs/2503.05674v3",
          "size": "2558kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T14:30:10+00:00",
          "link": "https://arxiv.org/abs/2503.05674v4",
          "size": "2559kb",
          "version": "v4"
        }
      ],
      "title": "Multiple solutions to the static forward free-boundary Grad-Shafranov problem on MAST-U",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05674",
        "HTML": "https://arxiv.org/html/2503.05674v4",
        "PDF": "https://arxiv.org/pdf/2503.05674"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines solutions to the Grad-Shafranov problem in plasma physics, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06079",
      "abstract": "Despite the significance of probabilistic time-series forecasting models, their evaluation metrics often involve intractable integrations. The most widely used metric, the continuous ranked probability score (CRPS), is a strictly proper scoring function; however, its computation requires approximation. We found that popular CRPS estimators--specifically, the quantile-based estimator implemented in the widely used GluonTS library and the probability-weighted moment approximation--both exhibit inherent estimation biases. These biases lead to crude approximations, resulting in improper rankings of forecasting model performance when CRPS values are close. To address this issue, we introduced a kernel quadrature approach that leverages an unbiased CRPS estimator and employs cubature construction for scalable computation. Empirically, our approach consistently outperforms the two widely used CRPS estimators.",
      "authors": [
        "Masaki Adachi",
        "Masahiro Fujisawa",
        "Michael A Osborne"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T06:01:10+00:00",
          "link": "https://arxiv.org/abs/2503.06079v1",
          "size": "4499kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T03:38:00+00:00",
          "link": "https://arxiv.org/abs/2503.06079v2",
          "size": "2732kb",
          "version": "v2"
        }
      ],
      "title": "Fixing the Pitfalls of Probabilistic Time-Series Forecasting Evaluation by Kernel Quadrature",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06079",
        "HTML": "https://arxiv.org/html/2503.06079v2",
        "PDF": "https://arxiv.org/pdf/2503.06079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces kernel quadrature for evaluating probabilistic time-series forecasting models, a topic that does not relate to LLM training data processing."
      },
      "tasks": [
        "Probabilistic Time Series Forecasting",
        "Time Series",
        "Time Series Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11634",
      "abstract": "Black-box separations are a cornerstone of cryptography, indicating barriers to various goals. A recent line of work has explored black-box separations for quantum cryptographic primitives. Namely, a number of separations are known in the Common Haar Random State (CHRS) model, though this model is not considered a complete separation, but rather a starting point. A few very recent works have attempted to lift these separations to a unitary separation, which are considered complete separations. Unfortunately, we find significant errors in some of these lifting results.\n  We prove general conditions under which CHRS separations can be generically lifted, thereby giving simple, modular, and bug-free proofs of complete unitary separations between various quantum primitives. Our techniques allow for simpler proofs of existing separations as well as new separations that were previously only known in the CHRS model.",
      "authors": [
        "Eli Goldin",
        "Mark Zhandry"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T17:52:48+00:00",
          "link": "https://arxiv.org/abs/2503.11634v1",
          "size": "5966kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T23:22:47+00:00",
          "link": "https://arxiv.org/abs/2503.11634v2",
          "size": "5967kb",
          "version": "v2"
        }
      ],
      "title": "Translating Between the Common Haar Random State Model and the Unitary Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11634",
        "HTML": "https://arxiv.org/html/2503.11634v2",
        "PDF": "https://arxiv.org/pdf/2503.11634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses black-box separations in cryptography, particularly in the quantum domain. It does not pertain to LLM training data processing or any relevant data-related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.15704",
      "abstract": "The performance of sequential Monte Carlo (SMC) samplers heavily depends on the tuning of the Markov kernels used in the path proposal. For SMC samplers with unadjusted Markov kernels, standard tuning objectives, such as the Metropolis-Hastings acceptance rate or the expected-squared jump distance, are no longer applicable. While stochastic gradient-based end-to-end optimization has been explored for tuning SMC samplers, they often incur excessive training costs, even for tuning just the kernel step sizes. In this work, we propose a general adaptation framework for tuning the Markov kernels in SMC samplers by minimizing the incremental Kullback-Leibler (KL) divergence between the proposal and target paths. For step size tuning, we provide a gradient- and tuning-free algorithm that is generally applicable for kernels such as Langevin Monte Carlo (LMC). We further demonstrate the utility of our approach by providing a tailored scheme for tuning kinetic LMC used in SMC samplers. Our implementations are able to obtain a full schedule of tuned parameters at the cost of a few vanilla SMC runs, which is a fraction of gradient-based approaches.",
      "authors": [
        "Kyurae Kim",
        "Zuheng Xu",
        "Jacob R. Gardner",
        "Trevor Campbell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T21:35:02+00:00",
          "link": "https://arxiv.org/abs/2503.15704v1",
          "size": "13913kb",
          "version": "v1"
        },
        {
          "date": "2025-05-23T19:51:18+00:00",
          "link": "https://arxiv.org/abs/2503.15704v2",
          "size": "14024kb",
          "version": "v2"
        },
        {
          "date": "2025-06-01T18:39:22+00:00",
          "link": "https://arxiv.org/abs/2503.15704v3",
          "size": "10782kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T20:34:43+00:00",
          "link": "https://arxiv.org/abs/2503.15704v4",
          "size": "10787kb",
          "version": "v4"
        }
      ],
      "title": "Tuning Sequential Monte Carlo Samplers via Greedy Incremental Divergence Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15704",
        "HTML": "https://arxiv.org/html/2503.15704v4",
        "PDF": "https://arxiv.org/pdf/2503.15704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on tuning Sequential Monte Carlo samplers via greedy incremental divergence minimization. It does not discuss or contribute to LLM training data processing operations such as data filtering, deduplication, or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.16315",
      "abstract": "Identifying the optimal diagnostic test and hardware system instance to infer reliability characteristics using field data is challenging, especially when constrained by fixed budgets and minimal maintenance cycles. Active Learning (AL) has shown promise for parameter inference with limited data and budget constraints in machine learning/deep learning tasks. However, AL for reliability model parameter inference remains underexplored for repairable hardware systems. It requires specialized AL Acquisition Functions (AFs) that consider hardware aging and the fact that a hardware system consists of multiple sub-systems, which may undergo only partial testing during a given diagnostic test. To address these challenges, we propose a relaxed Mixed Integer Semidefinite Program (MISDP) AL AF that incorporates Diagnostic Coverage (DC), Fisher Information Matrices (FIMs), and diagnostic testing budgets. Furthermore, we design empirical-based simulation experiments focusing on two diagnostic testing scenarios: (1) partial tests of a hardware system with overlapping subsystem coverage, and (2) partial tests where one diagnostic test fully subsumes the subsystem coverage of another. We evaluate our proposed approach against the most widely used AL AF in the literature (entropy), as well as several intuitive AL AFs tailored for reliability model parameter inference. Our proposed AF ranked best on average among the alternative AFs across 6,000 experimental configurations, with respect to Area Under the Curve (AUC) of the Absolute Total Expected Event Error (ATEER) and Mean Squared Error (MSE) curves, with statistical significance calculated at a 0.05 alpha level using a Friedman hypothesis test.",
      "authors": [
        "Michael Potter",
        "Beyza Kalkanl{\\i}",
        "Deniz Erdo\\u{g}mu\\c{s}",
        "and Michael Everett"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T16:38:16+00:00",
          "link": "https://arxiv.org/abs/2503.16315v1",
          "size": "389kb",
          "version": "v1"
        },
        {
          "date": "2025-05-31T14:36:23+00:00",
          "link": "https://arxiv.org/abs/2503.16315v2",
          "size": "833kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T00:51:58+00:00",
          "link": "https://arxiv.org/abs/2503.16315v3",
          "size": "2234kb",
          "version": "v3"
        }
      ],
      "title": "Active Learning For Repairable Hardware Systems With Partial Coverage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16315",
        "HTML": "https://arxiv.org/html/2503.16315v3",
        "PDF": "https://arxiv.org/pdf/2503.16315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses active learning for reliability model parameter inference in hardware systems, which is unrelated to LLM training data processing, dataset creation, or improvement in data quality."
      },
      "tasks": [
        "Active Learning",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.08305",
      "abstract": "We developed a 55 nm CMOS SRAM chip that scans all data every 125 ns and outputs timestamped soft error data via an SPI interface through a FIFO. The proposed system, consisting of the developed chip and particle detectors, enables event-wise soft error measurement and precise identification of SBUs and MCUs, thus resolving misclassifications such as Pseudo- and Distant MCUs that conventional methods cannot distinguish. An 80-MeV proton irradiation experiment at RARiS, Tohoku University verified the system operation. Timestamps between the SRAM chip and the particle detectors were successfully synchronized, accounting for PLL disturbances caused by radiation. Event building was achieved by determining a reset offset with sub-ns resolution, and spatial synchronization was maintained within several tens of micrometers.",
      "authors": [
        "Yuibi Gomi",
        "Akira Sato",
        "Waleed Madany",
        "Kenichi Okada",
        "Satoshi Adachi",
        "Masatoshi Itoh",
        "Masanori Hashimoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Detectors (physics.ins-det)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T07:14:12+00:00",
          "link": "https://arxiv.org/abs/2504.08305v1",
          "size": "16867kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:38:58+00:00",
          "link": "https://arxiv.org/abs/2504.08305v2",
          "size": "706kb",
          "version": "v2"
        }
      ],
      "title": "A 55-nm SRAM Chip Scanning Errors Every 125 ns for Event-Wise Soft Error Measurement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08305",
        "HTML": "https://arxiv.org/html/2504.08305v2",
        "PDF": "https://arxiv.org/pdf/2504.08305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details the development of a CMOS SRAM chip for soft error measurement, with no connection to LLM training data processing or enhancements in dataset quality for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00046",
      "abstract": "Implicit Neural Representations (INRs) have garnered significant attention for their ability to model complex signals in various domains. Recently, INR-based frameworks have shown promise in neural video compression by embedding video content into compact neural networks. However, these methods often struggle to reconstruct high-frequency details under stringent constraints on model size, which are critical in practical compression scenarios. To address this limitation, we propose an INR-based video representation framework that integrates a general-purpose super-resolution (SR) network. This design is motivated by the observation that high-frequency components tend to exhibit low temporal redundancy across frames. By offloading the reconstruction of fine details to a dedicated SR network pre-trained on natural images, the proposed method improves visual fidelity. Experimental results demonstrate that the proposed method outperforms conventional INR-based baselines in reconstruction quality, while maintaining a comparable model size.",
      "authors": [
        "Taiga Hayami",
        "Kakeru Koizumi",
        "Hiroshi Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T03:31:40+00:00",
          "link": "https://arxiv.org/abs/2505.00046v1",
          "size": "1131kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T12:24:50+00:00",
          "link": "https://arxiv.org/abs/2505.00046v2",
          "size": "1370kb",
          "version": "v2"
        }
      ],
      "title": "SR-NeRV: Improving Embedding Efficiency of Neural Video Representation via Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00046",
        "HTML": "https://arxiv.org/html/2505.00046v2",
        "PDF": "https://arxiv.org/pdf/2505.00046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an improved method for neural video representation by integrating super-resolution networks. It pertains to video compression techniques, not LLM training data processing, and does not involve relevant data operations."
      },
      "tasks": [
        "Super-Resolution",
        "Video Compression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00862",
      "abstract": "This paper investigates prime and co-prime integer matrices and their properties. It characterizes all pairwise co-prime integer matrices that are also prime integer matrices. This provides a simple way to construct families of pairwise co-prime integer matrices, that may have applications in multidimensional co-prime sensing and multidimensional Chinese remainder theorem.",
      "authors": [
        "Xiang-Gen Xia and Guangpu Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Discrete Mathematics (cs.DM)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T21:04:32+00:00",
          "link": "https://arxiv.org/abs/2505.00862v1",
          "size": "10kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T18:46:12+00:00",
          "link": "https://arxiv.org/abs/2505.00862v2",
          "size": "10kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T22:08:30+00:00",
          "link": "https://arxiv.org/abs/2505.00862v3",
          "size": "11kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T18:36:45+00:00",
          "link": "https://arxiv.org/abs/2505.00862v4",
          "size": "11kb",
          "version": "v4"
        }
      ],
      "title": "Prime and Co-prime Integer Matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00862",
        "HTML": "https://arxiv.org/html/2505.00862v4",
        "PDF": "https://arxiv.org/pdf/2505.00862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates integer matrices and their properties, focusing on co-prime sensing and the Chinese remainder theorem. It does not relate to LLM training data processing or involve any relevant data processing techniques or operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.09193",
      "abstract": "Recent forward prediction-based learned video compression (LVC) methods have achieved impressive results, even surpassing VVC reference software VTM under the Low Delay B (LDB) configuration. In contrast, learned bidirectional video compression (BVC) remains underexplored and still lags behind its forward-only counterparts. This performance gap is mainly due to the limited ability to extract diverse and accurate contexts: most existing BVCs primarily exploit temporal motion while neglecting non-local correlations across frames. Moreover, they lack the adaptability to dynamically suppress harmful contexts arising from fast motion or occlusion. To tackle these challenges, we propose BiECVC, a BVC framework that incorporates diversified local and non-local context modeling along with adaptive context gating. For local context enhancement, BiECVC reuses high-quality features from lower layers and aligns them using decoded motion vectors without introducing extra motion overhead. To model non-local dependencies efficiently, we adopt a linear attention mechanism that balances performance and complexity. To further mitigate the impact of inaccurate context prediction, we introduce Bidirectional Context Gating, inspired by data-dependent decay in recent autoregressive language models, to dynamically filter contextual information based on conditional coding results. Extensive experiments demonstrate that BiECVC achieves state-of-the-art performance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2 under the Random Access (RA) configuration with intra periods of 32 and 64, respectively. To our knowledge, BiECVC is the first learned video codec to surpass VTM 13.2 RA across all standard test datasets.",
      "authors": [
        "Wei Jiang",
        "Junru Li",
        "Kai Zhang",
        "Li Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T06:55:37+00:00",
          "link": "https://arxiv.org/abs/2505.09193v1",
          "size": "1417kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T01:32:30+00:00",
          "link": "https://arxiv.org/abs/2505.09193v2",
          "size": "1417kb",
          "version": "v2"
        },
        {
          "date": "2025-07-06T08:47:36+00:00",
          "link": "https://arxiv.org/abs/2505.09193v3",
          "size": "1334kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T16:57:30+00:00",
          "link": "https://arxiv.org/abs/2505.09193v4",
          "size": "1334kb",
          "version": "v4"
        }
      ],
      "title": "BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09193",
        "HTML": "https://arxiv.org/html/2505.09193v4",
        "PDF": "https://arxiv.org/pdf/2505.09193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with learned bidirectional video compression techniques. It does not cover topics related to LLM training data processing."
      },
      "tasks": [
        "Video Compression"
      ],
      "repo_urls": [
        "https://github.com/jiangweibeta/ecvc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09619",
      "abstract": "The management of chronic Heart Failure (HF) presents significant challenges in modern healthcare, requiring continuous monitoring, early detection of exacerbations, and personalized treatment strategies. In this paper, we present a predictive model founded on Machine Learning (ML) techniques to identify patients at HF risk. This model is an ensemble learning approach, a modified stacking technique, that uses two specialized models leveraging clinical and echocardiographic features and then a meta-model to combine the predictions of these two models. We initially assess the model on a real dataset and the obtained results suggest that it performs well in the stratification of patients at HR risk. Specifically, we obtained high sensitivity (95\\%), ensuring that nearly all high-risk patients are identified. As for accuracy, we obtained 84\\%, which can be considered moderate in some ML contexts. However, it is acceptable given our priority of identifying patients at risk of HF because they will be asked to participate in the telemonitoring program of the PrediHealth research project on which some of the authors of this paper are working. The initial findings also suggest that ML-based risk stratification models can serve as valuable decision-support tools not only in the PrediHealth project but also for healthcare professionals, aiding in early intervention and personalized patient management. To have a better understanding of the value and of potentiality of our predictive model, we also contrasted its results with those obtained by using three baseline models. The preliminary results indicate that our predictive model outperforms these baselines that flatly consider features, \\ie not grouping them in clinical and echocardiographic features.",
      "authors": [
        "Aiman Faiz",
        "Anna Maria De Roberto",
        "Claudio Pascarelli",
        "Gianvito Mitrano",
        "Gianluca Fimiani",
        "Marina Garofano",
        "Genoveffa Tortora",
        "Mariangela Lazoi",
        "Claudio Passino",
        "Alessia Bramanti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Other Statistics (stat.OT)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T14:07:05+00:00",
          "link": "https://arxiv.org/abs/2505.09619v1",
          "size": "135kb",
          "version": "v1"
        },
        {
          "date": "2025-05-16T16:36:29+00:00",
          "link": "https://arxiv.org/abs/2505.09619v2",
          "size": "138kb",
          "version": "v2"
        },
        {
          "date": "2025-05-22T13:49:33+00:00",
          "link": "https://arxiv.org/abs/2505.09619v3",
          "size": "138kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T15:55:05+00:00",
          "link": "https://arxiv.org/abs/2505.09619v4",
          "size": "94kb",
          "version": "v4"
        }
      ],
      "title": "Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09619",
        "HTML": "https://arxiv.org/html/2505.09619v4",
        "PDF": "https://arxiv.org/pdf/2505.09619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a machine learning model for heart failure risk stratification in healthcare, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Ensemble Learning",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.16908",
      "abstract": "Although quantum circuit depth is commonly used to approximate circuit runtimes, it overlooks a prevailing trait of current hardware implementation: different gates have different execution times. Recognizing the potential for discrepancies, we investigate depth's accuracy for comparing runtimes between compiled versions of the same circuit. In particular, we assess the accuracy of traditional and multi-qubit depth for (1) predicting relative differences in runtime and (2) identifying compiled circuit version(s) with the shortest runtime. Finding that circuit depth is not accurate for either task, we introduce a new metric, gate-aware depth, that weights gates' contributions to runtime using an architecture's average gate execution times. Using average gate times allows gate-aware depth to capture variations by gate type without requiring exact knowledge of all gate times, increasing accuracy while maintaining portability across devices of the same architecture. Compared to traditional and multi-qubit depth, gate-aware depth reduces the average relative error of predictions in task (1) by 68 and 18 times and increases the average number of correct identifications in task (2) by 20 and 43 percentage points, respectively. Finally, we provide gate-aware depth weight configurations for current IBM Eagle and Heron architectures.",
      "authors": [
        "Matthew Tremba",
        "Paul Hovland",
        "Ji Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T17:09:43+00:00",
          "link": "https://arxiv.org/abs/2505.16908v1",
          "size": "575kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T16:44:04+00:00",
          "link": "https://arxiv.org/abs/2505.16908v2",
          "size": "968kb",
          "version": "v2"
        }
      ],
      "title": "Is Circuit Depth Accurate for Comparing Quantum Circuit Runtimes?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16908",
        "HTML": "https://arxiv.org/html/2505.16908v2",
        "PDF": "https://arxiv.org/pdf/2505.16908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces a new metric for comparing quantum circuit runtimes, focusing on quantum computing metrics rather than LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/mtkgv/qcre",
        "https://github.com/mtkgv/cdaa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02574",
      "abstract": "Accurate remote sensing geographic mapping requires timely and representative samples. However, rapid land surface changes often render static samples obsolete within months, making manual sample updates labor-intensive and unsustainable. To address this challenge, we propose TasGen, a two-stage Temporal spectral-aware Automatic Sample Generation method for generating dynamic training samples from single-date static labels without human intervention. Land surface dynamics often manifest as anomalies in temporal-spectral sequences. %These anomalies are multivariate yet unified: temporal, spectral, or joint anomalies stem from different mechanisms and cannot be naively coupled, as this may obscure the nature of changes. Yet, any land surface state corresponds to a coherent temporal-spectral signature, which would be lost if the two dimensions are modeled separately. To effectively capture these dynamics, TasGen first disentangles temporal and spectral features to isolate their individual contributions, and then couples them to model their synergistic interactions. In the first stage, we introduce a hierarchical temporal-spectral variational autoencoder (HTS-VAE) with a dual-dimension embedding to learn low-dimensional latent patterns of normal samples by first disentangling and then jointly embedding temporal and spectral information. This temporal-spectral embedding enables robust anomaly detection by identifying deviations from learned joint patterns. In the second stage, a classifier trained on stable samples relabels change points across time to generate dynamic samples. To not only detect but also explain surface dynamics, we further propose an anomaly interpretation method based on Gibbs sampling, which attributes changes to specific spectral-temporal dimensions.",
      "authors": [
        "Shuai Yuan",
        "Shuang Chen",
        "Tianwu Lin",
        "Jincheng Yuan",
        "Geng Tian",
        "Yang Xu",
        "Jie Wang",
        "Peng Gong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T07:55:16+00:00",
          "link": "https://arxiv.org/abs/2506.02574v1",
          "size": "3205kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:05:23+00:00",
          "link": "https://arxiv.org/abs/2506.02574v2",
          "size": "4682kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic mapping from static labels: remote sensing dynamic sample generation with temporal-spectral embedding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02574",
        "HTML": "https://arxiv.org/html/2506.02574v2",
        "PDF": "https://arxiv.org/pdf/2506.02574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on remote sensing and dynamic sample generation for geographic mapping using temporal-spectral embedding, without addressing any aspect of LLM training data processing."
      },
      "tasks": [
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12006",
      "abstract": "The cross-Modality Domain Adaptation (crossMoDA) challenge series, initiated in 2021 in conjunction with the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), focuses on unsupervised cross-modality segmentation, learning from contrast-enhanced T1 (ceT1) and transferring to T2 MRI. The task is an extreme example of domain shift chosen to serve as a meaningful and illustrative benchmark. From a clinical application perspective, it aims to automate Vestibular Schwannoma (VS) and cochlea segmentation on T2 scans for more cost-effective VS management. Over time, the challenge objectives have evolved to enhance its clinical relevance. The challenge evolved from using single-institutional data and basic segmentation in 2021 to incorporating multi-institutional data and Koos grading in 2022, and by 2023, it included heterogeneous routine data and sub-segmentation of intra- and extra-meatal tumour components. In this work, we report the findings of the 2022 and 2023 editions and perform a retrospective analysis of the challenge progression over the years. The observations from the successive challenge contributions indicate that the number of outliers decreases with an expanding dataset. This is notable since the diversity of scanning protocols of the datasets concurrently increased. The winning approach of the 2023 edition reduced the number of outliers on the 2021 and 2022 testing data, demonstrating how increased data heterogeneity can enhance segmentation performance even on homogeneous data. However, the cochlea Dice score declined in 2023, likely due to the added complexity from tumour sub-annotations affecting overall segmentation performance. While progress is still needed for clinically acceptable VS segmentation, the plateauing performance suggests that a more challenging cross-modal task may better serve future benchmarking.",
      "authors": [
        "Navodini Wijethilake",
        "Reuben Dorent",
        "Marina Ivory",
        "Aaron Kujawa",
        "Stefan Cornelissen",
        "Patrick Langenhuizen",
        "Mohamed Okasha",
        "Anna Oviedova",
        "Hexin Dong",
        "Bogyeong Kang",
        "Guillaume Sall\\'e",
        "Luyi Han",
        "Ziyuan Zhao",
        "Han Liu",
        "Yubo Fan",
        "Tao Yang",
        "Shahad Hardan",
        "Hussain Alasmawi",
        "Santosh Sanjeev",
        "Yuzhou Zhuang",
        "Satoshi Kondo",
        "Maria Baldeon Calisto",
        "Shaikh Muhammad Uzair Noman",
        "Cancan Chen",
        "Ipek Oguz",
        "Rongguo Zhang",
        "Mina Rezaei",
        "Susana K. Lai-Yuen",
        "Satoshi Kasai",
        "Yunzhi Huang",
        "Chih-Cheng Hung",
        "Mohammad Yaqub",
        "Lisheng Wang",
        "Benoit M. Dawant",
        "Cuntai Guan",
        "Ritse Mann",
        "Vincent Jaouen",
        "Tae-Eui Kam",
        "Li Zhang",
        "Jonathan Shapey",
        "Tom Vercauteren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T17:56:39+00:00",
          "link": "https://arxiv.org/abs/2506.12006v1",
          "size": "1418kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T14:00:00+00:00",
          "link": "https://arxiv.org/abs/2506.12006v2",
          "size": "1419kb",
          "version": "v2"
        },
        {
          "date": "2025-07-24T14:51:39+00:00",
          "link": "https://arxiv.org/abs/2506.12006v3",
          "size": "1419kb",
          "version": "v3"
        }
      ],
      "title": "crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12006",
        "HTML": "https://arxiv.org/html/2506.12006v3",
        "PDF": "https://arxiv.org/pdf/2506.12006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on domain adaptation techniques for medical image segmentation, which is unrelated to LLM training data processing. It involves image data rather than text data."
      },
      "tasks": [
        "Benchmarking",
        "Domain Adaptation",
        "Segmentation"
      ],
      "repo_urls": [
        "https://github.com/fiy2w/cmda2022.superpolymerization",
        "https://github.com/ReubenDo/crossmoda2022"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22495",
      "abstract": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic characteristics, ranging from rhythm fluctuations to subtle waveform deformations that evolve across time and frequency domains. However, supervised ECG models tend to overfit dominant and repetitive patterns, overlooking fine-grained but clinically critical cues, a phenomenon known as Simplicity Bias (SB), where models favor easily learnable signals over subtle but informative ones. In this work, we first empirically demonstrate the presence of SB in ECG analyses and its negative impact on diagnostic performance, while simultaneously discovering that self-supervised learning (SSL) can alleviate it, providing a promising direction for tackling the bias. Following the SSL paradigm, we propose a novel method comprising two key components: 1) Temporal-Frequency aware Filters to capture temporal-frequency features reflecting the dynamic characteristics of ECG signals, and 2) building on this, Multi-Grained Prototype Reconstruction for coarse and fine representation learning across dual domains, further mitigating SB. To advance SSL in ECG analyses, we curate a large-scale multi-site ECG dataset with 1.53 million recordings from over 300 clinical centers. Experiments on three downstream tasks across six ECG datasets demonstrate that our method effectively reduces SB and achieves state-of-the-art performance. Code and dataset will be released publicly.",
      "authors": [
        "He-Yang Xu",
        "Hongxiang Gao",
        "Yuwen Li",
        "Xiu-Shen Wei and Chengyu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T03:25:49+00:00",
          "link": "https://arxiv.org/abs/2506.22495v1",
          "size": "4304kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T15:31:13+00:00",
          "link": "https://arxiv.org/abs/2506.22495v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22495",
        "PDF": "https://arxiv.org/pdf/2506.22495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses self-supervised learning to reduce simplicity bias in ECG analyses. It is focused on healthcare data and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22607",
      "abstract": "Age-specific fertility rates (ASFRs) provide the most extensive record of reproductive change, but their aggregate nature obscures the individual-level behavioral mechanisms that drive fertility trends. To bridge this micro-macro divide, we introduce a likelihood-free Bayesian framework that couples a demographically interpretable, individual-level simulation model of the reproductive process with Sequential Neural Posterior Estimation (SNPE). We show that this framework successfully recovers core behavioral parameters governing contemporary fertility, including preferences for family size, reproductive timing, and contraceptive failure, using only ASFRs. The framework's effectiveness is validated on cohorts from four countries with diverse fertility regimes. Most compellingly, the model, estimated solely on aggregate data, successfully predicts out-of-sample distributions of individual-level outcomes, including age at first sex, desired family size, and birth intervals. Because our framework yields complete synthetic life histories, it significantly reduces the data requirements for building microsimulation models and enables behaviorally explicit demographic forecasts.",
      "authors": [
        "Daniel Ciganda",
        "Ignacio Camp\\'on",
        "I\\~naki Permanyer",
        "Jakob H Macke"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:09:50+00:00",
          "link": "https://arxiv.org/abs/2506.22607v1",
          "size": "3445kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T18:51:06+00:00",
          "link": "https://arxiv.org/abs/2506.22607v2",
          "size": "8310kb",
          "version": "v2"
        }
      ],
      "title": "Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22607",
        "HTML": "https://arxiv.org/html/2506.22607v2",
        "PDF": "https://arxiv.org/pdf/2506.22607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on estimating individual reproductive behavior using neural posterior estimation. It involves demographic data and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10136",
      "abstract": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical challenge in metastatic melanoma, with the underlying molecular networks being poorly understood. To address this, we constructed a dynamic Probabilistic Boolean Network model using transcriptomic data from patient tumor biopsies to elucidate the regulatory logic governing therapy response. We then employed a reinforcement learning agent to systematically discover optimal, multi-step therapeutic interventions and used explainable artificial intelligence to mechanistically interpret the agent's control policy. The analysis revealed that a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2 protein (LOXL2) was the most effective strategy. Our explainable analysis showed that this ''hit-and-run\" intervention is sufficient to erase the molecular signature driving resistance, allowing the network to self-correct without requiring sustained intervention. This study presents a novel, time-dependent therapeutic hypothesis for overcoming immunotherapy resistance and provides a powerful computational framework for identifying non-obvious intervention protocols in complex biological systems.",
      "authors": [
        "Zhonglin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:35:38+00:00",
          "link": "https://arxiv.org/abs/2507.10136v1",
          "size": "674kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:37:39+00:00",
          "link": "https://arxiv.org/abs/2507.10136v2",
          "size": "674kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T13:21:18+00:00",
          "link": "https://arxiv.org/abs/2507.10136v3",
          "size": "674kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T04:04:13+00:00",
          "link": "https://arxiv.org/abs/2507.10136v4",
          "size": "674kb",
          "version": "v4"
        }
      ],
      "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10136",
        "HTML": "https://arxiv.org/html/2507.10136v4",
        "PDF": "https://arxiv.org/pdf/2507.10136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on discovering a therapeutic strategy for melanoma using a probabilistic model and reinforcement learning, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11783",
      "abstract": "Patterns of electrical brain activity recorded via electroencephalography (EEG) offer immense value for scientific and clinical investigations. The inability of supervised EEG encoders to learn robust EEG patterns and their over-reliance on expensive signal annotations have sparked a transition towards general-purpose self-supervised EEG encoders, i.e., EEG foundation models (EEG-FMs), for robust and scalable EEG feature extraction. However, the real-world readiness of early EEG-FMs and the rubric for long-term research progress remain unclear. A systematic and comprehensive review of first-generation EEG-FMs is therefore necessary to understand the current state-of-the-art and identify key directions for future EEG-FMs. To that end, this study reviews 10 early EEG-FMs and presents a critical synthesis of their methodology, empirical findings, and outstanding research gaps. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. We believe that developing benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may further advance the translational utility and real-world adoption of EEG-FMs.",
      "authors": [
        "Gayal Kuruppu",
        "Neeraj Wagh",
        "Yogatheesan Varatharajah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:52:44+00:00",
          "link": "https://arxiv.org/abs/2507.11783v1",
          "size": "1309kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T20:10:43+00:00",
          "link": "https://arxiv.org/abs/2507.11783v2",
          "size": "1303kb",
          "version": "v2"
        }
      ],
      "title": "EEG Foundation Models: A Critical Review of Current Progress and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11783",
        "HTML": "https://arxiv.org/html/2507.11783v2",
        "PDF": "https://arxiv.org/pdf/2507.11783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper offers a review of EEG foundation models, specifically dealing with EEG data. It does not address LLM training data processing in any form."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12890",
      "abstract": "Songs, as a central form of musical art, exemplify the richness of human intelligence and creativity. While recent advances in generative modeling have enabled notable progress in long-form song generation, current systems for full-length song synthesis still face major challenges, including data imbalance, insufficient controllability, and inconsistent musical quality. DiffRhythm, a pioneering diffusion-based model, advanced the field by generating full-length songs with expressive vocals and accompaniment. However, its performance was constrained by an unbalanced model training dataset and limited controllability over musical style, resulting in noticeable quality disparities and restricted creative flexibility. To address these limitations, we propose DiffRhythm+, an enhanced diffusion-based framework for controllable and flexible full-length song generation. DiffRhythm+ leverages a substantially expanded and balanced training dataset to mitigate issues such as repetition and omission of lyrics, while also fostering the emergence of richer musical skills and expressiveness. The framework introduces a multi-modal style conditioning strategy, enabling users to precisely specify musical styles through both descriptive text and reference audio, thereby significantly enhancing creative control and diversity. We further introduce direct performance optimization aligned with user preferences, guiding the model toward consistently preferred outputs across evaluation metrics. Extensive experiments demonstrate that DiffRhythm+ achieves significant improvements in naturalness, arrangement complexity, and listener satisfaction over previous systems.",
      "authors": [
        "Huakang Chen",
        "Yuepeng Jiang",
        "Guobin Ma",
        "Chunbo Hao",
        "Shuai Wang",
        "Jixun Yao",
        "Ziqian Ning",
        "Meng Meng",
        "Jian Luan",
        "Lei Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:18:55+00:00",
          "link": "https://arxiv.org/abs/2507.12890v1",
          "size": "219kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T08:15:02+00:00",
          "link": "https://arxiv.org/abs/2507.12890v2",
          "size": "219kb",
          "version": "v2"
        }
      ],
      "title": "DiffRhythm+: Controllable and Flexible Full-Length Song Generation with Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12890",
        "HTML": "https://arxiv.org/html/2507.12890v2",
        "PDF": "https://arxiv.org/pdf/2507.12890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with advancements in music generation using a diffusion-based model, focusing on issues like data imbalance and control in music generation. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15292",
      "abstract": "Visualizing subtle vascular motions in endoscopic surgery is crucial for surgical precision and decision-making, yet remains challenging due to the complex and dynamic nature of surgical scenes. To address this, we introduce EndoControlMag, a training-free, Lagrangian-based framework with mask-conditioned vascular motion magnification tailored to endoscopic environments. Our approach features two key modules: a Periodic Reference Resetting (PRR) scheme that divides videos into short overlapping clips with dynamically updated reference frames to prevent error accumulation while maintaining temporal coherence, and a Hierarchical Tissue-aware Magnification (HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores using a pretrained visual tracking model to maintain accurate localization despite occlusions and view changes. It then applies one of two adaptive softening strategies to surrounding tissues: motion-based softening that modulates magnification strength proportional to observed tissue displacement, or distance-based exponential decay that simulates biomechanical force attenuation. This dual-mode approach accommodates diverse surgical scenarios-motion-based softening excels with complex tissue deformations while distance-based softening provides stability during unreliable optical flow conditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four different surgery types and various challenging scenarios, including occlusions, instrument disturbance, view changes, and vessel deformations. Quantitative metrics, visual assessments, and expert surgeon evaluations demonstrate that EndoControlMag significantly outperforms existing methods in both magnification accuracy and visual quality while maintaining robustness across challenging surgical conditions. The code, dataset, and video results are available at https://szupc.github.io/EndoControlMag/.",
      "authors": [
        "An Wang",
        "Rulin Zhou",
        "Mengya Xu",
        "Yiru Ye",
        "Longfei Gou",
        "Yiting Chang",
        "Hao Chen",
        "Chwee Ming Lim",
        "Jiankun Wang",
        "Hongliang Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:47:44+00:00",
          "link": "https://arxiv.org/abs/2507.15292v1",
          "size": "1683kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T05:11:23+00:00",
          "link": "https://arxiv.org/abs/2507.15292v2",
          "size": "1672kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T12:04:57+00:00",
          "link": "https://arxiv.org/abs/2507.15292v3",
          "size": "1677kb",
          "version": "v3"
        },
        {
          "date": "2025-07-24T13:26:19+00:00",
          "link": "https://arxiv.org/abs/2507.15292v4",
          "size": "1677kb",
          "version": "v4"
        }
      ],
      "title": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15292",
        "HTML": "https://arxiv.org/html/2507.15292v4",
        "PDF": "https://arxiv.org/pdf/2507.15292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for endoscopic vascular motion magnification and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16122",
      "abstract": "Accurate and efficient medical image segmentation is crucial but challenging due to anatomical variability and high computational demands on volumetric data. Recent hybrid CNN-Transformer architectures achieve state-of-the-art results but add significant complexity. In this paper, we propose MLRU++, a Multiscale Lightweight Residual UNETR++ architecture designed to balance segmentation accuracy and computational efficiency. It introduces two key innovations: a Lightweight Channel and Bottleneck Attention Module (LCBAM) that enhances contextual feature encoding with minimal overhead, and a Multiscale Bottleneck Block (M2B) in the decoder that captures fine-grained details via multi-resolution feature aggregation. Experiments on four publicly available benchmark datasets (Synapse, BTCV, ACDC, and Decathlon Lung) demonstrate that MLRU++ achieves state-of-the-art performance, with average Dice scores of 87.57% (Synapse), 93.00% (ACDC), and 81.12% (Lung). Compared to existing leading models, MLRU++ improves Dice scores by 5.38% and 2.12% on Synapse and ACDC, respectively, while significantly reducing parameter count and computational cost. Ablation studies evaluating LCBAM and M2B further confirm the effectiveness of the proposed architectural components. Results suggest that MLRU++ offers a practical and high-performing solution for 3D medical image segmentation tasks. Source code is available at: https://github.com/1027865/MLRUPP",
      "authors": [
        "Nand Kumar Yadav",
        "Rodrigue Rizk",
        "William CW Chen",
        "KC (Santosh AI Research Lab",
        "Department of Computer Science and Biomedical and Translational Sciences",
        "Sanford School of Medicine",
        "University Of South Dakota",
        "Vermillion",
        "SD",
        "USA.)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T00:30:44+00:00",
          "link": "https://arxiv.org/abs/2507.16122v1",
          "size": "8305kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T04:17:09+00:00",
          "link": "https://arxiv.org/abs/2507.16122v2",
          "size": "8307kb",
          "version": "v2"
        }
      ],
      "title": "MLRU++: Multiscale Lightweight Residual UNETR++ with Attention for Efficient 3D Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16122",
        "HTML": "https://arxiv.org/html/2507.16122v2",
        "PDF": "https://arxiv.org/pdf/2507.16122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on medical image segmentation using a hybrid CNN-Transformer architecture and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16548",
      "abstract": "The proper design and architecture of testing machine learning models, especially in their application to quantitative finance problems, is crucial. The most important aspect of this process is selecting an adequate loss function for training, validation, estimation purposes, and hyperparameter tuning. Therefore, in this research, through empirical experiments on equity and cryptocurrency assets, we apply the Mean Absolute Directional Loss (MADL) function, which is more adequate for optimizing forecast-generating models used in algorithmic investment strategies. The MADL function results are compared between Transformer and LSTM models, and we show that in almost every case, Transformer results are significantly better than those obtained with LSTM.",
      "authors": [
        "Jakub Micha\\'nk\\'ow",
        "Pawe{\\l} Sakowski",
        "Robert \\'Slepaczuk"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Finance (q-fin.CP)",
        "Machine Learning (cs.LG)",
        "Trading and Market Microstructure (q-fin.TR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T12:57:25+00:00",
          "link": "https://arxiv.org/abs/2507.16548v1",
          "size": "1306kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T09:56:46+00:00",
          "link": "https://arxiv.org/abs/2507.16548v2",
          "size": "1306kb",
          "version": "v2"
        }
      ],
      "title": "Alternative Loss Function in Evaluation of Transformer Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16548",
        "HTML": "https://arxiv.org/html/2507.16548v2",
        "PDF": "https://arxiv.org/pdf/2507.16548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the use of an alternative loss function for evaluating models in quantitative finance, specifically between Transformer and LSTM models. It does not focus on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16838",
      "abstract": "Mispronunciation detection and diagnosis (MDD) is a significant part in modern computer aided language learning (CALL) systems. Within MDD, phoneme-level pronunciation assessment is key to helping L2 learners improve their pronunciation. However, most systems are based on a form of goodness of pronunciation (GOP) which requires pre-segmentation of speech into phonetic units. This limits the accuracy of these methods and the possibility to use modern CTC-based acoustic models for their evaluation. In this study, we first propose self-alignment GOP (GOP-SA) that enables the use of CTC-trained ASR models for MDD. Next, we define a more general alignment-free method that takes all possible alignments of the target phoneme into account (GOP-AF). We give a theoretical account of our definition of GOP-AF, an implementation that solves potential numerical issues as well as a proper normalization which makes the method applicable with acoustic models with different peakiness over time. We provide extensive experimental results on the CMU Kids and Speechocean762 datasets comparing the different definitions of our methods, estimating the dependency of GOP-AF on the peakiness of the acoustic models and on the amount of context around the target phoneme. Finally, we compare our methods with recent studies over the Speechocean762 data showing that the feature vectors derived from the proposed method achieve state-of-the-art results on phoneme-level pronunciation assessment.",
      "authors": [
        "Xinwei Cao",
        "Zijian Fan",
        "Torbj{\\o}rn Svendsen",
        "Giampiero Salvi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:00:58+00:00",
          "link": "https://arxiv.org/abs/2507.16838v1",
          "size": "226kb",
          "version": "v1"
        },
        {
          "date": "2025-07-24T02:55:40+00:00",
          "link": "https://arxiv.org/abs/2507.16838v2",
          "size": "226kb",
          "version": "v2"
        }
      ],
      "title": "Segmentation-free Goodness of Pronunciation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16838",
        "HTML": "https://arxiv.org/html/2507.16838v2",
        "PDF": "https://arxiv.org/pdf/2507.16838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mispronunciation detection and diagnosis using novel acoustic models and methods like GOP-SA and GOP-AF, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.09957",
      "abstract": "It is well known that artificial neural networks initialized from independent and identically distributed priors converge to Gaussian processes in the limit of a large number of neurons per hidden layer. In this work we prove an analogous result for Quantum Neural Networks (QNNs). Namely, we show that the outputs of certain models based on Haar random unitary or orthogonal deep QNNs converge to Gaussian processes in the limit of large Hilbert space dimension $d$. The derivation of this result is more nuanced than in the classical case due to the role played by the input states, the measurement observable, and the fact that the entries of unitary matrices are not independent. Then, we show that the efficiency of predicting measurements at the output of a QNN using Gaussian process regression depends on the observable's bodyness. Furthermore, our theorems imply that the concentration of measure phenomenon in Haar random QNNs is worse than previously thought, as we prove that expectation values and gradients concentrate as $\\mathcal{O}\\left(\\frac{1}{e^d \\sqrt{d}}\\right)$. Finally, we discuss how our results improve our understanding of concentration in $t$-designs.",
      "authors": [
        "Diego Garc\\'ia-Mart\\'in",
        "Martin Larocca",
        "M. Cerezo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-17T05:32:45+00:00",
          "link": "https://arxiv.org/abs/2305.09957v1",
          "size": "1770kb",
          "version": "v1"
        },
        {
          "date": "2023-11-09T23:22:07+00:00",
          "link": "https://arxiv.org/abs/2305.09957v2",
          "size": "1800kb",
          "version": "v2"
        },
        {
          "date": "2024-11-20T01:12:04+00:00",
          "link": "https://arxiv.org/abs/2305.09957v3",
          "size": "2075kb",
          "version": "v3"
        }
      ],
      "title": "Quantum neural networks form Gaussian processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.09957",
        "PDF": "https://arxiv.org/pdf/2305.09957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines quantum neural networks and their convergence to Gaussian processes, which does not pertain to the domain of LLM training data processing or associated methodologies."
      },
      "tasks": [
        "Form",
        "Gaussian Processes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.01804",
      "abstract": "We present Exact Volumetric Ellipsoid Rendering (EVER), a method for real-time differentiable emission-only volume rendering. Unlike recent rasterization based approach by 3D Gaussian Splatting (3DGS), our primitive based representation allows for exact volume rendering, rather than alpha compositing 3D Gaussian billboards. As such, unlike 3DGS our formulation does not suffer from popping artifacts and view dependent density, but still achieves frame rates of $\\sim\\!30$ FPS at 720p on an NVIDIA RTX4090. Since our approach is built upon ray tracing it enables effects such as defocus blur and camera distortion (e.g. such as from fisheye cameras), which are difficult to achieve by rasterization. We show that our method is more accurate with fewer blending issues than 3DGS and follow-up work on view-consistent rendering, especially on the challenging large-scale scenes from the Zip-NeRF dataset where it achieves sharpest results among real-time techniques.",
      "authors": [
        "Alexander Mai",
        "Peter Hedman",
        "George Kopanas",
        "Dor Verbin",
        "David Futschik",
        "Qiangeng Xu",
        "Falko Kuester",
        "Jonathan T. Barron",
        "Yinda Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T17:59:09+00:00",
          "link": "https://arxiv.org/abs/2410.01804v1",
          "size": "39567kb",
          "version": "v1"
        },
        {
          "date": "2024-10-03T18:21:07+00:00",
          "link": "https://arxiv.org/abs/2410.01804v2",
          "size": "39567kb",
          "version": "v2"
        },
        {
          "date": "2024-10-09T01:25:35+00:00",
          "link": "https://arxiv.org/abs/2410.01804v3",
          "size": "39588kb",
          "version": "v3"
        },
        {
          "date": "2024-10-18T17:20:20+00:00",
          "link": "https://arxiv.org/abs/2410.01804v4",
          "size": "39614kb",
          "version": "v4"
        },
        {
          "date": "2024-10-29T20:17:56+00:00",
          "link": "https://arxiv.org/abs/2410.01804v5",
          "size": "39614kb",
          "version": "v5"
        },
        {
          "date": "2025-07-24T16:36:50+00:00",
          "link": "https://arxiv.org/abs/2410.01804v6",
          "size": "39214kb",
          "version": "v6"
        }
      ],
      "title": "EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01804",
        "HTML": "https://arxiv.org/html/2410.01804",
        "PDF": "https://arxiv.org/pdf/2410.01804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on volumetric rendering techniques for view synthesis and does not relate to LLM training data processing, pretraining, fine-tuning, or any associated data processing tasks."
      },
      "tasks": [
        "3DGS",
        "NeRF",
        "Novel View Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.15105",
      "abstract": "In mixed autonomy traffic environment, every decision made by an autonomous-driving car may have a great impact on the transportation system. Because of the complex interaction between vehicles, it is challenging to make decisions that can ensure both high traffic efficiency and safety now and futher. Connected automated vehicles (CAVs) have great potential to improve the quality of decision-making in this continuous, highly dynamic and interactive environment because of their stronger sensing and communicating ability. For multi-vehicle collaborative decision-making algorithms based on deep reinforcement learning (DRL), we need to represent the interactions between vehicles to obtain interactive features. The representation in this aspect directly affects the learning efficiency and the quality of the learned policy. To this end, we propose a CAV decision-making architecture based on transformer and reinforcement learning algorithms. A learnable policy token is used as the learning medium of the multi-vehicle joint policy, the states of all vehicles in the area of interest can be adaptively noticed in order to extract interactive features among agents. We also design an intuitive physical positional encodings, the redundant location information of which optimizes the performance of the network. Simulations show that our model can make good use of all the state information of vehicles in traffic scenario, so as to obtain high-quality driving decisions that meet efficiency and safety objectives. The comparison shows that our method significantly improves existing DRL-based multi-vehicle cooperative decision-making algorithms.",
      "authors": [
        "Ye Han",
        "Lijun Zhang",
        "Dejian Meng",
        "Xingyu Hu",
        "Yixia Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T15:16:35+00:00",
          "link": "https://arxiv.org/abs/2409.15105v1",
          "size": "4776kb",
          "version": "v1"
        }
      ],
      "title": "SPformer: A Transformer Based DRL Decision Making Method for Connected Automated Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15105",
        "HTML": "https://arxiv.org/html/2409.15105",
        "PDF": "https://arxiv.org/pdf/2409.15105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a decision-making method for connected automated vehicles using transformers. It does not involve LLM training data processing or related operations such as dataset curation or quality improvement for LLMs."
      },
      "tasks": [
        "Autonomous Driving",
        "Decision Making",
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.09834",
      "abstract": "This paper studies the convergence of a spatial semidiscretization of a three-dimensional stochastic Allen-Cahn equation with multiplicative noise. For non-smooth initial data, the regularity of the mild solution is investigated, and an error estimate is derived within the spatial (L^2)-norm setting. In the case of smooth initial data, two error estimates are established within the framework of general spatial (L^q)-norms.",
      "authors": [
        "Qin Zhou and Binjie Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-18T09:50:59+00:00",
          "link": "https://arxiv.org/abs/2401.09834v1",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "2024-02-11T07:23:02+00:00",
          "link": "https://arxiv.org/abs/2401.09834v2",
          "size": "30kb",
          "version": "v2"
        },
        {
          "date": "2024-03-19T14:48:22+00:00",
          "link": "https://arxiv.org/abs/2401.09834v3",
          "size": "31kb",
          "version": "v3"
        },
        {
          "date": "2024-04-18T14:32:54+00:00",
          "link": "https://arxiv.org/abs/2401.09834v4",
          "size": "31kb",
          "version": "v4"
        },
        {
          "date": "2024-05-30T14:20:15+00:00",
          "link": "https://arxiv.org/abs/2401.09834v5",
          "size": "30kb",
          "version": "v5"
        },
        {
          "date": "2024-06-17T03:31:53+00:00",
          "link": "https://arxiv.org/abs/2401.09834v6",
          "size": "27kb",
          "version": "v6"
        },
        {
          "date": "2024-11-22T23:04:17+00:00",
          "link": "https://arxiv.org/abs/2401.09834v7",
          "size": "32kb",
          "version": "v7"
        },
        {
          "date": "2025-07-24T15:12:41+00:00",
          "link": "https://arxiv.org/abs/2401.09834v8",
          "size": "38kb",
          "version": "v8"
        }
      ],
      "title": "Convergence of a spatial semidiscretization for a three-dimensional stochastic Allen-Cahn equation with multiplicative noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.09834",
        "PDF": "https://arxiv.org/pdf/2401.09834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies mathematical convergence in stochastic equations, a topic unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.06121",
      "abstract": "Lane detection is a critical component of Advanced Driver Assistance Systems (ADAS). Existing lane detection algorithms generally perform well under favorable weather conditions. However, their performance degrades significantly in adverse conditions, such as fog, which increases the risk of traffic accidents. This challenge is compounded by the lack of specialized datasets and methods designed for foggy environments. To address this, we introduce the FoggyLane dataset, captured in real-world foggy scenarios, and synthesize two additional datasets, FoggyCULane and FoggyTusimple, from existing popular lane detection datasets. Furthermore, we propose a robust Fog-Enhanced Network for lane detection, incorporating a Global Feature Fusion Module (GFFM) to capture global relationships in foggy images, a Kernel Feature Fusion Module (KFFM) to model the structural and positional relationships of lane instances, and a Low-level Edge Enhanced Module (LEEM) to address missing edge details in foggy conditions. Comprehensive experiments demonstrate that our method achieves state-of-the-art performance, with F1-scores of 95.04 on FoggyLane, 79.85 on FoggyCULane, and 96.95 on FoggyTusimple. Additionally, with TensorRT acceleration, the method reaches a processing speed of 38.4 FPS on the NVIDIA Jetson AGX Orin, confirming its real-time capabilities and robustness in foggy environments.",
      "authors": [
        "Ronghui Zhang",
        "Yuhang Ma",
        "Tengfei Li",
        "Ziyu Lin",
        "Yueying Wu",
        "Junzhou Chen",
        "Lin Zhang",
        "Jia Hu",
        "Tony Z. Qiu and Konghui Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T15:13:01+00:00",
          "link": "https://arxiv.org/abs/2504.06121v1",
          "size": "34061kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T05:25:05+00:00",
          "link": "https://arxiv.org/abs/2504.06121v2",
          "size": "30555kb",
          "version": "v2"
        },
        {
          "date": "2025-04-23T02:22:10+00:00",
          "link": "https://arxiv.org/abs/2504.06121v3",
          "size": "11882kb",
          "version": "v3"
        },
        {
          "date": "2025-06-08T11:52:11+00:00",
          "link": "https://arxiv.org/abs/2504.06121v4",
          "size": "10635kb",
          "version": "v4"
        },
        {
          "date": "2025-06-16T01:05:37+00:00",
          "link": "https://arxiv.org/abs/2504.06121v5",
          "size": "6442kb",
          "version": "v5"
        },
        {
          "date": "2025-06-22T05:33:20+00:00",
          "link": "https://arxiv.org/abs/2504.06121v6",
          "size": "6453kb",
          "version": "v6"
        },
        {
          "date": "2025-07-07T21:04:20+00:00",
          "link": "https://arxiv.org/abs/2504.06121v7",
          "size": "6916kb",
          "version": "v7"
        },
        {
          "date": "2025-07-23T23:32:46+00:00",
          "link": "https://arxiv.org/abs/2504.06121v8",
          "size": "6922kb",
          "version": "v8"
        }
      ],
      "title": "A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06121",
        "HTML": "https://arxiv.org/html/2504.06121",
        "PDF": "https://arxiv.org/pdf/2504.06121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces new datasets like FoggyLane, which is related to lane detection in foggy conditions. While it involves data synthesis, the focus is on ADAS systems rather than LLM data processing for pretraining or fine-tuning."
      },
      "tasks": [
        "Lane Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.12607",
      "abstract": "The optimization of cooling systems is important in many cases, for example for cabin and battery cooling in electric cars. Such an optimization is governed by multiple, conflicting objectives and it is performed across a multi-dimensional parameter space. The extent of the parameter space, the complexity of the non-linear model of the system, as well as the time needed per simulation run and factors that are not modeled in the simulation necessitate an iterative, semi-automatic approach. We present an interactive visual optimization approach, where the user works with a p-h diagram to steer an iterative, guided optimization process. A deep learning (DL) model provides estimates for parameters, given a target characterization of the system, while numerical simulation is used to compute system characteristics for an ensemble of parameter sets. Since the DL model only serves as an approximation of the inverse of the cooling system and since target characteristics can be chosen according to different, competing objectives, an iterative optimization process is realized, developing multiple sets of intermediate solutions, which are visually related to each other. The standard p-h diagram, integrated interactively in this approach, is complemented by a dual, also interactive visual representation of additional expressive measures representing the system characteristics. We show how the known four-points semantic of the p-h diagram meaningfully transfers to the dual data representation. When evaluating this approach in the automotive domain, we found that our solution helped with the overall comprehension of the cooling system and that it lead to a faster convergence during optimization.",
      "authors": [
        "Rainer Splechtna",
        "Majid Behravan",
        "Mario Jelovic",
        "Denis Gracanin",
        "Helwig Hauser",
        "Kresimir Matkovic"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-08T06:24:57+00:00",
          "link": "https://arxiv.org/abs/2408.12607v1",
          "size": "41047kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Design-of-Experiments: Optimizing a Cooling System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.12607",
        "HTML": "https://arxiv.org/html/2408.12607",
        "PDF": "https://arxiv.org/pdf/2408.12607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves optimizing cooling systems using an interactive design-of-experiments approach, which does not relate to any aspect of training data processing for LLMs or dataset generation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.07986",
      "abstract": "We consider the problem of testing whether an unknown $n$-qubit quantum state $|\\psi\\rangle$ is a stabilizer state, with only single-copy access. We give an algorithm solving this problem using $O(n)$ copies, and conversely prove that $\\Omega(\\sqrt{n})$ copies are required for any algorithm. The main observation behind our algorithm is that when repeatedly measuring in a randomly chosen stabilizer basis, stabilizer states are the most likely among the set of all pure states to exhibit linear dependencies in measurement outcomes. Our algorithm is designed to probe deviations from this extremal behavior. For the lower bound, we first reduce stabilizer testing to the task of distinguishing random stabilizer states from the maximally mixed state. We then argue that, without loss of generality, it is sufficient to consider measurement strategies that a) lie in the commutant of the tensor action of the Clifford group and b) satisfy a Positive Partial Transpose (PPT) condition. By leveraging these constraints, together with novel results on the partial transposes of the generators of the Clifford commutant, we derive the lower bound on the sample complexity.",
      "authors": [
        "Marcel Hinsche",
        "Jonas Helsen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T14:39:47+00:00",
          "link": "https://arxiv.org/abs/2410.07986v1",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "title": "Single-copy stabilizer testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.07986",
        "HTML": "https://arxiv.org/html/2410.07986",
        "PDF": "https://arxiv.org/pdf/2410.07986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The topic of this paper is quantum stabilizer state testing, which does not pertain to LLM training data processing or dataset creation tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.11482",
      "abstract": "We introduce Meta Prompting (MP), a framework that elevates the reasoning capabilities of large language models (LLMs) by focusing on the formal structure of a task rather than content-specific examples. We establish a theoretical foundation for this paradigm, formalizing MP as a functor that maps a category of tasks to a category of structured prompts, thereby guaranteeing that compositional problem-solving strategies can be systematically decomposed into modular prompt structures. We extend this concept to Recursive Meta Prompting (RMP), an automated process where an LLM can generate and refine its own prompts. We model this self-improvement loop formally as a monad, providing a principled framework for automated prompt engineering. Our claims are validated through extensive experiments demonstrating that a Qwen-72B base model, guided by a single, example-agnostic meta-prompt, achieves state-of-the-art results on MATH, GSM8K, and Game of 24. These results are achieved with substantial token efficiency gains over traditional few-shot methods. Project Page: https://github.com/meta-prompting/meta-prompting.",
      "authors": [
        "Yifan Zhang",
        "Yang Yuan",
        "Andrew Chi-Chih Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-20T01:51:13+00:00",
          "link": "https://arxiv.org/abs/2311.11482v1",
          "size": "513kb",
          "version": "v1"
        },
        {
          "date": "2024-01-25T13:54:42+00:00",
          "link": "https://arxiv.org/abs/2311.11482v2",
          "size": "767kb",
          "version": "v2"
        },
        {
          "date": "2024-01-30T01:15:59+00:00",
          "link": "https://arxiv.org/abs/2311.11482v3",
          "size": "861kb",
          "version": "v3"
        },
        {
          "date": "2024-02-01T04:12:52+00:00",
          "link": "https://arxiv.org/abs/2311.11482v4",
          "size": "700kb",
          "version": "v4"
        },
        {
          "date": "2024-04-02T03:36:57+00:00",
          "link": "https://arxiv.org/abs/2311.11482v5",
          "size": "680kb",
          "version": "v5"
        },
        {
          "date": "2024-06-15T08:19:24+00:00",
          "link": "https://arxiv.org/abs/2311.11482v6",
          "size": "740kb",
          "version": "v6"
        },
        {
          "date": "2025-02-26T05:39:39+00:00",
          "link": "https://arxiv.org/abs/2311.11482v7",
          "size": "707kb",
          "version": "v7"
        },
        {
          "date": "2025-07-24T09:19:38+00:00",
          "link": "https://arxiv.org/abs/2311.11482v8",
          "size": "348kb",
          "version": "v8"
        }
      ],
      "title": "Meta Prompting for AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.11482",
        "PDF": "https://arxiv.org/pdf/2311.11482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores Meta Prompting, focusing on enhancing LLM reasoning through structured prompt design rather than on processing training data. While related to LLMs, the primary focus is on prompt engineering and task formulation, not data processing."
      },
      "tasks": [
        "Data Interaction",
        "GSM8K",
        "Language Modeling",
        "Language Modelling",
        "Math"
      ],
      "repo_urls": [
        "https://github.com/meta-prompting/meta-prompting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2209.05252",
      "abstract": "Ergonomic risk assessment is now, due to an increased awareness, carried out more often than in the past. The conventional risk assessment evaluation, based on expert-assisted observation of the workplaces and manually filling in score tables, is still predominant. Data analysis is usually done with a focus on critical moments, although without the support of contextual information and changes over time. In this paper we introduce ErgoExplorer, a system for the interactive visual analysis of risk assessment data. In contrast to the current practice, we focus on data that span across multiple actions and multiple workers while keeping all contextual information. Data is automatically extracted from video streams. Based on carefully investigated analysis tasks, we introduce new views and their corresponding interactions. These views also incorporate domain-specific score tables to guarantee an easy adoption by domain experts. All views are integrated into ErgoExplorer, which relies on coordinated multiple views to facilitate analysis through interaction. ErgoExplorer makes it possible for the first time to examine complex relationships between risk assessments of individual body parts over long sessions that span multiple operations. The newly introduced approach supports analysis and exploration at several levels of detail, ranging from a general overview, down to inspecting individual frames in the video stream, if necessary. We illustrate the usefulness of the newly proposed approach applying it to several datasets.",
      "authors": [
        "Manlio Massiris Fern\\'andez",
        "Sanjin Rado\\v{s}",
        "Kre\\v{s}imir Matkovi\\'c",
        "M. Eduard Gr\\\"oller",
        "Claudio Delrieux"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2022-09-07T13:32:45+00:00",
          "link": "https://arxiv.org/abs/2209.05252v1",
          "size": "40239kb",
          "version": "v1"
        }
      ],
      "title": "ErgoExplorer: Interactive Ergonomic Risk Assessment from Video Collections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2209.05252",
        "PDF": "https://arxiv.org/pdf/2209.05252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "ErgoExplorer is about interactive ergonomic risk assessment using video analysis. It is not relevant to LLM training data processing as it does not involve data operations pertinent to LLM pretraining or fine-tuning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.07854",
      "abstract": "Significant advances have been made in natural language processing in recent years. However, our current deep learning approach to language modeling requires substantial resources in terms of data and computation. One of the side effects of this data-hungry paradigm is the current schism between languages, separating those considered high-resource, where most of the development happens and resources are available, and the low-resource ones, which struggle to attain the same level of performance and autonomy. This study aims to introduce a new set of resources to stimulate the future development of neural text generation in Portuguese. In this work, we document the development of GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting to 200 billion tokens. Via this corpus, we trained a series of decoder-transformers named Tucano. Our models perform equal or superior to other Portuguese and multilingual language models of similar size in several Portuguese benchmarks. The evaluation of our models also reveals that model performance on many currently available benchmarks used by the Portuguese NLP community has little to no correlation with the scaling of token ingestion during training, highlighting the limitations of such evaluations when it comes to the assessment of Portuguese generative language models. All derivatives of our study are openly released on GitHub and Hugging Face. See https://nkluge-correa.github.io/Tucano/",
      "authors": [
        "Nicholas Kluge Corr\\^ea",
        "Aniket Sen",
        "Sophia Falk",
        "Shiza Fatimah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T15:06:06+00:00",
          "link": "https://arxiv.org/abs/2411.07854v1",
          "size": "3544kb",
          "version": "v1"
        }
      ],
      "title": "Tucano: Advancing Neural Text Generation for Portuguese",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07854",
        "HTML": "https://arxiv.org/html/2411.07854",
        "PDF": "https://arxiv.org/pdf/2411.07854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper documents the creation of GigaVerbo, a deduplicated Portuguese text corpus of 200 billion tokens, used to train language models. This involves data collection, deduplication, and dataset creation, contributing significantly to LLM training data processing."
      },
      "models": [
        {
          "model_path": "TucanoBR/Tucano-160m",
          "downloads": "1290",
          "likes": "3",
          "trending_score": "1.0",
          "link": "https://huggingface.co/TucanoBR/Tucano-160m"
        },
        {
          "model_path": "TucanoBR/Tucano-630m",
          "downloads": "53",
          "likes": "3",
          "trending_score": "1.0",
          "link": "https://huggingface.co/TucanoBR/Tucano-630m"
        },
        {
          "model_path": "TucanoBR/Tucano-1b1",
          "downloads": "901",
          "likes": "3",
          "trending_score": "1.0",
          "link": "https://huggingface.co/TucanoBR/Tucano-1b1"
        },
        {
          "model_path": "TucanoBR/Tucano-1b1-Instruct",
          "downloads": "117",
          "likes": "2",
          "trending_score": "1.0",
          "link": "https://huggingface.co/TucanoBR/Tucano-1b1-Instruct"
        },
        {
          "model_path": "TucanoBR/Tucano-2b4",
          "downloads": "1014",
          "likes": "5",
          "trending_score": "1.0",
          "link": "https://huggingface.co/TucanoBR/Tucano-2b4"
        },
        {
          "model_path": "TucanoBR/Tucano-2b4-Instruct",
          "downloads": "1310",
          "likes": "3",
          "trending_score": "1.0",
          "link": "https://huggingface.co/TucanoBR/Tucano-2b4-Instruct"
        },
        {
          "model_path": "TucanoBR/XGBClassifier-text-filter",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/TucanoBR/XGBClassifier-text-filter"
        },
        {
          "model_path": "TucanoBR/XGBRegressor-text-filter",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/TucanoBR/XGBRegressor-text-filter"
        },
        {
          "model_path": "TucanoBR/BERTimbau-large-text-filter",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/TucanoBR/BERTimbau-large-text-filter"
        },
        {
          "model_path": "TucanoBR/BERTimbau-base-text-filter",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/TucanoBR/BERTimbau-base-text-filter"
        },
        {
          "model_path": "cabelo/Tucano-2b4-Instruct-fp16-ov",
          "downloads": "3",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/cabelo/Tucano-2b4-Instruct-fp16-ov"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-1b1-awq",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-1b1-awq"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-1b1-Instruct-awq",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-1b1-Instruct-awq"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-160m-awq",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-160m-awq"
        },
        {
          "model_path": "TucanoBR/ViTucano-1b5-v1",
          "downloads": "16",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/TucanoBR/ViTucano-1b5-v1"
        },
        {
          "model_path": "TucanoBR/ViTucano-2b8-v1",
          "downloads": "81",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/TucanoBR/ViTucano-2b8-v1"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-630m-4bits",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-630m-4bits"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-630m-8bits",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-630m-8bits"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-2b4-Instruct-4bits",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-2b4-Instruct-4bits"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-2b4-Instruct-8bits",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-2b4-Instruct-8bits"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-2b4-4bits",
          "downloads": "1",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-2b4-4bits"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-2b4-8bits",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-2b4-8bits"
        },
        {
          "model_path": "RichardErkhov/TucanoBR_-_Tucano-2b4-awq",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/TucanoBR_-_Tucano-2b4-awq"
        }
      ],
      "datasets": [
        {
          "dataset_name": "TucanoBR/GigaVerbo-Text-Filter",
          "downloads": "108",
          "likes": "1",
          "link": "https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter"
        },
        {
          "dataset_name": "TucanoBR/GigaVerbo",
          "downloads": "1183",
          "likes": "20",
          "link": "https://huggingface.co/datasets/TucanoBR/GigaVerbo"
        },
        {
          "dataset_name": "TucanoBR/Tucano-SFT",
          "downloads": "121",
          "likes": "1",
          "link": "https://huggingface.co/datasets/TucanoBR/Tucano-SFT"
        },
        {
          "dataset_name": "TucanoBR/ViTucano-Pretrain",
          "downloads": "110",
          "likes": "1",
          "link": "https://huggingface.co/datasets/TucanoBR/ViTucano-Pretrain"
        },
        {
          "dataset_name": "TucanoBR/ViTucano-SFT",
          "downloads": "50",
          "likes": "2",
          "link": "https://huggingface.co/datasets/TucanoBR/ViTucano-SFT"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/nkluge-correa/tucano"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.05130",
      "abstract": "Recent research illustrates how AI can be developed and deployed in a manner detached from the concrete social context of application. By abstracting from the contexts of AI application, practitioners also disengage from the distinct normative structures that govern them. Building upon Helen Nissenbaum's framework of contextual integrity, I illustrate how disregard for contextual norms can threaten the integrity of a context with often decisive ethical implications. I argue that efforts to promote responsible and ethical AI can inadvertently contribute to and seemingly legitimize this disregard for established contextual norms. Echoing a persistent undercurrent in technology ethics of understanding emerging technologies as uncharted moral territory, certain approaches to AI ethics can promote a notion of AI as a novel and distinct realm for ethical deliberation, norm setting, and virtue cultivation. This narrative of AI as new ethical ground, however, can come at the expense of practitioners, policymakers and ethicists engaging with already established norms and virtues that were gradually cultivated to promote successful and responsible practice within concrete social contexts. In response, I question the current narrow prioritization in AI ethics of moral innovation over moral preservation. Engaging also with emerging foundation models, I advocate for a moderately conservative approach to the ethics of AI that prioritizes the responsible and considered integration of AI within established social contexts and their respective normative structures.",
      "authors": [
        "Alexander Martin Mussgnug"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T15:36:13+00:00",
          "link": "https://arxiv.org/abs/2412.05130v1",
          "size": "439kb",
          "version": "v1"
        },
        {
          "date": "2025-01-12T10:21:18+00:00",
          "link": "https://arxiv.org/abs/2412.05130v2",
          "size": "441kb",
          "version": "v2"
        }
      ],
      "title": "Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05130",
        "PDF": "https://arxiv.org/pdf/2412.05130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI ethics, particularly concerning contextual integrity and moral considerations, without addressing LLM training data processing or related operations."
      },
      "tasks": [
        "Ethics"
      ],
      "source": "arXiv"
    },
    {
      "id": "2305.06423",
      "abstract": "CSS-T codes are a class of stabilizer codes introduced by Rengaswamy \\emph{et al} with desired properties for quantum fault-tolerance. In this work, we comprehensively study non-degenerate CSS-T codes built from Reed-Muller codes. These classical codes allow for constructing CSS-T code families with nonvanishing asymptotic rates up to $\\frac{1}2$ and possibly diverging minimum distance when non-degenerate.",
      "authors": [
        "Emma Andrade",
        "Jessalyn Bolkema",
        "Thomas Dexter",
        "Harrison Eggers",
        "Victoria Luongo",
        "Felice Manganiello and Luke Szramowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-10T19:07:06+00:00",
          "link": "https://arxiv.org/abs/2305.06423v1",
          "size": "108kb",
          "version": "v1"
        },
        {
          "date": "2025-01-21T21:48:33+00:00",
          "link": "https://arxiv.org/abs/2305.06423v2",
          "size": "10kb",
          "version": "v2"
        }
      ],
      "title": "CSS-T Codes from Reed Muller Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.06423",
        "HTML": "https://arxiv.org/html/2305.06423",
        "PDF": "https://arxiv.org/pdf/2305.06423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores CSS-T codes derived from Reed-Muller codes for quantum fault-tolerance. There is no connection to LLM data processing or improvements to dataset quality for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10244",
      "abstract": "Software developers often have to gain an understanding of a codebase. Be it programmers getting onboarded onto a team project or, for example, developers striving to grasp an external open-source library. In either case, they frequently turn to the project's documentation. However, documentation in its traditional textual form is ill-suited for this kind of high-level exploratory analysis, since it is immutable from the readers' perspective and thus forces them to follow a predefined path. We have designed an approach bringing aspects of software architecture visualization to API reference documentation. It utilizes a highly interactive node-link diagram with expressive node glyphs and flexible filtering capabilities, providing a high-level overview of the codebase as well as details on demand. To test our design, we have implemented a prototype named Helveg, capable of automatically generating diagrams of C\\# codebases. User testing of Helveg confirmed its potential, but it also revealed problems with the readability, intuitiveness, and user experience of our tool. Therefore, in this paper, which is an extended version of our VISSOFT paper with DOI 10.1109/VISSOFT64034.2024.00012, we address many of these problems through major changes to the glyph design, means of interaction, and user interface of the tool. To assess the improvements, this new version of Helveg was evaluated again with the same group of participants as the previous version.",
      "authors": [
        "Adam \\v{S}t\\v{e}p\\'anek",
        "David Ku\\v{t}\\'ak",
        "Barbora Kozl\\'ikov\\'a",
        "Jan By\\v{s}ka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:07:50+00:00",
          "link": "https://arxiv.org/abs/2507.10244v1",
          "size": "7010kb",
          "version": "v1"
        }
      ],
      "title": "Helveg: Diagrams for Software Documentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10244",
        "HTML": "https://arxiv.org/html/2507.10244",
        "PDF": "https://arxiv.org/pdf/2507.10244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a tool for generating software documentation through diagrams. It does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.13510",
      "abstract": "Energy research software (ERS) is a central cornerstone to facilitate energy research. However, ERS is developed by researchers who, in many cases, lack formal training in software engineering. This reduces the quality of ERS, leading to limited reproducibility and reusability. To address these issues, we developed ten central recommendations for the development of ERS, covering areas such as conceptualization, development, testing, and publication of ERS. The recommendations are based on the outcomes of two workshops with a diverse group of energy researchers and aim to improve the awareness of research software engineering in the energy domain. The recommendations should enhance the quality of ERS and, therefore, the reproducibility of energy research.",
      "authors": [
        "Stephan Ferenz",
        "Emilie Frost",
        "Rico Schrage",
        "Thomas Wolgast",
        "Inga Beyers",
        "Oliver Karras",
        "Oliver Werth",
        "Astrid Nie{\\ss}e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T07:57:55+00:00",
          "link": "https://arxiv.org/abs/2502.13510v1",
          "size": "217kb",
          "version": "v1"
        }
      ],
      "title": "Ten Recommendations for Engineering Research Software in Energy Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13510",
        "HTML": "https://arxiv.org/html/2502.13510",
        "PDF": "https://arxiv.org/pdf/2502.13510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides recommendations for engineering research software in the energy sector, which does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.02853",
      "abstract": "The volatility and unpredictability of emerging technologies, such as artificial intelligence (AI), generate significant uncertainty, which is widely discussed on social media. This study examines anticipatory discourse surrounding technological futures by analysing 1.5 million posts from 400 key opinion leaders (KOLs) published on the X platform (from 2021 to 2023). Using advanced text mining techniques, including BERTopic modelling, sentiment, emotion, and attitude analyses, the research identifies 100 distinct topics reflecting anticipated tech-driven futures. Our findings emphasize the dual role of KOLs in framing \\textit{present futures} -- optimistic visions of transformative technologies like AI and IoT -- and influencing \\textit{future presents}, where these projections shape contemporary societal and geopolitical debates. Positive emotions such as Hope dominate, outweighing Anxiety, particularly in topics like ``Machine Learning, Data Science, and Deep Learning,'' while discussions around ``Climate Change'' and ``War, Ukraine, and Trump People'' elicit \\textit{Anxiety}. By framing technologies as solutions to societal challenges, KOLs act as mediators of societal narratives, bridging imagined futures and current realities. These insights underscore their pivotal role in directing public attention with emerging technologies during periods of heightened uncertainty, advancing our understanding of anticipatory discourse in technology-mediated contexts.",
      "authors": [
        "Maciej Skorski and Alina Landowska and Krzysztof Rajda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T15:20:15+00:00",
          "link": "https://arxiv.org/abs/2504.02853v1",
          "size": "508kb",
          "version": "v1"
        }
      ],
      "title": "Mapping Technological Futures: Anticipatory Discourse Through Text Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02853",
        "HTML": "https://arxiv.org/html/2504.02853",
        "PDF": "https://arxiv.org/pdf/2504.02853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines anticipatory discourse in social media about technological futures but does not address LLM training data processing or related data operations for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.07717",
      "abstract": "Accurately estimating aircraft fuel flow is essential for evaluating new procedures, designing next-generation aircraft, and monitoring the environmental impact of current aviation practices. This paper investigates the generalization capabilities of deep learning models in predicting fuel consumption, focusing particularly on their performance for aircraft types absent from the training data. We propose a novel methodology that integrates neural network architectures with domain generalization techniques to enhance robustness and reliability across a wide range of aircraft. A comprehensive dataset containing 101 different aircraft types, separated into training and generalization sets, with each aircraft type set containing 1,000 flights. We employed the base of aircraft data (BADA) model for fuel flow estimates, introduced a pseudo-distance metric to assess aircraft type similarity, and explored various sampling strategies to optimize model performance in data-sparse regions. Our results reveal that for previously unseen aircraft types, the introduction of noise into aircraft and engine parameters improved model generalization. The model is able to generalize with acceptable mean absolute percentage error between 2\\% and 10\\% for aircraft close to existing aircraft, while performance is below 1\\% error for known aircraft in the training set. This study highlights the potential of combining domain-specific insights with advanced machine learning techniques to develop scalable, accurate, and generalizable fuel flow estimation models.",
      "authors": [
        "Gabriel Jarry",
        "Ramon Dalmau",
        "Philippe Very and Junzi Sun"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T08:34:19+00:00",
          "link": "https://arxiv.org/abs/2410.07717v1",
          "size": "1473kb",
          "version": "v1"
        }
      ],
      "title": "On the Generalization Properties of Deep Learning for Aircraft Fuel Flow Estimation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.07717",
        "HTML": "https://arxiv.org/html/2410.07717",
        "PDF": "https://arxiv.org/pdf/2410.07717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on aircraft fuel flow estimation through deep learning, which is outside the scope of LLM training data processing and relevant data engineering operations."
      },
      "tasks": [
        "Domain Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.04824",
      "abstract": "In modern data analytics, analysts frequently face the challenge of searching for desirable entities by evaluating, for each entity, a collection of its feature relations to derive key analytical properties. This search is challenging because the definitions of both entities and their feature relations may span multiple, varying granularities. Existing constructs such as GROUP BY CUBE, GROUP BY GROUPING SETS, ARRAY AGGREGATE, WINDOW functions, OLAP cube, and various data explanation paradigms aim to facilitate such analyses, but all exhibit limitations in terms of composability, clear specifications, and performance. To address these challenges, we introduce Multi-Relational Algebra (MRA), which generalizes relational algebra with two core data abstractions: RelationSpace, for managing collections of relations, and SliceRelation, which structures data around entities with corresponding relation-valued features. MRA introduces a rich set of operators for transforming data between these representations, enabling complex multi-granular analysis in a modular and declarative way. An early version of MRA is in production at Google, supporting diverse data insight applications. This paper describes the motivation for MRA, its formalism, implementation, and future opportunities.",
      "authors": [
        "Xi Wu",
        "Eugene Wu",
        "Zichen Zhu",
        "Fengan Li",
        "Jeffrey F. Naughton"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-08T16:50:15+00:00",
          "link": "https://arxiv.org/abs/2311.04824v1",
          "size": "672kb",
          "version": "v1"
        },
        {
          "date": "2024-08-22T16:13:07+00:00",
          "link": "https://arxiv.org/abs/2311.04824v2",
          "size": "1766kb",
          "version": "v2"
        },
        {
          "date": "2024-09-03T22:03:44+00:00",
          "link": "https://arxiv.org/abs/2311.04824v3",
          "size": "1808kb",
          "version": "v3"
        },
        {
          "date": "2024-09-21T00:34:40+00:00",
          "link": "https://arxiv.org/abs/2311.04824v4",
          "size": "1812kb",
          "version": "v4"
        },
        {
          "date": "2024-09-30T01:35:59+00:00",
          "link": "https://arxiv.org/abs/2311.04824v5",
          "size": "1811kb",
          "version": "v5"
        },
        {
          "date": "2025-07-23T21:10:32+00:00",
          "link": "https://arxiv.org/abs/2311.04824v6",
          "size": "452kb",
          "version": "v6"
        }
      ],
      "title": "Multi-Relational Algebra for Multi-Granular Data Analytics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.04824",
        "HTML": "https://arxiv.org/html/2311.04824",
        "PDF": "https://arxiv.org/pdf/2311.04824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces Multi-Relational Algebra for handling multi-granular data analytics challenges, not focusing on LLM training data processing aspects such as dataset creation, filtering, or quality enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.02288",
      "abstract": "Large language models show a surprising in-context learning ability -- being able to use a prompt to form a prediction for a query, yet without additional training, in stark contrast to old-fashioned supervised learning. Providing a mechanistic interpretation and linking the empirical phenomenon to physics are thus challenging and remain unsolved. We study a simple yet expressive transformer with linear attention and map this structure to a spin glass model with real-valued spins, where the couplings and fields explain the intrinsic disorder in data. The spin glass model explains how the weight parameters interact with each other during pre-training, and further clarifies why an unseen function can be predicted by providing only a prompt yet without further training. Our theory reveals that for single-instance learning, increasing the task diversity leads to the emergence of in-context learning, by allowing the Boltzmann distribution to converge to a unique correct solution of weight parameters. Therefore the pre-trained transformer displays a prediction power in a novel prompt setting. The proposed analytically tractable model thus offers a promising avenue for thinking about how to interpret many intriguing but puzzling properties of large language models.",
      "authors": [
        "Yuhao Li",
        "Ruoran Bai",
        "Haiping Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-05T07:54:01+00:00",
          "link": "https://arxiv.org/abs/2408.02288v1",
          "size": "1086kb",
          "version": "v1"
        },
        {
          "date": "2024-11-13T07:13:36+00:00",
          "link": "https://arxiv.org/abs/2408.02288v2",
          "size": "1893kb",
          "version": "v2"
        },
        {
          "date": "2025-04-18T08:16:22+00:00",
          "link": "https://arxiv.org/abs/2408.02288v3",
          "size": "969kb",
          "version": "v3"
        }
      ],
      "title": "Spin glass model of in-context learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.02288",
        "HTML": "https://arxiv.org/html/2408.02288",
        "PDF": "https://arxiv.org/pdf/2408.02288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on in-context learning using a spin glass model in a mechanistic interpretation, which does not address LLM training data processing or any data engineering operations for pretraining or fine-tuning."
      },
      "tasks": [
        "Diversity",
        "In-Context Learning",
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2203.15398",
      "abstract": "The rise of process data availability has recently led to the development of data-driven learning approaches. However, most of these approaches restrict the use of the learned model to predict the future of ongoing process executions. The goal of this paper is moving a step forward and leveraging available data to learning to act, by supporting users with recommendations derived from an optimal strategy (measure of performance). We take the optimization perspective of one process actor and we recommend the best activities to execute next, in response to what happens in a complex external environment, where there is no control on exogenous factors. To this aim, we investigate an approach that learns, by means of Reinforcement Learning, the optimal policy from the observation of past executions and recommends the best activities to carry on for optimizing a Key Performance Indicator of interest. The validity of the approach is demonstrated on two scenarios taken from real-life data.",
      "authors": [
        "Stefano Branchi",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "David Massimo",
        "Francesco Ricci and Massimiliano Ronzani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-29T09:43:39+00:00",
          "link": "https://arxiv.org/abs/2203.15398v1",
          "size": "471kb",
          "version": "v1"
        },
        {
          "date": "2022-06-15T14:29:50+00:00",
          "link": "https://arxiv.org/abs/2203.15398v2",
          "size": "298kb",
          "version": "v2"
        }
      ],
      "title": "Learning to act: a Reinforcement Learning approach to recommend the best next activities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.15398",
        "PDF": "https://arxiv.org/pdf/2203.15398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on a reinforcement learning approach to recommend optimal next activities in process executions. It does not address LLM training data processing or related data engineering techniques."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2209.03083",
      "abstract": "Numerical simulation has become omnipresent in the automotive domain, posing new challenges such as high-dimensional parameter spaces and large as well as incomplete and multi-faceted data. In this design study, we show how interactive visual exploration and analysis of high-dimensional, spectral data from noise simulation can facilitate design improvements in the context of conflicting criteria. Here, we focus on structure-borne noise, i.e., noise from vibrating mechanical parts. Detecting problematic noise sources early in the design and production process is essential for reducing a product's development costs and its time to market. In a close collaboration of visualization and automotive engineering, we designed a new, interactive approach to quickly identify and analyze critical noise sources, also contributing to an improved understanding of the analyzed system. Several carefully designed, interactive linked views enable the exploration of noises, vibrations, and harshness at multiple levels of detail, both in the frequency and spatial domain. This enables swift and smooth changes of perspective; selections in the frequency domain are immediately reflected in the spatial domain, and vice versa. Noise sources are quickly identified and shown in the context of their neighborhood, both in the frequency and spatial domain. We propose a novel drill-down view, especially tailored to noise data analysis. Split boxplots and synchronized 3D geometry views support comparison tasks. With this solution, engineers iterate over design optimizations much faster, while maintaining a good overview at each iteration. We evaluated the new approach in the automotive industry, studying noise simulation data for an internal combustion engine.",
      "authors": [
        "Rainer Splechtna",
        "Denis Gracanin",
        "Goran Todorovic",
        "Stanislav Goja",
        "Boris Bedic",
        "Helwig Hauser",
        "Kresimir Matkovic"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2022-09-07T11:47:30+00:00",
          "link": "https://arxiv.org/abs/2209.03083v1",
          "size": "11551kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Visual Analysis of Structure-borne Noise Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2209.03083",
        "PDF": "https://arxiv.org/pdf/2209.03083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on the interactive visual analysis of structure-borne noise data in automotive engineering, unrelated to LLM training data processing or any relevant data engineering aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.20796",
      "abstract": "Graph neural network universal interatomic potentials (GNN-UIPs) have demonstrated remarkable generalization and transfer capabilities in material discovery and property prediction. These models can accelerate molecular dynamics (MD) simulation by several orders of magnitude while maintaining \\textit{ab initio} accuracy, making them a promising new paradigm in material simulations. One notable example is Crystal Hamiltonian Graph Neural Network (CHGNet), pretrained on the energies, forces, stresses, and magnetic moments from the MPtrj dataset, representing a state-of-the-art GNN-UIP model for charge-informed MD simulations. However, training the CHGNet model is time-consuming(8.3 days on one A100 GPU) for three reasons: (i) requiring multi-layer propagation to reach more distant atom information, (ii) requiring second-order derivatives calculation to finish weights updating and (iii) the implementation of reference CHGNet does not fully leverage the computational capabilities. This paper introduces FastCHGNet, an optimized CHGNet, with three contributions: Firstly, we design innovative Force/Stress Readout modules to decompose Force/Stress prediction. Secondly, we adopt massive optimizations such as kernel fusion, redundancy bypass, etc, to exploit GPU computation power sufficiently. Finally, we extend CHGNet to support multiple GPUs and propose a load-balancing technique to enhance GPU utilization. Numerical results show that FastCHGNet reduces memory footprint by a factor of 3.59. The final training time of FastCHGNet can be decreased to \\textbf{1.53 hours} on 32 GPUs without sacrificing model accuracy.",
      "authors": [
        "Yuanchang Zhou",
        "Siyu Hu",
        "Chen Wang",
        "Lin-Wang Wang",
        "Guangming Tan",
        "Weile Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T08:38:09+00:00",
          "link": "https://arxiv.org/abs/2412.20796v1",
          "size": "2516kb",
          "version": "v1"
        },
        {
          "date": "2025-03-14T08:01:35+00:00",
          "link": "https://arxiv.org/abs/2412.20796v2",
          "size": "2520kb",
          "version": "v2"
        }
      ],
      "title": "FastCHGNet: Training one Universal Interatomic Potential to 1.5 Hours with 32 GPUs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20796",
        "HTML": "https://arxiv.org/html/2412.20796",
        "PDF": "https://arxiv.org/pdf/2412.20796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses accelerating molecular dynamics simulation using graph neural networks and optimizing a model called FastCHGNet. It is unrelated to LLM training data processing or datasets creation for LLMs."
      },
      "tasks": [
        "Graph Neural Network",
        "Property Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.12653",
      "abstract": "We study popularity for matchings under preferences. This solution concept captures matchings that do not lose against any other matching in a majority vote by the agents. A popular matching is said to be robust if it is popular among multiple instances. We present a polynomial-time algorithm for deciding whether there exists a robust popular matching if instances only differ with respect to the preferences of a single agent while obtaining NP-completeness if two instances differ only by a downward shift of one alternative by four agents. Moreover, we find a complexity dichotomy based on preference completeness for the case where instances differ by making some options unavailable.",
      "authors": [
        "Martin Bullinger and Rohith Reddy Gangam and Parnian Shahkar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-23T11:03:18+00:00",
          "link": "https://arxiv.org/abs/2401.12653v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Robust Popular Matchings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.12653",
        "HTML": "https://arxiv.org/html/2401.12653",
        "PDF": "https://arxiv.org/pdf/2401.12653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study of matchings in preference frameworks and their complexities does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10009",
      "abstract": "A modern digital pathology vendor-agnostic binary slide format specifically targeting the unmet need of efficient real-time transfer and display has not yet been established. The growing adoption of digital pathology only intensifies the need for an intermediary digital slide format that emphasizes performance for use between slide servers and image management software. The DICOM standard is a well-established format widely used for the long-term storage of both images and associated critical metadata. However, it was inherently designed for radiology rather than digital pathology, a discipline that imposes a unique set of performance requirements due to high-speed multi-pyramidal rendering within whole slide viewer applications. Here we introduce the Iris file extension, a binary container specification explicitly designed for performance-oriented whole slide image viewer systems. The Iris file extension specification is explicit and straightforward, adding modern compression support, a dynamic structure with fully optional metadata features, computationally trivial deep file validation, corruption recovery capabilities, and slide annotations. In addition to the file specification document, we provide source code to allow for (de)serialization and validation of a binary stream against the standard. We also provide corresponding binary builds with C++, Python, and JavaScript language support. Finally, we provide full encoder and decoder implementation source code, as well as binary builds (part of the separate Iris Codec Community module), with language bindings for C++ and Python, allowing for easy integration with existing WSI solutions. We provide the Iris File Extension specification openly to the community in the form of a Creative Commons Attribution-No Derivative 4.0 International license.",
      "authors": [
        "Ryan Erik Landvater",
        "Michael David Olp",
        "Mustafa Yousif",
        "Ulysses Balis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T21:02:51+00:00",
          "link": "https://arxiv.org/abs/2506.10009v1",
          "size": "578kb",
          "version": "v1"
        },
        {
          "date": "2025-06-13T00:54:34+00:00",
          "link": "https://arxiv.org/abs/2506.10009v2",
          "size": "5049kb",
          "version": "v2"
        }
      ],
      "title": "The Iris File Extension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10009",
        "HTML": "https://arxiv.org/html/2506.10009",
        "PDF": "https://arxiv.org/pdf/2506.10009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the Iris file extension for digital pathology image storage and transfer. It does not relate to LLM training data processing or handling text data."
      },
      "tasks": [
        "whole slide images"
      ],
      "repo_urls": [
        "https://github.com/irisdigitalpathology/iris-example-files",
        "https://github.com/irisdigitalpathology/iris-codec",
        "https://github.com/IrisDigitalPathology/Iris-File-Extension"
      ],
      "source": "arXiv"
    },
    {
      "id": "2208.04146",
      "abstract": "Liquid metals (LM) are embedded in an elastomer matrix to obtain soft composites with unique thermal, dielectric, and mechanical properties. They have applications in soft robotics, biomedical engineering, and wearable electronics. By linking the structure to the properties of these materials, it is possible to perform material design rationally. Liquid-metal embedded elastomers (LMEEs) have been designed for targeted electro-thermo-mechanical properties by semi-supervised learning of structure-property (SP) links in a variational autoencoder network (VAE). The design parameters are the microstructural descriptors that are physically meaningful and have affine relationships with the synthetization of the studied particulate composite. The machine learning (ML) model is trained on a generated dataset of microstructural descriptors with their multifunctional property quantities as their labels. Sobol sequence is used for in-silico Design of Experiment (DoE) by sampling the design space to generate a comprehensive dataset of 3D microstructure realizations via a packing algorithm. The mechanical responses of the generated microstructures are simulated using a previously developed Finite Element (FE) model, considering the surface tension induced by LM inclusions, while the linear thermal and dielectric constants are homogenized with the help of our in-house Fast Fourier Transform (FFT) package. Following the training by minimization of an appropriate loss function, the VAE encoder acts as the surrogate of numerical solvers of the multifunctional homogenizations, and its decoder is used for the material design. Our results indicate the satisfactory performance of the surrogate model and the inverse calculator with respect to high-fidelity numerical simulations validated with LMEE experimental results.",
      "authors": [
        "Abhijith Thoopul Anantharanga",
        "Mohammad Saber Hashemi",
        "Azadeh Sheidaei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-24T06:02:26+00:00",
          "link": "https://arxiv.org/abs/2208.04146v1",
          "size": "1505kb",
          "version": "v1"
        }
      ],
      "title": "Linking Properties to Microstructure in Liquid Metal Embedded Elastomers via Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2208.04146",
        "PDF": "https://arxiv.org/pdf/2208.04146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with linking properties to microstructure in elastomers via machine learning for material design. It does not pertain to LLM training data processing or related data engineering operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.03078",
      "abstract": "In this paper, we investigate the dynamics of coordinating and anti-coordinating agents in a coevolutionary model for actions and opinions. In the model, the individuals of a population interact on a two-layer network, sharing their opinions and observing others' action, while revising their own opinions and actions according to a game-theoretic mechanism, grounded in the social psychology literature. First, we consider the scenario of coordinating agents, where convergence to a Nash equilibrium (NE) is guaranteed. We identify conditions for reaching consensus configurations and establish regions of attraction for these equilibria. Second, we study networks of anti-coordinating agents. In this second scenario, we prove that all trajectories converge to a NE by leveraging potential game theory. Then, we establish analytical conditions on the network structure and model parameters to guarantee the existence of consensus and polarized equilibria, characterizing their regions of attraction.",
      "authors": [
        "Hong Liang",
        "Mengbin Ye",
        "Lorenzo Zino",
        "Weiguo Xia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Social and Information Networks (cs.SI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T00:11:24+00:00",
          "link": "https://arxiv.org/abs/2505.03078v1",
          "size": "2594kb",
          "version": "v1"
        }
      ],
      "title": "Coevolution of Actions and Opinions in Networks of Coordinating and Anti-Coordinating Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03078",
        "HTML": "https://arxiv.org/html/2505.03078",
        "PDF": "https://arxiv.org/pdf/2505.03078"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the dynamics of agents in coevolutionary models for actions and opinions. It does not pertain to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.15871",
      "abstract": "Thermal transient responses of superconducting magnets can be simulated using the finite element (FE) method. Some accelerator magnets use cables whose electric insulation is significantly thinner than the bare electric conductor. The FE discretisation of such geometries with high-quality meshes leads to many degrees of freedom. This increases the computational time, particularly since non-linear material properties are involved. In this work, we propose to use a thermal thin-shell approximation (TSA) to improve the computational efficiency when solving the heat diffusion equation in two dimensions. We apply the method to compute the thermal transient response of superconducting accelerator magnets used for CERN's Large Hadron Collider (LHC) and High-Luminosity LHC. The TSA collapses thin electrical insulation layers into lines while accurately representing the thermal gradient across the insulation's thickness. The TSA is implemented in the multipole module of the open-source Finite Element Quench Simulator (FiQuS), which can generate the multipole magnet models programmatically from input text files. First, the TSA approach is verified by comparison to classical FE simulations with meshed surface insulation regions for a simple block of four cables and a detailed model of the MBH dipole. The results show that the TSA approach reduces the computational time significantly while preserving the accuracy of the solution. Second, the quench heater (QH) delay computed with the TSA method is compared to measurements for the MBH magnet. To this end, the thermal transient simulation is coupled to a magnetostatic solution to account for magneto-resistive effects. Third, the TSA's full capabilities are showcased in non-linear magneto-thermal simulations of several LHC and HL-LHC superconducting magnet models. The full source code, including all input files, is publicly available.",
      "authors": [
        "Erik Schnaubelt",
        "Andrea Vitrano",
        "Mariusz Wozniak",
        "Emmanuele Ravaioli",
        "Arjan Verweij",
        "Sebastian Sch\\\"ops"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Accelerator Physics (physics.acc-ph)",
        "Superconductivity (cond-mat.supr-con)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T08:47:24+00:00",
          "link": "https://arxiv.org/abs/2501.15871v1",
          "size": "6076kb",
          "version": "v1"
        }
      ],
      "title": "Transient Finite Element Simulation of Accelerator Magnets Using Thermal Thin Shell Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15871",
        "HTML": "https://arxiv.org/html/2501.15871",
        "PDF": "https://arxiv.org/pdf/2501.15871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with thermal transient simulations for accelerator magnets using a thermal thin-shell approximation and finite element methods, which is unrelated to any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.13746",
      "abstract": "The scientific and research community has benefited greatly from containerized distributed High Throughput Computing (dHTC), both by enabling elastic scaling of user compute workloads to thousands of compute nodes, and by allowing for distributed ownership of compute resources. To effectively and efficiently deal with the dynamic nature of the setup, the most successful implementations use an overlay batch scheduling infrastructure fed by a pilot provisioning system. One fundamental property of these setups is the use of late binding of containerized user workloads. From a resource provider point of view, a compute resource is thus claimed before the user container image is selected. This paper provides a mechanism to implement this late-binding of container images on Kubernetes-managed resources, without requiring any elevated privileges.",
      "authors": [
        "Igor Sfiligoi",
        "Yunjin Zhu and Jaime Frey"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T22:08:01+00:00",
          "link": "https://arxiv.org/abs/2503.13746v1",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "title": "Container late-binding in unprivileged dHTC pilot systems on Kubernetes resources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13746",
        "PDF": "https://arxiv.org/pdf/2503.13746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on container orchestration and scheduling in computing systems, particularly within Kubernetes, and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.04556",
      "abstract": "Comparing the tradeoffs of CPU and GPU compute for memory-heavy algorithms is often challenging, due to the drastically different memory subsystems on host CPUs and discrete GPUs. The AMD MI300A is an exception, since it sports both CPU and GPU cores in a single package, all backed by the same type of HBM memory. In this paper we analyze the performance of Permutational Multivariate Analysis of Variance (PERMANOVA), a non-parametric method that tests whether two or more groups of objects are significantly different based on a categorical factor. This method is memory-bound and has been recently optimized for CPU cache locality. Our tests show that GPU cores on the MI300A prefer the brute force approach instead, significantly outperforming the CPU-based implementation. The significant benefit of Simultaneous Multithreading (SMT) was also a pleasant surprise.",
      "authors": [
        "Igor Sfiligoi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T16:44:21+00:00",
          "link": "https://arxiv.org/abs/2505.04556v1",
          "size": "354kb",
          "version": "v1"
        }
      ],
      "title": "Comparing CPU and GPU compute of PERMANOVA on MI300A",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04556",
        "PDF": "https://arxiv.org/pdf/2505.04556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes performance comparisons of CPU and GPU compute for the PERMANOVA algorithm. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15765",
      "abstract": "Dynamic Facial Expression Recognition (DFER) plays a critical role in affective computing and human-computer interaction. Although existing methods achieve comparable performance, they inevitably suffer from performance degradation under sample heterogeneity caused by multi-source data and individual expression variability. To address these challenges, we propose a novel framework, called Heterogeneity-aware Distributional Framework (HDF), and design two plug-and-play modules to enhance time-frequency modeling and mitigate optimization imbalance caused by hard samples. Specifically, the Time-Frequency Distributional Attention Module (DAM) captures both temporal consistency and frequency robustness through a dual-branch attention design, improving tolerance to sequence inconsistency and visual style shifts. Then, based on gradient sensitivity and information bottleneck principles, an adaptive optimization module Distribution-aware Scaling Module (DSM) is introduced to dynamically balance classification and contrastive losses, enabling more stable and discriminative representation learning. Extensive experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF significantly improves both recognition accuracy and robustness. Our method achieves superior weighted average recall (WAR) and unweighted average recall (UAR) while maintaining strong generalization across diverse and imbalanced scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.",
      "authors": [
        "Feng-Qi Cui",
        "Anyang Tong",
        "Jinyang Huang",
        "Jie Zhang",
        "Dan Guo",
        "Zhi Liu",
        "Meng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:21:47+00:00",
          "link": "https://arxiv.org/abs/2507.15765v1",
          "size": "2364kb",
          "version": "v1"
        }
      ],
      "title": "Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15765",
        "HTML": "https://arxiv.org/html/2507.15765",
        "PDF": "https://arxiv.org/pdf/2507.15765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework to improve dynamic facial expression recognition, addressing challenges in affective computing and human-computer interaction. It does not involve LLM training data processing or dataset improvement for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.17503",
      "abstract": "In this work, we employ neural fields, which use neural networks to map a coordinate to the corresponding physical property value at that coordinate, in a test-time learning manner. For a test-time learning method, the weights are learned during the inversion, as compared to traditional approaches which require a network to be trained using a training dataset. Results for synthetic examples in seismic tomography and direct current resistivity inversions are shown first. We then perform a singular value decomposition analysis on the Jacobian of the weights of the neural network (SVD analysis) for both cases to explore the effects of neural networks on the recovered model. The results show that the test-time learning approach can eliminate unwanted artifacts in the recovered subsurface physical property model caused by the sensitivity of the survey and physics. Therefore, NFs-Inv improves the inversion results compared to the conventional inversion in some cases such as the recovery of the dip angle or the prediction of the boundaries of the main target. In the SVD analysis, we observe similar patterns in the left-singular vectors as were observed in some diffusion models, trained in a supervised manner, for generative tasks in computer vision. This observation provides evidence that there is an implicit bias, which is inherent in neural network structures, that is useful in supervised learning and test-time learning models. This implicit bias has the potential to be useful for recovering models in geophysical inversions.",
      "authors": [
        "Anran Xu",
        "Lindsey J. Heagy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Geophysics (physics.geo-ph)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T19:32:52+00:00",
          "link": "https://arxiv.org/abs/2503.17503v1",
          "size": "6571kb",
          "version": "v1"
        },
        {
          "date": "2025-05-22T19:02:31+00:00",
          "link": "https://arxiv.org/abs/2503.17503v2",
          "size": "6579kb",
          "version": "v2"
        }
      ],
      "title": "Towards Understanding the Benefits of Neural Network Parameterizations in Geophysical Inversions: A Study With Neural Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17503",
        "HTML": "https://arxiv.org/html/2503.17503",
        "PDF": "https://arxiv.org/pdf/2503.17503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural networks for geophysical inversions using test-time learning, without addressing any aspect of LLM training data processing. It does not involve data collection, generation, filtering, or dataset creation relevant to LLM."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.23782",
      "abstract": "Unmanned aerial vehicle (UAV) usage is expected to surge in the coming decade, raising the need for heightened security measures to prevent airspace violations and security threats. This study investigates deep learning approaches to UAV classification focusing on the key issue of data scarcity. To investigate this we opted to train the models using a total of 4,500 seconds of audio samples, evenly distributed across a 9-class dataset. We leveraged parameter efficient fine-tuning (PEFT) and data augmentations to mitigate the data scarcity. This paper implements and compares the use of convolutional neural networks (CNNs) and attention-based transformers. Our results show that, CNNs outperform transformers by 1-2\\% accuracy, while still being more computationally efficient. These early findings, however, point to potential in using transformers models; suggesting that with more data and further optimizations they could outperform CNNs. Future works aims to upscale the dataset to better understand the trade-offs between these approaches.",
      "authors": [
        "Andrew P. Berg",
        "Qian Zhang",
        "Mia Y. Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T22:34:07+00:00",
          "link": "https://arxiv.org/abs/2505.23782v1",
          "size": "1540kb",
          "version": "v1"
        }
      ],
      "title": "4,500 Seconds: Small Data Training Approaches for Deep UAV Audio Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23782",
        "HTML": "https://arxiv.org/html/2505.23782",
        "PDF": "https://arxiv.org/pdf/2505.23782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores deep learning models for audio classification in UAVs and addresses data scarcity in this context, which is unrelated to training data processing for large language models."
      },
      "tasks": [
        "Audio Classification",
        "parameter-efficient fine-tuning"
      ],
      "repo_urls": [
        "https://github.com/AndrewPBerg/UAV_Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15254",
      "abstract": "Classical machine learning often struggles with complex, high-dimensional data. Quantum machine learning offers a potential solution, promising more efficient processing. The quantum convolutional neural network (QCNN), a hybrid algorithm, fits current noisy intermediate-scale quantum hardware. However, its training depends largely on classical computation. Future gate-based quantum computers may realize full quantum advantages. In contrast to QCNNs, quantum autoencoders (QAEs) leverage classical optimization solely for parameter tuning. Data compression and reconstruction are handled entirely within quantum circuits, enabling purely quantum-based feature extraction. This study introduces a novel image-classification approach using QAEs, achieving classification without requiring additional qubits compared with conventional QAE implementations. The quantum circuit structure significantly impacts classification accuracy. Unlike hybrid methods such as QCNN, QAE-based classification emphasizes quantum computation. Our experiments demonstrate high accuracy in a four-class classification task, evaluating various quantum-gate configurations to understand the impact of different parameterized quantum circuit structures on classification performance. Specifically, noise-free conditions are considered, and simulations are performed using a statevector simulator to model the quantum system with full amplitude precision. Our results reveal that specific ansatz structures achieve superior accuracy. Moreover, the proposed approach achieves performance comparable to that of conventional machine-learning methods while significantly reducing the number of parameters requiring optimization. These findings indicate that QAEs can serve as efficient classification models with fewer parameters and highlight the potential of utilizing quantum circuits for complete end-to-end learning.",
      "authors": [
        "Hinako Asaoka",
        "Kazue Kudo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T07:13:38+00:00",
          "link": "https://arxiv.org/abs/2502.15254v1",
          "size": "1215kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T14:30:37+00:00",
          "link": "https://arxiv.org/abs/2502.15254v2",
          "size": "661kb",
          "version": "v2"
        }
      ],
      "title": "Quantum autoencoders for image classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15254",
        "HTML": "https://arxiv.org/html/2502.15254",
        "PDF": "https://arxiv.org/pdf/2502.15254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores quantum autoencoders for image classification, which is unrelated to LLM training data processing. It focuses on quantum computing and machine learning applications outside of the scope of language model data processing."
      },
      "tasks": [
        "Classification",
        "Data Compression",
        "image-classification",
        "Image Classification",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.07203",
      "abstract": "Complex networked systems in fields such as physics, biology, and social sciences often involve interactions that extend beyond simple pairwise ones. Hypergraphs serve as powerful modeling tools for describing and analyzing the intricate behaviors of systems with multi-body interactions. Herein, we investigate a discrete-time nonlinear averaging dynamics with three-body interactions: an underlying hypergraph, comprising triples as hyperedges, delineates the structure of these interactions, while the vertices update their states through a weighted, state-dependent average of neighboring pairs' states. This dynamics captures reinforcing group effects, such as peer pressure, and exhibits higher-order dynamical effects resulting from a complex interplay between initial states, hypergraph topology, and nonlinearity of the update. Differently from linear averaging dynamics on graphs with two-body interactions, this model does not converge to the average of the initial states but rather induces a shift. By assuming random initial states and by making some regularity and density assumptions on the hypergraph, we prove that the dynamics converges to a multiplicatively-shifted average of the initial states, with high probability. We further characterize the shift as a function of two parameters describing the initial state and interaction strength, as well as the convergence time as a function of the hypergraph structure.",
      "authors": [
        "Emilio Cruciani",
        "Emanuela L. Giacomelli",
        "Jinyeop Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-14T15:29:20+00:00",
          "link": "https://arxiv.org/abs/2304.07203v1",
          "size": "39kb",
          "version": "v1"
        },
        {
          "date": "2024-06-30T15:12:45+00:00",
          "link": "https://arxiv.org/abs/2304.07203v2",
          "size": "64kb",
          "version": "v2"
        }
      ],
      "title": "On the convergence of nonlinear averaging dynamics with three-body interactions on hypergraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.07203",
        "HTML": "https://arxiv.org/html/2304.07203",
        "PDF": "https://arxiv.org/pdf/2304.07203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with nonlinear averaging dynamics on hypergraphs and does not address any aspect of LLM training data processing or related data operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.13826",
      "abstract": "We present a framework for the efficient and accurate computation of resonance modes in photonic waveguides. The framework is based on AAA rational approximation with the application of special light sources. It allows one to calculate only relevant modes, such as the fundamental resonance modes localized in the central core of the waveguides. We demonstrate the framework using an example from the literature, a hollow-core photonic crystal fiber. This waveguide supports many other modes, such as cladding modes and higher-order modes. These nonrelevant modes are not calculated, so that challenging post-processing with mode filtering is not required.",
      "authors": [
        "Felix Binkowski",
        "Fridtjof Betz",
        "Martin Hammerschmidt",
        "Lin Zschiedrich",
        "Sven Burger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T13:13:37+00:00",
          "link": "https://arxiv.org/abs/2412.13826v1",
          "size": "802kb",
          "version": "v1"
        }
      ],
      "title": "Resonance modes in microstructured photonic waveguides: Efficient and accurate computation based on AAA rational approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13826",
        "HTML": "https://arxiv.org/html/2412.13826",
        "PDF": "https://arxiv.org/pdf/2412.13826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on the computation of resonance modes in photonic waveguides using AAA rational approximation and does not relate to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2109.14883",
      "abstract": "As the need to understand and formalise business processes into a model has grown over the last years, the process discovery research field has gained more and more importance, developing two different classes of approaches to model representation: procedural and declarative. Orthogonally to this classification, the vast majority of works envisage the discovery task as a one-class supervised learning process guided by the traces that are recorded into an input log. In this work instead, we focus on declarative processes and embrace the less-popular view of process discovery as a binary supervised learning task, where the input log reports both examples of the normal system execution, and traces representing \"stranger\" behaviours according to the domain semantics. We therefore deepen how the valuable information brought by both these two sets can be extracted and formalised into a model that is \"optimal\" according to user-defined goals. Our approach, namely NegDis, is evaluated w.r.t. other relevant works in this field, and shows promising results as regards both the performance and the quality of the obtained solution.",
      "authors": [
        "Federico Chesani",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Daniela Loreti",
        "Fabrizio Maria Maggi",
        "Paola Mello",
        "Marco Montali",
        "Sergio Tessaris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2021-09-30T06:58:34+00:00",
          "link": "https://arxiv.org/abs/2109.14883v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "Process discovery on deviant traces and other stranger things",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.14883",
        "PDF": "https://arxiv.org/pdf/2109.14883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around process discovery in business environments, involving process modeling rather than LLM training data processing or data engineering operations associated with LLM training."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.00838",
      "abstract": "The paper explores stylometry as a method to distinguish between texts created by Large Language Models (LLMs) and humans, addressing issues of model attribution, intellectual property, and ethical AI use. Stylometry has been used extensively to characterise the style and attribute authorship of texts. By applying it to LLM-generated texts, we identify their emergent writing patterns. The paper involves creating a benchmark dataset based on Wikipedia, with (a) human-written term summaries, (b) texts generated purely by LLMs (GPT-3.5/4, LLaMa 2/3, Orca, and Falcon), (c) processed through multiple text summarisation methods (T5, BART, Gensim, and Sumy), and (d) rephrasing methods (Dipper, T5). The 10-sentence long texts were classified by tree-based models (decision trees and LightGBM) using human-designed (StyloMetrix) and n-gram-based (our own pipeline) stylometric features that encode lexical, grammatical, syntactic, and punctuation patterns. The cross-validated results reached a performance of up to .87 Matthews correlation coefficient in the multiclass scenario with 7 classes, and accuracy between .79 and 1. in binary classification, with the particular example of Wikipedia and GPT-4 reaching up to .98 accuracy on a balanced dataset. Shapley Additive Explanations pinpointed features characteristic of the encyclopaedic text type, individual overused words, as well as a greater grammatical standardisation of LLMs with respect to human-written texts. These results show -- crucially, in the context of the increasingly sophisticated LLMs -- that it is possible to distinguish machine- from human-generated texts at least for a well-defined text type.",
      "authors": [
        "Karol Przystalski",
        "Jan K. Argasi\\'nski",
        "Iwona Grabska-Gradzi\\'nska",
        "Jeremi K. Ochab"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T15:08:53+00:00",
          "link": "https://arxiv.org/abs/2507.00838v1",
          "size": "937kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:31:45+00:00",
          "link": "https://arxiv.org/abs/2507.00838v2",
          "size": "933kb",
          "version": "v2"
        }
      ],
      "title": "Stylometry recognizes human and LLM-generated texts in short samples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00838",
        "HTML": "https://arxiv.org/html/2507.00838",
        "PDF": "https://arxiv.org/pdf/2507.00838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves creating a benchmark dataset to distinguish between human and LLM-generated texts via stylometry, which involves training data processing aspects. However, the main focus is on methods to identify text origin, not directly on enhancing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14718",
      "abstract": "SETI@home is a radio Search for Extraterrestrial Intelligence (SETI) project, looking for technosignatures in data recorded at multiple observatories from 1998 to 2020. Most radio SETI projects analyze data using dedicated processing hardware. SETI@home uses a different approach: time-domain data is distributed over the Internet to $\\gt 10^{5}$ volunteered home computers, which analyze it. The large amount of computing power this affords ($\\sim 10^{15}$ floating-point operations per second (FPOP/s)) allows us to increase the sensitivity and generality of our search in three ways. We use coherent integration, a technique in which data is transformed so that the power of drifting signals is confined to a single discrete Fourier transform (DFT) bin. We perform this coherent search over 123 000 Doppler drift rates in the range ($\\pm$100 Hz s$^{-1}$). Second, we search for a variety of signal types, such as pulsed signals and arbitrary repeated waveforms. The analysis uses a range of DFT sizes, with frequency resolutions ranging from 0.075 Hz to 1221 Hz. The front end of SETI@home produces a set of detections that exceed thresholds in power and goodness of fit. We accumulated $\\sim 1.2\\times 10^{10}$ such detections. The back end of SETI@home takes these detections, identifies and removes radio frequency interference (RFI), and looks for groups of detections that are consistent with extraterrestrial origin and that persist over long timescales. This paper describes the front end of SETI@home and provides parameters for the primary data source, the Arecibo Observatory; the back end and its results are described in a companion paper.",
      "authors": [
        "Eric J. Korpela",
        "David P. Anderson",
        "Jeff Cobb",
        "Matt Lebofsky",
        "Wei Liu",
        "and Dan Werthimer (Space Sciences Laboratory",
        "University of California",
        "Berkeley)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T16:52:48+00:00",
          "link": "https://arxiv.org/abs/2506.14718v1",
          "size": "9401kb",
          "version": "v1"
        }
      ],
      "title": "SETI@home: Data Acquisition and Front-End Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14718",
        "HTML": "https://arxiv.org/html/2506.14718",
        "PDF": "https://arxiv.org/pdf/2506.14718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes data processing techniques for the SETI@home project, unrelated to LLM training data as it pertains to searching for extraterrestrial signals rather than language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.02197",
      "abstract": "The tight coupling between communication and control in cyber-physical systems is necessary to enable the complex regulation required to operate these systems. Unfortunately, cyberattackers can exploit network vulnerabilities to compromise communication and force unsafe decision-making and dynamics. If a cyberattack is not detected and isolated in a timely manner, the control process must balance adhering to the received measurement signals to maintain system operation and ensuring that temporary compromise of the signals does not force unsafe dynamics. For this purpose, we present and employ a safety critical controller based on control barrier functions to mitigate attacks against load frequency control in smart power grids. We validate the paper's findings using simulation on a high-fidelity testbed.",
      "authors": [
        "Amr S. Mohamed",
        "Mohsen Khalaf",
        "and Deepa Kundur"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-03T20:07:11+00:00",
          "link": "https://arxiv.org/abs/2303.02197v1",
          "size": "1388kb",
          "version": "v1"
        }
      ],
      "title": "On the Use of Safety Critical Control for Cyber-Physical Security in the Smart Grid",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.02197",
        "PDF": "https://arxiv.org/pdf/2303.02197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses safety critical control in cyber-physical systems for smart grids, which is unrelated to LLM training or data processing activities."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07140",
      "abstract": "This work presents an encryption model based on Generative Adversarial Networks (GANs). Encryption of RTF-8 data is realized by dynamically generating decimal numbers that lead to the encryption and decryption of alphabetic strings in integer representation by simple addition rules, the modulus of the dimension of the considered alphabet. The binary numbers for the private dynamic keys correspond to the binary numbers of public reference keys, as defined by a specific GAN configuration. For reversible encryption with a bijective mapping between dynamic and reference keys, as defined by the GAN encryptor, secure text encryption can be achieved by transferring a GAN-encrypted public key along with the encrypted text from a sender to a receiver. Using the technique described above, secure text mail transfer can be realized through component-wise encryption and decryption of text mail strings, with total key sizes of up to $10^{8}$ bits that define random decimal numbers generated by the GAN. From the present model, we assert that encrypted texts can be transmitted more efficiently and securely than from RSA encryption, as long as users of the specific configuration of the GAN encryption model are unaware of the GAN encryptor circuit and configuration, respectively.",
      "authors": [
        "Alexej Schelle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T07:27:57+00:00",
          "link": "https://arxiv.org/abs/2504.07140v1",
          "size": "195kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T10:48:41+00:00",
          "link": "https://arxiv.org/abs/2504.07140v2",
          "size": "195kb",
          "version": "v2"
        }
      ],
      "title": "Secure Text Mail Encryption with Generative Adversarial Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07140",
        "HTML": "https://arxiv.org/html/2504.07140",
        "PDF": "https://arxiv.org/pdf/2504.07140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an encryption model using GANs, focusing on secure text mail encryption. There is no relation to LLM training data processing or dataset creation for language models."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/alexej-schelle/TextmailEncryption/tree/main/release"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.04615",
      "abstract": "This study investigates the boundedness of the \\( H^\\infty \\)-calculus\n  for the discrete negative Laplace operator, subject to homogeneous Dirichlet boundary conditions.\n  The discrete negative Laplace operator is implemented using the finite element method, and we establish\n  that its \\(H^\\infty\\)-calculus is uniformly bounded with respect to the spatial mesh size.\n  Using this finding, we derive a discrete stochastic maximal \\(L^p\\)-regularity estimate\n  for a spatial semidiscretization of a linear stochastic heat equation. Furthermore, we provide a nearly optimal pathwise uniform\n  convergence estimate for this spatial semidiscretization within the framework of general\n  spatial \\(L^q\\)-norms.",
      "authors": [
        "Binjie Li and Qin Zhou"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-08T11:31:52+00:00",
          "link": "https://arxiv.org/abs/2311.04615v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2023-11-19T02:45:41+00:00",
          "link": "https://arxiv.org/abs/2311.04615v2",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "2024-06-03T16:18:06+00:00",
          "link": "https://arxiv.org/abs/2311.04615v3",
          "size": "31kb",
          "version": "v3"
        },
        {
          "date": "2024-09-05T10:44:41+00:00",
          "link": "https://arxiv.org/abs/2311.04615v4",
          "size": "36kb",
          "version": "v4"
        },
        {
          "date": "2024-11-17T16:39:43+00:00",
          "link": "https://arxiv.org/abs/2311.04615v5",
          "size": "37kb",
          "version": "v5"
        },
        {
          "date": "2025-04-02T16:41:31+00:00",
          "link": "https://arxiv.org/abs/2311.04615v6",
          "size": "43kb",
          "version": "v6"
        },
        {
          "date": "2025-07-24T01:04:09+00:00",
          "link": "https://arxiv.org/abs/2311.04615v7",
          "size": "95kb",
          "version": "v7"
        }
      ],
      "title": "Discrete stochastic maximal $ L^p $-regularity and convergence of a spatial semidiscretization for a linear stochastic heat equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.04615",
        "PDF": "https://arxiv.org/pdf/2311.04615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates mathematical properties related to stochastic heat equations and their discrete spatial semidiscretization, which is unrelated to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2202.07760",
      "abstract": "Explainability is motivated by the lack of transparency of black-box Machine Learning approaches, which do not foster trust and acceptance of Machine Learning algorithms. This also happens in the Predictive Process Monitoring field, where predictions, obtained by applying Machine Learning techniques, need to be explained to users, so as to gain their trust and acceptance. In this work, we carry on a user evaluation on explanation approaches for Predictive Process Monitoring aiming at investigating whether and how the explanations provided (i) are understandable; (ii) are useful in decision making tasks;(iii) can be further improved for process analysts, with different Machine Learning expertise levels. The results of the user evaluation show that, although explanation plots are overall understandable and useful for decision making tasks for Business Process Management users -- with and without experience in Machine Learning -- differences exist in the comprehension and usage of different plots, as well as in the way users with different Machine Learning expertise understand and use them.",
      "authors": [
        "Williams Rizzi",
        "Marco Comuzzi",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Suhwan Lee",
        "Fabrizio Maria Maggi",
        "Alexander Nolte"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-15T22:24:21+00:00",
          "link": "https://arxiv.org/abs/2202.07760v1",
          "size": "2929kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Predictive Process Monitoring: A User Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.07760",
        "PDF": "https://arxiv.org/pdf/2202.07760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on explainable predictive process monitoring in business process management, aiming to improve trust and acceptance of machine learning predictions. It does not discuss any LLM training data processing aspects like data engineering or dataset creation."
      },
      "tasks": [
        "BIG-bench Machine Learning",
        "Decision Making",
        "Management",
        "Predictive Process Monitoring"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.01507",
      "abstract": "This study investigates strategies for minimizing Joule losses in resistive random access memory (ReRAM) cells, which are also referred to as memristive devices. Typically, the structure of ReRAM cells involves a nanoscale layer of resistance-switching material sandwiched between two metal electrodes. The basic question that we ask is what is the optimal driving protocol to switch a memristive device from one state to another. In the case of ideal memristors, in the most basic scenario, the optimal protocol is determined by solving a variational problem without constraints with the help of the Euler-Lagrange equation. In the case of memristive systems, for the same situation, the optimal protocol is found using the method of Lagrange multipliers. We demonstrate the advantages of our approaches through specific examples and compare our results with those of switching with constant voltage or current. Our findings suggest that voltage or current control can be used to reduce Joule losses in emerging memory devices.",
      "authors": [
        "Valeriy A. Slipko and Yuriy V. Pershin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-01T22:19:17+00:00",
          "link": "https://arxiv.org/abs/2404.01507v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2024-05-25T12:00:08+00:00",
          "link": "https://arxiv.org/abs/2404.01507v2",
          "size": "100kb",
          "version": "v2"
        },
        {
          "date": "2024-09-03T11:00:35+00:00",
          "link": "https://arxiv.org/abs/2404.01507v3",
          "size": "108kb",
          "version": "v3"
        },
        {
          "date": "2024-12-11T05:59:43+00:00",
          "link": "https://arxiv.org/abs/2404.01507v4",
          "size": "109kb",
          "version": "v4"
        },
        {
          "date": "2024-12-19T08:40:10+00:00",
          "link": "https://arxiv.org/abs/2404.01507v5",
          "size": "8496kb",
          "version": "v5"
        }
      ],
      "title": "Reduction of Joule Losses in Memristive Switching Using Optimal Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01507",
        "HTML": "https://arxiv.org/html/2404.01507",
        "PDF": "https://arxiv.org/pdf/2404.01507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on reducing Joule losses in memristive switching using optimal control strategies. It deals with memory devices and electrical engineering, offering no insights into LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.07344",
      "abstract": "Recurrent Neural Networks (RNNs) have revolutionized many areas of machine learning, particularly in natural language and data sequence processing. Long Short-Term Memory (LSTM) has demonstrated its ability to capture long-term dependencies in sequential data. Inspired by the Kolmogorov-Arnold Networks (KANs) a promising alternatives to Multi-Layer Perceptrons (MLPs), we proposed a new neural networks architecture inspired by KAN and the LSTM, the Temporal Kolomogorov-Arnold Networks (TKANs). TKANs combined the strenght of both networks, it is composed of Recurring Kolmogorov-Arnold Networks (RKANs) Layers embedding memory management. This innovation enables us to perform multi-step time series forecasting with enhanced accuracy and efficiency. By addressing the limitations of traditional models in handling complex sequential patterns, the TKAN architecture offers significant potential for advancements in fields requiring more than one step ahead forecasting.",
      "authors": [
        "Remi Genet and Hugo Inzirillo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-12T17:40:48+00:00",
          "link": "https://arxiv.org/abs/2405.07344v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2024-06-05T16:46:11+00:00",
          "link": "https://arxiv.org/abs/2405.07344v2",
          "size": "800kb",
          "version": "v2"
        },
        {
          "date": "2024-12-17T17:13:03+00:00",
          "link": "https://arxiv.org/abs/2405.07344v3",
          "size": "826kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T14:09:59+00:00",
          "link": "https://arxiv.org/abs/2405.07344v4",
          "size": "831kb",
          "version": "v4"
        }
      ],
      "title": "TKAN: Temporal Kolmogorov-Arnold Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.07344",
        "HTML": "https://arxiv.org/html/2405.07344",
        "PDF": "https://arxiv.org/pdf/2405.07344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a new architecture for neural networks aimed at improving time series forecasting, unrelated to LLM training data processing."
      },
      "tasks": [
        "Kolmogorov-Arnold Networks",
        "Management",
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/remigenet/tkan",
        "https://github.com/remigenet/TKAT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.09209",
      "abstract": "Prescriptive Process Monitoring is a prominent problem in Process Mining, which consists in identifying a set of actions to be recommended with the goal of optimising a target measure of interest or Key Performance Indicator (KPI). One challenge that makes this problem difficult is the need to provide Prescriptive Process Monitoring techniques only based on temporally annotated (process) execution data, stored in, so-called execution logs, due to the lack of well crafted and human validated explicit models. In this paper we aim at proposing an AI based approach that learns, by means of Reinforcement Learning (RL), an optimal policy (almost) only from the observation of past executions and recommends the best activities to carry on for optimizing a KPI of interest. This is achieved first by learning a Markov Decision Process for the specific KPIs from data, and then by using RL training to learn the optimal policy. The approach is validated on real and synthetic datasets and compared with off-policy Deep RL approaches. The ability of our approach to compare with, and often overcome, Deep RL approaches provides a contribution towards the exploitation of white box RL techniques in scenarios where only temporal execution data are available.",
      "authors": [
        "Stefano Branchi",
        "Andrei Buliga",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Francesca Meneghello",
        "Massimiliano Ronzani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-16T10:30:36+00:00",
          "link": "https://arxiv.org/abs/2303.09209v1",
          "size": "458kb",
          "version": "v1"
        }
      ],
      "title": "Recommending the optimal policy by learning to act from temporal data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.09209",
        "PDF": "https://arxiv.org/pdf/2303.09209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses leveraging reinforcement learning to develop optimal policies for optimizing KPIs from temporal execution data. It does not address or contribute to LLM training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.00721",
      "abstract": "Empathy indicates an individual's ability to understand others. Over the past few years, empathy has drawn attention from various disciplines, including but not limited to Affective Computing, Cognitive Science, and Psychology. Detecting empathy has potential applications in society, healthcare and education. Despite being a broad and overlapping topic, the avenue of empathy detection leveraging Machine Learning remains underexplored from a systematic literature review perspective. We collected 849 papers from 10 well-known academic databases, systematically screened them and analysed the final 82 papers. Our analyses reveal several prominent task formulations - including empathy on localised utterances or overall expressions, unidirectional or parallel empathy, and emotional contagion - in monadic, dyadic and group interactions. Empathy detection methods are summarised based on four input modalities - text, audiovisual, audio and physiological signals - thereby presenting modality-specific network architecture design protocols. We discuss challenges, research gaps and potential applications in the Affective Computing-based empathy domain, which can facilitate new avenues of exploration. We further enlist the public availability of datasets and codes. This paper, therefore, provides a structured overview of recent advancements and remaining challenges towards developing a robust empathy detection system that could meaningfully contribute to enhancing human well-being.",
      "authors": [
        "Md Rakibul Hasan",
        "Md Zakir Hossain",
        "Shreya Ghosh",
        "Aneesh Krishna",
        "Tom Gedeon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-30T08:34:12+00:00",
          "link": "https://arxiv.org/abs/2311.00721v1",
          "size": "3058kb",
          "version": "v1"
        },
        {
          "date": "2024-06-26T07:10:49+00:00",
          "link": "https://arxiv.org/abs/2311.00721v2",
          "size": "2470kb",
          "version": "v2"
        },
        {
          "date": "2024-12-17T02:12:54+00:00",
          "link": "https://arxiv.org/abs/2311.00721v3",
          "size": "2471kb",
          "version": "v3"
        },
        {
          "date": "2025-05-20T09:40:42+00:00",
          "link": "https://arxiv.org/abs/2311.00721v4",
          "size": "2620kb",
          "version": "v4"
        }
      ],
      "title": "Empathy Detection from Text, Audiovisual, Audio or Physiological Signals: A Systematic Review of Task Formulations and Machine Learning Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.00721",
        "HTML": "https://arxiv.org/html/2311.00721",
        "PDF": "https://arxiv.org/pdf/2311.00721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper systematically reviews task formulations and machine learning methods for empathy detection, focusing on modalities such as text, audiovisual, and physiological signals. It does not contribute to LLM training data processing."
      },
      "tasks": [
        "Privacy Preserving",
        "Systematic Literature Review"
      ],
      "repo_urls": [
        "https://github.com/hasan-rakibul/boolean-search-bib-abstract"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23242",
      "abstract": "Increased sophistication of large language models (LLMs) and the consequent quality of generated multilingual text raises concerns about potential disinformation misuse. While humans struggle to distinguish LLM-generated content from human-written texts, the scholarly debate about their impact remains divided. Some argue that heightened fears are overblown due to natural ecosystem limitations, while others contend that specific \"longtail\" contexts face overlooked risks. Our study bridges this debate by providing the first empirical evidence of LLM presence in the latest real-world disinformation datasets, documenting the increase of machine-generated content following ChatGPT's release, and revealing crucial patterns across languages, platforms, and time periods.",
      "authors": [
        "Dominik Macko",
        "Aashish Anantha Ramakrishnan",
        "Jason Samuel Lucas",
        "Robert Moro",
        "Ivan Srba",
        "Adaku Uchendu",
        "Dongwon Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T22:47:53+00:00",
          "link": "https://arxiv.org/abs/2503.23242v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "Beyond speculation: Measuring the growing presence of LLM-generated texts in multilingual disinformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23242",
        "PDF": "https://arxiv.org/pdf/2503.23242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study measures the presence of LLM-generated texts in disinformation but does not contribute to training data processing for LLMs in the context of pretraining or fine-tuning datasets."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.13130",
      "abstract": "Underwater images taken from autonomous underwater vehicles (AUV's) often suffer from low light, high turbidity, poor contrast, motion-blur and excessive light scattering and hence require image enhancement techniques for object recognition. Machine learning methods are being increasingly used for object recognition under such adverse conditions. These enhanced object recognition methods of images taken from AUV's has potential applications in underwater pipeline and optical fibre surveillance, ocean bed resource extraction, ocean floor mapping, underwater species exploration, etc. While the classical machine learning methods are very efficient in terms of accuracy, they require large datasets and high computational time for image classification. In the current work, we use quantum-classical hybrid machine learning methods for real-time under-water object recognition on-board an AUV for the first time. We use real-time motion-blurred and low-light images taken from an on-board camera of AUV built in-house and apply existing hybrid machine learning methods for object recognition. Our hybrid methods consist of quantum encoding and flattening of classical images using quantum circuits and sending them to classical neural networks for image classification. The results of hybrid methods carried out using Pennylane based quantum simulators both on GPU and using pre-trained models on an on-board NVIDIA GPU chipset are compared with results from corresponding classical machine learning methods. We observe that the hybrid quantum machine learning methods show an efficiency greater than 65\\% and reduction in run-time by one-thirds and require 50\\% smaller dataset sizes for training the models compared to classical machine learning methods. We hope that our work opens up further possibilities in quantum enhanced real-time computer vision in autonomous vehicles.",
      "authors": [
        "Sreeraj Rajan Warrier",
        "D Sri Harshavardhan Reddy",
        "Sriya Bada",
        "Rohith Achampeta",
        "Sebastian Uppapalli and Jayasri Dontabhaktuni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-19T18:34:52+00:00",
          "link": "https://arxiv.org/abs/2404.13130v1",
          "size": "3441kb",
          "version": "v1"
        }
      ],
      "title": "On-board classification of underwater images using hybrid classical-quantum CNN based method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.13130",
        "HTML": "https://arxiv.org/html/2404.13130",
        "PDF": "https://arxiv.org/pdf/2404.13130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the use of hybrid classical-quantum CNN methods for onboard classification of underwater images. The paper emphasizes object recognition and quantum machine learning, not relevant to LLM training data processing."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Hybrid Machine Learning",
        "image-classification",
        "Image Classification",
        "Image Enhancement",
        "Object",
        "Object Recognition",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2212.03184",
      "abstract": "We will consider all policies of the agent and will prove that one of them is the best performing policy. While that policy is not computable, computable policies do exist in its proximity. We will define AI as a computable policy which is sufficiently proximal to the best performing policy. Before we can define the agent's best performing policy, we need a language for description of the world. We will also use this language to develop a program which satisfies the AI definition. The program will first understand the world by describing it in the selected language. The program will then use the description in order to predict the future and select the best possible move. While this program is extremely inefficient and practically unusable, it can be improved by refining both the language for description of the world and the algorithm used to predict the future. This can yield a program which is both efficient and consistent with the AI definition.",
      "authors": [
        "Dimiter Dobrev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-28T19:05:32+00:00",
          "link": "https://arxiv.org/abs/2212.03184v1",
          "size": "692kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T07:42:49+00:00",
          "link": "https://arxiv.org/abs/2212.03184v2",
          "size": "474kb",
          "version": "v2"
        }
      ],
      "title": "The AI Definition and a Program Which Satisfies this Definition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.03184",
        "PDF": "https://arxiv.org/pdf/2212.03184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on defining AI as a computable policy and developing a program based on that definition. It does not relate to LLM training data processing or make any contributions in that area."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.15899",
      "abstract": "This paper focuses on the problem of collaborative collision avoidance for autonomous inland ships. Two solutions are provided to solve the problem in a distributed manner. We first present a distributed model predictive control (MPC) algorithm that allows ships to directly negotiate their intention to avoid collision in a synchronous communication framework. Moreover, we introduce a new approach to shape the ship's behavior to follow the waterway traffic regulations. The conditional convergence toward a stationary solution of this algorithm is guaranteed by the theory of the Alternating Direction Method of Multipliers (ADMM). To overcome the problem of asynchronous communication between ships, we adopt a new asynchronous nonlinear ADMM and present an asynchronous distributed MPC algorithm based on it. Several simulations and field experiments show that the proposed algorithms can prevent ship collisions even in complex scenarios.",
      "authors": [
        "Hoang Anh Tran",
        "Nikolai Lauv{\\aa}s",
        "Tor Arne Johansen",
        "Rudy R. Negenborn"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T09:48:28+00:00",
          "link": "https://arxiv.org/abs/2501.15899v1",
          "size": "1805kb",
          "version": "v1"
        }
      ],
      "title": "Asynchronous distributed collision avoidance with intention consensus for inland autonomous ships",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15899",
        "HTML": "https://arxiv.org/html/2501.15899",
        "PDF": "https://arxiv.org/pdf/2501.15899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses asynchronous distributed collision avoidance for inland autonomous ships, focusing on control algorithm design, which is not relevant to LLM training data processing."
      },
      "tasks": [
        "Collision Avoidance",
        "Model Predictive Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17657",
      "abstract": "This paper focuses on identifying the cause and proposing a remedy for the problem of spurious pressure oscillations in a sharp-interface immersed boundary finite element method for incompressible flow problems in moving domains. The numerical method belongs to the class of Eulerian unfitted finite element methods. It employs a cutFEM discretization in space and a standard BDF time-stepping scheme, enabled by a discrete extension of the solution from the physical domain into the ambient space using ghost-penalty stabilization. To investigate the origin of spurious temporal pressure oscillations, we revisit a finite element stability analysis for the steady domain case and extend it to derive a stability estimate for the pressure in the $L^\\infty(L^2)$-norm that is uniform with respect to discretization parameters. By identifying where the arguments fail in the context of a moving domain, we propose a variant of the method that ensures unconditional stability of the instantaneous pressure. As a result, the modified method eliminates spurious pressure oscillations. We also present extensive numerical studies aimed at illustrating our findings and exploring the effects of fluid viscosity, geometry approximation, mass conservation, discretization and stabilization parameters, and the choice of finite element spaces on the occurrence and magnitude of spurious temporal pressure oscillations. The results of the experiments demonstrate a significant improvement in the robustness and accuracy of the proposed method compared to existing approaches.",
      "authors": [
        "Maxim Olshanskii and Henry von Wahl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T15:35:29+00:00",
          "link": "https://arxiv.org/abs/2412.17657v1",
          "size": "10153kb",
          "version": "v1"
        }
      ],
      "title": "Stability of instantaneous pressures in an Eulerian finite element method for moving boundary flow problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17657",
        "PDF": "https://arxiv.org/pdf/2412.17657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on numerical methods for fluid dynamics problems, specifically addressing pressure oscillations in finite element methods. It does not relate to LLM training data processing or any relevant data engineering tasks."
      },
      "repo_urls": [
        "https://github.com/hvonwah/stable_inst_pressure_moving_domain_repro"
      ],
      "source": "arXiv"
    },
    {
      "id": "2011.09177",
      "abstract": "Business process modelling languages typically enable the representation of business process models by employing (graphical) symbols. These symbols can vary depending upon the verbosity of the language, the modelling paradigm, the focus of the language, and so on. To make explicit the different constructs and rules employed by a specific language, as well as bridge the gap across different languages, meta-models have been proposed in literature. These meta-models are a crucial source of knowledge on what state-of-the-art literature considers relevant to describe business processes. The goal of this work is to provide an extensive systematic literature review (SLR) of business process meta-models. This SLR aims at answering research questions concerning: (i) the kind of meta-models proposed in literature; (ii) the recurring constructs they contain; (iii) their purposes; and (iv) their evaluations.",
      "authors": [
        "Greta Adamo",
        "Chiara Ghidini",
        "Chiara Di Francescomarino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2020-11-18T09:54:51+00:00",
          "link": "https://arxiv.org/abs/2011.09177v1",
          "size": "711kb",
          "version": "v1"
        }
      ],
      "title": "What is a Process Model Composed of? A Systematic Literature Review of Meta-Models in BPM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2011.09177",
        "PDF": "https://arxiv.org/pdf/2011.09177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a systematic literature review of meta-models in business process modeling, which does not pertain to LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.17226",
      "abstract": "We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an RL algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{\\frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.",
      "authors": [
        "Yilie Huang",
        "Yanwei Jia",
        "Xun Yu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-24T12:26:21+00:00",
          "link": "https://arxiv.org/abs/2407.17226v1",
          "size": "247kb",
          "version": "v1"
        },
        {
          "date": "2024-09-21T16:48:58+00:00",
          "link": "https://arxiv.org/abs/2407.17226v2",
          "size": "262kb",
          "version": "v2"
        },
        {
          "date": "2025-03-18T14:55:51+00:00",
          "link": "https://arxiv.org/abs/2407.17226v3",
          "size": "203kb",
          "version": "v3"
        },
        {
          "date": "2025-04-08T19:11:31+00:00",
          "link": "https://arxiv.org/abs/2407.17226v4",
          "size": "205kb",
          "version": "v4"
        },
        {
          "date": "2025-07-02T12:25:47+00:00",
          "link": "https://arxiv.org/abs/2407.17226v5",
          "size": "205kb",
          "version": "v5"
        },
        {
          "date": "2025-07-24T15:32:35+00:00",
          "link": "https://arxiv.org/abs/2407.17226v6",
          "size": "205kb",
          "version": "v6"
        }
      ],
      "title": "Sublinear Regret for a Class of Continuous-Time Linear-Quadratic Reinforcement Learning Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17226",
        "PDF": "https://arxiv.org/pdf/2407.17226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on reinforcement learning for continuous-time linear-quadratic control problems and does not address any aspects of LLM training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18549",
      "abstract": "The target defense problem (TDP) for unmanned surface vehicles (USVs) concerns intercepting an adversarial USV before it breaches a designated target region, using one or more defending USVs. A particularly challenging scenario arises when the attacker exhibits superior maneuverability compared to the defenders, significantly complicating effective interception. To tackle this challenge, this letter introduces ARBoids, a novel adaptive residual reinforcement learning framework that integrates deep reinforcement learning (DRL) with the biologically inspired, force-based Boids model. Within this framework, the Boids model serves as a computationally efficient baseline policy for multi-agent coordination, while DRL learns a residual policy to adaptively refine and optimize the defenders' actions. The proposed approach is validated in a high-fidelity Gazebo simulation environment, demonstrating superior performance over traditional interception strategies, including pure force-based approaches and vanilla DRL policies. Furthermore, the learned policy exhibits strong adaptability to attackers with diverse maneuverability profiles, highlighting its robustness and generalization capability. The code of ARBoids will be released upon acceptance of this letter.",
      "authors": [
        "Jiyue Tao",
        "Tongsheng Shen",
        "Dexin Zhao",
        "Feitian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T16:05:33+00:00",
          "link": "https://arxiv.org/abs/2502.18549v1",
          "size": "648kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T05:08:34+00:00",
          "link": "https://arxiv.org/abs/2502.18549v2",
          "size": "2031kb",
          "version": "v2"
        }
      ],
      "title": "ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for Cooperative Multi-USV Target Defense",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18549",
        "HTML": "https://arxiv.org/html/2502.18549",
        "PDF": "https://arxiv.org/pdf/2502.18549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a reinforcement learning framework for unmanned surface vehicle target defense, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20292",
      "abstract": "Vision-Language Models (VLMs) have demonstrated impressive multimodal capabilities in learning joint representations of visual and textual data, making them powerful tools for tasks such as Compositional Zero-Shot Learning (CZSL). CZSL requires models to generalize to novel combinations of visual primitives--such as attributes and objects--that were not explicitly encountered during training. Recent works in prompting for CZSL have focused on modifying inputs for the text encoder, often using static prompts that do not change across varying visual contexts. However, these approaches struggle to fully capture varying visual contexts, as they focus on text adaptation rather than leveraging visual features for compositional reasoning. To address this, we propose a Visual Adaptive Prompting System (VAPS) that leverages a learnable visual prompt repository and similarity-based retrieval mechanism within the framework of VLMs to bridge the gap between semantic and visual features. Our method introduces a dynamic visual prompt repository mechanism that selects the most relevant attribute and object prompts based on the visual features of the image. Our proposed system includes a visual prompt adapter that encourages the model to learn a more generalizable embedding space. Experiments on three CZSL benchmarks, across both closed and open-world scenarios, demonstrate state-of-the-art results.",
      "authors": [
        "Kyle Stein",
        "Arash Mahyari",
        "Guillermo Francia",
        "Eman El-Sheikh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T17:17:43+00:00",
          "link": "https://arxiv.org/abs/2502.20292v1",
          "size": "4205kb",
          "version": "v1"
        },
        {
          "date": "2025-03-14T15:01:37+00:00",
          "link": "https://arxiv.org/abs/2502.20292v2",
          "size": "4205kb",
          "version": "v2"
        },
        {
          "date": "2025-04-30T03:47:52+00:00",
          "link": "https://arxiv.org/abs/2502.20292v3",
          "size": "4205kb",
          "version": "v3"
        },
        {
          "date": "2025-05-03T01:45:21+00:00",
          "link": "https://arxiv.org/abs/2502.20292v4",
          "size": "4205kb",
          "version": "v4"
        },
        {
          "date": "2025-07-08T01:38:49+00:00",
          "link": "https://arxiv.org/abs/2502.20292v5",
          "size": "4134kb",
          "version": "v5"
        },
        {
          "date": "2025-07-24T15:38:22+00:00",
          "link": "https://arxiv.org/abs/2502.20292v6",
          "size": "4134kb",
          "version": "v6"
        }
      ],
      "title": "Visual Adaptive Prompting for Compositional Zero-Shot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20292",
        "HTML": "https://arxiv.org/html/2502.20292",
        "PDF": "https://arxiv.org/pdf/2502.20292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses visual adaptive prompting in Vision-Language Models for compositional zero-shot learning, which does not involve LLMs training data processing."
      },
      "tasks": [
        "Attribute",
        "Compositional Zero-Shot Learning",
        "Zero-Shot Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "1909.12738",
      "abstract": "Recent advances in the field of Business Process Management have brought about several suites able to model complex data objects along with the traditional control flow perspective. Nonetheless, when it comes to formal verification there is still the lack of effective verification tools on imperative data-aware process models and executions: the data perspective is often abstracted away and verification tools are often missing. In this paper we provide a concrete framework for formal verification of reachability properties on imperative data-aware business processes. We start with an expressive, yet empirically tractable class of data-aware process models, an extension of Workflow Nets, and we provide a rigorous mapping between the semantics of such models and that of three important paradigms for reasoning about dynamic systems: Action Languages, Classical Planning, and Model Checking. Then we perform a comprehensive assessment of the performance of three popular tools supporting the above paradigms in solving reachability problems for imperative data-aware business processes, which paves the way for a theoretically well founded and practically viable exploitation of formal verification techniques on data-aware business processes.",
      "authors": [
        "Riccardo De Masellis and Chiara Di Francescomarino and Chiara Ghidini and Sergio Tessaris"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2019-09-27T15:15:55+00:00",
          "link": "https://arxiv.org/abs/1909.12738v1",
          "size": "1525kb",
          "version": "v1"
        },
        {
          "date": "2020-09-03T15:07:02+00:00",
          "link": "https://arxiv.org/abs/1909.12738v2",
          "size": "1533kb",
          "version": "v2"
        }
      ],
      "title": "Solving reachability problems on data-aware workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/1909.12738",
        "PDF": "https://arxiv.org/pdf/1909.12738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a framework for formal verification of reachability properties in data-aware business processes, with no mention of LLM training data processing."
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.14239",
      "abstract": "Efficient computation in deep neural networks is crucial for real-time object detection. However, recent advancements primarily result from improved high-performing hardware rather than improving parameters and FLOP efficiency. This is especially evident in the latest YOLO architectures, where speed is prioritized over lightweight design. As a result, object detection models optimized for low-resource environments like microcontrollers have received less attention. For devices with limited computing power, existing solutions primarily rely on SSDLite or combinations of low-parameter classifiers, creating a noticeable gap between YOLO-like architectures and truly efficient lightweight detectors. This raises a key question: Can a model optimized for parameter and FLOP efficiency achieve accuracy levels comparable to mainstream YOLO models? To address this, we introduce two key contributions to object detection models using MSCOCO as a base validation set. First, we propose LeNeck, a general-purpose detection framework that maintains inference speed comparable to SSDLite while significantly improving accuracy and reducing parameter count. Second, we present LeYOLO, an efficient object detection model designed to enhance computational efficiency in YOLO-based architectures. LeYOLO effectively bridges the gap between SSDLite-based detectors and YOLO models, offering high accuracy in a model as compact as MobileNets. Both contributions are particularly well-suited for mobile, embedded, and ultra-low-power devices, including microcontrollers, where computational efficiency is critical.",
      "authors": [
        "Lilian Hollard",
        "Lucas Mohimont",
        "Nathalie Gaveau",
        "Luiz Angelo Steffenel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-20T12:08:24+00:00",
          "link": "https://arxiv.org/abs/2406.14239v1",
          "size": "486kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T11:48:17+00:00",
          "link": "https://arxiv.org/abs/2406.14239v2",
          "size": "1192kb",
          "version": "v2"
        }
      ],
      "title": "LeYOLO, New Embedded Architecture for Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.14239",
        "HTML": "https://arxiv.org/html/2406.14239",
        "PDF": "https://arxiv.org/pdf/2406.14239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces LeYOLO for object detection, which is unrelated to LLM training data processing. It focuses on efficient model architecture, not on data operations for LLM training."
      },
      "models": [
        {
          "model_path": "lhollard/leyolo-nano",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/lhollard/leyolo-nano"
        },
        {
          "model_path": "lhollard/leyolo-small",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/lhollard/leyolo-small"
        },
        {
          "model_path": "lhollard/leyolo-medium",
          "downloads": "51",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/lhollard/leyolo-medium"
        },
        {
          "model_path": "lhollard/leyolo-large",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/lhollard/leyolo-large"
        }
      ],
      "tasks": [
        "Computational Efficiency",
        "Object",
        "object-detection",
        "Object Detection"
      ],
      "repo_urls": [
        "https://github.com/LilianHollard/LeYOLO"
      ],
      "source": "arXiv"
    },
    {
      "id": "2010.00041",
      "abstract": "A supervised machine learning (ML) based computational methodology for the design of particulate multifunctional composite materials with desired thermal conductivity (TC) is presented. The design variables are physical descriptors of the material microstructure that directly link microstructure to the material's properties. A sufficiently large and uniformly sampled database was generated based on the Sobol sequence. Microstructures were realized using an efficient dense packing algorithm, and the TCs were obtained using our previously developed Fast Fourier Transform (FFT) homogenization method. Our optimized ML method is trained over the generated database and establishes the complex relationship between the structure and properties. Finally, the application of the trained ML model in the inverse design of a new class of composite materials, liquid metal (LM) elastomer, with desired TC is discussed. The results show that the surrogate model is accurate in predicting the microstructure behavior with respect to high-fidelity FFT simulations, and inverse design is robust in finding microstructure parameters according to case studies.",
      "authors": [
        "Mohammad Saber Hashemi",
        "Masoud Safdari",
        "Azadeh Sheidaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2020-09-30T18:18:00+00:00",
          "link": "https://arxiv.org/abs/2010.00041v1",
          "size": "1330kb",
          "version": "v1"
        },
        {
          "date": "2020-10-15T14:47:45+00:00",
          "link": "https://arxiv.org/abs/2010.00041v2",
          "size": "1393kb",
          "version": "v2"
        },
        {
          "date": "2021-01-05T02:15:23+00:00",
          "link": "https://arxiv.org/abs/2010.00041v3",
          "size": "1405kb",
          "version": "v3"
        }
      ],
      "title": "A Supervised Machine Learning Approach for Accelerating the Design of Particulate Composites: Application to Thermal Conductivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2010.00041",
        "PDF": "https://arxiv.org/pdf/2010.00041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a machine learning methodology for designing composite materials, focusing on thermal conductivity, with no connection to LLM training data processing or relevant tasks."
      },
      "tasks": [
        "BIG-bench Machine Learning"
      ],
      "repo_urls": [
        "https://github.com/ms-hashemi/Insulated-LM-elastomer-conductivity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.19757",
      "abstract": "Context: Developer experience (DX) plays a key role in developers' performance and their continued involvement in a software ecosystem (SECO) platform. While researchers and practitioners have recognized several factors affecting DX in SECO platforms, a clear roadmap of the most influential factors is still missing. This is particularly important given the direct impact on developers' interest in SECO and their ongoing engagement with the common technological platform. Goal: This work aims to identify key DX factors and understand how they influence third-party developers' decisions to adopt and keep contributing to a SECO. Methods: We conducted a systematic mapping study (SMS), analyzing 29 studies to assess the state-of-the-art of DX in SECO. Additionally, we conducted a Delphi study to evaluate the influence of 27 DX factors (identified in our SMS) from the perspective of 21 third-party developers to adopt and keep contributing to a SECO. Results: The factors that most strongly influence developers' adoption and ongoing contributions to a SECO are: financial costs for using the platform, desired technical resources for development, low barriers to entry into the applications market, and more financial gains. Conclusion: DX is essential for the success and sustainability of SECO. Our set of DX factors provides valuable insights and recommendations for researchers and practitioners to address key DX concerns from the perspective of third-party developers.",
      "authors": [
        "Rodrigo Oliveira Zacarias and L\\'eo Carvalho Ramos Antunes and M\\'arcio de Oliveira Barros and Rodrigo Pereira dos Santos and Patricia Lago"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T16:17:24+00:00",
          "link": "https://arxiv.org/abs/2506.19757v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Developer Experience Factors in Software Ecosystems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19757",
        "HTML": "https://arxiv.org/html/2506.19757",
        "PDF": "https://arxiv.org/pdf/2506.19757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developer experience factors in software ecosystems and their impact on developers' performance and involvement. It does not discuss any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1912.07383",
      "abstract": "This paper highlights the importance of maintenance techniques in the coming industrial revolution, reviews the evolution of maintenance techniques, and presents a comprehensive literature review on the latest advancement of maintenance techniques, i.e., Predictive Maintenance (PdM), with emphasis on system architectures, optimization objectives, and optimization methods. In industry, any outages and unplanned downtime of machines or systems would degrade or interrupt a company's core business, potentially resulting in significant penalties and immeasurable reputation and economic loss. Existing traditional maintenance approaches, such as Reactive Maintenance (RM) and Preventive Maintenance (PM), suffer from high prevent and repair costs, inadequate or inaccurate mathematical degradation processes, and manual feature extraction. The incoming fourth industrial revolution is also demanding for a new maintenance paradigm to reduce the maintenance cost and downtime, and increase system availability and reliability. Predictive Maintenance (PdM) is envisioned the solution. In this survey, we first provide a high-level view of the PdM system architectures including PdM 4.0, Open System Architecture for Condition Based Monitoring (OSA-CBM), and cloud-enhanced PdM system. Then, we review the specific optimization objectives, which mainly comprise cost minimization, availability/reliability maximization, and multi-objective optimization. Furthermore, we present the optimization methods to achieve the aforementioned objectives, which include traditional Machine Learning (ML) based and Deep Learning (DL) based approaches. Finally, we highlight the future research directions that are critical to promote the application of DL techniques in the context of PdM.",
      "authors": [
        "Tianwen Zhu",
        "Yongyi Ran",
        "Xin Zhou",
        "and Yonggang Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2019-12-12T20:11:51+00:00",
          "link": "https://arxiv.org/abs/1912.07383v1",
          "size": "2823kb",
          "version": "v1"
        },
        {
          "date": "2024-03-22T03:02:39+00:00",
          "link": "https://arxiv.org/abs/1912.07383v2",
          "size": "12935kb",
          "version": "v2"
        }
      ],
      "title": "A Survey of Predictive Maintenance: Systems, Purposes and Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/1912.07383",
        "HTML": "https://arxiv.org/html/1912.07383",
        "PDF": "https://arxiv.org/pdf/1912.07383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on predictive maintenance techniques and systems architecture within industrial settings, without any mention of LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02088",
      "abstract": "We investigate the problem of fairly allocating $m$ indivisible items among $n$ sequentially arriving agents with additive valuations, under the sought-after fairness notion of maximin share (MMS). We first observe a strong impossibility: without appropriate knowledge about the valuation functions of the incoming agents, no online algorithm can ensure any non-trivial MMS approximation, even when there are only two agents. Motivated by this impossibility, we introduce OnlineKTypeFD (online $k$-type fair division), a model that balances theoretical tractability with real-world applicability. In this model, each arriving agent belongs to one of $k$ types, with all agents of a given type sharing the same known valuation function. We do not constrain $k$ to be a constant. Upon arrival, an agent reveals her type, receives an irrevocable allocation, and departs. We study the ex-post MMS guarantees of online algorithms under two arrival models:\n  1- Adversarial arrivals: In this model, an adversary determines the type of each arriving agent. We design a $\\frac{1}{k}$-MMS competitive algorithm and complement it with a lower bound, ruling out any $\\Omega(\\frac{1}{\\sqrt{k}})$-MMS-competitive algorithm, even for binary valuations.\n  2- Stochastic arrivals: In this model, the type of each arriving agent is independently drawn from an underlying, possibly unknown distribution. Unlike the adversarial setting where the dependence on $k$ is unavoidable, we surprisingly show that in the stochastic setting, an asymptotic, arbitrarily close-to-$\\frac{1}{2}$-MMS competitive guarantee is achievable under mild distributional assumptions.\n  Our results extend naturally to a learning-augmented framework; when given access to predictions about valuation functions, we show that the competitive ratios of our algorithms degrade gracefully with multiplicative prediction errors.",
      "authors": [
        "Pooja Kulkarni",
        "Ruta Mehta",
        "Parnian Shahkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Data Structures and Algorithms (cs.DS)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T22:14:03+00:00",
          "link": "https://arxiv.org/abs/2503.02088v1",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "title": "Online Fair Division: Towards Ex-Post Constant MMS Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02088",
        "PDF": "https://arxiv.org/pdf/2503.02088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on fair division algorithms for allocating items among agents with additive valuations, a topic unrelated to LLM training data processing."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Quantum Physics (quant-ph)",
    "Multimedia (cs.MM)",
    "Optimization and Control (math.OC)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Physics and Society (physics.soc-ph)",
    "Computer Science and Game Theory (cs.GT)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Image and Video Processing (eess.IV)",
    "Sound (cs.SD)",
    "Performance (cs.PF)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Portfolio Management (q-fin.PM)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Geometry (cs.CG)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Applications (stat.AP)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Symplectic Geometry (math.SG)",
    "Applied Physics (physics.app-ph)",
    "Accelerator Physics (physics.acc-ph)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "Computational Complexity (cs.CC)",
    "Quantitative Methods (q-bio.QM)",
    "Logic (math.LO)",
    "Superconductivity (cond-mat.supr-con)",
    "Plasma Physics (physics.plasm-ph)",
    "Statistical Finance (q-fin.ST)",
    "General Relativity and Quantum Cosmology (gr-qc)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Trading and Market Microstructure (q-fin.TR)",
    "Category Theory (math.CT)",
    "Astrophysics of Galaxies (astro-ph.GA)",
    "Mathematical Software (cs.MS)",
    "Symbolic Computation (cs.SC)",
    "High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Probability (math.PR)",
    "Discrete Mathematics (cs.DM)",
    "Information Theory (math.IT)",
    "Mathematical Physics (math.MP)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Computation (stat.CO)",
    "Audio and Speech Processing (eess.AS)",
    "Other Computer Science (cs.OH)",
    "Social and Information Networks (cs.SI)",
    "Chaotic Dynamics (nlin.CD)",
    "Metric Geometry (math.MG)",
    "Combinatorics (math.CO)",
    "Differential Geometry (math.DG)",
    "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Group Theory (math.GR)",
    "Other Statistics (stat.OT)",
    "Functional Analysis (math.FA)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "High Energy Physics - Theory (hep-th)",
    "Hardware Architecture (cs.AR)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Computational Physics (physics.comp-ph)",
    "Computational Finance (q-fin.CP)",
    "Software Engineering (cs.SE)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Econometrics (econ.EM)",
    "Data Structures and Algorithms (cs.DS)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Dynamical Systems (math.DS)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to the performance of large language models (LLMs). You are a computer science expert specializing in LLM training data processing. Your task is to analyze a set of arXiv papers and determine their relevance to **LLM training data processing**.\n\n### **Task Objective**\n\nFor each paper, assess whether it makes a technical contribution to **LLM training data processing**.\n\n1. First, the paper must relate to data processing for **pretraining or fine-tuning**, including stages such as LLM pretraining, instruction fine-tuning, supervised fine-tuning (SFT), or alignment fine-tuning.\n2. Second, the paper must involve **training data processing** operations, such as:\n\n   * Data engineering operations, including data collection, data generation, deduplication, filtering, etc.;\n   * Techniques or methods that significantly improve data quality;\n   * Creation or generation of new datasets.\n\n### Answer: **Relevance Classification**\n\n**`core`**: The paper makes a direct contribution to LLM training data processing. Examples include: creation, generation, or synthesis of new datasets; building higher-quality datasets from existing ones; novel data processing techniques; or any data engineering operations that substantially improve data quality.\n\n**`partial`**: The paper briefly discusses training data processing, but the main focus lies elsewhere\u2014such as model architecture, task design, evaluation, or prompt engineering\u2014rather than training data processing.\n\n**`irrelevant`**: The paper does not address any aspect of LLM training data processing.\n\n### **Output Format (strictly follow this JSON structure)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<Paper ID>\",\n      \"answer\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1\u20132 sentence explanation of your classification, citing key content from the abstract or methodology section.\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n\n### Example\n\ninput:\n\n```\n[\n    {\n        \"id\": \"2411.12372\",\n        \"title\": \"RedPajama: an Open Dataset for Training Large Language Models\",\n        \"abstract\": \"Large language models are increasingly becoming a cornerstone technology in artificial intelligence, the sciences, and society as a whole, yet the optimal strategies for dataset composition and filtering remain largely elusive. Many of the top-performing models lack transparency in their dataset curation and model development processes, posing an obstacle to the development of fully open language models. In this paper, we identify three core data-related challenges that must be addressed to advance open-source language models. These include (1) transparency in model development, including the data curation process, (2) access to large quantities of high-quality data, and (3) availability of artifacts and metadata for dataset curation and analysis. To address these challenges, we release RedPajama-V1, an open reproduction of the LLaMA training dataset. In addition, we release RedPajama-V2, a massive web-only dataset consisting of raw, unfiltered text data together with quality signals and metadata. Together, the RedPajama datasets comprise over 100 trillion tokens spanning multiple domains and with their quality signals facilitate the filtering of data, aiming to inspire the development of numerous new datasets. To date, these datasets have already been used in the training of strong language models used in production, such as Snowflake Arctic, Salesforce's XGen and AI2's OLMo. To provide insight into the quality of RedPajama, we present a series of analyses and ablation studies with decoder-only language models with up to 1.6B parameters. Our findings demonstrate how quality signals for web data can be effectively leveraged to curate high-quality subsets of the dataset, underscoring the potential of RedPajama to advance the development of transparent and high-performing language models at scale.\"\n    },\n    {\n        \"id\": \"2306.01116\",\n        \"title\": \"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\",\n        \"abstract\": \"Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.\"\n    }\n]\n```\n\noutput:\n\n```\n{\n  \"result\": [\n    {\n      \"id\": \"2411.12372\",\n      \"answer\": \"core\",\n      \"reason\": \"This paper releases RedPajama-V1 and V2 datasets, comprising over 100 trillion tokens, and introduces quality signals for filtering. It involves data collection, deduplication, filtering, and quality assessment, making a significant contribution to LLM training data processing.\"\n    },\n    {\n      \"id\": \"2306.01116\",\n      \"answer\": \"core\",\n      \"reason\": \"The paper presents the RefinedWeb dataset, which uses only deduplicated and filtered web data to train LLMs. It challenges the conventional reliance on mixed curated corpora and publicly releases both the dataset and models, representing a core contribution to high-quality data construction.\"\n    }\n  ]\n}\n\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "irrelevant": 700,
    "partial": 101,
    "core": 22
  },
  "arxiv_update_date": "2025-07-25",
  "updated_at": "2025-07-25 10:18:31"
}