{
  "data": [
    {
      "id": "2507.13354",
      "abstract": "The introduction of the transformer architecture in 2017 (cf.\\cite{VSP2017}) marked the most striking advancement in natural language processing. The transformer is a model architecture relying entirely on an attention mechanism to draw global dependencies between input and output. However, we believe there is a gap in our theoretical understanding of what the transformer is, and why it works physically. In this paper, from a physical perspective on modern chips, we construct physical models in the Fock space over the Hilbert space of tokens realizing large language models based on a transformer architecture as open quantum systems. Our physical models underlie the transformer architecture for large language models.",
      "authors": [
        "Zeqian Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T10:53:05+00:00",
          "link": "https://arxiv.org/abs/2507.13354v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "Physical models realizing the transformer architecture of large language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13354",
        "HTML": "https://arxiv.org/html/2507.13354v1",
        "PDF": "https://arxiv.org/pdf/2507.13354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the transformer architecture through a physical and theoretical lens, without discussing any aspects of data processing specific to training language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13355",
      "abstract": "Leveraging artificial intelligence (AI)-driven electronic design and automation (EDA) tools, high-performance computing, and parallelized algorithms are essential for next-generation microprocessor innovation, ensuring continued progress in computing, AI, and semiconductor technology. Machine learning-based design rule checking (DRC) and lithography hotspot detection can improve first-pass silicon success. However, conventional ML and neural network (NN)-based models use supervised learning and require a large balanced dataset (in terms of positive and negative classes) and training time. This research addresses those key challenges by proposing the first-ever unsupervised DRC violation prediction methodology. The proposed model can be built using any unbalanced dataset using only one class and set a threshold for it, then fitting any new data querying if they are within the boundary of the model for classification. This research verified the proposed model by implementing different computational cores using CMOS 28 nm technology and Synopsys Design Compiler and IC Compiler II tools. Then, layouts were divided into virtual grids to collect about 60k data for analysis and verification. The proposed method has 99.95% prediction test accuracy, while the existing support vector machine (SVM) and neural network (NN) models have 85.44\\% and 98.74\\% accuracy, respectively. In addition, the proposed methodology has about 26.3x and up to 6003x lower training times compared to SVM and NN-models, respectively.",
      "authors": [
        "Riadul Islam and Dhandeep Challagundla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T04:51:13+00:00",
          "link": "https://arxiv.org/abs/2507.13355v1",
          "size": "3081kb",
          "version": "v1"
        }
      ],
      "title": "PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13355",
        "HTML": "https://arxiv.org/html/2507.13355v1",
        "PDF": "https://arxiv.org/pdf/2507.13355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on predicting design rule violations in electronic design using unsupervised learning, which is unrelated to LLM training data processing, as it doesn't involve any relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13357",
      "abstract": "Phishing attacks represent a significant cybersecurity threat, necessitating adaptive detection techniques. This study explores few-shot Adaptive Linguistic Prompting (ALP) in detecting phishing webpages through the multimodal capabilities of state-of-the-art large language models (LLMs) such as GPT-4o and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides LLMs to analyze textual deception by breaking down linguistic patterns, detecting urgency cues, and identifying manipulative diction commonly found in phishing content. By integrating textual, visual, and URL-based analysis, we propose a unified model capable of identifying sophisticated phishing attempts. Our experiments demonstrate that ALP significantly enhances phishing detection accuracy by guiding LLMs through structured reasoning and contextual analysis. The findings highlight the potential of ALP-integrated multimodal LLMs to advance phishing detection frameworks, achieving an F1-score of 0.93, surpassing traditional approaches. These results establish a foundation for more robust, interpretable, and adaptive linguistic-based phishing detection systems using LLMs.",
      "authors": [
        "Atharva Bhargude",
        "Ishan Gonehal",
        "Chandler Haney",
        "Dave Yoon",
        "Kevin Zhu",
        "Aaron Sandoval",
        "Sean O'Brien",
        "Kaustubh Vinnakota"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T01:26:25+00:00",
          "link": "https://arxiv.org/abs/2507.13357v1",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13357",
        "HTML": "https://arxiv.org/html/2507.13357v1",
        "PDF": "https://arxiv.org/pdf/2507.13357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving phishing detection using Adaptive Linguistic Prompting in multimodal LLMs. It centers on semantic analysis for cybersecurity applications rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13359",
      "abstract": "Due to its extensive applications, aerial image object detection has long been a hot topic in computer vision. In recent years, advancements in Unmanned Aerial Vehicles (UAV) technology have further propelled this field to new heights, giving rise to a broader range of application requirements. However, traditional UAV aerial object detection methods primarily focus on detecting predefined categories, which significantly limits their applicability. The advent of cross-modal text-image alignment (e.g., CLIP) has overcome this limitation, enabling open-vocabulary object detection (OVOD), which can identify previously unseen objects through natural language descriptions. This breakthrough significantly enhances the intelligence and autonomy of UAVs in aerial scene understanding. This paper presents a comprehensive survey of OVOD in the context of UAV aerial scenes. We begin by aligning the core principles of OVOD with the unique characteristics of UAV vision, setting the stage for a specialized discussion. Building on this foundation, we construct a systematic taxonomy that categorizes existing OVOD methods for aerial imagery and provides a comprehensive overview of the relevant datasets. This structured review enables us to critically dissect the key challenges and open problems at the intersection of these fields. Finally, based on this analysis, we outline promising future research directions and application prospects. This survey aims to provide a clear road map and a valuable reference for both newcomers and seasoned researchers, fostering innovation in this rapidly evolving domain. We keep tracing related works at https://github.com/zhouyang2002/OVOD-in-UVA-imagery",
      "authors": [
        "Yang Zhou and Junjie Li and CongYang Ou and Dawei Yan and Haokui Zhang and Xizhe Xue"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T04:56:25+00:00",
          "link": "https://arxiv.org/abs/2507.13359v1",
          "size": "3753kb",
          "version": "v1"
        }
      ],
      "title": "Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13359",
        "HTML": "https://arxiv.org/html/2507.13359v1",
        "PDF": "https://arxiv.org/pdf/2507.13359"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a survey of open-vocabulary object detection in UAV imagery, focusing on a comprehensive review of existing methods and datasets. It doesn't address any aspects of LLM training data processing or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13360",
      "abstract": "This paper introduces a novel deep learning framework for low-light image enhancement, named the Encoder-Decoder Network with Illumination Guidance (EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination map, derived from Bright Channel Prior (BCP), as a guidance input. This illumination guidance helps the network focus on underexposed regions, effectively steering the enhancement process. To further improve the model's representational power, a Spatial Pyramid Pooling (SPP) module is incorporated to extract multi-scale contextual features, enabling better handling of diverse lighting conditions. Additionally, the Swish activation function is employed to ensure smoother gradient propagation during training. EDNIG is optimized within a Generative Adversarial Network (GAN) framework using a composite loss function that combines adversarial loss, pixel-wise mean squared error (MSE), and perceptual loss. Experimental results show that EDNIG achieves competitive performance compared to state-of-the-art methods in quantitative metrics and visual quality, while maintaining lower model complexity, demonstrating its suitability for real-world applications. The source code for this work is available at https://github.com/tranleanh/ednig.",
      "authors": [
        "Le-Anh Tran",
        "Chung Nguyen Tran",
        "Ngoc-Luu Nguyen",
        "Nhan Cach Dang",
        "Jordi Carrabina",
        "David Castells-Rufas",
        "Minh Son Nguyen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T09:35:00+00:00",
          "link": "https://arxiv.org/abs/2507.13360v1",
          "size": "2041kb",
          "version": "v1"
        }
      ],
      "title": "Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13360",
        "HTML": "https://arxiv.org/html/2507.13360v1",
        "PDF": "https://arxiv.org/pdf/2507.13360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a deep learning framework for low-light image enhancement, targeting computer vision task improvements, not LLM training data processing or dataset contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13361",
      "abstract": "Visual Language Models (VLMs) excel at complex visual tasks such as VQA and chart understanding, yet recent work suggests they struggle with simple perceptual tests. We present an evaluation that tests vision-language models' capacity for nonlocal visual reasoning -- reasoning that requires chaining evidence collected from multiple, possibly distant, regions of an image. We isolate three distinct forms of non-local vision: comparative perception, which demands holding two images in working memory and comparing them; saccadic search, which requires making discrete, evidence-driven jumps to locate successive targets; and smooth visual search, which involves searching smoothly along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude Vision 3.7, GPT-o4-mini), even those that perform well on prior primitive-vision benchmarks, fail these tests and barely exceed random accuracy on two variants of our tasks that are trivial for humans. Our structured evaluation suite allows us to test if VLMs can perform similar visual algorithms to humans. Our findings show that despite gains in raw visual acuity, current models lack core visual reasoning capabilities.",
      "authors": [
        "Shmuel Berman",
        "Jia Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T23:15:52+00:00",
          "link": "https://arxiv.org/abs/2507.13361v1",
          "size": "5494kb",
          "version": "v1"
        }
      ],
      "title": "VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13361",
        "HTML": "https://arxiv.org/html/2507.13361v1",
        "PDF": "https://arxiv.org/pdf/2507.13361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates nonlocal visual reasoning in visual language models, focusing on the reasoning capabilities of VLMs rather than training data processing or dataset contributions related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13362",
      "abstract": "This study investigates the spatial reasoning capabilities of vision-language models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement learning. We begin by evaluating the impact of different prompting strategies and find that simple CoT formats, where the model generates a reasoning step before the answer, not only fail to help, but can even harm the model's original performance. In contrast, structured multi-stage prompting based on scene graphs (SceneGraph CoT) significantly improves spatial reasoning accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune models using Group Relative Policy Optimization (GRPO) on the SAT dataset and evaluate their performance on CVBench. Compared to supervised fine-tuning (SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates superior robustness under out-of-distribution (OOD) conditions. In particular, we find that SFT overfits to surface-level linguistic patterns and may degrade performance when test-time phrasing changes (e.g., from \"closer to\" to \"farther from\"). GRPO, on the other hand, generalizes more reliably and maintains stable performance under such shifts. Our findings provide insights into how reinforcement learning and structured prompting improve the spatial reasoning capabilities and generalization behavior of modern VLMs. All code is open source at: https://github.com/Yvonne511/spatial-vlm-investigator",
      "authors": [
        "Binbin Ji",
        "Siddharth Agrawal",
        "Qiance Tang",
        "and Yvonne Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T10:51:12+00:00",
          "link": "https://arxiv.org/abs/2507.13362v1",
          "size": "228kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13362",
        "HTML": "https://arxiv.org/html/2507.13362v1",
        "PDF": "https://arxiv.org/pdf/2507.13362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This study examines spatial reasoning improvements in vision-language models via fine-tuning techniques, mentioning supervised fine-tuning, which relates to LLM training data processing, but the main focus is on enhancing VLM capabilities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13363",
      "abstract": "Modern 3D object detection datasets are constrained by narrow class taxonomies and costly manual annotations, limiting their ability to scale to open-world settings. In contrast, 2D vision-language models trained on web-scale image-text pairs exhibit rich semantic understanding and support open-vocabulary detection via natural language prompts. In this work, we leverage the maturity and category diversity of 2D foundation models to perform open-vocabulary 3D object detection without any human-annotated 3D labels.\n  Our pipeline uses a 2D vision-language detector to generate text-conditioned proposals, which are segmented with SAM and back-projected into 3D using camera geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D bounding boxes without training. To simulate adverse real-world conditions, we construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes dataset.\n  Experiments demonstrate that our method achieves competitive localization performance across multiple settings, including LiDAR-based and purely RGB-D inputs, all while remaining training-free and open-vocabulary. Our results highlight the untapped potential of 2D foundation models for scalable 3D perception. We open-source our code and resources at https://github.com/atharv0goel/open-world-3D-det.",
      "authors": [
        "Atharv Goel",
        "Mehar Khurana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T15:00:13+00:00",
          "link": "https://arxiv.org/abs/2507.13363v1",
          "size": "624kb",
          "version": "v1"
        }
      ],
      "title": "Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13363",
        "HTML": "https://arxiv.org/html/2507.13363v1",
        "PDF": "https://arxiv.org/pdf/2507.13363"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D object detection leveraging 2D vision-language models for open-vocabulary detection and does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13364",
      "abstract": "We present a novel multimodal multitask network and associated training algorithm. The method is capable of ingesting data from approximately 12 different modalities namely image, video, audio, text, depth, point cloud, time series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed approach utilizes modality specialized tokenizers, a shared transformer architecture, and cross-attention mechanisms to project the data from different modalities into a unified embedding space. It addresses multimodal and multitask scenarios by incorporating modality-specific task heads for different tasks in respective modalities. We propose a novel pretraining strategy with iterative modality switching to initialize the network, and a training algorithm which trades off fully joint training over all modalities, with training on pairs of modalities at a time. We provide comprehensive evaluation across 25 datasets from 12 modalities and show state of the art performances, demonstrating the effectiveness of the proposed architecture, pretraining strategy and adapted multitask training.",
      "authors": [
        "Siddharth Srivastava",
        "Gaurav Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T18:51:22+00:00",
          "link": "https://arxiv.org/abs/2507.13364v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13364",
        "HTML": "https://arxiv.org/html/2507.13364v1",
        "PDF": "https://arxiv.org/pdf/2507.13364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a novel multimodal multitask network, focusing on a transformer-based architecture for processing various data modalities, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13366",
      "abstract": "Urban mobility data has significant connections with economic growth and plays an essential role in various smart-city applications. However, due to privacy concerns and substantial data collection costs, fine-grained human mobility trajectories are difficult to become publicly available on a large scale. A promising solution to address this issue is trajectory synthesizing. However, existing works often ignore the inherent structural complexity of trajectories, unable to handle complicated high-dimensional distributions and generate realistic fine-grained trajectories. In this paper, we propose Cardiff, a coarse-to-fine Cascaded hybrid diffusion-based trajectory synthesizing framework for fine-grained and privacy-preserving mobility generation. By leveraging the hierarchical nature of urban mobility, Cardiff decomposes the generation process into two distinct levels, i.e., discrete road segment-level and continuous fine-grained GPS-level: (i) In the segment-level, to reduce computational costs and redundancy in raw trajectories, we first encode the discrete road segments into low-dimensional latent embeddings and design a diffusion transformer-based latent denoising network for segment-level trajectory synthesis. (ii) Taking the first stage of generation as conditions, we then design a fine-grained GPS-level conditional denoising network with a noise augmentation mechanism to achieve robust and high-fidelity generation. Additionally, the Cardiff framework not only progressively generates high-fidelity trajectories through cascaded denoising but also flexibly enables a tunable balance between privacy preservation and utility. Experimental results on three large real-world trajectory datasets demonstrate that our method outperforms state-of-the-art baselines in various metrics.",
      "authors": [
        "Baoshen Guo and Zhiqing Hong and Junyi Li and Shenhao Wang and Jinhua Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:50:01+00:00",
          "link": "https://arxiv.org/abs/2507.13366v1",
          "size": "8046kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging the Spatial Hierarchy: Coarse-to-fine Trajectory Generation via Cascaded Hybrid Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13366",
        "HTML": "https://arxiv.org/html/2507.13366v1",
        "PDF": "https://arxiv.org/pdf/2507.13366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on trajectory synthesizing using a diffusion-based framework, a technique applied to mobility data that does not delve into LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13367",
      "abstract": "Steganography is the process of embedding secret information discreetly within a carrier, ensuring secure exchange of confidential data. The Adaptive Pixel Value Differencing (APVD) steganography method, while effective, encounters certain challenges like the \"unused blocks\" issue. This problem can cause a decrease in security, compromise the embedding capacity, and lead to lower visual quality. This research presents a novel steganographic strategy that integrates APVD with pseudorandom pixel selection to effectively mitigate these issues. The results indicate that the new method outperforms existing techniques in aspects of security, data hiding capacity, and the preservation of image quality. Empirical results reveal that the combination of APVD with pseudorandom pixel selection significantly enhances key image quality metrics such as Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQ), and Structural Similarity Index (SSIM), surpassing other contemporary methods in performance. The newly proposed method is versatile, able to handle a variety of cover and secret images in both color and grayscale, thereby ensuring secure data transmission without compromising the aesthetic quality of the image.",
      "authors": [
        "Mehrab Hosain",
        "Rajiv Kapoor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T04:54:06+00:00",
          "link": "https://arxiv.org/abs/2507.13367v1",
          "size": "776kb",
          "version": "v1"
        }
      ],
      "title": "A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13367",
        "PDF": "https://arxiv.org/pdf/2507.13367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research paper presents a steganographic technique for image security and does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13368",
      "abstract": "Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes in an attribute graph into different clusters, has seen substantial potential in various industrial scenarios like community detection and recommendation. However, the real-world attribute graphs, e.g., social networks interactions, are usually large-scale and attribute-missing. To solve these two problems, we propose a novel DGC method termed \\underline{\\textbf{C}}omplementary \\underline{\\textbf{M}}ulti-\\underline{\\textbf{V}}iew \\underline{\\textbf{N}}eighborhood \\underline{\\textbf{D}}ifferentiation (\\textit{CMV-ND}), which preprocesses graph structural information into multiple views in a complete but non-redundant manner. First, to ensure completeness of the structural information, we propose a recursive neighborhood search that recursively explores the local structure of the graph by completely expanding node neighborhoods across different hop distances. Second, to eliminate the redundancy between neighborhoods at different hops, we introduce a neighborhood differential strategy that ensures no overlapping nodes between the differential hop representations. Then, we construct $K+1$ complementary views from the $K$ differential hop representations and the features of the target node. Last, we apply existing multi-view clustering or DGC methods to the views. Experimental results on six widely used graph datasets demonstrate that CMV-ND significantly improves the performance of various methods.",
      "authors": [
        "Yaowen Hu",
        "Wenxuan Tu",
        "Yue Liu",
        "Xinhang Wan",
        "Junyi Yan",
        "Taichun Zhou",
        "Xinwang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:42:43+00:00",
          "link": "https://arxiv.org/abs/2507.13368v1",
          "size": "891kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiatio",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13368",
        "HTML": "https://arxiv.org/html/2507.13368v1",
        "PDF": "https://arxiv.org/pdf/2507.13368"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for deep graph clustering to address missing attributes in large-scale graphs, and it is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13369",
      "abstract": "Large Language Models (LLMs) are gaining popularity for hardware design automation, particularly through Register Transfer Level (RTL) code generation. In this work, we examine the current literature on RTL generation using LLMs and identify key requirements for training and fine-tuning datasets. We construct a robust Verilog dataset through an automated three-pronged process involving database (DB) creation and management with PostgreSQL, data collection from code hosting sites like OpenCores and GitHub, and data preprocessing to verify the codes' syntax, run logic synthesis, and extract relevant module metadata. We implement a scalable and efficient DB infrastructure to support analysis and detail our preprocessing pipeline to enforce high-quality data before DB insertion. The resulting dataset comprises 20,392 Verilog samples, 751 MB of Verilog code data, which is the largest high-quality Verilog dataset for LLM fine-tuning to our knowledge. We further evaluate the dataset, address associated challenges, and explore potential applications for future research and development in LLM-based hardware generation.",
      "authors": [
        "Paul E. Calzada",
        "Zahin Ibnat",
        "Tanvir Rahman",
        "Kamal Kandula",
        "Danyu Lu",
        "Sujan Kumar Saha",
        "Farimah Farahmandi",
        "Mark Tehranipoor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:06:54+00:00",
          "link": "https://arxiv.org/abs/2507.13369v1",
          "size": "3269kb",
          "version": "v1"
        }
      ],
      "title": "VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13369",
        "HTML": "https://arxiv.org/html/2507.13369v1",
        "PDF": "https://arxiv.org/pdf/2507.13369"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper constructs the largest high-quality Verilog dataset for LLM fine-tuning, detailing data collection and preprocessing to ensure high-quality data. It directly contributes to LLM training data processing by focusing on dataset creation and enhancement with a robust preprocessing framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13370",
      "abstract": "The openness of social media enables the free exchange of opinions, but it also presents challenges in guiding opinion evolution towards global consensus. Existing methods often directly modify user views or enforce cross-group connections. These intrusive interventions undermine user autonomy, provoke psychological resistance, and reduce the efficiency of global consensus. Additionally, due to the lack of a long-term perspective, promoting local consensus often exacerbates divisions at the macro level. To address these issues, we propose the hierarchical, non-intrusive opinion guidance framework, H-NeiFi. It first establishes a two-layer dynamic model based on social roles, considering the behavioral characteristics of both experts and non-experts. Additionally, we introduce a non-intrusive neighbor filtering method that adaptively controls user communication channels. Using multi-agent reinforcement learning (MARL), we optimize information propagation paths through a long-term reward function, avoiding direct interference with user interactions. Experiments show that H-NeiFi increases consensus speed by 22.0% to 30.7% and maintains global convergence even in the absence of experts. This approach enables natural and efficient consensus guidance by protecting user interaction autonomy, offering a new paradigm for social network governance.",
      "authors": [
        "Shijun Guo",
        "Haoran Xu",
        "Yaming Yang",
        "Ziyu Guan",
        "Wei Zhao",
        "Xinyi Zhang",
        "Yishan Song",
        "Jiwei Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:56:33+00:00",
          "link": "https://arxiv.org/abs/2507.13370v1",
          "size": "24845kb",
          "version": "v1"
        }
      ],
      "title": "H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13370",
        "HTML": "https://arxiv.org/html/2507.13370v1",
        "PDF": "https://arxiv.org/pdf/2507.13370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a social media opinion guidance framework, leveraging multi-agent reinforcement learning for consensus. It does not address any aspect of LLM training data processing, such as dataset creation or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13371",
      "abstract": "This paper proposes an end-to-end deep learning framework integrating optical motion capture with a Transformer-based model to enhance medical rehabilitation. It tackles data noise and missing data caused by occlusion and environmental factors, while detecting abnormal movements in real time to ensure patient safety. Utilizing temporal sequence modeling, our framework denoises and completes motion capture data, improving robustness. Evaluations on stroke and orthopedic rehabilitation datasets show superior performance in data reconstruction and anomaly detection, providing a scalable, cost-effective solution for remote rehabilitation with reduced on-site supervision.",
      "authors": [
        "Yeming Cai",
        "Yang Wang",
        "Zhenglin Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:28:55+00:00",
          "link": "https://arxiv.org/abs/2507.13371v1",
          "size": "2067kb",
          "version": "v1"
        }
      ],
      "title": "Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13371",
        "PDF": "https://arxiv.org/pdf/2507.13371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a transformer-based framework for motion capture denoising and anomaly detection in medical rehabilitation, focusing on improving data quality for specific applications. It does not pertain to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13372",
      "abstract": "Breast cancer is a leading cause of death among women globally, and early detection is critical for improving survival rates. This paper introduces an innovative framework that integrates Vision Transformers (ViT) and Graph Neural Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset. Our framework leverages ViT's ability to capture global image features and GNN's strength in modeling structural relationships, achieving an accuracy of 84.2%, outperforming traditional methods. Additionally, interpretable attention heatmaps provide insights into the model's decision-making process, aiding radiologists in clinical settings.",
      "authors": [
        "Yeming Cai",
        "Zhenglin Li",
        "Yang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:32:48+00:00",
          "link": "https://arxiv.org/abs/2507.13372v1",
          "size": "1697kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13372",
        "PDF": "https://arxiv.org/pdf/2507.13372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework integrating Vision Transformers and Graph Neural Networks for breast cancer detection, focusing on image processing and model architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13373",
      "abstract": "Hierarchical feature representations play a pivotal role in computer vision, particularly in object detection for autonomous driving. Multi-level semantic understanding is crucial for accurately identifying pedestrians, vehicles, and traffic signs in dynamic environments. However, existing architectures, such as YOLO and DETR, struggle to maintain feature consistency across different scales while balancing detection precision and computational efficiency. To address these challenges, we propose Butter, a novel object detection framework designed to enhance hierarchical feature representations for improving detection robustness. Specifically, Butter introduces two key innovations: Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which refines multi-scale feature consistency by leveraging adaptive frequency filtering to enhance structural and boundary precision, and Progressive Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively integrates multi-level features to mitigate semantic gaps and strengthen hierarchical feature learning. Through extensive experiments on BDD100K, KITTI, and Cityscapes, Butter demonstrates superior feature representation capabilities, leading to notable improvements in detection accuracy while reducing model complexity. By focusing on hierarchical feature refinement and integration, Butter provides an advanced approach to object detection that achieves a balance between accuracy, deployability, and computational efficiency in real-time autonomous driving scenarios. Our model and implementation are publicly available at https://github.com/Aveiro-Lin/Butter, facilitating further research and validation within the autonomous driving community.",
      "authors": [
        "Xiaojian Lin",
        "Wenxin Zhang",
        "Yuchu Jiang",
        "Wangyu Wu",
        "Yiran Guo",
        "Kangxu Wang",
        "Zongzheng Zhang",
        "Guijin Wang",
        "Lei Jin",
        "Hao Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:31:01+00:00",
          "link": "https://arxiv.org/abs/2507.13373v1",
          "size": "25146kb",
          "version": "v1"
        }
      ],
      "title": "Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13373",
        "HTML": "https://arxiv.org/html/2507.13373v1",
        "PDF": "https://arxiv.org/pdf/2507.13373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an object detection framework for autonomous driving, emphasizing feature enhancement and hierarchical fusion. It does not involve LLM training data processing or dataset creation related to natural language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13374",
      "abstract": "We introduce ModaRoute, an LLM-based intelligent routing system that dynamically selects optimal modalities for multimodal video retrieval. While dense text captions can achieve 75.9% Recall@5, they require expensive offline processing and miss critical visual information present in 34% of clips with scene text not captured by ASR. By analyzing query intent and predicting information needs, ModaRoute reduces computational overhead by 41% while achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR (speech), OCR (text), and visual indices, averaging 1.78 modalities per query versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips demonstrates that intelligent routing provides a practical solution for scaling multimodal retrieval systems, reducing infrastructure costs while maintaining competitive effectiveness for real-world deployment.",
      "authors": [
        "Kevin Dela Rosa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:45:03+00:00",
          "link": "https://arxiv.org/abs/2507.13374v1",
          "size": "2208kb",
          "version": "v1"
        }
      ],
      "title": "Smart Routing for Multimodal Video Retrieval: When to Search What",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13374",
        "HTML": "https://arxiv.org/html/2507.13374v1",
        "PDF": "https://arxiv.org/pdf/2507.13374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multimodal video retrieval system (ModaRoute) which optimizes query routing using LLMs, but it does not contribute to LLM training data processing such as data engineering or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13375",
      "abstract": "Layer assignment is critical for global routing of VLSI circuits. It converts 2D routing paths into 3D routing solutions by determining the proper metal layer for each routing segments to minimize congestion and via count. As different layers have different unit resistance and capacitance, layer assignment also has significant impacts to timing and power. With growing design complexity, it becomes increasingly challenging to simultaneously optimize timing, power, and congestion efficiently. Existing studies are mostly limited to a subset of objectives. In this paper, we propose a GPU-accelerated performance-driven layer assignment framework, GAP-LA, for holistic optimization the aforementioned objectives. Experimental results demonstrate that we can achieve 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4% better total negative slack (TNS) while maintaining power and congestion with competitive runtime compared with ISPD 2025 contest winners, especially on designs with up to 12 millions of nets.",
      "authors": [
        "Chunyuan Zhao",
        "Zizheng Guo",
        "Zuodong Zhang",
        "Yibo Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:43:44+00:00",
          "link": "https://arxiv.org/abs/2507.13375v1",
          "size": "991kb",
          "version": "v1"
        }
      ],
      "title": "GAP-LA: GPU-Accelerated Performance-Driven Layer Assignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13375",
        "HTML": "https://arxiv.org/html/2507.13375v1",
        "PDF": "https://arxiv.org/pdf/2507.13375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses GPU-accelerated layer assignment for VLSI circuit routing, focusing on optimizing timing, power, and congestion. It does not pertain to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13377",
      "abstract": "In this paper, we propose StructInbet, an inbetweening system designed to generate controllable transitions over explicit structural guidance. StructInbet introduces two key contributions. First, we propose explicit structural guidance to the inbetweening problem to reduce the ambiguity inherent in pixel trajectories. Second, we adopt a temporal attention mechanism that incorporates visual identity from both the preceding and succeeding keyframes, ensuring consistency in character appearance.",
      "authors": [
        "Zhenglin Pan",
        "Haoran Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:01:29+00:00",
          "link": "https://arxiv.org/abs/2507.13377v1",
          "size": "923kb",
          "version": "v1"
        }
      ],
      "title": "StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13377",
        "HTML": "https://arxiv.org/html/2507.13377v1",
        "PDF": "https://arxiv.org/pdf/2507.13377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes an inbetweening system (StructInbet) focusing on generating controllable transitions in visual content. It does not address LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13378",
      "abstract": "Industrial defect detection is vital for upholding product quality across contemporary manufacturing systems. As the expectations for precision, automation, and scalability intensify, conventional inspection approaches are increasingly found wanting in addressing real-world demands. Notable progress in computer vision and deep learning has substantially bolstered defect detection capabilities across both 2D and 3D modalities. A significant development has been the pivot from closed-set to open-set defect detection frameworks, which diminishes the necessity for extensive defect annotations and facilitates the recognition of novel anomalies. Despite such strides, a cohesive and contemporary understanding of industrial defect detection remains elusive. Consequently, this survey delivers an in-depth analysis of both closed-set and open-set defect detection strategies within 2D and 3D modalities, charting their evolution in recent years and underscoring the rising prominence of open-set techniques. We distill critical challenges inherent in practical detection environments and illuminate emerging trends, thereby providing a current and comprehensive vista of this swiftly progressing field.",
      "authors": [
        "Yuqi Cheng",
        "Yunkang Cao",
        "Haiming Yao",
        "Wei Luo",
        "Cheng Jiang",
        "Hui Zhang",
        "Weiming Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:03:56+00:00",
          "link": "https://arxiv.org/abs/2507.13378v1",
          "size": "3341kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13378",
        "HTML": "https://arxiv.org/html/2507.13378v1",
        "PDF": "https://arxiv.org/pdf/2507.13378"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on industrial defect detection methods, demonstrating advancements in computer vision and deep learning for detecting defects. It does not relate to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13379",
      "abstract": "The rise of digital platforms has enabled the large scale observation of individual and collective behavior through high resolution interaction data. This development has opened new analytical pathways for investigating how information circulates, how opinions evolve, and how coordination emerges in online environments. Yet despite a growing body of research, the field remains fragmented and marked by methodological heterogeneity, limited model validation, and weak integration across domains. This survey offers a systematic synthesis of empirical findings and formal models. We examine platform-level regularities, assess the methodological architectures that generate them, and evaluate the extent to which current modeling frameworks account for observed dynamics. The goal is to consolidate a shared empirical baseline and clarify the structural constraints that shape inference in this domain, laying the groundwork for more robust, comparable, and actionable analyses of online social systems.",
      "authors": [
        "Niccol\\`o Di Marco",
        "Anita Bonetti",
        "Edoardo Di Martino",
        "Edoardo Loru",
        "Jacopo Nudo",
        "Mario Edoardo Pandolfo",
        "Giulio Pecile",
        "Emanuele Sangiorgio",
        "Irene Scalco",
        "Simon Zollo",
        "Matteo Cinelli",
        "Fabiana Zollo",
        "Walter Quattrociocchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:46:20+00:00",
          "link": "https://arxiv.org/abs/2507.13379v1",
          "size": "139kb",
          "version": "v1"
        }
      ],
      "title": "Patterns, Models, and Challenges in Online Social Media: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13379",
        "HTML": "https://arxiv.org/html/2507.13379v1",
        "PDF": "https://arxiv.org/pdf/2507.13379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys empirical findings and modeling frameworks related to online social media platforms, focusing on information circulation and opinion dynamics without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13380",
      "abstract": "In the field of emotion recognition, the development of high-performance models remains a challenge due to the scarcity of high-quality, diverse emotional datasets. Emotional expressions are inherently subjective, shaped by individual personality traits, socio-cultural backgrounds, and contextual factors, making large-scale, generalizable data collection both ethically and practically difficult. To address this issue, we introduce PersonaGen, a novel framework for generating emotionally rich text using a Large Language Model (LLM) through multi-stage persona-based conditioning. PersonaGen constructs layered virtual personas by combining demographic attributes, socio-cultural backgrounds, and detailed situational contexts, which are then used to guide emotion expression generation. We conduct comprehensive evaluations of the generated synthetic data, assessing semantic diversity through clustering and distributional metrics, human-likeness via LLM-based quality scoring, realism through comparison with real-world emotion corpora, and practical utility in downstream emotion classification tasks. Experimental results show that PersonaGen significantly outperforms baseline methods in generating diverse, coherent, and discriminative emotion expressions, demonstrating its potential as a robust alternative for augmenting or replacing real-world emotional datasets.",
      "authors": [
        "Keito Inoshita",
        "Rushia Harada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:32:38+00:00",
          "link": "https://arxiv.org/abs/2507.13380v1",
          "size": "1148kb",
          "version": "v1"
        }
      ],
      "title": "Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13380",
        "PDF": "https://arxiv.org/pdf/2507.13380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces a framework for generating synthetic data for emotion recognition using LLMs, involving some aspects of data generation. However, its primary focus is on emotion recognition, not on broader LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13381",
      "abstract": "Large Language Models (LLMs) are increasingly applied to tasks involving structured inputs such as graphs. Abstract Meaning Representations (AMRs), which encode rich semantics as directed graphs, offer a rigorous testbed for evaluating LLMs on text generation from such structures. Yet, current methods often arbitrarily linearize AMRs, discarding key structural cues, or rely on architectures incompatible with standard LLMs. We introduce SAFT, a structure-aware fine-tuning approach that injects graph topology into pretrained LLMs without architectural changes. We compute direction-sensitive positional encodings from the magnetic Laplacian of transformed AMRs and project them into the embedding space of the LLM. While possibly applicable to any graph-structured inputs, we focus on AMR-to-text generation as a representative and challenging benchmark. SAFT sets a new state-of-the-art on AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph complexity, highlighting the value of structure-aware representations in enhancing LLM performance. SAFT offers a general and effective pathway for bridging structured data and language models.",
      "authors": [
        "Rafiq Kamel",
        "Filippo Guerranti",
        "Simon Geisler",
        "Stephan G\\\"unnemann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:12:57+00:00",
          "link": "https://arxiv.org/abs/2507.13381v1",
          "size": "1484kb",
          "version": "v1"
        }
      ],
      "title": "SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13381",
        "PDF": "https://arxiv.org/pdf/2507.13381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning LLMs with structure-aware techniques for AMR-to-text generation, which involves data processing for fine-tuning, but the core focus is on methodology rather than dataset creation or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13382",
      "abstract": "In today\\'s digital world, fake news is spreading with immense speed. Its a significant concern to address. In this work, we addressed that challenge using novel graph based approach. We took dataset from Kaggle that contains real and fake news articles. To test our approach we incorporated recent covid-19 related news articles that contains both genuine and fake news that are relevant to this problem. This further enhances the dataset as well instead of relying completely on the original dataset. We propose a contextual graph-based approach to detect fake news articles. We need to convert news articles into appropriate schema, so we leverage Natural Language Processing (NLP) techniques to transform news articles into contextual graph structures. We then apply the Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD) algorithm for graph mining. Graph-based methods are particularly effective for handling rich contextual data, as they enable the discovery of complex patterns that traditional query-based or statistical techniques might overlook. Our proposed approach identifies normative patterns within the dataset and subsequently uncovers anomalous patterns that deviate from these established norms.",
      "authors": [
        "Chandrashekar Muniyappa",
        "Sirisha Velampalli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:45:25+00:00",
          "link": "https://arxiv.org/abs/2507.13382v1",
          "size": "752kb",
          "version": "v1"
        }
      ],
      "title": "Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13382",
        "HTML": "https://arxiv.org/html/2507.13382v1",
        "PDF": "https://arxiv.org/pdf/2507.13382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper applies graph-based approaches for fake news detection using NLP techniques, but it does not directly address the creation, processing, or enhancement of datasets specific to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13383",
      "abstract": "Current text-to-image (T2I) models often fail to account for diverse human experiences, leading to misaligned systems. We advocate for pluralistic alignment, where an AI understands and is steerable towards diverse, and often conflicting, human values. Our work provides three core contributions to achieve this in T2I models. First, we introduce a novel dataset for Diverse Intersectional Visual Evaluation (DIVE) -- the first multimodal dataset for pluralistic alignment. It enable deep alignment to diverse safety perspectives through a large pool of demographically intersectional human raters who provided extensive feedback across 1000 prompts, with high replication, capturing nuanced safety perceptions. Second, we empirically confirm demographics as a crucial proxy for diverse viewpoints in this domain, revealing significant, context-dependent differences in harm perception that diverge from conventional evaluations. Finally, we discuss implications for building aligned T2I models, including efficient data collection strategies, LLM judgment capabilities, and model steerability towards diverse perspectives. This research offers foundational tools for more equitable and aligned T2I systems. Content Warning: The paper includes sensitive content that may be harmful.",
      "authors": [
        "Charvi Rastogi",
        "Tian Huey Teh",
        "Pushkar Mishra",
        "Roma Patel",
        "Ding Wang",
        "Mark D\\'iaz",
        "Alicia Parrish",
        "Aida Mostafazadeh Davani",
        "Zoe Ashwood",
        "Michela Paganini",
        "Vinodkumar Prabhakaran",
        "Verena Rieser",
        "Lora Aroyo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:02:35+00:00",
          "link": "https://arxiv.org/abs/2507.13383v1",
          "size": "4157kb",
          "version": "v1"
        }
      ],
      "title": "Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13383",
        "HTML": "https://arxiv.org/html/2507.13383v1",
        "PDF": "https://arxiv.org/pdf/2507.13383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel dataset, DIVE, aimed at improving alignment in text-to-image models with diverse safety perspectives, involving data collection strategies and quality improvement relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13385",
      "abstract": "A large variety of geospatial data layers is available around the world ranging from remotely-sensed raster data like satellite imagery, digital elevation models, predicted land cover maps, and human-annotated data, to data derived from environmental sensors such as air temperature or wind speed data. A large majority of machine learning models trained on satellite imagery (SatML), however, are designed primarily for optical input modalities such as multi-spectral satellite imagery. To better understand the value of using other input modalities alongside optical imagery in supervised learning settings, we generate augmented versions of SatML benchmark tasks by appending additional geographic data layers to datasets spanning classification, regression, and segmentation. Using these augmented datasets, we find that fusing additional geographic inputs with optical imagery can significantly improve SatML model performance. Benefits are largest in settings where labeled data are limited and in geographic out-of-sample settings, suggesting that multi-modal inputs may be especially valuable for data-efficiency and out-of-sample performance of SatML models. Surprisingly, we find that hard-coded fusion strategies outperform learned variants, with interesting implications for future work.",
      "authors": [
        "Arjun Rao",
        "Esther Rolf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:57:29+00:00",
          "link": "https://arxiv.org/abs/2507.13385v1",
          "size": "14437kb",
          "version": "v1"
        }
      ],
      "title": "Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13385",
        "PDF": "https://arxiv.org/pdf/2507.13385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with using multiple input modalities to improve machine learning with satellite imagery. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13386",
      "abstract": "Recent advances in generative models have demonstrated remarkable capabilities in producing high-quality images, but their reliance on large-scale unlabeled data has raised significant safety and copyright concerns. Efforts to address these issues by erasing unwanted concepts have shown promise. However, many existing erasure methods involve excessive modifications that compromise the overall utility of the model. In this work, we address these issues by formulating a novel minimalist concept erasure objective based \\emph{only} on the distributional distance of final generation outputs. Building on our formulation, we derive a tractable loss for differentiable optimization that leverages backpropagation through all generation steps in an end-to-end manner. We also conduct extensive analysis to show theoretical connections with other models and methods. To improve the robustness of the erasure, we incorporate neuron masking as an alternative to model fine-tuning. Empirical evaluations on state-of-the-art flow-matching models demonstrate that our method robustly erases concepts without degrading overall model performance, paving the way for safer and more responsible generative models.",
      "authors": [
        "Yang Zhang",
        "Er Jin",
        "Yanfei Dong",
        "Yixuan Wu",
        "Philip Torr",
        "Ashkan Khakzar",
        "Johannes Stegmaier",
        "Kenji Kawaguchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:32:14+00:00",
          "link": "https://arxiv.org/abs/2507.13386v1",
          "size": "17001kb",
          "version": "v1"
        }
      ],
      "title": "Minimalist Concept Erasure in Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13386",
        "HTML": "https://arxiv.org/html/2507.13386v1",
        "PDF": "https://arxiv.org/pdf/2507.13386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on minimalist concept erasure in generative models, addressing safety and copyright concerns but not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13387",
      "abstract": "Accurate perception of the surrounding environment is essential for safe autonomous driving. 3D occupancy prediction, which estimates detailed 3D structures of roads, buildings, and other objects, is particularly important for vision-centric autonomous driving systems that do not rely on LiDAR sensors. However, in 3D semantic occupancy prediction -- where each voxel is assigned a semantic label -- annotated LiDAR point clouds are required, making data acquisition costly. In contrast, large-scale binary occupancy data, which only indicate occupied or free space without semantic labels, can be collected at a lower cost. Despite their availability, the potential of leveraging such data remains unexplored. In this study, we investigate the utilization of large-scale binary occupancy data from two perspectives: (1) pre-training and (2) learning-based auto-labeling. We propose a novel binary occupancy-based framework that decomposes the prediction process into binary and semantic occupancy modules, enabling effective use of binary occupancy data. Our experimental results demonstrate that the proposed framework outperforms existing methods in both pre-training and auto-labeling tasks, highlighting its effectiveness in enhancing 3D semantic occupancy prediction. The code is available at https://github.com/ToyotaInfoTech/b2s-occupancy",
      "authors": [
        "Chihiro Noguchi and Takaki Yamamoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:57:16+00:00",
          "link": "https://arxiv.org/abs/2507.13387v1",
          "size": "8688kb",
          "version": "v1"
        }
      ],
      "title": "From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13387",
        "HTML": "https://arxiv.org/html/2507.13387v1",
        "PDF": "https://arxiv.org/pdf/2507.13387"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores binary occupancy data for 3D semantic occupancy prediction in autonomous driving, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13388",
      "abstract": "With the rapid advancement of diffusion-based generative models, Stable Diffusion (SD) has emerged as a state-of-the-art framework for high-fidelity im-age synthesis. However, existing SD models suffer from suboptimal feature aggregation, leading to in-complete semantic alignment and loss of fine-grained details, especially in highly textured and complex scenes. To address these limitations, we propose a novel dual-latent integration framework that en-hances feature interactions between the base latent and refined latent representations. Our approach em-ploys a feature concatenation strategy followed by an adaptive fusion module, which can be instantiated as either (i) an Adaptive Global Fusion (AGF) for hier-archical feature harmonization, or (ii) a Dynamic Spatial Fusion (DSF) for spatially-aware refinement. This design enables more effective cross-latent com-munication, preserving both global coherence and local texture fidelity. Our GitHub page: https://anonymous.4open.science/r/MVA2025-22 .",
      "authors": [
        "Zhen-Qi Chen",
        "Yuan-Fu Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:22:43+00:00",
          "link": "https://arxiv.org/abs/2507.13388v1",
          "size": "645kb",
          "version": "v1"
        }
      ],
      "title": "DLSF: Dual-Layer Synergistic Fusion for High-Fidelity Image Syn-thesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13388",
        "PDF": "https://arxiv.org/pdf/2507.13388"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses feature aggregation in diffusion-based generative models, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13390",
      "abstract": "Large Language Models (LLMs) have emerged as powerful general-purpose reasoning systems, yet their development remains dominated by English-centric data, architectures, and optimization paradigms. This exclusionary design results in structural under-representation of linguistically diverse regions such as India, where over 20 official languages and 100+ dialects coexist alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a 2.9B parameter decoder-only, text-only language model trained from scratch with an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is trained on a bilingual dataset consisting of only Hindi and English, constructed with a strong focus on fact-rich, high-quality content. It is guided by three core principles: equitable representation of Indic languages through a 25% corpus allocation; tokenization fairness via a SentencePiece tokenizer adapted to Indian morphological structures; and culturally aligned evaluation benchmarks across IndicQA, code-mixed reasoning, and socio-linguistic robustness tasks. By embedding diversity at the pretraining level-rather than deferring it to post-hoc alignment-PARAM-1 offers a design-first blueprint for equitable foundation modeling. Our results demonstrate that it serves as both a competent general-purpose model and a robust baseline for India-centric applications.",
      "authors": [
        "Kundeshwar Pundalik",
        "Piyush Sawarkar",
        "Nihar Sahoo",
        "Abhishek Shinde",
        "Prateek Chanda",
        "Vedant Goswami",
        "Ajay Nagpal",
        "Atul Singh",
        "Viraj Thakur",
        "Vijay Dewane",
        "Aamod Thakur",
        "Bhargav Patel",
        "Smita Gautam",
        "Bhagwan Panditi",
        "Shyam Pawar",
        "Madhav Kotcha",
        "Suraj Racha",
        "Saral Sureka",
        "Pankaj Singh",
        "Rishi Bal",
        "Rohit Saluja",
        "Ganesh Ramakrishnan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:14:33+00:00",
          "link": "https://arxiv.org/abs/2507.13390v1",
          "size": "3439kb",
          "version": "v1"
        }
      ],
      "title": "PARAM-1 BharatGen 2.9B Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13390",
        "PDF": "https://arxiv.org/pdf/2507.13390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces PARAM-1, an LLM trained on a specially constructed bilingual dataset focusing on Hindi and English. The dataset construction involves data collection and linguistic balance, making it directly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13392",
      "abstract": "We improve the extraction of insights from customer reviews by restructuring the topic modelling pipeline to operate on opinion units - distinct statements that include relevant text excerpts and associated sentiment scores. Prior work has demonstrated that such units can be reliably extracted using large language models. The result is a heightened performance of the subsequent topic modeling, leading to coherent and interpretable topics while also capturing the sentiment associated with each topic. By correlating the topics and sentiments with business metrics, such as star ratings, we can gain insights on how specific customer concerns impact business outcomes. We present our system's implementation, use cases, and advantages over other topic modeling and classification solutions. We also evaluate its effectiveness in creating coherent topics and assess methods for integrating topic and sentiment modalities for accurate star-rating prediction.",
      "authors": [
        "Emil H\\\"aglund and Johanna Bj\\\"orklund"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:19:26+00:00",
          "link": "https://arxiv.org/abs/2507.13392v1",
          "size": "719kb",
          "version": "v1"
        }
      ],
      "title": "TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13392",
        "HTML": "https://arxiv.org/html/2507.13392v1",
        "PDF": "https://arxiv.org/pdf/2507.13392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses restructuring topic modeling pipelines using opinion units extracted by LLMs, but its main focus is on feedback analysis and sentiment prediction, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13393",
      "abstract": "Data normalization is crucial in machine learning, usually performed by subtracting the mean and dividing by standard deviation, or by rescaling to a fixed range. In copula theory, popular in finance, there is used normalization to approximately quantiles by transforming x to CDF(x) with estimated CDF (cumulative distribution function) to nearly uniform distribution in [0,1], allowing for simpler representations which are less likely to overfit. It seems nearly unknown in machine learning, therefore, we would like to present some its advantages on example of recently popular Kolmogorov-Arnold Networks (KANs), improving predictions from Legendre-KAN by just switching rescaling to CDF normalization. Additionally, in HCR interpretation, weights of such neurons are mixed moments providing local joint distribution models, allow to propagate also probability distributions, and change propagation direction.",
      "authors": [
        "Jakub Strawa",
        "Jarek Duda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:24:11+00:00",
          "link": "https://arxiv.org/abs/2507.13393v1",
          "size": "4393kb",
          "version": "v1"
        }
      ],
      "title": "Improving KAN with CDF normalization to quantiles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13393",
        "HTML": "https://arxiv.org/html/2507.13393v1",
        "PDF": "https://arxiv.org/pdf/2507.13393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses data normalization techniques within machine learning and copula theory applications, lacking any focus on LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13395",
      "abstract": "The advent of neural machine translation (NMT) has revolutionized cross-lingual communication, yet preserving stylistic nuances remains a significant challenge. While existing approaches often require parallel corpora for style preservation, we introduce Babel, a novel framework that enhances stylistic fidelity in NMT using only monolingual corpora. Babel employs two key components: (1) a style detector based on contextual embeddings that identifies stylistic disparities between source and target texts, and (2) a diffusion-based style applicator that rectifies stylistic inconsistencies while maintaining semantic integrity. Our framework integrates with existing NMT systems as a post-processing module, enabling style-aware translation without requiring architectural modifications or parallel stylistic data. Extensive experiments on five diverse domains (law, literature, scientific writing, medicine, and educational content) demonstrate Babel's effectiveness: it identifies stylistic inconsistencies with 88.21% precision and improves stylistic preservation by 150% while maintaining a high semantic similarity score of 0.92. Human evaluation confirms that translations refined by Babel better preserve source text style while maintaining fluency and adequacy.",
      "authors": [
        "Xuanqi Gao",
        "Weipeng Jiang",
        "Juan Zhai",
        "Shiqing Ma",
        "Siyi Xie",
        "Xinyang Yin",
        "Chao Shen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:45:11+00:00",
          "link": "https://arxiv.org/abs/2507.13395v1",
          "size": "277kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13395",
        "HTML": "https://arxiv.org/html/2507.13395v1",
        "PDF": "https://arxiv.org/pdf/2507.13395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving neural machine translation systems using monolingual corpora for stylistic fidelity. It does not address LLM training data processing as its focus is on translation rather than data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13396",
      "abstract": "Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for grounding large language models with external structured knowledge. However, existing Graph RAG methods struggle with temporal reasoning, due to their inability to model the evolving structure and order of real-world events. In this work, we introduce DyG-RAG, a novel event-centric dynamic graph retrieval-augmented generation framework designed to capture and reason over temporal knowledge embedded in unstructured text. To eliminate temporal ambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units (DEUs) that explicitly encode both semantic content and precise temporal anchors, enabling accurate and interpretable time-aware retrieval. To capture temporal and causal dependencies across events, DyG-RAG constructs an event graph by linking DEUs that share entities and occur close in time, supporting efficient and meaningful multi-hop reasoning. To ensure temporally consistent generation, DyG-RAG introduces an event timeline retrieval pipeline that retrieves event sequences via time-aware traversal, and proposes a Time Chain-of-Thought strategy for temporally grounded answer generation. This unified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event sequences and to answer complex, time-sensitive queries that standard RAG systems cannot resolve. Extensive experiments on temporal QA benchmarks demonstrate that DyG-RAG significantly improves the accuracy and recall of three typical types of temporal reasoning questions, paving the way for more faithful and temporal-aware generation. DyG-RAG is available at https://github.com/RingBDStack/DyG-RAG.",
      "authors": [
        "Qingyun Sun",
        "Jiaqi Yuan",
        "Shan He",
        "Xiao Guan",
        "Haonan Yuan",
        "Xingcheng Fu",
        "Jianxin Li",
        "Philip S. Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:22:35+00:00",
          "link": "https://arxiv.org/abs/2507.13396v1",
          "size": "3944kb",
          "version": "v1"
        }
      ],
      "title": "DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13396",
        "HTML": "https://arxiv.org/html/2507.13396v1",
        "PDF": "https://arxiv.org/pdf/2507.13396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for improving temporal reasoning in language models using dynamic graph retrieval methods. It is focused on reasoning and augmentation techniques, not on training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13397",
      "abstract": "Accurate pedestrian trajectory prediction is crucial for intelligent applications, yet it remains highly challenging due to the complexity of interactions among pedestrians. Previous methods have primarily relied on relative positions to model pedestrian interactions; however, they tend to overlook specific interaction patterns such as paired walking or conflicting behaviors, limiting the prediction accuracy in crowded scenarios. To address this issue, we propose InSyn (Interaction-Synchronization Network), a novel Transformer-based model that explicitly captures diverse interaction patterns (e.g., walking in sync or conflicting) while effectively modeling direction-sensitive social behaviors. Additionally, we introduce a training strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue of initial-step divergence in numerical time-series prediction. Experiments on the ETH and UCY datasets demonstrate that our model outperforms recent baselines significantly, especially in high-density scenarios. Furthermore, the SSOS strategy proves effective in improving sequential prediction performance, reducing the initial-step prediction error by approximately 6.58%.",
      "authors": [
        "Kaiyuan Zhai",
        "Juan Chen",
        "Chao Wang",
        "Zeyi Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:23:04+00:00",
          "link": "https://arxiv.org/abs/2507.13397v1",
          "size": "10325kb",
          "version": "v1"
        }
      ],
      "title": "InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13397",
        "HTML": "https://arxiv.org/html/2507.13397v1",
        "PDF": "https://arxiv.org/pdf/2507.13397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with predictive modeling of pedestrian trajectories using a Transformer-based model. It does not address data processing for LLM training, focusing instead on trajectory prediction in crowd scenarios."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13398",
      "abstract": "Conspiracy theories have long drawn public attention, but their explosive growth on platforms like Telegram during the COVID-19 pandemic raises pressing questions about their impact on societal trust, democracy, and public health. We provide a geographical, temporal and network analysis of the structure of of conspiracy-related German-language Telegram chats in a novel large-scale data set. We examine how information flows between regional user groups and influential broadcasting channels, revealing the interplay between decentralized discussions and content spread driven by a small number of key actors.\n  Our findings reveal that conspiracy-related activity spikes during major COVID-19-related events, correlating with societal stressors and mirroring prior research on how crises amplify conspiratorial beliefs. By analysing the interplay between regional, national and transnational chats, we uncover how information flows from larger national or transnational discourse to localised, community-driven discussions. Furthermore, we find that the top 10% of chats account for 94% of all forwarded content, portraying the large influence of a few actors in disseminating information. However, these chats operate independently, with minimal interconnection between each other, primarily forwarding messages to low-traffic groups. Notably, 43% of links shared in the data set point to untrustworthy sources as identified by NewsGuard, a proportion far exceeding their share on other platforms and in other discourse contexts, underscoring the role of conspiracy-related discussions on Telegram as vector for the spread of misinformation.",
      "authors": [
        "Elisabeth H\\\"oldrich",
        "Mathias Angermaier",
        "Jana Lasser",
        "Joao Pinheiro-Neto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:45:57+00:00",
          "link": "https://arxiv.org/abs/2507.13398v1",
          "size": "1013kb",
          "version": "v1"
        }
      ],
      "title": "Characterizing the Dynamics of Conspiracy Related German Telegram Conversations during COVID-19",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13398",
        "HTML": "https://arxiv.org/html/2507.13398v1",
        "PDF": "https://arxiv.org/pdf/2507.13398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes conspiracy-related chat dynamics on Telegram, surveying geographic, temporal, and network factors. It does not contribute to LLM training data processing, focusing on social network analysis instead."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13399",
      "abstract": "Deep learning has revolutionized many industries by enabling models to automatically learn complex patterns from raw data, reducing dependence on manual feature engineering. However, deep learning algorithms are sensitive to input data, and performance often deteriorates under nonstationary conditions and across dissimilar domains, especially when using time-domain data. Conventional single-channel or parallel multi-source data loading strategies either limit generalization or increase computational costs. This study introduces selective embedding, a novel data loading strategy, which alternates short segments of data from multiple sources within a single input channel. Drawing inspiration from cognitive psychology, selective embedding mimics human-like information processing to reduce model overfitting, enhance generalization, and improve computational efficiency. Validation is conducted using six time-domain datasets, demonstrating that the proposed method consistently achieves high classification accuracy across various deep learning architectures while significantly reducing training times. The approach proves particularly effective for complex systems with multiple data sources, offering a scalable and resource-efficient solution for real-world applications in healthcare, heavy machinery, marine, railway, and agriculture, where robustness and adaptability are critical.",
      "authors": [
        "Mert Sehri",
        "Zehui Hua",
        "Francisco de Assis Boldt",
        "Patrick Dumond"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:45:01+00:00",
          "link": "https://arxiv.org/abs/2507.13399v1",
          "size": "5737kb",
          "version": "v1"
        }
      ],
      "title": "Selective Embedding for Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13399",
        "PDF": "https://arxiv.org/pdf/2507.13399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a selective embedding strategy for deep learning, which could potentially impact data handling in model training. However, its main focus is on reducing overfitting and improving generalization across domains, not specifically on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13401",
      "abstract": "Despite the remarkable success of diffusion models in text-to-image generation, their effectiveness in grounded visual editing and compositional control remains challenging. Motivated by advances in self-supervised learning and in-context generative modeling, we propose a series of simple yet powerful design choices that significantly enhance diffusion model capacity for structured, controllable generation and editing. We introduce Masking-Augmented Diffusion with Inference-Time Scaling (MADI), a framework that improves the editability, compositionality and controllability of diffusion models through two core innovations. First, we introduce Masking-Augmented gaussian Diffusion (MAgD), a novel training strategy with dual corruption process which combines standard denoising score matching and masked reconstruction by masking noisy input from forward process. MAgD encourages the model to learn discriminative and compositional visual representations, thus enabling localized and structure-aware editing. Second, we introduce an inference-time capacity scaling mechanism based on Pause Tokens, which act as special placeholders inserted into the prompt for increasing computational capacity at inference time. Our findings show that adopting expressive and dense prompts during training further enhances performance, particularly for MAgD. Together, these contributions in MADI substantially enhance the editability of diffusion models, paving the way toward their integration into more general-purpose, in-context generative diffusion architectures.",
      "authors": [
        "Shreya Kadambi",
        "Risheek Garrepalli",
        "Shubhankar Borse",
        "Munawar Hyatt",
        "Fatih Porikli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:56:57+00:00",
          "link": "https://arxiv.org/abs/2507.13401v1",
          "size": "24824kb",
          "version": "v1"
        }
      ],
      "title": "MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13401",
        "HTML": "https://arxiv.org/html/2507.13401v1",
        "PDF": "https://arxiv.org/pdf/2507.13401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the editability and compositional control of diffusion models for visual editing, which does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13403",
      "abstract": "In this study, we present a comprehensive public dataset for driver drowsiness detection, integrating multimodal signals of facial, behavioral, and biometric indicators. Our dataset includes 3D facial video using a depth camera, IR camera footage, posterior videos, and biometric signals such as heart rate, electrodermal activity, blood oxygen saturation, skin temperature, and accelerometer data. This data set provides grip sensor data from the steering wheel and telemetry data from the American truck simulator game to provide more information about drivers' behavior while they are alert and drowsy. Drowsiness levels were self-reported every four minutes using the Karolinska Sleepiness Scale (KSS). The simulation environment consists of three monitor setups, and the driving condition is completely like a car. Data were collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully alert and when they exhibited signs of sleepiness. Unlike other datasets, our multimodal dataset has a continuous duration of 40 minutes for each data collection session per subject, contributing to a total length of 1,400 minutes, and we recorded gradual changes in the driver state rather than discrete alert/drowsy labels. This study aims to create a comprehensive multimodal dataset of driver drowsiness that captures a wider range of physiological, behavioral, and driving-related signals. The dataset will be available upon request to the corresponding author.",
      "authors": [
        "Morteza Bodaghi",
        "Majid Hosseini",
        "Raju Gottumukkala",
        "Ravi Teja Bhupatiraju",
        "Iftikhar Ahmad",
        "Moncef Gabbouj"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.13403v1",
          "size": "5479kb",
          "version": "v1"
        }
      ],
      "title": "UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13403",
        "HTML": "https://arxiv.org/html/2507.13403v1",
        "PDF": "https://arxiv.org/pdf/2507.13403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a dataset for driver drowsiness detection using multimodal signals but does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13404",
      "abstract": "Accurate 3D aortic construction is crucial for clinical diagnosis, preoperative planning, and computational fluid dynamics (CFD) simulations, as it enables the estimation of critical hemodynamic parameters such as blood flow velocity, pressure distribution, and wall shear stress. Existing construction methods often rely on large annotated training datasets and extensive manual intervention. While the resulting meshes can serve for visualization purposes, they struggle to produce geometrically consistent, well-constructed surfaces suitable for downstream CFD analysis. To address these challenges, we introduce AortaDiff, a diffusion-based framework that generates smooth aortic surfaces directly from CT/MRI volumes. AortaDiff first employs a volume-guided conditional diffusion model (CDM) to iteratively generate aortic centerlines conditioned on volumetric medical images. Each centerline point is then automatically used as a prompt to extract the corresponding vessel contour, ensuring accurate boundary delineation. Finally, the extracted contours are fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh representation. AortaDiff offers distinct advantages over existing methods, including an end-to-end workflow, minimal dependency on large labeled datasets, and the ability to generate CFD-compatible aorta meshes with high geometric fidelity. Experimental results demonstrate that AortaDiff performs effectively even with limited training data, successfully constructing both normal and pathologically altered aorta meshes, including cases with aneurysms or coarctation. This capability enables the generation of high-quality visualizations and positions AortaDiff as a practical solution for cardiovascular research.",
      "authors": [
        "Delin An",
        "Pan Du",
        "Jian-Xun Wang",
        "Chaoli Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:36:51+00:00",
          "link": "https://arxiv.org/abs/2507.13404v1",
          "size": "26227kb",
          "version": "v1"
        }
      ],
      "title": "AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13404",
        "HTML": "https://arxiv.org/html/2507.13404v1",
        "PDF": "https://arxiv.org/pdf/2507.13404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents AortaDiff, a framework for generating 3D aortic surfaces from medical images. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13405",
      "abstract": "Recently, many benchmarks and datasets have been developed to evaluate Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and models have shown significant accuracy improvements. However, these benchmarks rarely test the model's ability to accurately complete visual entailment, for instance, accepting or refuting a hypothesis based on the image. To address this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a benchmark of 5608 image and synthetically generated true/false statement pairs, with images derived from the CrowdHuman dataset, to provoke visual entailment reasoning on challenging crowded images. Our results show that even the top-performing VLMs achieve accuracy below 80%, with other models performing substantially worse (39.98%-69.95%). This significant performance gap reveals key limitations in VLMs' ability to reason over certain types of image-question pairs in crowded scenes.",
      "authors": [
        "Ishant Chintapatla",
        "Kazuma Choji",
        "Naaisha Agarwal",
        "Andrew Lin",
        "Hannah You",
        "Charles Duong",
        "Kevin Zhu",
        "Sean O'Brien",
        "Vasu Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.13405v1",
          "size": "19629kb",
          "version": "v1"
        }
      ],
      "title": "COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13405",
        "HTML": "https://arxiv.org/html/2507.13405v1",
        "PDF": "https://arxiv.org/pdf/2507.13405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a benchmark (COREVQA) for evaluating visual entailment in Vision-Language Models. While relevant to data evaluation for models, it does not focus on the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13407",
      "abstract": "With the rapid rise of generative AI and synthetic media, distinguishing AI-generated images from real ones has become crucial in safeguarding against misinformation and ensuring digital authenticity. Traditional watermarking techniques have shown vulnerabilities to adversarial attacks, undermining their effectiveness in the presence of attackers. We propose IConMark, a novel in-generation robust semantic watermarking method that embeds interpretable concepts into AI-generated images, as a first step toward interpretable watermarking. Unlike traditional methods, which rely on adding noise or perturbations to AI-generated images, IConMark incorporates meaningful semantic attributes, making it interpretable to humans and hence, resilient to adversarial manipulation. This method is not only robust against various image augmentations but also human-readable, enabling manual verification of watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness, demonstrating its superiority in terms of detection accuracy and maintaining image quality. Moreover, IConMark can be combined with existing watermarking techniques to further enhance and complement its robustness. We introduce IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with StegaStamp and TrustMark, respectively, to further bolster robustness against multiple types of image manipulations. Our base watermarking technique (IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9% higher mean area under the receiver operating characteristic curve (AUROC) scores for watermark detection, respectively, compared to the best baseline on various datasets.",
      "authors": [
        "Vinu Sankar Sadasivan",
        "Mehrdad Saberi",
        "Soheil Feizi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:38:30+00:00",
          "link": "https://arxiv.org/abs/2507.13407v1",
          "size": "13123kb",
          "version": "v1"
        }
      ],
      "title": "IConMark: Robust Interpretable Concept-Based Watermark For AI Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13407",
        "PDF": "https://arxiv.org/pdf/2507.13407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with a watermarking method for AI-generated images and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13408",
      "abstract": "Background: Shoulder fractures are often underdiagnosed, especially in emergency and high-volume clinical settings. Studies report up to 10% of such fractures may be missed by radiologists. AI-driven tools offer a scalable way to assist early detection and reduce diagnostic delays. We address this gap through a dedicated AI system for shoulder radiographs. Methods: We developed a multi-model deep learning system using 10,000 annotated shoulder X-rays. Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and RF-DETR. To enhance detection, we applied bounding box and classification-level ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming individual models across all key metrics. It demonstrated strong recall and localization precision, confirming its effectiveness for clinical fracture detection in shoulder X-rays. Conclusion: The results show ensemble-based AI can reliably detect shoulder fractures in radiographs with high clinical relevance. The model's accuracy and deployment readiness position it well for integration into real-time diagnostic workflows. The current model is limited to binary fracture detection, reflecting its design for rapid screening and triage support rather than detailed orthopedic classification.",
      "authors": [
        "Hemanth Kumar M",
        "Karthika M",
        "Saianiruth M",
        "Vasanthakumar Venugopal",
        "Anandakumar D",
        "Revathi Ezhumalai",
        "Charulatha K",
        "Kishore Kumar J",
        "Dayana G",
        "Kalyan Sivasailam",
        "Bargava Subramanian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:06:12+00:00",
          "link": "https://arxiv.org/abs/2507.13408v1",
          "size": "578kb",
          "version": "v1"
        }
      ],
      "title": "A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13408",
        "HTML": "https://arxiv.org/html/2507.13408v1",
        "PDF": "https://arxiv.org/pdf/2507.13408"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep learning system for fracture detection in radiographs and does not involve any LLM training data processing operations such as data collection, deduplication, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13410",
      "abstract": "Deterministically controlling the target generation language of large multilingual language models (LLMs) remains a fundamental challenge, particularly in zero-shot settings where neither explicit language prompts nor fine-tuning are available. In this work, we investigate whether sparse autoencoder (SAE) features, previously shown to correlate with interpretable model behaviors, can be leveraged to steer the generated language of LLMs during inference. Leveraging pretrained SAEs on the residual streams of Gemma-2B and Gemma-9B, we identify features whose activations differ most significantly between English and four target languages: Chinese, Japanese, Spanish, and French. By modifying just a single SAE feature at one transformer layer, we achieve controlled language shifts with up to 90\\% success, as measured by FastText language classification, while preserving semantic fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding) similarity. Our analysis reveals that language steering is most effective in mid-to-late transformer layers and is amplified by specific attention heads disproportionately associated with language-sensitive SAE features. These results demonstrate the promise of sparse feature steering as a lightweight and interpretable mechanism for controllable multilingual generation.",
      "authors": [
        "Cheng-Ting Chou",
        "George Liu",
        "Jessica Sun",
        "Cole Blondin",
        "Kevin Zhu",
        "Vasu Sharma",
        "Sean O'Brien"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:49:16+00:00",
          "link": "https://arxiv.org/abs/2507.13410v1",
          "size": "1943kb",
          "version": "v1"
        }
      ],
      "title": "Causal Language Control in Multilingual Transformers via Sparse Feature Steering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13410",
        "HTML": "https://arxiv.org/html/2507.13410v1",
        "PDF": "https://arxiv.org/pdf/2507.13410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a novel technique called sparse feature steering to control language generation in multilingual LLMs. While it touches on inference data manipulation, it is more focused on model inference control rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13411",
      "abstract": "Large language models like GPT-4, Gemini, and Claude have transformed natural language processing (NLP) tasks such as question answering, dialogue generation, summarization, and so forth; yet their susceptibility to hallucination stands as one of the major challenges. Among numerous approaches to overcome this challenge, integration of Knowledge Graphs (KGs) into language models has emerged as a promising solution as it provides structured, reliable, domain-specific, and up-to-date external information to the language models. In this paper, we introduce ALIGNed-LLM, a simple yet effective approach to improve language models' factuality via a lean strategy to infuse KGs into the latent space of language models inspired by LLaVA where visual and textual information is infused. We use embeddings from a pre-trained Knowledge Graph Embedding (KGE) model, such as TransE, and a trainable projection layer to align entity and text embeddings. This alignment enables the language model to distinguish between similar entities improving factual grounding and reducing hallucination. We tested our approach on three popular questions-answering benchmark datasets alongside language models of varying sizes, showing significant improvement. Furthermore, we applied our approach to a real-world financial use case from a large central bank in Europe, which demands high accuracy and precision, demonstrating a substantial improvement of the LLM answers.",
      "authors": [
        "Nur A Zarin Nishat",
        "Andrea Coletta",
        "Luigi Bellomarini",
        "Kossi Amouzouvi",
        "Jens Lehmann",
        "Sahar Vahdati"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:15:50+00:00",
          "link": "https://arxiv.org/abs/2507.13411v1",
          "size": "5303kb",
          "version": "v1"
        }
      ],
      "title": "Aligning Knowledge Graphs and Language Models for Factual Accuracy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13411",
        "HTML": "https://arxiv.org/html/2507.13411v1",
        "PDF": "https://arxiv.org/pdf/2507.13411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This work involves aligning Knowledge Graphs with LLMs to improve factual accuracy, touching on data fusion methods. However, its primary focus is on improving LLM output accuracy rather than contributing directly to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13413",
      "abstract": "AutoML has advanced in handling complex tasks using the integration of LLMs, yet its efficiency remains limited by dependence on specific underlying tools. In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for tasks with tabular data, which combines an LLM-based code generation with several AutoML tools. Our approach improves the flexibility and robustness of pipeline design, outperforming state-of-the-art open-source solutions on several data science tasks from Kaggle. The code of LightAutoDS-Tab is available in the open repository https://github.com/sb-ai-lab/LADS",
      "authors": [
        "Aleksey Lapin",
        "Igor Hromov",
        "Stanislav Chumakov",
        "Mile Mitrovic",
        "Dmitry Simakov",
        "Nikolay O. Nikitin",
        "Andrey V. Savchenko"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:33:24+00:00",
          "link": "https://arxiv.org/abs/2507.13413v1",
          "size": "712kb",
          "version": "v1"
        }
      ],
      "title": "LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13413",
        "HTML": "https://arxiv.org/html/2507.13413v1",
        "PDF": "https://arxiv.org/pdf/2507.13413"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an AutoML system for tabular data, emphasizing LLM-based code generation and AutoML tool integration rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13414",
      "abstract": "This paper introduces Gauge Flow Models, a novel class of Generative Flow Models. These models incorporate a learnable Gauge Field within the Flow Ordinary Differential Equation (ODE). A comprehensive mathematical framework for these models, detailing their construction and properties, is provided. Experiments using Flow Matching on Gaussian Mixture Models demonstrate that Gauge Flow Models yields significantly better performance than traditional Flow Models of comparable or even larger size. Additionally, unpublished research indicates a potential for enhanced performance across a broader range of generative tasks.",
      "authors": [
        "Alexander Strunk",
        "Roland Assam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Differential Geometry (math.DG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.13414v1",
          "size": "147kb",
          "version": "v1"
        }
      ],
      "title": "Gauge Flow Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13414",
        "HTML": "https://arxiv.org/html/2507.13414v1",
        "PDF": "https://arxiv.org/pdf/2507.13414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Gauge Flow Models within generative models, focusing on model architecture improvements and not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13415",
      "abstract": "Previous studies on multimodal fake news detection mainly focus on the alignment and integration of cross-modal features, as well as the application of text-image consistency. However, they overlook the semantic enhancement effects of large multimodal models and pay little attention to the emotional features of news. In addition, people find that fake news is more inclined to contain negative emotions than real ones. Therefore, we propose a novel Semantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake news detection. We generate summarized captions for image semantic understanding and utilize the products of large multimodal models for semantic enhancement. Inspired by the perceived relationship between news authenticity and emotional tendencies, we propose an expert emotional reasoning module that simulates real-life scenarios to optimize emotional features and infer the authenticity of news. Extensive experiments on two real-world datasets demonstrate the superiority of our SEER over state-of-the-art baselines.",
      "authors": [
        "Peican Zhu",
        "Yubo Jing",
        "Le Cheng",
        "Bin Chen",
        "Xiaodong Cui",
        "Lianwei Wu",
        "Keke Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:33:45+00:00",
          "link": "https://arxiv.org/abs/2507.13415v1",
          "size": "911kb",
          "version": "v1"
        }
      ],
      "title": "SEER: Semantic Enhancement and Emotional Reasoning Network for Multimodal Fake News Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13415",
        "HTML": "https://arxiv.org/html/2507.13415v1",
        "PDF": "https://arxiv.org/pdf/2507.13415"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal fake news detection using semantic enhancement and emotional reasoning, which are unrelated to LLM training data processing. It does not involve dataset creation, data engineering operations, or improvements in training data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13416",
      "abstract": "Data-driven learning is generalized to consider history-dependent multi-fidelity data, while quantifying epistemic uncertainty and disentangling it from data noise (aleatoric uncertainty). This generalization is hierarchical and adapts to different learning scenarios: from training the simplest single-fidelity deterministic neural networks up to the proposed multi-fidelity variance estimation Bayesian recurrent neural networks. The versatility and generality of the proposed methodology are demonstrated by applying it to different data-driven constitutive modeling scenarios that include multiple fidelities with and without aleatoric uncertainty (noise). The method accurately predicts the response and quantifies model error while also discovering the noise distribution (when present). This opens opportunities for future real-world applications in diverse scientific and engineering domains; especially, the most challenging cases involving design and analysis under uncertainty.",
      "authors": [
        "Jiaxiang Yi",
        "Bernardo P. Ferreira",
        "Miguel A. Bessa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:45:10+00:00",
          "link": "https://arxiv.org/abs/2507.13416v1",
          "size": "3114kb",
          "version": "v1"
        }
      ],
      "title": "Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13416",
        "HTML": "https://arxiv.org/html/2507.13416v1",
        "PDF": "https://arxiv.org/pdf/2507.13416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses data-driven learning for history-dependent multi-fidelity data with uncertainty quantification and disentanglement, but it does not contribute to LLM training data processing or involve any relevant data processing operations or dataset creation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13417",
      "abstract": "Clustering based on belief functions has been gaining increasing attention in the machine learning community due to its ability to effectively represent uncertainty and/or imprecision. However, none of the existing algorithms can be applied to complex data, such as mixed data (numerical and categorical) or non-tabular data like time series. Indeed, these types of data are, in general, not represented in a Euclidean space and the aforementioned algorithms make use of the properties of such spaces, in particular for the construction of barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem for clustering complex data. We propose a new algorithm, Soft-ECM, which consistently positions the centroids of imprecise clusters requiring only a semi-metric. Our experiments show that Soft-ECM present results comparable to conventional fuzzy clustering approaches on numerical data, and we demonstrate its ability to handle mixed data and its benefits when combining fuzzy clustering with semi-metrics such as DTW for time series data.",
      "authors": [
        "Armel Soubeiga (LIMOS)",
        "Thomas Guyet (AISTROSIGHT)",
        "Violaine Antoine (LIMOS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:00:22+00:00",
          "link": "https://arxiv.org/abs/2507.13417v1",
          "size": "1479kb",
          "version": "v1"
        }
      ],
      "title": "Soft-ECM: An extension of Evidential C-Means for complex data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13417",
        "PDF": "https://arxiv.org/pdf/2507.13417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on clustering complex data using belief functions, not on LLM training data processing. It does not deal with pretraining, fine-tuning, or any data engineering operations pertinent to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13419",
      "abstract": "The research topic of digital twins has attracted a large amount of interest over the past decade. However, publicly available exemplars remain scarce. In the interest of open and reproducible science, in this exemplar paper we present a lab-scale gantry crane and its digital twin. The exemplar comprises both the physical and digital side of the twin system. The physical side consists of the physical crane and its controller. The digital side covers the CAD models and kinematic model of the crane, and provides services for optimal control, historical data logging, data visualization and continuous validation. We used this setup as use case in several previous publications where its functionality was validated. It is publicly available and only relies on other freely available and commonly used software, this way we hope it can be used for future research or education on the topic of digital twins.",
      "authors": [
        "Joost Mertens",
        "Joachim Denil"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.13419v1",
          "size": "731kb",
          "version": "v1"
        }
      ],
      "title": "Lab-Scale Gantry Crane Digital Twin Exemplar",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13419",
        "HTML": "https://arxiv.org/html/2507.13419v1",
        "PDF": "https://arxiv.org/pdf/2507.13419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a digital twin for a gantry crane, emphasizing its physical and digital components and its applicability to digital twin research. It does not have any relevance to LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13420",
      "abstract": "By upgrading an existing deep learning model with the knowledge provided by one of the oldest sets of grayscale satellite imagery, known as CORONA, we improved the AI model attitude towards the automatic identification of archaeological sites in an environment which has been completely transformed in the last five decades, including the complete destruction of many of those same sites. The initial Bing based convolutional network model was retrained using CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad, central Mesopotamian floodplain. The results were twofold and surprising. First, the detection precision obtained on the area of interest increased sensibly: in particular, the Intersection over Union (IoU) values, at the image segmentation level, surpassed 85 percent, while the general accuracy in detecting archeological sites reached 90 percent. Second, our retrained model allowed the identification of four new sites of archaeological interest (confirmed through field verification), previously not identified by archaeologists with traditional techniques. This has confirmed the efficacy of using AI techniques and the CORONA imagery from the 1960 to discover archaeological sites currently no longer visible, a concrete breakthrough with significant consequences for the study of landscapes with vanishing archaeological evidence induced by anthropization",
      "authors": [
        "Alessandro Pistola",
        "Valentina Orru'",
        "Nicolo' Marchetti",
        "Marco Roccetti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:21:50+00:00",
          "link": "https://arxiv.org/abs/2507.13420v1",
          "size": "10085kb",
          "version": "v1"
        }
      ],
      "title": "AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13420",
        "PDF": "https://arxiv.org/pdf/2507.13420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study enhances an AI model for detecting archaeological sites using historical satellite imagery, focusing on improving detection accuracy. It is unrelated to LLM training data processing, dataset development, or data operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13423",
      "abstract": "Real-time assessment of near-term Air Traffic Controller (ATCO) task demand is a critical challenge in an increasingly crowded airspace, as existing complexity metrics often fail to capture nuanced operational drivers beyond simple aircraft counts. This work introduces an interpretable Graph Neural Network (GNN) framework to address this gap. Our attention-based model predicts the number of upcoming clearances, the instructions issued to aircraft by ATCOs, from interactions within static traffic scenarios. Crucially, we derive an interpretable, per-aircraft task demand score by systematically ablating aircraft and measuring the impact on the model's predictions. Our framework significantly outperforms an ATCO-inspired heuristic and is a more reliable estimator of scenario complexity than established baselines. The resulting tool can attribute task demand to specific aircraft, offering a new way to analyse and understand the drivers of complexity for applications in controller training and airspace redesign.",
      "authors": [
        "Edward Henderson",
        "Dewi Gould",
        "Richard Everson",
        "George De Ath",
        "Nick Pepper"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:02:42+00:00",
          "link": "https://arxiv.org/abs/2507.13423v1",
          "size": "238kb",
          "version": "v1"
        }
      ],
      "title": "Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13423",
        "HTML": "https://arxiv.org/html/2507.13423v1",
        "PDF": "https://arxiv.org/pdf/2507.13423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with real-time assessment of air traffic controller task demand using graph neural networks. It does not address LLM training data processing or involve datasets relevant to language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13425",
      "abstract": "Accurate prediction of driving intention is key to enhancing the safety and interactive efficiency of human-machine co-driving systems. It serves as a cornerstone for achieving high-level autonomous driving. However, current approaches remain inadequate for accurately modeling the complex spatio-temporal interdependencies and the unpredictable variability of human driving behavior. To address these challenges, we propose CaSTFormer, a Causal Spatio-Temporal Transformer to explicitly model causal interactions between driver behavior and environmental context for robust intention prediction. Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF) mechanism for precise temporal alignment of internal and external feature streams, a Causal Pattern Extraction (CPE) module that systematically eliminates spurious correlations to reveal authentic causal dependencies, and an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these purified representations into coherent spatio-temporal inferences. We evaluate the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves state-of-the-art performance. It effectively captures complex causal spatio-temporal dependencies and enhances both the accuracy and transparency of driving intention prediction.",
      "authors": [
        "Sirui Wang",
        "Zhou Guan",
        "Bingxi Zhao",
        "Tongjia Gu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:10:37+00:00",
          "link": "https://arxiv.org/abs/2507.13425v1",
          "size": "6483kb",
          "version": "v1"
        }
      ],
      "title": "CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13425",
        "HTML": "https://arxiv.org/html/2507.13425v1",
        "PDF": "https://arxiv.org/pdf/2507.13425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces CaSTFormer for predicting driving intentions. Although it involves data modeling, it focuses on driving systems, not on LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13428",
      "abstract": "Video generation models have achieved remarkable progress in creating high-quality, photorealistic content. However, their ability to accurately simulate physical phenomena remains a critical and unresolved challenge. This paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate video generation models based on their adherence to the laws of physics. The benchmark covers multiple levels of physical phenomena, ranging from fundamental principles like object motion and energy conservation to more complex scenarios involving rigid body interactions and human or animal motion. Additionally, we introduce a novel \"\"Anti-Physics\"\" category, where prompts intentionally violate real-world physics, enabling the assessment of whether models can follow such instructions while maintaining logical consistency. Besides large-scale human evaluation, we also design a simple yet effective method that could utilize current MLLM to evaluate the physics realism in a zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation models, including five open-source and five proprietary models, with a detailed comparison and analysis. we identify pivotal challenges models face in adhering to real-world physics. Through systematic testing of their outputs across 1,050 curated prompts-spanning fundamental, composite, and anti-physics scenarios-we identify pivotal challenges these models face in adhering to real-world physics. We then rigorously examine their performance on diverse physical phenomena with varying prompt types, deriving targeted recommendations for crafting prompts that enhance fidelity to physical principles.",
      "authors": [
        "Jing Gu",
        "Xian Liu",
        "Yu Zeng",
        "Ashwin Nagarajan",
        "Fangrui Zhu",
        "Daniel Hong",
        "Yue Fan",
        "Qianqi Yan",
        "Kaiwen Zhou",
        "Ming-Yu Liu",
        "Xin Eric Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:54:09+00:00",
          "link": "https://arxiv.org/abs/2507.13428v1",
          "size": "44772kb",
          "version": "v1"
        }
      ],
      "title": "\"PhyWorldBench\": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13428",
        "HTML": "https://arxiv.org/html/2507.13428v1",
        "PDF": "https://arxiv.org/pdf/2507.13428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a benchmark for evaluating physical realism in text-to-video models. It does not relate to LLM training data processing, but instead focuses on evaluating video generation models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13455",
      "abstract": "Compliant mechanisms have significant potential in precision applications due to their ability to guide motion without contact. However, an inherent vulnerability to fatigue and mechanical failure has hindered the translation of compliant mechanisms to real-world applications. This is particularly challenging in service environments where loading is complex and uncertain, and the cost of failure is high. In such cases, mechanical hard stops are critical to prevent yielding and buckling. Conventional hard-stop designs, which rely on stacking single-DOF limits, must be overly restrictive in multi-DOF space to guarantee safety in the presence of unknown loads. In this study, we present a systematic design synthesis method to guarantee overload protection in compliant mechanisms by integrating coupled multi-DOF motion limits within a single pair of compact hard-stop surfaces. Specifically, we introduce a theoretical and practical framework for optimizing the contact surface geometry to maximize the mechanisms multi-DOF working space while still ensuring that the mechanism remains within its elastic regime. We apply this synthesis method to a case study of a caged-hinge mechanism for orthopaedic implants, and provide numerical and experimental validation that the derived design offers reliable protection against fatigue, yielding, and buckling. This work establishes a foundation for precision hard-stop design in compliant systems operating under uncertain loads, which is a crucial step toward enabling the application of compliant mechanisms in real-world systems.",
      "authors": [
        "Dean Chen",
        "Armin Pomeroy",
        "Brandon T. Peterson",
        "Will Flanagan",
        "He Kai Lim",
        "Alexandra Stavrakis",
        "Nelson F. SooHoo",
        "Jonathan B. Hopkins and Tyler R. Clites"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:01:18+00:00",
          "link": "https://arxiv.org/abs/2507.13455v1",
          "size": "12500kb",
          "version": "v1"
        }
      ],
      "title": "Hard-Stop Synthesis for Multi-DOF Compliant Mechanisms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13455",
        "PDF": "https://arxiv.org/pdf/2507.13455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered around compliant mechanisms and mechanical designs to prevent mechanical failure. It does not address any aspects of LLM training data processing or involve related datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13459",
      "abstract": "Surrogate models for the rapid inference of nonlinear boundary value problems in mechanics are helpful in a broad range of engineering applications. However, effective surrogate modeling of applications involving the contact of deformable bodies, especially in the context of varying geometries, is still an open issue. In particular, existing methods are confined to rigid body contact or, at best, contact between rigid and soft objects with well-defined contact planes. Furthermore, they employ contact or collision detection filters that serve as a rapid test but use only the necessary and not sufficient conditions for detection. In this work, we present a graph neural network architecture that utilizes continuous collision detection and, for the first time, incorporates sufficient conditions designed for contact between soft deformable bodies. We test its performance on two benchmarks, including a problem in soft tissue mechanics of predicting the closed state of a bioprosthetic aortic valve. We find a regularizing effect on adding additional contact terms to the loss function, leading to better generalization of the network. These benefits hold for simple contact at similar planes and element normal angles, and complex contact at differing planes and element normal angles. We also demonstrate that the framework can handle varying reference geometries. However, such benefits come with high computational costs during training, resulting in a trade-off that may not always be favorable. We quantify the training cost and the resulting inference speedups on various hardware architectures. Importantly, our graph neural network implementation results in up to a thousand-fold speedup for our benchmark problems at inference.",
      "authors": [
        "Vijay K. Dubey (1)",
        "Collin E. Haese (1)",
        "Osman G\\\"ultekin (1)",
        "David Dalton (2)",
        "Manuel K. Rausch (1)",
        "Jan N. Fuhg (1) ((1) The University of Texas at Austin",
        "(2) University of Glasgow)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.13459v1",
          "size": "16590kb",
          "version": "v1"
        }
      ],
      "title": "Graph Neural Network Surrogates for Contacting Deformable Bodies with Necessary and Sufficient Contact Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13459",
        "HTML": "https://arxiv.org/html/2507.13459v1",
        "PDF": "https://arxiv.org/pdf/2507.13459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses surrogate modeling with graph neural networks for mechanics applications involving deformable body contacts and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13464",
      "abstract": "There is a close relationship between the communication complexity and information complexity of communication problems, as demonstrated by results such as Shannon's noiseless source coding theorem, and the Slepian-Wolf theorem. Here, we study this relationship in the prior-free and interactive setting, where we provide an alternate proof for the result of Braverman [SIAM Review, vol. 59, no. 4, 2017], that the amortized communication complexity of simulating a prior-free interactive communication protocol, is equal to its prior-free information cost. While this is a known result, our approach addresses the need for a more natural proof of it. We also improve on the result by achieving round preservation, and using a bounded quantity of shared randomness. We do this by showing that the communicating parties can produce a reliable estimate of the joint type, or empirical distribution, of their inputs. This estimate is then used in our protocol for the prior-free reverse Shannon theorem with side information at the receiver. These results are then generalized to the interactive setting to obtain our main result.",
      "authors": [
        "Gurleen Padda",
        "Dave Touchette"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:15:19+00:00",
          "link": "https://arxiv.org/abs/2507.13464v1",
          "size": "308kb",
          "version": "v1"
        }
      ],
      "title": "Round-Preserving Asymptotic Compression of Prior-Free Interactive Protocols",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13464",
        "HTML": "https://arxiv.org/html/2507.13464v1",
        "PDF": "https://arxiv.org/pdf/2507.13464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research examines the communication and information complexity in interactive protocols, unrelated to LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13468",
      "abstract": "The integration of large language models (LLMs) into conversational robots has made human-robot conversations more dynamic. Yet, LLM-powered conversational robots remain prone to errors, e.g., misunderstanding user intent, prematurely interrupting users, or failing to respond altogether. Detecting and addressing these failures is critical for preventing conversational breakdowns, avoiding task disruptions, and sustaining user trust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal dataset of LLM-powered conversational robot failures during human-robot conversations and encourages researchers to benchmark machine learning models designed to detect robot failures. The dataset includes 16 hours of dyadic human-robot interactions, incorporating facial, speech, and head movement features. Each interaction is annotated with the presence or absence of robot errors from the system perspective, and perceived user intention to correct for a mismatch between robot behavior and user expectation. Participants are invited to form teams and develop machine learning models that detect these failures using multimodal data. Submissions will be evaluated using various performance metrics, including detection accuracy and false positive rate. This challenge represents another key step toward improving failure detection in human-robot interaction through social signal analysis.",
      "authors": [
        "Shiye Cao",
        "Maia Stiber",
        "Amama Mahmood",
        "Maria Teresa Parreira",
        "Wendy Ju",
        "Micol Spitale",
        "Hatice Gunes",
        "Chien-Ming Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:21:45+00:00",
          "link": "https://arxiv.org/abs/2507.13468v1",
          "size": "681kb",
          "version": "v1"
        }
      ],
      "title": "ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13468",
        "HTML": "https://arxiv.org/html/2507.13468v1",
        "PDF": "https://arxiv.org/pdf/2507.13468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the primary focus is on error detection in human-robot interactions, the paper introduces a multimodal dataset for conversational failures, which is a facet of generating data relevant to training language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13470",
      "abstract": "Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$ of $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the $S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of vertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms run BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$'s transitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le 2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known bound is $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$. Leveraging shortcut constructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a centralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3} \\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix multiplication exponent. Using current estimates on $\\omega(\\sigma)$, our exponent improves upon $\\min \\{2 + \\sigma, \\omega \\}$ for $\\tilde \\sigma \\leq \\sigma \\leq 0.53$, where $1/3 < \\tilde \\sigma < 0.3336$ is a universal constant.\n  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel algorithms for $S \\times V$ reachability on graphs admitting balanced recursive separators of size $n^{\\rho}$ for $\\rho < 1$, requiring polylogarithmic time and work $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$. We significantly improve, extend, and generalize Cohen's result. First, our parallel algorithm for graphs with small recursive separators has lower work complexity than Cohen's in boraod paramater ranges. Second, we generalize our algorithm to graphs of treewidth at most $n^{\\rho}$ ($\\rho < 1$) and provide a centralized algorithm that outperforms existing bounds for $S \\times V$ reachability on such graphs. We also do this for some other graph familes with small separators. Finally, we extend these results to $(1 + \\epsilon)$-approximate distance computation.",
      "authors": [
        "Michael Elkin and Chhaya Trehan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:27:26+00:00",
          "link": "https://arxiv.org/abs/2507.13470v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13470",
        "HTML": "https://arxiv.org/html/2507.13470v1",
        "PDF": "https://arxiv.org/pdf/2507.13470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses graph reachability and algorithmic improvements related to matrix multiplication, which do not pertain to LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13474",
      "abstract": "The safety of large language models (LLMs) has garnered significant research attention. In this paper, we argue that previous empirical studies demonstrate LLMs exhibit a propensity to trust information from authoritative sources, such as academic papers, implying new possible vulnerabilities. To verify this possibility, a preliminary analysis is designed to illustrate our two findings. Based on this insight, a novel jailbreaking method, Paper Summary Attack (\\llmname{PSA}), is proposed. It systematically synthesizes content from either attack-focused or defense-focused LLM safety paper to construct an adversarial prompt template, while strategically infilling harmful query as adversarial payloads within predefined subsections. Extensive experiments show significant vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning model like Deepseek-R1. PSA achieves a 97\\% attack success rate (ASR) on well-aligned models like Claude3.5-Sonnet and an even higher 98\\% ASR on Deepseek-R1. More intriguingly, our work has further revealed diametrically opposed vulnerability bias across different base models, and even between different versions of the same model, when exposed to either attack-focused or defense-focused papers. This phenomenon potentially indicates future research clues for both adversarial methodologies and safety alignment.Code is available at https://github.com/233liang/Paper-Summary-Attack",
      "authors": [
        "Liang Lin",
        "Zhihao Xu",
        "Xuehai Tang",
        "Shi Liu",
        "Biyu Zhou",
        "Fuqing Zhu",
        "Jizhong Han",
        "Songlin Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:33:50+00:00",
          "link": "https://arxiv.org/abs/2507.13474v1",
          "size": "1150kb",
          "version": "v1"
        }
      ],
      "title": "Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13474",
        "HTML": "https://arxiv.org/html/2507.13474v1",
        "PDF": "https://arxiv.org/pdf/2507.13474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on the vulnerabilities of LLMs to adversarial attacks through authoritative sources and proposes a jailbreaking method. It does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13476",
      "abstract": "Machine learning models in networking suffer from the domain adaptation problem; models trained in one domain often fail when deployed in different production environments. This paper presents the design and implementation of NetReplica, a system that addresses this challenge by generating training datasets with two critical properties: realism in protocol dynamics and controllability of network conditions. NetReplica models networks as collections of bottleneck links with specific attributes, achieves realism by leveraging production network traces, and enables controllability through fine grained control knobs for each link attribute. Our evaluation using Puffer demonstrates that NetReplica not only matches existing data characteristics but generates realistic samples that are underrepresented in or absent from Puffer data. Models trained on NetReplica augmented datasets show substantially improved generalizability, reducing transmission time prediction error by up to 47% for challenging network conditions compared to models trained solely on Puffer data. This work represents a significant step toward solving the domain adaptation problem that has limited the effectiveness of ML based networking systems.",
      "authors": [
        "Jaber Daneshamooz",
        "Jessica Nguyen",
        "William Chen",
        "Sanjay Chandrasekaran",
        "Satyandra Guthula",
        "Ankit Gupta",
        "Arpit Gupta",
        "Walter Willinger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:35:33+00:00",
          "link": "https://arxiv.org/abs/2507.13476v1",
          "size": "1416kb",
          "version": "v1"
        }
      ],
      "title": "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13476",
        "HTML": "https://arxiv.org/html/2507.13476v1",
        "PDF": "https://arxiv.org/pdf/2507.13476"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a system for generating realistic and controllable training datasets for networking ML models, primarily related to domain adaptation. It does not pertain to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13477",
      "abstract": "The Internet facilitates sex trafficking through adult service websites (ASWs) that host online advertisements for sexual services (sex ads). Since the closure of the popular site Backpage.com, the ecosystem of ASWs has expanded to include multiple competing sites that are hosted outside US jurisdiction. Gaining intelligence for counter-trafficking efforts requires collecting, linking, and cleaning the data from multiple sites. However, high ad volumes, disparate data types, and the existence of generic and misappropriated data make this process challenging. We present an end-to-end process for linking sex ad data and filtering potentially erroneous links. Outputs of the developed process have been used to inform counter-trafficking operations that have helped identify more than 60 potential victims of sex trafficking, some of whom are getting help to transition out of the life. Our process leverages concepts and techniques from network science, information systems, and artificial intelligence to link ads across sites at the level of an individual or unique posting entity. Our approach is computationally efficient, allowing millions of ads to be processed in under an hour. A key component of our process is an edge filtering procedure that identifies and removes potentially erroneous links in a graph representation of sex ad data. A comparison of the proposed process to an existing approach shows that our process is typically more computationally efficient and yields substantial increases in the number of individuals for which we can derive actionable intelligence. The proposed process is an efficient and effective approach for transforming the high volumes of disparate data from sex ads into intelligence that can save lives. It has been refined over years of collaboration with practitioners and represents a strong foundation upon which further counter-trafficking tools can be built.",
      "authors": [
        "Nickolas K. Freeman",
        "Gregory J. Bott",
        "Burcu B. Keskin",
        "Jason M. Parton",
        "James J. Cochran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:38:00+00:00",
          "link": "https://arxiv.org/abs/2507.13477v1",
          "size": "2935kb",
          "version": "v1"
        }
      ],
      "title": "Linking Multi-Site Sex Ad Data at the Individual Level to Aid Counter-Trafficking Efforts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13477",
        "HTML": "https://arxiv.org/html/2507.13477v1",
        "PDF": "https://arxiv.org/pdf/2507.13477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper outlines a process for linking sex ad data to aid counter-trafficking operations and does not contribute to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13480",
      "abstract": "Inspired by edge detection based on the decay behavior of wavelet coefficients, we introduce a (near) linear-time algorithm for detecting the local regularity in non-uniformly sampled multivariate signals. Our approach quantifies regularity within the framework of microlocal spaces introduced by Jaffard. The central tool in our analysis is the fast samplet transform, a distributional wavelet transform tailored to scattered data. We establish a connection between the decay of samplet coefficients and the pointwise regularity of multivariate signals. As a by product, we derive decay estimates for functions belonging to classical H\\\"older spaces and Sobolev-Slobodeckij spaces. While traditional wavelets are effective for regularity detection in low-dimensional structured data, samplets demonstrate robust performance even for higher dimensional and scattered data. To illustrate our theoretical findings, we present extensive numerical studies detecting local regularity of one-, two- and three-dimensional signals, ranging from non-uniformly sampled time series over image segmentation to edge detection in point clouds.",
      "authors": [
        "Sara Avesani and Gianluca Giacchi and Michael Multerer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:46:01+00:00",
          "link": "https://arxiv.org/abs/2507.13480v1",
          "size": "20043kb",
          "version": "v1"
        }
      ],
      "title": "Multiresolution local smoothness detection in non-uniformly sampled multivariate signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13480",
        "HTML": "https://arxiv.org/html/2507.13480v1",
        "PDF": "https://arxiv.org/pdf/2507.13480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an algorithm for detecting smoothness in multivariate signals and focuses on wavelet transforms. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13481",
      "abstract": "Code samples play a pivotal role in open-source ecosystems (OSSECO), serving as lightweight artifacts that support knowledge transfer, onboarding, and framework adoption. Despite their instructional relevance, these samples are often governed informally, with minimal review and unclear ownership, which increases their exposure to socio-technical degradation. In this context, the co-occurrence and longitudinal interplay of code smells (e.g., large classes, poor modularity) and community smells (e.g., lone contributors, fragmented communication) become particularly critical. While each type of smell has been studied in isolation, little is known about how community-level dysfunctions anticipate or exacerbate technical anomalies in code samples over time. This study investigates how code and community smells emerge, co-occur, and evolve within code samples maintained in OSSECOs. A Multivocal Literature Review protocol was applied, encompassing 30 peer-reviewed papers and 17 practitioner-oriented sources (2013-2024). Thematic synthesis was conducted to identify recurring socio-technical patterns related to smell dynamics. Nine patterns were identified, showing that community smells often precede or reinforce technical degradation in code samples. Symptoms such as \"radio silence\" and centralized ownership were frequently associated with persistent structural anomalies. Additionally, limited onboarding, the absence of continuous refactoring, and informal collaboration emerged as recurring conditions for smell accumulation. Conclusion: In OSSECOs, particularly within code samples, community-level dysfunctions not only correlate with but often signal maintainability decay. These findings underscore the need for socio-technical quality indicators and lightweight governance mechanisms tailored to shared instructional artifacts.",
      "authors": [
        "Arthur Bueno",
        "Bruno Cafeo",
        "Maria Cagnin",
        "Awdren Font\\~ao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:46:08+00:00",
          "link": "https://arxiv.org/abs/2507.13481v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13481",
        "HTML": "https://arxiv.org/html/2507.13481v1",
        "PDF": "https://arxiv.org/pdf/2507.13481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates socio-technical patterns and code smell dynamics within code samples in open-source ecosystems. It does not address any aspects related to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13482",
      "abstract": "Human Activity Recognition (HAR) based on wearable inertial sensors plays a critical role in remote health monitoring. In patients with movement disorders, the ability to detect abnormal patient movements in their home environments can enable continuous optimization of treatments and help alert caretakers as needed. Machine learning approaches have been proposed for HAR tasks using Inertial Measurement Unit (IMU) data; however, most rely on application-specific labels and lack generalizability to data collected in different environments or populations. To address this limitation, we propose a new cross-modal self-supervised pretraining approach to learn representations from large-sale unlabeled IMU-video data and demonstrate improved generalizability in HAR tasks on out of distribution (OOD) IMU datasets, including a dataset collected from patients with Parkinson's disease. Specifically, our results indicate that the proposed cross-modal pretraining approach outperforms the current state-of-the-art IMU-video pretraining approach and IMU-only pretraining under zero-shot and few-shot evaluations. Broadly, our study provides evidence that in highly dynamic data modalities, such as IMU signals, cross-modal pretraining may be a useful tool to learn generalizable data representations. Our software is available at https://github.com/scheshmi/IMU-Video-OOD-HAR.",
      "authors": [
        "Seyyed Saeid Cheshmi",
        "Buyao Lyu",
        "Thomas Lisko",
        "Rajesh Rajamani",
        "Robert A. McGovern",
        "Yogatheesan Varatharajah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:47:46+00:00",
          "link": "https://arxiv.org/abs/2507.13482v1",
          "size": "931kb",
          "version": "v1"
        }
      ],
      "title": "Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13482",
        "HTML": "https://arxiv.org/html/2507.13482v1",
        "PDF": "https://arxiv.org/pdf/2507.13482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving human activity recognition using cross-modal representation learning. It is centered on machine learning for health monitoring, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13485",
      "abstract": "Bio-inspired neural networks are attractive for their adversarial robustness, energy frugality, and closer alignment with cortical physiology, yet they often lag behind back-propagation (BP) based models in accuracy and ability to scale. We show that allowing the use of different bio-inspired learning rules in different layers, discovered automatically by a tailored neural-architecture-search (NAS) procedure, bridges this gap. Starting from standard NAS baselines, we enlarge the search space to include bio-inspired learning rules and use NAS to find the best architecture and learning rule to use in each layer. We show that neural networks that use different bio-inspired learning rules for different layers have better accuracy than those that use a single rule across all the layers. The resulting NN that uses a mix of bio-inspired learning rules sets new records for bio-inspired models: 95.16% on CIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on ImageNet. In some regimes, they even surpass comparable BP-based networks while retaining their robustness advantages. Our results suggest that layer-wise diversity in learning rules allows better scalability and accuracy, and motivates further research on mixing multiple bio-inspired learning rules in the same network.",
      "authors": [
        "Imane Hamzaoui",
        "Riyadh Baghdadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:49:38+00:00",
          "link": "https://arxiv.org/abs/2507.13485v1",
          "size": "1035kb",
          "version": "v1"
        }
      ],
      "title": "Neural Architecture Search with Mixed Bio-inspired Learning Rules",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13485",
        "HTML": "https://arxiv.org/html/2507.13485v1",
        "PDF": "https://arxiv.org/pdf/2507.13485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores neural architecture search with bio-inspired learning rules for neural networks. It does not discuss training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13486",
      "abstract": "Uncertainty quantification of the photogrammetry process is essential for providing per-point accuracy credentials of the point clouds. Unlike airborne LiDAR, which typically delivers consistent accuracy across various scenes, the accuracy of photogrammetric point clouds is highly scene-dependent, since it relies on algorithm-generated measurements (i.e., stereo or multi-view stereo). Generally, errors of the photogrammetric point clouds propagate through a two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA), followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM stage has been well studied using the first-order statistics of the reprojection error function, that in the MVS stage remains largely unsolved and non-standardized, primarily due to its non-differentiable and multi-modal nature (i.e., from pixel values to geometry). In this paper, we present an uncertainty quantification framework closing this gap by associating an error covariance matrix per point accounting for this two-step photogrammetry process. Specifically, to estimate the uncertainty in the MVS stage, we propose a novel, self-calibrating method by taking reliable n-view points (n>=6) per-view to regress the disparity uncertainty using highly relevant cues (such as matching cost values) from the MVS stage. Compared to existing approaches, our method uses self-contained, reliable 3D points extracted directly from the MVS process, with the benefit of being self-supervised and naturally adhering to error propagation path of the photogrammetry process, thereby providing a robust and certifiable uncertainty quantification across diverse scenes. We evaluate the framework using a variety of publicly available airborne and UAV imagery datasets. Results demonstrate that our method outperforms existing approaches by achieving high bounding rates without overestimating uncertainty.",
      "authors": [
        "Debao Huang",
        "Rongjun Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:50:01+00:00",
          "link": "https://arxiv.org/abs/2507.13486v1",
          "size": "3808kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13486",
        "PDF": "https://arxiv.org/pdf/2507.13486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with uncertainty quantification in photogrammetry. It does not relate to any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13490",
      "abstract": "There has been extensive research on assessing the value orientation of Large Language Models (LLMs) as it can shape user experiences across demographic groups. However, several challenges remain. First, while the Multiple Choice Question (MCQ) setting has been shown to be vulnerable to perturbations, there is no systematic comparison of probing methods for value probing. Second, it is unclear to what extent the probed values capture in-context information and reflect models' preferences for real-world actions. In this paper, we evaluate the robustness and expressiveness of value representations across three widely used probing strategies. We use variations in prompts and options, showing that all methods exhibit large variances under input perturbations. We also introduce two tasks studying whether the values are responsive to demographic context, and how well they align with the models' behaviors in value-related scenarios. We show that the demographic context has little effect on the free-text generation, and the models' values only weakly correlate with their preference for value-based actions. Our work highlights the need for a more careful examination of LLM value probing and awareness of its limitations.",
      "authors": [
        "Siqi Shen",
        "Mehar Singh",
        "Lajanugen Logeswaran",
        "Moontae Lee",
        "Honglak Lee",
        "Rada Mihalcea"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:56:41+00:00",
          "link": "https://arxiv.org/abs/2507.13490v1",
          "size": "356kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13490",
        "HTML": "https://arxiv.org/html/2507.13490v1",
        "PDF": "https://arxiv.org/pdf/2507.13490"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines probing strategies for evaluating value orientation in LLMs, focusing on robustness and expressiveness. It does not address training data processing tasks for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13491",
      "abstract": "Training sophisticated agents for optimal decision-making under uncertainty has been key to the rapid development of modern autonomous systems across fields. Notably, model-free reinforcement learning (RL) has enabled decision-making agents to improve their performance directly through system interactions, with minimal prior knowledge about the system. Yet, model-free RL has generally relied on agents equipped with deep neural network function approximators, appealing to the networks' expressivity to capture the agent's policy and value function for complex systems. However, neural networks amplify the issues of sample inefficiency, unsafe learning, and limited interpretability in model-free RL. To this end, this work introduces model-based agents as a compelling alternative for control policy approximation, leveraging adaptable models of system dynamics, cost, and constraints for safe policy learning. These models can encode prior system knowledge to inform, constrain, and aid in explaining the agent's decisions, while deficiencies due to model mismatch can be remedied with model-free RL. We outline the benefits and challenges of learning model-based agents -- exemplified by model predictive control -- and detail the primary learning approaches: Bayesian optimization, policy search RL, and offline strategies, along with their respective strengths. While model-free RL has long been established, its interplay with model-based agents remains largely unexplored, motivating our perspective on their combined potentials for sample-efficient learning of safe and interpretable decision-making agents.",
      "authors": [
        "Thomas Banker and Ali Mesbah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.13491v1",
          "size": "321kb",
          "version": "v1"
        }
      ],
      "title": "Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13491",
        "HTML": "https://arxiv.org/html/2507.13491v1",
        "PDF": "https://arxiv.org/pdf/2507.13491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model-free and model-based reinforcement learning for optimal decision-making, addressing issues like sample efficiency and decision interpretability, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13494",
      "abstract": "This article introduces a new approach to principled and practical random variate generation with formal guarantees. The key idea is to first specify the desired probability distribution in terms of a finite-precision numerical program that defines its cumulative distribution function (CDF), and then generate exact random variates according to this CDF. We present a universal and fully automated method to synthesize exact random variate generators given any numerical CDF implemented in any binary number format, such as floating-point, fixed-point, and posits. The method is guaranteed to operate with the same precision used to specify the CDF, does not overflow, avoids expensive arbitrary-precision arithmetic, and exposes a consistent API. The method rests on a novel space-time optimal implementation for the class of generators that attain the information-theoretically optimal Knuth and Yao entropy rate, consuming the least possible number of input random bits per output variate. We develop a random variate generation library using our method in C and evaluate it on a diverse set of ``continuous'' and ``discrete'' distributions, showing competitive runtime with the state-of-the-art GNU Scientific Library while delivering higher accuracy, entropy efficiency, and automation.",
      "authors": [
        "Feras A. Saad and Wonyeol Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:05:07+00:00",
          "link": "https://arxiv.org/abs/2507.13494v1",
          "size": "1319kb",
          "version": "v1"
        }
      ],
      "title": "Random Variate Generation with Formal Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13494",
        "PDF": "https://arxiv.org/pdf/2507.13494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new method for random variate generation with formal guarantees, focusing on computational aspects and efficiency of generating random numbers, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13499",
      "abstract": "Aim. There are 10s of thousands of code review comments each week at Meta. We developed Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes for reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch> data points to fine-tune Llama models. Once our models achieve reasonable offline results, we roll them into production. To ensure that our AI-assisted fixes do not negatively impact the time it takes to do code reviews, we conduct randomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large Llama models. In offline results, our LargeLSFT model creates an exact match patch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The internal models also use more modern Hack functions when compared to the PHP functions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that compares no AI patches with AI patch suggestions, we see a large regression with reviewers taking over 5% longer to conduct reviews. After investigation, we modify the UX to only show authors the AI patches, and see no regressions in the time for reviews.\n  Production. When we roll LargeLSFT into production, we see an ActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o. Our results illustrate the importance of safety trials in ensuring that AI does not inadvertently slow down engineers, and a successful review comment to AI patch product running at scale.",
      "authors": [
        "Chandra Maddila",
        "Negar Ghorbani",
        "James Saindon",
        "Parth Thakkar",
        "Vijayaraghavan Murali",
        "Rui Abreu",
        "Jingyue Shen",
        "Brian Zhou",
        "Nachiappan Nagappan",
        "and Peter C. Rigby"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:11:00+00:00",
          "link": "https://arxiv.org/abs/2507.13499v1",
          "size": "1542kb",
          "version": "v1"
        }
      ],
      "title": "AI-Assisted Fixes to Code Review Comments at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13499",
        "HTML": "https://arxiv.org/html/2507.13499v1",
        "PDF": "https://arxiv.org/pdf/2507.13499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper mentions using a dataset for fine-tuning Llama models for code review comment fixes but primarily emphasizes AI-assisted code review processes and evaluation, not data processing methods for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13501",
      "abstract": "We provide a mathematical argument showing that, given a representation of lexical items as functions (wavelets, for instance) in some function space, it is possible to construct a faithful representation of arbitrary syntactic objects in the same function space. This space can be endowed with a commutative non-associative semiring structure built using the second Renyi entropy. The resulting representation of syntactic objects is compatible with the magma structure. The resulting set of functions is an algebra over an operad, where the operations in the operad model circuits that transform the input wave forms into a combined output that encodes the syntactic structure. The action of Merge on workspaces is faithfully implemented as action on these circuits, through a coproduct and a Hopf algebra Markov chain. The results obtained here provide a constructive argument showing the theoretical possibility of a neurocomputational realization of the core computational structure of syntax. We also present a particular case of this general construction where this type of realization of Merge is implemented as a cross frequency phase synchronization on sinusoidal waves. This also shows that Merge can be expressed in terms of the successor function of a semiring, thus clarifying the well known observation of its similarities with the successor function of arithmetic.",
      "authors": [
        "Matilde Marcolli and Robert C. Berwick"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Rings and Algebras (math.RA)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:14:57+00:00",
          "link": "https://arxiv.org/abs/2507.13501v1",
          "size": "261kb",
          "version": "v1"
        }
      ],
      "title": "Encoding syntactic objects and Merge operations in function spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13501",
        "HTML": "https://arxiv.org/html/2507.13501v1",
        "PDF": "https://arxiv.org/pdf/2507.13501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores theoretical models of syntax and their neurocomputational representations, focusing on syntactic structures in function spaces, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13505",
      "abstract": "Cybersecurity simulation environments, such as cyber ranges, honeypots, and sandboxes, require realistic human behavior to be effective, yet no quantitative method exists to assess the behavioral fidelity of synthetic user personas. This paper presents PHASE (Passive Human Activity Simulation Evaluation), a machine learning framework that analyzes Zeek connection logs and distinguishes human from non-human activity with over 90\\% accuracy. PHASE operates entirely passively, relying on standard network monitoring without any user-side instrumentation or visible signs of surveillance. All network activity used for machine learning is collected via a Zeek network appliance to avoid introducing unnecessary network traffic or artifacts that could disrupt the fidelity of the simulation environment. The paper also proposes a novel labeling approach that utilizes local DNS records to classify network traffic, thereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley Additive exPlanations) analysis to uncover temporal and behavioral signatures indicative of genuine human users. In a case study, we evaluate a synthetic user persona and identify distinct non-human patterns that undermine behavioral realism. Based on these insights, we develop a revised behavioral configuration that significantly improves the human-likeness of synthetic activity yielding a more realistic and effective synthetic user persona.",
      "authors": [
        "Steven Lamp",
        "Jason D. Hiser",
        "Anh Nguyen-Tuong",
        "Jack W. Davidson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:24:11+00:00",
          "link": "https://arxiv.org/abs/2507.13505v1",
          "size": "2452kb",
          "version": "v1"
        }
      ],
      "title": "PHASE: Passive Human Activity Simulation Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13505",
        "HTML": "https://arxiv.org/html/2507.13505v1",
        "PDF": "https://arxiv.org/pdf/2507.13505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a machine learning framework for evaluating human activity simulation in cybersecurity environments, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13508",
      "abstract": "The \"Fake or Real\" competition hosted on Kaggle (\\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}) is the second part of a series of follow-up competitions and hackathons related to the \"Assurance for Space Domain AI Applications\" project funded by the European Space Agency (\\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}). The competition idea is based on two real-life AI security threats identified within the project -- data poisoning and overreliance in Large Language Models. The task is to distinguish between the proper output from LLM and the output generated under malicious modification of the LLM. As this problem was not extensively researched, participants are required to develop new techniques to address this issue or adjust already existing ones to this problem's statement.",
      "authors": [
        "Agata Kaczmarek (1)",
        "Dawid P{\\l}udowski (1)",
        "Piotr Wilczy\\'nski (1)",
        "Przemys{\\l}aw Biecek (1)",
        "Krzysztof Kotowski (2)",
        "Ramez Shendy (2)",
        "Jakub Nalepa (2 and 3)",
        "Artur Janicki (1)",
        "Evridiki Ntagiou (4) ((1) Warsaw University of Technology",
        "(2) KP Labs",
        "(3) Silesian University of Technology",
        "(4) European Space Agency",
        "European Space Operations Center)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:35:29+00:00",
          "link": "https://arxiv.org/abs/2507.13508v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13508",
        "PDF": "https://arxiv.org/pdf/2507.13508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with identifying malicious modifications in LLM outputs, focusing on AI security threats, but not on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13510",
      "abstract": "The Strassen $2\\times2$ matrix multiplication algorithm arises from the volume form on the 3-dimensional quotient space of the $2\\times 2$ matrices by the multiples of identity.",
      "authors": [
        "Benoit Jacob (AMD)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:40:52+00:00",
          "link": "https://arxiv.org/abs/2507.13510v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Strassen $2\\times2$ Matrix Multiplication from a 3-dimensional Volume Form",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13510",
        "HTML": "https://arxiv.org/html/2507.13510v1",
        "PDF": "https://arxiv.org/pdf/2507.13510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Strassen's matrix multiplication algorithm and its mathematical foundation, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13511",
      "abstract": "Large Language Models (LLMs) offer significant promise for intelligent traffic management; however, current chain-based systems like TrafficGPT are hindered by sequential task execution, high token usage, and poor scalability, making them inefficient for complex, real-world scenarios. To address these limitations, we propose GraphTrafficGPT, a novel graph-based architecture, which fundamentally redesigns the task coordination process for LLM-driven traffic applications. GraphTrafficGPT represents tasks and their dependencies as nodes and edges in a directed graph, enabling efficient parallel execution and dynamic resource allocation. The main idea behind the proposed model is a Brain Agent that decomposes user queries, constructs optimized dependency graphs, and coordinates a network of specialized agents for data retrieval, analysis, visualization, and simulation. By introducing advanced context-aware token management and supporting concurrent multi-query processing, the proposed architecture handles interdependent tasks typical of modern urban mobility environments. Experimental results demonstrate that GraphTrafficGPT reduces token consumption by 50.2% and average response latency by 19.0% compared to TrafficGPT, while supporting simultaneous multi-query execution with up to 23.0% improvement in efficiency.",
      "authors": [
        "Nabil Abdelaziz Ferhat Taleb",
        "Abdolazim Rezaei",
        "Raj Atulkumar Patel",
        "Mehdi Sookhak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:41:09+00:00",
          "link": "https://arxiv.org/abs/2507.13511v1",
          "size": "3756kb",
          "version": "v1"
        }
      ],
      "title": "GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13511",
        "HTML": "https://arxiv.org/html/2507.13511v1",
        "PDF": "https://arxiv.org/pdf/2507.13511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes GraphTrafficGPT for traffic management, focusing on task coordination and execution improvements, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13514",
      "abstract": "Satellite Image Time Series (SITS) data has proven effective for agricultural tasks due to its rich spectral and temporal nature. In this study, we tackle the task of stress detection in sugar-beet fields using a fully unsupervised approach. We propose a 3D convolutional autoencoder model to extract meaningful features from Sentinel-2 image sequences, combined with acquisition-date-specific temporal encodings to better capture the growth dynamics of sugar-beets. The learned representations are used in a downstream clustering task to separate stressed from healthy fields. The resulting stress detection system can be directly applied to data from different years, offering a practical and accessible tool for stress detection in sugar-beets.",
      "authors": [
        "Bhumika Laxman Sadbhave",
        "Philipp Vaeth",
        "Denise Dejon",
        "Gunther Schorcht",
        "Magda Gregorov\\'a"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:48:10+00:00",
          "link": "https://arxiv.org/abs/2507.13514v1",
          "size": "938kb",
          "version": "v1"
        }
      ],
      "title": "Sugar-Beet Stress Detection using Satellite Image Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13514",
        "HTML": "https://arxiv.org/html/2507.13514v1",
        "PDF": "https://arxiv.org/pdf/2507.13514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on stress detection in sugar-beet fields using satellite image time series and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13516",
      "abstract": "The proximal Galerkin (PG) method is a finite element method for solving variational problems with inequality constraints. It has several advantages, including constraint-preserving approximations and mesh independence. This paper presents the first abstract a priori error analysis of PG methods, providing a general framework to establish convergence and error estimates. As applications of the framework, we demonstrate optimal convergence rates for both the obstacle and Signorini problems using various finite element subspaces.",
      "authors": [
        "Brendan Keith",
        "Rami Masri",
        "Marius Zeinhofer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:54:18+00:00",
          "link": "https://arxiv.org/abs/2507.13516v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "A priori error analysis of the proximal Galerkin method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13516",
        "HTML": "https://arxiv.org/html/2507.13516v1",
        "PDF": "https://arxiv.org/pdf/2507.13516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents error analysis for the proximal Galerkin method in finite element analysis, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13517",
      "abstract": "International coordination faces significant friction due to reliance on periodic summits, bilateral consultations, and fragmented communication channels that impede rapid collective responses to emerging global challenges while limiting transparency to constituents. We present the Stated Protocol, a decentralized framework that enables organizations to coordinate through standardized text statements published on their website domains. While applicable to all organizations, this work focuses primarily on the application in international relations, where the protocol enables rapid consensus discovery and collective decision-making without relying on centralized social media platforms. We explore specific applications: (1) faster treaty negotiation through incremental micro-agreements that can be signed digitally within hours rather than months, (2) continuous and transparent operation of international institutions through asynchronous decision-making, (3) coordinated signaling from local governments to national authorities through simultaneous statement publication, and (4) coalition formation among non-governmental organizations through transparent position aggregation.",
      "authors": [
        "Christopher J. P. Rieckmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.13517v1",
          "size": "210kb",
          "version": "v1"
        }
      ],
      "title": "The Stated Protocol: A Decentralized Framework for Digital Diplomacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13517",
        "HTML": "https://arxiv.org/html/2507.13517v1",
        "PDF": "https://arxiv.org/pdf/2507.13517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a decentralized framework for digital diplomacy and international coordination, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13522",
      "abstract": "This paper presents Checkmate, a system that enables per-iteration checkpointing in DNN training without any training slowdown. The traditional approach to checkpointing requires a pause in training to copy model states to a separate location, allowing the state to be restored in the event of failure. This approach fundamentally has a tradeoff between the frequency of checkpoints and the cost of a failure. We avoid this tradeoff; our key insight is that in data-parallel training, all information necessary to create a checkpoint already exists in the network as gradients. Our core contribution is a new multicast abstraction that simultaneously delivers gradients to a separate CPU-based shadow cluster. The shadow maintains a checkpoint by applying those gradients to a copy of the model. Our evaluation shows that Checkmate performs per-iteration checkpointing with training throughput comparable to an ideal no-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent checkpointing compared to state-of-the-art checkpointing systems, resulting in 80% to 97.1% reduction in repeated work per failure. At the same checkpointing frequency, Checkmate delivers 1.3x to 6.5x throughput compared to other systems.",
      "authors": [
        "Ankit Bhardwaj",
        "Weiyang Wang",
        "Jeremy Carin",
        "Adam Belay",
        "Manya Ghobadi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:21:18+00:00",
          "link": "https://arxiv.org/abs/2507.13522v1",
          "size": "346kb",
          "version": "v1"
        }
      ],
      "title": "Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13522",
        "HTML": "https://arxiv.org/html/2507.13522v1",
        "PDF": "https://arxiv.org/pdf/2507.13522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a system for efficient model checkpointing in DNN training but does not address data processing specifically related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13524",
      "abstract": "Partner selection is crucial for cooperation and hinges on communication. As artificial agents, especially those powered by large language models (LLMs), become more autonomous, intelligent, and persuasive, they compete with humans for partnerships. Yet little is known about how humans select between human and AI partners and adapt under AI-induced competition pressure. We constructed a communication-based partner selection game and examined the dynamics in hybrid mini-societies of humans and bots powered by a state-of-the-art LLM. Through three experiments (N = 975), we found that bots, though more prosocial than humans and linguistically distinguishable, were not selected preferentially when their identity was hidden. Instead, humans misattributed bots' behaviour to humans and vice versa. Disclosing bots' identity induced a dual effect: it reduced bots' initial chances of being selected but allowed them to gradually outcompete humans by facilitating human learning about the behaviour of each partner type. These findings show how AI can reshape social interaction in mixed societies and inform the design of more effective and cooperative hybrid systems.",
      "authors": [
        "Yaomin Jiang",
        "Levin Brinkmann",
        "Anne-Marie Nussberger",
        "Ivan Soraperra",
        "Jean-Fran\\c{c}ois Bonnefon",
        "Iyad Rahwan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:24:26+00:00",
          "link": "https://arxiv.org/abs/2507.13524v1",
          "size": "4722kb",
          "version": "v1"
        }
      ],
      "title": "Humans learn to prefer trustworthy AI over human partners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13524",
        "HTML": "https://arxiv.org/html/2507.13524v1",
        "PDF": "https://arxiv.org/pdf/2507.13524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study involves human interactions with bots powered by LLMs but focuses on partner selection dynamics, not directly on LLM training data processing. The main focus is not on the data aspect."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13525",
      "abstract": "Large language models (LLMs) can perform recommendation tasks by taking prompts written in natural language as input. Compared to traditional methods such as collaborative filtering, LLM-based recommendation offers advantages in handling cold-start, cross-domain, and zero-shot scenarios, as well as supporting flexible input formats and generating explanations of user behavior. In this paper, we focus on a single-user setting, where no information from other users is used. This setting is practical for privacy-sensitive or data-limited applications. In such cases, prompt engineering becomes especially important for controlling the output generated by the LLM. We conduct a large-scale comparison of 23 prompt types across 8 public datasets and 12 LLMs. We use statistical tests and linear mixed-effects models to evaluate both accuracy and inference cost. Our results show that for cost-efficient LLMs, three types of prompts are especially effective: those that rephrase instructions, consider background knowledge, and make the reasoning process easier to follow. For high-performance LLMs, simple prompts often outperform more complex ones while reducing cost. In contrast, commonly used prompting styles in natural language processing, such as step-by-step reasoning, or the use of reasoning models often lead to lower accuracy. Based on these findings, we provide practical suggestions for selecting prompts and LLMs depending on the required balance between accuracy and cost.",
      "authors": [
        "Genki Kusano and Kosuke Akimoto and Kunihiro Takeoka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:26:00+00:00",
          "link": "https://arxiv.org/abs/2507.13525v1",
          "size": "394kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13525",
        "HTML": "https://arxiv.org/html/2507.13525v1",
        "PDF": "https://arxiv.org/pdf/2507.13525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating prompt engineering for LLM-based personalized recommendation tasks but does not address training data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13527",
      "abstract": "The increasing use of two-dimensional (2D) materials in nanoelectronics demands robust metrology techniques for electrical characterization, especially for large-scale production. While atomic force microscopy (AFM) techniques like conductive AFM (C-AFM) offer high accuracy, they suffer from slow data acquisition speeds due to the raster scanning process. To address this, we introduce SparseC-AFM, a deep learning model that rapidly and accurately reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM scans. Our approach is robust across various scanning modes, substrates, and experimental conditions. We report a comparison between (a) classic flow implementation, where a high pixel density C-AFM image (e.g., 15 minutes to collect) is manually parsed to extract relevant material parameters, and (b) our SparseC-AFM method, which achieves the same operation using data that requires substantially less acquisition time (e.g., under 5 minutes). SparseC-AFM enables efficient extraction of critical material parameters in MoS$_2$, including film coverage, defect density, and identification of crystalline island boundaries, edges, and cracks. We achieve over 11x reduction in acquisition time compared to manual extraction from a full-resolution C-AFM image. Moreover, we demonstrate that our model-predicted samples exhibit remarkably similar electrical properties to full-resolution data gathered using classic-flow scanning. This work represents a significant step toward translating AI-assisted 2D material characterization from laboratory research to industrial fabrication. Code and model weights are available at github.com/UNITES-Lab/sparse-cafm.",
      "authors": [
        "Levi Harris",
        "Md Jayed Hossain",
        "Mufan Qiu",
        "Ruichen Zhang",
        "Pingchuan Ma",
        "Tianlong Chen",
        "Jiaqi Gu",
        "Seth Ariel Tongay",
        "and Umberto Celano"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:38:32+00:00",
          "link": "https://arxiv.org/abs/2507.13527v1",
          "size": "3168kb",
          "version": "v1"
        }
      ],
      "title": "SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13527",
        "HTML": "https://arxiv.org/html/2507.13527v1",
        "PDF": "https://arxiv.org/pdf/2507.13527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces SparseC-AFM, a deep learning method for characterizing 2D materials, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13528",
      "abstract": "TickTacking is a rhythm-based interface that allows users to control a pointer in a two-dimensional space through dual-button tapping. This paper investigates the generation of human-like trajectories using a receding horizon approach applied to the TickTacking interface in a target-tracking task. By analyzing user-generated trajectories, we identify key human behavioral features and incorporate them in a controller that mimics these behaviors. The performance of this human-inspired controller is evaluated against a baseline optimal-control-based agent, demonstrating the importance of specific control features for achieving human-like interaction. These findings contribute to the broader goal of developing rhythm-based human-machine interfaces by offering design insights that enhance user performance, improve intuitiveness, and reduce interaction frustration",
      "authors": [
        "Daniele Masti",
        "Stefano Menchetti",
        "\\c{C}a\\u{g}r{\\i} Erdem",
        "Giorgio Gnecco",
        "and Davide Rocchesso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:41:17+00:00",
          "link": "https://arxiv.org/abs/2507.13528v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13528",
        "HTML": "https://arxiv.org/html/2507.13528v1",
        "PDF": "https://arxiv.org/pdf/2507.13528"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates trajectory generation for human-machine interaction using a novel interface, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13530",
      "abstract": "We propose a novel formulation for the second-order total generalized variation (TGV) of the normal vector on an oriented, triangular mesh embedded in $\\mathbb{R}^3$. The normal vector is considered as a manifold-valued function, taking values on the unit sphere. Our formulation extends previous discrete TGV models for piecewise constant scalar data that utilize a Raviart-Thomas function space. To exctend this formulation to the manifold setting, a tailor-made tangential Raviart-Thomas type finite element space is constructed in this work. The new regularizer is compared to existing methods in mesh denoising experiments.",
      "authors": [
        "Lukas Baumg\\\"artner and Ronny Bergmann and Roland Herzog and Stephan Schmidt and Manuel Wei{\\ss}"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Differential Geometry (math.DG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:44:49+00:00",
          "link": "https://arxiv.org/abs/2507.13530v1",
          "size": "5338kb",
          "version": "v1"
        }
      ],
      "title": "Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13530",
        "PDF": "https://arxiv.org/pdf/2507.13530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a formulation for mesh denoising using total generalized variation, which is not related to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13533",
      "abstract": "Static verification provides strong correctness guarantees for code; however, fully specifying programs for static verification is a complex, burdensome process for users. Gradual verification was introduced to make this process easier by supporting the verification of partially specified programs. The only currently working gradual verifier, Gradual C0, successfully verifies heap manipulating programs, but lacks expressiveness in its specification language. This paper describes the design and implementation of an extension to Gradual C0 that supports unfolding expressions, which allow more intuitive specifications of recursive heap data structures.",
      "authors": [
        "Priyam Gupta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:50:52+00:00",
          "link": "https://arxiv.org/abs/2507.13533v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "Increasing the Expressiveness of a Gradual Verifier",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13533",
        "HTML": "https://arxiv.org/html/2507.13533v1",
        "PDF": "https://arxiv.org/pdf/2507.13533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on extending a gradual verification tool, Gradual C0, to better handle recursive heap data structures, and it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13534",
      "abstract": "Intensifying heatwaves driven by climate change are accelerating the adoption of mobile air conditioning (AC) systems. A rapid mass adoption of such AC systems could create additional stress on electricity grids and the power system. This study presents a novel method to estimate the electricity demand from AC systems both at system level and at high temporal and spatial granularity. We apply the method to a near-future heatwave scenario in Germany in which household AC adoption increases from current 19% to 35% during a heatwave similar to the one of July 2025. We analyze the effects for 196,428 grid cells of one square kilometer across Germany, by combining weather data, census data, socio-demographic assumptions, mobility patterns, and temperature-dependent AC activation functions. We find that electricity demand of newly purchased mobile AC systems could increase the peak load by over 14 GW (23%), with urban hot-spots reaching 5.8 MW per square kilometer. The temporal pattern creates a pronounced afternoon peak that coincides with lower photovoltaic generation, potentially exacerbating power system stability challenges. Our findings underscore the urgency for proactive energy system planning to manage emerging demand peaks.",
      "authors": [
        "Leo Semmelmann",
        "Frederik vom Scheidt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:55:23+00:00",
          "link": "https://arxiv.org/abs/2507.13534v1",
          "size": "7804kb",
          "version": "v1"
        }
      ],
      "title": "Heatwave-driven air conditioning adoption could increase German electricity demand by 14 GW in the near future",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13534",
        "HTML": "https://arxiv.org/html/2507.13534v1",
        "PDF": "https://arxiv.org/pdf/2507.13534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on estimating electricity demand related to air conditioning adoption during heatwaves and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13539",
      "abstract": "Evolutionary methods have previously been shown to be an effective learning method for walking gaits on hexapod robots. However, the ability of these algorithms to evolve an effective policy rapidly degrades as the input space becomes more complex. This degradation is due to the exponential growth of the solution space, resulting from an increasing parameter count to handle a more complex input. In order to address this challenge, we introduce Sparse Cosine Optimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine Transform (DCT) to learn directly from the feature coefficients of an input matrix. By truncating the coefficient matrix returned by the DCT, we can reduce the dimensionality of an input while retaining the highest energy features of the original input. We demonstrate the effectiveness of this method by using SCOPE to learn the gait of a hexapod robot. The hexapod controller is given a matrix input containing time-series information of previous poses, which are then transformed to gait parameters by an evolved policy. In this task, the addition of SCOPE to a reference algorithm achieves a 20% increase in efficacy. SCOPE achieves this result by reducing the total input size of the time-series pose data from 2700 to 54, a 98% decrease. Additionally, SCOPE is capable of compressing an input to any output shape, provided that each output dimension is no greater than the corresponding input dimension. This paper demonstrates that SCOPE is capable of significantly compressing the size of an input to an evolved controller, resulting in a statistically significant gain in efficacy.",
      "authors": [
        "Jim O'Connor",
        "Jay B. Nash",
        "Derin Gezgin",
        "Gary B. Parker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:15:48+00:00",
          "link": "https://arxiv.org/abs/2507.13539v1",
          "size": "6590kb",
          "version": "v1"
        }
      ],
      "title": "SCOPE for Hexapod Gait Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13539",
        "HTML": "https://arxiv.org/html/2507.13539v1",
        "PDF": "https://arxiv.org/pdf/2507.13539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Sparse Cosine Optimized Policy Evolution (SCOPE) for hexapod gait generation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13540",
      "abstract": "In-context learning (ICL) enables large language models (LLMs) to acquire new behaviors from the input sequence alone without any parameter updates. Recent studies have shown that ICL can surpass the original meaning learned in pretraining stage through internalizing the structure the data-generating process (DGP) of the prompt into the hidden representations. However, the mechanisms by which LLMs achieve this ability is left open. In this paper, we present the first rigorous explanation of such phenomena by introducing a unified framework of double convergence, where hidden representations converge both over context and across layers. This double convergence process leads to an implicit bias towards smooth (low-frequency) representations, which we prove analytically and verify empirically. Our theory explains several open empirical observations, including why learned representations exhibit globally structured but locally distorted geometry, and why their total energy decays without vanishing. Moreover, our theory predicts that ICL has an intrinsic robustness towards high-frequency noise, which we empirically confirm. These results provide new insights into the underlying mechanisms of ICL, and a theoretical foundation to study it that hopefully extends to more general data distributions and settings.",
      "authors": [
        "Yongyi Yang",
        "Hidenori Tanaka",
        "Wei Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:19:32+00:00",
          "link": "https://arxiv.org/abs/2507.13540v1",
          "size": "373kb",
          "version": "v1"
        }
      ],
      "title": "Provable Low-Frequency Bias of In-Context Learning of Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13540",
        "HTML": "https://arxiv.org/html/2507.13540v1",
        "PDF": "https://arxiv.org/pdf/2507.13540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses in-context learning (ICL) in large language models and representation learning, it does not address any aspect of training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13541",
      "abstract": "Personalizing AI systems requires understanding not just what users prefer, but the reasons that underlie those preferences - yet current preference models typically treat human judgment as a black box. We introduce PrefPalette, a framework that decomposes preferences into attribute dimensions and tailors its preference prediction to distinct social community values in a human-interpretable manner. PrefPalette operationalizes a cognitive science principle known as multi-attribute decision making in two ways: (1) a scalable counterfactual attribute synthesis step that involves generating synthetic training data to isolate for individual attribute effects (e.g., formality, humor, cultural values), and (2) attention-based preference modeling that learns how different social communities dynamically weight these attributes. This approach moves beyond aggregate preference modeling to capture the diverse evaluation frameworks that drive human judgment. When evaluated on 45 social communities from the online platform Reddit, PrefPalette outperforms GPT-4o by 46.6% in average prediction accuracy. Beyond raw predictive improvements, PrefPalette also shed light on intuitive, community-specific profiles: scholarly communities prioritize verbosity and stimulation, conflict-oriented communities value sarcasm and directness, and support-based communities emphasize empathy. By modeling the attribute-mediated structure of human judgment, PrefPalette delivers both superior preference modeling and transparent, interpretable insights, and serves as a first step toward more trustworthy, value-aware personalized applications.",
      "authors": [
        "Shuyue Stella Li",
        "Melanie Sclar",
        "Hunter Lang",
        "Ansong Ni",
        "Jacqueline He",
        "Puxin Xu",
        "Andrew Cohen",
        "Chan Young Park",
        "Yulia Tsvetkov",
        "Asli Celikyilmaz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:21:54+00:00",
          "link": "https://arxiv.org/abs/2507.13541v1",
          "size": "1230kb",
          "version": "v1"
        }
      ],
      "title": "PrefPalette: Personalized Preference Modeling with Latent Attributes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13541",
        "HTML": "https://arxiv.org/html/2507.13541v1",
        "PDF": "https://arxiv.org/pdf/2507.13541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents PrefPalette for personalized preference modeling, involving the generation of synthetic training data for attribute effects. It covers data generation, but the main focus is on preference modeling rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13542",
      "abstract": "Traditional echocardiographic parameters such as ejection fraction (EF) and global longitudinal strain (GLS) have limitations in the early detection of cardiac dysfunction. EF often remains normal despite underlying pathology, and GLS is influenced by load conditions and vendor variability. There is a growing need for reproducible, interpretable, and operator-independent parameters that capture subtle and global cardiac functional alterations.\n  We introduce the Acoustic Index, a novel AI-derived echocardiographic parameter designed to quantify cardiac dysfunction from standard ultrasound views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on Koopman operator theory with a hybrid neural network that incorporates clinical metadata. Spatiotemporal dynamics are extracted from echocardiographic sequences to identify coherent motion patterns. These are weighted via attention mechanisms and fused with clinical data using manifold learning, resulting in a continuous score from 0 (low risk) to 1 (high risk).\n  In a prospective cohort of 736 patients, encompassing various cardiac pathologies and normal controls, the Acoustic Index achieved an area under the curve (AUC) of 0.89 in an independent test set. Cross-validation across five folds confirmed the robustness of the model, showing that both sensitivity and specificity exceeded 0.8 when evaluated on independent data. Threshold-based analysis demonstrated stable trade-offs between sensitivity and specificity, with optimal discrimination near this threshold.\n  The Acoustic Index represents a physics-informed, interpretable AI biomarker for cardiac function. It shows promise as a scalable, vendor-independent tool for early detection, triage, and longitudinal monitoring. Future directions include external validation, longitudinal studies, and adaptation to disease-specific classifiers.",
      "authors": [
        "Beka Begiashvili",
        "Carlos J. Fernandez-Candel",
        "Mat\\'ias P\\'erez Paredes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:27:28+00:00",
          "link": "https://arxiv.org/abs/2507.13542v1",
          "size": "346kb",
          "version": "v1"
        }
      ],
      "title": "Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13542",
        "HTML": "https://arxiv.org/html/2507.13542v1",
        "PDF": "https://arxiv.org/pdf/2507.13542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a novel AI parameter (Acoustic Index) for cardiac risk stratification using echocardiography, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13543",
      "abstract": "We develop a framework for dualizing the Kolmogorov structure function $h_x(\\alpha)$, which then allows using computable complexity proxies. We establish a mathematical analogy between information-theoretic constructs and statistical mechanics, introducing a suitable partition function and free energy functional. We explicitly prove the Legendre-Fenchel duality between the structure function and free energy, showing detailed balance of the Metropolis kernel, and interpret acceptance probabilities as information-theoretic scattering amplitudes. A susceptibility-like variance of model complexity is shown to peak precisely at loss-complexity trade-offs interpreted as phase transitions. Practical experiments with linear and tree-based regression models verify these theoretical predictions, explicitly demonstrating the interplay between the model complexity, generalization, and overfitting threshold.",
      "authors": [
        "Alexander Kolpakov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:31:45+00:00",
          "link": "https://arxiv.org/abs/2507.13543v1",
          "size": "1900kb",
          "version": "v1"
        }
      ],
      "title": "Loss-Complexity Landscape and Model Structure Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13543",
        "HTML": "https://arxiv.org/html/2507.13543v1",
        "PDF": "https://arxiv.org/pdf/2507.13543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the mathematical framework and complexity involved in modeling processes, but it does not address any aspect of LLM training data processing, data engineering operations, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13544",
      "abstract": "The analysis of conversational dynamics has gained increasing importance with the rise of large language model-based systems, which interact with users across diverse contexts. In this work, we propose a novel computational framework for constructing conversational graphs that capture the flow and structure of loosely organized dialogues, referred to as quasi-patterned conversations. We introduce the Filter & Reconnect method, a novel graph simplification technique that minimizes noise while preserving semantic coherence and structural integrity of conversational graphs. Through comparative analysis, we demonstrate that the use of large language models combined with our graph simplification technique has resulted in semantic metric S increasing by a factor of 2.06 compared to previous approaches while simultaneously enforcing a tree-like structure with 0 {\\delta}-hyperbolicity, ensuring optimal clarity in conversation modeling. This work provides a computational method for analyzing large-scale dialogue datasets, with practical applications related to monitoring automated systems such as chatbots, dialogue management tools, and user behavior analytics.",
      "authors": [
        "Mohamed Achref Ben Ammar and Mohamed Taha Bennani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:34:13+00:00",
          "link": "https://arxiv.org/abs/2507.13544v1",
          "size": "644kb",
          "version": "v1"
        }
      ],
      "title": "A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13544",
        "HTML": "https://arxiv.org/html/2507.13544v1",
        "PDF": "https://arxiv.org/pdf/2507.13544"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework for analyzing conversational systems using conversational graphs and a novel graph simplification technique. While it may have applications in dialogue dataset analysis, the focus is more on modeling and evaluation of conversational flows, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13546",
      "abstract": "Recent progress in transformer-based architectures has demonstrated remarkable success in video generation tasks. However, the quadratic complexity of full attention mechanisms remains a critical bottleneck, particularly for high-resolution and long-duration video sequences. In this paper, we propose NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that dynamically adapts to sparsity patterns in video diffusion transformers (DiTs). By leveraging block-wise attention with adaptive sparsity-driven threshold, NABLA reduces computational overhead while preserving generative quality. Our method does not require custom low-level operator design and can be seamlessly integrated with PyTorch's Flex Attention operator. Experiments demonstrate that NABLA achieves up to 2.7x faster training and inference compared to baseline almost without compromising quantitative metrics (CLIP score, VBench score, human evaluation score) and visual quality drop. The code and model weights are available here: https://github.com/gen-ai-team/Wan2.1-NABLA",
      "authors": [
        "Dmitrii Mikhailov",
        "Aleksey Letunovskiy",
        "Maria Kovaleva",
        "Vladimir Arkhipkin",
        "Vladimir Korviakov",
        "Vladimir Polovnikov",
        "Viacheslav Vasilev",
        "Evelina Sidorova",
        "Denis Dimitrov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:36:36+00:00",
          "link": "https://arxiv.org/abs/2507.13546v1",
          "size": "18325kb",
          "version": "v1"
        }
      ],
      "title": "$\\nabla$NABLA: Neighborhood Adaptive Block-Level Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13546",
        "HTML": "https://arxiv.org/html/2507.13546v1",
        "PDF": "https://arxiv.org/pdf/2507.13546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a novel attention mechanism for transformer-based architectures in video generation tasks and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13548",
      "abstract": "We present efficient decoding algorithms from square-root errors for two known families of double-circulant codes: A construction based on Sidon sets (Bhargava, Taveres, and Shiva, \\emph{IEEE IT 74}; Calderbank, \\emph{IEEE IT 83}; Guruswami and Li, \\emph{IEEE IT 2025}), and a construction based on cyclic codes (Chen, Peterson, and Weldon, \\emph{Information and Control 1969}). We further observe that the work of Guruswami and Li implicitly gives a transformation from double-circulant codes of certain block lengths to Wozencraft codes which preserves that distance of the codes, and we show that this transformation also preserves efficiency of decoding. By instantiating this transformation with the first family of double-circulant codes based on Sidon sets, we obtain an explicit construction of a Wozencraft code that is efficiently decodable from square-root errors. We also discuss limitations on instantiating this transformation with the second family of double-circulant codes based on cyclic codes.",
      "authors": [
        "Oren Dubin",
        "Noam Oz",
        "and Noga Ron-Zewi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:51:50+00:00",
          "link": "https://arxiv.org/abs/2507.13548v1",
          "size": "20kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Decoding of Double-circulant and Wozencraft Codes from Square-root Errors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13548",
        "HTML": "https://arxiv.org/html/2507.13548v1",
        "PDF": "https://arxiv.org/pdf/2507.13548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses efficient decoding algorithms for specific families of double-circulant and Wozencraft codes, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13549",
      "abstract": "This paper investigates the development of high-performance racing controllers for a newly implemented racing mode within the Xpilot-AI platform, utilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By leveraging NEAT's capability to evolve both the structure and weights of neural networks, we develop adaptive controllers that can navigate complex circuits under the challenging space simulation physics of Xpilot-AI, which includes elements such as inertia, friction, and gravity. The racing mode we introduce supports flexible circuit designs and allows for the evaluation of multiple agents in parallel, enabling efficient controller optimization across generations. Experimental results demonstrate that our evolved controllers achieve up to 32% improvement in lap time compared to the controller's initial performance and develop effective racing strategies, such as optimal cornering and speed modulation, comparable to human-like techniques. This work illustrates NEAT's effectiveness in producing robust control strategies within demanding game environments and highlights Xpilot-AI's potential as a rigorous testbed for competitive AI controller evolution.",
      "authors": [
        "Jim O'Connor",
        "Nicholas Lorentzen",
        "Gary B. Parker",
        "Derin Gezgin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:53:08+00:00",
          "link": "https://arxiv.org/abs/2507.13549v1",
          "size": "483kb",
          "version": "v1"
        }
      ],
      "title": "Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13549",
        "HTML": "https://arxiv.org/html/2507.13549v1",
        "PDF": "https://arxiv.org/pdf/2507.13549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the use of NEAT to develop adaptive neural controllers for a racing game environment, which does not involve LLM training data processing or related data engineering activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13550",
      "abstract": "The development of large language models (LLMs) has successfully transformed knowledge-based systems such as open domain question nswering, which can automatically produce vast amounts of seemingly coherent information. Yet, those models have several disadvantages like hallucinations or confident generation of incorrect or unverifiable facts. In this paper, we introduce a new approach to the development of expert systems using LLMs in a controlled and transparent way. By limiting the domain and employing a well-structured prompt-based extraction approach, we produce a symbolic representation of knowledge in Prolog, which can be validated and corrected by human experts. This approach also guarantees interpretability, scalability and reliability of the developed expert systems. Via quantitative and qualitative experiments with Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic coherence on our generated knowledge bases. We present a transparent hybrid solution that combines the recall capacity of LLMs with the precision of symbolic systems, thereby laying the foundation for dependable AI applications in sensitive domains.",
      "authors": [
        "Eduardo C. Garrido-Merch\\'an",
        "Cristina Puente"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:57:37+00:00",
          "link": "https://arxiv.org/abs/2507.13550v1",
          "size": "1819kb",
          "version": "v1"
        }
      ],
      "title": "GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13550",
        "HTML": "https://arxiv.org/html/2507.13550v1",
        "PDF": "https://arxiv.org/pdf/2507.13550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing expert systems using LLMs with a symbolic representation approach, but it does not involve any training data processing operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13551",
      "abstract": "Formal thought disorder (FTD), a hallmark of schizophrenia spectrum disorders, manifests as incoherent speech and poses challenges for clinical assessment. Traditional clinical rating scales, though validated, are resource-intensive and lack scalability. Automated speech analysis with automatic speech recognition (ASR) allows for objective quantification of linguistic and temporal features of speech, offering scalable alternatives. The use of utterance timestamps in ASR captures pause dynamics, which are thought to reflect the cognitive processes underlying speech production. However, the utility of integrating these ASR-derived features for assessing FTD severity requires further evaluation. This study integrates pause features with semantic coherence metrics across three datasets: naturalistic self-recorded diaries (AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream narratives (PsyCL, n = 43). We evaluated pause related features alongside established coherence measures, using support vector regression (SVR) to predict clinical FTD scores. Key findings demonstrate that pause features alone robustly predict the severity of FTD. Integrating pause features with semantic coherence metrics enhanced predictive performance compared to semantic-only models, with integration of independent models achieving correlations up to \\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best \\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance gains from semantic and pause features integration held consistently across all contexts, though the nature of pause patterns was dataset-dependent. These findings suggest that frameworks combining temporal and semantic analyses provide a roadmap for refining the assessment of disorganized speech and advance automated speech analysis in psychosis.",
      "authors": [
        "Feng Chen",
        "Weizhe Xu",
        "Changye Li",
        "Serguei Pakhomov",
        "Alex Cohen",
        "Simran Bhola",
        "Sandy Yin",
        "Sunny X Tang",
        "Michael Mackinley",
        "Lena Palaniyappan",
        "Dror Ben-Zeev",
        "Trevor Cohen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T22:00:16+00:00",
          "link": "https://arxiv.org/abs/2507.13551v1",
          "size": "738kb",
          "version": "v1"
        }
      ],
      "title": "Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13551",
        "PDF": "https://arxiv.org/pdf/2507.13551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with automated speech analysis and formal thought disorder assessment; it does not address training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13553",
      "abstract": "As user demands evolve, effectively incorporating feature requests is crucial for maintaining software relevance and user satisfaction. Feature requests, typically expressed in natural language, often suffer from ambiguity or incomplete information due to communication gaps or the requester's limited technical expertise. These issues can lead to misinterpretation, faulty implementation, and reduced software quality. While seeking clarification from requesters is a common strategy to mitigate these risks, little is known about how developers engage in this clarification process in practice-how they formulate clarifying questions, seek technical or contextual details, align on goals and use cases, or decide to close requests without attempting clarification. This study investigates how feature requests are prone to NL defects (i.e. ambiguous or incomplete) and the conversational dynamics of clarification in open-source software (OSS) development, aiming to understand how developers handle ambiguous or incomplete feature requests. Our findings suggest that feature requests published on the OSS platforms do possess ambiguity and incompleteness, and in some cases, both. We also find that explicit clarification for the resolution of these defects is uncommon; developers usually focus on aligning with project goals rather than resolving unclear text. When clarification occurs, it emphasizes understanding user intent/goal and feasibility, rather than technical details. By characterizing the dynamics of clarification in open-source issue trackers, this work identifies patterns that can improve user-developer collaboration and inform best practices for handling feature requests effectively.",
      "authors": [
        "Pragyan K C",
        "Rambod Ghandiparsi",
        "Thomas Herron",
        "John Heaps",
        "Mitra Bokaei Hosseini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T22:04:29+00:00",
          "link": "https://arxiv.org/abs/2507.13553v1",
          "size": "510kb",
          "version": "v1"
        }
      ],
      "title": "Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13553",
        "HTML": "https://arxiv.org/html/2507.13553v1",
        "PDF": "https://arxiv.org/pdf/2507.13553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates handling feature requests and conversational dynamics in OSS development, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13555",
      "abstract": "The growing popularity and widespread use of software applications (apps) across various domains have driven rapid industry growth. Along with this growth, fast-paced market changes have led to constantly evolving software requirements. Such requirements are often grounded in feature requests and enhancement suggestions, typically provided by users in natural language (NL). However, these requests often suffer from defects such as ambiguity and incompleteness, making them challenging to interpret. Traditional validation methods (e.g., interviews and workshops) help clarify such defects but are impractical in decentralized environments like open-source software (OSS), where change requests originate from diverse users on platforms like GitHub. This paper proposes a novel approach leveraging Large Language Models (LLMs) to detect and refine NL defects in feature requests. Our approach automates the identification of ambiguous and incomplete requests and generates clarification questions (CQs) to enhance their usefulness for developers. To evaluate its effectiveness, we apply our method to real-world OSS feature requests and compare its performance against human annotations. In addition, we conduct interviews with GitHub developers to gain deeper insights into their perceptions of NL defects, the strategies they use to address these defects, and the impact of defects on downstream software engineering (SE) tasks.",
      "authors": [
        "Pragyan K C",
        "Rambod Ghandiparsi",
        "Thomas Herron",
        "John Heaps",
        "Mitra Bokaei Hosseini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T22:16:13+00:00",
          "link": "https://arxiv.org/abs/2507.13555v1",
          "size": "699kb",
          "version": "v1"
        }
      ],
      "title": "Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13555",
        "HTML": "https://arxiv.org/html/2507.13555v1",
        "PDF": "https://arxiv.org/pdf/2507.13555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes using LLMs to refine feature requests in OSS by detecting and clarifying NL defects. While it involves processing textual data, it is not primarily focused on LLM training data processing but rather application of LLMs for NL defect identification."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13556",
      "abstract": "This paper proposes using two metrics to quantify the forecastability of time series prior to model development: the spectral predictability score and the largest Lyapunov exponent. Unlike traditional model evaluation metrics, these measures assess the inherent forecastability characteristics of the data before any forecast attempts. The spectral predictability score evaluates the strength and regularity of frequency components in the time series, whereas the Lyapunov exponents quantify the chaos and stability of the system generating the data. We evaluated the effectiveness of these metrics on both synthetic and real-world time series from the M5 forecast competition dataset. Our results demonstrate that these two metrics can correctly reflect the inherent forecastability of a time series and have a strong correlation with the actual forecast performance of various models. By understanding the inherent forecastability of time series before model training, practitioners can focus their planning efforts on products and supply chain levels that are more forecastable, while setting appropriate expectations or seeking alternative strategies for products with limited forecastability.",
      "authors": [
        "Rui Wang",
        "Steven Klee",
        "Alexis Roos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T22:23:51+00:00",
          "link": "https://arxiv.org/abs/2507.13556v1",
          "size": "2037kb",
          "version": "v1"
        }
      ],
      "title": "Time Series Forecastability Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13556",
        "HTML": "https://arxiv.org/html/2507.13556v1",
        "PDF": "https://arxiv.org/pdf/2507.13556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes two metrics for assessing the forecastability of time series data and does not engage with language model training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13558",
      "abstract": "AI seems to be taking over the world with systems that model pixels, words, and phonemes. The world is arguably made up, not of pixels, words, and phonemes but of entities (objects, things, including events) with properties and relations among them. Surely we should model these, not the perception or description of them. You might suspect that concentrating on modeling words and pixels is because all of the (valuable) data in the world is in terms of text and images. If you look into almost any company you will find their most valuable data is in spreadsheets, databases and other relational formats. These are not the form that are studied in introductory machine learning, but are full of product numbers, student numbers, transaction numbers and other identifiers that can't be interpreted naively as numbers. The field that studies this sort of data has various names including relational learning, statistical relational AI, and many others. This paper explains why relational learning is not taking over the world -- except in a few cases with restricted relations -- and what needs to be done to bring it to it's rightful prominence.",
      "authors": [
        "David Poole"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T22:32:07+00:00",
          "link": "https://arxiv.org/abs/2507.13558v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Why Isn't Relational Learning Taking Over the World?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13558",
        "HTML": "https://arxiv.org/html/2507.13558v1",
        "PDF": "https://arxiv.org/pdf/2507.13558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses relational learning versus perceptive modeling (like text and image modeling) but does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13563",
      "abstract": "Russian speech synthesis presents distinctive challenges, including vowel reduction, consonant devoicing, variable stress patterns, homograph ambiguity, and unnatural intonation. This paper introduces Balalaika, a novel dataset comprising more than 2,000 hours of studio-quality Russian speech with comprehensive textual annotations, including punctuation and stress markings. Experimental results show that models trained on Balalaika significantly outperform those trained on existing datasets in both speech synthesis and enhancement tasks. We detail the dataset construction pipeline, annotation methodology, and results of comparative evaluations.",
      "authors": [
        "Kirill Borodin and Nikita Vasiliev and Vasiliy Kudryavtsev and Maxim Maslov and Mikhail Gorodnichev and Oleg Rogov and Grach Mkrtchian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T22:41:40+00:00",
          "link": "https://arxiv.org/abs/2507.13563v1",
          "size": "122kb",
          "version": "v1"
        }
      ],
      "title": "A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13563",
        "HTML": "https://arxiv.org/html/2507.13563v1",
        "PDF": "https://arxiv.org/pdf/2507.13563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a new dataset, Balalaika, with 2,000 hours of annotated Russian speech, which enhances model training for speech synthesis and addresses specific phonetic and prosodic challenges, making it core to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13568",
      "abstract": "Continual learning for vision-language models has achieved remarkable performance through synthetic replay, where samples are generated using Stable Diffusion to regularize during finetuning and retain knowledge. However, real-world downstream applications often exhibit domain-specific nuances and fine-grained semantics not captured by generators, causing synthetic-replay methods to produce misaligned samples that misguide finetuning and undermine retention of prior knowledge. In this work, we propose a LoRA-enhanced synthetic-replay framework that injects task-specific low-rank adapters into a frozen Stable Diffusion model, efficiently capturing each new task's unique visual and semantic patterns. Specifically, we introduce a two-stage, confidence-based sample selection: we first rank real task data by post-finetuning VLM confidence to focus LoRA finetuning on the most representative examples, then generate synthetic samples and again select them by confidence for distillation. Our approach integrates seamlessly with existing replay pipelines-simply swap in the adapted generator to boost replay fidelity. Extensive experiments on the Multi-domain Task Incremental Learning (MTIL) benchmark show that our method outperforms previous synthetic-replay techniques, achieving an optimal balance among plasticity, stability, and zero-shot capability. These results demonstrate the effectiveness of generator adaptation via LoRA for robust continual learning in VLMs.",
      "authors": [
        "Kaihong Wang",
        "Donghyun Kim",
        "Margrit Betke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:08:29+00:00",
          "link": "https://arxiv.org/abs/2507.13568v1",
          "size": "2816kb",
          "version": "v1"
        }
      ],
      "title": "LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13568",
        "HTML": "https://arxiv.org/html/2507.13568v1",
        "PDF": "https://arxiv.org/pdf/2507.13568"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a method for continual learning in vision-language models using synthetic replay, it mainly focuses on model adaptation rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13569",
      "abstract": "Transformers evaluated in a single, fixed-depth pass are provably limited in expressive power to the constant-depth circuit class TC0. Running a Transformer autoregressively removes that ceiling -- first in next-token prediction and, more recently, in chain-of-thought reasoning. Both regimes rely on feedback loops that decode internal states into tokens only to re-encode them in subsequent steps. While this \"thinking aloud\" mirrors human reasoning, biological brains iterate without externalising intermediate states as language. To boost the expressive power of encoder Transformers without resorting to token-level autoregression, we introduce the SELF-Transformer: an encoder layer that iteratively refines its own attention weights to a fixed point. Instead of producing -- in one pass -- the alignment matrix that remixes the input sequence, the SELF-Transformer iteratively updates that matrix internally, scaling test-time computation with input difficulty. This adaptivity yields up to 20\\% accuracy gains on encoder-style benchmarks without increasing parameter count, demonstrating that input-adaptive alignment at test time offers substantial benefits for only a modest extra compute budget. Self-Transformers thus recover much of the expressive power of iterative reasoning while preserving the simplicity of pure encoder architectures.",
      "authors": [
        "Mrinal Mathur",
        "Mike Doan",
        "Barak Pearlmutter",
        "Sergey Plis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:12:57+00:00",
          "link": "https://arxiv.org/abs/2507.13569v1",
          "size": "1123kb",
          "version": "v1"
        }
      ],
      "title": "Change of Thought: Adaptive Test-Time Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13569",
        "HTML": "https://arxiv.org/html/2507.13569v1",
        "PDF": "https://arxiv.org/pdf/2507.13569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a new approach to Transformer computation for enhanced expressive power, but it does not touch upon training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13572",
      "abstract": "Audio-based music structure analysis (MSA) is an essential task in Music Information Retrieval that remains challenging due to the complexity and variability of musical form. Recent advances highlight the potential of fine-tuning pre-trained music foundation models for MSA tasks. However, these models are typically trained with high temporal feature resolution and short audio windows, which limits their efficiency and introduces bias when applied to long-form audio. This paper presents a temporal adaptation approach for fine-tuning music foundation models tailored to MSA. Our method enables efficient analysis of full-length songs in a single forward pass by incorporating two key strategies: (1) audio window extension and (2) low-resolution adaptation. Experiments on the Harmonix Set and RWC-Pop datasets show that our method significantly improves both boundary detection and structural function prediction, while maintaining comparable memory usage and inference speed.",
      "authors": [
        "Yixiao Zhang",
        "Haonan Chen",
        "Ju-Chiang Wang",
        "Jitong Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:25:58+00:00",
          "link": "https://arxiv.org/abs/2507.13572v1",
          "size": "748kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Adaptation of Pre-trained Foundation Models for Music Structure Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13572",
        "HTML": "https://arxiv.org/html/2507.13572v1",
        "PDF": "https://arxiv.org/pdf/2507.13572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on music structure analysis and proposes a temporal adaptation for music foundation models, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13575",
      "abstract": "We introduce two multilingual, multimodal foundation language models that power Apple Intelligence features across Apple devices and services: i a 3B-parameter on-device model optimized for Apple silicon through architectural innovations such as KV-cache sharing and 2-bit quantization-aware training; and ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts PT-MoE transformer that combines track parallelism, mixture-of-experts sparse computation, and interleaved global-local attention to deliver high quality with competitive cost on Apple's Private Cloud Compute platform. Both models are trained on large-scale multilingual and multimodal datasets sourced via responsible web crawling, licensed corpora, and high-quality synthetic data, then further refined with supervised fine-tuning and reinforcement learning on a new asynchronous platform. The resulting models support several additional languages while understanding images and executing tool calls. In public benchmarks and human evaluations, both the server model and the on-device model match or surpass comparably sized open baselines.\n  A new Swift-centric Foundation Models framework exposes guided generation, constrained tool calling, and LoRA adapter fine-tuning, allowing developers to integrate these capabilities with a few lines of code. The latest advancements in Apple Intelligence models are grounded in our Responsible AI approach with safeguards like content filtering and locale-specific evaluation, as well as our commitment to protecting our users' privacy with innovations like Private Cloud Compute.",
      "authors": [
        "Hanzhi Zhou",
        "Erik Hornberger",
        "Pengsheng Guo",
        "Xiyou Zhou",
        "Saiwen Wang",
        "Xin Wang",
        "Yifei He",
        "Xuankai Chang",
        "Rene Rauch",
        "Louis D'hauwe",
        "John Peebles",
        "Alec Doane",
        "Kohen Chia",
        "Jenna Thibodeau",
        "Zi-Yi Dou",
        "Yuanyang Zhang",
        "Ruoming Pang",
        "Reed Li",
        "Zhifeng Chen",
        "Jeremy Warner",
        "Zhaoyang Xu",
        "Sophy Lee",
        "David Mizrahi",
        "Ramsey Tantawi",
        "Chris Chaney",
        "Kelsey Peterson",
        "Jun Qin",
        "Alex Dombrowski",
        "Mira Chiang",
        "Aiswarya Raghavan",
        "Gerard Casamayor",
        "Qibin Chen",
        "Aonan Zhang",
        "Nathalie Tran",
        "Jianyu Wang",
        "Hang Su",
        "Thomas Voice",
        "Alessandro Pappalardo",
        "Brycen Wershing",
        "Prasanth Yadla",
        "Rui Li",
        "Priyal Chhatrapati",
        "Ismael Fernandez",
        "Yusuf Goren",
        "Xin Zheng",
        "Forrest Huang",
        "Tao Lei",
        "Eray Yildiz",
        "Alper Kokmen",
        "Gokul Santhanam",
        "Areeba Kamal",
        "Kaan Elgin",
        "Dian Ang Yap",
        "Jeremy Liu",
        "Peter Gray",
        "Howard Xing",
        "Kieran Liu",
        "Matteo Ronchi",
        "Moritz Schwarzer-Becker",
        "Yun Zhu",
        "Mandana Saebi",
        "Jeremy Snow",
        "David Griffiths",
        "Guillaume Tartavel",
        "Erin Feldman",
        "Simon Lehnerer",
        "Fernando Berm\\'udez-Medina",
        "Hans Han",
        "Joe Zhou",
        "Xiaoyi Ren",
        "Sujeeth Reddy",
        "Zirui Wang",
        "Tom Gunter",
        "Albert Antony",
        "Yuanzhi Li",
        "John Dennison",
        "Tony Sun",
        "Yena Han",
        "Yi Qin",
        "Sam Davarnia",
        "Jeffrey Bigham",
        "Wayne Shan",
        "Hannah Gillis Coleman",
        "Guillaume Klein",
        "Peng Liu",
        "Muyang Yu",
        "Jack Cackler",
        "Yuan Gao",
        "Crystal Xiao",
        "Binazir Karimzadeh",
        "Zhengdong Zhang",
        "Felix Bai",
        "Albin Madappally Jose",
        "Feng Nan",
        "Nazir Kamaldin",
        "Dong Yin",
        "Hans Hao",
        "Yanchao Sun",
        "Yi Hua",
        "Charles Maalouf",
        "Alex Guillen Garcia",
        "Guoli Yin",
        "Lezhi Li",
        "Mohana Prasad Sathya Moorthy",
        "Hongbin Gao",
        "Jay Tang",
        "Joanna Arreaza-Taylor",
        "Faye Lao",
        "Carina Peng",
        "Josh Shaffer",
        "Dan Masi",
        "Sushma Rao",
        "Tommi Vehvilainen",
        "Senyu Tong",
        "Dongcai Shen",
        "Yang Zhao",
        "Chris Bartels",
        "Peter Fu",
        "Qingqing Cao",
        "Christopher Neubauer",
        "Ethan Li",
        "Mingfei Gao",
        "Rebecca Callahan",
        "Richard Wei",
        "Patrick Dong",
        "Alex Braunstein",
        "Sachin Ravi",
        "Adolfo Lopez Mendez",
        "Kaiwei Huang",
        "Kun Duan",
        "Haoshuo Huang",
        "Rui Qian",
        "Stefano Ligas",
        "Jordan Huffaker",
        "Dongxu Li",
        "Bailin Wang",
        "Nanzhu Wang",
        "Anuva Agarwal",
        "Tait Madsen",
        "Josh Newnham",
        "Abhishek Sharma",
        "Zhile Ren",
        "Deepak Gopinath",
        "Erik Daxberger",
        "Saptarshi Guha",
        "Oron Levy",
        "Jing Lu",
        "Nan Dun",
        "Marc Kirchner",
        "Yinfei Yang",
        "Manjot Bilkhu",
        "Dave Nelson",
        "Anthony Spalvieri-Kruse",
        "Juan Lao Tebar",
        "Yang Xu",
        "Phani Mutyala",
        "Gabriel Jacoby-Cooper",
        "Yingbo Wang",
        "Karla Vega",
        "Vishaal Mahtani",
        "Darren Botten",
        "Eric Wang",
        "Hanli Li",
        "Matthias Paulik",
        "Haoran Yan",
        "Navid Shiee",
        "Yihao Qian",
        "Bugu Wu",
        "Qi Zhu",
        "Ob Adaranijo",
        "Bhuwan Dhingra",
        "Zhe Gan",
        "Nicholas Seidl",
        "Grace Duanmu",
        "Rong Situ",
        "Yiping Ma",
        "Yin Xia",
        "David Riazati",
        "Vasileios Saveris",
        "Anh Nguyen",
        "Michael (Taoyi) Lee",
        "Patrick Sonnenberg",
        "Chinguun Erdenebileg",
        "Yanghao Li",
        "Vivian Ma",
        "James Chou",
        "Isha Garg",
        "Mark Lee",
        "Keen You",
        "Yuhong Li",
        "Ransen Niu",
        "Nandhitha Raghuram",
        "Pulkit Agrawal",
        "Henry Mason",
        "Sumeet Singh",
        "Keyu He",
        "Hong-You Chen",
        "Lucas Guibert",
        "Shiyu Li",
        "Varsha Paidi",
        "Narendran Raghavan",
        "Mingze Xu",
        "Yuli Yang",
        "Sergiu Sima",
        "Irina Belousova",
        "Sprite Chu",
        "Afshin Dehghan",
        "Philipp Dufter",
        "David Haldimann",
        "Zhen Yang",
        "Margit Bowler",
        "Chang Liu",
        "Ying-Chang Cheng",
        "Vivek Rathod",
        "Syd Evans",
        "Wilson Tsao",
        "Dustin Withers",
        "Haitian Sun",
        "Biyao Wang",
        "Peter Grasch",
        "Walker Cheng",
        "Yihao Feng",
        "Vivek Kumar",
        "Frank Chu",
        "Victoria M\\\"onchJuan Haladjian",
        "Doug Kang",
        "Jiarui Lu",
        "Ciro Sannino",
        "Max Lam",
        "Floris Weers",
        "Bowen Pan",
        "Kenneth Jung",
        "Dhaval Doshi",
        "Fangping Shi",
        "Olli Saarikivi",
        "Alp Aygar",
        "Josh Elman",
        "Cheng Leong",
        "Eshan Verma",
        "Matthew Lei",
        "Jeff Nichols",
        "Jiulong Shan",
        "Donald Zhang",
        "Lawrence Zhou",
        "Stephen Murphy",
        "Xianzhi Du",
        "Chang Lan",
        "Ankur Jain",
        "Elmira Amirloo",
        "Marcin Eichner",
        "Naomy Sabo",
        "Anupama Mann Anupama",
        "David Qiu",
        "Zhao Meng",
        "Michael FitzMaurice",
        "Peng Zhang",
        "Simon Yeung",
        "Chen Chen",
        "Marco Zuliani",
        "Andrew Hansen",
        "Yang Lu",
        "Brent Ramerth",
        "Ziyi Zhong",
        "Parsa Mazaheri",
        "Matthew Hopkins",
        "Mengyu Li",
        "Simon Wang",
        "David Chen",
        "Farzin Rasteh",
        "Chong Wang",
        "Josh Gardner",
        "Asaf Liberman",
        "Haoxuan You",
        "Andrew Walkingshaw",
        "Xingyu Zhou",
        "Jinhao Lei",
        "Yan Meng",
        "Quentin Keunebroek",
        "Sam Wiseman",
        "Anders Boesen Lindbo Larsen",
        "Yi Zhang",
        "Zaid Ahmed",
        "Haiming Gang",
        "Aaron Franklin",
        "Kelvin Zou",
        "Guillaume Seguin",
        "Jonathan Janke",
        "Rachel Burger",
        "Co Giang",
        "Cheng Shen",
        "Jen Liu",
        "Sanskruti Shah",
        "Xiang Kong",
        "Yiran Fei",
        "TJ Collins",
        "Chen Zhang",
        "Zhiyun Lu",
        "Michael Booker",
        "Qin Ba",
        "Yasutaka Tanaka",
        "Andres Romero Mier Y Teran",
        "Federico Scozzafava",
        "Regan Poston",
        "Jane Li",
        "Eduardo Jimenez",
        "Bas Straathof",
        "Karanjeet Singh",
        "Lindsay Hislop",
        "Rajat Arora",
        "Deepa Seshadri",
        "Boyue Li",
        "Colorado Reed",
        "Zhen Li",
        "TJ Lu",
        "Yi Wang",
        "Kaelen Haag",
        "Nicholas Lusskin",
        "Raunak Sinha",
        "Rahul Nair",
        "Eldon Schoop",
        "Mary Beth Kery",
        "Mehrdad Farajtbar",
        "Brenda Yang",
        "George Horrell",
        "Shiwen Zhao",
        "Dhruti Shah",
        "Cha Chen",
        "Bowen Zhang",
        "Chang Gao",
        "Devi Krishna",
        "Jennifer Mallalieu",
        "Javier Movellan",
        "Di Feng",
        "Emily Zhang",
        "Sam Xu",
        "Junting Pan",
        "Dominik Moritz",
        "Suma Jayaram",
        "Kevin Smith",
        "Dongseong Hwang",
        "Daniel Parilla",
        "Jiaming Hu",
        "You-Cyuan Jhang",
        "Emad Soroush",
        "Fred Hohman",
        "Nan Du",
        "Emma Wang",
        "Sam Dodge",
        "Pragnya Sridhar",
        "Joris Pelemans",
        "Wei Fang",
        "Nina Wenzel",
        "Joseph Yitan Cheng",
        "Hadas Kotek",
        "Chung-Cheng Chiu",
        "Meng Cao",
        "Haijing Fu",
        "Ruixuan Hou",
        "Ke Ye",
        "Diane Zhu",
        "Nikhil Bhendawade",
        "Joseph Astrauskas",
        "Jian Liu",
        "Sai Aitharaju",
        "Wentao Wu",
        "Artsiom Peshko",
        "Hyunjik Kim",
        "Nilesh Shahdadpuri",
        "Andy De Wang",
        "Qi Shan",
        "Piotr Maj",
        "Raul Rea Menacho",
        "Justin Lazarow",
        "Eric Liang Yang",
        "Arsalan Farooq",
        "Donghan Yu",
        "David G\\\"uera",
        "Minsik Cho",
        "Kavya Nerella",
        "Yongqiang Wang",
        "Tao Jia",
        "John Park",
        "Jeff Lai",
        "Haotian Zhang",
        "Futang Peng",
        "Daniele Molinari",
        "Aparna Rajamani",
        "Tyler Johnson",
        "Lauren Gardiner",
        "Chao Jia",
        "Violet Yao",
        "Wojciech Kryscinski",
        "Xiujun Li",
        "Shang-Chen Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:37:19+00:00",
          "link": "https://arxiv.org/abs/2507.13575v1",
          "size": "966kb",
          "version": "v1"
        }
      ],
      "title": "Apple Intelligence Foundation Language Models: Tech Report 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13575",
        "HTML": "https://arxiv.org/html/2507.13575v1",
        "PDF": "https://arxiv.org/pdf/2507.13575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper describes multilingual and multimodal datasets used for training models, the main focus is on model architecture and features across Apple devices, not on specific techniques for training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13576",
      "abstract": "This paper characterizes when one axiomatic theory, as a proof system for tautologies, $p$-simulates another, by showing: (i)~if c.e. theory $\\mathcal{S}$ efficiently interprets $\\mathcal{S}{+}\\phi$, then $\\mathcal{S}$ $p$-simulates $\\mathcal{S}{+}\\phi$ (Je\\v{r}\\'abek in Pudl\\'ak17 proved simulation), since the interpretation maps an $\\mathcal{S}{+}\\phi$-proof whose lines are all theorems into an $\\mathcal{S}$-proof; (ii)~$\\mathcal{S}$ proves ``$\\mathcal{S}$ efficiently interprets $\\mathcal{S}{+}\\phi$'' iff $\\mathcal{S}$ proves ``$\\mathcal{S}$ $p$-simulates $\\mathcal{S}{+}\\phi$'' (if so, $\\mathcal{S}$ already proves the $\\Pi_1$ theorems of $\\mathcal{S}{+}\\phi$); and (iii)~no $\\mathcal{S}$ $p$-simulates all theories. Result (iii) implies $\\textbf{P}{\\neq}\\textbf{NP}{\\neq}\\textbf{coNP}$, using the nonrelativizing fact ``no c.e. theory interprets all c.e. theories'' (false for $\\mathcal{S}$ with predicate for true sentences). To explore whether this framework resolves other open questions, the paper formulates conjectures stronger than ``no optimal proof system exists'' that imply Feige's Hypothesis, the existence of one-way functions, and circuit lower bounds.",
      "authors": [
        "Hunter Monroe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:39:44+00:00",
          "link": "https://arxiv.org/abs/2507.13576v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "Characterizing p-Simulation Between Theories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13576",
        "HTML": "https://arxiv.org/html/2507.13576v1",
        "PDF": "https://arxiv.org/pdf/2507.13576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with theoretical aspects of proof systems and simulations between different axiomatic theories, not with LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13577",
      "abstract": "We represent interdependent infrastructure systems and communities alike with a hetero-functional graph (HFG) that encodes the dependencies between functionalities. This graph naturally imposes a partial order of functionalities that can inform the sequence of repair decisions to be made during a disaster across affected communities. However, using such technical criteria alone provides limited guidance at the point where the functionalities directly impact the communities, since these can be repaired in any order without violating the system constraints. To address this gap and improve resilience, we integrate community preferences to refine this partial order from the HFG into a total order. Our strategy involves getting the communities' opinions on their preferred sequence for repair crews to address infrastructure issues, considering potential constraints on resources. Due to the delay and cost associated with real-world survey data, we utilize a Large Language Model (LLM) as a proxy survey tool. We use the LLM to craft distinct personas representing individuals, each with varied disaster experiences. We construct diverse disaster scenarios, and each simulated persona provides input on prioritizing infrastructure repair needs across various communities. Finally, we apply learning algorithms to generate a global order based on the aggregated responses from these LLM-generated personas.",
      "authors": [
        "Adaeze Okeukwu-Ogbonnaya",
        "Rahul Amatapu",
        "Jason Bergtold and George Amariucai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:43:22+00:00",
          "link": "https://arxiv.org/abs/2507.13577v1",
          "size": "639kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Based Community Surveys for Operational Decision Making in Interconnected Utility Infrastructures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13577",
        "HTML": "https://arxiv.org/html/2507.13577v1",
        "PDF": "https://arxiv.org/pdf/2507.13577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper uses a Large Language Model as a proxy survey tool to generate synthetic data representing community opinions for decision-making purposes, which contributes to the area of data generation in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13578",
      "abstract": "Individual cognitive stimulation therapy (iCST) is a non-pharmacological intervention for improving the cognition and quality of life of persons with dementia (PwDs); however, its effectiveness is limited by low adherence to delivery by their family members. In this work, we present the user-centered design and evaluation of a novel socially assistive robotic system to provide iCST therapy to PwDs in their homes for long-term use. We consulted with 16 dementia caregivers and professionals. Through these consultations, we gathered design guidelines and developed the prototype. The prototype was validated by testing it with three dementia professionals and five PwDs. The evaluation revealed PwDs enjoyed using the system and are willing to adopt its use over the long term. One shortcoming was the system's speech-to-text capabilities, where it frequently failed to understand the PwDs.",
      "authors": [
        "Emmanuel Akinrintoyo and Nicole Salomons"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:48:09+00:00",
          "link": "https://arxiv.org/abs/2507.13578v1",
          "size": "3393kb",
          "version": "v1"
        }
      ],
      "title": "In-Home Social Robots Design for Cognitive Stimulation Therapy in Dementia Care",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13578",
        "HTML": "https://arxiv.org/html/2507.13578v1",
        "PDF": "https://arxiv.org/pdf/2507.13578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing a robotic system for cognitive stimulation therapy, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13579",
      "abstract": "As everyday use cases of large language model (LLM) AI assistants have expanded, it is becoming increasingly important to personalize responses to align to different users' preferences and goals. While reinforcement learning from human feedback (RLHF) is effective at improving LLMs to be generally more helpful and fluent, it does not account for variability across users, as it models the entire user population with a single reward model. We present a novel framework, Preference Learning Using Summarization (PLUS), that learns text-based summaries of each user's preferences, characteristics, and past conversations. These summaries condition the reward model, enabling it to make personalized predictions about the types of responses valued by each user. We train the user-summarization model with reinforcement learning, and update the reward model simultaneously, creating an online co-adaptation loop. We show that in contrast with prior personalized RLHF techniques or with in-context learning of user information, summaries produced by PLUS capture meaningful aspects of a user's preferences. Across different pluralistic user datasets, we show that our method is robust to new users and diverse conversation topics. Additionally, we demonstrate that the textual summaries generated about users can be transferred for zero-shot personalization of stronger, proprietary models like GPT-4. The resulting user summaries are not only concise and portable, they are easy for users to interpret and modify, allowing for more transparency and user control in LLM alignment.",
      "authors": [
        "Hyunji Nam",
        "Yanming Wan",
        "Mickel Liu",
        "Jianxun Lian",
        "Natasha Jaques"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:48:51+00:00",
          "link": "https://arxiv.org/abs/2507.13579v1",
          "size": "124kb",
          "version": "v1"
        }
      ],
      "title": "Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13579",
        "HTML": "https://arxiv.org/html/2507.13579v1",
        "PDF": "https://arxiv.org/pdf/2507.13579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Preference Learning Using Summarization (PLUS) for personalization in LLMs but focuses mainly on improving model alignment using reinforcement learning, not training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13586",
      "abstract": "Advancements in volume visualization (VolVis) focus on extracting insights from 3D volumetric data by generating visually compelling renderings that reveal complex internal structures. Existing VolVis approaches have explored non-photorealistic rendering techniques to enhance the clarity, expressiveness, and informativeness of visual communication. While effective, these methods often rely on complex predefined rules and are limited to transferring a single style, restricting their flexibility. To overcome these limitations, we advocate the representation of VolVis scenes using differentiable Gaussian primitives combined with pretrained large models to enable arbitrary style transfer and real-time rendering. However, conventional 3D Gaussian primitives tightly couple geometry and appearance, leading to suboptimal stylization results. To address this, we introduce TexGS-VolVis, a textured Gaussian splatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives, extending each Gaussian with additional texture and shading attributes, resulting in higher-quality, geometry-consistent stylization and enhanced lighting control during inference. Despite these improvements, achieving flexible and controllable scene editing remains challenging. To further enhance stylization, we develop image- and text-driven non-photorealistic scene editing tailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing with fine-grained control. We evaluate TexGS-VolVis both qualitatively and quantitatively across various volume rendering scenes, demonstrating its superiority over existing methods in terms of efficiency, visual quality, and editing flexibility.",
      "authors": [
        "Kaiyuan Tang",
        "Kuangshi Ai",
        "Jun Han",
        "and Chaoli Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T00:14:27+00:00",
          "link": "https://arxiv.org/abs/2507.13586v1",
          "size": "41932kb",
          "version": "v1"
        }
      ],
      "title": "TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13586",
        "HTML": "https://arxiv.org/html/2507.13586v1",
        "PDF": "https://arxiv.org/pdf/2507.13586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on volume visualization and leveraging pretrained models for style transfer and scene editing, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13589",
      "abstract": "Over 140 million people worldwide and over 45 million people in the United states wear contact lenses; it is estimated 12%-27.4% contact lens users stop wearing them due to discomfort. Contact lens mechanical interactions with the ocular surface have been found to affect the ocular surface. The mechanical interactions between the contact lens and the eye are difficult to measure and calculate in the clinical setting, and the research in this field is limited. This paper presents the first mathematical model that couples the interaction between the contact lens and the open eye, where the contact lens configuration, the contact lens suction pressure, and the deformed ocular shape are all emergent properties of the model. The non-linear coupling between the contact lens and the eye is achieved assuming the the suction pressure under the lens is applied directly to the ocular surface, neglecting the post-lens tear film layer. The contact lens dynamics is modeled using a previous published model. We consider a homogeneous and a heterogeneous linear elastic eye model, different ocular shapes, different lens shapes and lens thickness profiles, and extract lens deformation, lens suction pressure profiles, and ocular deformations and stresses for all the scenarios considered. The model predicts higher ocular deformations and stresses at the center of the eye and in the limbal/scleral region. Accounting for a heterogeneous material eye parameters increases such deformations and stresses. The ocular displacements and stresses increase non-linearly as we increase the stiffness of the contact lens. Inserting a steeper contact lens on the eye results in a reduction of the ocular displacement at the center of the eye and a larger displacement at the edge of the contact lens. The model predictions are compared to experimental data and previously developed mathematical models.",
      "authors": [
        "Lucia Carichino",
        "Kara L. Maki",
        "David S. Ross",
        "Riley K. Supple",
        "and Evan Rysdam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T00:45:41+00:00",
          "link": "https://arxiv.org/abs/2507.13589v1",
          "size": "4979kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying Ocular Surface Changes with Contact Lens Wear",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13589",
        "HTML": "https://arxiv.org/html/2507.13589v1",
        "PDF": "https://arxiv.org/pdf/2507.13589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the mechanical model of contact lens interactions with the eye, having no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13591",
      "abstract": "Federated Learning (FL) enables collaborative model training without centralizing client data, making it attractive for privacy-sensitive domains. While existing approaches employ cryptographic techniques such as homomorphic encryption, differential privacy, or secure multiparty computation to mitigate inference attacks-including model inversion, membership inference, and gradient leakage-they often suffer from high computational, communication, or memory overheads. Moreover, many methods overlook the confidentiality of the global model itself, which may be proprietary and sensitive. These challenges limit the practicality of secure FL, especially in cross-silo deployments involving large datasets and strict compliance requirements.\n  We present FuSeFL, a fully secure and scalable FL scheme designed for cross-silo settings. FuSeFL decentralizes training across client pairs using lightweight secure multiparty computation (MPC), while confining the server's role to secure aggregation. This design eliminates server bottlenecks, avoids data offloading, and preserves full confidentiality of data, model, and updates throughout training. FuSeFL defends against inference threats, achieves up to 95% lower communication latency and 50% lower server memory usage, and improves accuracy over prior secure FL solutions, demonstrating strong security and efficiency at scale.",
      "authors": [
        "Sahar Ghoflsaz Ghinani and Elaheh Sadredini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T00:50:44+00:00",
          "link": "https://arxiv.org/abs/2507.13591v1",
          "size": "1126kb",
          "version": "v1"
        }
      ],
      "title": "FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13591",
        "HTML": "https://arxiv.org/html/2507.13591v1",
        "PDF": "https://arxiv.org/pdf/2507.13591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The FuSeFL paper discusses secure federated learning frameworks but does not address LLM training data processing steps such as data collection or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13595",
      "abstract": "Reconstructing accurate implicit surface representations from point clouds remains a challenging task, particularly when data is captured using low-quality scanning devices. These point clouds often contain substantial noise, leading to inaccurate surface reconstructions. Inspired by the Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel method designed to extend this concept to 3D neural fields. Our approach enables learning clean neural SDFs directly from noisy point clouds through noisy supervision by minimizing the MSE loss between noisy SDF representations, allowing the network to implicitly denoise and refine surface estimations. We evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that our framework significantly improves surface reconstruction quality from noisy inputs.",
      "authors": [
        "Tengkai Wang",
        "Weihao Li",
        "Ruikai Cui",
        "Shi Qiu",
        "Nick Barnes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T00:58:42+00:00",
          "link": "https://arxiv.org/abs/2507.13595v1",
          "size": "19909kb",
          "version": "v1"
        }
      ],
      "title": "NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13595",
        "HTML": "https://arxiv.org/html/2507.13595v1",
        "PDF": "https://arxiv.org/pdf/2507.13595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reconstructing accurate implicit surface representations from noisy point clouds, extending the Noise2Noise paradigm to 3D neural fields. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13598",
      "abstract": "We present GIFT: a {G}radient-aware {I}mmunization technique to defend diffusion models against malicious {F}ine-{T}uning while preserving their ability to generate safe content. Existing safety mechanisms like safety checkers are easily bypassed, and concept erasure methods fail under adversarial fine-tuning. GIFT addresses this by framing immunization as a bi-level optimization problem: the upper-level objective degrades the model's ability to represent harmful concepts using representation noising and maximization, while the lower-level objective preserves performance on safe data. GIFT achieves robust resistance to malicious fine-tuning while maintaining safe generative quality. Experimental results show that our method significantly impairs the model's ability to re-learn harmful concepts while maintaining performance on safe content, offering a promising direction for creating inherently safer generative models resistant to adversarial fine-tuning attacks.",
      "authors": [
        "Amro Abdalla",
        "Ismail Shaheen",
        "Dan DeGenaro",
        "Rupayan Mallick",
        "Bogdan Raita",
        "Sarah Adel Bargal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T01:47:07+00:00",
          "link": "https://arxiv.org/abs/2507.13598v1",
          "size": "2749kb",
          "version": "v1"
        }
      ],
      "title": "GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13598",
        "HTML": "https://arxiv.org/html/2507.13598v1",
        "PDF": "https://arxiv.org/pdf/2507.13598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents GIFT, a technique to defend diffusion models against malicious fine-tuning. While it involves fine-tuning, it focuses on model safety and concept retention rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13599",
      "abstract": "Since acquiring large amounts of realistic blurry-sharp image pairs is difficult and expensive, learning blind image deblurring from unpaired data is a more practical and promising solution. Unfortunately, dominant approaches rely heavily on adversarial learning to bridge the gap from blurry domains to sharp domains, ignoring the complex and unpredictable nature of real-world blur patterns. In this paper, we propose a novel diffusion model (DM)-based framework, dubbed \\ours, for image deblurring by learning spatially varying texture prior from unpaired data. In particular, \\ours performs DM to generate the prior knowledge that aids in recovering the textures of blurry images. To implement this, we propose a Texture Prior Encoder (TPE) that introduces a memory mechanism to represent the image textures and provides supervision for DM training. To fully exploit the generated texture priors, we present the Texture Transfer Transformer layer (TTformer), in which a novel Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes spatially varying blurring through adaptive filtering. Furthermore, we implement a wavelet-based adversarial loss to preserve high-frequency texture details. Extensive evaluations show that \\ours provides a promising unsupervised deblurring solution and outperforms SOTA methods in widely-used benchmarks.",
      "authors": [
        "Chengxu Liu",
        "Lu Qi",
        "Jinshan Pan",
        "Xueming Qian",
        "Ming-Hsuan Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T01:50:31+00:00",
          "link": "https://arxiv.org/abs/2507.13599v1",
          "size": "9210kb",
          "version": "v1"
        }
      ],
      "title": "Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13599",
        "PDF": "https://arxiv.org/pdf/2507.13599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses image deblurring using a diffusion model and unpaired data, which is unrelated to LLM training data processing. It focuses on computer vision tasks rather than language model data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13601",
      "abstract": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into multiple logical instances with fully-isolated resources, which can be dynamically reconfigured. This work highlights the untapped potential of MIG through moldable task scheduling with dynamic reconfigurations. Specifically, we propose a makespan minimization problem for multi-task execution under MIG constraints. Our profiling shows that assuming monotonicity in task work with respect to resources is not viable, as is usual in multicore scheduling. Relying on a state-of-the-art proposal that does not require such an assumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1 of FAR builds on a classical task moldability method, phase 2 combines Longest Processing Time First and List Scheduling with a novel repartitioning tree heuristic tailored to MIG constraints, and phase 3 employs local search via task moves and swaps. FAR schedules tasks in batches offline, concatenating their schedules on the fly in an improved way that favors resource reuse. Excluding reconfiguration costs, the List Scheduling proof shows an approximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to the particular constraints of an NVIDIA A100/H100 to obtain an approximation factor of 2. Including the reconfiguration cost, our real-world experiments reveal a makespan with respect to the optimum no worse than 1.22x for a well-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real kernels. We obtain good experimental results for each batch of tasks, but also in the concatenation of batches, with large improvements over the state-of-the-art and proposals without GPU reconfiguration. Beyond the algorithm, the paper demonstrates the research potential of the MIG technology and suggests useful metrics, workload characterizations and evaluation techniques for future work in this field.",
      "authors": [
        "Jorge Villarrubia",
        "Luis Costero",
        "Francisco D. Igual",
        "Katzalin Olcoz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Emerging Technologies (cs.ET)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:03:37+00:00",
          "link": "https://arxiv.org/abs/2507.13601v1",
          "size": "337kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Multi-Instance GPUs through moldable task scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13601",
        "HTML": "https://arxiv.org/html/2507.13601v1",
        "PDF": "https://arxiv.org/pdf/2507.13601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses leveraging NVIDIA MIG technology for moldable task scheduling. It focuses on GPU resource management and scheduling, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13602",
      "abstract": "In this work we extend the low-cost GELLO teleoperation system, initially designed for joint position control, with additional force information. Our first extension is to implement force feedback, allowing users to feel resistance when interacting with the environment. Our second extension is to add force information into the data collection process and training of imitation learning models. We validate our additions by implementing these on a GELLO system with a Franka Panda arm as the follower robot, performing a user study, and comparing the performance of policies trained with and without force information on a range of simulated and real dexterous manipulation tasks. Qualitatively, users with robotics experience preferred our controller, and the addition of force inputs improved task success on the majority of tasks.",
      "authors": [
        "Shivakanth Sujit",
        "Luca Nunziante",
        "Dan Ogawa Lillrank",
        "Rousslan Fernand Julien Dossa",
        "Kai Arulkumaran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:05:07+00:00",
          "link": "https://arxiv.org/abs/2507.13602v1",
          "size": "3322kb",
          "version": "v1"
        }
      ],
      "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13602",
        "HTML": "https://arxiv.org/html/2507.13602v1",
        "PDF": "https://arxiv.org/pdf/2507.13602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study enhances a teleoperation system with force feedback and force data integration. It pertains to robotics and imitation learning, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13607",
      "abstract": "While burst Low-Resolution (LR) images are useful for improving their Super Resolution (SR) image compared to a single LR image, prior burst SR methods are trained in a deterministic manner, which produces a blurry SR image. Since such blurry images are perceptually degraded, we aim to reconstruct sharp and high-fidelity SR images by a diffusion model. Our method improves the efficiency of the diffusion model with a stochastic sampler with a high-order ODE as well as one-step diffusion using knowledge distillation. Our experimental results demonstrate that our method can reduce the runtime to 1.6 % of its baseline while maintaining the SR quality measured based on image distortion and perceptual quality.",
      "authors": [
        "Kento Kawai",
        "Takeru Oba",
        "Kyotaro Tokoro",
        "Kazutoshi Akita",
        "Norimichi Ukita"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:21:29+00:00",
          "link": "https://arxiv.org/abs/2507.13607v1",
          "size": "3363kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Burst Super-Resolution with One-step Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13607",
        "HTML": "https://arxiv.org/html/2507.13607v1",
        "PDF": "https://arxiv.org/pdf/2507.13607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses super-resolution in images using a diffusion model. It does not pertain to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13608",
      "abstract": "Matching users based on mutual preferences is a fundamental aspect of services driven by reciprocal recommendations, such as job search and dating applications. Although A/B tests remain the gold standard for evaluating new policies in recommender systems for matching markets, it is costly and impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays a crucial role by enabling the evaluation of recommendation policies using only offline logged data naturally collected on the platform. However, unlike conventional recommendation settings, the large scale and bidirectional nature of user interactions in matching platforms introduce variance issues and exacerbate reward sparsity, making standard OPE methods unreliable. To address these challenges and facilitate effective offline evaluation, we propose novel OPE estimators, \\textit{DiPS} and \\textit{DPR}, specifically designed for matching markets. Our methods combine elements of the Direct Method (DM), Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while incorporating intermediate labels, such as initial engagement signals, to achieve better bias-variance control in matching markets. Theoretically, we derive the bias and variance of the proposed estimators and demonstrate their advantages over conventional methods. Furthermore, we show that these estimators can be seamlessly extended to offline policy learning methods for improving recommendation policies for making more matches. We empirically evaluate our methods through experiments on both synthetic data and A/B testing logs from a real job-matching platform. The empirical results highlight the superiority of our approach over existing methods in off-policy evaluation and learning tasks for a variety of configurations.",
      "authors": [
        "Yudai Hayashi",
        "Shuhei Goda",
        "Yuta Saito"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:23:37+00:00",
          "link": "https://arxiv.org/abs/2507.13608v1",
          "size": "2898kb",
          "version": "v1"
        }
      ],
      "title": "Off-Policy Evaluation and Learning for Matching Markets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13608",
        "HTML": "https://arxiv.org/html/2507.13608v1",
        "PDF": "https://arxiv.org/pdf/2507.13608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces novel off-policy evaluation and learning methods for matching markets, targeting recommendation policies. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13609",
      "abstract": "Despite recent progress in video large language models (VideoLLMs), a key open challenge remains: how to equip models with chain-of-thought (CoT) reasoning abilities grounded in fine-grained object-level video understanding. Existing instruction-tuned models, such as the Qwen and LLaVA series, are trained on high-level video-text pairs, often lacking structured annotations necessary for compositional, step-by-step reasoning. We propose CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR) into four entity-level foundational tasks: frame localization, entity tracking, spatial and temporal relation extraction. By embedding these intermediate CoT-style reasoning steps into the input, CoTasks enables models to explicitly perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA benchmark show that CoTasks significantly enhance inference performance: LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal (+10.9), and descriptive (+48.1) subcategories. These results demonstrate the effectiveness of CoTasks as a structured CoT-style supervision framework for improving compositional video reasoning.",
      "authors": [
        "Yanan Wang and Julio Vizcarra and Zhi Li and Hao Niu and Mori Kurokawa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:29:19+00:00",
          "link": "https://arxiv.org/abs/2507.13609v1",
          "size": "14494kb",
          "version": "v1"
        }
      ],
      "title": "CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13609",
        "HTML": "https://arxiv.org/html/2507.13609v1",
        "PDF": "https://arxiv.org/pdf/2507.13609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes CoTasks, which refine video instruction tuning tasks for models like LLaVA by decomposing complex questions into foundational tasks. While it involves instruction tuning, its main focus is on model reasoning enhancements rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13614",
      "abstract": "The rapid advancements in large language models (LLMs) have significantly improved their ability to generate natural language, making texts generated by LLMs increasingly indistinguishable from human-written texts. While recent research has primarily focused on using LLMs to classify text as either human-written and machine-generated texts, our study focus on characterizing these texts using a set of linguistic features across different linguistic levels such as morphology, syntax, and semantics. We select a dataset of human-written and machine-generated texts spanning 8 domains and produced by 11 different LLMs. We calculate different linguistic features such as dependency length and emotionality and we use them for characterizing human-written and machine-generated texts along with different sampling strategies, repetition controls and model release date. Our statistical analysis reveals that human-written texts tend to exhibit simpler syntactic structures and more diverse semantic content. Furthermore, we calculate the variability of our set of features across models and domains. Both human and machine texts show stylistic diversity across domains, with humans displaying greater variation in our features. Finally, we apply style embeddings to further test variability among human-written and machine-generated texts. Notably, newer models output text that is similarly variable, pointing to an homogenization of machine-generated texts.",
      "authors": [
        "Sergio E. Zanotto",
        "Segun Aroyehun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:46:55+00:00",
          "link": "https://arxiv.org/abs/2507.13614v1",
          "size": "131kb",
          "version": "v1"
        }
      ],
      "title": "Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13614",
        "HTML": "https://arxiv.org/html/2507.13614v1",
        "PDF": "https://arxiv.org/pdf/2507.13614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on characterizing texts generated by humans and LLMs using linguistic features, rather than contributing to LLM training data processing or creation, generation, or improvement of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13616",
      "abstract": "The integration of agential artificial intelligence into socioeconomic systems requires us to reexamine the evolutionary processes that describe changes in our economic institutions. This article synthesizes three frameworks: multi-level selection theory, Aoki's view of firms as computational processes, and Ostrom's design principles for robust institutions. We develop a framework where selection operates concurrently across organizational levels, firms implement distributed inference via game-theoretic architectures, and Ostrom-style rules evolve as alignment mechanisms that address AI-related risks. This synthesis yields a multi-level Price equation expressed over nested games, providing quantitative metrics for how selection and governance co-determine economic outcomes. We examine connections to Acemoglu's work on inclusive institutions, analyze how institutional structures shape AI deployment, and demonstrate the framework's explanatory power via case studies. We conclude by proposing a set of design principles that operationalize alignment between humans and AI across institutional layers, enabling scalable, adaptive, and inclusive governance of agential AI systems. We conclude with practical policy recommendations and further research to extend these principles into real-world implementation.",
      "authors": [
        "Michael S. Harre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)",
        "Information Theory (cs.IT)",
        "Multiagent Systems (cs.MA)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:52:58+00:00",
          "link": "https://arxiv.org/abs/2507.13616v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "From Firms to Computation: AI Governance and the Evolution of Institutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13616",
        "HTML": "https://arxiv.org/html/2507.13616v1",
        "PDF": "https://arxiv.org/pdf/2507.13616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses AI governance and socioeconomic systems but does not address LLM training data processing, dataset creation, or improvement in data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13618",
      "abstract": "Multilingual translation stands as a challenging task for large language models (LLMs) to handle intricate language patterns and stilted translations that arise in automated translations. In this paper, we introduce Seed-X, a family of open-source LLMs comprising instruct and reasoning models, pushing the limits of translation capability with 7B parameter size. The base model is pre-trained on a diverse, high-quality dataset encompassing both monolingual and bilingual content across 28 languages, harnessing the full potential of multilingual data. The instruct model is then finetuned to translate by Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement learning (RL) to achieve better generalization across diverse language pairs. Seed-X achieves performance comparable to leading closed-source models, including Gemini-2.5 and GPT-4o, across 28 languages, and significantly outperforms larger open-source models in both automatic metrics and human evaluations. We share the best practices through our optimization process, and make the parameter public available for advancing translation research and applications.",
      "authors": [
        "Shanbo Cheng",
        "Yu Bao",
        "Qian Cao",
        "Luyang Huang",
        "Liyan Kang",
        "Zhicheng Liu",
        "Yu Lu",
        "Wenhao Zhu",
        "Zhichao Huang",
        "Tao Li",
        "Sitong Liu",
        "Ningxin Peng",
        "Shuaijie She",
        "Lu Xu",
        "Nuo Xu",
        "Sen Yang",
        "Runsheng Yu",
        "Yiming Yu",
        "Liehao Zou",
        "Hang Li",
        "Lu Lu",
        "Yuxuan Wang",
        "Yonghui Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:19:43+00:00",
          "link": "https://arxiv.org/abs/2507.13618v1",
          "size": "364kb",
          "version": "v1"
        }
      ],
      "title": "Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13618",
        "HTML": "https://arxiv.org/html/2507.13618v1",
        "PDF": "https://arxiv.org/pdf/2507.13618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces Seed-X multilingual translation models and mentions pre-training on a diverse dataset, the main focus is on translation capabilities and model performance, not specifically on the process of dataset creation or improvement for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13620",
      "abstract": "In recent years, models based on Graph Convolutional Networks (GCN) have made significant strides in the field of graph data analysis. However, challenges such as over-smoothing and over-compression remain when handling large-scale and complex graph datasets, leading to a decline in clustering quality. Although the Graph Transformer architecture has mitigated some of these issues, its performance is still limited when processing heterogeneous graph data. To address these challenges, this study proposes a novel deep clustering framework that comprising GCN, Autoencoder (AE), and Graph Transformer, termed the Tri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the differentiation and consistency of global and local information through a unique tri-learning mechanism and feature fusion enhancement strategy. The framework integrates GCN, AE, and Graph Transformer modules. These components are meticulously fused by a triple-channel enhancement module, which maximizes the use of both node attributes and topological structures, ensuring robust clustering representation. The tri-learning mechanism allows mutual learning among these modules, while the feature fusion strategy enables the model to capture complex relationships, yielding highly discriminative representations for graph clustering. It surpasses many state-of-the-art methods, achieving an accuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the Reuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding performance on the Reuters dataset, Tri-GFN can be applied to automatic news classification, topic retrieval, and related fields.",
      "authors": [
        "Binxiong Li",
        "Yuefei Wang",
        "Xu Xiang",
        "Xue Li",
        "Binyu Zhao",
        "Heyang Gao",
        "Qinyu Zhao",
        "Xi Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:25:07+00:00",
          "link": "https://arxiv.org/abs/2507.13620v1",
          "size": "4636kb",
          "version": "v1"
        }
      ],
      "title": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13620",
        "PDF": "https://arxiv.org/pdf/2507.13620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a graph clustering framework using GCN and related technologies, with no focus on LLM training data processing or operations related to dataset construction and improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13622",
      "abstract": "News recommender systems aim to provide personalized news reading experiences for users based on their reading history. Behavioral science studies suggest that screen-based news reading contains three successive steps: scanning, title reading, and then clicking. Adhering to these steps, we find that intra-news entity interest dominates the scanning stage, while the inter-news entity interest guides title reading and influences click decisions. Unfortunately, current methods overlook the unique utility of entities in news recommendation. To this end, we propose a novel method called IP2 to probe entity-guided reading interest at both intra- and inter-news levels. At the intra-news level, a Transformer-based entity encoder is devised to aggregate mentioned entities in the news title into one signature entity. Then, a signature entity-title contrastive pre-training is adopted to initialize entities with proper meanings using the news story context, which in the meantime facilitates us to probe for intra-news entity interest. As for the inter-news level, a dual tower user encoder is presented to capture inter-news reading interest from both the title meaning and entity sides. In addition to highlighting the contribution of inter-news entity guidance, a cross-tower attention link is adopted to calibrate title reading interest using inter-news entity interest, thus further aligning with real-world behavior. Extensive experiments on two real-world datasets demonstrate that our IP2 achieves state-of-the-art performance in news recommendation.",
      "authors": [
        "Youlin Wu",
        "Yuanyuan Sun",
        "Xiaokun Zhang",
        "Haoxi Zhan",
        "Bo Xu",
        "Liang Yang",
        "Hongfei Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:35:58+00:00",
          "link": "https://arxiv.org/abs/2507.13622v1",
          "size": "1049kb",
          "version": "v1"
        }
      ],
      "title": "IP2: Entity-Guided Interest Probing for Personalized News Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13622",
        "HTML": "https://arxiv.org/html/2507.13622v1",
        "PDF": "https://arxiv.org/pdf/2507.13622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for personalized news recommendation based on entity interest probing, which is unrelated to LLM training data processing or improvements in dataset quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13623",
      "abstract": "Orthogonal Frequency Division Multiplexing (OFDM) combined with Multiple-Input Multiple-Output (MIMO) techniques forms the backbone of modern wireless communication systems. While offering high spectral efficiency and robustness, conventional MIMO-OFDM, especially with complex equalizers like Minimum Mean Square Error (MMSE), suffers from high Peak-to-Average Power Ratio (PAPR) and significant power consumption due to multiple active Radio Frequency (RF) chains. This paper proposes and mathematically models an alternative system, termed Multi-Dimensional OFDM (MD-OFDM), which employs a per-subcarrier transmit antenna selection strategy. By activating only one transmit antenna for each subcarrier, MD-OFDM aims to reduce PAPR, lower power consumption, and improve Bit Error Rate (BER) performance. We provide detailed mathematical formulations for BER, Energy Efficiency (EE), and PAPR, and discuss the suitability of MD-OFDM for various applications, particularly in energy-constrained and cost-sensitive scenarios such as the Internet of Things (IoT) and Low-Power Wide Area Networks (LPWAN). Simulation results demonstrate that MD-OFDM achieves superior BER and significantly lower PAPR compared to MMSE MIMO, albeit with a trade-off in peak overall energy efficiency due to reduced spectral multiplexing.",
      "authors": [
        "Rahul Gulia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:37:52+00:00",
          "link": "https://arxiv.org/abs/2507.13623v1",
          "size": "130kb",
          "version": "v1"
        }
      ],
      "title": "MD-OFDM: An Energy-Efficient and Low-PAPR MIMO-OFDM Variant for Resource-Constrained Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13623",
        "HTML": "https://arxiv.org/html/2507.13623v1",
        "PDF": "https://arxiv.org/pdf/2507.13623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses energy efficiency and performance improvements in MIMO-OFDM systems for wireless communication, and does not discuss or contribute to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13624",
      "abstract": "Communication overhead remains a primary bottleneck in federated learning (FL), particularly for applications involving mobile and IoT devices with constrained bandwidth. This work introduces FedSkipTwin, a novel client-skipping algorithm driven by lightweight, server-side digital twins. Each twin, implemented as a simple LSTM, observes a client's historical sequence of gradient norms to forecast both the magnitude and the epistemic uncertainty of its next update. The server leverages these predictions, requesting communication only when either value exceeds a predefined threshold; otherwise, it instructs the client to skip the round, thereby saving bandwidth. Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients under a non-IID data distribution. The results demonstrate that FedSkipTwin reduces total communication by 12-15.5% across 20 rounds while simultaneously improving final model accuracy by up to 0.5 percentage points compared to the standard FedAvg algorithm. These findings establish that prediction-guided skipping is a practical and effective strategy for resource-aware FL in bandwidth-constrained edge environments.",
      "authors": [
        "Daniel Commey",
        "Kamel Abbad",
        "Garth V. Crosby and Lyes Khoukhi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:39:08+00:00",
          "link": "https://arxiv.org/abs/2507.13624v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13624",
        "HTML": "https://arxiv.org/html/2507.13624v1",
        "PDF": "https://arxiv.org/pdf/2507.13624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on federated learning and communication efficiency using a client-skipping algorithm. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13625",
      "abstract": "Information retrieval and question answering from safety regulations are essential for automated construction compliance checking but are hindered by the linguistic and structural complexity of regulatory text. Many compliance-related queries are multi-hop, requiring synthesis of information across interlinked clauses. This poses a challenge for traditional retrieval-augmented generation (RAG) systems. To overcome this, we introduce BifrostRAG: a dual-graph RAG-integrated system that explicitly models both linguistic relationships (via an Entity Network Graph) and document structure (via a Document Navigator Graph). This architecture powers a hybrid retrieval mechanism that combines graph traversal with vector-based semantic search, enabling large language models to reason over both the meaning and the structure of the text. Evaluation on a multi-hop question dataset shows that BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1 score of 87.3 percent. These results significantly outperform vector-only and graph-only RAG baselines that represent current leading approaches. Error analysis further highlights the comparative advantages of our hybrid method over single-modality RAGs. These findings establish BifrostRAG as a robust knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid retrieval mechanism offers a transferable blueprint for navigating complex technical documents across knowledge-intensive engineering domains.",
      "authors": [
        "Yuxin Zhang (1)",
        "Xi Wang (1)",
        "Mo Hu (1)",
        "Zhenyu Zhang (1) ((1) Department of Construction Science",
        "College of Architecture",
        "Texas A&M University",
        "College Station",
        "USA)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:39:14+00:00",
          "link": "https://arxiv.org/abs/2507.13625v1",
          "size": "8903kb",
          "version": "v1"
        }
      ],
      "title": "BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13625",
        "HTML": "https://arxiv.org/html/2507.13625v1",
        "PDF": "https://arxiv.org/pdf/2507.13625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses a retrieval-augmented generation system for question answering, it does not make technical contributions to training data processing necessary for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13628",
      "abstract": "Separating moving and static objects from a moving camera viewpoint is essential for 3D reconstruction, autonomous navigation, and scene understanding in robotics. Existing approaches often rely primarily on optical flow, which struggles to detect moving objects in complex, structured scenes involving camera motion. To address this limitation, we propose Focus of Expansion Likelihood and Segmentation (FoELS), a method based on the core idea of integrating both optical flow and texture information. FoELS computes the focus of expansion (FoE) from optical flow and derives an initial motion likelihood from the outliers of the FoE computation. This likelihood is then fused with a segmentation-based prior to estimate the final moving probability. The method effectively handles challenges including complex structured scenes, rotational camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016 dataset and real-world traffic videos demonstrate its effectiveness and state-of-the-art performance.",
      "authors": [
        "Masahiro Ogawa",
        "Qi An",
        "and Atsushi Yamashita"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:40:44+00:00",
          "link": "https://arxiv.org/abs/2507.13628v1",
          "size": "3330kb",
          "version": "v1"
        }
      ],
      "title": "Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13628",
        "HTML": "https://arxiv.org/html/2507.13628v1",
        "PDF": "https://arxiv.org/pdf/2507.13628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a method for detecting moving objects using optical flow and segmentation, which is not related to LLM training data processing or its associated operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13629",
      "abstract": "Large Language Models (LLMs) are transforming cybersecurity by enabling intelligent, adaptive, and automated approaches to threat detection, vulnerability assessment, and incident response. With their advanced language understanding and contextual reasoning, LLMs surpass traditional methods in tackling challenges across domains such as IoT, blockchain, and hardware security. This survey provides a comprehensive overview of LLM applications in cybersecurity, focusing on two core areas: (1) the integration of LLMs into key cybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along with mitigation strategies. By synthesizing recent advancements and identifying key limitations, this work offers practical insights and strategic recommendations for leveraging LLMs to build secure, scalable, and future-ready cyber defense systems.",
      "authors": [
        "Niveen O. Jaffal",
        "Mohammed Alkhanafseh",
        "David Mohaisen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:41:18+00:00",
          "link": "https://arxiv.org/abs/2507.13629v1",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13629",
        "HTML": "https://arxiv.org/html/2507.13629v1",
        "PDF": "https://arxiv.org/pdf/2507.13629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applications of LLMs in cybersecurity, analyzing their potential, vulnerabilities, and defense strategies. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13631",
      "abstract": "Computation-in-Memory (CiM) is attracting attention as a technology that can perform MAC calculations required for AI accelerators, at high speed with low power consumption. However, there is a problem regarding power consumption and device-derived errors that increase as row parallelism increases. In this paper, a 4T2R ReRAM cell and an 8T SRAM CiM suitable for CiM is proposed. It is shown that adopting the proposed 4T2R ReRAM cell reduces the errors due to variation in ReRAM devices compared to conventional 4T4R ReRAM cells.",
      "authors": [
        "Fuyuki Kihara",
        "Seiji Uenohara",
        "Satoshi Awamura",
        "Naoko Misawa",
        "Chihiro Matsui",
        "and Ken Takeuchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:44:39+00:00",
          "link": "https://arxiv.org/abs/2507.13631v1",
          "size": "1335kb",
          "version": "v1"
        }
      ],
      "title": "4T2R X-ReRAM CiM Array for Variation-tolerant, Low-power, Massively Parallel MAC Operation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13631",
        "PDF": "https://arxiv.org/pdf/2507.13631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a technology for computation-in-memory using ReRAM cells and does not involve LLM training data processing or any related data engineering methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13636",
      "abstract": "This paper investigates inauthentic duplication on social media, where multiple accounts share identical misinformation tweets. Leveraging a dataset of misinformation verified by AltNews, an Indian fact-checking organization, we analyze over 12 million posts from 5,493 accounts known to have duplicated such content. Contrary to common assumptions that bots are primarily responsible for spreading false information, fewer than 1\\% of these accounts exhibit bot-like behavior. We present TweeXster, a framework for detecting and analyzing duplication campaigns, revealing clusters of accounts involved in repeated and sometimes revived dissemination of false or abusive content.",
      "authors": [
        "Ashfaq Ali Shafin and Bogdan Carbunar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:48:55+00:00",
          "link": "https://arxiv.org/abs/2507.13636v1",
          "size": "714kb",
          "version": "v1"
        }
      ],
      "title": "Duplicating Deceit: Inauthentic Behavior Among Indian Misinformation Duplicators on X/Twitter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13636",
        "PDF": "https://arxiv.org/pdf/2507.13636"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates social media misinformation duplication, using data from Indian misinformation duplicators. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13640",
      "abstract": "We recently introduced the Fast Newton Transform (FNT), an algorithm for performing multivariate Newton interpolation in downward closed polynomial spaces of spatial dimension $m$. In this work, we analyze the FNT in the context of a specific family of downward closed sets $A_{m,n,p}$, defined as all multi-indices with $\\ell^p$ norm less than $n$ with $p \\in [0,\\infty]$. These sets induce the downward closed polynomial space $\\Pi_{m,n,p}$, within which the FNT algorithm achieves a time complexity of $\\mathcal{O}(|A_{m,n,p}|mn)$. We show that this setting, compared to tensor product spaces, yields an improvement in complexity by a factor $\\rho_{m,n,p}$, which decays super exponentially with increasing spatial dimension when $m \\lesssim n^p$. Additionally, we demonstrate the construction of the hierarchical scheme employed by the FNT and showcase its performance to compute activity scores in sensitivity analysis.",
      "authors": [
        "Phil-Alexander Hofmann",
        "Damar Wicaksono",
        "Michael Hecht"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:58:23+00:00",
          "link": "https://arxiv.org/abs/2507.13640v1",
          "size": "66kb",
          "version": "v1"
        }
      ],
      "title": "Interpolation in Polynomial Spaces of p-Degree",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13640",
        "PDF": "https://arxiv.org/pdf/2507.13640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the Fast Newton Transform for multivariate Newton interpolation in polynomial spaces, which is unrelated to LLM training data processing or dataset management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13641",
      "abstract": "As an important metric for mesh quality evaluation, the isotropy property holds significant value for applications such as texture UV-mapping, physical simulation, and discrete geometric analysis. Classical isotropy remeshing methods adjust vertices and edge lengths, which exhibit certain limitations in terms of input data sensitivity, geometric consistency control, and convergence speed. In this paper, we propose an improved isotropy remeshing solution with inter-angle optimization during mesh editing to enhance shape control capability and accelerate convergence. The advantage of the solution lies in its ability to predict the impact of edge length adjustments on subsequent optimization by monitoring angle transformations. It avoids inefficient editing that may cause performance fluctuations, thereby improving efficiency. Experiments demonstrate that the proposed method effectively improves the overall efficiency of mesh optimization.",
      "authors": [
        "Hanbing Zheng and Chenlei Lv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:59:31+00:00",
          "link": "https://arxiv.org/abs/2507.13641v1",
          "size": "9068kb",
          "version": "v1"
        }
      ],
      "title": "Isotropic Remeshing with Inter-Angle Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13641",
        "HTML": "https://arxiv.org/html/2507.13641v1",
        "PDF": "https://arxiv.org/pdf/2507.13641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on isotropic remeshing with inter-angle optimization, which pertains to mesh quality evaluation rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13644",
      "abstract": "Multiscale modeling and analysis of multiphysics coupling processes in highly heterogeneous media present significant challenges. In this paper, we propose a novel multiphysics embedding localized orthogonal decomposition (ME-LOD) method for solving thermomechanical coupling problems, which also provides a systematic approach to address intricate coupling effects in multiphysical systems. Unlike the standard localized orthogonal decomposition (LOD) method that constructs separate multiscale spaces for each physical field, the proposed method features a unified construction for both displacement and temperature. Compared to the standard LOD method, our approach achieves operator stability reconstruction through orthogonalization while preserving computational efficiency. Several numerical experiments demonstrate that the ME-LOD method outperforms the traditional LOD method in accuracy, particularly in cases with significant contrasts in material properties.",
      "authors": [
        "Yuzhou Nan",
        "Yajun Wang",
        "Changqing Ye and Xiaofei Guan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:14:24+00:00",
          "link": "https://arxiv.org/abs/2507.13644v1",
          "size": "1452kb",
          "version": "v1"
        }
      ],
      "title": "Multiphysics embedding localized orthogonal decomposition for thermomechanical coupling problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13644",
        "HTML": "https://arxiv.org/html/2507.13644v1",
        "PDF": "https://arxiv.org/pdf/2507.13644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for solving thermomechanical coupling problems in multiphysics modeling, which is not related to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13646",
      "abstract": "The impact of Transformer-based language models has been unprecedented in Natural Language Processing (NLP). The success of such models has also led to their adoption in other fields including bioinformatics. Taking this into account, this paper discusses recent advances in Transformer-based models for protein sequence analysis and design. In this review, we have discussed and analysed a significant number of works pertaining to such applications. These applications encompass gene ontology, functional and structural protein identification, generation of de novo proteins and binding of proteins. We attempt to shed light on the strength and weaknesses of the discussed works to provide a comprehensive insight to readers. Finally, we highlight shortcomings in existing research and explore potential avenues for future developments. We believe that this review will help researchers working in this field to have an overall idea of the state of the art in this field, and to orient their future studies.",
      "authors": [
        "Nimisha Ghosh",
        "Daniele Santoni",
        "Debaleena Nawn",
        "Eleonora Ottaviani",
        "Giovanni Felici"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:20:33+00:00",
          "link": "https://arxiv.org/abs/2507.13646v1",
          "size": "432kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13646",
        "HTML": "https://arxiv.org/html/2507.13646v1",
        "PDF": "https://arxiv.org/pdf/2507.13646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews Transformer-based models for protein sequence analysis, discussing applications in bioinformatics rather than focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13647",
      "abstract": "Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic environments remains a key challenge due to high computational demands and the need for fast, adaptive responses. Traditional Particle Swarm Optimization (PSO) methods, while effective for offline planning, often struggle with premature convergence and latency in real-time scenarios. To overcome these limitations, we propose PE-PSO, an enhanced PSO-based online trajectory planner. The method introduces a persistent exploration mechanism to preserve swarm diversity and an entropy-based parameter adjustment strategy to dynamically adapt optimization behavior. UAV trajectories are modeled using B-spline curves, which ensure path smoothness while reducing optimization complexity. To extend this capability to UAV swarms, we develop a multi-agent framework that combines genetic algorithm (GA)-based task allocation with distributed PE-PSO, supporting scalable and coordinated trajectory generation. The distributed architecture allows for parallel computation and decentralized control, enabling effective cooperation among agents while maintaining real-time performance. Comprehensive simulations demonstrate that the proposed framework outperforms conventional PSO and other swarm-based planners across several metrics, including trajectory quality, energy efficiency, obstacle avoidance, and computation time. These results confirm the effectiveness and applicability of PE-PSO in real-time multi-UAV operations under complex environmental conditions.",
      "authors": [
        "Minze Li",
        "Wei Zhao",
        "Ran Chen and Mingqiang Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:31:49+00:00",
          "link": "https://arxiv.org/abs/2507.13647v1",
          "size": "1266kb",
          "version": "v1"
        }
      ],
      "title": "Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13647",
        "HTML": "https://arxiv.org/html/2507.13647v1",
        "PDF": "https://arxiv.org/pdf/2507.13647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on trajectory optimization for UAV swarms using an enhanced Particle Swarm Optimization algorithm and does not address any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13648",
      "abstract": "The rapid advancement of neural radiance fields (NeRF) has paved the way to generate animatable human avatars from a monocular video. However, the sole usage of NeRF suffers from a lack of details, which results in the emergence of hybrid representation that utilizes SMPL-based mesh together with NeRF representation. While hybrid-based models show photo-realistic human avatar generation qualities, they suffer from extremely slow inference due to their deformation scheme: to be aligned with the mesh, hybrid-based models use the deformation based on SMPL skinning weights, which needs high computational costs on each sampled point. We observe that since most of the sampled points are located in empty space, they do not affect the generation quality but result in inference latency with deformation. In light of this observation, we propose EPSilon, a hybrid-based 3D avatar generation scheme with novel efficient point sampling strategies that boost both training and inference. In EPSilon, we propose two methods to omit empty points at rendering; empty ray omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that progress through the empty space. Then, EIO narrows down the sampling interval on the ray, which wipes out the region not occupied by either clothes or mesh. The delicate sampling scheme of EPSilon enables not only great computational cost reduction during deformation but also the designation of the important regions to be sampled, which enables a single-stage NeRF structure without hierarchical sampling. Compared to existing methods, EPSilon maintains the generation quality while using only 3.9% of sampled points and achieves around 20 times faster inference, together with 4 times faster training convergence. We provide video results on https://github.com/seungjun-moon/epsilon.",
      "authors": [
        "Seungjun Moon",
        "Sangjoon Yu",
        "Gyeong-Moon Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:35:51+00:00",
          "link": "https://arxiv.org/abs/2507.13648v1",
          "size": "2895kb",
          "version": "v1"
        }
      ],
      "title": "EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13648",
        "HTML": "https://arxiv.org/html/2507.13648v1",
        "PDF": "https://arxiv.org/pdf/2507.13648"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents EPSilon, a 3D avatar generation scheme with efficient point sampling strategies, focused on reducing computational cost for hybrid-based models and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13650",
      "abstract": "Secondary cataract is one of the most common complications of vision loss due to the proliferation of residual lens materials that naturally grow on the lens capsule after cataract surgery. A potential treatment is capsule cleaning, a surgical procedure that requires enhanced visualization of the entire capsule and tool manipulation on the thin membrane. This article presents a robotic system capable of performing the capsule cleaning procedure by integrating a standard transpupillary and an intraocular optical coherence tomography probe on a surgical instrument for equatorial capsule visualization and real-time tool-to-tissue distance feedback. Using robot precision, the developed system enables complete capsule mapping in the pupillary and equatorial regions with in-situ calibration of refractive index and fiber offset, which are still current challenges in obtaining an accurate capsule model. To demonstrate effectiveness, the capsule mapping strategy was validated through five experimental trials on an eye phantom that showed reduced root-mean-square errors in the constructed capsule model, while the cleaning strategy was performed in three ex-vivo pig eyes without tissue damage.",
      "authors": [
        "Yu-Ting Lai",
        "Yasamin Foroutani",
        "Aya Barzelay",
        "Tsu-Chin Tsao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:37:18+00:00",
          "link": "https://arxiv.org/abs/2507.13650v1",
          "size": "20635kb",
          "version": "v1"
        }
      ],
      "title": "Safe Robotic Capsule Cleaning with Integrated Transpupillary and Intraocular Optical Coherence Tomography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13650",
        "HTML": "https://arxiv.org/html/2507.13650v1",
        "PDF": "https://arxiv.org/pdf/2507.13650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a robotic system for capsule cleaning in eye surgery, integrating optical coherence tomography for visualization and feedback. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13651",
      "abstract": "Many intelligent tutoring systems can support a student in solving a stepwise task. When a student combines several steps in one step, the number of possible paths connecting consecutive inputs may be very large. This combinatorial explosion makes error diagnosis hard. Using a final answer to diagnose a combination of steps can mitigate the combinatorial explosion, because there are generally fewer possible (erroneous) final answers than (erroneous) solution paths. An intermediate input for a task can be diagnosed by automatically completing it according to the task solution strategy and diagnosing this solution. This study explores the potential of automated error diagnosis based on a final answer. We investigate the design of a service that provides a buggy rule diagnosis when a student combines several steps. To validate the approach, we apply the service to an existing dataset (n=1939) of unique student steps when solving quadratic equations, which could not be diagnosed by a buggy rule service that tries to connect consecutive inputs with a single rule. Results show that final answer evaluation can diagnose 29,4% of these steps. Moreover, a comparison of the generated diagnoses with teacher diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the cases. These results can be considered a basis for further exploration of the approach.",
      "authors": [
        "Gerben van der Hoek",
        "Johan Jeuring and Rogier Bos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:39:13+00:00",
          "link": "https://arxiv.org/abs/2507.13651v1",
          "size": "424kb",
          "version": "v1"
        }
      ],
      "title": "Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13651",
        "PDF": "https://arxiv.org/pdf/2507.13651"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves error diagnosis in intelligent tutoring systems, focusing on diagnosing combined steps in educational tasks using final answer evaluation and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13652",
      "abstract": "Model tracing and constraint-based modeling are two approaches to diagnose student input in stepwise tasks. Model tracing supports identifying consecutive problem-solving steps taken by a student, whereas constraint-based modeling supports student input diagnosis even when several steps are combined into one step. We propose an approach that merges both paradigms. By defining constraints as properties that a student input has in common with a step of a strategy, it is possible to provide a diagnosis when a student deviates from a strategy even when the student combines several steps. In this study we explore the design of a system for multistep strategy diagnoses, and evaluate these diagnoses. As a proof of concept, we generate diagnoses for an existing dataset containing steps students take when solving quadratic equations (n=2136). To compare with human diagnoses, two teachers coded a random sample of deviations (n=70) and applications of the strategy (n=70). Results show that that the system diagnosis aligned with the teacher coding in all of the 140 student steps.",
      "authors": [
        "Gerben van der Hoek",
        "Johan Jeuring and Rogier Bos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.13652v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "Combining model tracing and constraint-based modeling for multistep strategy diagnoses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13652",
        "PDF": "https://arxiv.org/pdf/2507.13652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores combining model tracing and constraint-based modeling for diagnosing student input in stepwise tasks. No aspect of the paper addresses LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13654",
      "abstract": "This paper examines the performance of Inside and Outside Control modes at various scaling factors in a simulated vitreoretinal surgical setting. The IRISS teleoperated surgical system's console (cockpit) was adapted to project a simulated microscope view of an intraocular setup to a virtual reality (VR) headset. Five experienced vitreoretinal surgeons and five engineers with no surgical experience used the system to perform tasks common to vitreoretinal surgery. Experimental results indicate that Inside Control methods at higher scaling factors (20 or 30) achieved the best performance overall, though the optimal scaling factor may vary by task and complexity. Optimizing control methods and scaling factors could lead to improvements in surgical efficiency and accuracy, as well as minimize risks in future robotic-assisted intraocular procedures.",
      "authors": [
        "Haoran Wang",
        "Yasamin Foroutani",
        "Matthew Nepo",
        "Mercedes Rodriguez",
        "Ji Ma",
        "Jean-Pierre Hubschman",
        "Tsu-Chin Tsao",
        "Jacob Rosen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:48:46+00:00",
          "link": "https://arxiv.org/abs/2507.13654v1",
          "size": "10952kb",
          "version": "v1"
        }
      ],
      "title": "A Study of Teleoperation Methods in a Simulated Virtual Eye Surgery Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13654",
        "HTML": "https://arxiv.org/html/2507.13654v1",
        "PDF": "https://arxiv.org/pdf/2507.13654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on teleoperation methods and performance in a simulated virtual eye surgery environment, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13655",
      "abstract": "Integrating large language models into specialized domains like healthcare presents unique challenges, including domain adaptation and limited labeled data. We introduce CU-ICU, a method for customizing unsupervised instruction-finetuned language models for ICU datasets by leveraging the Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse fine-tuning approach that combines few-shot prompting with selective parameter updates, enabling efficient adaptation with minimal supervision. Our evaluation across critical ICU tasks--early sepsis detection, mortality prediction, and clinical note generation--demonstrates that CU-ICU consistently improves predictive accuracy and interpretability over standard fine-tuning methods. Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and a 20% enhancement in generating clinically relevant explanations while updating fewer than 1% of model parameters in its most efficient configuration. These results establish CU-ICU as a scalable, low-overhead solution for delivering accurate and interpretable clinical decision support in real-world ICU environments.",
      "authors": [
        "Teerapong Panboonyuen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:49:41+00:00",
          "link": "https://arxiv.org/abs/2507.13655v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13655",
        "HTML": "https://arxiv.org/html/2507.13655v1",
        "PDF": "https://arxiv.org/pdf/2507.13655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses adopting a fine-tuning method (CU-ICU) for ICU datasets, it emphasizes adaptation techniques rather than training data processing, offering limited relevance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13659",
      "abstract": "Recent researchers have proposed using event cameras for person re-identification (ReID) due to their promising performance and better balance in terms of privacy protection, event camera-based person ReID has attracted significant attention. Currently, mainstream event-based person ReID algorithms primarily focus on fusing visible light and event stream, as well as preserving privacy. Although significant progress has been made, these methods are typically trained and evaluated on small-scale or simulated event camera datasets, making it difficult to assess their real identification performance and generalization ability. To address the issue of data scarcity, this paper introduces a large-scale RGB-event based person ReID dataset, called EvReID. The dataset contains 118,988 image pairs and covers 1200 pedestrian identities, with data collected across multiple seasons, scenes, and lighting conditions. We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid foundation for future research in terms of both data and benchmarking. Based on our newly constructed dataset, this paper further proposes a pedestrian attribute-guided contrastive learning framework to enhance feature learning for person re-identification, termed TriPro-ReID. This framework not only effectively explores the visual features from both RGB frames and event streams, but also fully utilizes pedestrian attributes as mid-level semantic features. Extensive experiments on the EvReID dataset and MARS datasets fully validated the effectiveness of our proposed RGB-Event person ReID framework. The benchmark dataset and source code will be released on https://github.com/Event-AHU/Neuromorphic_ReID",
      "authors": [
        "Xiao Wang",
        "Qian Zhu",
        "Shujuan Wu",
        "Bo Jiang",
        "Shiliang Zhang",
        "Yaowei Wang",
        "Yonghong Tian",
        "Bin Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:04:59+00:00",
          "link": "https://arxiv.org/abs/2507.13659v1",
          "size": "4058kb",
          "version": "v1"
        }
      ],
      "title": "When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13659",
        "HTML": "https://arxiv.org/html/2507.13659v1",
        "PDF": "https://arxiv.org/pdf/2507.13659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new dataset and framework for person re-identification with event cameras, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13660",
      "abstract": "Two user studies were performed to evaluate the effect of level-of-detail (LOD) degradation in the periphery of head-mounted displays on visual search performance. In the first study, spatial detail was degraded by reducing resolution. In the second study, detail was degraded in the color domain by using grayscale in the periphery. In each study, 10 subjects were given a complex search task that required users to indicate whether or not a target object was present among distracters. Subjects used several different displays varying in the amount of detail presented. Frame rate, object location, subject input method, and order of display use were all controlled. The primary dependent measures were search time on correctly performed trials and the percentage of all trials correctly performed. Results indicated that peripheral LOD degradation can be used to reduce color or spatial visual complexity by almost half in some search tasks with out significantly reducing performance.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "Larry F Hodges",
        "Aileen Worden"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:07:02+00:00",
          "link": "https://arxiv.org/abs/2507.13660v1",
          "size": "308kb",
          "version": "v1"
        }
      ],
      "title": "Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13660",
        "PDF": "https://arxiv.org/pdf/2507.13660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines level-of-detail management in head-mounted displays for visual search tasks, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13661",
      "abstract": "Despite extensive research, the testing of autonomous driving systems (ADS) landscape remains fragmented, and there is currently no basis for an informed technical assessment of the importance and contribution of the current state of the art. This paper attempts to address this problem by exploring two complementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms of their intrinsic effectiveness and validity. It shows that many methods do not meet both of these requirements. Either because they are based on criteria that do not allow for rapid, inexpensive, and comprehensive detection of failures, or because the degree of validity of the properties tested cannot be accurately estimated. In particular, it is shown that most critical test methods do not take into account the nominal operational capabilities of autopilots and generate scenarios that are impossible for the tested vehicles to handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly dependent on how autopilots are designed: how they choose between different control policies to perform maneuvers, as well as on the reproducibility of the results. In fact, most test methods take for granted two principles underlying traditional methods, but do not generally apply to ADS. We maintain that the absence of rationality and determinacy significantly impairs the effectiveness and validity of test methods, and provide test results on eight open autopilots, in which most do not satisfy these properties, thereby illustrating this fact.\n  We conclude that under the current state of the art, it is impossible to obtain strong enough guarantees for essential autopilot properties and recommend that autopilots be developed with a view to both rationality and determinacy.",
      "authors": [
        "Changwen Li",
        "Joseph Sifakis",
        "Rongjie Yan",
        "Jian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:09:15+00:00",
          "link": "https://arxiv.org/abs/2507.13661v1",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13661",
        "HTML": "https://arxiv.org/html/2507.13661v1",
        "PDF": "https://arxiv.org/pdf/2507.13661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses testing methods for autonomous driving systems, unrelated to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13662",
      "abstract": "This paper presents a scalable and adaptive control framework for legged robots that integrates Iterative Learning Control (ILC) with a biologically inspired torque library (TL), analogous to muscle memory. The proposed method addresses key challenges in robotic locomotion, including accurate trajectory tracking under unmodeled dynamics and external disturbances. By leveraging the repetitive nature of periodic gaits and extending ILC to nonperiodic tasks, the framework enhances accuracy and generalization across diverse locomotion scenarios. The control architecture is data-enabled, combining a physics-based model derived from hybrid-system trajectory optimization with real-time learning to compensate for model uncertainties and external disturbances. A central contribution is the development of a generalized TL that stores learned control profiles and enables rapid adaptation to changes in speed, terrain, and gravitational conditions-eliminating the need for repeated learning and significantly reducing online computation. The approach is validated on the bipedal robot Cassie and the quadrupedal robot A1 through extensive simulations and hardware experiments. Results demonstrate that the proposed framework reduces joint tracking errors by up to 85% within a few seconds and enables reliable execution of both periodic and nonperiodic gaits, including slope traversal and terrain adaptation. Compared to state-of-the-art whole-body controllers, the learned skills eliminate the need for online computation during execution and achieve control update rates exceeding 30x those of existing methods. These findings highlight the effectiveness of integrating ILC with torque memory as a highly data-efficient and practical solution for legged locomotion in unstructured and dynamic environments.",
      "authors": [
        "Jing Cheng",
        "Yasser G. Alqaham",
        "Zhenyu Gan and Amit K. Sanyal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:13:02+00:00",
          "link": "https://arxiv.org/abs/2507.13662v1",
          "size": "23475kb",
          "version": "v1"
        }
      ],
      "title": "Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13662",
        "HTML": "https://arxiv.org/html/2507.13662v1",
        "PDF": "https://arxiv.org/pdf/2507.13662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a scalable and adaptive control framework for legged robots, integrating Iterative Learning Control with a biologically inspired torque library. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13663",
      "abstract": "Natural image quality is often degraded by adverse weather conditions, significantly impairing the performance of downstream tasks. Image restoration has emerged as a core solution to this challenge and has been widely discussed in the literature. Although recent transformer-based approaches have made remarkable progress in image restoration, their increasing system complexity poses significant challenges for real-time processing, particularly in real-world deployment scenarios. To this end, most existing methods attempt to simplify the self-attention mechanism, such as by channel self-attention or state space model. However, these methods primarily focus on network architecture while neglecting the inherent characteristics of image restoration itself. In this context, we explore a pyramid Wavelet-Fourier iterative pipeline to demonstrate the potential of Wavelet-Fourier processing for image restoration. Inspired by the above findings, we propose a novel and efficient restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet). Specifically, PW-FNet features two key design principles: 1) at the inter-block level, integrates a pyramid wavelet-based multi-input multi-output structure to achieve multi-scale and multi-frequency bands decomposition; and 2) at the intra-block level, incorporates Fourier transforms as an efficient alternative to self-attention mechanisms, effectively reducing computational complexity while preserving global modeling capability. Extensive experiments on tasks such as image deraining, raindrop removal, image super-resolution, motion deblurring, image dehazing, image desnowing and underwater/low-light enhancement demonstrate that PW-FNet not only surpasses state-of-the-art methods in restoration quality but also achieves superior efficiency, with significantly reduced parameter size, computational cost and inference time.",
      "authors": [
        "Xingyu Jiang",
        "Ning Gao",
        "Hongkun Dou",
        "Xiuhui Zhang",
        "Xiaoqing Zhong",
        "Yue Deng",
        "and Hongjue Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:15:04+00:00",
          "link": "https://arxiv.org/abs/2507.13663v1",
          "size": "8648kb",
          "version": "v1"
        }
      ],
      "title": "Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13663",
        "HTML": "https://arxiv.org/html/2507.13663v1",
        "PDF": "https://arxiv.org/pdf/2507.13663"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores image restoration using a novel Pyramid Wavelet-Fourier Network but does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13666",
      "abstract": "Large language models (LLMs) have demonstrated state-of-the-art performance across a wide range of natural language processing tasks. However, high-performing models are typically accessible only via APIs, incurring substantial inference costs. Cascade methods address this by initially employing a cheaper model and escalating to a stronger one only when necessary. Nevertheless, existing cascade approaches struggle to select a reliable representative response and assess the overall reliability of free-form outputs, as they rely on exact text matching. To overcome these limitations, we propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient free-form text generation. KiC identifies the most representative answer among multiple outputs from a weaker model and evaluates the semantic alignment of other responses with it. Based on the degree of alignment, KiC determines whether to accept the weaker model's output or escalate to a stronger model. Experiments on three free-form text generation benchmarks show that KiC achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81 percent on average, and even outperforms GPT-4 in a specific benchmark.",
      "authors": [
        "Woo-Chan Kim",
        "Ji-Hoon Park",
        "and Seong-Whan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:34:36+00:00",
          "link": "https://arxiv.org/abs/2507.13666v1",
          "size": "1039kb",
          "version": "v1"
        }
      ],
      "title": "KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13666",
        "HTML": "https://arxiv.org/html/2507.13666v1",
        "PDF": "https://arxiv.org/pdf/2507.13666"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a cost-efficient method for using LLMs through Keyword-inspired Cascade (KiC), which is tangentially related to data processing by optimizing model selection based on generated outputs, yet it lacks direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13671",
      "abstract": "We investigate the structure and reconstruction complexity of Manacher arrays. First, we establish a combinatorial lower bound, proving that the number of rooted tandem repeat trees with $n+1$ genes exceeds the number of distinct Manacher arrays of length $n$. Second, we introduce a graph-theoretic framework that associates a graph to each Manacher array, where every proper vertex coloring yields a string consistent with the array. Finally, we analyze a reconstruction algorithm by I et al. (SPIRE 2010), showing that it simultaneously achieves a globally minimal alphabet size, uses at most $\\log_2(n{-}1) + 2$ distinct symbols, and can be adapted to produce reconstructions over arbitrary alphabets when possible. Our results also resolve an open problem posed by the original authors. Together, these findings advance the combinatorial understanding of Manacher arrays and open new directions for string reconstruction under structural constraints.",
      "authors": [
        "Michael Itzhaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:49:10+00:00",
          "link": "https://arxiv.org/abs/2507.13671v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Combinatorics of Palindromes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13671",
        "PDF": "https://arxiv.org/pdf/2507.13671"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the combinatorial and graph-theoretic properties of Manacher arrays, unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13672",
      "abstract": "This study addresses the challenge of ensuring safe spacecraft proximity operations, focusing on collision avoidance between a chaser spacecraft and a complex-geometry target spacecraft under disturbances. To ensure safety in such scenarios, a safe robust control framework is proposed that leverages implicit neural representations. To handle arbitrary target geometries without explicit modeling, a neural signed distance function (SDF) is learned from point cloud data via a enhanced implicit geometric regularization method, which incorporates an over-apporximation strategy to create a conservative, safety-prioritized boundary. The target's surface is implicitly defined by the zero-level set of the learned neural SDF, while the values and gradients provide critical information for safety controller design. This neural SDF representation underpins a two-layer hierarchcial safe robust control framework: a safe velocity generation layer and a safe robust controller layer. In the first layer, a second-order cone program is formulated to generate safety-guaranteed reference velocity by explicitly incorporating the under-approximation error bound. Furthermore, a circulation inequality is introduced to mitigate the local minimum issues commonly encountered in control barrier function (CBF) methods. The second layer features an integrated disturbance observer and a smooth safety filter explicitly compensating for estimation error, bolstering robustness to external disturbances. Extensive numerical simulations and Monte Carlo analysis validate the proposed framework, demonstrating significantly improved safety margins and avoidance of local minima compared to conventional CBF approaches.",
      "authors": [
        "Hang Zhou",
        "Tao Meng",
        "Kun Wang",
        "Chengrui Shi",
        "Renhao Mao",
        "Weijia Wang",
        "Jiakun Lei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:49:55+00:00",
          "link": "https://arxiv.org/abs/2507.13672v1",
          "size": "8765kb",
          "version": "v1"
        }
      ],
      "title": "Spacecraft Safe Robust Control Using Implicit Neural Representation for Geometrically Complex Targets in Proximity Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13672",
        "HTML": "https://arxiv.org/html/2507.13672v1",
        "PDF": "https://arxiv.org/pdf/2507.13672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a safe robust control framework for spacecraft proximity operations, leveraging implicit neural representations. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13673",
      "abstract": "In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of hands and objects from monocular RGB input remains highly challenging due to the inherent geometric ambiguity of RGB images and the severe mutual occlusions that occur during interaction.To address these challenges, we propose MaskHOI, a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI pose estimation. Our core idea is to leverage the masking-then-reconstruction strategy of MAE to encourage the feature encoder to infer missing spatial and structural information, thereby facilitating geometric-aware and occlusion-robust representation learning. Specifically, based on our observation that human hands exhibit far greater geometric complexity than rigid objects, conventional uniform masking fails to effectively guide the reconstruction of fine-grained hand structures. To overcome this limitation, we introduce a Region-specific Mask Ratio Allocation, primarily comprising the region-specific masking assignment and the skeleton-driven hand masking guidance. The former adaptively assigns lower masking ratios to hand regions than to rigid objects, balancing their feature learning difficulty, while the latter prioritizes masking critical hand parts (e.g., fingertips or entire fingers) to realistically simulate occlusion patterns in real-world interactions. Furthermore, to enhance the geometric awareness of the pretrained encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven multimodal learning mechanism. Through the self-masking 3D SDF prediction, the learned encoder is able to perceive the global geometric structure of hands and objects beyond the 2D image plane, overcoming the inherent limitations of monocular input and alleviating self-occlusion issues. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art approaches.",
      "authors": [
        "Yuechen Xie",
        "Haobo Jiang",
        "Jian Yang",
        "Yigong Zhang",
        "Jin Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:52:37+00:00",
          "link": "https://arxiv.org/abs/2507.13673v1",
          "size": "4046kb",
          "version": "v1"
        }
      ],
      "title": "MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13673",
        "HTML": "https://arxiv.org/html/2507.13673v1",
        "PDF": "https://arxiv.org/pdf/2507.13673"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses MaskHOI, a framework for 3D hand-object interaction estimation using a Masked Autoencoder. It focuses on pose estimation and representation learning, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13676",
      "abstract": "This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to provide Integrated Sensing and Communication (ISAC) services. The performance of both communication and sensing fundamentally depends on the availability of accurate and up-to-date channel state information (CSI). In modern 5G networks, uplink CSI is derived from two reference signals: the demodulation reference signal (DMRS) and the sounding reference signal (SRS). However, current base station implementations treat these CSI measurements as separate information streams. The key innovation of CARTS is to fuse these two CSI streams, thereby increasing the frequency of CSI updates and extending sensing opportunities to more users. CARTS addresses two key challenges: (i) a novel channel stitching and compensation method that integrates asynchronous CSI estimates from DMRS and SRS, despite their different time and frequency allocations, and (ii) a real-time SRS triggering algorithm that complements the inherently uncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing opportunities for all users. Our trace-driven evaluation shows that CARTS significantly improves scalability, achieving a channel estimation error (NMSE) of 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of users as a periodic SRS-only baseline with similar performance. By opportunistically combining DMRS and SRS, CARTS therefore provides a practical, standard-compliant solution to improve CSI availability for ISAC without requiring additional radio resources.",
      "authors": [
        "Cheng Jiang",
        "Yihe Yan",
        "Yanxiang Wang",
        "Jiawei Hu",
        "Chun Tung Chou",
        "Wen Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:02:03+00:00",
          "link": "https://arxiv.org/abs/2507.13676v1",
          "size": "5091kb",
          "version": "v1"
        }
      ],
      "title": "CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13676",
        "HTML": "https://arxiv.org/html/2507.13676v1",
        "PDF": "https://arxiv.org/pdf/2507.13676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents CARTS, an adaptive sensing scheme for 5G ISAC services, which involves improving channel state information. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13677",
      "abstract": "Real-world Vehicle-to-Everything (V2X) cooperative perception systems often operate under heterogeneous sensor configurations due to cost constraints and deployment variability across vehicles and infrastructure. This heterogeneity poses significant challenges for feature fusion and perception reliability. To address these issues, we propose HeCoFuse, a unified framework designed for cooperative perception across mixed sensor setups where nodes may carry Cameras (C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that adaptively weights features through a combination of channel-wise and spatial attention, HeCoFuse can tackle critical challenges such as cross-modality feature misalignment and imbalanced representation quality. In addition, an adaptive spatial resolution adjustment module is employed to balance computational cost and fusion effectiveness. To enhance robustness across different configurations, we further implement a cooperative learning strategy that dynamically adjusts fusion type based on available modalities. Experiments on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22% 3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine heterogeneous sensor configurations. These results, validated by our first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust performance across diverse sensor deployments.",
      "authors": [
        "Chuheng Wei",
        "Ziye Qin",
        "Walter Zimmer",
        "Guoyuan Wu",
        "Matthew J. Barth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:02:22+00:00",
          "link": "https://arxiv.org/abs/2507.13677v1",
          "size": "17258kb",
          "version": "v1"
        }
      ],
      "title": "HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13677",
        "HTML": "https://arxiv.org/html/2507.13677v1",
        "PDF": "https://arxiv.org/pdf/2507.13677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes HeCoFuse, a framework for cooperative perception in V2X systems using heterogeneous sensors. It is concerned with feature fusion and sensor data, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13678",
      "abstract": "Coordinating multi-agent systems requires balancing synchronization performance and controller implementation costs. To this end, we classify agents by their intrinsic properties, enabling each group to be controlled by a uniform controller and thus reducing the number of unique controller types required. Existing centralized control methods, despite their capability to achieve high synchronization performance with fewer types of controllers, suffer from critical drawbacks such as limited scalability and vulnerability to single points of failure. On the other hand, distributed control strategies, where controllers are typically agent-dependent, result in the type of required controllers increasing proportionally with the size of the system.\n  This paper introduces a novel phase-alignment-based framework to minimize the type of controllers by strategically clustering agents with aligned synchronization behaviors. Leveraging the intrinsic phase properties of complex matrices, we formulate a constrained clustering problem and propose a hierarchical optimization method combining recursive exact searches for small-scale systems and scalable stochastic approximations for large-scale networks. This work bridges theoretical phase analysis with practical control synthesis, offering a cost-effective solution for large-scale multi-agent systems. The theoretical results applied for the analysis of a 50-agent network illustrate the effectiveness of the proposed algorithms.",
      "authors": [
        "Honghao Wu",
        "Kemi Ding and Li Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:04:50+00:00",
          "link": "https://arxiv.org/abs/2507.13678v1",
          "size": "745kb",
          "version": "v1"
        }
      ],
      "title": "Minimum Clustering of Matrices Based on Phase Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13678",
        "HTML": "https://arxiv.org/html/2507.13678v1",
        "PDF": "https://arxiv.org/pdf/2507.13678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a phase-alignment-based framework for clustering in multi-agent systems. It is focused on synchronization and control, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13681",
      "abstract": "Multi-turn dialogues are essential in many real-world applications of large language models, such as chatbots and virtual assistants. As conversation histories become longer, existing large language models face increasing computational and memory challenges, which hinder their ability to provide efficient and responsive interactions. Most current acceleration methods either compress the context or optimize key value caching, but they often rely on fixed or position-based heuristics that do not adapt well to the dynamic and unpredictable patterns found in actual multi-turn conversations. In this paper, we present LoopServe, an adaptive dual-phase inference acceleration framework for large language models in multi-turn dialogues. LoopServe introduces two main innovations. First, it performs online sparsification during the prefilling phase by dynamically selecting the most important parts of the attention matrix for each new input. Second, it uses progressive key value compression during decoding by adaptively maintaining a relevant and efficient cache based on the most recently generated output tokens. We also propose a \\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new benchmark} with eleven multi-turn datasets that reflect realistic query positions and conversational dependencies. Extensive experiments demonstrate that LoopServe consistently achieves superior effectiveness compared to existing baselines and significantly accelerates LLM inference across a wide range of long-context dialogue tasks.",
      "authors": [
        "Haoyang Li",
        "Zhanchao Xu",
        "Yiming Li",
        "Xuejia Chen",
        "Darian Li",
        "Anxin Tian",
        "Qingfa Xiao",
        "Cheng Deng",
        "Jun Wang",
        "Qing Li",
        "Lei Chen",
        "Mingxuan Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:12:08+00:00",
          "link": "https://arxiv.org/abs/2507.13681v1",
          "size": "676kb",
          "version": "v1"
        }
      ],
      "title": "LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13681",
        "HTML": "https://arxiv.org/html/2507.13681v1",
        "PDF": "https://arxiv.org/pdf/2507.13681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces LoopServe, an acceleration system for LLM inference in multi-turn dialogues and a new benchmark with multi-turn datasets. While it involves datasets to evaluate performance, its primary focus is on improving inference acceleration rather than significant contributions to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13685",
      "abstract": "This study addresses a critical challenge in time series anomaly detection: enhancing the predictive capability of loan default models more than three months in advance to enable early identification of default events, helping financial institutions implement preventive measures before risk events materialize. Existing methods have significant drawbacks, such as their lack of accuracy in early predictions and their dependence on training and testing within the same year and specific time frames. These issues limit their practical use, particularly with out-of-time data. To address these, the study introduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge Kolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long Short-Term Memory (LSTM) networks. The proposed models were evaluated against the baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms of accuracy, precision, recall, F1 and AUC in different lengths of feature window, sample sizes, and early prediction intervals. The results demonstrate that the proposed model achieves a prediction accuracy of over 92% three months in advance and over 88% eight months in advance, significantly outperforming existing baselines.",
      "authors": [
        "Yue Yang",
        "Zihan Su",
        "Ying Zhang",
        "Chang Chuan Goh",
        "Yuxiang Lin",
        "Anthony Graham Bellotti",
        "Boon Giin Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:20:41+00:00",
          "link": "https://arxiv.org/abs/2507.13685v1",
          "size": "1354kb",
          "version": "v1"
        }
      ],
      "title": "Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13685",
        "HTML": "https://arxiv.org/html/2507.13685v1",
        "PDF": "https://arxiv.org/pdf/2507.13685"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on enhancing time series anomaly detection models for loan default prediction using new LSTM and GRU architectures. It does not address LLM training data processing or any related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13686",
      "abstract": "Large language models (LLMs) have shown remarkable performance across a range of NLP tasks. However, their strong instruction-following capabilities and inability to distinguish instructions from data content make them vulnerable to indirect prompt injection attacks. In such attacks, instructions with malicious purposes are injected into external data sources, such as web documents. When LLMs retrieve this injected data through tools, such as a search engine and execute the injected instructions, they provide misled responses. Recent attack methods have demonstrated potential, but their abrupt instruction injection often undermines their effectiveness. Motivated by the limitations of existing attack methods, we propose TopicAttack, which prompts the LLM to generate a fabricated conversational transition prompt that gradually shifts the topic toward the injected instruction, making the injection smoother and enhancing the plausibility and success of the attack. Through comprehensive experiments, TopicAttack achieves state-of-the-art performance, with an attack success rate (ASR) over 90\\% in most cases, even when various defense methods are applied. We further analyze its effectiveness by examining attention scores. We find that a higher injected-to-original attention ratio leads to a greater success probability, and our method achieves a much higher ratio than the baseline methods.",
      "authors": [
        "Yulin Chen",
        "Haoran Li",
        "Yuexin Li",
        "Yue Liu",
        "Yangqiu Song",
        "Bryan Hooi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:23:31+00:00",
          "link": "https://arxiv.org/abs/2507.13686v1",
          "size": "177kb",
          "version": "v1"
        }
      ],
      "title": "TopicAttack: An Indirect Prompt Injection Attack via Topic Transition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13686",
        "HTML": "https://arxiv.org/html/2507.13686v1",
        "PDF": "https://arxiv.org/pdf/2507.13686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents TopicAttack, focusing on indirect prompt injection attacks on LLMs. It discusses vulnerabilities and attack strategies but does not involve LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13687",
      "abstract": "Multi-target tracking (MTT) serves as a cornerstone technology in information fusion, yet faces significant challenges in robustness and efficiency when dealing with model uncertainties, clutter interference, and target interactions. Conventional approaches like Gaussian Mixture PHD (GM-PHD) and Cardinalized PHD (CPHD) filters suffer from inherent limitations including combinatorial explosion, sensitivity to birth/death process parameters, and numerical instability. This study proposes an innovative minimax robust PHD filtering framework with four key contributions: (1) A theoretically derived robust GM-PHD recursion algorithm that achieves optimal worst-case error control under bounded uncertainties; (2) An adaptive real-time parameter adjustment mechanism ensuring stability and error bounds; (3) A generalized heavy-tailed measurement likelihood function maintaining polynomial computational complexity; (4) A novel partition-based credibility weighting method for extended targets. The research not only establishes rigorous convergence guarantees and proves the uniqueness of PHD solutions, but also verifies algorithmic equivalence with standard GM-PHD. Experimental results demonstrate that in high-clutter environments, this method achieves a remarkable 32.4% reduction in OSPA error and 25.3% lower cardinality RMSE compared to existing techniques, while maintaining real-time processing capability at 15.3 milliseconds per step. This breakthrough lays a crucial foundation for reliable MTT in safety-critical applications.",
      "authors": [
        "Ming Lei and Shufan Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:32:07+00:00",
          "link": "https://arxiv.org/abs/2507.13687v1",
          "size": "191kb",
          "version": "v1"
        }
      ],
      "title": "Robust Probability Hypothesis Density Filtering: Theory and Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13687",
        "HTML": "https://arxiv.org/html/2507.13687v1",
        "PDF": "https://arxiv.org/pdf/2507.13687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses challenges in multi-target tracking with PHD filtering improvements. It does not relate to LLM training data processing or any data operations specific to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13689",
      "abstract": "Sparse block interleaver division multiple access (SB-IDMA) is a recently introduced unsourced multiple access protocol that aims to improve the performance of the grant-free two-step random access transmission protocol of the 3GPP 5G New Radio standard. We introduced a density evolution analysis of the successive interference cancellation receiver of SB-IDMA, providing a theoretical characterization of its performance.",
      "authors": [
        "Jean-Francois Chamberland and Gianluigi Liva and Krishna Narayanan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:40:03+00:00",
          "link": "https://arxiv.org/abs/2507.13689v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Density Evolution Analysis of Sparse-Block IDMA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13689",
        "HTML": "https://arxiv.org/html/2507.13689v1",
        "PDF": "https://arxiv.org/pdf/2507.13689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the analysis of a multiple access protocol in wireless communication, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13693",
      "abstract": "The growing demand for structural health monitoring has driven increasing interest in high-precision motion measurement, as structural information derived from extracted motions can effectively reflect the current condition of the structure. Among various motion measurement techniques, vision-based methods stand out due to their low cost, easy installation, and large-scale measurement. However, when it comes to sub-pixel-level motion measurement, current vision-based methods either lack sufficient accuracy or require extensive manual parameter tuning (e.g., pyramid layers, target pixels, and filter parameters) to reach good precision. To address this issue, we developed a novel Gaussian kernel-based motion measurement method, which can extract the motion between different frames via tracking the location of Gaussian kernels. The motion consistency, which fits practical structural conditions, and a super-resolution constraint, are introduced to increase accuracy and robustness of our method. Numerical and experimental validations show that it can consistently reach high accuracy without customized parameter setup for different test samples.",
      "authors": [
        "Hongyi Liu",
        "Haifeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:49:57+00:00",
          "link": "https://arxiv.org/abs/2507.13693v1",
          "size": "3553kb",
          "version": "v1"
        }
      ],
      "title": "Gaussian kernel-based motion measurement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13693",
        "HTML": "https://arxiv.org/html/2507.13693v1",
        "PDF": "https://arxiv.org/pdf/2507.13693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motion measurement techniques using Gaussian kernel-based methods, which are unrelated to LLM training data processing or any aspect of data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13700",
      "abstract": "Most work on adaptive data analysis assumes that samples in the dataset are independent. When correlations are allowed, even the non-adaptive setting can become intractable, unless some structural constraints are imposed. To address this, Bassily and Freund [2016] introduced the elegant framework of concentrated queries, which requires the analyst to restrict itself to queries that are concentrated around their expected value. While this assumption makes the problem trivial in the non-adaptive setting, in the adaptive setting it remains quite challenging. In fact, all known algorithms in this framework support significantly fewer queries than in the independent case: At most $O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the independent setting.\n  In this work, we prove that this utility gap is inherent under the current formulation of the concentrated queries framework, assuming some natural conditions on the algorithm. Additionally, we present a simplified version of the best-known algorithms that match our impossibility result.",
      "authors": [
        "Emma Rapoport",
        "Edith Cohen",
        "Uri Stemmer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:08:42+00:00",
          "link": "https://arxiv.org/abs/2507.13700v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Tight Bounds for Answering Adaptively Chosen Concentrated Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13700",
        "HTML": "https://arxiv.org/html/2507.13700v1",
        "PDF": "https://arxiv.org/pdf/2507.13700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses answering adaptively chosen queries in data analysis with concentrated queries framework, which does not pertain to LLM training data processing or data engineering operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13702",
      "abstract": "Multi-robot localization is a crucial task for implementing multi-robot systems. Numerous researchers have proposed optimization-based multi-robot localization methods that use camera, IMU, and UWB sensors. Nevertheless, characteristics of individual robot odometry estimates and distance measurements between robots used in the optimization are not sufficiently considered. In addition, previous researches were heavily influenced by the odometry accuracy that is estimated from individual robots. Consequently, long-term drift error caused by error accumulation is potentially inevitable. In this paper, we propose a novel visual-inertial-range-based multi-robot localization method, named SaWa-ML, which enables geometric structure-aware pose correction and weight adaptation-based robust multi-robot localization. Our contributions are twofold: (i) we leverage UWB sensor data, whose range error does not accumulate over time, to first estimate the relative positions between robots and then correct the positions of each robot, thus reducing long-term drift errors, (ii) we design adaptive weights for robot pose correction by considering the characteristics of the sensor data and visual-inertial odometry estimates. The proposed method has been validated in real-world experiments, showing a substantial performance increase compared with state-of-the-art algorithms.",
      "authors": [
        "Junho Choi",
        "Kihwan Ryoo",
        "Jeewon Kim",
        "Taeyun Kim",
        "Eungchang Lee",
        "Myeongwoo Jeong",
        "Kevin Christiansen Marsim",
        "Hyungtae Lim",
        "and Hyun Myung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:10:29+00:00",
          "link": "https://arxiv.org/abs/2507.13702v1",
          "size": "4289kb",
          "version": "v1"
        }
      ],
      "title": "SaWa-ML: Structure-Aware Pose Correction and Weight Adaptation-Based Robust Multi-Robot Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13702",
        "HTML": "https://arxiv.org/html/2507.13702v1",
        "PDF": "https://arxiv.org/pdf/2507.13702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a multi-robot localization method integrating visual-inertial-range-based techniques, which does not relate to LLM training data processing or data quality improvements for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13703",
      "abstract": "Physics-inspired graph neural networks (PI-GNNs) have been utilized as an efficient unsupervised framework for relaxing combinatorial optimization problems encoded through a specific graph structure and loss, reflecting dependencies between the problem's variables. While the framework has yielded promising results in various combinatorial problems, we show that the performance of PI-GNNs systematically plummets with an increasing density of the combinatorial problem graphs. Our analysis reveals an interesting phase transition in the PI-GNNs' training dynamics, associated with degenerate solutions for the denser problems, highlighting a discrepancy between the relaxed, real-valued model outputs and the binary-valued problem solutions. To address the discrepancy, we propose principled alternatives to the naive strategy used in PI-GNNs by building on insights from fuzzy logic and binarized neural networks. Our experiments demonstrate that the portfolio of proposed methods significantly improves the performance of PI-GNNs in increasingly dense settings.",
      "authors": [
        "Martin Krutsk\\'y",
        "Gustav \\v{S}\\'ir",
        "Vyacheslav Kungurtsev",
        "Georgios Korpas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:11:50+00:00",
          "link": "https://arxiv.org/abs/2507.13703v1",
          "size": "1053kb",
          "version": "v1"
        }
      ],
      "title": "Binarizing Physics-Inspired GNNs for Combinatorial Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13703",
        "HTML": "https://arxiv.org/html/2507.13703v1",
        "PDF": "https://arxiv.org/pdf/2507.13703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with enhancing physics-inspired graph neural networks for combinatorial optimization, not related to LLM training data processing or any data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13704",
      "abstract": "Multi-objective Bayesian optimization (MOBO) provides a principled framework for navigating trade-offs in molecular design. However, its empirical advantages over scalarized alternatives remain underexplored. We benchmark a simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) -- against a simple fixed-weight scalarized baseline using Expected Improvement (EI), under a tightly controlled setup with identical Gaussian Process surrogates and molecular representations. Across three molecular optimization tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front coverage, convergence speed, and chemical diversity. While scalarization encompasses flexible variants -- including random or adaptive schemes -- our results show that even strong deterministic instantiations can underperform in low-data regimes. These findings offer concrete evidence for the practical advantages of Pareto-aware acquisition in de novo molecular optimization, especially when evaluation budgets are limited and trade-offs are nontrivial.",
      "authors": [
        "Anabel Yong",
        "Austin Tripp",
        "Layla Hosseini-Gerami",
        "Brooks Paige"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:12:19+00:00",
          "link": "https://arxiv.org/abs/2507.13704v1",
          "size": "124kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13704",
        "HTML": "https://arxiv.org/html/2507.13704v1",
        "PDF": "https://arxiv.org/pdf/2507.13704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on multi-objective Bayesian optimization for molecular design, which does not contribute to LLM training data processing or involve any pertinent data processing operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13705",
      "abstract": "Large Language Models (LLMs) are increasingly being implemented as joint decision-makers and explanation generators for Group Recommender Systems (GRS). In this paper, we evaluate these recommendations and explanations by comparing them to social choice-based aggregation strategies. Our results indicate that LLM-generated recommendations often resembled those produced by Additive Utilitarian (ADD) aggregation. However, the explanations typically referred to averaging ratings (resembling but not identical to ADD aggregation). Group structure, uniform or divergent, did not impact the recommendations. Furthermore, LLMs regularly claimed additional criteria such as user or item similarity, diversity, or used undefined popularity metrics or thresholds. Our findings have important implications for LLMs in the GRS pipeline as well as standard aggregation strategies. Additional criteria in explanations were dependent on the number of ratings in the group scenario, indicating potential inefficiency of standard aggregation methods at larger item set sizes. Additionally, inconsistent and ambiguous explanations undermine transparency and explainability, which are key motivations behind the use of LLMs for GRS.",
      "authors": [
        "Cedric Waterschoot",
        "Nava Tintarev",
        "Francesco Barile"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:20:52+00:00",
          "link": "https://arxiv.org/abs/2507.13705v1",
          "size": "311kb",
          "version": "v1"
        }
      ],
      "title": "Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13705",
        "HTML": "https://arxiv.org/html/2507.13705v1",
        "PDF": "https://arxiv.org/pdf/2507.13705"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the evaluation of LLM-generated recommendations and explanations for Group Recommender Systems, without addressing data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13706",
      "abstract": "This paper introduces two quasi-metrics for performance assessment of multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an extension of the generalised optimal subpattern assignment (GOSPA) metric and measures the discrepancy between sets of objects. The other quasi-metric is an extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy between sets of trajectories. Similar to the GOSPA-based metrics, these quasi-metrics include costs for localisation error for properly detected objects, the number of false objects and the number of missed objects. The T-GOSPA quasi-metric also includes a track switching cost. Differently from the GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of penalising missed and false objects with different costs, and the localisation costs are not required to be symmetric. These properties can be useful in MOT evaluation in certain applications. The performance of several Bayesian MOT algorithms is assessed with the T-GOSPA quasi-metric via simulations.",
      "authors": [
        "\\'Angel F. Garc\\'ia-Fern\\'andez",
        "Jinhao Gu",
        "Lennart Svensson",
        "Yuxuan Xia",
        "Jan Krej\\v{c}\\'i",
        "Oliver Kost",
        "Ond\\v{r}ej Straka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:25:41+00:00",
          "link": "https://arxiv.org/abs/2507.13706v1",
          "size": "201kb",
          "version": "v1"
        }
      ],
      "title": "GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13706",
        "HTML": "https://arxiv.org/html/2507.13706v1",
        "PDF": "https://arxiv.org/pdf/2507.13706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces quasi-metrics for evaluating multi-object tracking algorithms, which is unrelated to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13707",
      "abstract": "Simulating interactions between deformable bodies is vital in fields like material science, mechanical design, and robotics. While learning-based methods with Graph Neural Networks (GNNs) are effective at solving complex physical systems, they encounter scalability issues when modeling deformable body interactions. To model interactions between objects, pairwise global edges have to be created dynamically, which is computationally intensive and impractical for large-scale meshes. To overcome these challenges, drawing on insights from geometric representations, we propose an Adaptive Spatial Tokenization (AST) method for efficient representation of physical states. By dividing the simulation space into a grid of cells and mapping unstructured meshes onto this structured grid, our approach naturally groups adjacent mesh nodes. We then apply a cross-attention module to map the sparse cells into a compact, fixed-length embedding, serving as tokens for the entire physical state. Self-attention modules are employed to predict the next state over these tokens in latent space. This framework leverages the efficiency of tokenization and the expressive power of attention mechanisms to achieve accurate and scalable simulation results. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art approaches in modeling deformable body interactions. Notably, it remains effective on large-scale simulations with meshes exceeding 100,000 nodes, where existing methods are hindered by computational limitations. Additionally, we contribute a novel large-scale dataset encompassing a wide range of deformable body interactions to support future research in this area.",
      "authors": [
        "Hao Wang",
        "Yu Liu",
        "Daniel Biggs",
        "Haoru Wang",
        "Jiandong Yu",
        "Ping Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:27:35+00:00",
          "link": "https://arxiv.org/abs/2507.13707v1",
          "size": "39039kb",
          "version": "v1"
        }
      ],
      "title": "Learning Deformable Body Interactions With Adaptive Spatial Tokenization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13707",
        "HTML": "https://arxiv.org/html/2507.13707v1",
        "PDF": "https://arxiv.org/pdf/2507.13707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper contributes a novel dataset for deformable body interactions, which supports future research but is not directly related to LLM training data processing, as it focuses on physical simulations rather than NLP data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13708",
      "abstract": "Recent advancements in text-to-image diffusion models have achieved remarkable success in generating realistic and diverse visual content. A critical factor in this process is the model's ability to accurately interpret textual prompts. However, these models often struggle with creative expressions, particularly those involving complex, abstract, or highly descriptive language. In this work, we introduce a novel training-free approach tailored to improve image generation for a unique form of creative language: poetic verse, which frequently features layered, abstract, and dual meanings. Our proposed PoemTale Diffusion approach aims to minimise the information that is lost during poetic text-to-image conversion by integrating a multi stage prompt refinement loop into Language Models to enhance the interpretability of poetic texts. To support this, we adapt existing state-of-the-art diffusion models by modifying their self-attention mechanisms with a consistent self-attention technique to generate multiple consistent images, which are then collectively used to convey the poem's meaning. Moreover, to encourage research in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting of 1111 poems sourced from multiple online and offline resources. We engaged a panel of poetry experts for qualitative assessments. The results from both human and quantitative evaluations validate the efficacy of our method and contribute a novel perspective to poem-to-image generation with enhanced information capture in the generated images.",
      "authors": [
        "Sofia Jamil",
        "Bollampalli Areen Reddy",
        "Raghvendra Kumar",
        "Sriparna Saha",
        "Koustava Goswami",
        "K.J. Joseph"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:33:08+00:00",
          "link": "https://arxiv.org/abs/2507.13708v1",
          "size": "17801kb",
          "version": "v1"
        }
      ],
      "title": "PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13708",
        "HTML": "https://arxiv.org/html/2507.13708v1",
        "PDF": "https://arxiv.org/pdf/2507.13708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces the P4I (PoemForImage) dataset, its main focus is on improving poem-to-image generation, not LLM pretraining or fine-tuning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13710",
      "abstract": "Data preparation is a foundational yet notoriously challenging component of the machine learning lifecycle, characterized by a vast combinatorial search space of potential operator sequences. While reinforcement learning (RL) offers a promising direction, existing approaches are inefficient as they fail to capture the structured, hierarchical nature of the problem. We argue that Hierarchical Reinforcement Learning (HRL), a paradigm that has been successful in other domains, provides a conceptually ideal yet previously unexplored framework for this task. However, a naive HRL implementation with a `hard hierarchy' is prone to suboptimal, irreversible decisions. To address this, we introduce CogniQ-H, the first framework to implement a soft hierarchical paradigm for robust, end-to-end automated data preparation. CogniQ-H formulates action selection as a Bayesian inference problem. A high-level strategic prior, generated by a Large Language Model (LLM), guides exploration probabilistically. This prior is synergistically combined with a fine-grained operator quality score from a supervised Learning-to-Rank (LTR) model and a long-term value estimate from the agent's own Q-function. This hybrid architecture allows CogniQ-H to balance strategic guidance with adaptive, evidence-based decision-making. Through extensive experiments on 18 diverse datasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to 13.9\\% improvement in pipeline quality and 2.8$\\times$ faster convergence compared to state-of-the-art RL-based methods.",
      "authors": [
        "Jing Chang",
        "Chang Liu",
        "Jinbin Huang",
        "Rui Mao",
        "Jianbin Qin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:43:22+00:00",
          "link": "https://arxiv.org/abs/2507.13710v1",
          "size": "444kb",
          "version": "v1"
        }
      ],
      "title": "CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13710",
        "HTML": "https://arxiv.org/html/2507.13710v1",
        "PDF": "https://arxiv.org/pdf/2507.13710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents CogniQ-H, a framework for automated data preparation using hierarchical reinforcement learning, involving a large language model (LLM) in the strategic guidance. This contributes to the training data processing for LLMs by focusing on data preparation in machine learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13712",
      "abstract": "Automated data preparation is crucial for democratizing machine learning, yet existing reinforcement learning (RL) based approaches suffer from inefficient exploration in the vast space of possible preprocessing pipelines. We present LLaPipe, a novel framework that addresses this exploration bottleneck by integrating Large Language Models (LLMs) as intelligent policy advisors. Unlike traditional methods that rely solely on statistical features and blind trial-and-error, LLaPipe leverages the semantic understanding capabilities of LLMs to provide contextually relevant exploration guidance. Our framework introduces three key innovations: (1) an LLM Policy Advisor that analyzes dataset semantics and pipeline history to suggest promising preprocessing operations, (2) an Experience Distillation mechanism that mines successful patterns from past pipelines and transfers this knowledge to guide future exploration, and (3) an Adaptive Advisor Triggering strategy (Advisor\\textsuperscript{+}) that dynamically determines when LLM intervention is most beneficial, balancing exploration effectiveness with computational cost. Through extensive experiments on 18 diverse datasets spanning multiple domains, we demonstrate that LLaPipe achieves up to 22.4\\% improvement in pipeline quality and 2.3$\\times$ faster convergence compared to state-of-the-art RL-based methods, while maintaining computational efficiency through selective LLM usage (averaging only 19.0\\% of total exploration steps).",
      "authors": [
        "Jing Chang",
        "Chang Liu",
        "Jinbin Huang",
        "Rui Mao",
        "Jianbin Qin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:52:19+00:00",
          "link": "https://arxiv.org/abs/2507.13712v1",
          "size": "302kb",
          "version": "v1"
        }
      ],
      "title": "LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13712",
        "HTML": "https://arxiv.org/html/2507.13712v1",
        "PDF": "https://arxiv.org/pdf/2507.13712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents LLaPipe, a framework using LLMs for reinforcement learning to improve data preparation pipelines. While it discusses data preparation, its focus is more on using LLMs for exploration in RL rather than on LLM-specific data processing operations like those for training data of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13716",
      "abstract": "Parkinson's Disease PD is a progressive neurodegenerative disorder that affects motor and cognitive functions with early diagnosis being critical for effective clinical intervention Electroencephalography EEG offers a noninvasive and costeffective means of detecting PDrelated neural alterations yet the development of reliable automated diagnostic models remains a challenge In this study we conduct a systematic benchmark of traditional machine learning ML and deep learning DL models for classifying PD using a publicly available oddball task dataset Our aim is to lay the groundwork for developing an effective learning system and to determine which approach produces the best results We implement a unified sevenstep preprocessing pipeline and apply consistent subjectwise crossvalidation and evaluation criteria to ensure comparability across models Our results demonstrate that while baseline deep learning architectures particularly CNNLSTM models achieve the best performance compared to other deep learning architectures underlining the importance of capturing longrange temporal dependencies several traditional classifiers such as XGBoost also offer strong predictive accuracy and calibrated decision boundaries By rigorously comparing these baselines our work provides a solid reference framework for future studies aiming to develop and evaluate more complex or specialized architectures Establishing a reliable set of baseline results is essential to contextualize improvements introduced by novel methods ensuring scientific rigor and reproducibility in the evolving field of EEGbased neurodiagnostics",
      "authors": [
        "Danilo Avola",
        "Andrea Bernardini",
        "Giancarlo Crocetti",
        "Andrea Ladogana",
        "Mario Lezoche",
        "Maurizio Mancini",
        "Daniele Pannone",
        "Amedeo Ranaldi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:59:17+00:00",
          "link": "https://arxiv.org/abs/2507.13716v1",
          "size": "1013kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13716",
        "HTML": "https://arxiv.org/html/2507.13716v1",
        "PDF": "https://arxiv.org/pdf/2507.13716"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper benchmarks EEG analysis techniques for Parkinson's Disease, comparing ML and DL methodologies. It is centered on evaluating diagnostic models and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13717",
      "abstract": "The growing scale and complexity of reconfigurable data center networks (DCNs) demand more scalable and efficient algorithms for computing logical topologies and routing. Reconfigurable DCNs typically operate in two modes: one-hop configurations that require frequent topology optimization (TO), and multi-hop scenarios that involve joint topology and routing optimization (TRO). In both cases, the combinatorial nature of topology decisions makes it difficult for existing methods to balance solution quality and runtime efficiency. To address this, we introduce Alternating Topology and Routing Optimization (ATRO), a solver-free framework that alternates between TO and routing optimization (RO). This decomposition exploits two key insights: first, each alternating update step monotonically reduces maximum link utilization (MLU), ensuring consistent performance improvement across iterations; second, the TO subproblem, equivalent to one-hop optimization, exhibits a monotonic structure that enables optimal solutions via an efficient Accelerated Binary Search Method (ABSM). To preserve the solver-free design, RO is solved using existing Traffic Engineering accelerators. ATRO attains the global optimum in one-hop scenarios and significantly outperforms baselines in multi-hop settings in terms of both runtime and solution quality. Evaluations confirm its scalability and robustness across diverse DCNs.",
      "authors": [
        "Yingming Mao",
        "Qiaozhu Zhai",
        "Zhen Yao",
        "Xia Zhu",
        "Ximeng Liu",
        "Xinchi Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:59:19+00:00",
          "link": "https://arxiv.org/abs/2507.13717v1",
          "size": "488kb",
          "version": "v1"
        }
      ],
      "title": "ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13717",
        "HTML": "https://arxiv.org/html/2507.13717v1",
        "PDF": "https://arxiv.org/pdf/2507.13717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an algorithm for topology and routing optimization in datacenter networks. It does not pertain to LLM training data processing, focusing instead on network optimization solutions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13718",
      "abstract": "Deception detection is a significant challenge in fields such as security, psychology, and forensics. This study presents a deep learning approach for classifying deceptive and truthful behavior using ElectroEncephaloGram (EEG) signals from the Bag-of-Lies dataset, a multimodal corpus designed for naturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit (Bi-GRU) neural network was trained to perform binary classification of EEG samples. The model achieved a test accuracy of 97\\%, along with high precision, recall, and F1-scores across both classes. These results demonstrate the effectiveness of using bidirectional temporal modeling for EEG-based deception detection and suggest potential for real-time applications and future exploration of advanced neural architectures.",
      "authors": [
        "Danilo Avola",
        "Muhammad Yasir Bilal",
        "Emad Emam",
        "Cristina Lakasz",
        "Daniele Pannone",
        "Amedeo Ranaldi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:59:23+00:00",
          "link": "https://arxiv.org/abs/2507.13718v1",
          "size": "834kb",
          "version": "v1"
        }
      ],
      "title": "Bi-GRU Based Deception Detection using EEG Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13718",
        "HTML": "https://arxiv.org/html/2507.13718v1",
        "PDF": "https://arxiv.org/pdf/2507.13718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study uses Bi-GRU networks for EEG-based deception detection. It relates to neural model application in deception detection rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13719",
      "abstract": "This paper presents an innovative augmented reality pipeline tailored for museum environments, aimed at recognizing artworks and generating accurate 3D models from single images. By integrating two complementary pre-trained depth estimation models, i.e., GLPN for capturing global scene structure and Depth-Anything for detailed local reconstruction, the proposed approach produces optimized depth maps that effectively represent complex artistic features. These maps are then converted into high-quality point clouds and meshes, enabling the creation of immersive AR experiences. The methodology leverages state-of-the-art neural network architectures and advanced computer vision techniques to overcome challenges posed by irregular contours and variable textures in artworks. Experimental results demonstrate significant improvements in reconstruction accuracy and visual realism, making the system a highly robust tool for museums seeking to enhance visitor engagement through interactive digital content.",
      "authors": [
        "Daniele Pannone",
        "Alessia Castronovo",
        "Maurizio Mancini",
        "Gian Luca Foresti",
        "Claudio Piciarelli",
        "Rossana Gabrieli",
        "Muhammad Yasir Bilal",
        "Danilo Avola"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:59:29+00:00",
          "link": "https://arxiv.org/abs/2507.13719v1",
          "size": "4541kb",
          "version": "v1"
        }
      ],
      "title": "Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13719",
        "HTML": "https://arxiv.org/html/2507.13719v1",
        "PDF": "https://arxiv.org/pdf/2507.13719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a 3D artwork reconstruction pipeline for augmented reality applications. It focuses on 3D modeling and computer vision techniques, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13720",
      "abstract": "Quantum computing poses fundamental risks to classical blockchain systems by undermining widely used cryptographic primitives. In response, two major research directions have emerged: post-quantum blockchains, which integrate quantum-resistant algorithms, and quantum blockchains, which leverage quantum properties such as entanglement and quantum key distribution. This survey reviews key developments in both areas, analyzing their cryptographic foundations, architectural designs, and implementation challenges. This work provides a comparative overview of technical proposals, highlight trade-offs in security, scalability, and deployment, and identify open research problems across hardware, consensus, and network design. The goal is to offer a structured and comprehensive reference for advancing secure blockchain systems in the quantum era.",
      "authors": [
        "Saurav Ghosh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Emerging Technologies (cs.ET)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:00:09+00:00",
          "link": "https://arxiv.org/abs/2507.13720v1",
          "size": "495kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13720",
        "PDF": "https://arxiv.org/pdf/2507.13720"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum blockchain technologies, including post-quantum blockchains and quantum blockchains, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13721",
      "abstract": "To address the challenges posed by cascading reactions caused by component failures in autonomous cargo ships (ACS) and the uncertainties in emergency decision-making, this paper proposes a novel hybrid feature fusion framework for constructing a graph-structured dataset of failure modes. By employing an improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to the NSGA-II and CSA search algorithms, respectively. A hierarchical feature fusion framework is constructed, using Word2Vec encoding to encode subsystem/component features, BERT-KPCA to process failure modes/reasons, and Sentence-BERT to quantify the semantic association between failure impact and emergency decision-making. The dataset covers 12 systems, 1,262 failure modes, and 6,150 propagation paths. Validation results show that the GATE-GNN model achieves a classification accuracy of 0.735, comparable to existing benchmarks. Additionally, a silhouette coefficient of 0.641 indicates that the features are highly distinguishable. In the label prediction results, the Shore-based Meteorological Service System achieved an F1 score of 0.93, demonstrating high prediction accuracy. This paper not only provides a solid foundation for failure analysis in autonomous cargo ships but also offers reliable support for fault diagnosis, risk assessment, and intelligent decision-making systems. The link to the dataset is https://github.com/wojiufukele/Graph-Structured-about-CSA.",
      "authors": [
        "Zizhao Zhang",
        "Tianxiang Zhao",
        "Yu Sun",
        "Liping Sun",
        "Jichuan Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:02:49+00:00",
          "link": "https://arxiv.org/abs/2507.13721v1",
          "size": "3644kb",
          "version": "v1"
        }
      ],
      "title": "Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13721",
        "PDF": "https://arxiv.org/pdf/2507.13721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily addresses component failure analysis in autonomous ships using graph-structured data. It includes the creation of a specialized dataset, but the focus is not on LLMs or general language model training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13722",
      "abstract": "In today's digital age, concerns about the dangers of AI-generated images are increasingly common. One powerful tool in this domain is StyleGAN (style-based generative adversarial networks), a generative adversarial network capable of producing highly realistic synthetic faces. To gain a deeper understanding of how such a model operates, this work focuses on analyzing the inner workings of StyleGAN's generator component. Key architectural elements and techniques, such as the Equalized Learning Rate, are explored in detail to shed light on the model's behavior. A StyleGAN model is trained using the PyTorch framework, enabling direct inspection of its learned weights. Through pruning, it is revealed that a significant number of these weights can be removed without drastically affecting the output, leading to reduced computational requirements. Moreover, the role of the latent vector -- which heavily influences the appearance of the generated faces -- is closely examined. Global alterations to this vector primarily affect aspects like color tones, while targeted changes to individual dimensions allow for precise manipulation of specific facial features. This ability to finetune visual traits is not only of academic interest but also highlights a serious ethical concern: the potential misuse of such technology. Malicious actors could exploit this capability to fabricate convincing fake identities, posing significant risks in the context of digital deception and cybercrime.",
      "authors": [
        "Julia Laubmann",
        "Johannes Reschke"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:04:09+00:00",
          "link": "https://arxiv.org/abs/2507.13722v1",
          "size": "15078kb",
          "version": "v1"
        }
      ],
      "title": "Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13722",
        "HTML": "https://arxiv.org/html/2507.13722v1",
        "PDF": "https://arxiv.org/pdf/2507.13722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes StyleGAN, a generative adversarial network model, focusing on its inner workings and potential misuse, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13725",
      "abstract": "Point of interest (POI) recommendation can play a pivotal role in enriching tourists' experiences by suggesting context-dependent and preference-matching locations and activities, such as restaurants, landmarks, itineraries, and cultural attractions. Unlike some more common recommendation domains (e.g., music and video), POI recommendation is inherently high-stakes: users invest significant time, money, and effort to search, choose, and consume these suggested POIs. Despite the numerous research works in the area, several fundamental issues remain unresolved, hindering the real-world applicability of the proposed approaches. In this paper, we discuss the current status of the POI recommendation problem and the main challenges we have identified. The first contribution of this paper is a critical assessment of the current state of POI recommendation research and the identification of key shortcomings across three main dimensions: datasets, algorithms, and evaluation methodologies. We highlight persistent issues such as the lack of standardized benchmark datasets, flawed assumptions in the problem definition and model design, and inadequate treatment of biases in the user behavior and system performance. The second contribution is a structured research agenda that, starting from the identified issues, introduces important directions for future work related to multistakeholder design, context awareness, data collection, trustworthiness, novel interactions, and real-world evaluation.",
      "authors": [
        "Alejandro Bellog\\'in and Linus W. Dietz and Francesco Ricci and Pablo S\\'anchez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:10:09+00:00",
          "link": "https://arxiv.org/abs/2507.13725v1",
          "size": "382kb",
          "version": "v1"
        }
      ],
      "title": "Point of Interest Recommendation: Pitfalls and Viable Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13725",
        "HTML": "https://arxiv.org/html/2507.13725v1",
        "PDF": "https://arxiv.org/pdf/2507.13725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses point of interest (POI) recommendation systems, highlighting challenges in datasets and evaluation methodologies for POI. It doesn't address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13727",
      "abstract": "Adversarial training is a promising strategy for enhancing model robustness against adversarial attacks. However, its impact on generalization under substantial data distribution shifts in audio classification remains largely unexplored. To address this gap, this work investigates how different adversarial training strategies improve generalization performance and adversarial robustness in audio classification. The study focuses on two model architectures: a conventional convolutional neural network (ConvNeXt) and an inherently interpretable prototype-based model (AudioProtoPNet). The approach is evaluated using a challenging bird sound classification benchmark. This benchmark is characterized by pronounced distribution shifts between training and test data due to varying environmental conditions and recording methods, a common real-world challenge. The investigation explores two adversarial training strategies: one based on output-space attacks that maximize the classification loss function, and another based on embedding-space attacks designed to maximize embedding dissimilarity. These attack types are also used for robustness evaluation. Additionally, for AudioProtoPNet, the study assesses the stability of its learned prototypes under targeted embedding-space attacks. Results show that adversarial training, particularly using output-space attacks, improves clean test data performance by an average of 10.5% relative and simultaneously strengthens the adversarial robustness of the models. These findings, although derived from the bird sound domain, suggest that adversarial training holds potential to enhance robustness against both strong distribution shifts and adversarial attacks in challenging audio classification settings.",
      "authors": [
        "Ren\\'e Heinrich",
        "Lukas Rauch",
        "Bernhard Sick",
        "Christoph Scholz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:16:13+00:00",
          "link": "https://arxiv.org/abs/2507.13727v1",
          "size": "5610kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13727",
        "HTML": "https://arxiv.org/html/2507.13727v1",
        "PDF": "https://arxiv.org/pdf/2507.13727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on adversarial training in bioacoustic audio classification, particularly under data distribution shifts, which falls outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13729",
      "abstract": "Rare, yet critical, scenarios pose a significant challenge in testing and evaluating autonomous driving planners. Relying solely on real-world driving scenes requires collecting massive datasets to capture these scenarios. While automatic generation of traffic scenarios appears promising, data-driven models require extensive training data and often lack fine-grained control over the output. Moreover, generating novel scenarios from scratch can introduce a distributional shift from the original training scenes which undermines the validity of evaluations especially for learning-based planners. To sidestep this, recent work proposes to generate challenging scenarios by augmenting original scenarios from the test set. However, this involves the manual augmentation of scenarios by domain experts. An approach that is unable to meet the demands for scale in the evaluation of self-driving systems. Therefore, this paper introduces a novel LLM-agent based framework for augmenting real-world traffic scenarios using natural language descriptions, addressing the limitations of existing methods. A key innovation is the use of an agentic design, enabling fine-grained control over the output and maintaining high performance even with smaller, cost-effective LLMs. Extensive human expert evaluation demonstrates our framework's ability to accurately adhere to user intent, generating high quality augmented scenarios comparable to those created manually.",
      "authors": [
        "Yu Yao",
        "Salil Bhatnagar",
        "Markus Mazzola",
        "Vasileios Belagiannis",
        "Igor Gilitschenski",
        "Luigi Palmieri",
        "Simon Razniewski and Marcel Hallgarten"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:20:16+00:00",
          "link": "https://arxiv.org/abs/2507.13729v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13729",
        "HTML": "https://arxiv.org/html/2507.13729v1",
        "PDF": "https://arxiv.org/pdf/2507.13729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating challenging traffic scenarios for autonomous driving systems using an LLM-based framework for scenario augmentation. It does not focus on LLM training data processing for pretraining or fine-tuning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13731",
      "abstract": "Randomized algorithms for low-rank approximation of quaternion matrices have gained increasing attention in recent years. However, existing methods overlook pass efficiency, the ability to limit the number of passes over the input matrix-which is critical in modern computing environments dominated by communication costs. We address this gap by proposing a suite of pass-efficient randomized algorithms that let users directly trade pass budget for approximation accuracy. Our contributions include: (i) a family of arbitrary-pass randomized algorithms for low-rank approximation of quaternion matrices that operate under a user-specified number of matrix views, and (ii) a pass-efficient extension of block Krylov subspace methods that accelerates convergence for matrices with slowly decaying spectra. Furthermore, we establish spectral norm error bounds showing that the expected approximation error decays exponentially with the number of passes. Finally, we validate our framework through extensive numerical experiments and demonstrate its practical relevance across multiple applications, including quaternionic data compression, matrix completion, image super-resolution, and deep learning.",
      "authors": [
        "Salman Ahmadi-Asl",
        "Malihe Nobakht Kooshkghazi",
        "Valentin Leplat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:27:10+00:00",
          "link": "https://arxiv.org/abs/2507.13731v1",
          "size": "5069kb",
          "version": "v1"
        }
      ],
      "title": "Pass-efficient Randomized Algorithms for Low-rank Approximation of Quaternion Matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13731",
        "HTML": "https://arxiv.org/html/2507.13731v1",
        "PDF": "https://arxiv.org/pdf/2507.13731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about developing pass-efficient randomized algorithms for low-rank approximation of quaternion matrices. It does not pertain to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13732",
      "abstract": "This study examines the role of human judges in legal decision-making by using machine learning to predict child physical custody outcomes in French appellate courts. Building on the legal realism-formalism debate, we test whether individual judges' decision-making patterns significantly influence case outcomes, challenging the assumption that judges are neutral variables that apply the law uniformly. To ensure compliance with French privacy laws, we implement a strict pseudonymization process. Our analysis uses 18,937 living arrangements rulings extracted from 10,306 cases. We compare models trained on individual judges' past rulings (specialist models) with a judge-agnostic model trained on aggregated data (generalist models). The prediction pipeline is a hybrid approach combining large language models (LLMs) for structured feature extraction and ML models for outcome prediction (RF, XGB and SVC). Our results show that specialist models consistently achieve higher predictive accuracy than the general model, with top-performing models reaching F1 scores as high as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x more samples. Specialist models capture stable individual patterns that are not transferable to other judges. In-Domain and Cross-Domain validity tests provide empirical support for legal realism, demonstrating that judicial identity plays a measurable role in legal outcomes. All data and code used will be made available.",
      "authors": [
        "Guillaume Zambrano"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:28:53+00:00",
          "link": "https://arxiv.org/abs/2507.13732v1",
          "size": "641kb",
          "version": "v1"
        }
      ],
      "title": "The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13732",
        "PDF": "https://arxiv.org/pdf/2507.13732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses LLMs for structured feature extraction as part of a prediction pipeline, the main focus is on predicting legal outcomes, rather than a significant contribution to LLM training data processing per se."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13736",
      "abstract": "This work presents a multi-layer DNN scheduling framework as an extension of OctopuScheduler, providing an end-to-end flow from PyTorch models to inference on a single SpiNNaker2 chip. Together with a front-end comprised of quantization and lowering steps, the proposed framework enables the edge-based execution of large and complex DNNs up to transformer scale using the neuromorphic platform SpiNNaker2.",
      "authors": [
        "Matthias Jobst",
        "Tim Langer",
        "Chen Liu",
        "Mehmet Alici",
        "Hector A. Gonzalez",
        "Christian Mayr"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:32:34+00:00",
          "link": "https://arxiv.org/abs/2507.13736v1",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13736",
        "HTML": "https://arxiv.org/html/2507.13736v1",
        "PDF": "https://arxiv.org/pdf/2507.13736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an end-to-end DNN inference framework on the SpiNNaker2 platform, which is not related to LLM training data processing or associated operations like dataset creation or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13737",
      "abstract": "Rich and context-aware activity logs facilitate user behavior analysis and health monitoring, making them a key research focus in ubiquitous computing. The remarkable semantic understanding and generation capabilities of Large Language Models (LLMs) have recently created new opportunities for activity log generation. However, existing methods continue to exhibit notable limitations in terms of accuracy, efficiency, and semantic richness. To address these challenges, we propose DailyLLM. To the best of our knowledge, this is the first log generation and summarization system that comprehensively integrates contextual activity information across four dimensions: location, motion, environment, and physiology, using only sensors commonly available on smartphones and smartwatches. To achieve this, DailyLLM introduces a lightweight LLM-based framework that integrates structured prompting with efficient feature extraction to enable high-level activity understanding. Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art (SOTA) log generation methods and can be efficiently deployed on personal computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM achieves a 17% improvement in log generation BERTScore precision compared to the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference speed.",
      "authors": [
        "Ye Tian",
        "Xiaoyuan Ren",
        "Zihao Wang",
        "Onat Gungor",
        "Xiaofan Yu and Tajana Rosing"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:33:30+00:00",
          "link": "https://arxiv.org/abs/2507.13737v1",
          "size": "765kb",
          "version": "v1"
        }
      ],
      "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13737",
        "HTML": "https://arxiv.org/html/2507.13737v1",
        "PDF": "https://arxiv.org/pdf/2507.13737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes DailyLLM, a system for generating activity logs using sensors and LLMs. It focuses on deploying LLMs for log generation rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13739",
      "abstract": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely limited training data; while aiming to reduce catastrophic forgetting and learn new information. We propose Diffusion-FSCIL, a novel approach that employs a text-to-image diffusion model as a frozen backbone. Our conjecture is that FSCIL can be tackled using a large generative model's capabilities benefiting from 1) generation ability via large-scale pre-training; 2) multi-scale representation; 3) representational flexibility through the text encoder. To maximize the representation capability, we propose to extract multiple complementary diffusion features to play roles as latent replay with slight support from feature distillation for preventing generative biases. Our framework realizes efficiency through 1) using a frozen backbone; 2) minimal trainable components; 3) batch processing of multiple feature extractions. Extensive experiments on CUB-200, \\emph{mini}ImageNet, and CIFAR-100 show that Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on previously learned classes and adapting effectively to new ones.",
      "authors": [
        "Junsu Kim",
        "Yunhoe Ku",
        "Seungryul Baek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:38:07+00:00",
          "link": "https://arxiv.org/abs/2507.13739v1",
          "size": "2173kb",
          "version": "v1"
        }
      ],
      "title": "Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13739",
        "HTML": "https://arxiv.org/html/2507.13739v1",
        "PDF": "https://arxiv.org/pdf/2507.13739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on few-shot class-incremental learning through a novel approach utilizing diffusion models. It does not address LLM training data processing, pretraining, or data engineering relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13741",
      "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in graph classification tasks by capturing both structural and feature-based representations. However, real-world graphs often exhibit two critical forms of imbalance: class imbalance and graph size imbalance. These imbalances can bias the learning process and degrade model performance. Existing methods typically address only one type of imbalance or incur high computational costs. In this work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning framework that effectively mitigates both class and graph size imbalance. SamGoG constructs multiple GoGs through an efficient importance-based sampling mechanism and trains on them sequentially. This sampling mechanism incorporates the learnable pairwise similarity and adaptive GoG node degree to enhance edge homophily, thus improving downstream model quality. SamGoG can seamlessly integrate with various downstream GNNs, enabling their efficient adaptation for graph classification tasks. Extensive experiments on benchmark datasets demonstrate that SamGoG achieves state-of-the-art performance with up to a 15.66% accuracy improvement with 6.7$\\times$ training acceleration.",
      "authors": [
        "Shangyou Wang",
        "Zezhong Ding",
        "Xike Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:41:58+00:00",
          "link": "https://arxiv.org/abs/2507.13741v1",
          "size": "820kb",
          "version": "v1"
        }
      ],
      "title": "SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13741",
        "HTML": "https://arxiv.org/html/2507.13741v1",
        "PDF": "https://arxiv.org/pdf/2507.13741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with graph classification and imbalance issues in graph neural networks, which are unrelated to LLM training data processing or any operations focused on language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13742",
      "abstract": "In the fast-moving world of AI, as organizations and researchers develop more advanced models, they face challenges due to their sheer size and computational demands. Deploying such models on edge devices or in resource-constrained environments adds further challenges related to energy consumption, memory usage and latency. To address these challenges, emerging trends are shaping the future of efficient model optimization techniques. From this premise, by employing supervised state-of-the-art transformer-based models, this research introduces a systematic method for ontology alignment, grounded in cosine-based semantic similarity between a biomedical layman vocabulary and the Unified Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to search for target optimizations among different Execution Providers (EPs) using the ONNX Runtime backend, followed by an assembled process of dynamic quantization employing Intel Neural Compressor and IPEX (Intel Extension for PyTorch). Through our optimization process, we conduct extensive assessments on the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new state-of-the-art in both. We retain performance metrics intact, while attaining an average inference speed-up of 20x and reducing memory usage by approximately 70%.",
      "authors": [
        "Oussama Bouaggad",
        "Natalia Grabar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:42:20+00:00",
          "link": "https://arxiv.org/abs/2507.13742v1",
          "size": "598kb",
          "version": "v1"
        }
      ],
      "title": "Search-Optimized Quantization in Biomedical Ontology Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13742",
        "HTML": "https://arxiv.org/html/2507.13742v1",
        "PDF": "https://arxiv.org/pdf/2507.13742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on model optimization techniques and ontology alignment in biomedical domains, which is not related to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13743",
      "abstract": "Large Language Models (LLMs) frequently reproduce the gender- and sexual-identity prejudices embedded in their training corpora, leading to outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of great importance. To achieve this, we evaluate two parameter-efficient fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt tuning - as lightweight alternatives to full-model fine-tuning for mitigating such biases. Using the WinoQueer benchmark, we quantify bias in three open-source LLMs and observe baseline bias scores reaching up to 98 (out of 100) across a range of queer identities defined by gender and/or sexual orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1% additional parameters) on a curated QueerNews corpus reduces those scores by up to 50 points and raises neutrality from virtually 0% to as much as 36%. Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements. These findings show that LoRA can deliver meaningful fairness gains with minimal computation. We advocate broader adoption of community-informed PEFT, the creation of larger queer-authored corpora, and richer evaluation suites beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.",
      "authors": [
        "Maluna Menke",
        "Thilo Hagendorff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:44:27+00:00",
          "link": "https://arxiv.org/abs/2507.13743v1",
          "size": "284kb",
          "version": "v1"
        }
      ],
      "title": "PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13743",
        "PDF": "https://arxiv.org/pdf/2507.13743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses parameter-efficient fine-tuning techniques to mitigate biases in LLMs, the primary focus is on bias reduction rather than data processing operations such as dataset creation or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13753",
      "abstract": "In recent years, large text-to-video (T2V) synthesis models have garnered considerable attention for their abilities to generate videos from textual descriptions. However, achieving both high imaging quality and effective motion representation remains a significant challenge for these T2V models. Existing approaches often adapt pre-trained text-to-image (T2I) models to refine video frames, leading to issues such as flickering and artifacts due to inconsistencies across frames. In this paper, we introduce EVS, a training-free Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both visual fidelity and motion smoothness of generated videos. Our approach utilizes a well-trained diffusion-based T2I model to refine low-quality video frames by treating them as out-of-distribution samples, effectively optimizing them with noising and denoising steps. Meanwhile, we employ T2V backbones to ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior into the T2I generation process, EVS successfully leverages the strengths of both types of models, resulting in videos of improved imaging and motion quality. Experimental results validate the effectiveness of our approach compared to previous approaches. Our composition process also leads to a significant improvement of 1.6x-4.5x speedup in inference time. Source codes: https://github.com/Tonniia/EVS.",
      "authors": [
        "Tongtong Su",
        "Chengyu Wang",
        "Bingyan Liu",
        "Jun Huang",
        "Dongming Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.13753v1",
          "size": "8402kb",
          "version": "v1"
        }
      ],
      "title": "Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13753",
        "HTML": "https://arxiv.org/html/2507.13753v1",
        "PDF": "https://arxiv.org/pdf/2507.13753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing video synthesis by integrating text-to-image and text-to-video models. It does not address LLM training data processing, pretraining, fine-tuning, or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13757",
      "abstract": "This study explored the development of a novel self-healing framework for databases using meta-learning and reinforcement learning techniques. The primary objective was to address the challenges of real-time adaptability and minimal retraining in dynamic workload environments. The proposed approach integrated Model-Agnostic Meta-Learning (MAML) with reinforcement learning to enable anomaly detection and corrective actions that adapted swiftly to evolving database conditions. Multi-objective optimization was employed to balance performance, resource utilization, and cost efficiency during the healing process. Graph Neural Networks (GNNs) were incorporated to model interdependencies within database components, ensuring holistic recovery strategies. Data efficiency was enhanced through synthetic task augmentation and self-supervised learning, enabling effective training in sparse data regimes. To promote trust and transparency, explainable AI techniques were integrated to provide interpretable insights into anomaly detection and healing actions. Federated meta-learning further enabled privacy-preserving adaptability in distributed database environments. The framework demonstrated significant improvements in adaptability, efficiency, and reliability, contributing to advancements in database management and self-healing systems.",
      "authors": [
        "Joydeep Chandra",
        "Prabal Manhas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:05:37+00:00",
          "link": "https://arxiv.org/abs/2507.13757v1",
          "size": "233kb",
          "version": "v1"
        }
      ],
      "title": "Efficient and Scalable Self-Healing Databases Using Meta-Learning and Dependency-Driven Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13757",
        "HTML": "https://arxiv.org/html/2507.13757v1",
        "PDF": "https://arxiv.org/pdf/2507.13757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores a self-healing database system using meta-learning and reinforcement learning. It focuses on database management improvements and self-healing strategies, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13758",
      "abstract": "Large Reasoning Models (LRMs) like DeepSeek-R1 and o1 are increasingly used as automated evaluators, raising critical questions about their vulnerability to the aesthetics of reasoning in LLM-as-a-judge settings. We introduce THEATER, a comprehensive benchmark to systematically evaluate this vulnerability-termed Reasoning Theater Bias (RTB)-by comparing LLMs and LRMs across subjective preference and objective factual datasets. Through investigation of six bias types including Simple Cues and Fake Chain-of-Thought, we uncover three key findings: (1) in a critical paradox, reasoning-specialized LRMs are consistently more susceptible to RTB than general-purpose LLMs, particularly in subjective tasks; (2) this creates a task-dependent trade-off, where LRMs show more robustness on factual tasks but less on subjective ones; and (3) we identify 'shallow reasoning'-plausible but flawed arguments-as the most potent form of RTB. To address this, we design and evaluate two prompting strategies: a targeted system prompt that improves accuracy by up to 12% on factual tasks but only 1-3% on subjective tasks, and a self-reflection mechanism that shows similarly limited effectiveness in the more vulnerable subjective domains. Our work reveals that RTB is a deep-seated challenge for LRM-based evaluation and provides a systematic framework for developing more genuinely robust and trustworthy LRMs.",
      "authors": [
        "Qian Wang",
        "Yubo Fan",
        "Zhenheng Tang",
        "Nuo Chen",
        "Wenxuan Wang",
        "and Bingsheng He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:06:10+00:00",
          "link": "https://arxiv.org/abs/2507.13758v1",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "title": "The Emperor's New Chain-of-Thought: Probing Reasoning Theater Bias in Large Reasoning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13758",
        "HTML": "https://arxiv.org/html/2507.13758v1",
        "PDF": "https://arxiv.org/pdf/2507.13758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines Reasoning Theater Bias in Large Reasoning Models and proposes strategies to reduce it, which aligns more with model evaluation and robustness than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13759",
      "abstract": "In the field of knowledge management and computer science, ontologies provide a structured framework for modeling domain-specific knowledge by defining concepts and their relationships. However, the lack of tools that provide effective visualization is still a significant challenge. While numerous ontology editors and viewers exist, most of them fail to graphically represent ontology structures in a meaningful and non-overwhelming way, limiting users' ability to comprehend dependencies and properties within large ontological frameworks.\n  In this paper, we present OntView, an ontology viewer that is designed to provide users with an intuitive visual representation of ontology concepts and their formal definitions through a user-friendly interface. Building on the use of a DL reasoner, OntView follows a \"What you see is what you meant\" paradigm, showing the actual inferred knowledge. One key aspect for this is its ability to visualize General Concept Inclusions (GCI), a feature absent in existing visualization tools. Moreover, to avoid a possible information overload, OntView also offers different ways to show a simplified view of the ontology by: 1) creating ontology summaries by assessing the importance of the concepts (according to different available algorithms), 2) focusing the visualization on the existing TBox elements between two given classes and 3) allowing to hide/show different branches in a dynamic way without losing the semantics. OntView has been released with an open-source license for the whole community.",
      "authors": [
        "Carlos Bobed and Carlota Quintana and Eduardo Mena and Jorge Bobed and Fernando Bobillo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:06:49+00:00",
          "link": "https://arxiv.org/abs/2507.13759v1",
          "size": "11989kb",
          "version": "v1"
        }
      ],
      "title": "OntView: What you See is What you Meant",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13759",
        "HTML": "https://arxiv.org/html/2507.13759v1",
        "PDF": "https://arxiv.org/pdf/2507.13759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "OntView provides visualization solutions for ontology concepts, which relate to knowledge management and ontology structuring, but not to LLM training data processing or associated data tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13761",
      "abstract": "Language models are highly sensitive to prompt formulations - small changes in input can drastically alter their output. This raises a critical question: To what extent can prompt sensitivity be exploited to generate inapt content? In this paper, we investigate how discrete components of prompt design influence the generation of inappropriate content in Visual Language Models (VLMs). Specifically, we analyze the impact of three key factors on successful jailbreaks: (a) the inclusion of detailed visual information, (b) the presence of adversarial examples, and (c) the use of positively framed beginning phrases. Our findings reveal that while a VLM can reliably distinguish between benign and harmful inputs in unimodal settings (text-only or image-only), this ability significantly degrades in multimodal contexts. Each of the three factors is independently capable of triggering a jailbreak, and we show that even a small number of in-context examples (as few as three) can push the model toward generating inappropriate outputs. Furthermore, we propose a framework that utilizes a skip-connection between two internal layers of the VLM, which substantially increases jailbreak success rates, even when using benign images. Finally, we demonstrate that memes, often perceived as humorous or harmless, can be as effective as toxic visuals in eliciting harmful content, underscoring the subtle and complex vulnerabilities of VLMs.",
      "authors": [
        "Palash Nandi",
        "Maithili Joshi",
        "Tanmoy Chakraborty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:13:05+00:00",
          "link": "https://arxiv.org/abs/2507.13761v1",
          "size": "10722kb",
          "version": "v1"
        }
      ],
      "title": "Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13761",
        "HTML": "https://arxiv.org/html/2507.13761v1",
        "PDF": "https://arxiv.org/pdf/2507.13761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates how prompt design influences content generation in Visual Language Models, focusing on prompt sensitivity and vulnerability, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13762",
      "abstract": "Advances in deep learning for molecular generation show promise in accelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown impressive performance across diverse chemical tasks, with their success often ascribed to the paradigm of modeling in a low-variance parameter space. However, the Bayesian inference-based strategy imposes limitations on designing more flexible distribution transformation pathways, making it challenging to adapt to diverse data distributions and varied task requirements. Furthermore, the potential for simpler, more efficient parameter-space-based models is unexplored. To address this, we propose a novel Parameter Interpolation Flow model (named PIF) with detailed theoretical foundation, training, and inference procedures. We then develop MolPIF for structure-based drug design, demonstrating its superior performance across diverse metrics compared to baselines. This work validates the effectiveness of parameter-space-based generative modeling paradigm for molecules and offers new perspectives for model design.",
      "authors": [
        "Yaowei Jin",
        "Junjie Wang",
        "Wenkai Xiang",
        "Duanhua Cao",
        "Dan Teng",
        "Zhehuan Fan",
        "Jiacheng Xiong",
        "Xia Sheng",
        "Chuanlong Zeng",
        "Mingyue Zheng",
        "Qian Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:15:35+00:00",
          "link": "https://arxiv.org/abs/2507.13762v1",
          "size": "7893kb",
          "version": "v1"
        }
      ],
      "title": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13762",
        "HTML": "https://arxiv.org/html/2507.13762v1",
        "PDF": "https://arxiv.org/pdf/2507.13762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a parameter interpolation flow model for molecular generation in drug discovery, which does not relate to LLM training data processing or involve any data processing operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13765",
      "abstract": "Graph clustering is crucial for unraveling intricate data structures, yet it presents significant challenges due to its unsupervised nature. Recently, goal-directed clustering techniques have yielded impressive results, with contrastive learning methods leveraging pseudo-label garnering considerable attention. Nonetheless, pseudo-label as a supervision signal is unreliable and existing goal-directed approaches utilize only features to construct a single-target distribution for single-center optimization, which lead to incomplete and less dependable guidance. In our work, we propose a novel Dual-Center Graph Clustering (DCGC) approach based on neighbor distribution properties, which includes representation learning with neighbor distribution and dual-center optimization. Specifically, we utilize neighbor distribution as a supervision signal to mine hard negative samples in contrastive learning, which is reliable and enhances the effectiveness of representation learning. Furthermore, neighbor distribution center is introduced alongside feature center to jointly construct a dual-target distribution for dual-center optimization. Extensive experiments and analysis demonstrate superior performance and effectiveness of our proposed method.",
      "authors": [
        "Enhao Cheng",
        "Shoujia Zhang",
        "Jianhua Yin",
        "Li Jin and Liqiang Nie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:17:04+00:00",
          "link": "https://arxiv.org/abs/2507.13765v1",
          "size": "2346kb",
          "version": "v1"
        }
      ],
      "title": "Dual-Center Graph Clustering with Neighbor Distribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13765",
        "HTML": "https://arxiv.org/html/2507.13765v1",
        "PDF": "https://arxiv.org/pdf/2507.13765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a dual-center graph clustering approach for data structures but does not address LLM training data processing or relevant data operations such as dataset creation or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13768",
      "abstract": "We present a hybrid architecture for agent-augmented strategic reasoning, combining heuristic extraction, semantic activation, and compositional synthesis. Drawing on sources ranging from classical military theory to contemporary corporate strategy, our model activates and composes multiple heuristics through a process of semantic interdependence inspired by research in quantum cognition. Unlike traditional decision engines that select the best rule, our system fuses conflicting heuristics into coherent and context-sensitive narratives, guided by semantic interaction modeling and rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study, with preliminary validation through semantic metrics. Limitations and extensions (e.g., dynamic interference tuning) are discussed.",
      "authors": [
        "Renato Ghisellini and Remo Pareschi and Marco Pedroni and Giovanni Battista Raggi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:26:37+00:00",
          "link": "https://arxiv.org/abs/2507.13768v1",
          "size": "188kb",
          "version": "v1"
        }
      ],
      "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13768",
        "HTML": "https://arxiv.org/html/2507.13768v1",
        "PDF": "https://arxiv.org/pdf/2507.13768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a hybrid architecture for strategic reasoning through heuristic extraction and synthesis, unrelated to LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13769",
      "abstract": "Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its degraded 2D measurements. Recently great progress has been made in deep learning-based methods, however, these methods often struggle to accurately capture high-frequency details of the HSI. To address this issue, this paper proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from hyperspectral images using a diffusion model. Leveraging the powerful ability of the diffusion model to reconstruct details, this learned prior can significantly improve the performance when injected into the HSI model. To further improve the effectiveness of the learned prior, we also propose the Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover the HSI details. We evaluate our method on two representative HSI methods: MST and BISRNet. Experimental results show that our method outperforms existing networks by about 0.5 dB, effectively improving the performance of HSI reconstruction.",
      "authors": [
        "Mingyang Yu",
        "Zhijian Wu",
        "Dingjiang Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.13769v1",
          "size": "1208kb",
          "version": "v1"
        }
      ],
      "title": "Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13769",
        "HTML": "https://arxiv.org/html/2507.13769v1",
        "PDF": "https://arxiv.org/pdf/2507.13769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on hyperspectral image reconstruction using spectral diffusion prior, which is unrelated to any aspect of LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13772",
      "abstract": "Feature engineering continues to play a critical role in image classification, particularly when interpretability and computational efficiency are prioritized over deep learning models with millions of parameters. In this study, we revisit classical machine learning based image classification through a novel approach centered on Permutation Entropy (PE), a robust and computationally lightweight measure traditionally used in time series analysis but rarely applied to image data. We extend PE to two-dimensional images and propose a multiscale, multi-orientation entropy-based feature extraction approach that characterizes spatial order and complexity along rows, columns, diagonals, anti-diagonals, and local patches of the image. To enhance the discriminatory power of the entropy features, we integrate two classic image descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an image. The resulting hand-crafted feature set, comprising of 780 dimensions, is used to train Support Vector Machine (SVM) classifiers optimized through grid search. The proposed approach is evaluated on multiple benchmark datasets, including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers competitive classification performance without relying on deep architectures. Our results demonstrate that the fusion of PE with HOG and LBP provides a compact, interpretable, and effective alternative to computationally expensive and limited interpretable deep learning models. This shows a potential of entropy-based descriptors in image classification and contributes a lightweight and generalizable solution to interpretable machine learning in image classification and computer vision.",
      "authors": [
        "Abhijit Sen",
        "Giridas Maiti",
        "Bikram K. Parida",
        "Bhanu P. Mishra",
        "Mahima Arya",
        "Denys I. Bondar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:29:03+00:00",
          "link": "https://arxiv.org/abs/2507.13772v1",
          "size": "6222kb",
          "version": "v1"
        }
      ],
      "title": "Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13772",
        "HTML": "https://arxiv.org/html/2507.13772v1",
        "PDF": "https://arxiv.org/pdf/2507.13772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses classical machine learning for image classification with feature engineering, not addressing LLM training data processing or related data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13773",
      "abstract": "In visual question answering (VQA) context, users often pose ambiguous questions to visual language models (VLMs) due to varying expression habits. Existing research addresses such ambiguities primarily by rephrasing questions. These approaches neglect the inherently interactive nature of user interactions with VLMs, where ambiguities can be clarified through user feedback. However, research on interactive clarification faces two major challenges: (1) Benchmarks are absent to assess VLMs' capacity for resolving ambiguities through interaction; (2) VLMs are trained to prefer answering rather than asking, preventing them from seeking clarification. To overcome these challenges, we introduce \\textbf{ClearVQA} benchmark, which targets three common categories of ambiguity in VQA context, and encompasses various VQA scenarios.",
      "authors": [
        "Pu Jian",
        "Donglei Yu",
        "Wen Yang",
        "Shuo Ren",
        "Jiajun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:31:43+00:00",
          "link": "https://arxiv.org/abs/2507.13773v1",
          "size": "6600kb",
          "version": "v1"
        }
      ],
      "title": "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13773",
        "PDF": "https://arxiv.org/pdf/2507.13773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on resolving ambiguity in visual language models through interactive clarification in VQA, introducing a benchmark for ambiguity categories. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13774",
      "abstract": "The ability to cast values between related types is a leitmotiv of many flavors of dependent type theory, such as observational type theories, subtyping, or cast calculi for gradual typing. These casts all exhibit a common structural behavior that boils down to the pervasive functoriality of type formers. We propose and extensively study a type theory, called AdapTT, which makes systematic and precise this idea of functorial type formers, with respect to an abstract notion of adapters relating types. Leveraging descriptions for functorial inductive types in AdapTT, we derive structural laws for type casts on general inductive type formers.",
      "authors": [
        "Arthur Adjedj",
        "Meven Lennon-Bertrand",
        "Thibaut Benjamin",
        "Kenji Maillard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:34:10+00:00",
          "link": "https://arxiv.org/abs/2507.13774v1",
          "size": "322kb",
          "version": "v1"
        }
      ],
      "title": "AdapTT: Functoriality for Dependent Type Casts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13774",
        "PDF": "https://arxiv.org/pdf/2507.13774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses type theory related to dependent type casts in a proposed system called AdapTT. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13779",
      "abstract": "Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA) enhance the model performance by exploiting information from labeled and unlabeled data. The clustering assumption has proven advantageous for learning with limited supervision and states that data points belonging to the same cluster in a high-dimensional space should be assigned to the same category. Recent works have utilized different training mechanisms to implicitly enforce this assumption for the SSL and UDA. In this work, we take a different approach by explicitly involving a differentiable clustering module which is extended to leverage the supervised data to compute its centroids. We demonstrate the effectiveness of our straightforward end-to-end training strategy for SSL and UDA over extensive experiments and highlight its benefits, especially in low supervision regimes, both as a standalone model and as a regularizer for existing approaches.",
      "authors": [
        "Durgesh Singh and Ahc\\`ene Boubekki and Robert Jenssen and Michael Kampffmeyer"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:42:39+00:00",
          "link": "https://arxiv.org/abs/2507.13779v1",
          "size": "587kb",
          "version": "v1"
        }
      ],
      "title": "SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13779",
        "HTML": "https://arxiv.org/html/2507.13779v1",
        "PDF": "https://arxiv.org/pdf/2507.13779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions semi-supervised learning and domain adaptation, focusing on a clustering module for improved learning with limited supervision. While training data aspects are hinted at, the main focus is not on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13785",
      "abstract": "While biological neural networks develop from compact genomes using relatively simple rules, modern artificial neural architecture search methods mostly involve explicit and routine manual work. In this paper, we introduce MorphoNAS (Morphogenetic Neural Architecture Search), a system able to deterministically grow neural networks through morphogenetic self-organization inspired by the Free Energy Principle, reaction-diffusion systems, and gene regulatory networks. In MorphoNAS, simple genomes encode just morphogens dynamics and threshold-based rules of cellular development. Nevertheless, this leads to self-organization of a single progenitor cell into complex neural networks, while the entire process is built on local chemical interactions. Our evolutionary experiments focused on two different domains: structural targeting, in which MorphoNAS system was able to find fully successful genomes able to generate predefined random graph configurations (8-31 nodes); and functional performance on the CartPole control task achieving low complexity 6-7 neuron solutions when target network size minimization evolutionary pressure was applied. The evolutionary process successfully balanced between quality of of the final solutions and neural architecture search effectiveness. Overall, our findings suggest that the proposed MorphoNAS method is able to grow complex specific neural architectures, using simple developmental rules, which suggests a feasible biological route to adaptive and efficient neural architecture search.",
      "authors": [
        "Mykola Glybovets",
        "Sergii Medvid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:57:49+00:00",
          "link": "https://arxiv.org/abs/2507.13785v1",
          "size": "697kb",
          "version": "v1"
        }
      ],
      "title": "MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13785",
        "HTML": "https://arxiv.org/html/2507.13785v1",
        "PDF": "https://arxiv.org/pdf/2507.13785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses MorphoNAS, a method for neural architecture search inspired by biological development processes. It does not address LLM training data processing or any relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13787",
      "abstract": "This paper focuses on the design of a parallel robot designed for robotic assisted minimally invasive pancreatic surgery. Two alternative architectures, called ATHENA-1 and ATHENA-2, each with 4 degrees of freedom (DOF) are proposed. Their kinematic schemes are presented, and the conceptual 3D CAD models are illustrated. Based on these, two Finite Element Method (FEM) simulations were performed to determine which architecture has the higher stiffness. A workspace quantitative analysis is performed to further assess the usability of the two proposed parallel architectures related to the medical tasks. The obtained results are used to select the architecture which fit the required design criteria and will be used to develop the experimental model of the surgical robot.",
      "authors": [
        "Doina Pisla (CESTER)",
        "Alexandru Pusca",
        "Andrei Caprariu",
        "Adrian Pisla (CESTER",
        "Technical University of Cluj-Napoca)",
        "Bogdan Gherman",
        "Calin Vaida",
        "Damien Chablat (LS2N",
        "LS2N - \\'equipe RoMas)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:59:13+00:00",
          "link": "https://arxiv.org/abs/2507.13787v1",
          "size": "892kb",
          "version": "v1"
        }
      ],
      "title": "Design Analysis of an Innovative Parallel Robot for Minimally Invasive Pancreatic Surgery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13787",
        "PDF": "https://arxiv.org/pdf/2507.13787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the design and analysis of a robotic system for minimally invasive surgery, with no mention of language models or data processing related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13789",
      "abstract": "Hemodynamic analysis is essential for predicting aneurysm rupture and guiding treatment. While magnetic resonance flow imaging enables time-resolved volumetric blood velocity measurements, its low spatiotemporal resolution and signal-to-noise ratio limit its diagnostic utility. To address this, we propose the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that enhances both spatial and temporal resolution with the ability to predict wall shear stress (WSS) directly from clinical imaging data. LoFNO integrates Laplacian eigenvectors as geometric priors for improved structural awareness on irregular, unseen geometries and employs an Enhanced Deep Super-Resolution Network (EDSR) layer for robust upsampling. By combining geometric priors with neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow data, achieving superior velocity and WSS predictions compared to interpolation and alternative deep learning methods, enabling more precise cerebrovascular diagnostics.",
      "authors": [
        "Kyriakos Flouris",
        "Moritz Halter",
        "Yolanne Y. R. Lee",
        "Samuel Castonguay",
        "Luuk Jacobs",
        "Pietro Dirix",
        "Jonathan Nestmann",
        "Sebastian Kozerke",
        "and Ender Konukoglu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:00:38+00:00",
          "link": "https://arxiv.org/abs/2507.13789v1",
          "size": "10662kb",
          "version": "v1"
        }
      ],
      "title": "Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13789",
        "HTML": "https://arxiv.org/html/2507.13789v1",
        "PDF": "https://arxiv.org/pdf/2507.13789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the Localized FNO model for hemodynamic data enhancement in medical imaging. It does not involve any LLM-related data processing or dataset creation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13792",
      "abstract": "We extend the semantics and type system of a lambda calculus equipped with common constructs to be resource-aware. That is, the semantics keep tracks of the usage of resources, and is stuck, besides in case of type errors, if either a needed resource is exhausted, or a provided resource would be wasted. In such way, the type system guarantees, besides standard soundness, that for well-typed programs there is a computation where no resource gets either exhausted or wasted.\n  The no-waste extension is parametric on an arbitrary grade algebra, modeling an arbitrary assortment of possible usages, and does not require ad-hoc changes to the underlying language. To this end, the semantics needs to be formalized in big-step style; as a consequence, expressing and proving (resource-aware) soundness is challenging, and is achieved by applying recent techniques based on coinductive reasoning.",
      "authors": [
        "Riccardo Bianchini",
        "Francesco Dagnino",
        "Paola Giannini",
        "Elena Zucca"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:06:08+00:00",
          "link": "https://arxiv.org/abs/2507.13792v1",
          "size": "69kb",
          "version": "v1"
        }
      ],
      "title": "Don't exhaust, don't waste",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13792",
        "HTML": "https://arxiv.org/html/2507.13792v1",
        "PDF": "https://arxiv.org/pdf/2507.13792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper extends a lambda calculus for resource-aware computation, focusing on semantics and type systems. It does not relate to LLM training data processing in any capacity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13793",
      "abstract": "Short text clustering has become increasingly important with the popularity of social media like Twitter, Google+, and Facebook. Existing methods can be broadly categorized into two paradigms: topic model-based approaches and deep representation learning-based approaches. This task is inherently challenging due to the sparse, large-scale, and high-dimensional characteristics of the short text data. Furthermore, the computational intensity required by representation learning significantly increases the running time. To address these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet Multinomial Mixture model (GSDMM), which effectively handles the sparsity and high dimensionality of short texts while identifying representative words for each cluster. Based on several aspects of GSDMM that warrant further refinement, we propose an improved approach, GSDMM+, designed to further optimize its performance. GSDMM+ reduces initialization noise and adaptively adjusts word weights based on entropy, achieving fine-grained clustering that reveals more topic-related information. Additionally, strategic cluster merging is employed to refine clustering granularity, better aligning the predicted distribution with the true category distribution. We conduct extensive experiments, comparing our methods with both classical and state-of-the-art approaches. The experimental results demonstrate the efficiency and effectiveness of our methods. The source code for our model is publicly available at https://github.com/chehaoa/VEMC.",
      "authors": [
        "Enhao Cheng",
        "Shoujia Zhang",
        "Jianhua Yin",
        "Xuemeng Song",
        "Tian Gan",
        "Liqiang Nie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:07:42+00:00",
          "link": "https://arxiv.org/abs/2507.13793v1",
          "size": "6660kb",
          "version": "v1"
        }
      ],
      "title": "An Enhanced Model-based Approach for Short Text Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13793",
        "HTML": "https://arxiv.org/html/2507.13793v1",
        "PDF": "https://arxiv.org/pdf/2507.13793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents a model-based approach for clustering short texts, addressing the challenges inherent in social media data. It doesn't discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13795",
      "abstract": "Phobias significantly impact the quality of life of affected persons. Two methods of assessing anxiety responses are questionnaires and behavioural avoidance tests (BAT). While these can be used in a clinical environment they only record momentary insights into anxiety measures. In this study, we estimate the intensity of anxiety during these BATs, using physiological data collected from unobtrusive, wrist-worn sensors. Twenty-five participants performed four different BATs in a single session, while periodically being asked how anxious they currently are. Using heart rate, heart rate variability, electrodermal activity, and skin temperature, we trained regression models to predict anxiety ratings from three types of input data: (1) using only physiological signals, (2) adding computed features (e.g., min, max, range, variability), and (3) computed features combined with contextual task information. Adding contextual information increased the effectiveness of the model, leading to a root mean squared error (RMSE) of 0.197 and a mean absolute error (MAE) of 0.041. Overall, this study shows, that data obtained from wearables can continuously provide meaningful estimations of anxiety, which can assist in therapy planning and enable more personalised treatment.",
      "authors": [
        "Florian Grensing",
        "Vanessa Schm\\\"ucker",
        "Anne Sophie Hildebrand",
        "Tim Klucken",
        "Maria Maleshkova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:09:38+00:00",
          "link": "https://arxiv.org/abs/2507.13795v1",
          "size": "868kb",
          "version": "v1"
        }
      ],
      "title": "Regression-Based Approach to Anxiety Estimation of Spider Phobics During Behavioural Avoidance Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13795",
        "HTML": "https://arxiv.org/html/2507.13795v1",
        "PDF": "https://arxiv.org/pdf/2507.13795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on estimating anxiety using physiological signals with regression models, which does not relate to LLM training data processing. It is concerned with psychological assessment rather than language model data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13797",
      "abstract": "Blind Face Restoration aims to recover high-fidelity, detail-rich facial images from unknown degraded inputs, presenting significant challenges in preserving both identity and detail. Pre-trained diffusion models have been increasingly used as image priors to generate fine details. Still, existing methods often use fixed diffusion sampling timesteps and a global guidance scale, assuming uniform degradation. This limitation and potentially imperfect degradation kernel estimation frequently lead to under- or over-diffusion, resulting in an imbalance between fidelity and quality. We propose DynFaceRestore, a novel blind face restoration approach that learns to map any blindly degraded input to Gaussian blurry images. By leveraging these blurry images and their respective Gaussian kernels, we dynamically select the starting timesteps for each blurry image and apply closed-form guidance during the diffusion sampling process to maintain fidelity. Additionally, we introduce a dynamic guidance scaling adjuster that modulates the guidance strength across local regions, enhancing detail generation in complex areas while preserving structural fidelity in contours. This strategy effectively balances the trade-off between fidelity and quality. DynFaceRestore achieves state-of-the-art performance in both quantitative and qualitative evaluations, demonstrating robustness and effectiveness in blind face restoration.",
      "authors": [
        "Huu-Phu Do",
        "Yu-Wei Chen",
        "Yi-Cheng Liao",
        "Chi-Wei Hsiao",
        "Han-Yang Wang",
        "Wei-Chen Chiu",
        "Ching-Chun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:16:08+00:00",
          "link": "https://arxiv.org/abs/2507.13797v1",
          "size": "41465kb",
          "version": "v1"
        }
      ],
      "title": "DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13797",
        "HTML": "https://arxiv.org/html/2507.13797v1",
        "PDF": "https://arxiv.org/pdf/2507.13797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses blind face restoration with diffusion models, focusing on image processing techniques. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13801",
      "abstract": "In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a critical perception task for autonomous driving due to its ability to infer complete 3D scene layouts and semantics from single 2D images. However, in real-world traffic scenarios, a significant portion of the scene remains occluded or outside the camera's field of view -- a fundamental challenge that existing monocular SSC methods fail to address adequately. To overcome these limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC framework that leverages pseudo-future frame prediction to expand the model's effective perceptual range. Our approach combines poses and depths to establish accurate 3D correspondences, enabling geometrically-consistent fusion of past, present, and predicted future frames in 3D space. Unlike conventional methods that rely on simple feature stacking, our 3D-aware architecture achieves more robust scene completion by explicitly modeling spatial-temporal relationships. Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks demonstrate state-of-the-art performance, validating the effectiveness of our approach, highlighting our method's ability to improve occlusion reasoning and 3D scene completion accuracy.",
      "authors": [
        "Haoang Lu",
        "Yuanqi Su",
        "Xiaoning Zhang and Hao Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:24:58+00:00",
          "link": "https://arxiv.org/abs/2507.13801v1",
          "size": "3610kb",
          "version": "v1"
        }
      ],
      "title": "One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13801",
        "HTML": "https://arxiv.org/html/2507.13801v1",
        "PDF": "https://arxiv.org/pdf/2507.13801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a temporal framework for monocular semantic scene completion in 3D space for autonomous driving. It does not pertain to any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13802",
      "abstract": "In the European Union, official food safety monitoring data collected by member states are submitted to the European Food Safety Authority (EFSA) and published on Zenodo. This data includes 392 million analytical results derived from over 15.2 million samples covering more than 4,000 different types of food products, offering great opportunities for artificial intelligence to analyze trends, predict hazards, and support early warning systems. However, the current format with data distributed across approximately 1000 files totaling several hundred gigabytes hinders accessibility and analysis. To address this, we introduce the CompreHensive European Food Safety (CHEFS) database, which consolidates EFSA monitoring data on pesticide residues, veterinary medicinal product residues, and chemical contaminants into a unified and structured dataset. We describe the creation and structure of the CHEFS database and demonstrate its potential by analyzing trends in European food safety monitoring data from 2000 to 2024. Our analyses explore changes in monitoring activities, the most frequently tested products, which products were most often non-compliant and which contaminants were most often found, and differences across countries. These findings highlight the CHEFS database as both a centralized data source and a strategic tool for guiding food safety policy, research, and regulation.",
      "authors": [
        "Nehir Kizililsoley",
        "Floor van Meer",
        "Osman Mutlu",
        "Wouter F Hoenderdaal",
        "Rosan G. Hob\\'e",
        "Wenjuan Mu",
        "Arjen Gerssen",
        "H.J. van der Fels-Klerx",
        "\\'Akos J\\'o\\'zwiak",
        "Ioannis Manikas",
        "Ali H\\\"urriyeto\\v{g}lu",
        "Bas H.M. van der Velden"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:29:30+00:00",
          "link": "https://arxiv.org/abs/2507.13802v1",
          "size": "27583kb",
          "version": "v1"
        }
      ],
      "title": "Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13802",
        "HTML": "https://arxiv.org/html/2507.13802v1",
        "PDF": "https://arxiv.org/pdf/2507.13802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the CHEFS database for European food safety data, relevant to policy analysis and monitoring, but not to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13803",
      "abstract": "Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely deployed in smart homes, intelligent transport, industrial automation, and healthcare. However, existing systems often face challenges: high model complexity hinders deployment in resource-constrained environments, unidirectional modal alignment neglects inter-modal relationships, and robustness suffers when sensor data is missing. These issues impede efficient and robust multimodal perception in real-world IoT settings. To overcome these limitations, we propose GRAM-MAMBA. This framework utilizes the linear-complexity Mamba model for efficient sensor time-series processing, combined with an optimized GRAM matrix strategy for pairwise alignment among modalities, addressing the shortcomings of traditional single-modality alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive low-rank layer compensation strategy to handle missing modalities post-training. This strategy freezes the pre-trained model core and irrelevant adaptive layers, fine-tuning only those related to available modalities and the fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower error than baselines; adapting to missing modalities yields a 24.5% performance boost by training less than 0.2% of parameters. On the USC-HAD human activity recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA), outperforming prior work; the update strategy increases F1 by 23% while training less than 0.3% of parameters. These results highlight GRAM-MAMBA's potential for achieving efficient and robust multimodal perception in resource-constrained environments.",
      "authors": [
        "Weiqi Yang",
        "Xu Zhou",
        "Jingfu Guan",
        "Hao Du",
        "Tianyu Bai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:30:37+00:00",
          "link": "https://arxiv.org/abs/2507.13803v1",
          "size": "1687kb",
          "version": "v1"
        }
      ],
      "title": "GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13803",
        "HTML": "https://arxiv.org/html/2507.13803v1",
        "PDF": "https://arxiv.org/pdf/2507.13803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on multimodal fusion in IoT environments, proposing a model for sensor time-series processing. It does not discuss any LLM training data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13805",
      "abstract": "Due to the computational complexity of evaluating interatomic forces from first principles, the creation of interatomic machine learning force fields has become a highly active field of research. However, the generation of training datasets of sufficient size and sample diversity itself comes with a computational burden that can make this approach impractical for modeling rare events or systems with a large configuration space. Fine-tuning foundation models that have been pre-trained on large-scale material or molecular databases offers a promising opportunity to reduce the amount of training data necessary to reach a desired level of accuracy. However, even if this approach requires less training data overall, creating a suitable training dataset can still be a very challenging problem, especially for systems with rare events and for end-users who don't have an extensive background in machine learning. In on-the-fly learning, the creation of a training dataset can be largely automated by using model uncertainty during the simulation to decide if the model is accurate enough or if a structure should be recalculated with classical methods and used to update the model. A key challenge for applying this form of active learning to the fine-tuning of foundation models is how to assess the uncertainty of those models during the fine-tuning process, even though most foundation models lack any form of uncertainty quantification. In this paper, we overcome this challenge by introducing a fine-tuning approach based on Bayesian neural network methods and a subsequent on-the-fly workflow that automatically fine-tunes the model while maintaining a pre-specified accuracy and can detect rare events such as transition states and sample them at an increased rate relative to their occurrence.",
      "authors": [
        "Tim Rensmeyer",
        "Denis Kramer",
        "Oliver Niggemann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:33:06+00:00",
          "link": "https://arxiv.org/abs/2507.13805v1",
          "size": "12308kb",
          "version": "v1"
        }
      ],
      "title": "On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13805",
        "HTML": "https://arxiv.org/html/2507.13805v1",
        "PDF": "https://arxiv.org/pdf/2507.13805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses fine-tuning techniques, particularly an on-the-fly approach for neural network potentials, which indirectly relates to LLM training data processing. However, the primary focus is on the method of fine-tuning rather than on generating or enhancing training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13808",
      "abstract": "The substring edit error is the operation of replacing a substring $u$ of $x$ with another string $v$, where the lengths of $u$ and $v$ are bounded by a given constant $k$. It encompasses localized insertions, deletions, and substitutions within a window. Codes correcting one substring edit have redundancy at least $\\log n+k$. In this paper, we construct codes correcting one substring edit with redundancy $\\log n+O(\\log \\log n)$, which is asymptotically optimal.",
      "authors": [
        "Yuting Li",
        "Yuanyuan Tang",
        "Hao Lou",
        "Ryan Gabrys",
        "Farzad Farnoud"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:37:07+00:00",
          "link": "https://arxiv.org/abs/2507.13808v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Asymptotically Optimal Codes Correcting One Substring Edit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13808",
        "HTML": "https://arxiv.org/html/2507.13808v1",
        "PDF": "https://arxiv.org/pdf/2507.13808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is dedicated to constructing codes for correcting substring edits and does not address any aspects of LLM training data processing, dataset creation, or quality enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13812",
      "abstract": "The multi-modal remote sensing foundation model (MM-RSFM) has significantly advanced various Earth observation tasks, such as urban planning, environmental monitoring, and natural disaster management. However, most existing approaches generally require the training of separate backbone networks for each data modality, leading to redundancy and inefficient parameter utilization. Moreover, prevalent pre-training methods typically apply self-supervised learning (SSL) techniques from natural images without adequately accommodating the characteristics of remote sensing (RS) images, such as the complicated semantic distribution within a single RS image. In this work, we present SkySense V2, a unified MM-RSFM that employs a single transformer backbone to handle multiple modalities. This backbone is pre-trained with a novel SSL strategy tailored to the distinct traits of RS data. In particular, SkySense V2 incorporates an innovative adaptive patch merging module and learnable modality prompt tokens to address challenges related to varying resolutions and limited feature diversity across modalities. In additional, we incorporate the mixture of experts (MoE) module to further enhance the performance of the foundation model. SkySense V2 demonstrates impressive generalization abilities through an extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense by an average of 1.8 points.",
      "authors": [
        "Yingying Zhang",
        "Lixiang Ru",
        "Kang Wu",
        "Lei Yu",
        "Lei Liang",
        "Yansheng Li",
        "Jingdong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:44:22+00:00",
          "link": "https://arxiv.org/abs/2507.13812v1",
          "size": "4937kb",
          "version": "v1"
        }
      ],
      "title": "SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13812",
        "HTML": "https://arxiv.org/html/2507.13812v1",
        "PDF": "https://arxiv.org/pdf/2507.13812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a multi-modal remote sensing foundation model, which involves pre-training strategies for remote sensing data, but it does not address any specific operations related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13814",
      "abstract": "Large Language Models (LLMs) have demonstrated considerable potential in improving coding education by providing support for code writing, explanation, and debugging. However, existing LLM-based approaches generally fail to assess students' abilities, design learning plans, provide personalized material aligned with individual learning goals, and enable interactive learning. Current work mostly uses single LLM agents, which limits their ability to understand complex code repositories and schedule step-by-step tutoring. Recent research has shown that multi-agent LLMs can collaborate to solve complicated problems in various domains like software engineering, but their potential in the field of education remains unexplored. In this work, we introduce CodeEdu, an innovative multi-agent collaborative platform that combines LLMs with tool use to provide proactive and personalized education in coding. Unlike static pipelines, CodeEdu dynamically allocates agents and tasks to meet student needs. Various agents in CodeEdu undertake certain functions specifically, including task planning, personalized material generation, real-time QA, step-by-step tutoring, code execution, debugging, and learning report generation, facilitated with extensive external tools to improve task efficiency. Automated evaluations reveal that CodeEdu substantially enhances students' coding performance.",
      "authors": [
        "Jianing Zhao",
        "Peng Gao",
        "Jiannong Cao",
        "Zhiyuan Wen",
        "Chen Chen",
        "Jianing Yin",
        "Ruosong Yang",
        "Bo Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:52:22+00:00",
          "link": "https://arxiv.org/abs/2507.13814v1",
          "size": "822kb",
          "version": "v1"
        }
      ],
      "title": "CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13814",
        "HTML": "https://arxiv.org/html/2507.13814v1",
        "PDF": "https://arxiv.org/pdf/2507.13814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an educational platform called CodeEdu that utilizes LLMs for personalized coding education. It does not address any aspect of LLM training data processing, such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13818",
      "abstract": "Treedepth is a central parameter to algorithmic graph theory. The current state-of-the-art in computing and approximating treedepth consists of a $2^{O(k^2)} n$-time exact algorithm and a polynomial-time $O(\\text{OPT} \\log^{3/2} \\text{OPT})$-approximation algorithm, where the former algorithm returns an elimination forest of height $k$ (witnessing that treedepth is at most $k$) for the $n$-vertex input graph $G$, or correctly reports that $G$ has treedepth larger than $k$, and $\\text{OPT}$ is the actual value of the treedepth. On the complexity side, exactly computing treedepth is NP-complete, but the known reductions do not rule out a polynomial-time approximation scheme (PTAS), and under the Exponential Time Hypothesis (ETH) only exclude a running time of $2^{o(\\sqrt n)}$ for exact algorithms.\n  We show that 1.0003-approximating treedepth is NP-hard, and that exactly computing the treedepth of an $n$-vertex graph requires time $2^{\\Omega(n)}$, unless the ETH fails. We further derive that there exist absolute constants $\\delta, c > 0$ such that any $(1+\\delta)$-approximation algorithm requires time $2^{\\Omega(n / \\log^c n)}$. We do so via a simple direct reduction from Satisfiability to Treedepth, inspired by a reduction recently designed for Treewidth [STOC '25].",
      "authors": [
        "\\'Edouard Bonnet",
        "Daniel Neuen",
        "Marek Soko{\\l}owski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.13818v1",
          "size": "87kb",
          "version": "v1"
        }
      ],
      "title": "Treedepth Inapproximability and Exponential ETH Lower Bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13818",
        "HTML": "https://arxiv.org/html/2507.13818v1",
        "PDF": "https://arxiv.org/pdf/2507.13818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses treedepth computation and related graph-theoretic problems, with no mention of LLMs or training data processing. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13820",
      "abstract": "We propose a novel framework for open-ended video question answering that enhances reasoning depth and robustness in complex real-world scenarios, as benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models (Video-LMMs) often exhibit limited contextual understanding, weak temporal modeling, and poor generalization to ambiguous or compositional queries. To address these challenges, we introduce a prompting-and-response integration mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs) via structured chains of thought, each tailored to distinct reasoning pathways. An external Large Language Model (LLM) serves as an evaluator and integrator, selecting and fusing the most reliable responses. Extensive experiments demonstrate that our method significantly outperforms existing baselines across all evaluation metrics, showcasing superior generalization and robustness. Our approach offers a lightweight, extensible strategy for advancing multimodal reasoning without requiring model retraining, setting a strong foundation for future Video-LMM development.",
      "authors": [
        "Jun Xie",
        "Zhaoran Zhao",
        "Xiongjun Guan",
        "Yingjian Zhu",
        "Hongzhu Yi",
        "Xinming Wang",
        "Feng Chen",
        "Zhepeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:12:44+00:00",
          "link": "https://arxiv.org/abs/2507.13820v1",
          "size": "548kb",
          "version": "v1"
        }
      ],
      "title": "Team of One: Cracking Complex Video QA with Model Synergy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13820",
        "HTML": "https://arxiv.org/html/2507.13820v1",
        "PDF": "https://arxiv.org/pdf/2507.13820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for video question answering using LLMs for model integration and response evaluation. It does not involve any training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13822",
      "abstract": "Drug side effects are a major global health concern, necessitating advanced methods for their accurate detection and analysis. While Large Language Models (LLMs) offer promising conversational interfaces, their inherent limitations, including reliance on black-box training data, susceptibility to hallucinations, and lack of domain-specific knowledge, hinder their reliability in specialized fields like pharmacovigilance. To address this gap, we propose two architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which integrate comprehensive drug side effect knowledge into a Llama 3 8B language model. Through extensive evaluations on 19,520 drug side effect associations (covering 976 drugs and 3,851 side effect terms), our results demonstrate that GraphRAG achieves near-perfect accuracy in drug side effect retrieval. This framework offers a highly accurate and scalable solution, signifying a significant advancement in leveraging LLMs for critical pharmacovigilance applications.",
      "authors": [
        "Shad Nygren",
        "Pinar Avci",
        "Andre Daniels",
        "Reza Rassol",
        "Afshin Beheshti",
        "Diego Galeano"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:20:52+00:00",
          "link": "https://arxiv.org/abs/2507.13822v1",
          "size": "902kb",
          "version": "v1"
        }
      ],
      "title": "RAG-based Architectures for Drug Side Effect Retrieval in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13822",
        "PDF": "https://arxiv.org/pdf/2507.13822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes RAG and GraphRAG architectures for incorporating domain-specific knowledge into LLMs, focusing on data retrieval rather than creation or processing of training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13825",
      "abstract": "Temporal link prediction in dynamic graphs is a critical task with applications in diverse domains such as social networks, recommendation systems, and e-commerce platforms. While existing Temporal Graph Neural Networks (T-GNNs) have achieved notable success by leveraging complex architectures to model temporal and structural dependencies, they often suffer from scalability and efficiency challenges due to high computational overhead. In this paper, we propose EAGLE, a lightweight framework that integrates short-term temporal recency and long-term global structural patterns. EAGLE consists of a time-aware module that aggregates information from a node's most recent neighbors to reflect its immediate preferences, and a structure-aware module that leverages temporal personalized PageRank to capture the influence of globally important nodes. To balance these attributes, EAGLE employs an adaptive weighting mechanism to dynamically adjust their contributions based on data characteristics. Also, EAGLE eliminates the need for complex multi-hop message passing or memory-intensive mechanisms, enabling significant improvements in efficiency. Extensive experiments on seven real-world temporal graphs demonstrate that EAGLE consistently achieves superior performance against state-of-the-art T-GNNs in both effectiveness and efficiency, delivering more than a 50x speedup over effective transformer-based T-GNNs.",
      "authors": [
        "Haoyang Li",
        "Yuming Xu",
        "Yiming Li",
        "Hanmo Liu",
        "Darian Li",
        "Chen Jason Zhang",
        "Lei Chen",
        "Qing Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:29:15+00:00",
          "link": "https://arxiv.org/abs/2507.13825v1",
          "size": "1543kb",
          "version": "v1"
        }
      ],
      "title": "When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13825",
        "HTML": "https://arxiv.org/html/2507.13825v1",
        "PDF": "https://arxiv.org/pdf/2507.13825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on temporal link prediction in dynamic graphs using a novel framework, EAGLE. It does not involve any aspects of LLM training data processing like data engineering or data quality improvement for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13827",
      "abstract": "When deciding to read an article or incorporate it into their research, scholars often seek to quickly identify and understand its main ideas. In this paper, we aim to extract these key concepts and contributions from scientific articles in the form of Question and Answer (QA) pairs. We propose two distinct approaches for generating QAs. The first approach involves selecting salient paragraphs, using a Large Language Model (LLM) to generate questions, ranking these questions by the likelihood of obtaining meaningful answers, and subsequently generating answers. This method relies exclusively on the content of the articles. However, assessing an article's novelty typically requires comparison with the existing literature. Therefore, our second approach leverages a Knowledge Graph (KG) for QA generation. We construct a KG by fine-tuning an Entity Relationship (ER) extraction model on scientific articles and using it to build the graph. We then employ a salient triplet extraction method to select the most pertinent ERs per article, utilizing metrics such as the centrality of entities based on a triplet TF-IDF-like measure. This measure assesses the saliency of a triplet based on its importance within the article compared to its prevalence in the literature. For evaluation, we generate QAs using both approaches and have them assessed by Subject Matter Experts (SMEs) through a set of predefined metrics to evaluate the quality of both questions and answers. Our evaluations demonstrate that the KG-based approach effectively captures the main ideas discussed in the articles. Furthermore, our findings indicate that fine-tuning the ER extraction model on our scientific corpus is crucial for extracting high-quality triplets from such documents.",
      "authors": [
        "Hosein Azarbonyad",
        "Zi Long Zhu",
        "Georgios Cheirmpos",
        "Zubair Afzal",
        "Vikrant Yadav",
        "Georgios Tsatsaronis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:31:52+00:00",
          "link": "https://arxiv.org/abs/2507.13827v1",
          "size": "888kb",
          "version": "v1"
        }
      ],
      "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13827",
        "HTML": "https://arxiv.org/html/2507.13827v1",
        "PDF": "https://arxiv.org/pdf/2507.13827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs for question generation from scientific articles but does not focus primarily on LLM training data processing. It involves Q&A extraction, leveraging knowledge graphs, and fine-tuning, partially touching upon data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13833",
      "abstract": "Reinforcement learning (RL) has become the pivotal post-training technique for large language model. Effectively scaling reinforcement learning is now the key to unlocking advanced reasoning capabilities and ensuring safe, goal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually employ a hybrid-controller architecture where a single-controller dispatches the overall execution logic and manages overall data transfer and the multi-controller executes distributed computation. For large-scale reinforcement learning, minor load imbalances can introduce significant bottlenecks, ultimately constraining the scalability of the system. To address this limitation, we introduce DistFlow, a novel, fully distributed RL framework designed to break scaling barrier. We adopt a multi-controller paradigm that dispatches data transfer and execution tasks to all workers, which eliminates the centralized node. This allows each worker to operate independently, leading to near-linear scalability up to thousands of GPUs and dramatic efficiency gains. Furthermore, our architecture decouples resource configuration from execution logic, allowing each worker to have a unique execution flow, offering significant flexibility for rapid and cost-effective algorithmic experimentation. Extensive experiments show that DistFlow achieves excellent linear scalability and up to a 7x end-to-end throughput improvement over state-of-the-art (SOTA) frameworks.",
      "authors": [
        "Zhixin Wang",
        "Tianyi Zhou",
        "Liming Liu",
        "Ao Li",
        "Jiarui Hu",
        "Dian Yang",
        "Jinlong Hou",
        "Siyuan Feng",
        "Yuan Cheng and Yuan Qi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:41:49+00:00",
          "link": "https://arxiv.org/abs/2507.13833v1",
          "size": "642kb",
          "version": "v1"
        }
      ],
      "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13833",
        "HTML": "https://arxiv.org/html/2507.13833v1",
        "PDF": "https://arxiv.org/pdf/2507.13833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "DistFlow proposes a framework for scalable RL-based post-training of LLMs, focusing on reinforcement learning frameworks. It does not relate to data processing operations for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13834",
      "abstract": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the environment via a set of possible actions, and a reward is generated from some unknown distribution. The task here is to find an optimal set of actions such that the reward after a certain time step gets maximized. In a traditional setup, the reward function in an RL Problem is considered additive. However, in reality, there exist many problems, including path planning, coverage control, etc., the reward function follows the diminishing return, which can be modeled as a submodular function. In this paper, we study a variant of the RL Problem where the reward function is submodular, and our objective is to find an optimal policy such that this reward function gets maximized. We have proposed a pruned submodularity graph-based approach that provides a provably approximate solution in a feasible computation time. The proposed approach has been analyzed to understand its time and space requirements as well as a performance guarantee. We have experimented with a benchmark agent-environment setup, which has been used for similar previous studies, and the results are reported. From the results, we observe that the policy obtained by our proposed approach leads to more reward than the baseline methods.",
      "authors": [
        "Aditi Anand",
        "Suman Banerjee",
        "Dildar Ali"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:42:07+00:00",
          "link": "https://arxiv.org/abs/2507.13834v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13834",
        "HTML": "https://arxiv.org/html/2507.13834v1",
        "PDF": "https://arxiv.org/pdf/2507.13834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with submodular policy optimization in reinforcement learning environments, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13836",
      "abstract": "We consider the solution of variational equations on manifolds by Newton's method. These problems can be expressed as root finding problems for mappings from infinite dimensional manifolds into dual vector bundles. We derive the differential geometric tools needed for the realization of Newton's method, equipped with an affine covariant damping strategy. We apply Newton's method to a couple of variational problems and show numerical results.",
      "authors": [
        "Laura Weigl",
        "Ronny Bergmann",
        "Anton Schiela"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Differential Geometry (math.DG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.13836v1",
          "size": "647kb",
          "version": "v1"
        }
      ],
      "title": "Newton's method for nonlinear mappings into vector bundles Part II: Application to variational problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13836",
        "HTML": "https://arxiv.org/html/2507.13836v1",
        "PDF": "https://arxiv.org/pdf/2507.13836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is primarily concerned with applying Newton's method to solve variational problems on manifolds. It does not make any contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13837",
      "abstract": "Automated vehicles (AVs) increasingly encounter ethically ambiguous situations in everyday driving--scenarios involving conflicting human interests and lacking clearly optimal courses of action. While existing ethical models often focus on rare, high-stakes dilemmas (e.g., crash avoidance or trolley problems), routine decisions such as overtaking cyclists or navigating social interactions remain underexplored. This study addresses that gap by applying the tracking condition of Meaningful Human Control (MHC), which holds that AV behaviour should align with human reasons--defined as the values, intentions, and expectations that justify actions. We conducted qualitative interviews with 18 AV experts to identify the types of reasons that should inform AV manoeuvre planning. Thirteen categories of reasons emerged, organised across normative, strategic, tactical, and operational levels, and linked to the roles of relevant human agents. A case study on cyclist overtaking illustrates how these reasons interact in context, revealing a consistent prioritisation of safety, contextual flexibility regarding regulatory compliance, and nuanced trade-offs involving efficiency, comfort, and public acceptance. Based on these insights, we propose a principled conceptual framework for AV decision-making in routine, ethically ambiguous scenarios. The framework supports dynamic, human-aligned behaviour by prioritising safety, allowing pragmatic actions when strict legal adherence would undermine key values, and enabling constrained deviations when appropriately justified. This empirically grounded approach advances current guidance by offering actionable, context-sensitive design principles for ethically aligned AV systems.",
      "authors": [
        "Lucas Elbert Suryana",
        "Simeon Calvert",
        "Arkady Zgonnikov",
        "Bart van Arem"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:52:33+00:00",
          "link": "https://arxiv.org/abs/2507.13837v1",
          "size": "5708kb",
          "version": "v1"
        }
      ],
      "title": "Principles and Reasons Behind Automated Vehicle Decisions in Ethically Ambiguous Everyday Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13837",
        "HTML": "https://arxiv.org/html/2507.13837v1",
        "PDF": "https://arxiv.org/pdf/2507.13837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses ethical decision-making for automated vehicles, focusing on ethically ambiguous driving scenarios. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13839",
      "abstract": "This study explores the relationship between linguistic expressions and psychological states of depression and anxiety within Chinese psycho-counseling interactions, focusing specifically on the usage of first-person singular pronouns and negative emotional words. Utilizing a corpus derived from 735 online counseling sessions, the analysis employed a general linear mixed-effect model to assess linguistic patterns quantified by the Linguistic Inquiry and Word Count (LIWC) software. Results indicate a significant positive correlation between the frequency of negative emotional words and the severity of both depressive and anxious states among clients. However, contrary to prior findings predominantly derived from English-language contexts, the usage frequency of first-person singular pronouns did not vary significantly with the clients' psychological conditions. These outcomes are discussed within the framework of cultural distinctions between collectivist Chinese contexts and individualistic Western settings, as well as the interactive dynamics unique to psycho-counseling conversations. The findings highlight the nuanced influence of cultural and conversational contexts on language use in mental health communications, providing insights into psycholinguistic markers relevant to therapeutic practices in Chinese-speaking populations.",
      "authors": [
        "Lizhi Ma",
        "Tong Zhao",
        "Shuai Zhang",
        "Nirui Song",
        "Hongliang He",
        "Anqi Li",
        "Ran Feng",
        "Huachuan Qiu",
        "Jingsong Ma",
        "Zhenzhong Lan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:53:15+00:00",
          "link": "https://arxiv.org/abs/2507.13839v1",
          "size": "881kb",
          "version": "v1"
        }
      ],
      "title": "The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13839",
        "PDF": "https://arxiv.org/pdf/2507.13839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines linguistic expressions of psychological states in Chinese psycho-counseling, focusing on cultural and conversational contexts. It does not deal with LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13841",
      "abstract": "Effective storytelling relies on a delicate balance between meeting the reader's prior expectations and introducing unexpected developments. In the domain of detective fiction, this tension is known as fair play, which includes the implicit agreement between the writer and the reader as to the range of possible resolutions the mystery story may have. In this work, we present a probabilistic framework for detective fiction that allows us to define desired qualities. Using this framework, we formally define fair play and design appropriate metrics for it. Stemming from these definitions is an inherent tension between the coherence of the story, which measures how much it ``makes sense'', and the surprise it induces. We validate the framework by applying it to LLM-generated detective stories. This domain is appealing since we have an abundance of data, we can sample from the distribution generating the story, and the story-writing capabilities of LLMs are interesting in their own right. Results show that while LLM-generated stories may be unpredictable, they generally fail to balance the trade-off between surprise and fair play, which greatly contributes to their poor quality.",
      "authors": [
        "Eitan Wagner",
        "Renana Keydar",
        "Omri Abend"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:55:18+00:00",
          "link": "https://arxiv.org/abs/2507.13841v1",
          "size": "282kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Fair Play in Detective Stories with Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13841",
        "HTML": "https://arxiv.org/html/2507.13841v1",
        "PDF": "https://arxiv.org/pdf/2507.13841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper employs LLMs for generating detective stories and explores the balance between coherence and surprise, which pertains more to the generation capabilities of LLMs rather than data processing for LLM training. Thus, it only indirectly touches on aspects relevant to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13846",
      "abstract": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable success in environments where agents must learn coordinated behaviors. However, transferring knowledge across agents remains challenging in non-stationary environments with changing goals. [Problem] Traditional knowledge transfer methods in MARL struggle to generalize, and agents often require costly retraining to adapt. [Approach] This paper introduces a causal knowledge transfer framework that enables RL agents to learn and share compact causal representations of paths within a non-stationary environment. As the environment changes (new obstacles), agents' collisions require adaptive recovery strategies. We model each collision as a causal intervention instantiated as a sequence of recovery actions (a macro) whose effect corresponds to a causal knowledge of how to circumvent the obstacle while increasing the chances of achieving the agent's goal (maximizing cumulative reward). This recovery action macro is transferred online from a second agent and is applied in a zero-shot fashion, i.e., without retraining, just by querying a lookup model with local context information (collisions). [Results] Our findings reveal two key insights: (1) agents with heterogeneous goals were able to bridge about half of the gap between random exploration and a fully retrained policy when adapting to new environments, and (2) the impact of causal knowledge transfer depends on the interplay between environment complexity and agents' heterogeneous goals.",
      "authors": [
        "Kathrin Korte",
        "Christian Medeiros Adriano",
        "Sona Ghahremani",
        "Holger Giese"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.13846v1",
          "size": "445kb",
          "version": "v1"
        }
      ],
      "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13846",
        "HTML": "https://arxiv.org/html/2507.13846v1",
        "PDF": "https://arxiv.org/pdf/2507.13846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on causal knowledge transfer in multi-agent reinforcement learning, which does not involve LLM training data processing or any direct contributions to data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13847",
      "abstract": "We explore the problem of explaining observations in contexts involving statements with truth degrees such as `the lift is loaded', `the symptoms are severe', etc. To formalise these contexts, we consider infinitely-valued {\\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction problems and explanations in the language of {\\L}ukasiewicz logic expanded with `interval literals' of the form $p\\geq\\mathbf{c}$, $p\\leq\\mathbf{c}$, and their negations that express the set of values a variable can have. We analyse the complexity of standard abductive reasoning tasks (solution recognition, solution existence, and relevance / necessity of hypotheses) in {\\L}ukasiewicz logic for the case of the full language and for the case of theories containing only disjunctive clauses and show that in contrast to classical propositional logic, the abduction in the clausal fragment has lower complexity than in the general case.",
      "authors": [
        "Katsumi Inoue and Daniil Kozhemiachenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:00:22+00:00",
          "link": "https://arxiv.org/abs/2507.13847v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Complexity of Abduction in \\L{}ukasiewicz Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13847",
        "HTML": "https://arxiv.org/html/2507.13847v1",
        "PDF": "https://arxiv.org/pdf/2507.13847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the complexity of abduction in \\( \\L{} \\)ukasiewicz Logic and does not involve any aspects of LLM training data processing or data operations relevant to LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13852",
      "abstract": "Building segmentation in urban areas is essential in fields such as urban planning, disaster response, and population mapping. Yet accurately segmenting buildings in dense urban regions presents challenges due to the large size and high resolution of satellite images. This study investigates the use of a Quanvolutional pre-processing to enhance the capability of the Attention U-Net model in the building segmentation. Specifically, this paper focuses on the urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR) imagery. In this work, Quanvolution was used to extract more informative feature maps that capture essential structural details in radar imagery, proving beneficial for accurate building segmentation. Preliminary results indicate that proposed methodology achieves comparable test accuracy to the standard Attention U-Net model while significantly reducing network parameters. This result aligns with findings from previous works, confirming that Quanvolution not only maintains model accuracy but also increases computational efficiency. These promising outcomes highlight the potential of quantum-assisted Deep Learning frameworks for large-scale building segmentation in urban environments.",
      "authors": [
        "Luigi Russo",
        "Francesco Mauro",
        "Babak Memar",
        "Alessandro Sebastianelli",
        "Silvia Liberata Ullo and Paolo Gamba"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:16:04+00:00",
          "link": "https://arxiv.org/abs/2507.13852v1",
          "size": "761kb",
          "version": "v1"
        }
      ],
      "title": "A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13852",
        "HTML": "https://arxiv.org/html/2507.13852v1",
        "PDF": "https://arxiv.org/pdf/2507.13852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this study is on using quantum-assisted methods for building segmentation with Sentinel-1 data. It does not address LLM training data processing or operations related to improving LLM data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13853",
      "abstract": "This paper introduces a novel class of multi-stage resource allocation games that model real-world scenarios in which profitability depends on the balance between supply and demand, and where higher resource investment leads to greater returns. Our proposed framework, which incorporates the notion of profit loss due to insufficient player participation, gives rise to a Tullock-like functional form of the stage payoff structure when weighted fair proportional resource allocation is applied. We explore both centralized and Nash equilibrium strategies, establish sufficient conditions for their existence and uniqueness, and provide an iterative, semi-decentralized method to compute the Nash equilibrium in games with arbitrarily many players. Additionally, we demonstrate that the framework generalizes instances of several existing models, including Receding Horizon and Blotto games, and present a semi-analytical method for computing the unique Nash equilibrium within the Blotto setup. Our findings are validated through a numerical case study in smart mobility, highlighting the practical relevance and applicability of the proposed model.",
      "authors": [
        "Marko Maljkovic",
        "Gustav Nilsson",
        "and Nikolas Geroliminis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:18:49+00:00",
          "link": "https://arxiv.org/abs/2507.13853v1",
          "size": "5219kb",
          "version": "v1"
        }
      ],
      "title": "Resource-Splitting Games with Tullock-Based Lossy Contests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13853",
        "PDF": "https://arxiv.org/pdf/2507.13853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces resource-splitting games with Tullock-based contests, which is unrelated to LLM training data processing or tasks associated with improving LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13855",
      "abstract": "In this paper, we propose a new stochastic column-block gradient descent method for solving nonlinear systems of equations. It has a descent direction and holds an approximately optimal step size obtained through an optimization problem. We provide a thorough convergence analysis, and derive an upper bound for the convergence rate of the new method. Numerical experiments demonstrate that the proposed method outperforms the existing ones.",
      "authors": [
        "Naiyu Jiang",
        "Wendi Bao",
        "Lili Xing",
        "Weiguo Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:22:22+00:00",
          "link": "https://arxiv.org/abs/2507.13855v1",
          "size": "162kb",
          "version": "v1"
        }
      ],
      "title": "A stochastic column-block gradient descent method for solving nonlinear systems of equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13855",
        "HTML": "https://arxiv.org/html/2507.13855v1",
        "PDF": "https://arxiv.org/pdf/2507.13855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a stochastic method for solving nonlinear systems of equations, which does not pertain to LLM training data processing or contribute to data operations in an LLM context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13857",
      "abstract": "Monocular 3D lane detection is essential for autonomous driving, but challenging due to the inherent lack of explicit spatial information. Multi-modal approaches rely on expensive depth sensors, while methods incorporating fully-supervised depth networks rely on ground-truth depth data that is impractical to collect at scale. Additionally, existing methods assume that camera parameters are available, limiting their applicability in scenarios like crowdsourced high-definition (HD) lane mapping. To address these limitations, we propose Depth3DLane, a novel dual-pathway framework that integrates self-supervised monocular depth estimation to provide explicit structural information, without the need for expensive sensors or additional ground-truth depth data. Leveraging a self-supervised depth network to obtain a point cloud representation of the scene, our bird's-eye view pathway extracts explicit spatial information, while our front view pathway simultaneously extracts rich semantic information. Depth3DLane then uses 3D lane anchors to sample features from both pathways and infer accurate 3D lane geometry. Furthermore, we extend the framework to predict camera parameters on a per-frame basis and introduce a theoretically motivated fitting procedure to enhance stability on a per-segment basis. Extensive experiments demonstrate that Depth3DLane achieves competitive performance on the OpenLane benchmark dataset. Furthermore, experimental results show that using learned parameters instead of ground-truth parameters allows Depth3DLane to be applied in scenarios where camera calibration is infeasible, unlike previous methods.",
      "authors": [
        "Max van den Hoven",
        "Kishaan Jeeveswaran",
        "Pieter Piscaer",
        "Thijs Wensveen",
        "Elahe Arani",
        "Bahram Zonooz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:23:47+00:00",
          "link": "https://arxiv.org/abs/2507.13857v1",
          "size": "1484kb",
          "version": "v1"
        }
      ],
      "title": "Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13857",
        "HTML": "https://arxiv.org/html/2507.13857v1",
        "PDF": "https://arxiv.org/pdf/2507.13857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on 3D lane detection for autonomous driving by integrating self-supervised monocular depth estimation, which does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13858",
      "abstract": "The reasoning capabilities of Large Language Models (LLMs) have increased greatly over the last few years, as have their size and complexity. Nonetheless, the use of LLMs in production remains challenging due to their unpredictable nature and discrepancies that can exist between their desired behavior and their actual model output. In this paper, we introduce a new tool, InTraVisTo (Inside Transformer Visualisation Tool), designed to enable researchers to investigate and trace the computational process that generates each token in a Transformer-based LLM. InTraVisTo provides a visualization of both the internal state of the Transformer model (by decoding token embeddings at each layer of the model) and the information flow between the various components across the different layers of the model (using a Sankey diagram). With InTraVisTo, we aim to help researchers and practitioners better understand the computations being performed within the Transformer model and thus to shed some light on internal patterns and reasoning processes employed by LLMs.",
      "authors": [
        "Nicol\\`o Brunello",
        "Davide Rigamonti",
        "Andrea Sassella",
        "Vincenzo Scotti",
        "Mark James Carman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:23:47+00:00",
          "link": "https://arxiv.org/abs/2507.13858v1",
          "size": "3329kb",
          "version": "v1"
        }
      ],
      "title": "InTraVisTo: Inside Transformer Visualisation Tool",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13858",
        "HTML": "https://arxiv.org/html/2507.13858v1",
        "PDF": "https://arxiv.org/pdf/2507.13858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "InTraVisTo is a tool for visualizing internal computations of Transformer models, aimed at enhancing understanding of LLM operations. It does not address training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13859",
      "abstract": "Nowadays, the importance of software with natural-language user interfaces cannot be underestimated. In particular, in Question Answering (QA) systems, generating a SPARQL query for a given natural-language question (often named Query Building) from the information retrieved from the same question is the central task of QA systems working over Knowledge Graphs (KGQA). Due to the rise of Large Language Models (LLMs), they are considered a well-suited method to increase the quality of the question-answering functionality, as there is still a lot of room for improvement, aiming for enhanced quality and trustworthiness. However, LLMs are trained on web data, where researchers have no control over whether the benchmark or the knowledge graph was already included in the training data. In this paper, we introduce a novel method that evaluates the quality of LLMs by generating a SPARQL query from a natural-language question under various conditions: (1) zero-shot SPARQL generation, (2) with knowledge injection, and (3) with \"anonymized\" knowledge injection. This enables us, for the first time, to estimate the influence of the training data on the QA quality improved by LLMs. Ultimately, this will help to identify how portable a method is or whether good results might mostly be achieved because a benchmark was already included in the training data (cf. LLM memorization). The developed method is portable, robust, and supports any knowledge graph; therefore, it could be easily applied to any KGQA or LLM, s.t., generating consistent insights into the actual LLM capabilities is possible.",
      "authors": [
        "Aleksandr Gashkov",
        "Aleksandr Perevalov",
        "Maria Eltsova",
        "Andreas Both"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:28:08+00:00",
          "link": "https://arxiv.org/abs/2507.13859v1",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "title": "SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13859",
        "HTML": "https://arxiv.org/html/2507.13859v1",
        "PDF": "https://arxiv.org/pdf/2507.13859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the impact of training data memorization and knowledge injection on SPARQL query generation. While it touches upon the effects of training data, its primary focus is on query generation and model evaluation, not on data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13861",
      "abstract": "Recent subject-driven image customization has achieved significant advancements in fidelity, yet fine-grained entity-level spatial control remains elusive, hindering the broader real-world application. This limitation is mainly attributed to scalable datasets that bind identity with precise positional cues are absent. To this end, we introduce PositionIC, a unified framework that enforces position and identity consistency for multi-subject customization. We construct a scalable synthesis pipeline that employs a bidirectional generation paradigm to eliminate subject drift and maintain semantic coherence. On top of these data, we design a lightweight positional modulation layer that decouples spatial embeddings among subjects, enabling independent, accurate placement while preserving visual fidelity. Extensive experiments demonstrate that our approach can achieve precise spatial control while maintaining high consistency in image customization task. PositionIC paves the way for controllable, high-fidelity image customization in open-world, multi-entity scenarios and will be released to foster further research.",
      "authors": [
        "Junjie Hu",
        "Tianyang Han",
        "Kai Ma",
        "Jialin Gao",
        "Hao Dou",
        "Song Yang",
        "Xianhua He",
        "Jianhui Zhang",
        "Junfeng Luo",
        "Xiaoming Wei",
        "Wenqiang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:35:47+00:00",
          "link": "https://arxiv.org/abs/2507.13861v1",
          "size": "3858kb",
          "version": "v1"
        }
      ],
      "title": "PositionIC: Unified Position and Identity Consistency for Image Customization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13861",
        "HTML": "https://arxiv.org/html/2507.13861v1",
        "PDF": "https://arxiv.org/pdf/2507.13861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PositionIC deals with image customization and spatial control in images, revolving around building a synthesis pipeline and position modulation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13863",
      "abstract": "Noise suppression and speech distortion are two important aspects to be balanced when designing multi-channel Speech Enhancement (SE) algorithms. Although neural network models have achieved state-of-the-art noise suppression, their non-linear operations often introduce high speech distortion. Conversely, classical signal processing algorithms such as the Parameterized Multi-channel Wiener Filter ( PMWF) beamformer offer explicit mechanisms for controlling the suppression/distortion trade-off. In this work, we present NeuralPMWF, a system where the PMWF is entirely controlled using a low-latency, low-compute neural network, resulting in a low-complexity system offering high noise reduction and low speech distortion. Experimental results show that our proposed approach results in significantly better perceptual and objective speech enhancement in comparison to several competitive baselines using similar computational resources.",
      "authors": [
        "Eric Grinstein",
        "Ashutosh Pandey",
        "Cole Li",
        "Shanmukha Srinivas",
        "Juan Azcarreta",
        "Jacob Donley",
        "Sanha Lee",
        "Ali Aroudi",
        "Cagdas Bilen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:38:35+00:00",
          "link": "https://arxiv.org/abs/2507.13863v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "Controlling the Parameterized Multi-channel Wiener Filter using a tiny neural network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13863",
        "HTML": "https://arxiv.org/html/2507.13863v1",
        "PDF": "https://arxiv.org/pdf/2507.13863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study involves noise suppression in speech enhancement using a neural network-controlled Wiener filter. This is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13868",
      "abstract": "Vision-language models (VLMs) increasingly leverage diverse knowledge sources to address complex tasks, often encountering conflicts between their internal parametric knowledge and external information. Knowledge conflicts can result in hallucinations and unreliable responses, but the mechanisms governing such interactions remain unknown. To address this gap, we analyze the mechanisms that VLMs use to resolve cross-modal conflicts by introducing a dataset of multimodal counterfactual queries that deliberately contradict internal commonsense knowledge. We localize with logit inspection a small set of heads that control the conflict. Moreover, by modifying these heads, we can steer the model towards its internal knowledge or the visual inputs. Finally, we show that attention from such heads pinpoints localized image regions driving visual overrides, outperforming gradient-based attribution in precision.",
      "authors": [
        "Francesco Ortu",
        "Zhijing Jin",
        "Diego Doimo",
        "Alberto Cazzaniga"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:42:30+00:00",
          "link": "https://arxiv.org/abs/2507.13868v1",
          "size": "3203kb",
          "version": "v1"
        }
      ],
      "title": "When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13868",
        "PDF": "https://arxiv.org/pdf/2507.13868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on understanding and resolving knowledge conflicts in vision-language models, particularly concerning multimodal counterfactual queries. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13869",
      "abstract": "Let $G = (V,E,\\ell)$ be a $n$-node $m$-edge weighted undirected graph, where $\\ell: E \\rightarrow (0,\\infty)$ is a real \\emph{length} function defined on its edges, and let $g$ denote the girth of $G$, i.e., the length of its shortest cycle. We present an algorithm that, for any input, integer $k \\geq 1$, in $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ expected time finds a cycle of length at most $\\frac{4k}{3}g$. This algorithm nearly matches a $O(n^{1+1/k}\\log{n})$-time algorithm of \\cite{KadriaRSWZ22} which applied to unweighted graphs of girth $3$. For weighted graphs, this result also improves upon the previous state-of-the-art algorithm that in $O((n^{1+1/k}\\log n+m)\\log (nM))$ time, where $\\ell: E \\rightarrow [1, M]$ is an integral length function, finds a cycle of length at most $2kg$~\\cite{KadriaRSWZ22}. For $k=1$ this result improves upon the result of Roditty and Tov~\\cite{RodittyT13}.",
      "authors": [
        "Avi Kadria",
        "Liam Roditty",
        "Aaron Sidford",
        "Virginia Vassilevska Williams",
        "Uri Zwick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:43:30+00:00",
          "link": "https://arxiv.org/abs/2507.13869v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Improved girth approximation in weighted undirected graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13869",
        "HTML": "https://arxiv.org/html/2507.13869v1",
        "PDF": "https://arxiv.org/pdf/2507.13869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with algorithm development for finding cycles in graphs and does not involve any aspect of data processing for LLMs or training data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13870",
      "abstract": "The field of cybersecurity NER lacks standardized labels, making it challenging to combine datasets. We investigate label unification across four cybersecurity datasets to increase data resource usability. We perform a coarse-grained label unification and conduct pairwise cross-dataset evaluations using BiLSTM models. Qualitative analysis of predictions reveals errors, limitations, and dataset differences. To address unification limitations, we propose alternative architectures including a multihead model and a graph-based transfer model. Results show that models trained on unified datasets generalize poorly across datasets. The multihead model with weight sharing provides only marginal improvements over unified training, while our graph-based transfer model built on BERT-base-NER shows no significant performance gains compared BERT-base-NER.",
      "authors": [
        "Maciej Jalocha",
        "Johan Hausted Schmidt",
        "William Michelseen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:47:20+00:00",
          "link": "https://arxiv.org/abs/2507.13870v1",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "title": "Label Unification for Cross-Dataset Generalization in Cybersecurity NER",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13870",
        "HTML": "https://arxiv.org/html/2507.13870v1",
        "PDF": "https://arxiv.org/pdf/2507.13870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on label unification for cybersecurity named entity recognition (NER) tasks. While it involves dataset manipulation, it is specific to NER tasks in cybersecurity and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13871",
      "abstract": "Synthesising safe controllers from visual data typically requires extensive supervised labelling of safety-critical data, which is often impractical in real-world settings. Recent advances in world models enable reliable prediction in latent spaces, opening new avenues for scalable and data-efficient safe control. In this work, we introduce a semi-supervised framework that leverages control barrier certificates (CBCs) learned in the latent space of a world model to synthesise safe visuomotor policies. Our approach jointly learns a neural barrier function and a safe controller using limited labelled data, while exploiting the predictive power of modern vision transformers for latent dynamics modelling.",
      "authors": [
        "Mehul Anand and Shishir Kolathaya"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:50:27+00:00",
          "link": "https://arxiv.org/abs/2507.13871v1",
          "size": "543kb",
          "version": "v1"
        }
      ],
      "title": "Safety Certification in the Latent space using Control Barrier Functions and World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13871",
        "HTML": "https://arxiv.org/html/2507.13871v1",
        "PDF": "https://arxiv.org/pdf/2507.13871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on synthesizing safe controllers from visual data using world models and control barrier functions. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13872",
      "abstract": "Ensuring both performance and safety is critical for autonomous systems operating in real-world environments. While safety filters such as Control Barrier Functions (CBFs) enforce constraints by modifying nominal controllers in real time, they can become overly conservative when the nominal policy lacks safety awareness. Conversely, solving State-Constrained Optimal Control Problems (SC-OCPs) via dynamic programming offers formal guarantees but is intractable in high-dimensional systems. In this work, we propose a novel two-stage framework that combines gradient-based Model Predictive Control (MPC) with CBF-based safety filtering for co-optimizing safety and performance. In the first stage, we relax safety constraints as penalties in the cost function, enabling fast optimization via gradient-based methods. This step improves scalability and avoids feasibility issues associated with hard constraints. In the second stage, we modify the resulting controller using a CBF-based Quadratic Program (CBF-QP), which enforces hard safety constraints with minimal deviation from the reference. Our approach yields controllers that are both performant and provably safe. We validate the proposed framework on two case studies, showcasing its ability to synthesize scalable, safe, and high-performance controllers for complex, high-dimensional autonomous systems.",
      "authors": [
        "Aditya Singh",
        "Aastha Mishra",
        "Manan Tayal",
        "Shishir Kolathaya",
        "and Pushpak Jagtap"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:50:47+00:00",
          "link": "https://arxiv.org/abs/2507.13872v1",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "title": "Safe and Performant Controller Synthesis using Gradient-based Model Predictive Control and Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13872",
        "HTML": "https://arxiv.org/html/2507.13872v1",
        "PDF": "https://arxiv.org/pdf/2507.13872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses controller synthesis using gradient-based model predictive control and control barrier functions, focusing on ensuring performance and safety in autonomous systems. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13874",
      "abstract": "Innovative idea generation remains a core challenge in AI, as large language models (LLMs) often struggle to produce outputs that are both novel and relevant. Despite their fluency, LLMs tend to replicate patterns seen during training, limiting their ability to diverge creatively without extensive prompt engineering. Prior work has addressed this through domain-specific heuristics and structured prompting pipelines, but such solutions are brittle and difficult to generalize. In this paper, we propose a model-agnostic latent-space ideation framework that enables controlled, scalable creativity by navigating the continuous embedding space of ideas. Unlike prior methods, our framework requires no handcrafted rules and adapts easily to different domains, input formats, and creative tasks. This paper introduces an early-stage prototype of our method, outlining the conceptual framework and preliminary results highlighting its potential as a general-purpose co-ideator for human-AI collaboration.",
      "authors": [
        "Mateusz Bystro\\'nski",
        "Miko{\\l}aj Ho{\\l}ysz",
        "Grzegorz Piotrowski",
        "Nitesh V. Chawla",
        "Tomasz Kajdanowicz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:54:28+00:00",
          "link": "https://arxiv.org/abs/2507.13874v1",
          "size": "167kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13874",
        "HTML": "https://arxiv.org/html/2507.13874v1",
        "PDF": "https://arxiv.org/pdf/2507.13874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a latent-space ideation framework for creative tasks with LLMs and discusses the generation of novel ideas, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13875",
      "abstract": "Code-switching (CS), the alternating use of two or more languages, challenges automatic speech recognition (ASR) due to scarce training data and linguistic similarities. The lack of dedicated CS datasets limits ASR performance, as most models rely on monolingual or mixed-language corpora that fail to reflect real-world CS patterns. This issue is critical in multilingual societies where CS occurs in informal and formal settings. A key example is Catalan-Spanish CS, widely used in media and parliamentary speeches. In this work, we improve ASR for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data with language tokens. We extract CS data from Catalan speech corpora and fine-tune OpenAI's Whisper models, making them available on Hugging Face. Results show that combining a modest amount of synthetic CS data with the dominant language token yields the best transcription performance.",
      "authors": [
        "Carlos Mena",
        "Pol Serra",
        "Jacobo Romero",
        "Abir Messaoudi",
        "Jose Giraldo",
        "Carme Armentano-Oller",
        "Rodolfo Zevallos",
        "Ivan Meza",
        "Javier Hernando"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:54:41+00:00",
          "link": "https://arxiv.org/abs/2507.13875v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13875",
        "HTML": "https://arxiv.org/html/2507.13875v1",
        "PDF": "https://arxiv.org/pdf/2507.13875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper primarily focuses on optimizing ASR for Catalan-Spanish code-switching, it does involve the generation of synthetic CS data, which is a data processing technique relevant to training, though this is not the primary focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13880",
      "abstract": "This paper presents a novel approach to enhancing marine vision by fusing real-time visual data with chart information. Our system overlays nautical chart data onto live video feeds by accurately matching detected navigational aids, such as buoys, with their corresponding representations in chart data. To achieve robust association, we introduce a transformer-based end-to-end neural network that predicts bounding boxes and confidence scores for buoy queries, enabling the direct matching of image-domain detections with world-space chart markers. The proposed method is compared against baseline approaches, including a ray-casting model that estimates buoy positions via camera projection and a YOLOv7-based network extended with a distance estimation module. Experimental results on a dataset of real-world maritime scenes demonstrate that our approach significantly improves object localization and association accuracy in dynamic and challenging environments.",
      "authors": [
        "Marten Kreis",
        "Benjamin Kiefer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:58:11+00:00",
          "link": "https://arxiv.org/abs/2507.13880v1",
          "size": "1955kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13880",
        "HTML": "https://arxiv.org/html/2507.13880v1",
        "PDF": "https://arxiv.org/pdf/2507.13880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for enhancing marine vision through visual and chart data fusion, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13881",
      "abstract": "Academic programs are increasingly recognizing the importance of personal and professional skills and their critical role alongside technical expertise in preparing students for future success in diverse career paths. With this growing demand comes the need for scalable systems to measure, evaluate, and develop these skills. Situational Judgment Tests (SJTs) offer one potential avenue for measuring these skills in a standardized and reliable way, but open-response SJTs have traditionally relied on trained human raters for evaluation, presenting operational challenges to delivering SJTs at scale. Past attempts at developing NLP-based scoring systems for SJTs have fallen short due to issues with construct validity of these systems. In this article, we explore a novel approach to extracting construct-relevant features from SJT responses using large language models (LLMs). We use the Casper SJT to demonstrate the efficacy of this approach. This study sets the foundation for future developments in automated scoring for personal and professional skills.",
      "authors": [
        "Cole Walsh",
        "Rodica Ivan",
        "Muhammad Zafar Iqbal",
        "and Colleen Robb"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:59:17+00:00",
          "link": "https://arxiv.org/abs/2507.13881v1",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "title": "Using LLMs to identify features of personal and professional skills in an open-response situational judgment test",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13881",
        "HTML": "https://arxiv.org/html/2507.13881v1",
        "PDF": "https://arxiv.org/pdf/2507.13881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs to extract features from SJT responses, which involves some data processing, but the main focus is on automated scoring and evaluation rather than direct contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13885",
      "abstract": "Pattern matching is one of the fundamental problems in Computer Science. Both the classic version of the problem as well as the more sophisticated version where wildcards can also appear in the input can be solved in almost linear time $\\tilde O(n)$ using the KMP algorithm and Fast Fourier Transform, respectively. In 2000, Ramesh and Vinay~\\cite{ramesh2003string} give a quantum algorithm that solves classic pattern matching in sublinear time and asked whether the wildcard problem can also be solved in sublinear time? In this work, we give a quantum algorithm for pattern matching with wildcards that runs in time $\\tilde O(\\sqrt{n}\\sqrt{k})$ when the number of wildcards is bounded by $k$ for $k \\geq \\sqrt{n}$. This leads to an algorithm that runs in sublinear time as long as the number of wildcards is sublinear.",
      "authors": [
        "Masoud Seddighin and Saeed Seddighin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:02:05+00:00",
          "link": "https://arxiv.org/abs/2507.13885v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Pattern Matching with Wildcards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13885",
        "HTML": "https://arxiv.org/html/2507.13885v1",
        "PDF": "https://arxiv.org/pdf/2507.13885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a quantum algorithm for pattern matching with wildcards, which is unrelated to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13886",
      "abstract": "In this simulator study, we adopt a human-centered approach to explore whether and how drivers' cognitive state and driving environment complexity influence reliance on driving automation features. Besides, we examine whether such reliance affects driving performance. Participants operated a vehicle equipped with adaptive cruise control (ACC) in a simulator across six predefined driving scenarios varying in traffic conditions while either performing a cognitively demanding task (i.e., responding to mental calculations) or not. Throughout the experiment, participants had to respect speed limits and were free to activate or deactivate ACC. In complex driving environments, we found that the overall ACC engagement time was lower compared to less complex driving environments. We observed no significant effect of cognitive load on ACC use. Furthermore, while ACC use had no effect on the number of lane changes, it impacted the speed limits compliance and improved lateral control.",
      "authors": [
        "Ana\\\"is Halin",
        "Marc Van Droogenbroeck",
        "Christel Devue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:02:53+00:00",
          "link": "https://arxiv.org/abs/2507.13886v1",
          "size": "4519kb",
          "version": "v1"
        }
      ],
      "title": "Effects of Cognitive Distraction and Driving Environment Complexity on Adaptive Cruise Control Use and Its Impact on Driving Performance: A Simulator Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13886",
        "HTML": "https://arxiv.org/html/2507.13886v1",
        "PDF": "https://arxiv.org/pdf/2507.13886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines cognitive distraction and its impact on adaptive cruise control, focusing on driving performance rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13888",
      "abstract": "We present a novel method for designing higher-order Control Barrier Functions (CBFs) that guarantee convergence to a safe set within a user-specified finite. Traditional Higher Order CBFs (HOCBFs) ensure asymptotic safety but lack mechanisms for fixed-time convergence, which is critical in time-sensitive and safety-critical applications such as autonomous navigation. In contrast, our approach imposes a structured differential constraint using repeated roots in the characteristic polynomial, enabling closed-form polynomial solutions with exact convergence at a prescribed time. We derive conditions on the barrier function and its derivatives that ensure forward invariance and fixed-time reachability, and we provide an explicit formulation for second-order systems. Our method is evaluated on three robotic systems - a point-mass model, a unicycle, and a bicycle model and benchmarked against existing HOCBF approaches. Results demonstrate that our formulation reliably enforces convergence within the desired time, even when traditional methods fail. This work provides a tractable and robust framework for real-time control with provable finite-time safety guarantees.",
      "authors": [
        "Janani S K",
        "Shishir Kolathaya"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:05:47+00:00",
          "link": "https://arxiv.org/abs/2507.13888v1",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "title": "Fixed time convergence guarantees for Higher Order Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13888",
        "HTML": "https://arxiv.org/html/2507.13888v1",
        "PDF": "https://arxiv.org/pdf/2507.13888"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on higher-order control barrier functions for real-time control and convergence, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13889",
      "abstract": "This paper investigates the integration of active reconfigurable intelligent surfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance non-terrestrial network (NTN) performance in next-generation wireless systems. While prior studies focused on passive RIS architectures, the severe path loss and double fading in long-distance HAPS links make active RIS a more suitable alternative due to its inherent signal amplification capabilities. We formulate a sum-rate maximization problem to jointly optimize power allocation and RIS element assignment for ground user equipments (UEs) supported by a HAPS-based active RIS-assisted communication system. To reduce power consumption and hardware complexity, several sub-connected active RIS architectures are also explored. Simulation results reveal that active RIS configurations significantly outperform passive RIS in terms of quality of service (QoS). Moreover, although fully-connected architectures achieve the highest throughput, sub-connected schemes demonstrate superior energy efficiency under practical power constraints. These findings highlight the potential of active RIS-enabled HAPS systems to meet the growing demands of beyond-cellular coverage and green networking.",
      "authors": [
        "Bilal Karaman",
        "Ilhan Basturk",
        "Ferdi Kara",
        "Metin Ozturk",
        "Sezai Taskin",
        "Halil Yanikomeroglu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:06:19+00:00",
          "link": "https://arxiv.org/abs/2507.13889v1",
          "size": "1253kb",
          "version": "v1"
        }
      ],
      "title": "On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13889",
        "HTML": "https://arxiv.org/html/2507.13889v1",
        "PDF": "https://arxiv.org/pdf/2507.13889"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates HAPS and RIS technologies for non-terrestrial networks, which does not pertain to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13891",
      "abstract": "COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing attention due to its remarkable performance in reconstructing high-quality 3D scenes from unposed images or videos. However, it often struggles to handle scenes with complex camera trajectories as featured by drastic rotation and translation across adjacent camera views, leading to degraded estimation of camera poses and further local minima in joint optimization of camera poses and 3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that achieves superior 3D scene modeling and camera pose estimation via camera pose co-regularization. PCR-GS achieves regularization from two perspectives. The first is feature reprojection regularization which extracts view-robust DINO features from adjacent camera views and aligns their semantic information for camera pose regularization. The second is wavelet-based frequency regularization which exploits discrepancy in high-frequency details to further optimize the rotation matrix in camera poses. Extensive experiments over multiple real-world scenes show that the proposed PCR-GS achieves superior pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.",
      "authors": [
        "Yu Wei",
        "Jiahui Zhang",
        "Xiaoqin Zhang",
        "Ling Shao",
        "Shijian Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:09:33+00:00",
          "link": "https://arxiv.org/abs/2507.13891v1",
          "size": "6146kb",
          "version": "v1"
        }
      ],
      "title": "PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13891",
        "HTML": "https://arxiv.org/html/2507.13891v1",
        "PDF": "https://arxiv.org/pdf/2507.13891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D scene reconstruction and camera pose estimation techniques, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13892",
      "abstract": "Data engineering pipelines are a widespread way to provide high-quality data for all kinds of data science applications. However, numerous challenges still remain in the composition and operation of such pipelines. Data engineering pipelines do not always deliver high-quality data. By default, they are also not reactive to changes. When new data is coming in which deviates from prior data, the pipeline could crash or output undesired results. We therefore envision three levels of next generation data engineering pipelines: optimized data pipelines, self-aware data pipelines, and self-adapting data pipelines. Pipeline optimization addresses the composition of operators and their parametrization in order to achieve the highest possible data quality. Self-aware data engineering pipelines enable a continuous monitoring of its current state, notifying data engineers on significant changes. Self-adapting data engineering pipelines are then even able to automatically react to those changes. We propose approaches to achieve each of these levels.",
      "authors": [
        "Kevin M. Kramer",
        "Valerie Restat",
        "Sebastian Strasser",
        "Uta St\\\"orl",
        "Meike Klettke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:12:55+00:00",
          "link": "https://arxiv.org/abs/2507.13892v1",
          "size": "1114kb",
          "version": "v1"
        }
      ],
      "title": "Towards Next Generation Data Engineering Pipelines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13892",
        "HTML": "https://arxiv.org/html/2507.13892v1",
        "PDF": "https://arxiv.org/pdf/2507.13892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses data engineering pipelines; however, it does not specifically focus on training data processing for LLMs, making the contribution to LLM training data processing indirect."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13895",
      "abstract": "Novel utility computing paradigms rely upon the deployment of multi-service applications to pervasive and highly distributed cloud-edge infrastructure resources. Deciding onto which computational nodes to place services in cloud-edge networks, as per their functional and non-functional constraints, can be formulated as a combinatorial optimisation problem. Most existing solutions in this space are not able to deal with \\emph{unsatisfiable} problem instances, nor preferences, i.e. requirements that DevOps may agree to relax to obtain a solution. In this article, we exploit Answer Set Programming optimisation capabilities to tackle this problem. Experimental results in simulated settings show that our approach is effective on lifelike networks and applications.",
      "authors": [
        "Damiano Azzolini",
        "Marco Duca",
        "Stefano Forti",
        "Francesco Gallo",
        "Antonio Ielo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:20:58+00:00",
          "link": "https://arxiv.org/abs/2507.13895v1",
          "size": "1389kb",
          "version": "v1"
        }
      ],
      "title": "Application Placement with Constraint Relaxation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13895",
        "HTML": "https://arxiv.org/html/2507.13895v1",
        "PDF": "https://arxiv.org/pdf/2507.13895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses application placement in cloud-edge networks using optimization techniques, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13899",
      "abstract": "Recent advances in foundation models have opened up new possibilities for enhancing 3D perception. In particular, DepthAnything offers dense and reliable geometric priors from monocular RGB images, which can complement sparse LiDAR data in autonomous driving scenarios. However, such priors remain underutilized in LiDAR-based 3D object detection. In this paper, we address the limited expressiveness of raw LiDAR point features, especially the weak discriminative capability of the reflectance attribute, by introducing depth priors predicted by DepthAnything. These priors are fused with the original LiDAR attributes to enrich each point's representation. To leverage the enhanced point features, we propose a point-wise feature extraction module. Then, a Dual-Path RoI feature extraction framework is employed, comprising a voxel-based branch for global semantic context and a point-based branch for fine-grained structural details. To effectively integrate the complementary RoI features, we introduce a bidirectional gated RoI feature fusion module that balances global and local cues. Extensive experiments on the KITTI benchmark show that our method consistently improves detection accuracy, demonstrating the value of incorporating visual foundation model priors into LiDAR-based 3D object detection.",
      "authors": [
        "Yujian Mo and Yan Wu and Junqiao Zhao and Jijun Wang and Yinghao Hu and Jun Yan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:24:32+00:00",
          "link": "https://arxiv.org/abs/2507.13899v1",
          "size": "1389kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13899",
        "HTML": "https://arxiv.org/html/2507.13899v1",
        "PDF": "https://arxiv.org/pdf/2507.13899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on enhancing LiDAR point features for 3D object detection using foundation model priors, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13902",
      "abstract": "We propose a learned precomputation for the heterogeneous multiscale method (HMM) for rough-wall Stokes flow. A Fourier neural operator is used to approximate local averages over microscopic subsets of the flow, which allows to compute an effective slip length of the fluid away from the roughness. The network is designed to map from the local wall geometry to the Riesz representors for the corresponding local flow averages. With such a parameterisation, the network only depends on the local wall geometry and as such can be trained independent of boundary conditions. We perform a detailed theoretical analysis of the statistical error propagation, and prove that under suitable regularity and scaling assumptions, a bounded training loss leads to a bounded error in the resulting macroscopic flow. We then demonstrate on a family of test problems that the learned precomputation performs stably with respect to the scale of the roughness. The accuracy in the HMM solution for the macroscopic flow is comparable to when the local (micro) problems are solved using a classical approach, while the computational cost of solving the micro problems is significantly reduced.",
      "authors": [
        "Emanuel Str\\\"om",
        "Anna-Karin Tornberg and Ozan \\\"Oktem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:29:24+00:00",
          "link": "https://arxiv.org/abs/2507.13902v1",
          "size": "20510kb",
          "version": "v1"
        }
      ],
      "title": "Deep Micro Solvers for Rough-Wall Stokes Flow in a Heterogeneous Multiscale Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13902",
        "HTML": "https://arxiv.org/html/2507.13902v1",
        "PDF": "https://arxiv.org/pdf/2507.13902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using a Fourier neural operator for precomputation in rough-wall Stokes flow, which is unrelated to LLM training data processing or any data engineering operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13903",
      "abstract": "Autonomous aerial systems play an increasingly vital role in a wide range of applications, particularly for transport and delivery tasks in complex environments. In airdrop missions, these platforms face the dual challenges of abrupt control mode switching and inherent system delays along with control errors. To address these issues, this paper presents an autonomous airdrop system based on an aerial manipulator (AM). The introduction of additional actuated degrees of freedom enables active compensation for UAV tracking errors. By imposing smooth and continuous constraints on the parabolic landing point, the proposed approach generates aerial throwing trajectories that are less sensitive to the timing of payload release. A hierarchical disturbance compensation strategy is incorporated into the Nonlinear Model Predictive Control (NMPC) framework to mitigate the effects of sudden changes in system parameters, while the predictive capabilities of NMPC are further exploited to improve the precision of aerial throwing. Both simulation and real-world experimental results demonstrate that the proposed system achieves greater agility and precision in airdrop missions.",
      "authors": [
        "Ziliang Li",
        "Hongming Chen",
        "Yiyang Lin",
        "Biyu Ye",
        "Ximin Lyu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:32:17+00:00",
          "link": "https://arxiv.org/abs/2507.13903v1",
          "size": "7989kb",
          "version": "v1"
        }
      ],
      "title": "AeroThrow: An Autonomous Aerial Throwing System for Precise Payload Delivery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13903",
        "HTML": "https://arxiv.org/html/2507.13903v1",
        "PDF": "https://arxiv.org/pdf/2507.13903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an autonomous airdrop system and control errors, which are not related to LLM training data processing or data quality improvement for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13908",
      "abstract": "This paper presents a novel approach for robust periodic attitude control of satellites. Respecting the periodicity of the satellite dynamics in the synthesis allows to achieve constant performance and robustness requirements over the orbit. The proposed design follows a mixed sensitivity control design employing a physically motivated weighting scheme. The controller is calculated using a novel structured linear time-periodic output feedback synthesis with guaranteed optimal L2-performance. The synthesis poses a convex optimization problem and avoids grid-wise evaluations of coupling conditions inherent for classical periodic H-infinity-synthesis. Moreover, the controller has a transparent and easy to implement structure. A solar power plant satellite is used to demonstrate the effectiveness of the proposed method for periodic satellite attitude control.",
      "authors": [
        "Frederik Thiele",
        "Felix Biert\\\"umpfel and Harald Pfifer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:37:47+00:00",
          "link": "https://arxiv.org/abs/2507.13908v1",
          "size": "738kb",
          "version": "v1"
        }
      ],
      "title": "A Robust Periodic Controller for Spacecraft Attitude Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13908",
        "PDF": "https://arxiv.org/pdf/2507.13908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a controller for spacecraft attitude tracking and does not contribute to any aspect of LLM training data processing, such as data collection or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13910",
      "abstract": "Academic Search is a search task aimed to manage and retrieve scientific documents like journal articles and conference papers. Personalization in this context meets individual researchers' needs by leveraging, through user profiles, the user related information (e.g. documents authored by a researcher), to improve search effectiveness and to reduce the information overload. While citation graphs are a valuable means to support the outcome of recommender systems, their use in personalized academic search (with, e.g. nodes as papers and edges as citations) is still under-explored.\n  Existing personalized models for academic search often struggle to fully capture users' academic interests. To address this, we propose a two-step approach: first, training a neural language model for retrieval, then converting the academic graph into a knowledge graph and embedding it into a shared semantic space with the language model using translational embedding techniques. This allows user models to capture both explicit relationships and hidden structures in citation graphs and paper content. We evaluate our approach in four academic search domains, outperforming traditional graph-based and personalized models in three out of four, with up to a 10\\% improvement in MAP@100 over the second-best model. This highlights the potential of knowledge graph-based user models to enhance retrieval effectiveness.",
      "authors": [
        "Pranav Kasela",
        "Gabriella Pasi",
        "Raffaele Perego"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:41:01+00:00",
          "link": "https://arxiv.org/abs/2507.13910v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "PARK: Personalized academic retrieval with knowledge-graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13910",
        "HTML": "https://arxiv.org/html/2507.13910v1",
        "PDF": "https://arxiv.org/pdf/2507.13910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the enhancement of retrieval effectiveness for academic search using knowledge-graphs and LLM. Although it involves a neural language model, it does not focus specifically on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13912",
      "abstract": "Predicting phenotypes from gene expression data is a crucial task in biomedical research, enabling insights into disease mechanisms, drug responses, and personalized medicine. Traditional machine learning and deep learning rely on supervised learning, which requires large quantities of labeled data that are costly and time-consuming to obtain in the case of gene expression data. Self-supervised learning has recently emerged as a promising approach to overcome these limitations by extracting information directly from the structure of unlabeled data. In this study, we investigate the application of state-of-the-art self-supervised learning methods to bulk gene expression data for phenotype prediction. We selected three self-supervised methods, based on different approaches, to assess their ability to exploit the inherent structure of the data and to generate qualitative representations which can be used for downstream predictive tasks. By using several publicly available gene expression datasets, we demonstrate how the selected methods can effectively capture complex information and improve phenotype prediction accuracy. The results obtained show that self-supervised learning methods can outperform traditional supervised models besides offering significant advantage by reducing the dependency on annotated data. We provide a comprehensive analysis of the performance of each method by highlighting their strengths and limitations. We also provide recommendations for using these methods depending on the case under study. Finally, we outline future research directions to enhance the application of self-supervised learning in the field of gene expression data analysis. This study is the first work that deals with bulk RNA-Seq data and self-supervised learning.",
      "authors": [
        "Kevin Dradjat and Massinissa Hamidi and Pierre Bartet and Blaise Hanczar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:43:04+00:00",
          "link": "https://arxiv.org/abs/2507.13912v1",
          "size": "3585kb",
          "version": "v1"
        }
      ],
      "title": "Self-supervised learning on gene expression data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13912",
        "HTML": "https://arxiv.org/html/2507.13912v1",
        "PDF": "https://arxiv.org/pdf/2507.13912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is self-supervised learning methods on gene expression data, which is unrelated to LLM training data processing or improvements in data quality for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13913",
      "abstract": "This paper addresses the challenge of automatically classifying text according to political leaning and politicalness using transformer models. We compose a comprehensive overview of existing datasets and models for these tasks, finding that current approaches create siloed solutions that perform poorly on out-of-distribution texts. To address this limitation, we compile a diverse dataset by combining 12 datasets for political leaning classification and creating a new dataset for politicalness by extending 18 existing datasets with the appropriate label. Through extensive benchmarking with leave-one-in and leave-one-out methodologies, we evaluate the performance of existing models and train new ones with enhanced generalization capabilities.",
      "authors": [
        "Matous Volf (1)",
        "Jakub Simko (2) ((1) DELTA High school of computer science and economics",
        "Pardubice",
        "Czechia",
        "(2) Kempelen Institute of Intelligent Technologies",
        "Bratislava",
        "Slovakia)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:44:30+00:00",
          "link": "https://arxiv.org/abs/2507.13913v1",
          "size": "9608kb",
          "version": "v1"
        }
      ],
      "title": "Political Leaning and Politicalness Classification of Texts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13913",
        "HTML": "https://arxiv.org/html/2507.13913v1",
        "PDF": "https://arxiv.org/pdf/2507.13913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses compiling and evaluating political leaning datasets, which involves data processing activities such as dataset composition and augmentation. However, the primary focus is on political classification models rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13917",
      "abstract": "This paper presents Neural-GASh, a novel real-time shading pipeline for 3D meshes, that leverages a neural radiance field architecture to perform image-based rendering (IBR) using Conformal Geometric Algebra (CGA)-encoded vertex information as input. Unlike traditional Precomputed Radiance Transfer (PRT) methods, that require expensive offline precomputations, our learned model directly consumes CGA-based representations of vertex positions and normals, enabling dynamic scene shading without precomputation. Integrated seamlessly into the Unity engine, Neural-GASh facilitates accurate shading of animated and deformed 3D meshes - capabilities essential for dynamic, interactive environments. The shading of the scene is implemented within Unity, where rotation of scene lights in terms of Spherical Harmonics is also performed optimally using CGA. This neural field approach is designed to deliver fast and efficient light transport simulation across diverse platforms, including mobile and VR, while preserving high rendering quality. Additionally, we evaluate our method on scenes generated via 3D Gaussian splats, further demonstrating the flexibility and robustness of Neural-GASh in diverse scenarios. Performance is evaluated in comparison to conventional PRT, demonstrating competitive rendering speeds even with complex geometries.",
      "authors": [
        "Efstratios Geronikolakis",
        "Manos Kamarianakis",
        "Antonis Protopsaltis",
        "George Papagiannakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:48:06+00:00",
          "link": "https://arxiv.org/abs/2507.13917v1",
          "size": "30658kb",
          "version": "v1"
        }
      ],
      "title": "Neural-GASh: A CGA-based neural radiance prediction pipeline for real-time shading",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13917",
        "HTML": "https://arxiv.org/html/2507.13917v1",
        "PDF": "https://arxiv.org/pdf/2507.13917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a real-time shading pipeline for 3D meshes using a neural radiance prediction pipeline, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13919",
      "abstract": "There are widespread fears that conversational AI could soon exert unprecedented influence over human beliefs. Here, in three large-scale experiments (N=76,977), we deployed 19 LLMs-including some post-trained explicitly for persuasion-to evaluate their persuasiveness on 707 political issues. We then checked the factual accuracy of 466,769 resulting LLM claims. Contrary to popular concerns, we show that the persuasive power of current and near-future AI is likely to stem more from post-training and prompting methods-which boosted persuasiveness by as much as 51% and 27% respectively-than from personalization or increasing model scale. We further show that these methods increased persuasion by exploiting LLMs' unique ability to rapidly access and strategically deploy information and that, strikingly, where they increased AI persuasiveness they also systematically decreased factual accuracy.",
      "authors": [
        "Kobi Hackenburg",
        "Ben M. Tappin",
        "Luke Hewitt",
        "Ed Saunders",
        "Sid Black",
        "Hause Lin",
        "Catherine Fist",
        "Helen Margetts",
        "David G. Rand",
        "Christopher Summerfield"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:50:09+00:00",
          "link": "https://arxiv.org/abs/2507.13919v1",
          "size": "2455kb",
          "version": "v1"
        }
      ],
      "title": "The Levers of Political Persuasion with Conversational AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13919",
        "HTML": "https://arxiv.org/html/2507.13919v1",
        "PDF": "https://arxiv.org/pdf/2507.13919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves experiments with LLMs post-trained for persuasion, discussing methods that improve AI persuasiveness. However, it primarily deals with persuasion and evaluation rather than the direct processing of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13920",
      "abstract": "Formal frameworks of causality have operated largely parallel to modern trends in deep reinforcement learning (RL). However, there has been a revival of interest in formally grounding the representations learned by neural networks in causal concepts. Yet, most attempts at neural models of causality assume static causal graphs and ignore the dynamic nature of causal interactions. In this work, we introduce Causal Process framework as a novel theory for representing dynamic hypotheses about causal structure. Furthermore, we present Causal Process Model as an implementation of this framework. This allows us to reformulate the attention mechanism popularized by Transformer networks within an RL setting with the goal to infer interpretable causal processes from visual observations. Here, causal inference corresponds to constructing a causal graph hypothesis which itself becomes an RL task nested within the original RL problem. To create an instance of such hypothesis, we employ RL agents. These agents establish links between units similar to the original Transformer attention mechanism. We demonstrate the effectiveness of our approach in an RL environment where we outperform current alternatives in causal representation learning and agent performance, and uniquely recover graphs of dynamic causal processes.",
      "authors": [
        "Turan Orujlu",
        "Christian Gumbsch",
        "Martin V. Butz",
        "Charley M Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:50:57+00:00",
          "link": "https://arxiv.org/abs/2507.13920v1",
          "size": "2688kb",
          "version": "v1"
        }
      ],
      "title": "Reframing attention as a reinforcement learning problem for causal discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13920",
        "HTML": "https://arxiv.org/html/2507.13920v1",
        "PDF": "https://arxiv.org/pdf/2507.13920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a causal inference framework reformulating attention as an RL problem, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13923",
      "abstract": "The science of Human-Computer Interaction (HCI) is populated by isolated empirical findings, often tied to specific technologies, designs, and tasks. This paper proposes a formalization of user interaction observations (instead of user interfaces) and an associated revealing method (interaction loop diffraction). The resulting interactional properties that are studied in a calibrated manner, are well suited to replication across various conditions (prototypes, technologies, tasks, and user profiles). In particular, interactional properties can emerge and be replicated within the workflow of applicative cases, which in return benefit from the optimization of applicative prototypes. Applicative cases' publications will then contribute to demonstrating technology utility, along with providing empirical results that will lead future work to theory consolidation and theory building, and finally to a catalog and a science of relevant interactional properties. These properties will contribute to better user interactions, especially for the variety of ubiquitous user interfaces.",
      "authors": [
        "Guillaume Rivi\\`ere"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:58:30+00:00",
          "link": "https://arxiv.org/abs/2507.13923v1",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "title": "Initiating and Replicating the Observations of Interactional Properties by User Studies Optimizing Applicative Prototypes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13923",
        "HTML": "https://arxiv.org/html/2507.13923v1",
        "PDF": "https://arxiv.org/pdf/2507.13923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on user interaction observations, particularly within Human-Computer Interaction (HCI), and discusses interactional properties and user interfaces rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13926",
      "abstract": "Webextensions can improve web browser privacy, security, and user experience. The APIs offered by the browser to webextensions affect possible functionality. Currently, Chrome transitions to a modified set of APIs called Manifest v3. This paper studies the challenges and opportunities of Manifest v3 with an in-depth structured qualitative research. Even though some projects observed positive effects, a majority expresses concerns over limited benefits to users, removal of crucial APIs, or the need to find workarounds. Our findings indicate that the transition affects different types of webextensions differently; some can migrate without losing functionality, while other projects remove functionality or decline to update. The respondents identified several critical missing APIs, including reliable APIs to inject content scripts, APIs for storing confidential content, and others.",
      "authors": [
        "Libor Pol\\v{c}\\'ak",
        "Giorgio Maone",
        "Michael McMahon",
        "Martin Bedn\\'a\\v{r}"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:00:16+00:00",
          "link": "https://arxiv.org/abs/2507.13926v1",
          "size": "204kb",
          "version": "v1"
        }
      ],
      "title": "Developers Insight On Manifest v3 Privacy and Security Webextensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13926",
        "HTML": "https://arxiv.org/html/2507.13926v1",
        "PDF": "https://arxiv.org/pdf/2507.13926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies the impact of Manifest v3 on webextensions, focusing on privacy, security, and API changes in web browsers, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13929",
      "abstract": "We present TimeNeRF, a generalizable neural rendering approach for rendering novel views at arbitrary viewpoints and at arbitrary times, even with few input views. For real-world applications, it is expensive to collect multiple views and inefficient to re-optimize for unseen scenes. Moreover, as the digital realm, particularly the metaverse, strives for increasingly immersive experiences, the ability to model 3D environments that naturally transition between day and night becomes paramount. While current techniques based on Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing novel views, the exploration of NeRF's potential for temporal 3D scene modeling remains limited, with no dedicated datasets available for this purpose. To this end, our approach harnesses the strengths of multi-view stereo, neural radiance fields, and disentanglement strategies across diverse datasets. This equips our model with the capability for generalizability in a few-shot setting, allows us to construct an implicit content radiance field for scene representation, and further enables the building of neural radiance fields at any arbitrary time. Finally, we synthesize novel views of that time via volume rendering. Experiments show that TimeNeRF can render novel views in a few-shot setting without per-scene optimization. Most notably, it excels in creating realistic novel views that transition smoothly across different times, adeptly capturing intricate natural scene changes from dawn to dusk.",
      "authors": [
        "Hsiang-Hui Hung",
        "Huu-Phu Do",
        "Yung-Hui Li",
        "Ching-Chun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:07:02+00:00",
          "link": "https://arxiv.org/abs/2507.13929v1",
          "size": "19338kb",
          "version": "v1"
        }
      ],
      "title": "TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13929",
        "HTML": "https://arxiv.org/html/2507.13929v1",
        "PDF": "https://arxiv.org/pdf/2507.13929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses TimeNeRF, a method for rendering novel views using neural radiance fields, focusing on rendering and 3D scene modeling, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13931",
      "abstract": "This contribution presents a parameter identification methodology for the accurate and fast estimation of model parameters in a pseudo-two-dimensional (P2D) battery model. The methodology consists of three key elements. First, the data for identification is inspected and specific features herein that need to be captured are included in the model. Second, the P2D model is analyzed to assess the identifiability of the physical model parameters and propose alternative parameterizations that alleviate possible issues. Finally, diverse operating conditions are considered that excite distinct battery dynamics which allows the use of different low-order battery models accordingly. Results show that, under low current conditions, the use of low-order models achieve parameter estimates at least 500 times faster than using the P2D model at the expense of twice the error. However, if accuracy is a must, these estimated parameters can be used to initialize the P2D model and perform the identification in half of the time.",
      "authors": [
        "L.D. Couto",
        "K. Haghverdi",
        "F. Guo",
        "K. Trad",
        "G. Mulder"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:07:22+00:00",
          "link": "https://arxiv.org/abs/2507.13931v1",
          "size": "256kb",
          "version": "v1"
        }
      ],
      "title": "Identifiability Analysis of a Pseudo-Two-Dimensional Model & Single Particle Model-Aided Parameter Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13931",
        "HTML": "https://arxiv.org/html/2507.13931v1",
        "PDF": "https://arxiv.org/pdf/2507.13931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research centers on parameter estimation in battery models, specifically a pseudo-two-dimensional battery model, which does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13932",
      "abstract": "The rise of blockchain and Digital Ledger Technology (DLT) has gained wide traction. Instead of relying on a traditional centralized data authority, a blockchain system consists of digitally entangled block data shared across a distributed network. The specially designed chain data structure and its consensus mechanism protect blockchain data from being tampered by unauthorized adversaries. However, implementing a full-fledged blockchain system to protect a database can be technically cumbersome. In this work, we introduce an in-database design, named chain table, to protect data integrity without the need for a blockchain system. It features a succinct design without significant technology barriers or storage overhead. To realize rigorous data security, we also propose a set of data writing principles for the chain table. We prove that the chain table, together with the data writing principles, will guarantee flexible data integrity, named table-level data integrity (TDI).",
      "authors": [
        "Feng Yu",
        "Ryan Laird"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:08:24+00:00",
          "link": "https://arxiv.org/abs/2507.13932v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "Chain Table: Protecting Table-Level Data Integrity by Digital Ledger Technology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13932",
        "PDF": "https://arxiv.org/pdf/2507.13932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a chain table for data integrity in databases using digital ledger technology. It does not address any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13933",
      "abstract": "Increasingly, web content is automatically generated by large language models (LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs plagiarize and hallucinate, LLM-dominant content can be unreliable and unethical. Yet, websites rarely disclose such content, and human readers struggle to distinguish it. Thus, we must develop reliable detectors for LLM-dominant content. However, state-of-the-art LLM detectors are insufficient, because they perform well mainly on clean, prose-like text, while web content has complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire websites. Instead of naively classifying text extracted from each page, we classify each site based on an LLM text detector's outputs of multiple prose-like pages. We train and evaluate our detector by collecting 2 distinct ground truth datasets totaling 120 sites, and obtain 100% accuracies testing across them. In the wild, we detect a sizable portion of sites as LLM-dominant among 10k sites in search engine results and 10k in Common Crawl archives. We find LLM-dominant sites are growing in prevalence and rank highly in search results, raising questions about their impact on end users and the overall Web ecosystem.",
      "authors": [
        "Sichang \"Steven\" He and Ramesh Govindan and Harsha V. Madhyastha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:09:04+00:00",
          "link": "https://arxiv.org/abs/2507.13933v1",
          "size": "491kb",
          "version": "v1"
        }
      ],
      "title": "Preprint: Did I Just Browse A Website Written by LLMs?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13933",
        "HTML": "https://arxiv.org/html/2507.13933v1",
        "PDF": "https://arxiv.org/pdf/2507.13933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on detecting LLM-generated web content and developing detectors for it. This does not relate to LLM training data processing, as it does not involve data collection, filtering, or dataset creation for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13934",
      "abstract": "Unsupervised disentanglement of static appearance and dynamic motion in video remains a fundamental challenge, often hindered by information leakage and blurry reconstructions in existing VAE- and GAN-based approaches. We introduce DiViD, the first end-to-end video diffusion framework for explicit static-dynamic factorization. DiViD's sequence encoder extracts a global static token from the first frame and per-frame dynamic tokens, explicitly removing static content from the motion code. Its conditional DDPM decoder incorporates three key inductive biases: a shared-noise schedule for temporal consistency, a time-varying KL-based bottleneck that tightens at early timesteps (compressing static information) and relaxes later (enriching dynamics), and cross-attention that routes the global static token to all frames while keeping dynamic tokens frame-specific. An orthogonality regularizer further prevents residual static-dynamic leakage. We evaluate DiViD on real-world benchmarks using swap-based accuracy and cross-leakage metrics. DiViD outperforms state-of-the-art sequential disentanglement methods: it achieves the highest swap-based joint accuracy, preserves static fidelity while improving dynamic transfer, and reduces average cross-leakage.",
      "authors": [
        "Marzieh Gheisari",
        "Auguste Genovesio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:09:18+00:00",
          "link": "https://arxiv.org/abs/2507.13934v1",
          "size": "2211kb",
          "version": "v1"
        }
      ],
      "title": "DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13934",
        "HTML": "https://arxiv.org/html/2507.13934v1",
        "PDF": "https://arxiv.org/pdf/2507.13934"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses disentangling static and dynamic factors in video data, which is not related to training data processing for large language models. It focuses on improving video processing techniques rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13936",
      "abstract": "Over 90% of new vehicles in the United States now collect and transmit telematics data. Similar trends are seen in other developed countries. Transportation planners have previously utilized telematics data in various forms, but its current scale offers significant new opportunities in traffic measurement, classification, planning, and control. Despite these opportunities, the enormous volume of data and lack of standardization across manufacturers necessitates a clearer understanding of the data and improved data processing methods for extracting actionable insights.\n  This paper takes a step towards addressing these needs through four primary objectives. First, a data processing pipeline was built to efficiently analyze 1.4 billion miles (120 million trips) of telematics data collected in Virginia between August 2021 and August 2022. Second, an open data repository of trip and roadway segment level summaries was created. Third, interactive visualization tools were designed to extract insights from these data about trip-taking behavior and the speed profiles of roadways. Finally, major challenges that were faced during processing this data are summarized and recommendations to overcome them are provided. This work will help manufacturers collecting the data and transportation professionals using the data to develop a better understanding of the possibilities and major pitfalls to avoid.",
      "authors": [
        "Gibran Ali",
        "Neal Feierabend",
        "Prarthana Doshi",
        "Calvin Winkowski",
        "Michael Fontaine"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:09:40+00:00",
          "link": "https://arxiv.org/abs/2507.13936v1",
          "size": "25067kb",
          "version": "v1"
        }
      ],
      "title": "Extracting Insights from Large-Scale Telematics Data for ITS Applications: Lessons and Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13936",
        "HTML": "https://arxiv.org/html/2507.13936v1",
        "PDF": "https://arxiv.org/pdf/2507.13936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores telematics data processing for intelligent transportation systems. It does not pertain to LLM training data processing, as it is not involved in operations like data collection or filtering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13937",
      "abstract": "We present Marcel, a lightweight and open-source conversational agent designed to support prospective students with admission-related inquiries. The system aims to provide fast and personalized responses, while reducing workload of university staff. We employ retrieval-augmented generation to ground answers in university resources and to provide users with verifiable, contextually relevant information. To improve retrieval quality, we introduce an FAQ retriever that maps user questions to knowledge-base entries, allowing administrators to steer retrieval, and improving over standard dense/hybrid retrieval strategies. The system is engineered for easy deployment in resource-constrained academic settings. We detail the system architecture, provide a technical evaluation of its components, and report insights from a real-world deployment.",
      "authors": [
        "Jan Trienes",
        "Anastasiia Derzhanskaia",
        "Roland Schwarzkopf",
        "Markus M\\\"uhling",
        "J\\\"org Schl\\\"otterer",
        "Christin Seifert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:09:45+00:00",
          "link": "https://arxiv.org/abs/2507.13937v1",
          "size": "690kb",
          "version": "v1"
        }
      ],
      "title": "Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13937",
        "PDF": "https://arxiv.org/pdf/2507.13937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Marcel, a conversational agent employing retrieval-augmented generation by using an FAQ retriever to improve response quality. While it involves some data processing for retrieval, the focus is not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13939",
      "abstract": "Transportation researchers and planners utilize a wide range of roadway metrics that are usually associated with different basemaps. Conflation is an important process for transferring these metrics onto a single basemap. However, conflation is often an expensive and time-consuming process based on proprietary algorithms that require manual verification.\n  In this paper, an automated open-source process is used to conflate two basemaps: the linear reference system (LRS) basemap produced by the Virginia Department of Transportation and the OpenStreetMap (OSM) basemap for Virginia. This process loads one LRS route at a time, determines the correct direction of travel, interpolates to fill gaps larger than 12 meters, and then uses Valhalla's map-matching algorithm to find the corresponding points along OSM's segments. Valhalla's map-matching process uses a Hidden Markov Model (HMM) and Viterbi search-based approach to find the most likely OSM segments matching the LRS route.\n  This work has three key contributions. First, it conflates the Virginia roadway network LRS map with OSM using an automated conflation method based on HMM and Viterbi search. Second, it demonstrates a novel open-source processing pipeline that could be replicated without the need for proprietary licenses. Finally, the overall conflation process yields over 98% successful matches, which is an improvement over most automated processes currently available for this type of conflation.",
      "authors": [
        "Gibran Ali",
        "Neal Feierabend",
        "Prarthana Doshi",
        "Whoibin Chung",
        "Simona Babiceanu",
        "Michael Fontaine"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:12:41+00:00",
          "link": "https://arxiv.org/abs/2507.13939v1",
          "size": "7395kb",
          "version": "v1"
        }
      ],
      "title": "Automated Route-based Conflation Between Linear Referencing System Maps And OpenStreetMap Using Open-source Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13939",
        "HTML": "https://arxiv.org/html/2507.13939v1",
        "PDF": "https://arxiv.org/pdf/2507.13939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method for conflating maps using open source tools, specifically in transportation networks, and does not relate to LLM training data processing or techniques related to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13940",
      "abstract": "Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in robotics. Despite substantial advancements, existing methods often face a dilemma. Decentralized algorithms typically rely on predicting the behavior of other agents, sharing contracts, or maintaining communication for safety, while centralized approaches struggle with scalability and real-time decision-making. To address these challenges, we introduce Neural Hamilton-Jacobi Reachability Learning (HJR) for Decentralized Multi-Agent Motion Planning. Our method provides scalable neural HJR modeling to tackle high-dimensional configuration spaces and capture worst-case collision and safety constraints between agents. We further propose a decentralized trajectory optimization framework that incorporates the learned HJR solutions to solve MAMP tasks in real-time. We demonstrate that our method is both scalable and data-efficient, enabling the solution of MAMP problems in higher-dimensional scenarios with complex collision constraints. Our approach generalizes across various dynamical systems, including a 12-dimensional dual-arm setup, and outperforms a range of state-of-the-art techniques in successfully addressing challenging MAMP tasks. Video demonstrations are available at https://youtu.be/IZiePX0p1Mc.",
      "authors": [
        "Qingyi Chen and Ahmed H. Qureshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:12:56+00:00",
          "link": "https://arxiv.org/abs/2507.13940v1",
          "size": "8203kb",
          "version": "v1"
        }
      ],
      "title": "NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13940",
        "HTML": "https://arxiv.org/html/2507.13940v1",
        "PDF": "https://arxiv.org/pdf/2507.13940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses safe multi-agent motion planning in robotics using neural Hamilton-Jacobi Reachability learning, which is not pertinent to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13942",
      "abstract": "Forecasting what will happen next is a critical skill for general-purpose systems that plan or act in the world at different levels of abstraction. In this paper, we identify a strong correlation between a vision model's perceptual ability and its generalist forecasting performance over short time horizons. This trend holds across a diverse set of pretrained models-including those trained generatively-and across multiple levels of abstraction, from raw pixels to depth, point tracks, and object motion. The result is made possible by a novel generalist forecasting framework that operates on any frozen vision backbone: we train latent diffusion models to forecast future features in the frozen representation space, which are then decoded via lightweight, task-specific readouts. To enable consistent evaluation across tasks, we introduce distributional metrics that compare distributional properties directly in the space of downstream tasks and apply this framework to nine models and four tasks. Our results highlight the value of bridging representation learning and generative modeling for temporally grounded video understanding.",
      "authors": [
        "Jacob C Walker",
        "Pedro V\\'elez",
        "Luisa Polania Cabrera",
        "Guangyao Zhou",
        "Rishabh Kabra",
        "Carl Doersch",
        "Maks Ovsjanikov",
        "Jo\\~ao Carreira",
        "Shiry Ginosar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:14:19+00:00",
          "link": "https://arxiv.org/abs/2507.13942v1",
          "size": "7199kb",
          "version": "v1"
        }
      ],
      "title": "Generalist Forecasting with Frozen Video Models via Latent Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13942",
        "HTML": "https://arxiv.org/html/2507.13942v1",
        "PDF": "https://arxiv.org/pdf/2507.13942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses forecasting with video models using latent diffusion, without addressing any aspect of LLM training data processing operations or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13946",
      "abstract": "Propositional inquisitive logic is the limit of its $n$-bounded approximations. In the predicate setting, however, this does not hold anymore, as discovered by Ciardelli and Grilletti, who also found complete axiomatizations of $n$-bounded inquisitive logics $\\mathsf{InqBQ}_{n}$, for every fixed $n$. We introduce cut-free labelled sequent calculi for these logics. We illustrate the intricacies of \\textit{schematic validity} in such systems by showing that the well-known Casari formula is \\textit{atomically} valid in (a weak sublogic of) predicate inquisitive logic $\\mathsf{InqBQ}$, fails to be schematically valid in it, and yet is schematically valid under the finite boundedness assumption. The derivations in our calculi, however, are guaranteed to be schematically valid whenever a single specific rule is not used.",
      "authors": [
        "Tadeusz Litak",
        "Katsuhiko Sano"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:16:21+00:00",
          "link": "https://arxiv.org/abs/2507.13946v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Bounded Inquisitive Logics: Sequent Calculi and Schematic Validity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13946",
        "HTML": "https://arxiv.org/html/2507.13946v1",
        "PDF": "https://arxiv.org/pdf/2507.13946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work is centered on logical calculi, specifically focusing on propositional inquisitive logic, which is unrelated to LLM training data processing methods or application."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13949",
      "abstract": "Large Language Models (LLMs) have become essential in many Natural Language Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to achieve high accuracy. However, like humans, LLMs exhibit biases, particularly positional biases such as primacy and recency effects, which can influence the accuracy of the answers. The primacy effect-where items presented first are more likely to be remembered or selected-plays a key role in Multiple Choice Question Answering (MCQA), where the order of answer options can affect prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We first show that fine-tuning amplifies this bias, probably due to exposure to human-like patterns. Hence, we strategically leverage this effect by reordering response options based on semantic similarity to the query, without requiring knowledge of the correct answer. Our experimental results show that this approach significantly improves performance in MCQA. More generally, our findings underscore the dual nature of biases as both challenges and opportunities, offering insights for bias-aware model design and NLP applications.",
      "authors": [
        "Bianca Raimondi",
        "Maurizio Gabbrielli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:18:18+00:00",
          "link": "https://arxiv.org/abs/2507.13949v1",
          "size": "456kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Primacy Effect To Improve Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13949",
        "HTML": "https://arxiv.org/html/2507.13949v1",
        "PDF": "https://arxiv.org/pdf/2507.13949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper focuses on leveraging primacy bias to improve model performance in multiple choice question answering. It discusses fine-tuning approaches to enhance model accuracy, but the main contribution is not centered on data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13950",
      "abstract": "Extensively exploring protein conformational landscapes remains a major challenge in computational biology due to the high computational cost involved in dynamic physics-based simulations. In this work, we propose a novel pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and generative adversarial networks (GANs) to explore protein conformational spaces. MoDyGAN contains a generator that maps Gaussian distributions into MD-derived protein trajectories, and a refinement module that combines ensemble learning with a dual-discriminator to further improve the plausibility of generated conformations. Central to our approach is an innovative representation technique that reversibly transforms 3D protein structures into 2D matrices, enabling the use of advanced image-based GAN architectures. We use three rigid proteins to demonstrate that MoDyGAN can generate plausible new conformations. We also use deca-alanine as a case study to show that interpolations within the latent space closely align with trajectories obtained from steered molecular dynamics (SMD) simulations. Our results suggest that representing proteins as image-like data unlocks new possibilities for applying advanced deep learning techniques to biomolecular simulation, leading to an efficient sampling of conformational states. Additionally, the proposed framework holds strong potential for extension to other complex 3D structures.",
      "authors": [
        "Jingbo Liang and Bruna Jacobson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biological Physics (physics.bio-ph)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:18:28+00:00",
          "link": "https://arxiv.org/abs/2507.13950v1",
          "size": "10136kb",
          "version": "v1"
        }
      ],
      "title": "MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13950",
        "PDF": "https://arxiv.org/pdf/2507.13950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents MoDyGAN, a methodology for exploring protein conformational spaces using GANs and molecular dynamics. It is centered on computational biology and protein modeling, rather than LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13951",
      "abstract": "Game modding offers unique and personalized gaming experiences, but the technical complexity of creating mods often limits participation to skilled users. We envision a future where every player can create personalized mods for their games. To explore this space, we designed StarCharM, a GenAI-based non-player character (NPC) creator for Stardew Valley. Our tool enables players to iteratively create new NPC mods, requiring minimal user input while allowing for fine-grained adjustments through user control. We conducted a user study with ten Stardew Valley players who had varied mod usage experiences to understand the impacts of StarCharM and provide insights into how GenAI tools may reshape modding, particularly in NPC creation. Participants expressed excitement in bringing their character ideas to life, although they noted challenges in generating rich content to fulfill complex visions. While they believed GenAI tools like StarCharM can foster a more diverse modding community, some voiced concerns about diminished originality and community engagement that may come with such technology. Our findings provided implications and guidelines for the future of GenAI-powered modding tools and co-creative modding practices.",
      "authors": [
        "Hamid Zand Miralvand",
        "Mohammad Ronagh Nikghalb",
        "Mohammad Darandeh",
        "Abidullah Khan",
        "Ian Arawjo",
        "Jinghui Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:20:47+00:00",
          "link": "https://arxiv.org/abs/2507.13951v1",
          "size": "778kb",
          "version": "v1"
        }
      ],
      "title": "Democratizing Game Modding with GenAI: A Case Study of StarCharM, a Stardew Valley Character Maker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13951",
        "HTML": "https://arxiv.org/html/2507.13951v1",
        "PDF": "https://arxiv.org/pdf/2507.13951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes the development of a GenAI-based tool for game modding, focusing on creating NPCs for Stardew Valley. It does not address pretraining or fine-tuning data processing relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13952",
      "abstract": "The estimation of cognitive effort could potentially help educators to modify material to enhance learning effectiveness and student engagement. Where cognitive load refers how much work the brain is doing while someone is learning or doing a task cognitive effort consider both load and behavioral performance. Cognitive effort can be captured by measuring oxygen flow and behavioral performance during a task. This study infers cognitive effort metrics using machine learning models based on oxygenated hemoglobin collected by using functional near-infrared spectroscopy from the prefrontal cortex during an educational gameplay. In our study, sixteen participants responded to sixteen questions in an in-house Unity-based educational game. The quiz was divided into two sessions, each session consisting of two task segments. We extracted temporal statistical and functional connectivity features from collected oxygenated hemoglobin and analyzed their correlation with quiz performance. We trained multiple machine learning models to predict quiz performance from oxygenated hemoglobin features and achieved accuracies ranging from 58\\% to 67\\% accuracy. These predictions were used to calculate cognitive effort via relative neural involvement and efficiency, which consider both brain activation and behavioral performance. Although quiz score predictions achieved moderate accuracy, the derived relative neural efficiency and involvement values remained robust. Since both metrics are based on the relative positions of standardized brain activation and performance scores, even small misclassifications in predicted scores preserved the overall cognitive effort trends observed during gameplay.",
      "authors": [
        "Shayla Sharmin and Roghayeh Leila Barmaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:20:54+00:00",
          "link": "https://arxiv.org/abs/2507.13952v1",
          "size": "3668kb",
          "version": "v1"
        }
      ],
      "title": "Estimating Cognitive Effort from Functional Near-Infrared Spectroscopy (fNIRS) Signals using Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13952",
        "HTML": "https://arxiv.org/html/2507.13952v1",
        "PDF": "https://arxiv.org/pdf/2507.13952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates cognitive effort estimation using fNIRS signals and machine learning. It is focused on educational assessment and neural measurements, lacking relevance to LLM data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13954",
      "abstract": "Anomaly detection in complex domains poses significant challenges due to the need for extensive labeled data and the inherently imbalanced nature of anomalous versus benign samples. Graph-based machine learning models have emerged as a promising solution that combines attribute and relational data to uncover intricate patterns. However, the scarcity of anomalous data exacerbates the challenge, which requires innovative strategies to enhance model learning with limited information. In this paper, we hypothesize that the incorporation of the influence of the nodes, quantified through average controllability, can significantly improve the performance of anomaly detection. We propose two novel approaches to integrate average controllability into graph-based frameworks: (1) using average controllability as an edge weight and (2) encoding it as a one-hot edge attribute vector. Through rigorous evaluation on real-world and synthetic networks with six state-of-the-art baselines, our proposed methods demonstrate improved performance in identifying anomalies, highlighting the critical role of controllability measures in enhancing the performance of graph machine learning models. This work underscores the potential of integrating average controllability as additional metrics to address the challenges of anomaly detection in sparse and imbalanced datasets.",
      "authors": [
        "Yifan Wei",
        "Anwar Said",
        "Waseem Abbas",
        "Xenofon Koutsoukos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:21:10+00:00",
          "link": "https://arxiv.org/abs/2507.13954v1",
          "size": "175kb",
          "version": "v1"
        }
      ],
      "title": "Robust Anomaly Detection with Graph Neural Networks using Controllability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13954",
        "HTML": "https://arxiv.org/html/2507.13954v1",
        "PDF": "https://arxiv.org/pdf/2507.13954"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research involves anomaly detection using graph neural networks and focuses on controllability measures. It does not relate to data processing for LLM training or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13955",
      "abstract": "We establish improved convergence rates for curved boundary element methods applied to the three-dimensional (3D) Laplace and Helmholtz equations with smooth geometry and data. Our analysis relies on a precise analysis of the consistency errors introduced by the perturbed bilinear and sesquilinear forms. We illustrate our results with numerical experiments in 3D based on basis functions and curved triangular elements up to order four.",
      "authors": [
        "Luiz Maltez Faria",
        "Pierre Marchand",
        "Hadrien Montanelli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:21:13+00:00",
          "link": "https://arxiv.org/abs/2507.13955v1",
          "size": "330kb",
          "version": "v1"
        }
      ],
      "title": "Convergence rates of curved boundary element methods for the 3D Laplace and Helmholtz equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13955",
        "PDF": "https://arxiv.org/pdf/2507.13955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on convergence rates for boundary element methods related to the 3D Laplace and Helmholtz equations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13956",
      "abstract": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's Disease (AD), where early identification and intervention can effectively slow the progression to dementia. However, diagnosing AD remains a significant challenge in neurology due to the confounders caused mainly by the selection bias of multimodal data and the complex relationships between variables. To address these issues, we propose a novel visual-language causal intervention framework named Alzheimer's Disease Prediction with Cross-modal Causal Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language model (LLM) to summarize clinical data under strict templates, maintaining structured text outputs even with incomplete or unevenly distributed datasets. The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI) images and textual data generated by LLM to classify participants into Cognitively Normal (CN), MCI, and AD categories. Because of the presence of confounders, such as neuroimaging artifacts and age-related biomarkers, non-causal models are likely to capture spurious input-output correlations, generating less reliable results. Our framework implicitly eliminates confounders through causal intervention. Experimental results demonstrate the outstanding performance of our method in distinguishing CN/MCI/AD cases, achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The study showcases the potential of integrating causal reasoning with multi-modal learning for neurological disease diagnosis.",
      "authors": [
        "Yutao Jin",
        "Haowen Xiao",
        "Jielei Chu",
        "Fengmao Lv",
        "Yuxiao Li",
        "Tianrui Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:21:24+00:00",
          "link": "https://arxiv.org/abs/2507.13956v1",
          "size": "1606kb",
          "version": "v1"
        }
      ],
      "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13956",
        "HTML": "https://arxiv.org/html/2507.13956v1",
        "PDF": "https://arxiv.org/pdf/2507.13956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework involving LLMs to summarize clinical data for Alzheimer's disease prediction, which involves data processing but not specifically for LLM training. The main focus is on diagnostic assistance and causal intervention rather than LLM data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13957",
      "abstract": "The modern recommender systems are facing an increasing challenge of modelling and predicting the dynamic and context-rich user preferences. Traditional collaborative filtering and content-based methods often struggle to capture the temporal patternings and evolving user intentions. While Large Language Models (LLMs) have gained gradual attention in recent years, by their strong semantic understanding and reasoning abilities, they are not inherently designed to model chronologically evolving user preference and intentions. On the other hand, for sequential models like LSTM (Long-Short-Term-Memory) which is good at capturing the temporal dynamics of user behaviour and evolving user preference over time, but still lacks a rich semantic understanding for comprehensive recommendation generation. In this study, we propose DUALRec (Dynamic User-Aware Language-based Recommender), a novel recommender that leverages the complementary strength of both models, which combines the temporal modelling abilities of LSTM networks with semantic reasoning power of the fine-tuned Large Language Models. The LSTM component will capture users evolving preference through their viewing history, while the fine-tuned LLM variants will leverage these temporal user insights to generate next movies that users might enjoy. Experimental results on MovieLens-1M dataset shows that the DUALRec model outperforms a wide range of baseline models, with comprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted Cumulative Gain (NDCG@k), and genre similarity metrics. This research proposes a novel architecture that bridges the gap between temporal sequence modeling and semantic reasoning, and offers a promising direction for developing more intelligent and context-aware recommenders.",
      "authors": [
        "Yitong Li",
        "Raoul Grasman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:22:05+00:00",
          "link": "https://arxiv.org/abs/2507.13957v1",
          "size": "1110kb",
          "version": "v1"
        }
      ],
      "title": "DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13957",
        "HTML": "https://arxiv.org/html/2507.13957v1",
        "PDF": "https://arxiv.org/pdf/2507.13957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a hybrid model for movie recommendations using LLMs for semantic understanding. It briefly involves the fine-tuning of LLMs but does not focus on LLM training data processing methods or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13958",
      "abstract": "Reasoning about dynamic systems with a fine-grained temporal and numeric resolution presents significant challenges for logic-based approaches like Answer Set Programming (ASP). To address this, we introduce and elaborate upon a novel temporal and constraint-based extension of the logic of Here-and-There and its nonmonotonic equilibrium extension, representing, to the best of our knowledge, the first approach to nonmonotonic temporal reasoning with constraints specifically tailored for ASP. This expressive system is achieved by a synergistic combination of two foundational ASP extensions: the linear-time logic of Here-and-There, providing robust nonmonotonic temporal reasoning capabilities, and the logic of Here-and-There with constraints, enabling the direct integration and manipulation of numeric constraints, among others. This work establishes the foundational logical framework for tackling complex dynamic systems with high resolution within the ASP paradigm.",
      "authors": [
        "Pedro Cabalar",
        "Mart\\'in Di\\'eguez",
        "Fran\\c{c}ois Olivier",
        "Torsten Schaub and Igor St\\'ephan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:22:38+00:00",
          "link": "https://arxiv.org/abs/2507.13958v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Towards Constraint Temporal Answer Set Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13958",
        "PDF": "https://arxiv.org/pdf/2507.13958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses logic-based approaches for dynamic systems through temporal and numeric reasoning, lacking any component related to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13959",
      "abstract": "The work in this paper describes the training and evaluation of machine learning (ML) techniques for the classification of cuneiform signs. There is a lot of variability in cuneiform signs, depending on where they come from, for what and by whom they were written, but also how they were digitized. This variability makes it unlikely that an ML model trained on one dataset will perform successfully on another dataset. This contribution studies how such differences impact that performance. Based on our results and insights, we aim to influence future data acquisition standards and provide a solid foundation for future cuneiform sign classification tasks. The ML model has been trained and tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary texts inscribed on clay tablets originating from three Mesopotamian cities (Nippur, D\\=ur-Abie\\v{s}uh and Sippar). The presented and analysed model is ResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for signs with at least 20 instances. As these automatic classification results are the first on Old Babylonian texts, there are currently no comparable results.",
      "authors": [
        "Eli Verwimp and Gustav Ryberg Smidt and Hendrik Hameeuw and Katrien De Graef"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:24:22+00:00",
          "link": "https://arxiv.org/abs/2507.13959v1",
          "size": "5056kb",
          "version": "v1"
        }
      ],
      "title": "Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13959",
        "PDF": "https://arxiv.org/pdf/2507.13959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on classifying Old Babylonian cuneiform signs using machine learning techniques, which does not pertain to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13961",
      "abstract": "In this work, we consider a coded caching model called \\textit{hotplug coded caching}, in which some users are offline during the delivery phase. The concept of Hotplug Placement Delivery Arrays (HpPDAs) for hotplug coded caching systems has been introduced in the literature, and two classes of HpPDAs are known. In this paper, we consider a secrecy constraint in hotplug coded caching setup, where users should not learn anything about any file from their cache content, and active users should not gain any information about files other than their demanded file from either their cache content or the server transmissions. We propose two secretive schemes for the two classes of HpPDAs and compare them with a baseline scheme, which is a secretive scheme using PDAs for the classical coded caching setup and can be trivially adapted for the hotplug coded caching setup. We numerically show that our schemes outperform the baseline scheme in certain memory regions.",
      "authors": [
        "Mallikharjuna Chinnapadamala",
        "Charul Rajput",
        "and B. Sundar Rajan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:24:29+00:00",
          "link": "https://arxiv.org/abs/2507.13961v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "Secretive Hotplug Coded Caching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13961",
        "HTML": "https://arxiv.org/html/2507.13961v1",
        "PDF": "https://arxiv.org/pdf/2507.13961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses hotplug coded caching with secrecy constraints but does not address any aspect of LLM training data processing or data operations related to LLMs, such as collection, filtering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13963",
      "abstract": "A seminal result of Nisan and Szegedy (STOC, 1992) shows that for any total Boolean function, the degree of the real polynomial that computes the function, and the minimal degree of a real polynomial that point-wise approximates the function, are at most polynomially separated. Extending this result from degree to other complexity measures like sparsity of the polynomial representation, or total weight of the coefficients, remains poorly understood.\n  In this work, we consider this problem in the De Morgan basis, and prove an analogous result for the sparsity of the polynomials at a logarithmic scale. Our result further implies that the exact $\\ell_1$ norm and its approximate variant are also similarly related to each other at a log scale. This is in contrast to the Fourier basis, where the analog of our results are known to be false.\n  Our proof is based on a novel random restriction method. Unlike most existing random restriction methods used in complexity theory, our random restriction process is adaptive and is based on how various complexity measures simplify during the restriction process.",
      "authors": [
        "Arkadev Chattopadhyay",
        "Yogesh Dahiya",
        "Shachar Lovett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.13963v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Exact versus Approximate Representations of Boolean Functions in the De Morgan Basis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13963",
        "HTML": "https://arxiv.org/html/2507.13963v1",
        "PDF": "https://arxiv.org/pdf/2507.13963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the mathematical properties of polynomial representations for Boolean functions, not on LLM training data processing or related data management operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13966",
      "abstract": "Language models traditionally used for cross-domain generalization have recently demonstrated task-specific reasoning. However, their top-down training approach on general corpora is insufficient for acquiring abstractions needed for deep domain expertise. This may require a bottom-up approach that acquires expertise by learning to compose simple domain concepts into more complex ones. A knowledge graph (KG) provides this compositional structure, where domain primitives are represented as head-relation-tail edges and their paths encode higher-level concepts. We present a task generation pipeline that synthesizes tasks directly from KG primitives, enabling models to acquire and compose them for reasoning. We fine-tune language models on the resultant KG-grounded curriculum to demonstrate domain-specific superintelligence. While broadly applicable, we validate our approach in medicine, where reliable KGs exist. Using a medical KG, we curate 24,000 reasoning tasks paired with thinking traces derived from diverse medical primitives. We fine-tune the QwQ-32B model on this curriculum to obtain QwQ-Med-3 that takes a step towards medical superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify reasoning abilities across 15 medical domains. Our experiments demonstrate that QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired primitives to widen the performance gap on the hardest tasks of ICD-Bench. Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3 transfers acquired expertise to enhance the base model's performance. While the industry's approach to artificial general intelligence (AGI) emphasizes broad expertise, we envision a future in which AGI emerges from the composable interaction of efficient domain-specific superintelligent agents.",
      "authors": [
        "Bhishma Dedhia",
        "Yuval Kansal",
        "Niraj K. Jha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:30:08+00:00",
          "link": "https://arxiv.org/abs/2507.13966v1",
          "size": "1803kb",
          "version": "v1"
        }
      ],
      "title": "Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13966",
        "PDF": "https://arxiv.org/pdf/2507.13966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper discusses a task generation pipeline based on knowledge graphs for fine-tuning language models, which involves creating datasets for domain-specific reasoning tasks. This makes a direct contribution to LLM training data processing through new dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13969",
      "abstract": "The deployment of simple emergent behaviors in swarm robotics has been well-rehearsed in the literature. A recent study has shown how self-aggregation is possible in a multitask approach -- where multiple self-aggregation task instances occur concurrently in the same environment. The multitask approach poses new challenges, in special, how the dynamic of each group impacts the performance of others. So far, the multitask self-aggregation of groups of robots suffers from generating a circular formation -- that is not fully compact -- or is not fully autonomous. In this paper, we present a multitask self-aggregation where groups of homogeneous robots sort themselves into different compact clusters, relying solely on a line-of-sight sensor. Our multitask self-aggregation behavior was able to scale well and achieve a compact formation. We report scalability results from a series of simulation trials with different configurations in the number of groups and the number of robots per group. We were able to improve the multitask self-aggregation behavior performance in terms of the compactness of the clusters, keeping the proportion of clustered robots found in other studies.",
      "authors": [
        "Maria Eduarda Silva de Macedo",
        "Ana Paula Chiarelli de Souza",
        "Roberto Silvio Ubertino Rosso Jr.",
        "Yuri Kaszubowski Lopes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:32:29+00:00",
          "link": "https://arxiv.org/abs/2507.13969v1",
          "size": "180kb",
          "version": "v1"
        }
      ],
      "title": "A Minimalist Controller for Autonomously Self-Aggregating Robotic Swarms: Enabling Compact Formations in Multitasking Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13969",
        "HTML": "https://arxiv.org/html/2507.13969v1",
        "PDF": "https://arxiv.org/pdf/2507.13969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about swarm robotics and multitask self-aggregation behavior, having no connection to LLM training data processing or dataset management operations like filtering or synthesis."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13970",
      "abstract": "Robotic grasping, the ability of robots to reliably secure and manipulate objects of varying shapes, sizes and orientations, is a complex task that requires precise perception and control. Deep neural networks have shown remarkable success in grasp synthesis by learning rich and abstract representations of objects. When deployed at the edge, these models can enable low-latency, low-power inference, making real-time grasping feasible in resource-constrained environments. This work implements Heatmap-Guided Grasp Detection, an end-to-end framework for the detection of 6-Dof grasp poses, on the GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware techniques, including input dimensionality reduction, model partitioning, and quantisation. Experimental evaluation on the GraspNet-1Billion benchmark validates the feasibility of fully on-chip inference, highlighting the potential of low-power MCUs for real-time, autonomous manipulation.",
      "authors": [
        "Casper Br\\\"ocheler",
        "Thomas Vroom",
        "Derrick Timmermans",
        "Alan van den Akker",
        "Guangzhi Tang",
        "Charalampos S. Kouzinopoulos",
        "Rico M\\\"ockel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:32:45+00:00",
          "link": "https://arxiv.org/abs/2507.13970v1",
          "size": "2309kb",
          "version": "v1"
        }
      ],
      "title": "A segmented robot grasping perception neural network for edge AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13970",
        "PDF": "https://arxiv.org/pdf/2507.13970"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on robotic grasping perception using a neural network framework and does not involve LLM training data processing tasks such as data filtering, dataset creation, or enhancement of data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13977",
      "abstract": "Despite Arabic being one of the most widely spoken languages, the development of Arabic Automatic Speech Recognition (ASR) systems faces significant challenges due to the language's complexity, and only a limited number of public Arabic ASR models exist. While much of the focus has been on Modern Standard Arabic (MSA), there is considerably less attention given to the variations within the language. This paper introduces a universal methodology for Arabic speech and text processing designed to address unique challenges of the language. Using this methodology, we train two novel models based on the FastConformer architecture: one designed specifically for MSA and the other, the first unified public model for both MSA and Classical Arabic (CA). The MSA model sets a new benchmark with state-of-the-art (SOTA) performance on related datasets, while the unified model achieves SOTA accuracy with diacritics for CA while maintaining strong performance for MSA. To promote reproducibility, we open-source the models and their training recipes.",
      "authors": [
        "Lilit Grigoryan",
        "Nikolay Karpov",
        "Enas Albasiri",
        "Vitaly Lavrukhin",
        "Boris Ginsburg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:42:18+00:00",
          "link": "https://arxiv.org/abs/2507.13977v1",
          "size": "421kb",
          "version": "v1"
        }
      ],
      "title": "Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13977",
        "HTML": "https://arxiv.org/html/2507.13977v1",
        "PDF": "https://arxiv.org/pdf/2507.13977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces novel automatic speech recognition models for Arabic, focusing on speech processing and model architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13981",
      "abstract": "Recent advances in AI-powered surveillance have intensified concerns over the collection and processing of sensitive personal data. In response, research has increasingly focused on privacy-by-design solutions, raising the need for objective techniques to evaluate privacy protection. This paper presents a comprehensive framework for evaluating visual privacy-protection methods across three dimensions: privacy, utility, and practicality. In addition, it introduces HR-VISPR, a publicly available human-centric dataset with biometric, soft-biometric, and non-biometric labels to train an interpretable privacy metric. We evaluate 11 privacy protection methods, ranging from conventional techniques to advanced deep-learning methods, through the proposed framework. The framework differentiates privacy levels in alignment with human visual perception, while highlighting trade-offs between privacy, utility, and practicality. This study, along with the HR-VISPR dataset, serves as an insightful tool and offers a structured evaluation framework applicable across diverse contexts.",
      "authors": [
        "Sara Abdulaziz",
        "Giacomo D'Amicantonio",
        "and Egor Bondarev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:43:24+00:00",
          "link": "https://arxiv.org/abs/2507.13981v1",
          "size": "35819kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13981",
        "HTML": "https://arxiv.org/html/2507.13981v1",
        "PDF": "https://arxiv.org/pdf/2507.13981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses privacy protection in visual data and introduces a privacy framework and dataset, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13982",
      "abstract": "Reliable energy delivery is a critical requirement for\n  long-term lunar missions, particularly in regions with limited\n  solar access, such as polar craters and during extended lunar\n  nights. Optical Power Beaming (OPB) using high-power lasers\n  offers a promising alternative to conventional solar power, but\n  the effects of suspended lunar dust on beam propagation remain\n  poorly understood. This study introduces a detailed simulation\n  model that incorporates both diffraction and height-dependent\n  scattering by the electrostatically suspended lunar regolith. Un like prior approaches, which assumed uniform dust layers or\n  center-to-center transmission loss, our model uses generalized\n  diffraction theory and refractive index gradients derived from\n  particle density to assess beam deformation and attenuation. The\n  results show that even in ground-to-ground scenarios, lunar dust\n  significantly degrades energy transfer efficiency, dropping from\n  57% to 3.7% over 50 km in dust-free vs. dusty conditions with\n  175 nm particles. Increasing the particle size to 250 nm limits the\n  viable transmission range to below 30 km at 6% efficiency. The\n  study further demonstrates that raising the laser source height\n  can improve efficiency, achieving 91% for a distance of 5 km\n  and 25% at 50 km when the source is positioned 12 m above\n  ground. These findings underscore the importance of system\n  elevation and dust modeling in lunar OPB design and reveal\n  the mission-critical role of particle size distribution, especially in\n  environments disturbed by human activity.",
      "authors": [
        "Yanni Jiwan-Mercier",
        "Bar{\\i}\\c{s} D\\\"onmez",
        "G\\\"une\\c{s} Karabulut-Kurt",
        "S\\'ebastien Loranger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:45:16+00:00",
          "link": "https://arxiv.org/abs/2507.13982v1",
          "size": "1765kb",
          "version": "v1"
        }
      ],
      "title": "Diffraction and Scattering Modeling for Laser Power Beaming in Lunar Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13982",
        "HTML": "https://arxiv.org/html/2507.13982v1",
        "PDF": "https://arxiv.org/pdf/2507.13982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses laser power beaming on the moon and creates a simulation model for this context, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13984",
      "abstract": "Disentangling content and style from a single image, known as content-style decomposition (CSD), enables recontextualization of extracted content and stylization of extracted styles, offering greater creative flexibility in visual synthesis. While recent personalization methods have explored the decomposition of explicit content style, they remain tailored for diffusion models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a promising alternative with a next-scale prediction paradigm, achieving performance comparable to that of diffusion models. In this paper, we explore VAR as a generative framework for CSD, leveraging its scale-wise generation process for improved disentanglement. To this end, we propose CSD-VAR, a novel method that introduces three key innovations: (1) a scale-aware alternating optimization strategy that aligns content and style representation with their respective scales to enhance separation, (2) an SVD-based rectification method to mitigate content leakage into style representations, and (3) an Augmented Key-Value (K-V) memory enhancing content identity preservation. To benchmark this task, we introduce CSD-100, a dataset specifically designed for content-style decomposition, featuring diverse subjects rendered in various artistic styles. Experiments demonstrate that CSD-VAR outperforms prior approaches, achieving superior content preservation and stylization fidelity.",
      "authors": [
        "Quang-Binh Nguyen",
        "Minh Luu",
        "Quang Nguyen",
        "Anh Tran",
        "Khoi Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:45:48+00:00",
          "link": "https://arxiv.org/abs/2507.13984v1",
          "size": "21486kb",
          "version": "v1"
        }
      ],
      "title": "CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13984",
        "HTML": "https://arxiv.org/html/2507.13984v1",
        "PDF": "https://arxiv.org/pdf/2507.13984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on content-style decomposition in visual autoregressive models, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13985",
      "abstract": "Generating 3D scenes from natural language holds great promise for applications in gaming, film, and design. However, existing methods struggle with automation, 3D consistency, and fine-grained control. We present DreamScene, an end-to-end framework for high-quality and editable 3D scene generation from text or dialogue. DreamScene begins with a scene planning module, where a GPT-4 agent infers object semantics and spatial constraints to construct a hybrid graph. A graph-based placement algorithm then produces a structured, collision-free layout. Based on this layout, Formation Pattern Sampling (FPS) generates object geometry using multi-timestep sampling and reconstructive optimization, enabling fast and realistic synthesis. To ensure global consistent, DreamScene employs a progressive camera sampling strategy tailored to both indoor and outdoor settings. Finally, the system supports fine-grained scene editing, including object movement, appearance changes, and 4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior methods in quality, consistency, and flexibility, offering a practical solution for open-domain 3D content creation. Code and demos are available at https://dreamscene-project.github.io.",
      "authors": [
        "Haoran Li",
        "Yuli Tian",
        "Kun Lan",
        "Yong Liao",
        "Lin Wang",
        "Pan Hui",
        "Peng Yuan Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:45:54+00:00",
          "link": "https://arxiv.org/abs/2507.13985v1",
          "size": "13617kb",
          "version": "v1"
        }
      ],
      "title": "DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13985",
        "HTML": "https://arxiv.org/html/2507.13985v1",
        "PDF": "https://arxiv.org/pdf/2507.13985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D scene generation from text using a framework called DreamScene, emphasizing 3D consistency and fine-grained control, rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13987",
      "abstract": "Despite its prevalence, in many domains, OWL is not expressive enough to define ontology classes. In this paper, we present an approach that allows to use monadic second-order formalisations for ontology classification. As a case study, we have applied our approach to 14 peptide-related classes from the chemistry ontology ChEBI. For these classes, a monadic second-order logic formalisation has been developed and applied both to ChEBI as well as to 119 million molecules from the chemistry database PubChem. While this logical approach alone is limited to classification for the specified classes (in our case, (sub)classes of peptides), transformer deep learning models scale classification to the whole of the ChEBI ontology. We show that when using the classifications obtained by the logical approach as training data, the performance of the deep learning models can be significantly enhanced.",
      "authors": [
        "Simon Fl\\\"ugel and Martin Glauer and Till Mossakowski and Fabian Neuhaus"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:47:49+00:00",
          "link": "https://arxiv.org/abs/2507.13987v1",
          "size": "453kb",
          "version": "v1"
        }
      ],
      "title": "ChemLog: Making MSOL Viable for Ontological Classification and Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13987",
        "HTML": "https://arxiv.org/html/2507.13987v1",
        "PDF": "https://arxiv.org/pdf/2507.13987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus is on ontology classification using deep learning models, it mentions using classifications as training data. However, the focus is on classification, not LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13992",
      "abstract": "Small sample sizes in neuroimaging in general, and in structural connectome (SC) studies in particular limit the development of reliable biomarkers for neurological and psychiatric disorders - such as Alzheimer's disease and schizophrenia - by reducing statistical power, reliability, and generalizability. Large-scale multi-site studies have exist, but they have acquisition-related biases due to scanner heterogeneity, compromising imaging consistency and downstream analyses. While existing SC harmonization methods - such as linear regression (LR), ComBat, and deep learning techniques - mitigate these biases, they often rely on detailed metadata, traveling subjects (TS), or overlook the graph-topology of SCs. To address these limitations, we propose a site-conditioned deep harmonization framework that harmonizes SCs across diverse acquisition sites without requiring metadata or TS that we test in a simulated scenario based on the Human Connectome Dataset. Within this framework, we benchmark three deep architectures - a fully connected autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a top-performing LR baseline. While non-graph models excel in edge-weight prediction and edge existence detection, the graph AE demonstrates superior preservation of topological structure and subject-level individuality, as reflected by graph metrics and fingerprinting accuracy, respectively. Although the LR baseline achieves the highest numerical performance by explicitly modeling acquisition parameters, it lacks applicability to real-world multi-site use cases as detailed acquisition metadata is often unavailable. Our results highlight the critical role of model architecture in SC harmonization performance and demonstrate that graph-based approaches are particularly well-suited for structure-aware, domain-generalizable SC harmonization in large-scale multi-site SC studies.",
      "authors": [
        "Jagruti Patel",
        "Thomas A. W. Bolton",
        "Mikkel Sch\\\"ottner",
        "Anjali Tarun",
        "Sebastien Tourbier",
        "Yasser Alem\\`an-G\\`omez",
        "Jonas Richiardi",
        "Patric Hagmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:58:05+00:00",
          "link": "https://arxiv.org/abs/2507.13992v1",
          "size": "9724kb",
          "version": "v1"
        }
      ],
      "title": "Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13992",
        "HTML": "https://arxiv.org/html/2507.13992v1",
        "PDF": "https://arxiv.org/pdf/2507.13992"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on harmonizing structural connectomes using deep learning methods, specifically graph neural networks, with no direct relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13994",
      "abstract": "The classical comparison-based sorting problem asks us to find the underlying total order of a given set of elements, where we can only access the elements via comparisons. In this paper, we study a restricted version, where, as a hint, a set $T$ of possible total orders is given, usually in some compressed form.\n  Recently, an algorithm called topological heapsort with optimal running time was found for the case where $T$ is the set of topological orderings of a given directed acyclic graph, or, equivalently, $T$ is the set of linear extensions of a given partial order [Haeupler et al. 2024]. We show that a simple generalization of topological heapsort is applicable to a much broader class of restricted sorting problems, where $T$ corresponds to a given antimatroid.\n  As a consequence, we obtain optimal algorithms for the following restricted sorting problems, where the allowed total orders are restricted by: a given set of monotone precedence formulas; the perfect elimination orders of a given chordal graph; or the possible vertex search orders of a given connected rooted graph.",
      "authors": [
        "Benjamin Aram Berendsohn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:02:46+00:00",
          "link": "https://arxiv.org/abs/2507.13994v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Optimal antimatroid sorting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13994",
        "HTML": "https://arxiv.org/html/2507.13994v1",
        "PDF": "https://arxiv.org/pdf/2507.13994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is on optimal sorting algorithms based on antimatroids, which does not relate to processing data for training large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13998",
      "abstract": "Modern multivariate time series forecasting primarily relies on two architectures: the Transformer with attention mechanism and Mamba. In natural language processing, an approach has been used that combines local window attention for capturing short-term dependencies and Mamba for capturing long-term dependencies, with their outputs averaged to assign equal weight to both. We find that for time-series forecasting tasks, assigning equal weight to long-term and short-term dependencies is not optimal. To mitigate this, we propose a dynamic weighting mechanism, ParallelTime Weighter, which calculates interdependent weights for long-term and short-term dependencies for each token based on the input and the model's knowledge. Furthermore, we introduce the ParallelTime architecture, which incorporates the ParallelTime Weighter mechanism to deliver state-of-the-art performance across diverse benchmarks. Our architecture demonstrates robustness, achieves lower FLOPs, requires fewer parameters, scales effectively to longer prediction horizons, and significantly outperforms existing methods. These advances highlight a promising path for future developments of parallel Attention-Mamba in time series forecasting. The implementation is readily available at: \\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub",
      "authors": [
        "Itay Katav",
        "Aryeh Kontorovich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:08:02+00:00",
          "link": "https://arxiv.org/abs/2507.13998v1",
          "size": "4827kb",
          "version": "v1"
        }
      ],
      "title": "ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13998",
        "HTML": "https://arxiv.org/html/2507.13998v1",
        "PDF": "https://arxiv.org/pdf/2507.13998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses architectures for multivariate time series forecasting, specifically focusing on dynamic weighting mechanisms in model design. It does not address LLM training data processing or operations related to data preparation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14000",
      "abstract": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM (PFA), a photonic-enabled switch and memory subsystem that delivers low latency, high bandwidth, and low per-bit energy. By integrating high-bandwidth HBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D electro-optical system-in-package, the PFA offers up to 32 TB of shared memory alongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM enables distributed AI training and inference to execute parallelism strategies more efficiently. The Photonic Fabric removes the silicon beachfront constraint that limits the fixed memory-to-compute ratio observed in virtually all current XPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet that connects to the Photonic Fabric increases its memory capacity and correspondingly its memory bandwidth by offering a flexible path to scaling well beyond the limitations of on-package HBM alone. We introduce CelestiSim, a lightweight analytical simulator validated on NVIDIA H100 and H200 systems. It is used to evaluate the performance of LLM reference and energy savings on PFA, without any significant change to the GPU core design. With the PFA, the simulation results show that up to 3.66x throughput and 1.40x latency improvements in LLM inference at 405B parameters, up to 7.04x throughput and 1.41x latency improvements at 1T parameters, and 60-90% energy savings in data movement for heavy collective operations in all LLM training scenarios. While these results are shown for NVIDIA GPUs, they can be applied similarly to other AI accelerator designs (XPUs) that share the same fundamental limitation of fixed memory to compute.",
      "authors": [
        "Jing Ding and Trung Diep"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Performance (cs.PF)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:14:56+00:00",
          "link": "https://arxiv.org/abs/2507.14000v1",
          "size": "2241kb",
          "version": "v1"
        }
      ],
      "title": "Photonic Fabric Platform for AI Accelerators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14000",
        "PDF": "https://arxiv.org/pdf/2507.14000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a photonic-enabled platform for AI accelerators, improving hardware efficiency for AI training and inference. It does not pertain to data processing for LLMs or related datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14004",
      "abstract": "This paper presents an new approach for detecting in the electrical power system of satellites operating in Low Earth Orbit (LEO) without an Attitude Determination and Control Subsystem (ADCS). Components of these systems are prone to faults, such as line-to-line faults in the photovoltaic subsystem, open circuits, and short circuits in the DC-to-DC converter, as well as ground faults in batteries. In the previous research has largely focused on detecting faults in each components, such as photovoltaic arrays or converter systems, therefore, has been limited attention given to whole electrical power system of satellite as a whole system. Our approach addresses this gap by utilizing a Multi-Layer Perceptron (MLP) neural network model, which leverages input data such as solar radiation and surface temperature to predict current and load outputs. These machine learning techniques that classifiy use different approaches like Principal Component Analysis (PCA) and K-Nearest Neighbors (KNN), to classify faults effectively. The model presented achieves over 99% accuracy in identifying faults across multiple subsystems, marking a notable advancement from previous approaches by offering a complete diagnostic solution for the entire satellite power system. This thorough method boosts system reliability and helps lower the chances of mission failure",
      "authors": [
        "Niloofar Nobahari and Alireza Rezaee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:17:57+00:00",
          "link": "https://arxiv.org/abs/2507.14004v1",
          "size": "1103kb",
          "version": "v1"
        }
      ],
      "title": "Smart fault detection in satellite electrical power system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14004",
        "PDF": "https://arxiv.org/pdf/2507.14004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on fault detection in satellite electrical systems using machine learning models. It does not address issues relevant to LLM training data processing or the creation of datasets for such models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14005",
      "abstract": "Recent work has shown that dynamic programming (DP) methods for finding static CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when based on the dual formulation, yet the root cause for the failure has remained unclear. We expand on these findings by shifting focus from policy optimization to the seemingly simpler task of policy evaluation. We show that evaluating the static CVaR of a given policy can be framed as two distinct minimization problems. For their solutions to match, a set of ``risk-assignment consistency constraints'' must be satisfied, and we demonstrate that the intersection of the constraints being empty is the source of previously observed evaluation errors. Quantifying the evaluation error as the CVaR evaluation gap, we then demonstrate that the issues observed when optimizing over the dual-based CVaR DP are explained by the returned policy having a non-zero CVaR evaluation gap. We then leverage our proposed risk-assignment perspective to prove that the search for a single, uniformly optimal policy via on the dual CVaR decomposition is fundamentally limited, identifying an MDP where no single policy can be optimal across all initial risk levels.",
      "authors": [
        "Mathieu Godbout and Audrey Durand"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:18:19+00:00",
          "link": "https://arxiv.org/abs/2507.14005v1",
          "size": "476kb",
          "version": "v1"
        }
      ],
      "title": "On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14005",
        "HTML": "https://arxiv.org/html/2507.14005v1",
        "PDF": "https://arxiv.org/pdf/2507.14005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores static CVaR policy evaluation in Markov Decision Processes, focusing on optimization issues. It does not relate to LLM training data processing or data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14007",
      "abstract": "The rapid integration of blockchain, cryptocurrency, and Web3 technologies into digital banks and fintech operations has created an integrated environment blending traditional financial systems with decentralised elements. This paper introduces the CryptoNeo Threat Modelling Framework (CNTMF), a proposed framework designed to address the risks in these ecosystems, such as oracle manipulation and cross-chain exploits. CNTMF represents a proposed extension of established methodologies like STRIDE, OWASP Top 10, NIST frameworks, LINDDUN, and PASTA, while incorporating tailored components including Hybrid Layer Analysis, the CRYPTOQ mnemonic for cryptocurrency-specific risks, and an AI-Augmented Feedback Loop. Drawing on real-world data from 2025 incidents, CNTMF supports data-driven mitigation to reduce losses, which totalled approximately $2.47 billion in the first half of 2025 across 344 security events (CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025). Its phases guide asset mapping, risk profiling, prioritisation, mitigation, and iterative feedback. This supports security against evolving risks like state-sponsored attacks.",
      "authors": [
        "Serhan W. Bahar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:19:08+00:00",
          "link": "https://arxiv.org/abs/2507.14007v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14007",
        "HTML": "https://arxiv.org/html/2507.14007v1",
        "PDF": "https://arxiv.org/pdf/2507.14007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on a threat modeling framework for blockchain and fintech ecosystems, and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14010",
      "abstract": "Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming to classify and segment tunnel cracks with enhanced accuracy and efficiency, this study proposes a two-step deep learning-based method. An automatic tunnel image classification model is developed using the DenseNet-169 in the first step. The proposed crack segmentation model in the second step is based on the DeepLabV3+, whose internal logic is evaluated via a score-weighted visual explanation technique. Proposed method combines tunnel image classification and segmentation together, so that the selected images containing cracks from the first step are segmented in the second step to improve the detection accuracy and efficiency. The superior performances of the two-step method are validated by experiments. The results show that the accuracy and frames per second (FPS) of the tunnel crack classification model are 92.23% and 39.80, respectively, which are higher than other convolutional neural networks (CNN) based and Transformer based models. Also, the intersection over union (IoU) and F1 score of the tunnel crack segmentation model are 57.01% and 67.44%, respectively, outperforming other state-of-the-art models. Moreover, the provided visual explanations in this study are conducive to understanding the \"black box\" of deep learning-based models. The developed two-stage deep learning-based method integrating visual explanations provides a basis for fast and accurate quantitative assessment of tunnel health status.",
      "authors": [
        "Yong Feng",
        "Xiaolei Zhang",
        "Shijin Feng",
        "Yong Zhao",
        "Yihan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:21:02+00:00",
          "link": "https://arxiv.org/abs/2507.14010v1",
          "size": "902kb",
          "version": "v1"
        }
      ],
      "title": "Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14010",
        "PDF": "https://arxiv.org/pdf/2507.14010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a method for classifying and segmenting tunnel cracks using deep learning but does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14011",
      "abstract": "This article proposes a method to formalise models of cognitive processes grounded in experience, considering experience from the perspective of a living system and not from that of an observer of the living system. The perspective of a living system is defined by the need of the system to preserve the vital equilibria. The method is based on an algorithmic schema that we call Environment Generative Operator (EGO) and uses a self-referential language developed for this purpose which we call E-language. EGO simulates cognitive processes as operations on neuron assemblies as understood by Hebb. In this article we present an EGO prototype (EGO-P) which has already been implemented and tested.",
      "authors": [
        "Paolo Totaro and Alberto Mangiante"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:22:33+00:00",
          "link": "https://arxiv.org/abs/2507.14011v1",
          "size": "4776kb",
          "version": "v1"
        }
      ],
      "title": "Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14011",
        "PDF": "https://arxiv.org/pdf/2507.14011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a self-referential algorithm for simulating cognitive processes and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14013",
      "abstract": "Accurate detection of nutrient deficiency in plant leaves is essential for precision agriculture, enabling early intervention in fertilization, disease, and stress management. This study presents a deep learning framework for leaf anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model with a transformer-based attention head. The model is tailored for processing nine-channel multispectral input and uses self-attention mechanisms to better capture subtle, spatially-distributed symptoms. The plants in the experiments were grown under controlled nutrient stress conditions for evaluation. We carry out extensive experiments to benchmark the proposed model against the baseline YOLOv5. Extensive experiments show that the proposed model significantly outperforms the baseline YOLOv5, with an average Dice score and IoU (Intersection over Union) improvement of about 12%. In particular, this model is effective in detecting challenging symptoms like chlorosis and pigment accumulation. These results highlight the promise of combining multi-spectral imaging with spectral-spatial feature learning for advancing plant phenotyping and precision agriculture.",
      "authors": [
        "Ji-Yan Wu",
        "Zheng Yong Poh",
        "Anoop C. Patil",
        "Bongsoo Park",
        "Giovanni Volpe and Daisuke Urano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:25:36+00:00",
          "link": "https://arxiv.org/abs/2507.14013v1",
          "size": "6280kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14013",
        "HTML": "https://arxiv.org/html/2507.14013v1",
        "PDF": "https://arxiv.org/pdf/2507.14013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a framework for detecting plant nutrient deficiencies using multispectral imaging and deep learning, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14017",
      "abstract": "We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for Human Mobility), a framework that leverages large language models (LLMs) as spatio-temporal predictors and trajectory reasoners. RHYTHM partitions trajectories into daily segments encoded as discrete tokens with hierarchical attention, capturing both daily and weekly dependencies while substantially reducing the sequence length. Token representations are enriched with pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability to capture interdependencies without extensive computational overhead. By freezing the LLM backbone, RHYTHM achieves significant computational efficiency. Evaluation on three real-world datasets demonstrates a 2.4% improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in training time compared to state-of-the-art methods.",
      "authors": [
        "Haoyu He",
        "Haozheng Luo",
        "Yan Chen",
        "Qi R. Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:31:16+00:00",
          "link": "https://arxiv.org/abs/2507.14017v1",
          "size": "1048kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Temporal Tokenization for Mobility Prediction with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14017",
        "HTML": "https://arxiv.org/html/2507.14017v1",
        "PDF": "https://arxiv.org/pdf/2507.14017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces RHYTHM, which uses LLMs for human mobility prediction but does not focus on LLM training data processing. Although it employs LLMs, it concentrates on model architecture and efficiency improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14020",
      "abstract": "Understanding how batteries perform after automotive use is crucial to determining their potential for reuse. This article presents experimental results aimed at advancing knowledge of retired battery performance. Three modules extracted from electric vehicles were tested. Their performance was assessed, and the results were analyzed statistically using analysis of variance (ANOVA). The 36 retired cells exhibited a high level of performance, albeit with significant variation. On average, the cells had a 95% state of health capacity with a dispersion of 2.4%. ANOVA analysis suggests that cell performance is not correlated with their position inside the module. These results demonstrate the need to evaluate dispersion within retired batteries and to develop thermal management and balancing systems for second-life batteries.",
      "authors": [
        "Marwan Hassini",
        "Colette Mintsa-Eya",
        "Eduardo Redondo-Iglesias",
        "Pascal Venet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:38:11+00:00",
          "link": "https://arxiv.org/abs/2507.14020v1",
          "size": "3095kb",
          "version": "v1"
        }
      ],
      "title": "Influence of Cell Position on the Capacity of Retired Batteries: Experimental and Statistical Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14020",
        "HTML": "https://arxiv.org/html/2507.14020v1",
        "PDF": "https://arxiv.org/pdf/2507.14020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the performance analysis of retired automotive batteries and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14021",
      "abstract": "In this paper, we study Byzantine-resilient federated online learning for Gaussian process regression (GPR). We develop a Byzantine-resilient federated GPR algorithm that allows a cloud and a group of agents to collaboratively learn a latent function and improve the learning performances where some agents exhibit Byzantine failures, i.e., arbitrary and potentially adversarial behavior. Each agent-based local GPR sends potentially compromised local predictions to the cloud, and the cloud-based aggregated GPR computes a global model by a Byzantine-resilient product of experts aggregation rule. Then the cloud broadcasts the current global model to all the agents. Agent-based fused GPR refines local predictions by fusing the received global model with that of the agent-based local GPR. Moreover, we quantify the learning accuracy improvements of the agent-based fused GPR over the agent-based local GPR. Experiments on a toy example and two medium-scale real-world datasets are conducted to demonstrate the performances of the proposed algorithm.",
      "authors": [
        "Xu Zhang",
        "Zhenyuan Yuan",
        "Minghui Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:39:47+00:00",
          "link": "https://arxiv.org/abs/2507.14021v1",
          "size": "5268kb",
          "version": "v1"
        }
      ],
      "title": "Byzantine-resilient federated online learning for Gaussian process regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14021",
        "HTML": "https://arxiv.org/html/2507.14021v1",
        "PDF": "https://arxiv.org/pdf/2507.14021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Byzantine-resilient federated online learning and Gaussian process regression, which are not related to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14022",
      "abstract": "This study proposes the Cognitive Pairwise Comparison Classification Model Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC, based on expert knowledge judgment, is used to calculate the weights of evaluation criteria, including accuracy, precision, recall, F1-score, specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from Transformers (ALBERT) are chosen as classification baseline models. A weighted decision matrix consisting of classification evaluation scores with respect to criteria weights, is formed to select the best classification model for a classification problem. Three open datasets of social media are used to demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation, for evaluation results excluding the time factor, ALBERT is the best for the three datasets; if time consumption is included, no single model always performs better than the other models. The CPC-CMS can be applied to the other classification applications in different areas.",
      "authors": [
        "Jianfei Li",
        "Kevin Kam Fung Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:41:53+00:00",
          "link": "https://arxiv.org/abs/2507.14022v1",
          "size": "1215kb",
          "version": "v1"
        }
      ],
      "title": "CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14022",
        "PDF": "https://arxiv.org/pdf/2507.14022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for model selection in document-level sentiment analysis, without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14024",
      "abstract": "Bridging emotions and visual content for emotion-driven image editing holds great potential in creative industries, yet precise manipulation remains challenging due to the abstract nature of emotions and their varied manifestations across different contexts. We tackle this challenge with an integrated approach consisting of three complementary components. First, we introduce MoodArchive, an 8M+ image dataset with detailed hierarchical emotional annotations generated by LLaVA and partially validated by human evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned on MoodArchive to translate abstract emotions into specific visual attributes. Third, we propose Moodifier, a training-free editing model leveraging MoodifyCLIP and multimodal large language models (MLLMs) to enable precise emotional transformations while preserving content integrity. Our system works across diverse domains such as character expressions, fashion design, jewelry, and home d\\'ecor, enabling creators to quickly visualize emotional variations while preserving identity and structure. Extensive experimental evaluations show that Moodifier outperforms existing methods in both emotional accuracy and content preservation, providing contextually appropriate edits. By linking abstract emotions to concrete visual changes, our solution unlocks new possibilities for emotional content creation in real-world applications. We will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier code and demo publicly available upon acceptance.",
      "authors": [
        "Jiarong Ye",
        "Sharon X. Huang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:52:39+00:00",
          "link": "https://arxiv.org/abs/2507.14024v1",
          "size": "28826kb",
          "version": "v1"
        }
      ],
      "title": "Moodifier: MLLM-Enhanced Emotion-Driven Image Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14024",
        "HTML": "https://arxiv.org/html/2507.14024v1",
        "PDF": "https://arxiv.org/pdf/2507.14024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions creating a large dataset (MoodArchive) with hierarchical emotional annotations, the main focus is on its application in emotion-driven image editing, not directly improving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14025",
      "abstract": "In this paper, we propose a novel reference-free iterative learning model predictive control (MPC). In the proposed method, a certificate function based on the concept of Control Lyapunov Barrier Function (CLBF) is learned using data collected from past control executions and used to define the terminal set and cost in the MPC optimization problem at the current iteration. This scheme enables the progressive refinement of the MPC's terminal components over successive iterations. Unlike existing methods that rely on mixed-integer programming and suffer from numerical difficulties, the proposed approach formulates the MPC optimization problem as a standard nonlinear program, enabling more efficient online computation. The proposed method satisfies key MPC properties, including recursive feasibility and asymptotic stability. Additionally, we demonstrate that the performance cost is non-increasing with respect to the number of iterations, under certain assumptions. Numerical experiments including the simulation with PyBullet confirm that our control scheme iteratively enhances control performance and significantly improves online computational efficiency compared to the existing methods.",
      "authors": [
        "Wataru Hashimoto",
        "Kazumune Hashimoto",
        "Masako Kishida",
        "and Shigemasa Takai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:53:44+00:00",
          "link": "https://arxiv.org/abs/2507.14025v1",
          "size": "554kb",
          "version": "v1"
        }
      ],
      "title": "Reference-Free Iterative Learning Model Predictive Control with Neural Certificates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14025",
        "HTML": "https://arxiv.org/html/2507.14025v1",
        "PDF": "https://arxiv.org/pdf/2507.14025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel model predictive control method and does not address any aspect of LLM training data processing, such as data collection or creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14031",
      "abstract": "Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside imaging modality with high temporal resolution, making it suitable for bedside monitoring. However, its inherently ill-posed inverse problem poses significant challenges for accurate image reconstruction. Deep learning (DL)-based approaches have shown promise but often rely on complex network architectures with a large number of parameters, limiting efficiency and scalability. Here, we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network (QA-Net), combining parallel 2-qubit quantum circuits to generate expressive latent representations that serve as implicit nonlinear priors, followed by a single linear layer for conductivity reconstruction. This design drastically reduces model complexity and parameter number. Uniquely, QuantEIT operates in an unsupervised, training-data-free manner and represents the first integration of quantum circuits into EIT image reconstruction. Extensive experiments on simulated and real-world 2D and 3D EIT lung imaging data demonstrate that QuantEIT outperforms conventional methods, achieving comparable or superior reconstruction accuracy using only 0.2% of the parameters, with enhanced robustness to noise.",
      "authors": [
        "Hao Fang",
        "Sihao Teng",
        "Hao Yu",
        "Siyi Yuan",
        "Huaiwu He",
        "Zhe Liu",
        "and Yunjie Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:57:53+00:00",
          "link": "https://arxiv.org/abs/2507.14031v1",
          "size": "3287kb",
          "version": "v1"
        }
      ],
      "title": "QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14031",
        "HTML": "https://arxiv.org/html/2507.14031v1",
        "PDF": "https://arxiv.org/pdf/2507.14031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a quantum-assisted framework for Electrical Impedance Tomography, which operates in a training-data-free manner and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14032",
      "abstract": "Ontology Matching (OM) is a cornerstone task of semantic interoperability, yet existing systems often rely on handcrafted rules or specialized models with limited adaptability. We present KROMA, a novel OM framework that harnesses Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG) pipeline to dynamically enrich the semantic context of OM tasks with structural, lexical, and definitional knowledge. To optimize both performance and efficiency, KROMA integrates a bisimilarity-based concept matching and a lightweight ontology refinement step, which prune candidate concepts and substantially reduce the communication overhead from invoking LLMs. Through experiments on multiple benchmark datasets, we show that integrating knowledge retrieval with context-augmented LLMs significantly enhances ontology matching, outperforming both classic OM systems and cutting-edge LLM-based approaches while keeping communication overhead comparable. Our study highlights the feasibility and benefit of the proposed optimization techniques (targeted knowledge retrieval, prompt enrichment, and ontology refinement) for ontology matching at scale.",
      "authors": [
        "Lam Nguyen and Erika Barcelos and Roger French and Yinghui Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:00:11+00:00",
          "link": "https://arxiv.org/abs/2507.14032v1",
          "size": "2491kb",
          "version": "v1"
        }
      ],
      "title": "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14032",
        "HTML": "https://arxiv.org/html/2507.14032v1",
        "PDF": "https://arxiv.org/pdf/2507.14032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes using LLMs for ontology matching with enhanced context through knowledge retrieval and ontology refinement. While it involves some processing of context data, it does not focus on LLM training data processing directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14034",
      "abstract": "Agentic AI systems, powered by Large Language Models (LLMs), offer transformative potential for value co-creation in technical services. However, persistent challenges like hallucinations and operational brittleness limit their autonomous use, creating a critical need for robust frameworks to guide human-AI collaboration. Drawing on established Human-AI teaming research and analogies from fields like autonomous driving, this paper develops a structured taxonomy of human-agent interaction. Based on case study research within technical support platforms, we propose a six-mode taxonomy that organizes collaboration across a spectrum of AI autonomy. This spectrum is anchored by the Human-Out-of-the-Loop (HOOTL) model for full automation and the Human-Augmented Model (HAM) for passive AI assistance. Between these poles, the framework specifies four distinct intermediate structures. These include the Human-in-Command (HIC) model, where AI proposals re-quire mandatory human approval, and the Human-in-the-Process (HITP) model for structured work-flows with deterministic human tasks. The taxonomy further delineates the Human-in-the-Loop (HITL) model, which facilitates agent-initiated escalation upon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables discretionary human oversight of an autonomous AI. The primary contribution of this work is a comprehensive framework that connects this taxonomy to key contingency factors -- such as task complexity, operational risk, and system reliability -- and their corresponding conceptual architectures. By providing a systematic method for selecting and designing an appropriate level of human oversight, our framework offers practitioners a crucial tool to navigate the trade-offs between automation and control, thereby fostering the development of safer, more effective, and context-aware technical service systems.",
      "authors": [
        "Jochen Wulf",
        "Jurg Meierhofer",
        "Frank Hannich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:06:03+00:00",
          "link": "https://arxiv.org/abs/2507.14034v1",
          "size": "515kb",
          "version": "v1"
        }
      ],
      "title": "Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14034",
        "PDF": "https://arxiv.org/pdf/2507.14034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a taxonomy of human-agent interaction models in technical services, focusing on human-AI collaboration rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14038",
      "abstract": "Coherent X-ray scattering techniques are critical for investigating the fundamental structural properties of materials at the nanoscale. While advancements have made these experiments more accessible, real-time analysis remains a significant bottleneck, often hindered by artifacts and computational demands. In scanning X-ray nanodiffraction microscopy, which is widely used to spatially resolve structural heterogeneities, this challenge is compounded by the convolution of the divergent beam with the sample's local structure. To address this, we introduce DONUT (Diffraction with Optics for Nanobeam by Unsupervised Training), a physics-aware neural network designed for the rapid and automated analysis of nanobeam diffraction data. By incorporating a differentiable geometric diffraction model directly into its architecture, DONUT learns to predict crystal lattice strain and orientation in real-time. Crucially, this is achieved without reliance on labeled datasets or pre-training, overcoming a fundamental limitation for supervised machine learning in X-ray science. We demonstrate experimentally that DONUT accurately extracts all features within the data over 200 times more efficiently than conventional fitting methods.",
      "authors": [
        "Aileen Luo",
        "Tao Zhou",
        "Ming Du",
        "Martin V. Holt",
        "Andrej Singer",
        "Mathew J. Cherukara"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:10:39+00:00",
          "link": "https://arxiv.org/abs/2507.14038v1",
          "size": "1840kb",
          "version": "v1"
        }
      ],
      "title": "DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14038",
        "PDF": "https://arxiv.org/pdf/2507.14038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a physics-aware machine learning approach for X-ray nanodiffraction analysis, which does not relate to LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14039",
      "abstract": "We study the problem of fair division of indivisible chores among $n$ agents in an online setting, where items arrive sequentially and must be allocated irrevocably upon arrival. The goal is to produce an $\\alpha$-MMS allocation at the end. Several recent works have investigated this model, but have only succeeded in obtaining non-trivial algorithms under restrictive assumptions, such as the two-agent bi-valued special case (Wang and Wei, 2025), or by assuming knowledge of the total disutility of each agent (Zhou, Bai, and Wu, 2023). For the general case, the trivial $n$-MMS guarantee remains the best known, while the strongest lower bound is still only $2$.\n  We close this gap on the negative side by proving that for any fixed $n$ and $\\varepsilon$, no algorithm can guarantee an $(n - \\varepsilon)$-MMS allocation. Notably, this lower bound holds precisely for every $n$, without hiding constants in big-$O$ notation, thereby exactly matching the trivial upper bound.\n  Despite this strong impossibility result, we also present positive results. We provide an online algorithm that applies in the general case, guaranteeing a $\\min\\{n, O(k), O(\\log D)\\}$-MMS allocation, where $k$ is the maximum number of distinct disutilities across all agents and $D$ is the maximum ratio between the largest and smallest disutilities for any agent. This bound is reasonable across a broad range of scenarios and, for example, implies that we can achieve an $O(1)$-MMS allocation whenever $k$ is constant. Moreover, to optimize the constant in the important personalized bi-valued case, we show that if each agent has at most two distinct disutilities, our algorithm guarantees a $(2 + \\sqrt{3}) \\approx 3.7$-MMS allocation.",
      "authors": [
        "Jiaxin Song",
        "Biaoshuai Tao",
        "Wenqian Wang",
        "Yuhao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:10:51+00:00",
          "link": "https://arxiv.org/abs/2507.14039v1",
          "size": "61kb",
          "version": "v1"
        }
      ],
      "title": "Online MMS Allocation for Chores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14039",
        "HTML": "https://arxiv.org/html/2507.14039v1",
        "PDF": "https://arxiv.org/pdf/2507.14039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fair division of chores among agents, which is unrelated to LLM training data processing. It deals with algorithmic allocation strategies rather than data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14042",
      "abstract": "Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs) due to its ability to efficiently capture long-range dependencies with linear computational complexity. While token reduction, an effective compression technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision Mamba's efficiency is essential for enabling broader applications. However, we find that directly applying existing token reduction techniques for ViTs to Vision Mamba leads to significant performance degradation. This is primarily because Mamba is a sequence model without attention mechanisms, whereas most token reduction techniques for ViTs rely on attention mechanisms for importance measurement and overlook the order of compressed tokens. In this paper, we investigate a Mamba structure-aware importance score to evaluate token importance in a simple and effective manner. Building on this score, we further propose MTR, a training-free \\textbf{M}amba \\textbf{T}oken \\textbf{R}eduction framework. Without the need for training or additional tuning parameters, our method can be seamlessly integrated as a plug-and-play component across various Mamba models. Extensive experiments demonstrate that our approach significantly reduces computational workload while minimizing performance impact across various tasks and multiple backbones. Notably, MTR reduces FLOPs by approximately 40\\% on the Vim-B backbone, with only a 1.6\\% drop in ImageNet performance without retraining.",
      "authors": [
        "Qiankun Ma",
        "Ziyao Zhang",
        "Chi Su",
        "Jie Chen",
        "Zhen Song",
        "Hairong Zheng",
        "Wen Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:11:28+00:00",
          "link": "https://arxiv.org/abs/2507.14042v1",
          "size": "1258kb",
          "version": "v1"
        }
      ],
      "title": "Training-free Token Reduction for Vision Mamba",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14042",
        "HTML": "https://arxiv.org/html/2507.14042v1",
        "PDF": "https://arxiv.org/pdf/2507.14042"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores token reduction techniques for Vision Mamba models, which are related to vision tasks rather than language model training data processing. It concentrates on computational efficiency in vision tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14043",
      "abstract": "Metaheuristic algorithms have gained widespread application across various fields owing to their ability to generate diverse solutions. One such algorithm is the Snake Optimizer (SO), a progressive optimization approach. However, SO suffers from the issues of slow convergence speed and susceptibility to local optima. In light of these shortcomings, we propose a novel Multi-strategy Improved Snake Optimizer (MISO). Firstly, we propose a new adaptive random disturbance strategy based on sine function to alleviate the risk of getting trapped in a local optimum. Secondly, we introduce adaptive Levy flight strategy based on scale factor and leader and endow the male snake leader with flight capability, which makes it easier for the algorithm to leap out of the local optimum and find the global optimum. More importantly, we put forward a position update strategy combining elite leadership and Brownian motion, effectively accelerating the convergence speed while ensuring precision. Finally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test functions and the CEC2022 test suite, comparing it with 11 popular algorithms across different dimensions to validate its effectiveness. Moreover, Unmanned Aerial Vehicle (UAV) has been widely used in various fields due to its advantages of low cost, high mobility and easy operation. However, the UAV path planning problem is crucial for flight safety and efficiency, and there are still challenges in establishing and optimizing the path model. Therefore, we apply MISO to the UAV 3D path planning problem as well as 6 engineering design problems to assess its feasibility in practical applications. The experimental results demonstrate that MISO exceeds other competitive algorithms in terms of solution quality and stability, establishing its strong potential for application.",
      "authors": [
        "Genliang Li",
        "Yaxin Cui",
        "Jinyu Su"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:11:35+00:00",
          "link": "https://arxiv.org/abs/2507.14043v1",
          "size": "22517kb",
          "version": "v1"
        }
      ],
      "title": "A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14043",
        "PDF": "https://arxiv.org/pdf/2507.14043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an improved optimizer for UAV path planning, focusing on optimization algorithms rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14045",
      "abstract": "This paper presents a comprehensive evaluation of cost-efficient Large Language Models (LLMs) for diverse biomedical tasks spanning both text and image modalities. We evaluated a range of closed-source and open-source LLMs on tasks such as biomedical text classification and generation, question answering, and multimodal image processing. Our experimental findings indicate that there is no single LLM that can consistently outperform others across all tasks. Instead, different LLMs excel in different tasks. While some closed-source LLMs demonstrate strong performance on specific tasks, their open-source counterparts achieve comparable results (sometimes even better), with additional benefits like faster inference and enhanced privacy. Our experimental results offer valuable insights for selecting models that are optimally suited for specific biomedical applications.",
      "authors": [
        "Israt Jahan",
        "Md Tahmid Rahman Laskar",
        "Chun Peng",
        "Jimmy Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:13:35+00:00",
          "link": "https://arxiv.org/abs/2507.14045v1",
          "size": "672kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14045",
        "HTML": "https://arxiv.org/html/2507.14045v1",
        "PDF": "https://arxiv.org/pdf/2507.14045"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates the performance of large language models on biomedical tasks but does not discuss training data processing or improvements, making it irrelevant to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14049",
      "abstract": "Vision-Language Models (VLMs) have emerged as a promising approach to address the data scarcity challenge in robotics, enabling the development of generalizable visuomotor control policies. While models like OpenVLA showcase the potential of this paradigm, deploying large-scale VLMs on resource-constrained mobile manipulation systems remains a significant hurdle. This paper introduces Edge VLA (EVLA), a novel approach designed to significantly enhance the inference speed of Vision-Language-Action (VLA) models. EVLA maintains the representational power of these models while enabling real-time performance on edge devices. We achieve this through two key innovations: 1) Eliminating the autoregressive requirement for end-effector position prediction, leading to a 7x speedup in inference, and 2) Leveraging the efficiency of Small Language Models (SLMs), demonstrating comparable training performance to larger models with significantly reduced computational demands. Our early results demonstrate that EVLA achieves comparable training characteristics to OpenVLA while offering substantial gains in inference speed and memory efficiency. We release our model checkpoints and training \\href{https://github.com/kscalelabs/evla }{codebase} to foster further research.",
      "authors": [
        "Pawe{\\l} Budzianowski",
        "Wesley Maa",
        "Matthew Freed",
        "Jingxiang Mo",
        "Winston Hsiao",
        "Aaron Xie",
        "Tomasz M{\\l}oduchowski",
        "Viraj Tipnis",
        "Benjamin Bolte"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:15:09+00:00",
          "link": "https://arxiv.org/abs/2507.14049v1",
          "size": "3219kb",
          "version": "v1"
        }
      ],
      "title": "EdgeVLA: Efficient Vision-Language-Action Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14049",
        "HTML": "https://arxiv.org/html/2507.14049v1",
        "PDF": "https://arxiv.org/pdf/2507.14049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the efficiency of Vision-Language-Action models for edge devices, specifically in the context of robotics, and does not address LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14050",
      "abstract": "Class-Incremental Learning (CIL) aims to learn new classes over time without forgetting previously acquired knowledge. The emergence of foundation models (FM) pretrained on large datasets presents new opportunities for CIL by offering rich, transferable representations. However, their potential for enabling incremental learning in dermatology remains largely unexplored. In this paper, we systematically evaluate frozen FMs pretrained on large-scale skin lesion datasets for CIL in dermatological disease classification. We propose a simple yet effective approach where the backbone remains frozen, and a lightweight MLP is trained incrementally for each task. This setup achieves state-of-the-art performance without forgetting, outperforming regularization, replay, and architecture based methods. To further explore the capabilities of frozen FMs, we examine zero training scenarios using nearest mean classifiers with prototypes derived from their embeddings. Through extensive ablation studies, we demonstrate that this prototype based variant can also achieve competitive results. Our findings highlight the strength of frozen FMs for continual learning in dermatology and support their broader adoption in real world medical applications. Our code and datasets are available here.",
      "authors": [
        "Mohamed Elkhayat",
        "Mohamed Mahmoud",
        "Jamil Fayyad",
        "Nourhan Bayasi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:15:51+00:00",
          "link": "https://arxiv.org/abs/2507.14050v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Foundation Models as Class-Incremental Learners for Dermatological Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14050",
        "HTML": "https://arxiv.org/html/2507.14050v1",
        "PDF": "https://arxiv.org/pdf/2507.14050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with Class-Incremental Learning in dermatological image classification utilizing foundation models, but it does not make any technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14052",
      "abstract": "Inversion-based feedforward control relies on an accurate model that describes the inverse system dynamics. The gated recurrent unit (GRU), which is a recent architecture in recurrent neural networks, is a strong candidate for obtaining such a model from data. However, due to their black-box nature, GRUs face challenges such as limited interpretability and vulnerability to overfitting. Recently, physics-guided neural networks (PGNNs) have been introduced, which integrate the prior physical model structure into the prediction process. This approach not only improves training convergence, but also facilitates the learning of a physics-based model. In this work, we integrate a GRU in the PGNN framework to obtain a PG-GRU, based on which we adopt a two-step approach to feedforward control design. First, we adopt stable inversion techniques to design a stable linear model of the inverse dynamics. Then, a GRU trained on the residual is tailored to inverse system identification. The resulting PG-GRU feedforward controller is validated by means of real-life experiments on a two-mass spring-damper system, where it demonstrates roughly a two-fold improvement compared to the linear feedforward and a preview-based GRU feedforward in terms of the integral absolute error.",
      "authors": [
        "Mingdao Lin",
        "Max Bolderman",
        "Mircea Lazar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.14052v1",
          "size": "3265kb",
          "version": "v1"
        }
      ],
      "title": "Physics-guided gated recurrent units for inversion-based feedforward control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14052",
        "HTML": "https://arxiv.org/html/2507.14052v1",
        "PDF": "https://arxiv.org/pdf/2507.14052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study integrates physics-guided neural networks with GRU architectures for inversion-based feedforward control, which is unrelated to LLM training data processing or any aspect of language model training data curation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14056",
      "abstract": "Recent studies in continual learning have identified a transient drop in performance on mastered tasks when assimilating new ones, known as the stability gap. Such dynamics contradict the objectives of continual learning, revealing a lack of robustness in mitigating forgetting, and notably, persisting even under an ideal joint-loss regime. Examining this gap within this idealized joint training context is critical to isolate it from other sources of forgetting. We argue that it reflects an imbalance between rapid adaptation and robust retention at task boundaries, underscoring the need to investigate mechanisms that reconcile plasticity and stability within continual learning frameworks. Biological brains navigate a similar dilemma by operating concurrently on multiple timescales, leveraging neuromodulatory signals to modulate synaptic plasticity. However, artificial networks lack native multitimescale dynamics, and although optimizers like momentum-SGD and Adam introduce implicit timescale regularization, they still exhibit stability gaps. Inspired by locus coeruleus mediated noradrenergic bursts, which transiently enhance neuronal gain under uncertainty to facilitate sensory assimilation, we propose uncertainty-modulated gain dynamics - an adaptive mechanism that approximates a two-timescale optimizer and dynamically balances integration of knowledge with minimal interference on previously consolidated information. We evaluate our mechanism on domain-incremental and class-incremental variants of the MNIST and CIFAR benchmarks under joint training, demonstrating that uncertainty-modulated gain dynamics effectively attenuate the stability gap. Finally, our analysis elucidates how gain modulation replicates noradrenergic functions in cortical circuits, offering mechanistic insights into reducing stability gaps and enhance performance in continual learning tasks.",
      "authors": [
        "Alejandro Rodriguez-Garcia",
        "Anindya Ghosh",
        "Srikanth Ramaswamy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:34:06+00:00",
          "link": "https://arxiv.org/abs/2507.14056v1",
          "size": "3209kb",
          "version": "v1"
        }
      ],
      "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14056",
        "HTML": "https://arxiv.org/html/2507.14056v1",
        "PDF": "https://arxiv.org/pdf/2507.14056"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on mitigating the stability gap in continual learning, a concept not applicable to LLM training data processing. It does not address any aspect of data engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14059",
      "abstract": "The use of autonomous robots in space is an essential part of the \"New Space\" commercial ecosystem of assembly and re-use of space hardware components in Earth orbit and beyond. The STARFAB project aims to create a ground demonstration of an orbital automated warehouse as a hub for sustainable commercial operations and servicing. A critical part of this fully-autonomous robotic facility will be the capability to monitor, inspect, and assess the condition of both the components stored in the warehouse, and the STARFAB facility itself. This paper introduces ongoing work on the STARFAB Mobile Inspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it can be carried by Walking Manipulators (WM) as an independently-mobile robot, and multiple MIMs can be stored and retrieved as needed for operations on STARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a thermal imaging sensor, with the capability to add other modular sensors. A grasping tool and torque wrench are stored within the modular body for use by an attached WM for maintenance operations. Implementation and testing is still ongoing at the time of writing. This paper details the concept of operations for the MIM as an on-orbit autonomous inspection and maintenance system, the mechanical and electronic design of the MIM, and the sensors package used for non-destructive testing.",
      "authors": [
        "Tianyuan Wang",
        "Mark A Post",
        "Mathieu Deremetz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:40:58+00:00",
          "link": "https://arxiv.org/abs/2507.14059v1",
          "size": "27817kb",
          "version": "v1"
        }
      ],
      "title": "Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14059",
        "HTML": "https://arxiv.org/html/2507.14059v1",
        "PDF": "https://arxiv.org/pdf/2507.14059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the design of a robot for space operations, detailing the mechanical and electronic design for an inspection and maintenance system. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14060",
      "abstract": "We initiate the study of approximation algorithms and computational barriers for constructing sparse $\\alpha$-navigable graphs [IX23, DGM+24], a core primitive underlying recent advances in graph-based nearest neighbor search. Given an $n$-point dataset $P$ with an associated metric $\\mathsf{d}$ and a parameter $\\alpha \\geq 1$, the goal is to efficiently build the sparsest graph $G=(P, E)$ that is $\\alpha$-navigable: for every distinct $s, t \\in P$, there exists an edge $(s, u) \\in E$ with $\\mathsf{d}(u, t) < \\mathsf{d}(s, t)/\\alpha$. We consider two natural sparsity objectives: minimizing the maximum out-degree and minimizing the total size.\n  We first show a strong negative result: the slow-preprocessing version of DiskANN (analyzed in [IX23] for low-doubling metrics) can yield solutions whose sparsity is $\\widetilde{\\Omega}(n)$ times larger than optimal, even on Euclidean instances. We then show a tight approximation-preserving equivalence between the Sparsest Navigable Graph problem and the classic Set Cover problem, obtaining an $O(n^3)$-time $(\\ln n + 1)$-approximation algorithm, as well as establishing NP-hardness of achieving an $o(\\ln n)$-approximation. Building on this equivalence, we develop faster $O(\\ln n)$-approximation algorithms. The first runs in $\\widetilde{O}(n \\cdot \\mathrm{OPT})$ time and is thus much faster when the optimal solution is sparse. The second, based on fast matrix multiplication, is a bicriteria algorithm that computes an $O(\\ln n)$-approximation to the sparsest $2\\alpha$-navigable graph, running in $\\widetilde{O}(n^{\\omega})$ time.\n  Finally, we complement our upper bounds with a query complexity lower bound, showing that any $o(n)$-approximation requires examining $\\Omega(n^2)$ distances. This result shows that in the regime where $\\mathrm{OPT} = \\widetilde{O}(n)$, our $\\widetilde{O}(n \\cdot \\mathrm{OPT})$-time algorithm is essentially best possible.",
      "authors": [
        "Sanjeev Khanna",
        "Ashwin Padaki",
        "Erik Waingarten"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:41:21+00:00",
          "link": "https://arxiv.org/abs/2507.14060v1",
          "size": "35kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and Hardness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14060",
        "HTML": "https://arxiv.org/html/2507.14060v1",
        "PDF": "https://arxiv.org/pdf/2507.14060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses approximation algorithms related to sparse navigable graphs for nearest neighbor searches. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14061",
      "abstract": "What if a robot could rethink its own morphological representation to better meet the demands of diverse tasks? Most robotic systems today treat their physical form as a fixed constraint rather than an adaptive resource, forcing the same rigid geometric representation to serve applications with vastly different computational and precision requirements. We introduce MorphIt, a novel algorithm for approximating robot morphology using spherical primitives that balances geometric accuracy with computational efficiency. Unlike existing approaches that rely on either labor-intensive manual specification or inflexible computational methods, MorphIt implements an automatic gradient-based optimization framework with tunable parameters that provides explicit control over the physical fidelity versus computational cost tradeoff. Quantitative evaluations demonstrate that MorphIt outperforms baseline approaches (Variational Sphere Set Approximation and Adaptive Medial-Axis Approximation) across multiple metrics, achieving better mesh approximation with fewer spheres and reduced computational overhead. Our experiments show enhanced robot capabilities in collision detection accuracy, contact-rich interaction simulation, and navigation through confined spaces. By dynamically adapting geometric representations to task requirements, robots can now exploit their physical embodiment as an active resource rather than an inflexible parameter, opening new frontiers for manipulation in environments where physical form must continuously balance precision with computational tractability.",
      "authors": [
        "Nataliya Nechyporenko",
        "Yutong Zhang",
        "Sean Campbell",
        "Alessandro Roncone"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:41:35+00:00",
          "link": "https://arxiv.org/abs/2507.14061v1",
          "size": "8464kb",
          "version": "v1"
        }
      ],
      "title": "MorphIt: Flexible Spherical Approximation of Robot Morphology for Representation-driven Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14061",
        "HTML": "https://arxiv.org/html/2507.14061v1",
        "PDF": "https://arxiv.org/pdf/2507.14061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces an algorithm for robot morphology optimization using spherical approximations. It doesn't pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14063",
      "abstract": "As AI systems take on collaborative roles, they must reason about shared goals and beliefs-not just generate fluent language. The Rational Speech Act (RSA) framework offers a principled approach to pragmatic reasoning, but existing extensions face challenges in scaling to multi-turn, collaborative scenarios. In this paper, we introduce Collaborative Rational Speech Act (CRSA), an information-theoretic (IT) extension of RSA that models multi-turn dialog by optimizing a gain function adapted from rate-distortion theory. This gain is an extension of the gain model that is maximized in the original RSA model but takes into account the scenario in which both agents in a conversation have private information and produce utterances conditioned on the dialog. We demonstrate the effectiveness of CRSA on referential games and template-based doctor-patient dialogs in the medical domain. Empirical results show that CRSA yields more consistent, interpretable, and collaborative behavior than existing baselines-paving the way for more pragmatic and socially aware language agents.",
      "authors": [
        "Lautaro Estienne",
        "Gabriel Ben Zenou",
        "Nona Naderi",
        "Jackie Cheung",
        "Pablo Piantanida"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:42:22+00:00",
          "link": "https://arxiv.org/abs/2507.14063v1",
          "size": "9195kb",
          "version": "v1"
        }
      ],
      "title": "Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14063",
        "HTML": "https://arxiv.org/html/2507.14063v1",
        "PDF": "https://arxiv.org/pdf/2507.14063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents the Collaborative Rational Speech Act framework for dialog systems. It focuses on pragmatic reasoning in dialogue rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14064",
      "abstract": "In this paper, we apply the Clique Lov\\'asz Local Lemma to provide sufficient conditions on memory and lifting degree for removing certain harmful combinatorial structures in spatially-coupled (SC) codes that negatively impact decoding performance. Additionally, we present, for the first time, a constructive algorithm based on the Moser-Tardos algorithm that ensures predictable performance. Furthermore, leveraging the properties of LLL-distribution and M-T-distribution, we establish the dependencies among the harmful structures during the construction process. We provide upper bounds on the probability change of remaining harmful structures after eliminating some of them. In particular, the elimination of 4-cycles increases the probability of 6-cycles becoming active by at most a factor of $e^{8/3}$.",
      "authors": [
        "Lei Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:42:24+00:00",
          "link": "https://arxiv.org/abs/2507.14064v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "Bounds and Constructions of High-Memory Spatially-Coupled Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14064",
        "HTML": "https://arxiv.org/html/2507.14064v1",
        "PDF": "https://arxiv.org/pdf/2507.14064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with spatially-coupled codes and their decoding performance, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14066",
      "abstract": "Multi-objective reinforcement learning (MORL) is a structured approach for optimizing tasks with multiple objectives. However, it often relies on pre-defined reward functions, which can be hard to design for balancing conflicting goals and may lead to oversimplification. Preferences can serve as more flexible and intuitive decision-making guidance, eliminating the need for complicated reward design. This paper introduces preference-based MORL (Pb-MORL), which formalizes the integration of preferences into the MORL framework. We theoretically prove that preferences can derive policies across the entire Pareto frontier. To guide policy optimization using preferences, our method constructs a multi-objective reward model that aligns with the given preferences. We further provide theoretical proof to show that optimizing this reward model is equivalent to training the Pareto optimal policy. Extensive experiments in benchmark multi-objective tasks, a multi-energy management task, and an autonomous driving task on a multi-line highway show that our method performs competitively, surpassing the oracle method, which uses the ground truth reward function. This highlights its potential for practical applications in complex real-world systems.",
      "authors": [
        "Ni Mu",
        "Yao Luan",
        "Qing-Shan Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:43:04+00:00",
          "link": "https://arxiv.org/abs/2507.14066v1",
          "size": "1220kb",
          "version": "v1"
        }
      ],
      "title": "Preference-based Multi-Objective Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14066",
        "HTML": "https://arxiv.org/html/2507.14066v1",
        "PDF": "https://arxiv.org/pdf/2507.14066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on preference-based multi-objective reinforcement learning, which is not directly related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14067",
      "abstract": "Vision-language models demand watermarking solutions that protect intellectual property without compromising multimodal coherence. Existing text watermarking methods disrupt visual-textual alignment through biased token selection and static strategies, leaving semantic-critical concepts vulnerable. We propose VLA-Mark, a vision-aligned framework that embeds detectable watermarks while preserving semantic fidelity through cross-modal coordination. Our approach integrates multiscale visual-textual alignment metrics, combining localized patch affinity, global semantic coherence, and contextual attention patterns, to guide watermark injection without model retraining. An entropy-sensitive mechanism dynamically balances watermark strength and semantic preservation, prioritizing visual grounding during low-uncertainty generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than conventional methods, with near-perfect detection (98.8% AUC). The framework demonstrates 96.1\\% attack resilience against attacks such as paraphrasing and synonym substitution, while maintaining text-visual consistency, establishing new standards for quality-preserving multimodal watermarking",
      "authors": [
        "Shuliang Liu",
        "Qi Zheng",
        "Jesse Jiaxi Xu",
        "Yibo Yan",
        "He Geng",
        "Aiwei Liu",
        "Peijie Jiang",
        "Jia Liu",
        "Yik-Cheung Tam",
        "and Xuming Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:44:41+00:00",
          "link": "https://arxiv.org/abs/2507.14067v1",
          "size": "396kb",
          "version": "v1"
        }
      ],
      "title": "VLA-Mark: A cross modal watermark for large vision-language alignment model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14067",
        "HTML": "https://arxiv.org/html/2507.14067v1",
        "PDF": "https://arxiv.org/pdf/2507.14067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses watermarking for vision-language models, which pertains to protecting intellectual property rather than contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14069",
      "abstract": "The convergence of artificial intelligence and edge computing has spurred growing interest in enabling intelligent services directly on resource-constrained devices. While traditional deep learning models require significant computational resources and centralized data management, the resulting latency, bandwidth consumption, and privacy concerns have exposed critical limitations in cloud-centric paradigms. Brain-inspired computing, particularly Spiking Neural Networks (SNNs), offers a promising alternative by emulating biological neuronal dynamics to achieve low-power, event-driven computation. This survey provides a comprehensive overview of Edge Intelligence based on SNNs (EdgeSNNs), examining their potential to address the challenges of on-device learning, inference, and security in edge scenarios. We present a systematic taxonomy of EdgeSNN foundations, encompassing neuron models, learning algorithms, and supporting hardware platforms. Three representative practical considerations of EdgeSNN are discussed in depth: on-device inference using lightweight SNN models, resource-aware training and updating under non-stationary data conditions, and secure and privacy-preserving issues. Furthermore, we highlight the limitations of evaluating EdgeSNNs on conventional hardware and introduce a dual-track benchmarking strategy to support fair comparisons and hardware-aware optimization. Through this study, we aim to bridge the gap between brain-inspired learning and practical edge deployment, offering insights into current advancements, open challenges, and future research directions. To the best of our knowledge, this is the first dedicated and comprehensive survey on EdgeSNNs, providing an essential reference for researchers and practitioners working at the intersection of neuromorphic computing and edge intelligence.",
      "authors": [
        "Shuiguang Deng",
        "Di Yu",
        "Changze Lv",
        "Xin Du",
        "Linshan Jiang",
        "Xiaofan Zhao",
        "Wentao Tong",
        "Xiaoqing Zheng",
        "Weijia Fang",
        "Peng Zhao",
        "Gang Pan",
        "Schahram Dustdar",
        "Albert Y. Zomaya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:47:52+00:00",
          "link": "https://arxiv.org/abs/2507.14069v1",
          "size": "7259kb",
          "version": "v1"
        }
      ],
      "title": "Edge Intelligence with Spiking Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14069",
        "HTML": "https://arxiv.org/html/2507.14069v1",
        "PDF": "https://arxiv.org/pdf/2507.14069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey examines Edge Intelligence with Spiking Neural Networks (SNNs), centering on edge computing and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14070",
      "abstract": "We study segmented burst-deletion channels motivated by the observation that synchronization errors commonly occur in a bursty manner in real-world settings. In this channel model, transmitted sequences are implicitly divided into non-overlapping segments, each of which may experience at most one burst of deletions. In this paper, we develop error correction codes for segmented burst-deletion channels over arbitrary alphabets under the assumption that each segment may contain only one burst of t-deletions. The main idea is to encode the input subsequence corresponding to each segment using existing one-burst deletion codes, with additional constraints that enable the decoder to identify segment boundaries during the decoding process from the received sequence. The resulting codes achieve redundancy that scales as O(log b), where b is the length of each segment.",
      "authors": [
        "Yajuan Liu and Tolga M. Duman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:49:22+00:00",
          "link": "https://arxiv.org/abs/2507.14070v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "Error Correcting Codes for Segmented Burst-Deletion Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14070",
        "HTML": "https://arxiv.org/html/2507.14070v1",
        "PDF": "https://arxiv.org/pdf/2507.14070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents error-correcting codes for burst-deletion channels, a topic unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14073",
      "abstract": "The paper concentrates on the analysis of the region of attraction (ROA) for unknown autonomous dynamical systems. The aim is to explore a data-driven approach based on moment-sum-of-squares (SoS) hierarchy, which enables novel RoA outer approximations despite the reduced information on the structure of the dynamics. The main contribution of this work is bypassing the system model and, consequently, the recurring constraint on its polynomial structure. Numerical experimentation showcases the influence of data on learned approximating sets, offering a promising outlook on the potential of this method.",
      "authors": [
        "Oumayma Khattabi",
        "Matteo Tacchi-B\\'enard",
        "Sorin Olaru"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:50:31+00:00",
          "link": "https://arxiv.org/abs/2507.14073v1",
          "size": "1018kb",
          "version": "v1"
        }
      ],
      "title": "Convex computation of regions of attraction from data using Sums-of-Squares programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14073",
        "HTML": "https://arxiv.org/html/2507.14073v1",
        "PDF": "https://arxiv.org/pdf/2507.14073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on convex computation for regions of attraction in dynamical systems using Sums-of-Squares programming, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14077",
      "abstract": "Artificial intelligence (AI) algorithms are a critical part of state-of-the-art digital health technology for diabetes management. Yet, access to large high-quality datasets is creating barriers that impede development of robust AI solutions. To accelerate development of transparent, reproducible, and robust AI solutions, we present Glucose-ML, a collection of 10 publicly available diabetes datasets, released within the last 7 years (i.e., 2018 - 2025). The Glucose-ML collection comprises over 300,000 days of continuous glucose monitor (CGM) data with a total of 38 million glucose samples collected from 2500+ people across 4 countries. Participants include persons living with type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support researchers and innovators with using this rich collection of diabetes datasets, we present a comparative analysis to guide algorithm developers with data selection. Additionally, we conduct a case study for the task of blood glucose prediction - one of the most common AI tasks within the field. Through this case study, we provide a benchmark for short-term blood glucose prediction across all 10 publicly available diabetes datasets within the Glucose-ML collection. We show that the same algorithm can have significantly different prediction results when developed/evaluated with different datasets. Findings from this study are then used to inform recommendations for developing robust AI solutions within the diabetes or broader health domain. We provide direct links to each longitudinal diabetes dataset in the Glucose-ML collection and openly provide our code.",
      "authors": [
        "Temiloluwa Prioleau",
        "Baiying Lu",
        "Yanjun Cui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:53:05+00:00",
          "link": "https://arxiv.org/abs/2507.14077v1",
          "size": "831kb",
          "version": "v1"
        }
      ],
      "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14077",
        "HTML": "https://arxiv.org/html/2507.14077v1",
        "PDF": "https://arxiv.org/pdf/2507.14077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on providing datasets for diabetes management AI solutions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14079",
      "abstract": "Progress notes are among the most clinically meaningful artifacts in an Electronic Health Record (EHR), offering temporally grounded insights into a patient's evolving condition, treatments, and care decisions. Despite their importance, they are severely underrepresented in large-scale EHR datasets. For instance, in the widely used Medical Information Mart for Intensive Care III (MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress notes, leaving gaps in longitudinal patient narratives. In contrast, the dataset contains a diverse array of other note types, each capturing different aspects of care.\n  We present DENSE (Documenting Evolving Progress Notes from Scattered Evidence), a system designed to align with clinical documentation workflows by simulating how physicians reference past encounters while drafting progress notes. The system introduces a fine-grained note categorization and a temporal alignment mechanism that organizes heterogeneous notes across visits into structured, chronological inputs. At its core, DENSE leverages a clinically informed retrieval strategy to identify temporally and semantically relevant content from both current and prior visits. This retrieved evidence is used to prompt a large language model (LLM) to generate clinically coherent and temporally aware progress notes.\n  We evaluate DENSE on a curated cohort of patients with multiple visits and complete progress note documentation. The generated notes demonstrate strong longitudinal fidelity, achieving a temporal alignment ratio of $1.089$, surpassing the continuity observed in original notes. By restoring narrative coherence across fragmented documentation, our system supports improved downstream tasks such as summarization, predictive modeling, and clinical decision support, offering a scalable solution for LLM-driven note synthesis in real-world healthcare settings.",
      "authors": [
        "Garapati Keerthana",
        "Manik Gupta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:00:27+00:00",
          "link": "https://arxiv.org/abs/2507.14079v1",
          "size": "1033kb",
          "version": "v1"
        }
      ],
      "title": "DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14079",
        "HTML": "https://arxiv.org/html/2507.14079v1",
        "PDF": "https://arxiv.org/pdf/2507.14079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the generation of clinical progress notes using LLMs with a retrieval strategy aligned with clinical documentation workflows. However, its primary focus is on note generation and evaluation rather than the creation or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14080",
      "abstract": "Ensuring liveness in a decentralized system, such as PBFT, is critical, because there may not be any single administrator that can restart the system if it encounters a liveness bug. At the same time, liveness is challenging to achieve because any single participant could be malicious, and yet the overall system must make forward progress. While verification is a promising approach for ensuring the absence of bugs, no prior work has been able to verify liveness for an executable implementation of PBFT.\n  Shipwright is a verification framework for proving correctness and liveness of distributed systems where some participants might be malicious. Shipwright introduces three techniques that enable formal reasoning about decentralized settings with malicious participants, allow developers to decompose their system and proof in a modular fashion into sub-protocols and sub-proofs, and support sound reasoning about cryptographic signatures that may be embedded in messages. We used Shipwright to implement and verify an initial prototype of agreement on a single log entry in PBFT (with a few limitations) and translate it to an executable implementation in Go. We experimentally demonstrate its operation and liveness both in the common case and in several failure scenarios.",
      "authors": [
        "Derek Leung",
        "Nickolai Zeldovich",
        "Frans Kaashoek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:03:07+00:00",
          "link": "https://arxiv.org/abs/2507.14080v1",
          "size": "591kb",
          "version": "v1"
        }
      ],
      "title": "Shipwright: Proving liveness of distributed systems with Byzantine participants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14080",
        "HTML": "https://arxiv.org/html/2507.14080v1",
        "PDF": "https://arxiv.org/pdf/2507.14080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the verification of liveness in distributed systems, specifically with Byzantine participants, and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14082",
      "abstract": "The Fifteenth International Workshop on Non-Classical Models of Automata and Applications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025, organized by the Department of Computer Science at Loughborough University and co-located with the 26th International Conference on Descriptional Complexity of Formal Systems (DCFS 2025, 22-24 July).\n  The NCMA workshop series was established in 2009 as an annual event for researchers working on non-classical and classical models of automata, grammars or related devices. Such models are investigated both as theoretical models and as formal models for applications from various points of view. The goal of the NCMA workshop series is to exchange and develop novel ideas in order to gain deeper and interdisciplinary coverage of this particular area that may foster new insights and substantial progress.",
      "authors": [
        "Nelma Moreira (Universidade do Porto)",
        "Luca Prigioniero (Loughborough University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:05:57+00:00",
          "link": "https://arxiv.org/abs/2507.14082v1",
          "size": "3kb",
          "version": "v1"
        }
      ],
      "title": "Proceedings of the 15th International Workshop on Non-Classical Models of Automata and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14082",
        "PDF": "https://arxiv.org/pdf/2507.14082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The proceedings of a workshop on non-classical models of automata do not address any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14083",
      "abstract": "Advancements in deep learning have improved anomaly detection in surveillance videos, yet they raise urgent privacy concerns due to the collection of sensitive human data. In this paper, we present a comprehensive analysis of anomaly detection performance under four human anonymization techniques, including blurring, masking, encryption, and avatar replacement, applied to the UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU, BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method responds to different obfuscation techniques. Experimental results demonstrate that anomaly detection remains viable under anonymized data and is dependent on the algorithmic design and the learning strategy. For instance, under certain anonymization patterns, such as encryption and masking, some models inadvertently achieve higher AUC performance compared to raw data, due to the strong responsiveness of their algorithmic components to these noise patterns. These results highlight the algorithm-specific sensitivities to anonymization and emphasize the trade-off between preserving privacy and maintaining detection utility. Furthermore, we compare these conventional anonymization techniques with the emerging privacy-by-design solutions, highlighting an often overlooked trade-off between robust privacy protection and utility flexibility. Through comprehensive experiments and analyses, this study provides a compelling benchmark and insights into balancing human privacy with the demands of anomaly detection.",
      "authors": [
        "Sara Abdulaziz and Egor Bondarev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:06:03+00:00",
          "link": "https://arxiv.org/abs/2507.14083v1",
          "size": "13951kb",
          "version": "v1"
        }
      ],
      "title": "Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14083",
        "HTML": "https://arxiv.org/html/2507.14083v1",
        "PDF": "https://arxiv.org/pdf/2507.14083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates human anonymization effects on video anomaly detection, focusing on privacy concerns and anomaly detection, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14084",
      "abstract": "Humans have a selective memory, remembering relevant episodes and forgetting the less relevant information. Possessing awareness of event memorability for a user could help intelligent systems in more accurate user modelling, especially for such applications as meeting support systems, memory augmentation, and meeting summarisation. Emotion recognition has been widely studied, since emotions are thought to signal moments of high personal relevance to users. The emotional experience of situations and their memorability have traditionally been considered to be closely tied to one another: moments that are experienced as highly emotional are considered to also be highly memorable. This relationship suggests that emotional annotations could serve as proxies for memorability. However, existing emotion recognition systems rely heavily on third-party annotations, which may not accurately represent the first-person experience of emotional relevance and memorability. This is why, in this study, we empirically examine the relationship between perceived group emotions (Pleasure-Arousal) and group memorability in the context of conversational interactions. Our investigation involves continuous time-based annotations of both emotions and memorability in dynamic, unstructured group settings, approximating conditions of real-world conversational AI applications such as online meeting support systems. Our results show that the observed relationship between affect and memorability annotations cannot be reliably distinguished from what might be expected under random chance. We discuss the implications of this surprising finding for the development and applications of Affective Computing technology. In addition, we contextualise our findings in broader discourses in the Affective Computing and point out important targets for future research efforts.",
      "authors": [
        "Maria Tsfasman",
        "Ramin Ghorbani",
        "Catholijn M. Jonker",
        "Bernd Dudzik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:06:34+00:00",
          "link": "https://arxiv.org/abs/2507.14084v1",
          "size": "2800kb",
          "version": "v1"
        }
      ],
      "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14084",
        "HTML": "https://arxiv.org/html/2507.14084v1",
        "PDF": "https://arxiv.org/pdf/2507.14084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the relationship between emotions and memorability in the context of affective computing. It does not address LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14088",
      "abstract": "Real-time human-artificial intelligence (AI) collaboration is crucial yet challenging, especially when AI agents must adapt to diverse and unseen human behaviors in dynamic scenarios. Existing large language model (LLM) agents often fail to accurately model the complex human mental characteristics such as domain intentions, especially in the absence of direct communication. To address this limitation, we propose a novel dual process multi-scale theory of mind (DPMT) framework, drawing inspiration from cognitive science dual process theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM) module to facilitate robust human partner modeling through mental characteristic reasoning. Experimental results demonstrate that DPMT significantly enhances human-AI collaboration, and ablation studies further validate the contributions of our multi-scale ToM in the slow system.",
      "authors": [
        "Xiyun Li",
        "Yining Ding",
        "Yuhua Jiang",
        "Yunlong Zhao",
        "Runpeng Xie",
        "Shuang Xu",
        "Yuanhua Ni",
        "Yiqin Yang",
        "Bo Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:13:21+00:00",
          "link": "https://arxiv.org/abs/2507.14088v1",
          "size": "1649kb",
          "version": "v1"
        }
      ],
      "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14088",
        "HTML": "https://arxiv.org/html/2507.14088v1",
        "PDF": "https://arxiv.org/pdf/2507.14088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a dual process multi-scale theory of mind (ToM) framework for human-AI collaboration. It relates to modeling complex human mental characteristics and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14089",
      "abstract": "In this paper, we present an efficient massively parallel approximation algorithm for the $k$-means problem. Specifically, we provide an MPC algorithm that computes a constant-factor approximation to an arbitrary $k$-means instance in $O(\\log\\log n \\cdot \\log\\log\\log n)$ rounds. The algorithm uses $O(n^\\sigma)$ bits of memory per machine, where $\\sigma > 0$ is a constant that can be made arbitrarily small. The global memory usage is $O(n^{1+\\varepsilon})$ bits for an arbitrarily small constant $\\varepsilon > 0$, and is thus only slightly superlinear. Recently, Czumaj, Gao, Jiang, Krauthgamer, and Vesel\\'{y} showed that a constant-factor bicriteria approximation can be computed in $O(1)$ rounds in the MPC model. However, our algorithm is the first constant-factor approximation for the general $k$-means problem that runs in $o(\\log n)$ rounds in the MPC model.\n  Our approach builds upon the foundational framework of Jain and Vazirani. The core component of our algorithm is a constant-factor approximation for the related facility location problem. While such an approximation was already achieved in constant time in the work of Czumaj et al.\\ mentioned above, our version additionally satisfies the so-called Lagrangian Multiplier Preserving (LMP) property. This property enables the transformation of a facility location approximation into a comparably good $k$-means approximation.",
      "authors": [
        "Vincent Cohen-Addad",
        "Fabian Kuhn",
        "Zahra Parsaeian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:13:36+00:00",
          "link": "https://arxiv.org/abs/2507.14089v1",
          "size": "84kb",
          "version": "v1"
        }
      ],
      "title": "An Efficient Massively Parallel Constant-Factor Approximation Algorithm for the $k$-Means Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14089",
        "HTML": "https://arxiv.org/html/2507.14089v1",
        "PDF": "https://arxiv.org/pdf/2507.14089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents an algorithm for the $k$-means problem within a parallel computing context. It does not connect to LLM training data processing or provide any data-related techniques for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14093",
      "abstract": "Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment decisions depend on precise Cobb angle measurement. Manual assessment is time consuming and subject to inter observer variation. We conducted a retrospective, multi centre evaluation of a fully automated deep learning software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on 103 standing anteroposterior whole spine radiographs collected from ten hospitals. Two musculoskeletal radiologists independently measured each study and served as reference readers. Agreement between the AI and each radiologist was assessed with Bland Altman analysis, mean absolute error (MAE), root mean squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four grade severity classification. Against Radiologist 1 the AI achieved an MAE of 3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59). These results demonstrate that the proposed software reproduces expert level Cobb angle measurements and categorical grading across multiple centres, suggesting its utility for streamlining scoliosis reporting and triage in clinical workflows.",
      "authors": [
        "\\v{S}imon Kubov",
        "Simon Kl\\'i\\v{c}n\\'ik",
        "Jakub Dand\\'ar",
        "Zden\\v{e}k Straka",
        "Karol\\'ina Kvakov\\'a and Daniel Kvak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:21:53+00:00",
          "link": "https://arxiv.org/abs/2507.14093v1",
          "size": "6194kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14093",
        "HTML": "https://arxiv.org/html/2507.14093v1",
        "PDF": "https://arxiv.org/pdf/2507.14093"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study validates a deep learning model for scoliosis assessment in medical imaging. It does not focus on LLM training data processing or contribute to data processing methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14095",
      "abstract": "Multi-view multi-object association is a fundamental step in 3D reconstruction pipelines, enabling consistent grouping of object instances across multiple camera views. Existing methods often rely on appearance features or geometric constraints such as epipolar consistency. However, these approaches can fail when objects are visually indistinguishable or observations are corrupted by noise. We propose C-DOG, a training-free framework that serves as an intermediate module bridging object detection (or pose estimation) and 3D reconstruction, without relying on visual features. It combines connected delta-overlap graph modeling with epipolar geometry to robustly associate detections across views. Each 2D observation is represented as a graph node, with edges weighted by epipolar consistency. A delta-neighbor-overlap clustering step identifies strongly consistent groups while tolerating noise and partial connectivity. To further improve robustness, we incorporate Interquartile Range (IQR)-based filtering and a 3D back-projection error criterion to eliminate inconsistent observations. Extensive experiments on synthetic benchmarks demonstrate that C-DOG outperforms geometry-based baselines and remains robust under challenging conditions, including high object density, without visual features, and limited camera overlap, making it well-suited for scalable 3D reconstruction in real-world scenarios.",
      "authors": [
        "Yung-Hong Sun",
        "Ting-Hung Lin",
        "Jiangang Chen",
        "Hongrui Jiang",
        "Yu Hen Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:23:45+00:00",
          "link": "https://arxiv.org/abs/2507.14095v1",
          "size": "1796kb",
          "version": "v1"
        }
      ],
      "title": "C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected {\\delta}-Overlap Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14095",
        "HTML": "https://arxiv.org/html/2507.14095v1",
        "PDF": "https://arxiv.org/pdf/2507.14095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for multi-view multi-object association in 3D reconstruction. It does not relate to LLM training data processing or involve operations relevant to LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14096",
      "abstract": "Objective: Recent advances in language models have shown potential to adapt professional-facing biomedical literature to plain language, making it accessible to patients and caregivers. However, their unpredictability, combined with the high potential for harm in this domain, means rigorous evaluation is necessary. Our goals with this track were to stimulate research and to provide high-quality evaluation of the most promising systems.\n  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts (PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included complete, sentence-level, rewriting of abstracts (Task 1) as well as identifying and replacing difficult terms (Task 2). For automatic evaluation of Task 1, we developed a four-fold set of professionally-written references. Submissions for both Tasks 1 and 2 were provided extensive manual evaluation from biomedical experts.\n  Results: Twelve teams spanning twelve countries participated in the track, with models from multilayer perceptrons to large pretrained transformers. In manual judgments of Task 1, top-performing models rivaled human levels of factual accuracy and completeness, but not simplicity or brevity. Automatic, reference-based metrics generally did not correlate well with manual judgments. In Task 2, systems struggled with identifying difficult terms and classifying how to replace them. When generating replacements, however, LLM-based systems did well in manually judged accuracy, completeness, and simplicity, though not in brevity.\n  Conclusion: The PLABA track showed promise for using Large Language Models to adapt biomedical literature for the general public, while also highlighting their deficiencies and the need for improved automatic benchmarking tools.",
      "authors": [
        "Brian Ondov",
        "William Xia",
        "Kush Attal",
        "Ishita Unde",
        "Jerry He",
        "Hoa Dang",
        "Ian Soboroff",
        "Dina Demner-Fushman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:23:52+00:00",
          "link": "https://arxiv.org/abs/2507.14096v1",
          "size": "11277kb",
          "version": "v1"
        }
      ],
      "title": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14096",
        "HTML": "https://arxiv.org/html/2507.14096v1",
        "PDF": "https://arxiv.org/pdf/2507.14096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adapting biomedical abstracts to plain language using LLMs for readability, with no direct contributions to LLM training data processing operations like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14097",
      "abstract": "Human motion simulation (HMS) supports cost-effective evaluation of worker behavior, safety, and productivity in industrial tasks. However, existing methods often suffer from low motion fidelity. This study introduces Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and text-to-motion models to enhance simulation quality for physical tasks. G-AI-HMS tackles two key challenges: (1) translating task descriptions into motion-aware language using Large Language Models aligned with MotionGPT's training vocabulary, and (2) validating AI-enhanced motions against real human movements using computer vision. Posture estimation algorithms are applied to real-time videos to extract joint landmarks, and motion similarity metrics are used to compare them with AI-enhanced sequences. In a case study involving eight tasks, the AI-enhanced motions showed lower error than human created descriptions in most scenarios, performing better in six tasks based on spatial accuracy, four tasks based on alignment after pose normalization, and seven tasks based on overall temporal similarity. Statistical analysis showed that AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and temporal misalignment while retaining comparable posture accuracy.",
      "authors": [
        "Hari Iyer",
        "Neel Macwan",
        "Atharva Jitendra Hude",
        "Heejin Jeong",
        "Shenghan Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:24:50+00:00",
          "link": "https://arxiv.org/abs/2507.14097v1",
          "size": "4222kb",
          "version": "v1"
        }
      ],
      "title": "Generative AI-Driven High-Fidelity Human Motion Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14097",
        "HTML": "https://arxiv.org/html/2507.14097v1",
        "PDF": "https://arxiv.org/pdf/2507.14097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses generative AI for human motion simulation and does not address any aspects of LLM training data processing or related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14099",
      "abstract": "Autonomous motion planning is critical for efficient and safe underwater manipulation in dynamic marine environments. Current motion planning methods often fail to effectively utilize prior motion experiences and adapt to real-time uncertainties inherent in underwater settings. In this paper, we introduce an Adaptive Heuristic Motion Planner framework that integrates a Heuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning for autonomous underwater manipulation. Our approach employs the Probabilistic Roadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite cost function that accounts for distance, uncertainty, energy consumption, and execution time. By leveraging HMS, our framework significantly reduces the search space, thereby boosting computational performance and enabling real-time planning capabilities. Bayesian Networks are utilized to dynamically update uncertainty estimates based on real-time sensor data and environmental conditions, thereby refining the joint probability of path success. Through extensive simulations and real-world test scenarios, we showcase the advantages of our method in terms of enhanced performance and robustness. This probabilistic approach significantly advances the capability of autonomous underwater robots, ensuring optimized motion planning in the face of dynamic marine challenges.",
      "authors": [
        "Markus Buchholz",
        "Ignacio Carlucho",
        "Michele Grimaldi",
        "Maria Koskinopoulou",
        "Yvan R. Petillot"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:25:54+00:00",
          "link": "https://arxiv.org/abs/2507.14099v1",
          "size": "3804kb",
          "version": "v1"
        }
      ],
      "title": "Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14099",
        "HTML": "https://arxiv.org/html/2507.14099v1",
        "PDF": "https://arxiv.org/pdf/2507.14099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents methodologies for autonomous underwater manipulation and motion planning, unrelated to LLM training data processing tasks like dataset creation or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14101",
      "abstract": "We introduce 'project-connex' tree-width as a measure of tractability for counting and aggregate conjunctive queries over semirings with 'group-by' projection (also known as 'AJAR' or 'FAQ' queries). This elementary measure allows to obtain comparable complexity bounds to the ones obtained by previous structural conditions tailored for efficient evaluation of semiring aggregate queries, enumeration algorithms of conjunctive queries, and tractability of counting answers to conjunctive queries.\n  Project-connex tree decompositions are defined as the natural extension of the known notion of 'free-connex' decompositions. They allow for a unified, simple and intuitive algorithmic manipulation for evaluation of aggregate queries and explain some existing tractability results on conjunctive query enumeration, counting conjunctive query evaluation, and evaluation of semiring aggregate queries. Using this measure we also recover results relating tractable classes of counting conjunctive queries and bounded free-connex tree-width, or the constant-time delay enumeration of semiring aggregate queries over bounded project-connex classes. We further show that project-connex tree decompositions can be obtained via algorithms for computing classical tree decompositions.",
      "authors": [
        "Diego Figueira and Cibele Freire"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:30:14+00:00",
          "link": "https://arxiv.org/abs/2507.14101v1",
          "size": "6111kb",
          "version": "v1"
        }
      ],
      "title": "Project-connex Decompositions and Tractability of Aggregate Group-by Conjunctive Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14101",
        "PDF": "https://arxiv.org/pdf/2507.14101"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduced focuses on query tractability in databases, which does not pertain to LLM training data processing, such as dataset creation or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14107",
      "abstract": "Bridge maintenance and safety are essential for transportation authorities, and Non-Destructive Evaluation (NDE) techniques are critical to assessing structural integrity. However, interpreting NDE data can be time-consuming and requires expertise, potentially delaying decision-making. Recent advancements in Large Language Models (LLMs) offer new ways to automate and improve this analysis. This pilot study introduces a holistic assessment of LLM capabilities for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in providing detailed bridge condition analyses. It establishes a framework for integrating LLMs into bridge inspection workflows, indicating that LLM-assisted analysis can enhance efficiency without compromising accuracy. In this study, several LLMs are explored with prompts specifically designed to enhance the quality of image descriptions, which are applied to interpret five different NDE contour maps obtained through technologies for assessing bridge conditions. Each LLM model is evaluated based on its ability to produce detailed descriptions, identify defects, provide actionable recommendations, and demonstrate overall accuracy. The research indicates that four of the nine models provide better image descriptions, effectively covering a wide range of topics related to the bridge's condition. The outputs from these four models are summarized using five different LLMs to form a comprehensive overview of the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more effective summaries. The findings suggest that LLMs have the potential to significantly improve efficiency and accuracy. This pilot study presents an innovative approach that leverages LLMs for image captioning in parallel and summarization, enabling faster decision-making in bridge maintenance and enhancing infrastructure management and safety assessments.",
      "authors": [
        "Viraj Nishesh Darji",
        "Callie C. Liao",
        "Duoduo Liao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:39:03+00:00",
          "link": "https://arxiv.org/abs/2507.14107v1",
          "size": "1186kb",
          "version": "v1"
        }
      ],
      "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14107",
        "HTML": "https://arxiv.org/html/2507.14107v1",
        "PDF": "https://arxiv.org/pdf/2507.14107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for interpreting NDE contour maps in bridge condition assessment, which is related to image captioning and condition analysis, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14109",
      "abstract": "Radio frequency (RF) fingerprinting, which extracts unique hardware imperfections of radio devices, has emerged as a promising physical-layer device identification mechanism in zero trust architectures and beyond 5G networks. In particular, deep learning (DL) methods have demonstrated state-of-the-art performance in this domain. However, existing approaches have primarily focused on enhancing system robustness against temporal and spatial variations in wireless environments, while the security vulnerabilities of these DL-based approaches have often been overlooked. In this work, we systematically investigate the security risks of DL-based RF fingerprinting systems through an adversarial-driven experimental analysis. We observe a consistent misclassification behavior for DL models under domain shifts, where a device is frequently misclassified as another specific one. Our analysis based on extensive real-world experiments demonstrates that this behavior can be exploited as an effective backdoor to enable external attackers to intrude into the system. Furthermore, we show that training DL models on raw received signals causes the models to entangle RF fingerprints with environmental and signal-pattern features, creating additional attack vectors that cannot be mitigated solely through post-processing security methods such as confidence thresholds.",
      "authors": [
        "Xinyu Cao",
        "Bimal Adhikari",
        "Shangqing Zhao",
        "Jingxian Wu",
        "Yanjun Pan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:42:20+00:00",
          "link": "https://arxiv.org/abs/2507.14109v1",
          "size": "473kb",
          "version": "v1"
        }
      ],
      "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14109",
        "HTML": "https://arxiv.org/html/2507.14109v1",
        "PDF": "https://arxiv.org/pdf/2507.14109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses adversarial-driven experimental studies on RF fingerprinting using deep learning, focusing on challenges in robustness and security, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14111",
      "abstract": "The exponential growth in demand for GPU computing resources, driven by the rapid advancement of Large Language Models, has created an urgent need for automated CUDA optimization strategies. While recent advances in LLMs show promise for code generation, current SOTA models (e.g. R1, o1) achieve low success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an automated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task: trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250 CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the model also demonstrates excellent portability across GPU architectures, achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40, x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100. Beyond these benchmark results, CUDA-L1 demonstrates several remarkable properties: 1) Discovers a variety of CUDA optimization techniques and learns to combine them strategically to achieve optimal performance; 2) Uncovers fundamental principles of CUDA optimization; 3) Identifies non-obvious performance bottlenecks and rejects seemingly beneficial optimizations that harm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can transform an initially poor-performing LLM into an effective CUDA optimizer through speedup-based reward signals alone, without human expertise or domain knowledge. More importantly, the trained RL model extend the acquired reasoning abilities to new kernels. This paradigm opens possibilities for automated optimization of CUDA operations, and holds promise to substantially promote GPU efficiency and alleviate the rising pressure on GPU computing resources.",
      "authors": [
        "Xiaoya Li",
        "Xiaofei Sun",
        "Albert Wang",
        "Jiwei Li and Chris Shum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:43:56+00:00",
          "link": "https://arxiv.org/abs/2507.14111v1",
          "size": "7482kb",
          "version": "v1"
        }
      ],
      "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14111",
        "PDF": "https://arxiv.org/pdf/2507.14111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on CUDA optimization using contrastive reinforcement learning to improve GPU resource efficiency, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14114",
      "abstract": "We introduce the poly-streaming model, a generalization of streaming models of computation in which $k$ processors process $k$ data streams containing a total of $N$ items. The algorithm is allowed $O\\left(f(k)\\cdot M_1\\right)$ space, where $M_1$ is either $o\\left(N\\right)$ or the space bound for a sequential streaming algorithm. Processors may communicate as needed. Algorithms are assessed by the number of passes, per-item processing time, total runtime, space usage, communication cost, and solution quality.\n  We design a single-pass algorithm in this model for approximating the maximum weight matching (MWM) problem. Given $k$ edge streams and a parameter $\\varepsilon > 0$, the algorithm computes a $\\left(2+\\epsilon\\right)$-approximate MWM. We analyze its performance in a shared-memory parallel setting: for any constant $\\varepsilon > 0$, it runs in time $\\widetilde{O}\\left(L_{\\max}+n\\right)$, where $n$ is the number of vertices and $L_{\\max}$ is the maximum stream length. It supports $O\\left(1\\right)$ per-edge processing time using $\\widetilde{O}\\left(k\\cdot n\\right)$ space. We further generalize the design to hierarchical architectures, in which $k$ processors are partitioned into $r$ groups, each with its own shared local memory. The total intergroup communication is $\\widetilde{O}\\left(r \\cdot n\\right)$ bits, while all other performance guarantees are preserved.\n  We evaluate the algorithm on a shared-memory system using graphs with trillions of edges. It achieves substantial speedups as $k$ increases and produces matchings with weights significantly exceeding the theoretical guarantee. On our largest test graph, it reduces runtime by nearly two orders of magnitude and memory usage by five orders of magnitude compared to an offline algorithm.",
      "authors": [
        "Ahammed Ullah",
        "S. M. Ferdous",
        "Alex Pothen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:44:40+00:00",
          "link": "https://arxiv.org/abs/2507.14114v1",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "title": "Weighted Matching in a Poly-Streaming Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14114",
        "PDF": "https://arxiv.org/pdf/2507.14114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an algorithm for weighted matching in a poly-streaming model, which deals with computational model innovations rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14117",
      "abstract": "Extreme weather variations and the increasing unpredictability of load behavior make it difficult to determine power grid dispatches that are robust to uncertainties. While machine learning (ML) methods have improved the ability to model uncertainty caused by loads and renewables, accurately integrating these forecasts and their sensitivities into steady-state analyses and decision-making strategies remains an open challenge. Toward this goal, we present a generalized methodology that seamlessly embeds ML-based forecasting engines within physics-based power flow and grid optimization tools. By coupling physics-based grid modeling with black-box ML methods, we accurately capture the behavior and sensitivity of loads and weather events by directly integrating the inputs and outputs of trained ML forecasting models into the numerical methods of power flow and grid optimization. Without fitting surrogate load models, our approach obtains the sensitivities directly from data to accurately predict the response of forecasted devices to changes in the grid. Our approach combines the sensitivities of forecasted devices attained via backpropagation and the sensitivities of physics-defined grid devices. We demonstrate the efficacy of our method by showcasing improvements in sensitivity calculations and leveraging them to design a robust power dispatch that improves grid reliability under stochastic weather events. Our approach enables the computation of system sensitivities to exogenous factors which supports broader analyses that improve grid reliability in the presence of load variability and extreme weather conditions.",
      "authors": [
        "Aayushya Agarwal",
        "Larry Pileggi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:48:04+00:00",
          "link": "https://arxiv.org/abs/2507.14117v1",
          "size": "2041kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Forecasting Models Within Steady-State Analysis and Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14117",
        "HTML": "https://arxiv.org/html/2507.14117v1",
        "PDF": "https://arxiv.org/pdf/2507.14117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating machine learning models within power grid dispatch optimization and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14119",
      "abstract": "Recent advances in generative modeling enable image editing assistants that follow natural language instructions without additional user input. Their supervised training requires millions of triplets: original image, instruction, edited image. Yet mining pixel-accurate examples is hard. Each edit must affect only prompt-specified regions, preserve stylistic coherence, respect physical plausibility, and retain visual appeal. The lack of robust automated edit-quality metrics hinders reliable automation at scale. We present an automated, modular pipeline that mines high-fidelity triplets across domains, resolutions, instruction complexities, and styles. Built on public generative models and running without human intervention, our system uses a task-tuned Gemini validator to score instruction adherence and aesthetics directly, removing any need for segmentation or grounding models. Inversion and compositional bootstrapping enlarge the mined set by approximately 2.2x, enabling large-scale high-fidelity training data. By automating the most repetitive annotation steps, the approach allows a new scale of training without human labeling effort. To democratize research in this resource-intensive area, we release NHR-Edit: an open dataset of 358k high-quality triplets. In the largest cross-dataset evaluation, it surpasses all public alternatives. We also release Bagel-NHR-Edit, an open-source fine-tuned Bagel model, which achieves state-of-the-art metrics in our experiments.",
      "authors": [
        "Maksim Kuprashevich and Grigorii Alekseenko and Irina Tolstykh and Georgii Fedorov and Bulat Suleimanov and Vladimir Dokholyan and Aleksandr Gordeev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:50:00+00:00",
          "link": "https://arxiv.org/abs/2507.14119v1",
          "size": "38067kb",
          "version": "v1"
        }
      ],
      "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14119",
        "PDF": "https://arxiv.org/pdf/2507.14119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper presents a dataset (NHR-Edit) for training image editing models with natural language instructions, its primary focus is on image editing rather than LLM training data processing. However, the dataset creation and processing aspects have some relevance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14121",
      "abstract": "Kolmogorov Arnold Networks (KANs) are recent architectural advancement in neural computation that offer a mathematically grounded alternative to standard neural networks. This study presents an empirical evaluation of KANs in context of class imbalanced classification, using ten benchmark datasets. We observe that KANs can inherently perform well on raw imbalanced data more effectively than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However, conventional imbalance strategies fundamentally conflict with KANs mathematical structure as resampling and focal loss implementations significantly degrade KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from prohibitive computational costs without proportional performance gains. Statistical validation confirms that MLPs with imbalance techniques achieve equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs. These findings reveal that KANs represent a specialized solution for raw imbalanced data where resources permit. But their severe performance-resource tradeoffs and incompatibility with standard resampling techniques currently limits practical deployment. We identify critical research priorities as developing KAN specific architectural modifications for imbalance learning, optimizing computational efficiency, and theoretical reconciling their conflict with data augmentation. This work establishes foundational insights for next generation KAN architectures in imbalanced classification scenarios.",
      "authors": [
        "Pankaj Yadav",
        "Vivek Vijay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:50:51+00:00",
          "link": "https://arxiv.org/abs/2507.14121v1",
          "size": "1171kb",
          "version": "v1"
        }
      ],
      "title": "Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14121",
        "HTML": "https://arxiv.org/html/2507.14121v1",
        "PDF": "https://arxiv.org/pdf/2507.14121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates Kolmogorov Arnold Networks for imbalanced data in classification tasks and does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14126",
      "abstract": "Temporal causal representation learning is a powerful tool for uncovering complex patterns in observational studies, which are often represented as low-dimensional time series. However, in many real-world applications, data are high-dimensional with varying input lengths and naturally take the form of irregular tensors. To analyze such data, irregular tensor decomposition is critical for extracting meaningful clusters that capture essential information. In this paper, we focus on modeling causal representation learning based on the transformed information. First, we present a novel causal formulation for a set of latent clusters. We then propose CaRTeD, a joint learning framework that integrates temporal causal representation learning with irregular tensor decomposition. Notably, our framework provides a blueprint for downstream tasks using the learned tensor factors, such as modeling latent structures and extracting causal information, and offers a more flexible regularization design to enhance tensor decomposition. Theoretically, we show that our algorithm converges to a stationary point. More importantly, our results fill the gap in theoretical guarantees for the convergence of state-of-the-art irregular tensor decomposition. Experimental results on synthetic and real-world electronic health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both phenotyping and network recovery perspectives, demonstrate that our proposed method outperforms state-of-the-art techniques and enhances the explainability of causal representations.",
      "authors": [
        "Jianhong Chen",
        "Meng Zhao",
        "Mostafa Reisi Gahrooei",
        "Xubo Yue"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:55:42+00:00",
          "link": "https://arxiv.org/abs/2507.14126v1",
          "size": "818kb",
          "version": "v1"
        }
      ],
      "title": "Toward Temporal Causal Representation Learning with Tensor Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14126",
        "HTML": "https://arxiv.org/html/2507.14126v1",
        "PDF": "https://arxiv.org/pdf/2507.14126"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses temporal causal representation learning using tensor decomposition and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14129",
      "abstract": "Masked token prediction has emerged as a powerful pre-training objective across language, vision, and speech, offering the potential to unify these diverse modalities through a single pre-training task. However, its application for general audio understanding remains underexplored, with BEATs being the only notable example. BEATs has seen limited modifications due to the absence of open-source pre-training code. Furthermore, BEATs was trained only on AudioSet, restricting its broader downstream applicability. To address these gaps, we present OpenBEATs, an open-source framework that extends BEATs via multi-domain audio pre-training. We conduct comprehensive evaluations across six types of tasks, twenty five datasets, and three audio domains, including audio reasoning tasks such as audio question answering, entailment, and captioning. OpenBEATs achieves state-of-the-art performance on six bioacoustics datasets, two environmental sound datasets and five reasoning datasets, performing better than models exceeding a billion parameters at one-fourth their parameter size. These results demonstrate the effectiveness of multi-domain datasets and masked token prediction task to learn general-purpose audio representations. To promote further research and reproducibility, we release all pre-training and evaluation code, pretrained and fine-tuned checkpoints, and training logs at https://shikhar-s.github.io/OpenBEATs",
      "authors": [
        "Shikhar Bharadwaj",
        "Samuele Cornell",
        "Kwanghee Choi",
        "Satoru Fukayama",
        "Hye-jin Shim",
        "Soham Deshmukh",
        "Shinji Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:57:46+00:00",
          "link": "https://arxiv.org/abs/2507.14129v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "OpenBEATs: A Fully Open-Source General-Purpose Audio Encoder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14129",
        "HTML": "https://arxiv.org/html/2507.14129v1",
        "PDF": "https://arxiv.org/pdf/2507.14129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "OpenBEATs is focused on general-purpose audio pre-training and evaluation, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14137",
      "abstract": "We present Franca (pronounced Fran-ka): free one; the first fully open-source (data, code, weights) vision foundation model that matches and in many cases surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2, CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in SSL clustering methods. While modern models rely on assigning image features to large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to account for the inherent ambiguity in clustering semantics. To address this, we introduce a parameter-efficient, multi-head clustering projector based on nested Matryoshka representations. This design progressively refines features into increasingly fine-grained clusters without increasing the model size, enabling both performance and memory efficiency. Additionally, we propose a novel positional disentanglement strategy that explicitly removes positional biases from dense representations, thereby improving the encoding of semantic content. This leads to consistent gains on several downstream benchmarks, demonstrating the utility of cleaner feature spaces. Our contributions establish a new standard for transparent, high-performance vision models and open a path toward more reproducible and generalizable foundation models for the broader AI community. The code and model checkpoints are available at https://github.com/valeoai/Franca.",
      "authors": [
        "Shashanka Venkataramanan",
        "Valentinos Pariza",
        "Mohammadreza Salehi",
        "Lukas Knobel",
        "Spyros Gidaris",
        "Elias Ramzi",
        "Andrei Bursuc",
        "Yuki M. Asano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.14137v1",
          "size": "1519kb",
          "version": "v1"
        }
      ],
      "title": "Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14137",
        "HTML": "https://arxiv.org/html/2507.14137v1",
        "PDF": "https://arxiv.org/pdf/2507.14137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visual representation learning and clustering techniques to enhance vision models, rather than LLM training data processing. It does not address any data engineering operations or data quality improvements related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10739",
      "abstract": "This paper constructs the first quantum algorithm for wavelet packet transforms with a tree structure, sometimes called wave atom transforms. Classically, wave atoms are used to construct sparse representations of differential operators, which enable fast numerical algorithms for partial differential equations. Compared to previous work, our quantum algorithm can implement a larger class of wavelet and wave atom transforms, by using an efficient representation for a larger class of possible tree structures. Our quantum implementation has $O(\\mathrm{poly}(n))$ gate complexity for the transform of dimension $2^n$, while classical implementations have $O(n 2^n)$ floating point operations. The result can be used to improve existing quantum algorithms for solving hyperbolic partial differential equations.",
      "authors": [
        "Marianna Podzorova",
        "Yi-Kai Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:03:22+00:00",
          "link": "https://arxiv.org/abs/2507.10739v1",
          "size": "1364kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Wave Atom Transforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10739",
        "HTML": "https://arxiv.org/html/2507.10739v1",
        "PDF": "https://arxiv.org/pdf/2507.10739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on quantum algorithms for wavelet packet transforms and does not relate to any aspect of LLM training data processing. It primarily deals with quantum representations for improving numerical solutions to differential equations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12182",
      "abstract": "The paper is concerned with deformed Wigner random matrices. These matrices are closely connected with Deep Neural Networks (DNNs): weight matrices of trained DNNs could be represented in the form $R + S$, where $R$ is random and $S$ is highly correlated. The spectrum of such matrices plays a key role in rigorous underpinning of the novel pruning technique based on Random Matrix Theory. Mathematics has been done only for finite-rank matrix $S$. However, in practice rank may grow. In this paper we develop asymptotic analysis for the case of growing rank.",
      "authors": [
        "Ievgenii Afanasiev",
        "Leonid Berlyand",
        "Mariia Kiyashko"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Mathematical Physics (math-ph)",
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math.MP)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:29:23+00:00",
          "link": "https://arxiv.org/abs/2507.12182v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12182",
        "HTML": "https://arxiv.org/html/2507.12182v1",
        "PDF": "https://arxiv.org/pdf/2507.12182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with random matrix theory and its relation to deep neural networks, with no mention of LLM training data processing or data-related contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13376",
      "abstract": "Physics-guided approaches offer a promising path toward accurate and generalisable impact identification in composite structures, especially when experimental data are sparse. This paper presents a hybrid framework for impact localisation and force estimation in composite plates, combining a data-driven implementation of First-Order Shear Deformation Theory (FSDT) with machine learning and uncertainty quantification. The structural configuration and material properties are inferred from dispersion relations, while boundary conditions are identified via modal characteristics to construct a low-fidelity but physically consistent FSDT model. This model enables physics-informed data augmentation for extrapolative localisation using supervised learning. Simultaneously, an adaptive regularisation scheme derived from the same model improves the robustness of impact force reconstruction. The framework also accounts for uncertainty by propagating localisation uncertainty through the force estimation process, producing probabilistic outputs. Validation on composite plate experiments confirms the framework's accuracy, robustness, and efficiency in reducing dependence on large training datasets. The proposed method offers a scalable and transferable solution for impact monitoring and structural health management in composite aerostructures.",
      "authors": [
        "Dong Xiao",
        "Zahra Sharif-Khodaei",
        "M. H. Aliabadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:17:25+00:00",
          "link": "https://arxiv.org/abs/2507.13376v1",
          "size": "1943kb",
          "version": "v1"
        }
      ],
      "title": "Physics-guided impact localisation and force estimation in composite plates with uncertainty quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13376",
        "HTML": "https://arxiv.org/html/2507.13376v1",
        "PDF": "https://arxiv.org/pdf/2507.13376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for impact localisation and force estimation in composite plates, which involves physics-guided and machine learning methods. It is unrelated to LLM training data processing or related dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13384",
      "abstract": "Vision Mamba models promise transformer-level performance at linear computational cost, but their reliance on serializing 2D images into 1D sequences introduces a critical, yet overlooked, design choice: the patch scan order. In medical imaging, where modalities like brain MRI contain strong anatomical priors, this choice is non-trivial. This paper presents the first systematic study of how scan order impacts MRI segmentation. We introduce Multi-Scan 2D (MS2D), a parameter-free module for Mamba-based architectures that facilitates exploring diverse scan paths without additional computational cost. We conduct a large-scale benchmark of 21 scan strategies on three public datasets (BraTS 2020, ISLES 2022, LGG), covering over 70,000 slices. Our analysis shows conclusively that scan order is a statistically significant factor (Friedman test: $\\chi^{2}_{20}=43.9, p=0.0016$), with performance varying by as much as 27 Dice points. Spatially contiguous paths -- simple horizontal and vertical rasters -- consistently outperform disjointed diagonal scans. We conclude that scan order is a powerful, cost-free hyperparameter, and provide an evidence-based shortlist of optimal paths to maximize the performance of Mamba models in medical imaging.",
      "authors": [
        "Osama Hardan",
        "Omar Elshenhabi",
        "Tamer Khattab",
        "Mohamed Mabrok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:37:37+00:00",
          "link": "https://arxiv.org/abs/2507.13384v1",
          "size": "654kb",
          "version": "v1"
        }
      ],
      "title": "Flatten Wisely: How Patch Order Shapes Mamba-Powered Vision for MRI Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13384",
        "HTML": "https://arxiv.org/html/2507.13384v1",
        "PDF": "https://arxiv.org/pdf/2507.13384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the impact of patch scan order on MRI segmentation in medical imaging and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13391",
      "abstract": "This research presents a framework for quantitative risk management in volatile markets, specifically focusing on expectile-based methodologies applied to the FTSE 100 index. Traditional risk measures such as Value-at-Risk (VaR) have demonstrated significant limitations during periods of market stress, as evidenced during the 2008 financial crisis and subsequent volatile periods. This study develops an advanced expectile-based framework that addresses the shortcomings of conventional quantile-based approaches by providing greater sensitivity to tail losses and improved stability in extreme market conditions. The research employs a dataset spanning two decades of FTSE 100 returns, incorporating periods of high volatility, market crashes, and recovery phases. Our methodology introduces novel mathematical formulations for expectile regression models, enhanced threshold determination techniques using time series analysis, and robust backtesting procedures. The empirical results demonstrate that expectile-based Value-at-Risk (EVaR) consistently outperforms traditional VaR measures across various confidence levels and market conditions. The framework exhibits superior performance during volatile periods, with reduced model risk and enhanced predictive accuracy. Furthermore, the study establishes practical implementation guidelines for financial institutions and provides evidence-based recommendations for regulatory compliance and portfolio management. The findings contribute significantly to the literature on financial risk management and offer practical tools for practitioners dealing with volatile market environments.",
      "authors": [
        "Abiodun Finbarrs Oketunji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:24:14+00:00",
          "link": "https://arxiv.org/abs/2507.13391v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Quantitative Risk Management in Volatile Markets with an Expectile-Based Framework for the FTSE Index",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13391",
        "HTML": "https://arxiv.org/html/2507.13391v1",
        "PDF": "https://arxiv.org/pdf/2507.13391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantitative risk management using expectile-based methodologies for financial markets. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13394",
      "abstract": "Nerve segmentation is crucial in medical imaging for precise identification of nerve structures. This study presents an optimized DeepLabV3-based segmentation pipeline that incorporates automated threshold fine-tuning to improve segmentation accuracy. By refining preprocessing steps and implementing parameter optimization, we achieved a Dice Score of 0.78, an IoU of 0.70, and a Pixel Accuracy of 0.95 on ultrasound nerve imaging. The results demonstrate significant improvements over baseline models and highlight the importance of tailored parameter selection in automated nerve detection.",
      "authors": [
        "Akhil John Thomas",
        "Christiaan Boerkamp"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:26:18+00:00",
          "link": "https://arxiv.org/abs/2507.13394v1",
          "size": "172kb",
          "version": "v1"
        }
      ],
      "title": "Enhanced DeepLab Based Nerve Segmentation with Optimized Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13394",
        "HTML": "https://arxiv.org/html/2507.13394v1",
        "PDF": "https://arxiv.org/pdf/2507.13394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on medical imaging and pipeline optimization for nerve segmentation, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13421",
      "abstract": "In this paper, we study the problem of splitting fairly bundles of items. We show that given $n$ bundles with $m$ kinds of items in them, it is possible to distribute the value of each kind of item fairly among $r$ persons by breaking apart at most $(r-1)m$ bundles. Moreover, we can guarantee that each participant will receive roughly $n/r - mr/2$ full bundles. The proof methods are topological and use a modified form of the configuration space/test map scheme. We obtain optimal results when $r$ is a power of two.",
      "authors": [
        "Pablo Sober\\'on"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:46:42+00:00",
          "link": "https://arxiv.org/abs/2507.13421v1",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "title": "Fair distribution of bundles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13421",
        "HTML": "https://arxiv.org/html/2507.13421v1",
        "PDF": "https://arxiv.org/pdf/2507.13421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the fair distribution of bundles using a topological approach. It does not pertain to LLM training data processing or any related data engineering activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13458",
      "abstract": "Deep learning has revolutionized neuroimage analysis by delivering unprecedented speed and accuracy. However, the narrow scope of many training datasets constrains model robustness and generalizability. This challenge is particularly acute in magnetic resonance imaging (MRI), where image appearance varies widely across pulse sequences and scanner hardware. A recent domain-randomization strategy addresses the generalization problem by training deep neural networks on synthetic images with randomized intensities and anatomical content. By generating diverse data from anatomical segmentation maps, the approach enables models to accurately process image types unseen during training, without retraining or fine-tuning. It has demonstrated effectiveness across modalities including MRI, computed tomography, positron emission tomography, and optical coherence tomography, as well as beyond neuroimaging in ultrasound, electron and fluorescence microscopy, and X-ray microtomography. This tutorial paper reviews the principles, implementation, and potential of the synthesis-driven training paradigm. It highlights key benefits, such as improved generalization and resistance to overfitting, while discussing trade-offs such as increased computational demands. Finally, the article explores practical considerations for adopting the technique, aiming to accelerate the development of generalizable tools that make deep learning more accessible to domain experts without extensive computational resources or machine learning knowledge.",
      "authors": [
        "Malte Hoffmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:07:42+00:00",
          "link": "https://arxiv.org/abs/2507.13458v1",
          "size": "1648kb",
          "version": "v1"
        }
      ],
      "title": "Domain-randomized deep learning for neuroimage analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13458",
        "HTML": "https://arxiv.org/html/2507.13458v1",
        "PDF": "https://arxiv.org/pdf/2507.13458"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on domain-randomization strategies to improve generalization in deep learning for neuroimaging analysis, which does not relate to LLM data processing, pretraining, or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13475",
      "abstract": "This paper develops expansive gradient dynamics in deep neural network-induced mapping spaces. Specifically, we generate tools and concepts for minimizing a class of energy functionals in an abstract Hilbert space setting covering a wide scope of applications such as PDEs-based inverse problems and supervised learning. The approach hinges on a Hilbert space metric in the full diffeomorphism mapping space, which could be viewed as a generalized Wasserstein-2 metric. We then study a projection gradient descent method within deep neural network parameterized sets. More importantly, we develop an adaptation and expanding strategy to step-by-step enlarge the deep neural network structures. In particular, the expansion mechanism aims to enhance the alignment of the neural manifold induced natural gradient direction as well as possible with the ideal Hilbert space gradient descent direction leveraging the fact that we can evaluate projections of the Hilbert space gradient. We demonstrate the efficacy of the proposed strategy for several simple model problems for energies arising in the context of supervised learning, model reduction, or inverse problems. In particular, we highlight the importance of assembling the neural flow matrix based on the inner product for the ambient Hilbert space. The actual algorithms are the simplest specifications of a broader spectrum based on a correspondingly wider discussion, postponing a detailed analysis to forthcoming work.",
      "authors": [
        "Wolfgang Dahmen",
        "Wuchen Li",
        "Yuankai Teng",
        "Zhu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:35:11+00:00",
          "link": "https://arxiv.org/abs/2507.13475v1",
          "size": "2765kb",
          "version": "v1"
        }
      ],
      "title": "Expansive Natural Neural Gradient Flows for Energy Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13475",
        "HTML": "https://arxiv.org/html/2507.13475v1",
        "PDF": "https://arxiv.org/pdf/2507.13475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores gradient dynamics in deep neural networks and energy minimization in abstract Hilbert spaces. It does not address data processing for LLM pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13492",
      "abstract": "Phase field simulations play a key role in the understanding of microstructure evolution in additive manufacturing. However, they have been found extremely computationally expensive. One of the reasons is the small time step requirement to resolve the complex microstructure evolution during the rapid solidification process. This paper investigates the possibility of using a class of stabilized time integration algorithms to accelerate such phase field simulations by increasing the time steps. The specific time integration formulation and theoretical analysis on energy stability were developed, based on a phase field model dedicated to simulating rapid solidification in additive manufacturing. The numerical results confirmed that the proposed method can ensure the numerical stability and a decreasing energy requirement for the phase field simulations with at least two orders-of-magnitude larger time steps over conventional explicit methods. 2D and 3D phase field simulations have been conducted with relevant physical and kinetic parameters for 316L stainless steels. This work provides a numerical framework for efficient phase field simulations and open numerous opportunities for large scale phase field modeling.",
      "authors": [
        "Chaoqian Yuan",
        "Chinnapat Panwisawas",
        "Ye Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:02:07+00:00",
          "link": "https://arxiv.org/abs/2507.13492v1",
          "size": "18386kb",
          "version": "v1"
        }
      ],
      "title": "On the time integration for phase field modeling of grain growth in additive manufacturing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13492",
        "HTML": "https://arxiv.org/html/2507.13492v1",
        "PDF": "https://arxiv.org/pdf/2507.13492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores stabilized time integration algorithms for phase field simulations in additive manufacturing. It focuses on computational efficiency for simulations, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13503",
      "abstract": "Monte Carlo algorithms, like the Swendsen-Wang and invaded-cluster, sample the Ising and Potts models asymptotically faster than single-spin Glauber dynamics do. Here, we generalize both algorithms to sample Potts lattice gauge theory by way of a $2$-dimensional cellular representation called the plaquette random-cluster model. The invaded-cluster algorithm targets Potts lattice gauge theory at criticality by implementing a stopping condition defined in terms of homological percolation, the emergence of spanning surfaces on the torus. Simulations for $\\mathbb Z_2$ and $\\mathbb Z_3$ lattice gauge theories on the cubical $4$-dimensional torus indicate that both generalized algorithms exhibit much faster autocorrelation decay than single-spin dynamics and allow for efficient sampling on $4$-dimensional tori of linear scale at least $40$.",
      "authors": [
        "Anthony E. Pizzimenti",
        "Paul Duncan",
        "and Benjamin Schweinhart"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Computational Geometry (cs.CG)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:19:15+00:00",
          "link": "https://arxiv.org/abs/2507.13503v1",
          "size": "245kb",
          "version": "v1"
        }
      ],
      "title": "Generalized cluster algorithms for Potts lattice gauge theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13503",
        "PDF": "https://arxiv.org/pdf/2507.13503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Monte Carlo algorithms for Potts lattice gauge theory and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13557",
      "abstract": "The efficient computer optimization of magnetic resonance pulses and pulse sequences involves the calculation of a problem-adapted cost function as well as its gradients with respect to all controls applied. The gradients generally can be calculated as a finite difference approximation, as a GRAPE approximation, or as an exact function, e.g. by the use of the augmented matrix exponentiation, where the exact gradient should lead to best optimization convergence. However, calculation of exact gradients is computationally expensive and analytical exact solutions to the problem would be highly desirable. As the majority of todays pulse optimizations involve a single spin 1/2, which can be represented by simple rotation matrices in the Bloch space or by their corresponding Cayley-Klein/quaternion parameters, the derivations of analytical exact gradient functions appear to be feasible. Taking two optimization types, the optimization of point-to-point pulses using 3D-rotations and the optimization of universal rotation pulses using quaternions, analytical solutions for gradients with respect to controls have been derived. Controls in this case can be conventional $x$ and $y$ pulses, but also $z$-controls, as well as gradients with respect to amplitude and phase of a pulse shape. In addition, analytical solutions with respect to pseudo controls, involving holonomic constraints to maximum rf-amplitudes, maximum rf-power, or maximum rf-energy, are introduced. Using the hyperbolic tangent function, maximum values are imposed in a fully continuous and differentiable way. The obtained analytical gradients allow the calculation two orders of magnitude faster than the augmented matrix exponential approach. The exact gradients for different controls are finally compared in a number of optimizations involving broadband pulses for $^{15}$N, $^{13}$C, and $^{19}$F applications.",
      "authors": [
        "Stella Slad and Burkhard Luy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T22:31:59+00:00",
          "link": "https://arxiv.org/abs/2507.13557v1",
          "size": "8467kb",
          "version": "v1"
        }
      ],
      "title": "Single spin exact gradients for the optimization of complex pulses and pulse sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13557",
        "HTML": "https://arxiv.org/html/2507.13557v1",
        "PDF": "https://arxiv.org/pdf/2507.13557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the optimization of magnetic resonance pulses using analytical exact gradient functions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13580",
      "abstract": "Combinatorial optimization algorithm is essential in computer-aided drug design by progressively exploring chemical space to design lead compounds with high affinity to target protein. However current methods face inherent challenges in integrating domain knowledge, limiting their performance in identifying lead compounds with novel and valid binding mode. Here, we propose AutoLeadDesign, a lead compounds design framework that inspires extensive domain knowledge encoded in large language models with chemical fragments to progressively implement efficient exploration of vast chemical space. The comprehensive experiments indicate that AutoLeadDesign outperforms baseline methods. Significantly, empirical lead design campaigns targeting two clinically relevant targets (PRMT5 and SARS-CoV-2 PLpro) demonstrate AutoLeadDesign's competence in de novo generation of lead compounds achieving expert-competitive design efficacy. Structural analysis further confirms their mechanism-validated inhibitory patterns. By tracing the process of design, we find that AutoLeadDesign shares analogous mechanisms with fragment-based drug design which traditionally rely on the expert decision-making, further revealing why it works. Overall, AutoLeadDesign offers an efficient approach for lead compounds design, suggesting its potential utility in drug design.",
      "authors": [
        "Hao Tuo",
        "Yan Li",
        "Xuanning Hu",
        "Haishi Zhao",
        "Xueyan Liu",
        "Bo Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:55:21+00:00",
          "link": "https://arxiv.org/abs/2507.13580v1",
          "size": "8301kb",
          "version": "v1"
        }
      ],
      "title": "A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13580",
        "HTML": "https://arxiv.org/html/2507.13580v1",
        "PDF": "https://arxiv.org/pdf/2507.13580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on optimizing chemical space exploration for drug design and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13604",
      "abstract": "Breast MRI provides high-resolution imaging critical for breast cancer screening and preoperative staging. However, existing segmentation methods for breast MRI remain limited in scope, often focusing on only a few anatomical structures, such as fibroglandular tissue or tumors, and do not cover the full range of tissues seen in scans. This narrows their utility for quantitative analysis. In this study, we present BreastSegNet, a multi-label segmentation algorithm for breast MRI that covers nine anatomical labels: fibroglandular tissue (FGT), vessel, muscle, bone, lesion, lymph node, heart, liver, and implant. We manually annotated a large set of 1123 MRI slices capturing these structures with detailed review and correction from an expert radiologist. Additionally, we benchmark nine segmentation models, including U-Net, SwinUNet, UNet++, SAM, MedSAM, and nnU-Net with multiple ResNet-based encoders. Among them, nnU-Net ResEncM achieves the highest average Dice scores of 0.694 across all labels. It performs especially well on heart, liver, muscle, FGT, and bone, with Dice scores exceeding 0.73, and approaching 0.90 for heart and liver. All model code and weights are publicly available, and we plan to release the data at a later date.",
      "authors": [
        "Qihang Li",
        "Jichen Yang",
        "Yaqian Chen",
        "Yuwen Chen",
        "Hanxue Gu",
        "Lars J. Grimm",
        "and Maciej A. Mazurowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:16:00+00:00",
          "link": "https://arxiv.org/abs/2507.13604v1",
          "size": "4273kb",
          "version": "v1"
        }
      ],
      "title": "BreastSegNet: Multi-label Segmentation of Breast MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13604",
        "HTML": "https://arxiv.org/html/2507.13604v1",
        "PDF": "https://arxiv.org/pdf/2507.13604"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a multi-label segmentation algorithm for breast MRI, which is not related to LLM training data processing or relevant data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13613",
      "abstract": "We present a novel robust control framework for continuous-time, perturbed nonlinear dynamical systems with uncertainty that depends nonlinearly on both the state and control inputs. Unlike conventional approaches that impose structural assumptions on the uncertainty, our framework enhances contraction-based robust control with data-driven uncertainty prediction, remaining agnostic to the models of the uncertainty and predictor. We statistically quantify how reliably the contraction conditions are satisfied under dynamics with uncertainty via conformal prediction, thereby obtaining a distribution-free and finite-time probabilistic guarantee for exponential boundedness of the trajectory tracking error. We further propose the probabilistically robust control invariant (PRCI) tube for distributionally robust motion planning, within which the perturbed system trajectories are guaranteed to stay with a finite probability, without explicit knowledge of the uncertainty model. Numerical simulations validate the effectiveness of the proposed robust control framework and the performance of the PRCI tube.",
      "authors": [
        "Sihang Wei",
        "Melkior Ornik",
        "Hiroyasu Tsukamoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:44:32+00:00",
          "link": "https://arxiv.org/abs/2507.13613v1",
          "size": "662kb",
          "version": "v1"
        }
      ],
      "title": "Conformal Contraction for Robust Nonlinear Control with Distribution-Free Uncertainty Quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13613",
        "HTML": "https://arxiv.org/html/2507.13613v1",
        "PDF": "https://arxiv.org/pdf/2507.13613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a robust control framework for nonlinear dynamical systems, focusing on uncertainty quantification, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13626",
      "abstract": "Speech Quality Assessment (SQA) and Continuous Speech Emotion Recognition (CSER) are two key tasks in speech technology, both relying on listener ratings. However, these ratings are inherently biased due to individual listener factors. Previous approaches have introduced a mean listener scoring scale and modeled all listener scoring scales in the training set. However, the mean listener approach is prone to distortion from averaging ordinal data, leading to potential biases. Moreover, learning multiple listener scoring scales while inferring based only on the mean listener scale limits effectiveness. In contrast, our method focuses on modeling a unified listener scoring scale, using comparison scores to correctly capture the scoring relationships between utterances. Experimental results show that our method effectively improves prediction performance in both SQA and CSER tasks, proving its effectiveness and robustness.",
      "authors": [
        "Cheng-Hung Hu",
        "Yusuke Yasud",
        "Akifumi Yoshimoto",
        "Tomoki Toda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:39:48+00:00",
          "link": "https://arxiv.org/abs/2507.13626v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "Unifying Listener Scoring Scales: Comparison Learning Framework for Speech Quality Assessment and Continuous Speech Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13626",
        "HTML": "https://arxiv.org/html/2507.13626v1",
        "PDF": "https://arxiv.org/pdf/2507.13626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on listener scoring scales for speech quality assessment and emotion recognition, which is unrelated to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13635",
      "abstract": "Reasoning about quantum programs remains a fundamental challenge, regardless of the programming model or computational paradigm. Despite extensive research, existing verification techniques are insufficient--even for quantum circuits, a deliberately restricted model that lacks classical control, but still underpins many current quantum algorithms. Many existing formal methods require exponential time and space to represent and manipulate (representations of) assertions and judgments, making them impractical for quantum circuits with many qubits. This paper presents a logic for reasoning in such settings, called SAQR-QC. The logic supports Scalable but Approximate Quantitative Reasoning about Quantum Circuits, whence the name. SAQR-QC has three characteristics: (i) some (deliberate) loss of precision is built into it; (ii) it has a mechanism to help the accumulated loss of precision during a sequence of reasoning steps remain small; and (iii) most importantly, to make reasoning scalable, all reasoning steps are local--i.e., they each involve just a small number of qubits. We demonstrate the effectiveness of SAQR-QC via two case studies: the verification of GHZ circuits involving non-Clifford gates, and the analysis of quantum phase estimation--a core subroutine in Shor's factoring algorithm.",
      "authors": [
        "Nengkun Yu",
        "Jens Palsberg",
        "and Thomas Reps"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:48:36+00:00",
          "link": "https://arxiv.org/abs/2507.13635v1",
          "size": "221kb",
          "version": "v1"
        }
      ],
      "title": "SAQR-QC: A Logic for Scalable but Approximate Quantitative Reasoning about Quantum Circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13635",
        "HTML": "https://arxiv.org/html/2507.13635v1",
        "PDF": "https://arxiv.org/pdf/2507.13635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a logic for reasoning about quantum circuits and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13638",
      "abstract": "A grand challenge in modern neuroscience is to bridge the gap between the detailed mapping of microscale neural circuits and a mechanistic understanding of cognitive functions. While extensive knowledge exists about neuronal connectivity and biophysics, a significant gap remains in how these elements combine to produce flexible, learned behaviors. Here, we propose that a framework based on State-Space Models (SSMs), an emerging class of deep learning architectures, can bridge this gap. We argue that the differential equations governing elements in an SSM are conceptually consistent with the biophysical dynamics of neurons, while the combined dynamics in the model lead to emergent behaviors observed in experimental neuroscience. We test this framework by training an S5 model--a specific SSM variant employing a diagonal state transition matrix--on temporal discrimination tasks with reinforcement learning (RL). We demonstrate that the model spontaneously develops neural representations that strikingly mimic biological 'time cells'. We reveal that these cells emerge from a simple generative principle: learned rotational dynamics of hidden state vectors in the complex plane. This single mechanism unifies the emergence of time cells, ramping activity, and oscillations/traveling waves observed in numerous experiments. Furthermore, we show that this rotational dynamics generalizes beyond interval discriminative tasks to abstract event-counting tasks that were considered foundational for performing complex cognitive tasks. Our findings position SSMs as a compelling framework that connects single-neuron dynamics to cognitive phenomena, offering a unifying and computationally tractable theoretical ground for temporal learning in the brain.",
      "authors": [
        "Sen Lu",
        "Xiaoyu Zhang",
        "Mingtao Hu",
        "Eric Yeu-Jer Lee",
        "Soohyeon Kim",
        "Wei D. Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:53:16+00:00",
          "link": "https://arxiv.org/abs/2507.13638v1",
          "size": "1088kb",
          "version": "v1"
        }
      ],
      "title": "State Space Models Naturally Produce Traveling Waves, Time Cells, and Scale to Abstract Cognitive Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13638",
        "PDF": "https://arxiv.org/pdf/2507.13638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores a neuroscience framework using State-Space Models for cognitive functions, unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13639",
      "abstract": "We consider the problem of contextual kernel bandits with stochastic contexts, where the underlying reward function belongs to a known Reproducing Kernel Hilbert Space. We study this problem under an additional constraint of Differential Privacy, where the agent needs to ensure that the sequence of query points is differentially private with respect to both the sequence of contexts and rewards. We propose a novel algorithm that achieves the state-of-the-art cumulative regret of $\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$ and $\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T\\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$ over a time horizon of $T$ in the joint and local models of differential privacy, respectively, where $\\gamma_T$ is the effective dimension of the kernel and $\\varepsilon_{\\mathrm{DP}} > 0$ is the privacy parameter. The key ingredient of the proposed algorithm is a novel private kernel-ridge regression estimator which is based on a combination of private covariance estimation and private random projections. It offers a significantly reduced sensitivity compared to its classical counterpart while maintaining a high prediction accuracy, allowing our algorithm to achieve the state-of-the-art performance guarantees.",
      "authors": [
        "Nikola Pavlovic",
        "Sudeep Salgia",
        "Qing Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:54:49+00:00",
          "link": "https://arxiv.org/abs/2507.13639v1",
          "size": "62kb",
          "version": "v1"
        }
      ],
      "title": "Differential Privacy in Kernelized Contextual Bandits via Random Projections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13639",
        "HTML": "https://arxiv.org/html/2507.13639v1",
        "PDF": "https://arxiv.org/pdf/2507.13639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with differential privacy in kernelized contextual bandits, focusing on algorithmic performance under privacy constraints rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13670",
      "abstract": "Deep thermalization refers to the emergence of Haar-like randomness from quantum systems upon partial measurements. As a generalization of quantum thermalization, it is often associated with high complexity and entanglement. Here, we introduce computational deep thermalization and construct the fastest possible dynamics exhibiting it at infinite effective temperature. Our circuit dynamics produce quantum states with low entanglement in polylogarithmic depth that are indistinguishable from Haar random states to any computationally bounded observer. Importantly, the observer is allowed to request many copies of the same residual state obtained from partial projective measurements on the state -- this condition is beyond the standard settings of quantum pseudorandomness, but natural for deep thermalization. In cryptographic terms, these states are pseudorandom, pseudoentangled, and crucially, retain these properties under local measurements. Our results demonstrate a new form of computational thermalization, where thermal-like behavior arises from structured quantum states endowed with cryptographic properties, instead of from highly unstructured ensembles. The low resource complexity of preparing these states suggests scalable simulations of deep thermalization using quantum computers. Our work also motivates the study of computational quantum pseudorandomness beyond BQP observers.",
      "authors": [
        "Shantanav Chakraborty",
        "Soonwon Choi",
        "Soumik Ghosh",
        "Tudor Giurgic\\u{a}-Tiron"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Computational Complexity (cs.CC)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:42:05+00:00",
          "link": "https://arxiv.org/abs/2507.13670v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "Fast computational deep thermalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13670",
        "HTML": "https://arxiv.org/html/2507.13670v1",
        "PDF": "https://arxiv.org/pdf/2507.13670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces computational deep thermalization in quantum systems, which is unrelated to LLM training data processing or improvement in training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13746",
      "abstract": "We introduce a monotone modal analogue of the intuitionistic (normal) modal logic IK using a translation into a suitable (intuitionistic) first-order logic. We axiomatise the logic and give a semantics by means of intuitionistic neighbourhood models, which contain neighbourhoods whose value can change when moving along the intuitionistic accessibility relation. We compare the resulting logic with other intuitionistic monotone modal logics and show how it can be embedded into a multimodal version of IK.",
      "authors": [
        "Jim de Groot"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:48:52+00:00",
          "link": "https://arxiv.org/abs/2507.13746v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "Intuitionistic monotone modal logic via translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13746",
        "PDF": "https://arxiv.org/pdf/2507.13746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a logic system focusing on intuitionistic modal logic, which has no connection to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13775",
      "abstract": "Linear and nonlinear distortions in optical communication signals are equalized using an integrated feed-forward Photonic Neural Network (PNN). The PNN is based on a linear stage made of an 8-tap Finite Impulse Response (FIR) filter, featuring tunable amplitude and phase weights at each tap, and of a nonlinear stage achieved through the square modulus operation at the end-of-line photodetector. Within an Intensity Modulation/Direct Detection (IMDD) system, the PNN is applied to 2-level Pulse Amplitude Modulated (PAM2) optical signals undergoing multi-span propagation. Each 50 km segment includes fiber transmission, optical power restoration, and optional chromatic dispersion compensation via a Tunable Dispersion Compensator. Positioned at the receiver, the PNN enables fully optical signal processing with minimal latency and power consumption. Experimental validation is conducted using a Silicon-On-Insulator device operating on 10 Gbps signals. It demonstrates chromatic dispersion equalization over distances up to 200 km and self-phase modulation (with dispersion removed) up to 450 km. Simulations explore PNN adaptation for 100 Gbps modulations and its potential for cross-phase modulation equalization.",
      "authors": [
        "Emiliano Staffoli",
        "Elisabetta Ferri",
        "Stefano Gretter and Lorenzo Pavesi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Emerging Technologies (cs.ET)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:36:04+00:00",
          "link": "https://arxiv.org/abs/2507.13775v1",
          "size": "2183kb",
          "version": "v1"
        }
      ],
      "title": "Nonlinear Distortion Equalization in Multi-Span Optical Links Via a Feed-Forward Photonic Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13775",
        "HTML": "https://arxiv.org/html/2507.13775v1",
        "PDF": "https://arxiv.org/pdf/2507.13775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a photonic neural network for equalizing distortions in optical communication signals, involving optical signal processing. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13782",
      "abstract": "Ultra-high resolution 7 tesla (7T) magnetic resonance imaging (MRI) provides detailed anatomical views, offering better signal-to-noise ratio, resolution and tissue contrast than 3T MRI, though at the cost of accessibility. We present an advanced deep learning model for synthesizing 7T brain MRI from 3T brain MRI. Paired 7T and 3T T1-weighted images were acquired from 172 participants (124 cognitively unimpaired, 48 impaired) from the Swedish BioFINDER-2 study. To synthesize 7T MRI from 3T images, we trained two models: a specialized U-Net, and a U-Net integrated with a generative adversarial network (GAN U-Net). Our models outperformed two additional state-of-the-art 3T-to-7T models in image-based evaluation metrics. Four blinded MRI professionals judged our synthetic 7T images as comparable in detail to real 7T images, and superior in subjective visual quality to 7T images, apparently due to the reduction of artifacts. Importantly, automated segmentations of the amygdalae of synthetic GAN U-Net 7T images were more similar to manually segmented amygdalae (n=20), than automated segmentations from the 3T images that were used to synthesize the 7T images. Finally, synthetic 7T images showed similar performance to real 3T images in downstream prediction of cognitive status using MRI derivatives (n=3,168). In all, we show that synthetic T1-weighted brain images approaching 7T quality can be generated from 3T images, which may improve image quality and segmentation, without compromising performance in downstream tasks. Future directions, possible clinical use cases, and limitations are discussed.",
      "authors": [
        "Malo Gicquel",
        "Ruoyi Zhao",
        "Anika Wuestefeld",
        "Nicola Spotorno",
        "Olof Strandberg",
        "Kalle {\\AA}str\\\"om",
        "Yu Xiao",
        "Laura EM Wisse",
        "Danielle van Westen",
        "Rik Ossenkoppele",
        "Niklas Mattsson-Carlgren",
        "David Berron",
        "Oskar Hansson",
        "Gabrielle Flood",
        "Jacob Vogel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:54:59+00:00",
          "link": "https://arxiv.org/abs/2507.13782v1",
          "size": "5630kb",
          "version": "v1"
        }
      ],
      "title": "Converting T1-weighted MRI from 3T to 7T quality using deep learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13782",
        "HTML": "https://arxiv.org/html/2507.13782v1",
        "PDF": "https://arxiv.org/pdf/2507.13782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about using deep learning to convert MRI quality from 3T to 7T. The focus is on medical imaging enhancement and does not cover aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13804",
      "abstract": "It is known that gradient descent (GD) on a $C^2$ cost function generically avoids strict saddle points when using a small, constant step size. However, no such guarantee existed for GD with a line-search method. We provide one for a modified version of the standard Armijo backtracking method with generic, arbitrarily large initial step size. In contrast to previous works, our analysis does not require a globally Lipschitz gradient.\n  We extend this to the Riemannian setting (RGD), assuming the retraction is real analytic (though the cost function still only needs to be $C^2$). In closing, we also improve guarantees for RGD with a constant step size in some scenarios.",
      "authors": [
        "Andreea-Alexandra Mu\\c{s}at",
        "Nicolas Boumal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:32:42+00:00",
          "link": "https://arxiv.org/abs/2507.13804v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Gradient descent avoids strict saddles with a simple line-search method too",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13804",
        "HTML": "https://arxiv.org/html/2507.13804v1",
        "PDF": "https://arxiv.org/pdf/2507.13804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on gradient descent methods and optimization techniques, which do not relate to any aspect of LLM training data processing such as data collection or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13810",
      "abstract": "This article introduces the innovative Quantum Dining Information Brokers Problem, presenting a novel entanglement-based quantum protocol to address it. The scenario involves $n$ information brokers, all located in distinct geographical regions, engaging in a metaphorical virtual dinner. The objective is for each broker to share a unique piece of information with all others simultaneously. Unlike previous approaches, this protocol enables a fully parallel, single-step communication exchange among all brokers, regardless of their physical locations. A key feature of this protocol is its ability to ensure both the anonymity and privacy of all participants are preserved, meaning no broker can discern the identity of the sender behind any received information. At its core, the Quantum Dining Information Brokers Problem serves as a conceptual framework for achieving anonymous, untraceable, and massively parallel information exchange in a distributed system. The proposed protocol introduces three significant advancements. First, while quantum protocols for one-to-many simultaneous information transmission have been developed, this is, to the best of our knowledge, one of the first quantum protocols to facilitate many-to-many simultaneous information exchange. Second, it guarantees complete anonymity and untraceability for all senders, a critical improvement over sequential applications of one-to-many protocols, which fail to ensure such robust anonymity. Third, leveraging quantum entanglement, the protocol operates in a fully distributed manner, accommodating brokers in diverse spatial locations. This approach marks a substantial advancement in secure, scalable, and anonymous communication, with potential applications in distributed environments where privacy and parallelism are paramount.",
      "authors": [
        "Theodore Andronikos",
        "Constantinos Bitsakos",
        "Konstantinos Nikas",
        "Georgios I. Goumas",
        "Nectarios Koziris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:41:27+00:00",
          "link": "https://arxiv.org/abs/2507.13810v1",
          "size": "139kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Shadows: The Dining Information Brokers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13810",
        "PDF": "https://arxiv.org/pdf/2507.13810"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a quantum protocol for information exchange, and it is focused on communication strategies rather than any facet of LLM training data processing or dataset enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13821",
      "abstract": "The notion of oriented line graphs is introduced by Kotani and Sunada, and they are closely related to Hashimato's non-backtracking matrix. It is known that for regular graphs $G$, the eigenvalues of the adjacency matrix of the oriented line graph $\\vec{L}(G)$ of $G$ are the reciprocals of the poles of the Ihara zeta function of $G$. We determine the characteristic polynomial of the adjacency matrix of the underlying undirected graph of $\\vec{L}(G)$ and the skew-symmetric adjacency matrix of $\\vec{L}(G)$ for $d$-regular graphs $G$ with $d\\geq 3$. We also exhibit a consequence of this result to star coloring of regular graphs.",
      "authors": [
        "Cyriac Antony",
        "Jacob Antony"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:20:42+00:00",
          "link": "https://arxiv.org/abs/2507.13821v1",
          "size": "6kb",
          "version": "v1"
        }
      ],
      "title": "Some short notes on oriented line graphs and related matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13821",
        "HTML": "https://arxiv.org/html/2507.13821v1",
        "PDF": "https://arxiv.org/pdf/2507.13821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies properties of oriented line graphs and matrices, with no connection to LLMs or the processing of training data for them."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13830",
      "abstract": "We introduce the first publicly available breast MRI dataset with explicit left and right breast segmentation labels, encompassing more than 13,000 annotated cases. Alongside this dataset, we provide a robust deep-learning model trained for left-right breast segmentation. This work addresses a critical gap in breast MRI analysis and offers a valuable resource for the development of advanced tools in women's health. The dataset and trained model are publicly available at: www.github.com/MIC-DKFZ/BreastDivider",
      "authors": [
        "Maximilian Rokuss",
        "Benjamin Hamm",
        "Yannick Kirchhoff",
        "Klaus Maier-Hein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.13830v1",
          "size": "3617kb",
          "version": "v1"
        }
      ],
      "title": "Divide and Conquer: A Large-Scale Dataset and Model for Left-Right Breast MRI Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13830",
        "HTML": "https://arxiv.org/html/2507.13830v1",
        "PDF": "https://arxiv.org/pdf/2507.13830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on a dataset and model for breast MRI segmentation, unrelated to LLM training data processing. It does not contribute to data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13835",
      "abstract": "The amount of quality data in many machine learning tasks is limited to what is available locally to data owners. The set of quality data can be expanded through trading or sharing with external data agents. However, data buyers need quality guarantees before purchasing, as external data may be contaminated or irrelevant to their specific learning task. Previous works primarily rely on distributional assumptions about data from different agents, relegating quality checks to post-hoc steps involving costly data valuation procedures. We propose a distribution-free, contamination-aware data-sharing framework that identifies external data agents whose data is most valuable for model personalization. To achieve this, we introduce novel two-sample testing procedures, grounded in rigorous theoretical foundations for conformal outlier detection, to determine whether an agent's data exceeds a contamination threshold. The proposed tests, termed conformal data contamination tests, remain valid under arbitrary contamination levels while enabling false discovery rate control via the Benjamini-Hochberg procedure. Empirical evaluations across diverse collaborative learning scenarios demonstrate the robustness and effectiveness of our approach. Overall, the conformal data contamination test distinguishes itself as a generic procedure for aggregating data with statistically rigorous quality guarantees.",
      "authors": [
        "Martin V. Vejling and Shashi Raj Pandey and Christophe A. N. Biscio and Petar Popovski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:44:42+00:00",
          "link": "https://arxiv.org/abs/2507.13835v1",
          "size": "452kb",
          "version": "v1"
        }
      ],
      "title": "Conformal Data Contamination Tests for Trading or Sharing of Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13835",
        "PDF": "https://arxiv.org/pdf/2507.13835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a data-sharing framework using conformal data contamination tests, which could be relevant to ensuring the quality of data used for LLM training. However, it does not explicitly address LLM training data processing but is instead focused on quality assurance in general collaborative learning scenarios."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13883",
      "abstract": "Stablecoins, with a capitalization exceeding 200 billion USD as of January 2025, have shown significant growth, with annual transaction volumes exceeding 10 trillion dollars in 2023 and nearly doubling that figure in 2024. This exceptional success has attracted the attention of traditional financial institutions, with an increasing number of governments exploring the potential of Central Bank Digital Currencies (CBDCs). Although academia has recognized the importance of stablecoins, research in this area remains fragmented, incomplete, and sometimes contradictory. In this paper, we aim to address the cited gap with a structured literature analysis, correlating recent contributions to present a picture of the complex economic, technical, and regulatory aspects of stablecoins. To achieve this, we formulate the main research questions and categorize scientific contributions accordingly, identifying main results, data sources, methodologies, and open research questions. The research questions we address in this survey paper cover several topics, such as the stability of various stablecoins, novel designs and implementations, and relevant regulatory challenges. The studies employ a wide range of methodologies and data sources, which we critically analyze and synthesize. Our analysis also reveals significant research gaps, including limited studies on security and privacy, underexplored stablecoins, unexamined failure cases, unstudied governance mechanisms, and the treatment of stablecoins under financial accounting standards, among other areas.",
      "authors": [
        "Ahmed Mahrous",
        "Maurantonio Caprolu",
        "Roberto Di Pietro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Cryptography and Security (cs.CR)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:00:19+00:00",
          "link": "https://arxiv.org/abs/2507.13883v1",
          "size": "1274kb",
          "version": "v1"
        }
      ],
      "title": "Stablecoins: Fundamentals, Emerging Issues, and Open Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13883",
        "HTML": "https://arxiv.org/html/2507.13883v1",
        "PDF": "https://arxiv.org/pdf/2507.13883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a survey on stablecoins, discussing economic, technical, and regulatory aspects, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13887",
      "abstract": "It is a standard assumption that datasets in high dimension have an internal structure which means that they in fact lie on, or near, subsets of a lower dimension. In many instances it is important to understand the real dimension of the data, hence the complexity of the dataset at hand. A great variety of dimension estimators have been developed to find the intrinsic dimension of the data but there is little guidance on how to reliably use these estimators.\n  This survey reviews a wide range of dimension estimation methods, categorising them by the geometric information they exploit: tangential estimators which detect a local affine structure; parametric estimators which rely on dimension-dependent probability distributions; and estimators which use topological or metric invariants.\n  The paper evaluates the performance of these methods, as well as investigating varying responses to curvature and noise. Key issues addressed include robustness to hyperparameter selection, sample size requirements, accuracy in high dimensions, precision, and performance on non-linear geometries. In identifying the best hyperparameters for benchmark datasets, overfitting is frequent, indicating that many estimators may not generalise well beyond the datasets on which they have been tested.",
      "authors": [
        "James A. D. Binnie",
        "Pawe{\\l} D{\\l}otko",
        "John Harvey",
        "Jakub Malinowski",
        "Ka Man Yim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Differential Geometry (math.DG)",
        "Metric Geometry (math.MG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:05:42+00:00",
          "link": "https://arxiv.org/abs/2507.13887v1",
          "size": "2172kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Dimension Estimation Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13887",
        "HTML": "https://arxiv.org/html/2507.13887v1",
        "PDF": "https://arxiv.org/pdf/2507.13887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey of dimension estimation methods and does not address any aspects of LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13901",
      "abstract": "We have developed a novel CT image analysis package named AnatomyArchive, built on top of the recent full body segmentation model TotalSegmentator. It provides automatic target volume selection and deselection capabilities according to user-configured anatomies for volumetric upper- and lower-bounds. It has a knowledge graph-based and time efficient tool for anatomy segmentation mask management and medical image database maintenance. AnatomyArchive enables automatic body volume cropping, as well as automatic arm-detection and exclusion, for more precise body composition analysis in both 2D and 3D formats. It provides robust voxel-based radiomic feature extraction, feature visualization, and an integrated toolchain for statistical tests and analysis. A python-based GPU-accelerated nearly photo-realistic segmentation-integrated composite cinematic rendering is also included. We present here its software architecture design, illustrate its workflow and working principle of algorithms as well provide a few examples on how the software can be used to assist development of modern machine learning models. Open-source codes will be released at https://github.com/lxu-medai/AnatomyArchive for only research and educational purposes.",
      "authors": [
        "Lei Xu and Torkel B Brismar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:28:32+00:00",
          "link": "https://arxiv.org/abs/2507.13901v1",
          "size": "2364kb",
          "version": "v1"
        }
      ],
      "title": "Software architecture and manual for novel versatile CT image analysis toolbox -- AnatomyArchive",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13901",
        "PDF": "https://arxiv.org/pdf/2507.13901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a CT image analysis toolbox called AnatomyArchive and focuses on medical image processing, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13915",
      "abstract": "Previous studies in blind super-resolution (BSR) have primarily concentrated on estimating degradation kernels directly from low-resolution (LR) inputs to enhance super-resolution. However, these degradation kernels, which model the transition from a high-resolution (HR) image to its LR version, should account for not only the degradation process but also the downscaling factor. Applying the same degradation kernel across varying super-resolution scales may be impractical. Our research acknowledges degradation kernels and scaling factors as pivotal elements for the BSR task and introduces a novel strategy that utilizes HR images as references to establish scale-aware degradation kernels. By employing content-irrelevant HR reference images alongside the target LR image, our model adaptively discerns the degradation process. It is then applied to generate additional LR-HR pairs through down-sampling the HR reference images, which are keys to improving the SR performance. Our reference-based training procedure is applicable to proficiently trained blind SR models and zero-shot blind SR methods, consistently outperforming previous methods in both scenarios. This dual consideration of blur kernels and scaling factors, coupled with the use of a reference image, contributes to the effectiveness of our approach in blind super-resolution tasks.",
      "authors": [
        "Huu-Phu Do",
        "Po-Chih Hu",
        "Hao-Chien Hsueh",
        "Che-Kai Liu",
        "Vu-Hoang Tran",
        "Ching-Chun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:45:04+00:00",
          "link": "https://arxiv.org/abs/2507.13915v1",
          "size": "21288kb",
          "version": "v1"
        }
      ],
      "title": "Blind Super Resolution with Reference Images and Implicit Degradation Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13915",
        "HTML": "https://arxiv.org/html/2507.13915v1",
        "PDF": "https://arxiv.org/pdf/2507.13915"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on blind super-resolution using reference images and degradation kernels, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13938",
      "abstract": "Recently, commercial ultra-wideband (UWB) transceivers have enabled not only measuring device-to-device distance but also tracking the position of a pedestrian who does not carry a UWB device. UWB-based device-free localization that does not require dedicated radar equipment is compatible with existing anchor infrastructure and can be reused to reduce hardware deployment costs. However, it is difficult to estimate the target's position accurately in real-world scenarios due to the low signal-to-noise ratio (SNR) and the cluttered environment. In this paper, we propose a deep learning (DL)-assisted particle filter to overcome these challenges. First, the channel impulse response (CIR) variance is analyzed to capture the variability induced by the target's movement. Then, a DL-based one-dimensional attention U-Net is used to extract only the reflection components caused by the target and suppress the noise components within the CIR variance profile. Finally, multiple preprocessed CIR variance profiles are used as input to a particle filter to estimate the target's position. Experimental results demonstrate that the proposed system is a practical and cost-effective solution for IoT and automotive applications with a root mean square error (RMSE) of about 15 cm and an average processing time of 4 ms. Furthermore, comparisons with existing state-of-the-art methods show that the proposed method provides the best performance with reasonable computational costs.",
      "authors": [
        "Hyun Seok Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:10:52+00:00",
          "link": "https://arxiv.org/abs/2507.13938v1",
          "size": "4270kb",
          "version": "v1"
        }
      ],
      "title": "Device-Free Localization Using Commercial UWB Transceivers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13938",
        "HTML": "https://arxiv.org/html/2507.13938v1",
        "PDF": "https://arxiv.org/pdf/2507.13938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses using UWB transceivers for device-free localization with DL-assisted filters. This topic does not relate to LLM training data processing, as it focuses on improving localization accuracy rather than language data management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13941",
      "abstract": "A fundamental question in cognitive neuroscience is what shapes visual perception: the external world's structure or the brain's internal architecture. Although some perceptual variability can be traced to individual differences, brain responses to naturalistic stimuli evoke similar activity patterns across individuals, suggesting a convergent representational principle. Here, we test if this stimulus-driven convergence follows a common trajectory across people and deep neural networks (DNNs) during its transformation from sensory to high-level internal representations. We introduce a unified framework that traces representational flow by combining inter-subject similarity with alignment to model hierarchies. Applying this framework to three independent fMRI datasets of visual scene perception, we reveal a cortex-wide network, conserved across individuals, organized into two pathways: a medial-ventral stream for scene structure and a lateral-dorsal stream tuned for social and biological content. This functional organization is captured by the hierarchies of vision DNNs but not language models, reinforcing the specificity of the visual-to-semantic transformation. These findings show a convergent computational solution for visual encoding in both human and artificial vision, driven by the structure of the external world.",
      "authors": [
        "Pablo Marcos-Manch\\'on",
        "Llu\\'is Fuentemilla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:13:54+00:00",
          "link": "https://arxiv.org/abs/2507.13941v1",
          "size": "10445kb",
          "version": "v1"
        }
      ],
      "title": "Convergent transformations of visual representation in brains and models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13941",
        "HTML": "https://arxiv.org/html/2507.13941v1",
        "PDF": "https://arxiv.org/pdf/2507.13941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on visual perception and the brain's representations compared to deep neural networks for vision, which is outside what LLM training data processing encompasses."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13974",
      "abstract": "Melanoma is an aggressive form of skin cancer with rapid progression and high metastatic potential. Accurate characterisation of tissue morphology in melanoma is crucial for prognosis and treatment planning. However, manual segmentation of tissue regions from haematoxylin and eosin (H&E) stained whole-slide images (WSIs) is labour-intensive and prone to inter-observer variability, this motivates the need for reliable automated tissue segmentation methods. In this study, we propose a novel deep learning network for the segmentation of five tissue classes in melanoma H&E images. Our approach leverages Virchow2, a pathology foundation model trained on 3.1 million histopathology images as a feature extractor. These features are fused with the original RGB images and subsequently processed by an encoder-decoder segmentation network (Efficient-UNet) to produce accurate segmentation maps. The proposed model achieved first place in the tissue segmentation task of the PUMA Grand Challenge, demonstrating robust performance and generalizability. Our results show the potential and efficacy of incorporating pathology foundation models into segmentation networks to accelerate computational pathology workflows.",
      "authors": [
        "Jiaqi Lv",
        "Yijie Zhu",
        "Carmen Guadalupe Colin Tenorio",
        "Brinder Singh Chohan",
        "Mark Eastwood",
        "Shan E Ahmed Raza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:38:25+00:00",
          "link": "https://arxiv.org/abs/2507.13974v1",
          "size": "5892kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Pathology Foundation Models for Panoptic Segmentation of Melanoma in H&E Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13974",
        "HTML": "https://arxiv.org/html/2507.13974v1",
        "PDF": "https://arxiv.org/pdf/2507.13974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep learning network for tissue segmentation in melanoma images using pathology foundation models, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13993",
      "abstract": "The growing volume of medical imaging data has increased the need for automated diagnostic tools, especially for musculoskeletal injuries like rib fractures, commonly detected via CT scans. Manual interpretation is time-consuming and error-prone. We propose OrthoInsight, a multi-modal deep learning framework for rib fracture diagnosis and report generation. It integrates a YOLOv9 model for fracture detection, a medical knowledge graph for retrieving clinical context, and a fine-tuned LLaVA language model for generating diagnostic reports. OrthoInsight combines visual features from CT images with expert textual data to deliver clinically useful outputs. Evaluated on 28,675 annotated CT images and expert reports, it achieves high performance across Diagnostic Accuracy, Content Completeness, Logical Coherence, and Clinical Guidance Value, with an average score of 4.28, outperforming models like GPT-4 and Claude-3. This study demonstrates the potential of multi-modal learning in transforming medical image analysis and providing effective support for radiologists.",
      "authors": [
        "Ningyong Wu",
        "Jinzhi Wang",
        "Wenhong Zhao",
        "Chenzhan Yu",
        "Zhigang Xiu",
        "Duwei Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:01:44+00:00",
          "link": "https://arxiv.org/abs/2507.13993v1",
          "size": "5572kb",
          "version": "v1"
        }
      ],
      "title": "OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13993",
        "HTML": "https://arxiv.org/html/2507.13993v1",
        "PDF": "https://arxiv.org/pdf/2507.13993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for medical diagnosis and report generation using multi-modal deep learning, with no focus on LLM training data processing steps such as data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13999",
      "abstract": "We address the problem of optimal pumping strategies in quantum networks. These networks enable secure communication by distributing entangled photon pairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like BBM92, generate secret keys from entangled photons. While secure communication and error correction are essential for any quantum communication channel, resource contention, optimization, and fairness issues are critical for networks. In this article, we analyze the performance of quantum networks, proposing simple distributed algorithms for QKD networks generating secret keys.\n  There are significant advantages of pumping entangled photons in QKD networks, but challenges arise in practical implementations. The underlying channels are inherently time-varying, and thus data rates fluctuate between nodes. Moreover, multiple edges (node pairs) can be pumped simultaneously, albeit at the cost of a reduced secret key rate (SKR). These temporal and spatial constraints yield a complex decision-making problem whose solutions may favor a small set of user pairs to the detriment of overall, long-run network performance.\n  We design adaptive pumping strategies that address these challenges in QKD networks. In particular, we find that a proportional fairness pumping strategy (PF-PS) stands out by dynamically prioritizing users with lower average secret key rates and optimally balancing fairness with throughput. The proposed algorithm is a natural extension to quantum networks of the Proportional Fair Scheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis and numerical simulations confirm that PF-PS is optimal for entangled state distribution, and thus, when adapted appropriately, proportional fair pumping is a strong candidate for efficient resource allocation in quantum networks.",
      "authors": [
        "Sanidhay Bhambay",
        "Siddarth Koduru Joshi",
        "Thirupathaiah Vasantam",
        "Neil Walton"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Networking and Internet Architecture (cs.NI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:10:43+00:00",
          "link": "https://arxiv.org/abs/2507.13999v1",
          "size": "1190kb",
          "version": "v1"
        }
      ],
      "title": "The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13999",
        "HTML": "https://arxiv.org/html/2507.13999v1",
        "PDF": "https://arxiv.org/pdf/2507.13999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on optimizing resource allocation in quantum networks for secure communication using quantum key distribution. It does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14023",
      "abstract": "Regression problems with bounded continuous outcomes frequently arise in real-world statistical and machine learning applications, such as the analysis of rates and proportions. A central challenge in this setting is predicting a response associated with a new covariate value. Most of the existing statistical and machine learning literature has focused either on point prediction of bounded outcomes or on interval prediction based on asymptotic approximations. We develop conformal prediction intervals for bounded outcomes based on transformation models and beta regression. We introduce tailored non-conformity measures based on residuals that are aligned with the underlying models, and account for the inherent heteroscedasticity in regression settings with bounded outcomes. We present a theoretical result on asymptotic marginal and conditional validity in the context of full conformal prediction, which remains valid under model misspecification. For split conformal prediction, we provide an empirical coverage analysis based on a comprehensive simulation study. The simulation study demonstrates that both methods provide valid finite-sample predictive coverage, including settings with model misspecification. Finally, we demonstrate the practical performance of the proposed conformal prediction intervals on real data and compare them with bootstrap-based alternatives.",
      "authors": [
        "Zhanli Wu and Fabrizio Leisen and F. Javier Rubio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:51:48+00:00",
          "link": "https://arxiv.org/abs/2507.14023v1",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "title": "Conformalized Regression for Continuous Bounded Outcomes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14023",
        "HTML": "https://arxiv.org/html/2507.14023v1",
        "PDF": "https://arxiv.org/pdf/2507.14023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is centered around regression analysis for bounded outcomes and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14046",
      "abstract": "Unsupervised learning methods, such as Deep Image Prior (DIP), have shown great potential in tomographic imaging due to their training-data-free nature and high generalization capability. However, their reliance on numerous network parameter iterations results in high computational costs, limiting their practical application, particularly in complex 3D or time-sequence tomographic imaging tasks. To overcome these challenges, we propose Deep Dynamic Image Prior (D2IP), a novel framework for 3D time-sequence imaging. D2IP introduces three key strategies - Unsupervised Parameter Warm-Start (UPWS), Temporal Parameter Propagation (TPP), and a customized lightweight reconstruction backbone, 3D-FastResUNet - to accelerate convergence, enforce temporal coherence, and improve computational efficiency. Experimental results on both simulated and clinical pulmonary datasets demonstrate that D2IP enables fast and accurate 3D time-sequence Electrical Impedance Tomography (tsEIT) reconstruction. Compared to state-of-the-art baselines, D2IP delivers superior image quality, with a 24.8% increase in average MSSIM and an 8.1% reduction in ERR, alongside significantly reduced computational time (7.1x faster), highlighting its promise for clinical dynamic pulmonary imaging.",
      "authors": [
        "Hao Fang",
        "Hao Yu",
        "Sihao Teng",
        "Tao Zhang",
        "Siyi Yuan",
        "Huaiwu He",
        "Zhe Liu",
        "and Yunjie Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:14:09+00:00",
          "link": "https://arxiv.org/abs/2507.14046v1",
          "size": "4802kb",
          "version": "v1"
        }
      ],
      "title": "D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14046",
        "HTML": "https://arxiv.org/html/2507.14046v1",
        "PDF": "https://arxiv.org/pdf/2507.14046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for dynamic pulmonary imaging, emphasizing imaging and computational efficiency rather than any LLM training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14057",
      "abstract": "We develop a semi-amortized, policy-based, approach to Bayesian experimental design (BED) called Stepwise Deep Adaptive Design (Step-DAD). Like existing, fully amortized, policy-based BED approaches, Step-DAD trains a design policy upfront before the experiment. However, rather than keeping this policy fixed, Step-DAD periodically updates it as data is gathered, refining it to the particular experimental instance. This test-time adaptation improves both the flexibility and the robustness of the design strategy compared with existing approaches. Empirically, Step-DAD consistently demonstrates superior decision-making and robustness compared with current state-of-the-art BED methods.",
      "authors": [
        "Marcel Hedman",
        "Desi R. Ivanova",
        "Cong Guan",
        "Tom Rainforth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:39:56+00:00",
          "link": "https://arxiv.org/abs/2507.14057v1",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "title": "Step-DAD: Semi-Amortized Policy-Based Bayesian Experimental Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14057",
        "HTML": "https://arxiv.org/html/2507.14057v1",
        "PDF": "https://arxiv.org/pdf/2507.14057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for Bayesian experimental design which improves decision-making flexibility and robustness, but it does not pertain to LLM training data processing or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14102",
      "abstract": "Accurate classification of computed tomography (CT) images is essential for diagnosis and treatment planning, but existing methods often struggle with the subtle and spatially diverse nature of pathological features. Current approaches typically process images uniformly, limiting their ability to detect localized abnormalities that require focused analysis. We introduce UGPL, an uncertainty-guided progressive learning framework that performs a global-to-local analysis by first identifying regions of diagnostic ambiguity and then conducting detailed examination of these critical areas. Our approach employs evidential deep learning to quantify predictive uncertainty, guiding the extraction of informative patches through a non-maximum suppression mechanism that maintains spatial diversity. This progressive refinement strategy, combined with an adaptive fusion mechanism, enables UGPL to integrate both contextual information and fine-grained details. Experiments across three CT datasets demonstrate that UGPL consistently outperforms state-of-the-art methods, achieving improvements of 3.29%, 2.46%, and 8.08% in accuracy for kidney abnormality, lung cancer, and COVID-19 detection, respectively. Our analysis shows that the uncertainty-guided component provides substantial benefits, with performance dramatically increasing when the full progressive learning pipeline is implemented. Our code is available at: https://github.com/shravan-18/UGPL",
      "authors": [
        "Shravan Venkatraman",
        "Pavan Kumar S",
        "Rakesh Raj Madavan",
        "Chandrakala S"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:30:56+00:00",
          "link": "https://arxiv.org/abs/2507.14102v1",
          "size": "8141kb",
          "version": "v1"
        }
      ],
      "title": "UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based Classification in Computed Tomography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14102",
        "HTML": "https://arxiv.org/html/2507.14102v1",
        "PDF": "https://arxiv.org/pdf/2507.14102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a method for CT image classification with a focus on uncertainty-based analysis, lacking any contribution to LLM training data processing like deduplication or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14116",
      "abstract": "Exploiting the fact that samples drawn from a quantum annealer inherently follow a Boltzmann-like distribution, annealing-based Quantum Boltzmann Machines (QBMs) have gained increasing popularity in the quantum research community. While they harbor great promises for quantum speed-up, their usage currently stays a costly endeavor, as large amounts of QPU time are required to train them. This limits their applicability in the NISQ era. Following the idea of No\\`e et al. (2024), who tried to alleviate this cost by incorporating parallel quantum annealing into their unsupervised training of QBMs, this paper presents an improved version of parallel quantum annealing that we employ to train QBMs in a supervised setting. Saving qubits to encode the inputs, the latter setting allows us to test our approach on medical images from the MedMNIST data set (Yang et al., 2023), thereby moving closer to real-world applicability of the technology. Our experiments show that QBMs using our approach already achieve reasonable results, comparable to those of similarly-sized Convolutional Neural Networks (CNNs), with markedly smaller numbers of epochs than these classical models. Our parallel annealing technique leads to a speed-up of almost 70 % compared to regular annealing-based BM executions.",
      "authors": [
        "Dani\\\"elle Schuman",
        "Mark V. Seebode",
        "Tobias Rohe",
        "Maximilian Balthasar Mansky",
        "Michael Schroedl-Baumann",
        "Jonas Stein",
        "Claudia Linnhoff-Popien",
        "Florian Krellner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:45:18+00:00",
          "link": "https://arxiv.org/abs/2507.14116v1",
          "size": "1179kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14116",
        "HTML": "https://arxiv.org/html/2507.14116v1",
        "PDF": "https://arxiv.org/pdf/2507.14116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum annealing and Quantum Boltzmann Machines for medical image classification, focusing on quantum computing techniques rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1910.09297",
      "abstract": "In this paper, we propose two efficient block preconditioners to solve the mass-conserved Ohta-Kawasaki equation with finite element discretization. We also study the spectral distribution of these two preconditioners, \\textit{i.e.,} Schur complement preconditioner and the modified Hermitian and skew-Hermitian splitting (MHSS in short) preconditioner. Besides, Newton method and Picard method are used to address the implicitly nonlinear term. We rigorously analyze the convergence of Newton method. Finally, we offer numerical examples to support the theoretical analysis and indicate the efficiency of the proposed preconditioners for the mass-conserved Ohta-Kawasaki equation.",
      "authors": [
        "Juan Zhang",
        "Shifeng Li and Kai Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2019-10-21T12:28:45+00:00",
          "link": "https://arxiv.org/abs/1910.09297v1",
          "size": "1294kb",
          "version": "v1"
        },
        {
          "date": "2021-06-14T12:57:58+00:00",
          "link": "https://arxiv.org/abs/1910.09297v2",
          "size": "950kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T01:57:01+00:00",
          "link": "https://arxiv.org/abs/1910.09297v3",
          "size": "943kb",
          "version": "v3"
        }
      ],
      "title": "Two efficient block preconditioners for the mass-conserved Ohta-Kawasaki equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/1910.09297",
        "HTML": "https://arxiv.org/html/1910.09297v3",
        "PDF": "https://arxiv.org/pdf/1910.09297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on block preconditioners for the Ohta-Kawasaki equation and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2202.10742",
      "abstract": "Gossip algorithms and their accelerated versions have been studied exclusively in discrete time on graphs. In this work, we take a different approach, and consider the scaling limit of gossip algorithms in both large graphs and large number of iterations. These limits lead to well-known partial differential equations (PDEs) with insightful properties. On lattices, we prove that the non-accelerated gossip algorithm of Boyd et al. [2006] converges to the heat equation, and the accelerated Jacobi polynomial iteration of Berthier et al. [2020] converges to the Euler-Poisson-Darboux (EPD) equation - a damped wave equation. Remarkably, with appropriate parameters, the fundamental solution of the EPD equation has the ideal gossip behaviour: a uniform density over an ellipsoid, whose radius increases at a rate proportional to t - the fastest possible rate for locally communicating gossip algorithms. This is in contrast with the heat equation where the density spreads on a typical scale of $\\sqrt{t}$. Additionally, we provide simulations demonstrating that the gossip algorithms are accurately approximated by their limiting PDEs.",
      "authors": [
        "Rapha\\\"el Berthier (SIERRA",
        "EPFL)",
        "Mufan Bill Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-22T09:02:21+00:00",
          "link": "https://arxiv.org/abs/2202.10742v1",
          "size": "85kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:50:14+00:00",
          "link": "https://arxiv.org/abs/2202.10742v2",
          "size": "85kb",
          "version": "v2"
        }
      ],
      "title": "Acceleration of Gossip Algorithms through the Euler-Poisson-Darboux Equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.10742",
        "PDF": "https://arxiv.org/pdf/2202.10742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines gossip algorithms and their limits in terms of partial differential equations, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.09409",
      "abstract": "Accurate sound source localization (SSL), such as direction-of-arrival (DoA) estimation, relies on consistent multichannel data. However, batteryless systems often suffer from missing data due to the stochastic nature of energy harvesting, degrading localization performance. We propose LOCUS, a deep learning framework that recovers corrupted features in such settings. LOCUS integrates three modules: (1) Information-Weighted Focus (InFo) to identify corrupted regions, (2) Latent Feature Synthesizer (LaFS) to reconstruct missing features, and (3) Guided Replacement (GRep) to restore data without altering valid inputs. LOCUS significantly improves DoA accuracy under missing-channel conditions, achieving up to 36.91% error reduction on DCASE and LargeSet, and 25.87-59.46% gains in real-world deployments. We release a 50-hour multichannel dataset to support future research on localization under energy constraints. Our code and data are available at: https://bashlab.github.io/locus_project/",
      "authors": [
        "Subrata Biswas",
        "Mohammad Nur Hossain Khan",
        "Violet Colwell",
        "Jack Adiletta",
        "Bashima Islam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-18T19:53:12+00:00",
          "link": "https://arxiv.org/abs/2302.09409v1",
          "size": "5283kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T15:13:36+00:00",
          "link": "https://arxiv.org/abs/2302.09409v2",
          "size": "17307kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T13:42:41+00:00",
          "link": "https://arxiv.org/abs/2302.09409v3",
          "size": "2090kb",
          "version": "v3"
        }
      ],
      "title": "LOCUS: LOcalization with Channel Uncertainty and Sporadic Energy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.09409",
        "HTML": "https://arxiv.org/html/2302.09409v3",
        "PDF": "https://arxiv.org/pdf/2302.09409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "LOCUS presents a deep learning framework that improves data quality under missing-channel conditions in sound source localization. It releases a multichannel dataset, contributing to new dataset creation and data quality improvement, relevant to LLM training data processing."
      },
      "tasks": [
        "Event Detection",
        "Missing Elements",
        "Sound Event Detection",
        "Sound Source Localization",
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.18162",
      "abstract": "Machine reading comprehension has been an interesting and challenging task in recent years, with the purpose of extracting useful information from texts. To attain the computer ability to understand the reading text and answer relevant information, we introduce ViMMRC 2.0 - an extension of the previous ViMMRC for the task of multiple-choice reading comprehension in Vietnamese Textbooks which contain the reading articles for students from Grade 1 to Grade 12. This dataset has 699 reading passages which are prose and poems, and 5,273 questions. The questions in the new dataset are not fixed with four options as in the previous version. Moreover, the difficulty of questions is increased, which challenges the models to find the correct choice. The computer must understand the whole context of the reading passage, the question, and the content of each choice to extract the right answers. Hence, we propose a multi-stage approach that combines the multi-step attention network (MAN) with the natural language inference (NLI) task to enhance the performance of the reading comprehension model. Then, we compare the proposed methodology with the baseline BERTology models on the new dataset and the ViMMRC 1.0. From the results of the error analysis, we found that the challenge of the reading comprehension models is understanding the implicit context in texts and linking them together in order to find the correct answers. Finally, we hope our new dataset will motivate further research to enhance the ability of computers to understand the Vietnamese language.",
      "authors": [
        "Son T. Luu",
        "Khoi Trong Hoang",
        "Tuong Quang Pham",
        "Kiet Van Nguyen",
        "Ngan Luu-Thuy Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-31T15:54:54+00:00",
          "link": "https://arxiv.org/abs/2303.18162v1",
          "size": "1894kb",
          "version": "v1"
        },
        {
          "date": "2025-06-08T00:58:52+00:00",
          "link": "https://arxiv.org/abs/2303.18162v2",
          "size": "1452kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T02:55:01+00:00",
          "link": "https://arxiv.org/abs/2303.18162v3",
          "size": "1452kb",
          "version": "v3"
        }
      ],
      "title": "ViMMRC 2.0 -- Enhancing Machine Reading Comprehension on Vietnamese Literature Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.18162",
        "HTML": "https://arxiv.org/html/2303.18162v3",
        "PDF": "https://arxiv.org/pdf/2303.18162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces ViMMRC 2.0, a new dataset for machine reading comprehension in Vietnamese, expanding upon its predecessor with increased complexity. This directly contributes to LLM training data processing through dataset creation and enhancement."
      },
      "tasks": [
        "Articles",
        "Machine Reading Comprehension",
        "Multiple-choice",
        "Natural Language Inference",
        "Reading Comprehension"
      ],
      "repo_urls": [
        "https://github.com/sonlam1102/vimmrc2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.06049",
      "abstract": "Over the past decade, neural network (NN)-based controllers have demonstrated remarkable efficacy in a variety of decision-making tasks. However, their black-box nature and the risk of unexpected behaviors pose a challenge to their deployment in real-world systems requiring strong guarantees of correctness and safety. We address these limitations by investigating the transformation of NN-based controllers into equivalent soft decision tree (SDT)-based controllers and its impact on verifiability. In contrast to existing work, we focus on discrete-output NN controllers including rectified linear unit (ReLU) activation functions as well as argmax operations. We then devise an exact yet efficient transformation algorithm which automatically prunes redundant branches. We first demonstrate the practical efficacy of the transformation algorithm applied to an autonomous driving NN controller within OpenAI Gym's CarRacing environment. Subsequently, we evaluate our approach using two benchmarks from the OpenAI Gym environment. Our results indicate that the SDT transformation can benefit formal verification, showing runtime improvements of up to $21 \\times$ and $2 \\times$ for MountainCar-v0 and CartPole-v1, respectively.",
      "authors": [
        "Kevin Chang",
        "Nathan Dahlin",
        "Rahul Jain and Pierluigi Nuzzo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-11T19:52:30+00:00",
          "link": "https://arxiv.org/abs/2304.06049v1",
          "size": "1045kb",
          "version": "v1"
        },
        {
          "date": "2023-09-16T00:52:18+00:00",
          "link": "https://arxiv.org/abs/2304.06049v2",
          "size": "1302kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T15:52:36+00:00",
          "link": "https://arxiv.org/abs/2304.06049v3",
          "size": "2786kb",
          "version": "v3"
        }
      ],
      "title": "Equivalent and Compact Representations of Neural Network Controllers With Decision Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.06049",
        "HTML": "https://arxiv.org/html/2304.06049v3",
        "PDF": "https://arxiv.org/pdf/2304.06049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research discusses transforming neural network controllers into decision trees to improve verifiability. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "OpenAI Gym"
      ],
      "source": "arXiv"
    },
    {
      "id": "2305.14080",
      "abstract": "The latest developments in computer hardware, sensor technologies, and artificial intelligence can make virtual reality (VR) and virtual spaces an important part of human everyday life. Eye tracking offers not only a hands-free way of interaction but also the possibility of a deeper understanding of human visual attention and cognitive processes in VR. Despite these possibilities, eye-tracking data also reveals users' privacy-sensitive attributes when combined with the information about the presented stimulus. To address all these possibilities and potential privacy issues, in this survey, we first cover major works in eye tracking, VR, and privacy areas between 2012 and 2022. While eye tracking in the VR part covers the complete pipeline of eye-tracking methodology from pupil detection and gaze estimation to offline use of the data and analyses, as for privacy and security, we focus on eye-based authentication as well as computational methods to preserve the privacy of individuals and their eye-tracking data in VR. Later, considering all of these, we draw three main directions for the research community by focusing on privacy challenges. In summary, this survey provides an extensive literature review of the utmost possibilities with eye tracking in VR and the privacy implications of those possibilities.",
      "authors": [
        "Efe Bozkir and S\\\"uleyman \\\"Ozdel and Mengdi Wang and Brendan David-John and Hong Gao and Kevin Butler and Eakta Jain and Enkelejda Kasneci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-23T14:02:38+00:00",
          "link": "https://arxiv.org/abs/2305.14080v1",
          "size": "10051kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:40:04+00:00",
          "link": "https://arxiv.org/abs/2305.14080v2",
          "size": "10232kb",
          "version": "v2"
        }
      ],
      "title": "Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and Privacy Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.14080",
        "HTML": "https://arxiv.org/html/2305.14080v2",
        "PDF": "https://arxiv.org/pdf/2305.14080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on eye tracking in virtual reality and privacy challenges, and it does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Gaze Estimation",
        "Pupil Detection",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2306.15375",
      "abstract": "We present a new design for an algebraic simplification library structured around concepts from universal algebra: theories, models, homomorphisms, and universal properties of free algebras and free extensions of algebras. The library's dependently typed interface guarantees that both built-in and user-defined simplification modules are terminating, sound, and complete with respect to a well-specified class of equations. We have implemented the design in the Idris 2 and Agda dependently typed programming languages and shown that it supports modular extension to new theories, proof extraction and certification, goal extraction via reflection, and interactive development.",
      "authors": [
        "Guillaume Allais",
        "Edwin Brady",
        "Nathan Corbyn",
        "Ohad Kammar",
        "Jeremy Yallop"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-27T10:47:22+00:00",
          "link": "https://arxiv.org/abs/2306.15375v1",
          "size": "547kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:57:21+00:00",
          "link": "https://arxiv.org/abs/2306.15375v2",
          "size": "473kb",
          "version": "v2"
        }
      ],
      "title": "Frex: dependently-typed algebraic simplification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.15375",
        "HTML": "https://arxiv.org/html/2306.15375v2",
        "PDF": "https://arxiv.org/pdf/2306.15375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with algebraic simplification using dependently-typed interfaces, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.15457",
      "abstract": "In this work, we present an iteratively decoupled algorithm for solving the quasi-static multiple-network poroelastic model. Our approach employs a total-pressure-based formulation with solid displacement, total pressure, and network pressures as primary unknowns. This reformulation decomposes the original problem into a generalized Stokes problem and a parabolic problem, offering key advantages such as reduced elastic locking effects and simplified discretization. The algorithm guarantees unconditional convergence to the solution of the fully coupled system. Numerical experiments demonstrate the accuracy, efficiency, and robustness of the method with respect to physical parameters and discretization. We further apply the algorithm to simulate the brain edema process, showcasing its practical utility in biomechanical modeling.",
      "authors": [
        "Mingchao Cai",
        "Meng Lei",
        "Jingzhi Li",
        "Jiaao Sun",
        "Feng Wang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-24T02:11:15+00:00",
          "link": "https://arxiv.org/abs/2310.15457v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2023-10-28T00:25:10+00:00",
          "link": "https://arxiv.org/abs/2310.15457v2",
          "size": "117kb",
          "version": "v2"
        },
        {
          "date": "2025-03-28T11:39:40+00:00",
          "link": "https://arxiv.org/abs/2310.15457v3",
          "size": "1443kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T12:08:18+00:00",
          "link": "https://arxiv.org/abs/2310.15457v4",
          "size": "1453kb",
          "version": "v4"
        }
      ],
      "title": "An Iteratively Decoupled Algorithm for Multiple-Network Poroelastic Model with Applications in Brain Edema Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.15457",
        "HTML": "https://arxiv.org/html/2310.15457v4",
        "PDF": "https://arxiv.org/pdf/2310.15457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an algorithm for a poroelastic model applied to brain edema simulations, which does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.04938",
      "abstract": "We propose using a Gaussian Mixture Model (GMM) as reverse transition operator (kernel) within the Denoising Diffusion Implicit Models (DDIM) framework, which is one of the most widely used approaches for accelerated sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM). Specifically we match the first and second order central moments of the DDPM forward marginals by constraining the parameters of the GMM. We see that moment matching is sufficient to obtain samples with equal or better quality than the original DDIM with Gaussian kernels. We provide experimental results with unconditional models trained on CelebAHQ and FFHQ and class-conditional models trained on ImageNet datasets respectively. Our results suggest that using the GMM kernel leads to significant improvements in the quality of the generated samples when the number of sampling steps is small, as measured by FID and IS metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73 respectively with a Gaussian kernel.",
      "authors": [
        "Prasad Gabbur"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-08T00:24:50+00:00",
          "link": "https://arxiv.org/abs/2311.04938v1",
          "size": "15410kb",
          "version": "v1"
        },
        {
          "date": "2024-01-18T00:44:11+00:00",
          "link": "https://arxiv.org/abs/2311.04938v2",
          "size": "15437kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T13:31:06+00:00",
          "link": "https://arxiv.org/abs/2311.04938v3",
          "size": "17242kb",
          "version": "v3"
        }
      ],
      "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.04938",
        "PDF": "https://arxiv.org/pdf/2311.04938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses improving DDIM sampling using Gaussian Mixture Models for diffusion probabilistic models, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.04242",
      "abstract": "The control of dynamical systems under temporal logic specifications among uncontrollable dynamic agents is challenging due to the agents' a-priori unknown behavior. Existing works have considered the problem where either all agents are controllable, the agent models are deterministic and known, or no safety guarantees are provided. We propose a predictive control synthesis framework that guarantees, with high probability, the satisfaction of signal temporal logic (STL) tasks that are defined over a controllable system in the presence of uncontrollable stochastic agents. We use trajectory predictors and conformal prediction to construct probabilistic prediction regions for each uncontrollable agent that are valid over multiple future time steps. Specifically, we construct a normalized prediction region over all agents and time steps to reduce conservatism and increase data efficiency. We then formulate a worst-case bilevel mixed integer program (MIP) that accounts for all agent realizations within the prediction region to obtain an open-loop controller that provably guarantee task satisfaction with high probability. To efficiently solve this bilevel MIP, we propose an equivalent MIP program based on KKT conditions of the original bilevel formulation. Building upon this, we design a closed-loop controller, where both recursive feasibility and task satisfaction can be guaranteed with high probability. We illustrate our control synthesis framework on two case studies.",
      "authors": [
        "Xinyi Yu",
        "Yiqi Zhao",
        "Xiang Yin",
        "Lars Lindemann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-07T11:58:58+00:00",
          "link": "https://arxiv.org/abs/2312.04242v1",
          "size": "96kb",
          "version": "v1"
        },
        {
          "date": "2024-10-13T20:45:12+00:00",
          "link": "https://arxiv.org/abs/2312.04242v2",
          "size": "107kb",
          "version": "v2"
        },
        {
          "date": "2025-05-13T07:47:43+00:00",
          "link": "https://arxiv.org/abs/2312.04242v3",
          "size": "126kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T00:30:39+00:00",
          "link": "https://arxiv.org/abs/2312.04242v4",
          "size": "110kb",
          "version": "v4"
        }
      ],
      "title": "Signal Temporal Logic Control Synthesis among Uncontrollable Dynamic Agents with Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.04242",
        "HTML": "https://arxiv.org/html/2312.04242v4",
        "PDF": "https://arxiv.org/pdf/2312.04242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses control synthesis for dynamical systems with temporal logic specifications, which is not related to LLM training data processing."
      },
      "tasks": [
        "Conformal Prediction",
        "Prediction",
        "valid"
      ],
      "repo_urls": [
        "https://github.com/saids-lab/stl-synthesis-among-uncontrollable-agents"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.14831",
      "abstract": "The verification of asynchronous software components poses significant challenges due to the way components interleave and exchange input/output data concurrently. Compositional strategies aim to address this by separating the task of verifying individual components on local properties from the task of combining them to achieve global properties. This paper concentrates on employing symbolic model checking techniques to verify properties specified in Linear-time Temporal Logic (LTL) on asynchronous software components that interact through data ports. Unlike event-based composition, local properties can now impose constraints on input from other components, increasing the complexity of their composition. We consider both the standard semantics over infinite traces as well as the truncated semantics over finite traces to allow scheduling components only finitely many times.\n  We propose a novel LTL rewriting approach, which converts a local property into a global one while considering the interleaving of infinite or finite execution traces of components. We prove the semantic equivalence of local properties and their rewritten version projected on the local symbols. The rewriting is also optimized to reduce formula size and to leave it unchanged when the temporal property is stutter invariant. These methods have been integrated into the OCRA tool, as part of the contract refinement verification suite. Finally, the different composition approaches were compared through an experimental evaluation that covers various types of specifications.",
      "authors": [
        "Alberto Bombardelli and Stefano Tonetta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-22T17:06:39+00:00",
          "link": "https://arxiv.org/abs/2312.14831v1",
          "size": "1726kb",
          "version": "v1"
        },
        {
          "date": "2025-01-11T08:39:07+00:00",
          "link": "https://arxiv.org/abs/2312.14831v2",
          "size": "1493kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T07:34:58+00:00",
          "link": "https://arxiv.org/abs/2312.14831v3",
          "size": "247kb",
          "version": "v3"
        }
      ],
      "title": "Asynchronous Composition of LTL Properties over Infinite and Finite Traces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.14831",
        "HTML": "https://arxiv.org/html/2312.14831v3",
        "PDF": "https://arxiv.org/pdf/2312.14831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about verifying properties in asynchronous software components using temporal logic, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.08080",
      "abstract": "The use of partially automated driving systems raises concerns about potential responsibility issues, posing risk to the system safety, acceptance, and adoption of these technologies. The concept of meaningful human control has emerged in response to the responsibility gap problem, requiring the fulfillment of two conditions, tracking and tracing. While this concept has provided important philosophical and design insights on automated driving systems, there is currently little knowledge on how meaningful human control relates to subjective experiences of actual users of these systems. To address this gap, our study aimed to investigate the alignment between the degree of meaningful human control and drivers' perceptions of safety and trust in a real-world partially automated driving system. We utilized previously collected data from interviews with Tesla \"Full Self-Driving\" (FSD) Beta users, investigating the alignment between the user perception and how well the system was tracking the users' reasons. We found that tracking of users' reasons for driving tasks (such as safe maneuvers) correlated with perceived safety and trust, albeit with notable exceptions. Surprisingly, failure to track lane changing and braking reasons was not necessarily associated with negative perceptions of safety. However, the failure of the system to track expected maneuvers in dangerous situations always resulted in low trust and perceived lack of safety. Overall, our analyses highlight alignment points but also possible discrepancies between perceived safety and trust on the one hand, and meaningful human control on the other hand. Our results can help the developers of automated driving technology to design systems under meaningful human control and are perceived as safe and trustworthy.",
      "authors": [
        "Lucas Elbert Suryana",
        "Sina Nordhoff",
        "Simeon C. Calvert",
        "Arkady Zgonnikov and Bart van Arem"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-12T21:48:57+00:00",
          "link": "https://arxiv.org/abs/2402.08080v1",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:31:17+00:00",
          "link": "https://arxiv.org/abs/2402.08080v2",
          "size": "73kb",
          "version": "v2"
        }
      ],
      "title": "A Meaningful Human Control Perspective on User Perception of Partially Automated Driving Systems: A Case Study of Tesla Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.08080",
        "HTML": "https://arxiv.org/html/2402.08080v2",
        "PDF": "https://arxiv.org/pdf/2402.08080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on user perception of partially automated driving systems and meaningful human control, lacking any connection to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.09816",
      "abstract": "Deep Learning (DL) is undergoing a paradigm shift with the emergence of foundation models. In this work, we focus on Contrastive Language-Image Pre-training (CLIP), a Vision-Language foundation model that achieves high accuracy across various image classification tasks and often rivals fully supervised baselines, despite not being explicitly trained for those tasks. Nevertheless, there are still domains where zero-shot CLIP performance is far from optimal, such as Remote Sensing (RS) and medical imagery. These domains do not only exhibit fundamentally different distributions compared to natural images, but also commonly rely on complementary modalities, beyond RGB, to derive meaningful insights. To this end, we propose a methodology to align distinct RS image modalities with the visual and textual modalities of CLIP. Our two-stage procedure addresses the aforementioned distribution shift, extends the zero-shot capabilities of CLIP and enriches CLIP's shared embedding space with domain-specific knowledge. Initially, we robustly fine-tune CLIP according to the PAINT (Ilharco et al., 2022) patching protocol, in order to deal with the distribution shift. Building upon this foundation, we facilitate the cross-modal alignment of a RS modality encoder by distilling knowledge from the CLIP visual and textual encoders. We empirically show that both patching and cross-modal alignment translate to significant performance gains, across several RS imagery classification and cross-modal retrieval benchmark datasets. Notably, these enhancements are achieved without the reliance on textual descriptions, without introducing any task-specific parameters, without training from scratch and without catastrophic forgetting. We make our code implementation and weights for all experiments publicly available at https://github.com/Orion-AI-Lab/MindTheModalityGap.",
      "authors": [
        "Angelos Zavras",
        "Dimitrios Michail",
        "Beg\\\"um Demir",
        "Ioannis Papoutsis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-15T09:31:07+00:00",
          "link": "https://arxiv.org/abs/2402.09816v1",
          "size": "3790kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:42:52+00:00",
          "link": "https://arxiv.org/abs/2402.09816v2",
          "size": "8475kb",
          "version": "v2"
        }
      ],
      "title": "Mind the Modality Gap: Towards a Remote Sensing Vision-Language Model via Cross-modal Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09816",
        "HTML": "https://arxiv.org/html/2402.09816v2",
        "PDF": "https://arxiv.org/pdf/2402.09816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves adapting a vision-language model to a specific domain (remote sensing imagery), its focus is cross-modal alignment and fine-tuning, not directly on LLM training data processing. However, the methodology could indirectly benefit data processing for aligning textual and image data."
      },
      "tasks": [
        "cross-modal alignment",
        "Cross-Modal Retrieval",
        "image-classification",
        "Image Classification",
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.10310",
      "abstract": "Imitation learning methods have demonstrated considerable success in teaching autonomous systems complex tasks through expert demonstrations. However, a limitation of these methods is their lack of interpretability, particularly in understanding the specific task the learning agent aims to accomplish. In this paper, we propose a novel imitation learning method that combines Signal Temporal Logic (STL) inference and control synthesis, enabling the explicit representation of the task as an STL formula. This approach not only provides a clear understanding of the task but also supports the integration of human knowledge and allows for adaptation to out-of-distribution scenarios by manually adjusting the STL formulas and fine-tuning the policy. We employ a Generative Adversarial Network (GAN)-inspired approach to train both the inference and policy networks, effectively narrowing the gap between expert and learned policies. The efficiency of our algorithm is demonstrated through simulations, showcasing its practical applicability and adaptability.",
      "authors": [
        "Wenliang Liu",
        "Danyang Li",
        "Erfan Aasi",
        "Daniela Rus",
        "Roberto Tron",
        "Calin Belta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-15T20:21:40+00:00",
          "link": "https://arxiv.org/abs/2402.10310v1",
          "size": "10399kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:44:19+00:00",
          "link": "https://arxiv.org/abs/2402.10310v2",
          "size": "4651kb",
          "version": "v2"
        }
      ],
      "title": "Interpretable Imitation Learning via Generative Adversarial STL Inference and Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.10310",
        "HTML": "https://arxiv.org/html/2402.10310v2",
        "PDF": "https://arxiv.org/pdf/2402.10310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new imitation learning method to enhance the interpretability of learning tasks and policies; it does not deal with data processing aspects for LLM training."
      },
      "tasks": [
        "Generative Adversarial Network",
        "Imitation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.14009",
      "abstract": "Geometry is a ubiquitous tool in computer graphics, design, and engineering. However, the lack of large shape datasets limits the application of state-of-the-art supervised learning methods and motivates the exploration of alternative learning strategies. To this end, we introduce geometry-informed neural networks (GINNs) -- a framework for training shape-generative neural fields without data by leveraging user-specified design requirements in the form of objectives and constraints. By adding diversity as an explicit constraint, GINNs avoid mode-collapse and can generate multiple diverse solutions, often required in geometry tasks. Experimentally, we apply GINNs to several problems spanning physics, geometry, and engineering design, showing control over geometrical and topological properties, such as surface smoothness or the number of holes. These results demonstrate the potential of training shape-generative models without data, paving the way for new generative design approaches without large datasets.",
      "authors": [
        "Arturs Berzins",
        "Andreas Radler",
        "Eric Volkmann",
        "Sebastian Sanokowski",
        "Sepp Hochreiter",
        "Johannes Brandstetter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-21T18:50:12+00:00",
          "link": "https://arxiv.org/abs/2402.14009v1",
          "size": "8639kb",
          "version": "v1"
        },
        {
          "date": "2024-05-27T16:12:14+00:00",
          "link": "https://arxiv.org/abs/2402.14009v2",
          "size": "6585kb",
          "version": "v2"
        },
        {
          "date": "2024-10-14T14:15:05+00:00",
          "link": "https://arxiv.org/abs/2402.14009v3",
          "size": "3562kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T09:22:26+00:00",
          "link": "https://arxiv.org/abs/2402.14009v4",
          "size": "2903kb",
          "version": "v4"
        }
      ],
      "title": "Geometry-Informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.14009",
        "HTML": "https://arxiv.org/html/2402.14009v4",
        "PDF": "https://arxiv.org/pdf/2402.14009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces geometry-informed neural networks for shape generation without data, primarily addressing the fields of geometry and design, not LLM training data processing."
      },
      "tasks": [
        "Diversity"
      ],
      "repo_urls": [
        "https://github.com/ml-jku/ginns-geometry-informed-neural-networks"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.14143",
      "abstract": "Movement disorder diagnosis often relies on expert evaluation of patient videos, but sharing these videos poses privacy risks. Current methods for de-identifying videos, such as blurring faces, are often manual, inconsistent, or inaccurate. Furthermore, these methods can compromise objective kinematic analysis - a crucial component of diagnosis. To address these challenges, we developed SecurePose, an open-source software that simultaneously provides reliable de-identification and automated kinematic extraction from videos recorded in clinic settings using smartphones/tablets. SecurePose utilizes pose estimation (using OpenPose) to extract full body kinematics, track individuals, identify the patient, and then accurately blur faces in the videos. We validated SecurePose on gait videos recorded in outpatient clinic visits of 116 children with cerebral palsy, assessing both the accuracy of its de-identification compared to the ground truth (manual blurring) and the reliability of the intermediate steps of kinematics extraction. Results demonstrate that SecurePose outperformed six existing methods in automated face detection and achieved comparable accuracy to robust manual blurring, but in significantly less time (91.08% faster). Ten experienced researchers also confirmed SecurePose's usability via System Usability Scale scores. These findings validate SecurePose as a practical and effective tool for protecting patient privacy while enabling accurate kinematics extraction in clinical settings.",
      "authors": [
        "Rishabh Bajpai and Bhooma Aravamuthan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-21T21:55:29+00:00",
          "link": "https://arxiv.org/abs/2402.14143v1",
          "size": "4467kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:01:33+00:00",
          "link": "https://arxiv.org/abs/2402.14143v2",
          "size": "765kb",
          "version": "v2"
        }
      ],
      "title": "SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.14143",
        "PDF": "https://arxiv.org/pdf/2402.14143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes SecurePose, a tool for kinematics extraction and de-identification in clinical videos, which is unrelated to LLM training data processing techniques or methodologies."
      },
      "tasks": [
        "Face Detection",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.07486",
      "abstract": "In recent years, Explainable AI (XAI) methods have facilitated profound validation and knowledge extraction from ML models. While extensively studied for classification, few XAI solutions have addressed the challenges specific to regression models. In regression, explanations need to be precisely formulated to address specific user queries (e.g.\\ distinguishing between `Why is the output above 0?' and `Why is the output above 50?'). They should furthermore reflect the model's behavior on the relevant data sub-manifold. In this paper, we introduce XpertAI, a framework that disentangles the prediction strategy into multiple range-specific sub-strategies and allows the formulation of precise queries about the model (the `explanandum') as a linear combination of those sub-strategies. XpertAI is formulated generally to work alongside popular XAI attribution techniques, based on occlusion, gradient integration, or reverse propagation. Qualitative and quantitative results, demonstrate the benefits of our approach.",
      "authors": [
        "Simon Letzgus",
        "Klaus-Robert M\\\"uller",
        "and Gr\\'egoire Montavon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-12T10:21:31+00:00",
          "link": "https://arxiv.org/abs/2403.07486v1",
          "size": "1608kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T15:08:37+00:00",
          "link": "https://arxiv.org/abs/2403.07486v2",
          "size": "3822kb",
          "version": "v2"
        },
        {
          "date": "2025-04-04T19:52:12+00:00",
          "link": "https://arxiv.org/abs/2403.07486v3",
          "size": "3553kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T11:06:13+00:00",
          "link": "https://arxiv.org/abs/2403.07486v4",
          "size": "3348kb",
          "version": "v4"
        }
      ],
      "title": "XpertAI: uncovering regression model strategies for sub-manifolds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.07486",
        "HTML": "https://arxiv.org/html/2403.07486v4",
        "PDF": "https://arxiv.org/pdf/2403.07486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Explainable AI methods for regression models, specifically targeting strategies for explaining regression outputs. It does not address any aspects of LLM training data processing."
      },
      "tasks": [
        "model",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.13740",
      "abstract": "The lack of transparency of Deep Neural Networks continues to be a limitation that severely undermines their reliability and usage in high-stakes applications. Promising approaches to overcome such limitations are Prototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions rely on the similarity between the input at hand and a set of prototypical representations of the output classes, offering therefore a deep, yet transparent-by-design, architecture. In this paper, we introduce a probabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point estimates for the prototypes with probability distributions over their values. This provides not only a more flexible framework for an end-to-end learning of prototypes, but can also capture the explanatory uncertainty of the model, which is a missing feature in previous approaches. In addition, since the prototypes determine both the explanation and the prediction, Prob-PSENNs allow us to detect when the model is making uninformed or uncertain predictions, and to obtain valid explanations for them. Our experiments demonstrate that Prob-PSENNs provide more meaningful and robust explanations than their non-probabilistic counterparts, while remaining competitive in terms of predictive performance, thus enhancing the explainability and reliability of the models.",
      "authors": [
        "Jon Vadillo",
        "Roberto Santana",
        "Jose A. Lozano",
        "Marta Kwiatkowska"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-20T16:47:28+00:00",
          "link": "https://arxiv.org/abs/2403.13740v1",
          "size": "8744kb",
          "version": "v1"
        },
        {
          "date": "2025-02-14T17:30:15+00:00",
          "link": "https://arxiv.org/abs/2403.13740v2",
          "size": "13257kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T17:19:59+00:00",
          "link": "https://arxiv.org/abs/2403.13740v3",
          "size": "13637kb",
          "version": "v3"
        }
      ],
      "title": "Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.13740",
        "HTML": "https://arxiv.org/html/2403.13740v3",
        "PDF": "https://arxiv.org/pdf/2403.13740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a probabilistic reformulation of Prototype-Based Self-Explainable Neural Networks to enhance transparency and reliability. It does not discuss LLM training data processing or any related data operations."
      },
      "tasks": [
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.14559",
      "abstract": "Localizing predefined 3D keypoints in a 2D image is an effective way to establish 3D-2D correspondences for instance-level 6DoF object pose estimation. However, unreliable localization results of invisible keypoints degrade the quality of correspondences. In this paper, we address this issue by localizing the important keypoints in terms of visibility. Since keypoint visibility information is currently missing in the dataset collection process, we propose an efficient way to generate binary visibility labels from available object-level annotations, for keypoints of both asymmetric objects and symmetric objects. We further derive real-valued visibility-aware importance from binary labels based on the PageRank algorithm. Taking advantage of the flexibility of our visibility-aware importance, we construct VAPO (Visibility-Aware POse estimator) by integrating the visibility-aware importance with a state-of-the-art pose estimation algorithm, along with additional positional encoding. VAPO can work in both CAD-based and CAD-free settings. Extensive experiments are conducted on popular pose estimation benchmarks including Linemod, Linemod-Occlusion, and YCB-V, demonstrating that VAPO clearly achieves state-of-the-art performances. Project page: https://github.com/RuyiLian/VAPO.",
      "authors": [
        "Ruyi Lian",
        "Yuewei Lin",
        "Longin Jan Latecki",
        "Haibin Ling"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-21T16:59:45+00:00",
          "link": "https://arxiv.org/abs/2403.14559v1",
          "size": "16949kb",
          "version": "v1"
        },
        {
          "date": "2025-01-01T20:36:45+00:00",
          "link": "https://arxiv.org/abs/2403.14559v2",
          "size": "17284kb",
          "version": "v2"
        },
        {
          "date": "2025-02-18T21:16:27+00:00",
          "link": "https://arxiv.org/abs/2403.14559v3",
          "size": "17377kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T20:41:43+00:00",
          "link": "https://arxiv.org/abs/2403.14559v4",
          "size": "708kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T03:15:30+00:00",
          "link": "https://arxiv.org/abs/2403.14559v5",
          "size": "708kb",
          "version": "v5"
        }
      ],
      "title": "VAPO: Visibility-Aware Keypoint Localization for Efficient 6DoF Object Pose Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.14559",
        "HTML": "https://arxiv.org/html/2403.14559v5",
        "PDF": "https://arxiv.org/pdf/2403.14559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a keypoint localization method for object pose estimation rather than LLM training data processing. It does not address training data generation, collection, or improvement for language models."
      },
      "tasks": [
        "Object",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.04834",
      "abstract": "Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This paper explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this paper, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.",
      "authors": [
        "Junda He",
        "Christoph Treude",
        "David Lo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-07T07:05:40+00:00",
          "link": "https://arxiv.org/abs/2404.04834v1",
          "size": "35kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T10:28:25+00:00",
          "link": "https://arxiv.org/abs/2404.04834v2",
          "size": "69kb",
          "version": "v2"
        },
        {
          "date": "2024-12-20T06:01:33+00:00",
          "link": "https://arxiv.org/abs/2404.04834v3",
          "size": "1093kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T05:02:11+00:00",
          "link": "https://arxiv.org/abs/2404.04834v4",
          "size": "1094kb",
          "version": "v4"
        }
      ],
      "title": "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.04834",
        "HTML": "https://arxiv.org/html/2404.04834v4",
        "PDF": "https://arxiv.org/pdf/2404.04834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the integration of LLMs into Multi-Agent Systems for software engineering challenges. It does not focus on training data processing for LLMs, nor does it detail operations such as data collection or filtering for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.07053",
      "abstract": "Metaphors, although occasionally unperceived, are ubiquitous in our everyday language. Thus, it is crucial for Language Models to be able to grasp the underlying meaning of this kind of figurative language. In this work, we present Meta4XNLI, a novel parallel dataset for the tasks of metaphor detection and interpretation that contains metaphor annotations in both Spanish and English. We investigate language models' metaphor identification and understanding abilities through a series of monolingual and cross-lingual experiments by leveraging our proposed corpus. In order to comprehend how these non-literal expressions affect models' performance, we look over the results and perform an error analysis. Additionally, parallel data offers many potential opportunities to investigate metaphor transferability between these languages and the impact of translation on the development of multilingual annotated resources.",
      "authors": [
        "Elisa Sanchez-Bayona",
        "Rodrigo Agerri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T14:44:48+00:00",
          "link": "https://arxiv.org/abs/2404.07053v1",
          "size": "150kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T15:03:29+00:00",
          "link": "https://arxiv.org/abs/2404.07053v2",
          "size": "1847kb",
          "version": "v2"
        }
      ],
      "title": "Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and Interpretation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.07053",
        "HTML": "https://arxiv.org/html/2404.07053v2",
        "PDF": "https://arxiv.org/pdf/2404.07053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on metaphor detection and interpretation using a crosslingual corpus, which is not directly related to LLM training data processing for pretraining or fine-tuning."
      },
      "models": [
        {
          "model_path": "HiTZ/mdeberta-metaphor-detection-multilang-es_en",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/HiTZ/mdeberta-metaphor-detection-multilang-es_en"
        },
        {
          "model_path": "HiTZ/xlm-roberta-large-metaphor-interpretationNLI-es",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/HiTZ/xlm-roberta-large-metaphor-interpretationNLI-es"
        },
        {
          "model_path": "HiTZ/xlm-roberta-large-metaphor-interpretationNLI-en",
          "downloads": "10",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/HiTZ/xlm-roberta-large-metaphor-interpretationNLI-en"
        }
      ],
      "datasets": [
        {
          "dataset_name": "HiTZ/meta4xnli",
          "downloads": "20",
          "likes": "1",
          "link": "https://huggingface.co/datasets/HiTZ/meta4xnli"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/elisanchez-beep/meta4xnli"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.03536",
      "abstract": "Following Milner's seminal paper, the representation of functions as processes has received considerable attention. For pure $\\lambda$-calculus, the process representations yield (at best) non-extensional $\\lambda $-theories (i.e., $\\beta$ rule holds, whereas $\\eta$ does not).\n  In the paper, we study how to obtain extensional representations, and how to move between extensional and non-extensional representations. Using Internal $\\pi$, $\\mathrm{I}\\pi$ (a subset of the $\\pi$-calculus in which all outputs are bound), we develop a refinement of Milner's original encoding of functions as processes that is parametric on certain abstract components called wires. These are, intuitively, processes whose task is to connect two end-point channels. We show that when a few algebraic properties of wires hold, the encoding yields a $\\lambda$-theory. Exploiting the symmetries and dualities of $\\mathrm{I}\\pi$, we isolate three main classes of wires. The first two have a sequential behaviour and are dual of each other; the third has a parallel behaviour and is the dual of itself. We show the adoption of the parallel wires yields an extensional $\\lambda$-theory; in fact, it yields an equality that coincides with that of B\\\"ohm trees with infinite $\\eta$. In contrast, the other two classes of wires yield non-extensional $\\lambda$-theories whose equalities are those of the L\\'evy-Longo and B\\\"ohm trees.",
      "authors": [
        "Ken Sakayori",
        "Davide Sangiorgi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-06T14:53:58+00:00",
          "link": "https://arxiv.org/abs/2405.03536v1",
          "size": "72kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T13:36:48+00:00",
          "link": "https://arxiv.org/abs/2405.03536v2",
          "size": "75kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T00:06:47+00:00",
          "link": "https://arxiv.org/abs/2405.03536v3",
          "size": "75kb",
          "version": "v3"
        }
      ],
      "title": "Extensional and Non-extensional Functions as Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.03536",
        "HTML": "https://arxiv.org/html/2405.03536v3",
        "PDF": "https://arxiv.org/pdf/2405.03536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with the representation of functions as processes in the context of lambda calculus and process calculus, which is not related to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.13999",
      "abstract": "The performance of physical workers is significantly influenced by the extent of their motions. However, monitoring and assessing these motions remains a challenge. Recent advancements have enabled in-situ video analysis for real-time observation of worker behaviors. This paper introduces a novel framework for tracking and quantifying upper and lower limb motions, issuing alerts when critical thresholds are reached. Using joint position data from posture estimation, the framework employs Hotelling's $T^2$ statistic to quantify and monitor motion amounts. A significant positive correlation was noted between motion warnings and the overall NASA Task Load Index (TLX) workload rating (\\textit{r} = 0.218, \\textit{p} = 0.0024). A supervised Random Forest model trained on the collected motion data was benchmarked against multiple datasets including UCF Sports Action and UCF50, and was found to effectively generalize across environments, identifying ergonomic risk patterns with accuracies up to 94\\%.",
      "authors": [
        "Hari Iyer",
        "Neel Macwan",
        "Shenghan Guo",
        "Heejin Jeong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-22T21:15:03+00:00",
          "link": "https://arxiv.org/abs/2405.13999v1",
          "size": "10520kb",
          "version": "v1"
        },
        {
          "date": "2024-11-19T07:45:30+00:00",
          "link": "https://arxiv.org/abs/2405.13999v2",
          "size": "2597kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T16:55:42+00:00",
          "link": "https://arxiv.org/abs/2405.13999v3",
          "size": "2369kb",
          "version": "v3"
        }
      ],
      "title": "Computer-Vision-Enabled Worker Video Analysis for Motion Amount Quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.13999",
        "HTML": "https://arxiv.org/html/2405.13999v3",
        "PDF": "https://arxiv.org/pdf/2405.13999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about using computer vision for motion analysis of physical workers, which does not involve any LLM training data processing operations or the creation of datasets for large language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.18386",
      "abstract": "Recent advances in text-to-music editing, which employ text queries to modify music (e.g.\\ by changing its style or adjusting instrumental components), present unique challenges and opportunities for AI-assisted music creation. Previous approaches in this domain have been constrained by the necessity to train specific editing models from scratch, which is both resource-intensive and inefficient; other research uses large language models to predict edited music, resulting in imprecise audio reconstruction. To Combine the strengths and address these limitations, we introduce Instruct-MusicGen, a novel approach that finetunes a pretrained MusicGen model to efficiently follow editing instructions such as adding, removing, or separating stems. Our approach involves a modification of the original MusicGen architecture by incorporating a text fusion module and an audio fusion module, which allow the model to process instruction texts and audio inputs concurrently and yield the desired edited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters to the original MusicGen model and only trains for 5K steps, yet it achieves superior performance across all tasks compared to existing baselines, and demonstrates performance comparable to the models trained for specific tasks. This advancement not only enhances the efficiency of text-to-music editing but also broadens the applicability of music language models in dynamic music production environments.",
      "authors": [
        "Yixiao Zhang",
        "Yukara Ikemiya",
        "Woosung Choi",
        "Naoki Murata",
        "Marco A. Mart\\'inez-Ram\\'irez",
        "Liwei Lin",
        "Gus Xia",
        "Wei-Hsiang Liao",
        "Yuki Mitsufuji",
        "Simon Dixon"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-28T17:27:20+00:00",
          "link": "https://arxiv.org/abs/2405.18386v1",
          "size": "4196kb",
          "version": "v1"
        },
        {
          "date": "2024-05-29T17:05:32+00:00",
          "link": "https://arxiv.org/abs/2405.18386v2",
          "size": "4196kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T21:29:13+00:00",
          "link": "https://arxiv.org/abs/2405.18386v3",
          "size": "1225kb",
          "version": "v3"
        }
      ],
      "title": "Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language Models via Instruction Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.18386",
        "HTML": "https://arxiv.org/html/2405.18386v3",
        "PDF": "https://arxiv.org/pdf/2405.18386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although this paper discusses fine-tuning a music language model, its primary focus is on model architecture and efficiency for text-to-music editing, with minimal emphasis on training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/MS-P3/code5/tree/main/musicgen",
        "https://github.com/ldzhangyx/instruct-MusicGen"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.00826",
      "abstract": "We consider the verification of neural network policies for discrete-time stochastic systems with respect to reach-avoid specifications. We use a learner-verifier procedure that learns a certificate for the specification, represented as a neural network. Verifying that this neural network certificate is a so-called reach-avoid supermartingale (RASM) proves the satisfaction of a reach-avoid specification. Existing approaches for such a verification task rely on computed Lipschitz constants of neural networks. These approaches struggle with large Lipschitz constants, especially for reach-avoid specifications with high threshold probabilities. We present two key contributions to obtain smaller Lipschitz constants than existing approaches. First, we introduce logarithmic RASMs (logRASMs), which take exponentially smaller values than RASMs and hence have lower theoretical Lipschitz constants. Second, we present a fast method to compute tighter upper bounds on Lipschitz constants based on weighted norms. Our empirical evaluation shows we can consistently verify the satisfaction of reach-avoid specifications with probabilities as high as 99.9999%.",
      "authors": [
        "Thom Badings",
        "Wietze Koops",
        "Sebastian Junges",
        "Nils Jansen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-02T18:19:19+00:00",
          "link": "https://arxiv.org/abs/2406.00826v1",
          "size": "1407kb",
          "version": "v1"
        },
        {
          "date": "2025-02-23T16:11:34+00:00",
          "link": "https://arxiv.org/abs/2406.00826v2",
          "size": "1735kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T07:42:57+00:00",
          "link": "https://arxiv.org/abs/2406.00826v3",
          "size": "1678kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T07:33:46+00:00",
          "link": "https://arxiv.org/abs/2406.00826v4",
          "size": "1678kb",
          "version": "v4"
        }
      ],
      "title": "Policy Verification in Stochastic Dynamical Systems Using Logarithmic Neural Certificates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.00826",
        "PDF": "https://arxiv.org/pdf/2406.00826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on policy verification in stochastic systems using neural network certificates, which is unrelated to LLM training data processing or dataset creation for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2406.12385",
      "abstract": "Vector search systems are indispensable in large language model (LLM) serving, search engines, and recommender systems, where minimizing online search latency is essential. Among various algorithms, graph-based vector search (GVS) is particularly popular due to its high search performance and quality. However, reducing GVS latency by intra-query parallelization remains challenging due to limitations imposed by both existing hardware architectures (CPUs and GPUs) and the inherent difficulty of parallelizing graph traversals. To efficiently serve low-latency GVS, we co-design hardware and algorithm by proposing Falcon and Delayed-Synchronization Traversal (DST). Falcon is a hardware GVS accelerator that implements efficient GVS operators, pipelines these operators, and reduces memory accesses by tracking search states with an on-chip Bloom filter. DST is an efficient graph traversal algorithm that simultaneously improves search performance and quality by relaxing traversal orders to maximize accelerator utilization. Evaluation across various graphs and datasets shows that Falcon, prototyped on FPGAs, together with DST, achieves up to 4.3x and 19.5x lower latency and up to 8.0x and 26.9x improvements in energy efficiency over CPU- and GPU-based GVS systems.",
      "authors": [
        "Wenqi Jiang",
        "Hang Hu",
        "Torsten Hoefler",
        "Gustavo Alonso"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-18T08:15:52+00:00",
          "link": "https://arxiv.org/abs/2406.12385v1",
          "size": "12941kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:52:14+00:00",
          "link": "https://arxiv.org/abs/2406.12385v2",
          "size": "620kb",
          "version": "v2"
        }
      ],
      "title": "Fast Graph Vector Search via Hardware Acceleration and Delayed-Synchronization Traversal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.12385",
        "HTML": "https://arxiv.org/html/2406.12385v2",
        "PDF": "https://arxiv.org/pdf/2406.12385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses hardware acceleration for graph vector search in LLM serving, focusing on hardware improvements rather than training data processing operations necessary for pretraining or fine-tuning large language models."
      },
      "repo_urls": [
        "https://github.com/WenqiJiang/SC-ANN-FPGA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.15154",
      "abstract": "The assignment of document and publication types in scholarly databases plays an important role in bibliometrics, for example in decision-making or university rankings. However, scholarly databases apply different curation strategies and taxonomies when classifying documents which makes it difficult to compare results from different database providers. In this study, the bibliometric databases OpenAlex, Web of Science, Scopus, PubMed and Semantic Scholar are used to analyse the extent of data variation and compare different approaches to taxonomy and data curation. Using a shared corpus of 9,575,603 publications from 2012 to 2022, we found large differences in the classification of document types such as research articles and editorials in these databases. We can also show that many of the records that lack a publication type in OpenAlex are classified as conference proceedings in Scopus and Semantic Scholar.",
      "authors": [
        "Nick Haupka",
        "Jack H. Culbert",
        "Alexander Schniedermann",
        "Najko Jahn",
        "Philipp Mayr"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-21T14:00:53+00:00",
          "link": "https://arxiv.org/abs/2406.15154v1",
          "size": "2727kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T10:47:40+00:00",
          "link": "https://arxiv.org/abs/2406.15154v2",
          "size": "2731kb",
          "version": "v2"
        }
      ],
      "title": "Analysis of the Publication and Document Types in OpenAlex, Web of Science, Scopus, PubMed and Semantic Scholar",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.15154",
        "HTML": "https://arxiv.org/html/2406.15154v2",
        "PDF": "https://arxiv.org/pdf/2406.15154"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes document type classification across bibliometric databases and their curation strategies. It does not deal with LLM training data processing, dataset creation, or data filtering techniques for pretraining or fine-tuning."
      },
      "repo_urls": [
        "https://github.com/naustica/openalex_doctypes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.15817",
      "abstract": "A major open problem in computational complexity is the existence of a one-way function, namely a function from strings to strings which is computationally easy to compute but hard to invert. Levin (2023) formulated the notion of one-way functions from reals (infinite bit-sequences) to reals in terms of computability, and asked whether partial computable one-way functions exist. We give a strong positive answer using the hardness of the halting problem and exhibiting a total computable one-way function.",
      "authors": [
        "George Barmpalias and Xiaoyan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-22T10:49:57+00:00",
          "link": "https://arxiv.org/abs/2406.15817v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2024-11-05T12:18:52+00:00",
          "link": "https://arxiv.org/abs/2406.15817v2",
          "size": "17kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T21:32:44+00:00",
          "link": "https://arxiv.org/abs/2406.15817v3",
          "size": "20kb",
          "version": "v3"
        }
      ],
      "title": "Computable one-way functions on the reals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.15817",
        "HTML": "https://arxiv.org/html/2406.15817v3",
        "PDF": "https://arxiv.org/pdf/2406.15817"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on computational complexity and the concept of one-way functions using computability. It does not address any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.17082",
      "abstract": "We define an extension of lambda-calculus with dependents types that enables us to encode transparent and opaque probabilistic programs and prove a strong normalisation result for it by a reducibility technique. While transparent nondeterministic programs are formalised by rather usual techniques, opaque nondeterministic programs are formalised by introducing in the syntax oracle constants, the behaviour of which is governed by oracular functions. The generality of these functions and the fact that their values are determined by the form of the whole term inside which the relative oracle occurs also enable us to simulate learning-like behaviours. We then extend the calculus in order to define a computational trustworthiness predicate. The extension of the calculus does not only enable us to precisely formalise a notion of trustworthiness and to encode the procedures required to test it on programs, but also to reason, by means of the type system, on the behaviour of programs with respect to trustworthiness.",
      "authors": [
        "Francesco A. Genco"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-24T19:14:06+00:00",
          "link": "https://arxiv.org/abs/2406.17082v1",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:10:22+00:00",
          "link": "https://arxiv.org/abs/2406.17082v2",
          "size": "35kb",
          "version": "v2"
        }
      ],
      "title": "A Strongly Normalising System of Dependent Types for Transparent and Opaque Probabilistic Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17082",
        "HTML": "https://arxiv.org/html/2406.17082v2",
        "PDF": "https://arxiv.org/pdf/2406.17082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper involves lambda calculus and probabilistic computation, exploring dependently typed systems. It does not contribute to data processing related to LLM training or dataset quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01558",
      "abstract": "Most visual grounding solutions primarily focus on realistic images. However, applications involving synthetic images, such as Graphical User Interfaces (GUIs), remain limited. This restricts the development of autonomous computer vision-powered artificial intelligence (AI) agents for automatic application interaction. Enabling AI to effectively understand and interact with GUIs is crucial to advancing automation in software testing, accessibility, and human-computer interaction. In this work, we explore Instruction Visual Grounding (IVG), a multi-modal approach to object identification within a GUI. More precisely, given a natural language instruction and a GUI screen, IVG locates the coordinates of the element on the screen where the instruction should be executed. We propose two main methods: (1) IVGocr, which combines a Large Language Model (LLM), an object detection model, and an Optical Character Recognition (OCR) module; and (2) IVGdirect, which uses a multimodal architecture for end-to-end grounding. For each method, we introduce a dedicated dataset. In addition, we propose the Central Point Validation (CPV) metric, a relaxed variant of the classical Central Proximity Score (CPS) metric. Our final test dataset is publicly released to support future research.",
      "authors": [
        "El Hassane Ettifouri and Jessica L\\'opez Espejel and Laura Minkova and Tassnim Dardouri and Walid Dahhane"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-05T19:10:19+00:00",
          "link": "https://arxiv.org/abs/2407.01558v1",
          "size": "335kb",
          "version": "v1"
        },
        {
          "date": "2024-09-17T10:15:07+00:00",
          "link": "https://arxiv.org/abs/2407.01558v2",
          "size": "897kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T11:35:01+00:00",
          "link": "https://arxiv.org/abs/2407.01558v3",
          "size": "835kb",
          "version": "v3"
        }
      ],
      "title": "Visual Grounding Methods for Efficient Interaction with Desktop Graphical User Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01558",
        "HTML": "https://arxiv.org/html/2407.01558v3",
        "PDF": "https://arxiv.org/pdf/2407.01558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces datasets for Instruction Visual Grounding within GUIs, its main focus is on multi-modal methods for object identification and not on LLM training data processing specifically. Therefore, it does not make a significant contribution to this area."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "object-detection",
        "Object Detection",
        "Visual Grounding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.07046",
      "abstract": "Multimodal sentiment analysis is an active research area that combines multiple data modalities, e.g., text, image and audio, to analyze human emotions and benefits a variety of applications. Existing multimodal sentiment analysis methods can be classified as modality interaction-based methods, modality transformation-based methods and modality similarity-based methods. However, most of these methods highly rely on the strong correlations between modalities, and cannot fully uncover and utilize the correlations between modalities to enhance sentiment analysis. Therefore, these methods usually achieve bad performance for identifying the sentiment of multimodal data with weak correlations. To address this issue, we proposed a two-stage semi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT) which consists pre-training stage and prediction stage. At the pre-training stage, a modality correlation contrastive learning module is designed to efficiently learn modality correlation coefficients between different modalities. At the prediction stage, the learned correlation coefficients are fused with modality representations to make the sentiment prediction. According to the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT obviously surpasses state-of-the-art multimodal sentiment analysis methods.",
      "authors": [
        "Yangmin Li",
        "Ruiqi Zhu",
        "Wengen Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-09T17:07:29+00:00",
          "link": "https://arxiv.org/abs/2407.07046v1",
          "size": "22928kb",
          "version": "v1"
        },
        {
          "date": "2024-08-29T06:15:55+00:00",
          "link": "https://arxiv.org/abs/2407.07046v2",
          "size": "13315kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T06:42:18+00:00",
          "link": "https://arxiv.org/abs/2407.07046v3",
          "size": "23224kb",
          "version": "v3"
        }
      ],
      "title": "CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.07046",
        "HTML": "https://arxiv.org/html/2407.07046v3",
        "PDF": "https://arxiv.org/pdf/2407.07046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a semi-supervised multimodal transformer for sentiment analysis with a focus on modality correlation. It does not address training data processing for LLMs or any related data engineering operations."
      },
      "tasks": [
        "Contrastive Learning",
        "Multimodal Sentiment Analysis",
        "Prediction",
        "Sentiment Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.10266",
      "abstract": "psifx is a plug-and-play multi-modal feature extraction toolkit, aiming to facilitate and democratize the use of state-of-the-art machine learning techniques for human sciences research. It is motivated by a need (a) to automate and standardize data annotation processes that typically require expensive, lengthy, and inconsistent human labour; (b) to develop and distribute open-source community-driven psychology research software; and (c) to enable large-scale access and ease of use for non-expert users. The framework contains an array of tools for tasks such as speaker diarization, closed-caption transcription and translation from audio; body, hand, and facial pose estimation and gaze tracking with multi-person tracking from video; and interactive textual feature extraction supported by large language models. The package has been designed with a modular and task-oriented approach, enabling the community to add or update new tools easily. This combination creates new opportunities for in-depth study of real-time behavioral phenomena in psychological and social science research.",
      "authors": [
        "Guillaume Rochette and Mathieu Rochat and Matthew J. Vowels"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-14T16:20:42+00:00",
          "link": "https://arxiv.org/abs/2407.10266v1",
          "size": "3664kb",
          "version": "v1"
        },
        {
          "date": "2024-07-16T09:30:03+00:00",
          "link": "https://arxiv.org/abs/2407.10266v2",
          "size": "3663kb",
          "version": "v2"
        },
        {
          "date": "2024-12-09T09:14:47+00:00",
          "link": "https://arxiv.org/abs/2407.10266v3",
          "size": "3706kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T18:29:50+00:00",
          "link": "https://arxiv.org/abs/2407.10266v4",
          "size": "627kb",
          "version": "v4"
        }
      ],
      "title": "psifx -- Psychological and Social Interactions Feature Extraction Package",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.10266",
        "HTML": "https://arxiv.org/html/2407.10266v4",
        "PDF": "https://arxiv.org/pdf/2407.10266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The psifx toolkit involves feature extraction and data annotation using LLMs, but its main focus is more broadly on human sciences research facilitation rather than LLM-specific training data processing."
      },
      "tasks": [
        "Pose Estimation",
        "speaker-diarization",
        "Speaker Diarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.14506",
      "abstract": "Recent studies customizing Multimodal Large Language Models (MLLMs) for domain-specific tasks have yielded promising results, especially in the field of scientific chart comprehension. These studies generally utilize visual instruction tuning with specialized datasets to enhance question and answer (QA) accuracy within the chart domain. However, they often neglect the fundamental discrepancy between natural image-caption pre-training data and digital chart image-QA data, particularly in the models' capacity to extract underlying numeric values from charts. This paper tackles this oversight by exploring the training processes necessary to improve MLLMs' comprehension of charts. We present three key findings: (1) Incorporating raw data values in alignment pre-training markedly improves comprehension of chart data. (2) Replacing images with their textual representation randomly during end-to-end fine-tuning transfer the language reasoning capability to chart interpretation skills. (3) Requiring the model to first extract the underlying chart data and then answer the question in the fine-tuning can further improve the accuracy. Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chart comprehension. CHOPINLLM effectively interprets various types of charts, including unannotated ones, while maintaining robust reasoning abilities. Furthermore, we establish a new benchmark to evaluate MLLMs' understanding of different chart types across various comprehension levels. Experimental results show that CHOPINLLM exhibits strong performance in understanding both annotated and unannotated charts across a wide range of types.",
      "authors": [
        "Wan-Cyuan Fan",
        "Yen-Chun Chen",
        "Mengchen Liu",
        "Lu Yuan",
        "Leonid Sigal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-19T17:58:36+00:00",
          "link": "https://arxiv.org/abs/2407.14506v1",
          "size": "4662kb",
          "version": "v1"
        },
        {
          "date": "2024-07-31T21:01:16+00:00",
          "link": "https://arxiv.org/abs/2407.14506v2",
          "size": "4662kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T18:53:04+00:00",
          "link": "https://arxiv.org/abs/2407.14506v3",
          "size": "5822kb",
          "version": "v3"
        }
      ],
      "title": "On Pre-training of Multimodal Language Models Customized for Chart Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.14506",
        "PDF": "https://arxiv.org/pdf/2407.14506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses pre-training multimodal models for chart understanding, including data alignment and representation strategies. However, it primarily targets model comprehension rather than specific contributions to the LLM training data processing itself."
      },
      "tasks": [
        "Chart Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.00998",
      "abstract": "Large-scale text-to-image diffusion models have been a revolutionary milestone in the evolution of generative AI and multimodal technology, allowing wonderful image generation with natural-language text prompt. However, the issue of lacking controllability of such models restricts their practical applicability for real-life content creation. Thus, attention has been focused on leveraging a reference image to control text-to-image synthesis, which is also regarded as manipulating (or editing) a reference image as per a text prompt, namely, text-driven image-to-image translation. This paper contributes a novel, concise, and efficient approach that adapts pre-trained large-scale text-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a plug-and-play manner, realizing high-quality and versatile text-driven I2I translation without any model training, model fine-tuning, or online optimization process. To guide T2I generation with a reference image, we propose to decompose diverse guiding factors with different frequency bands of diffusion features in the DCT spectral space, and accordingly devise a novel frequency band substitution layer which realizes dynamic control of the reference image to the T2I generation result in a plug-and-play manner. We demonstrate that our method allows flexible control over both guiding factor and guiding intensity of the reference image simply by tuning the type and bandwidth of the substituted frequency band, respectively. Extensive qualitative and quantitative experiments verify superiority of our approach over related methods in I2I translation visual quality, versatility, and controllability. The code is publicly available at: https://github.com/XiangGao1102/FBSDiff.",
      "authors": [
        "Xiang Gao",
        "Jiaying Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T04:13:38+00:00",
          "link": "https://arxiv.org/abs/2408.00998v1",
          "size": "22846kb",
          "version": "v1"
        },
        {
          "date": "2024-08-06T12:01:17+00:00",
          "link": "https://arxiv.org/abs/2408.00998v2",
          "size": "22833kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T04:43:17+00:00",
          "link": "https://arxiv.org/abs/2408.00998v3",
          "size": "21616kb",
          "version": "v3"
        }
      ],
      "title": "FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00998",
        "HTML": "https://arxiv.org/html/2408.00998v3",
        "PDF": "https://arxiv.org/pdf/2408.00998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for text-driven image-to-image translation using diffusion models. It focuses on image editing techniques and controllability rather than LLM training data processing operations."
      },
      "tasks": [
        "Image Generation",
        "Image-to-Image Translation",
        "Translation"
      ],
      "repo_urls": [
        "https://github.com/xianggao1102/fbsdiff"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.06345",
      "abstract": "Extracting key information from documents represents a large portion of business workloads and therefore offers a high potential for efficiency improvements and process automation. With recent advances in Deep Learning, a plethora of Deep Learning based approaches for Key Information Extraction have been proposed under the umbrella term Document Understanding that enable the processing of complex business documents. The goal of this systematic literature review is an in-depth analysis of existing approaches in this domain and the identification of opportunities for further research. To this end, 130 approaches published between 2017 and 2024 are analyzed in this study.",
      "authors": [
        "Alexander Michael Rombach",
        "Peter Fettke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-23T08:15:55+00:00",
          "link": "https://arxiv.org/abs/2408.06345v1",
          "size": "3580kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:42:38+00:00",
          "link": "https://arxiv.org/abs/2408.06345v2",
          "size": "5137kb",
          "version": "v2"
        }
      ],
      "title": "Deep Learning based Key Information Extraction from Business Documents: Systematic Literature Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06345",
        "HTML": "https://arxiv.org/html/2408.06345v2",
        "PDF": "https://arxiv.org/pdf/2408.06345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a systematic literature review of deep learning approaches for key information extraction from business documents. It does not address any aspect of LLM training data processing such as dataset creation, processing, or quality improvement."
      },
      "tasks": [
        "Deep Learning",
        "document understanding",
        "Key Information Extraction",
        "Systematic Literature Review"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.00839",
      "abstract": "With the increasing complexity of the traffic environment, the significance of safety perception in intelligent driving is intensifying. Traditional methods in the field of intelligent driving perception rely on deep learning, which suffers from limited interpretability, often described as a \"black box.\" This paper introduces a novel type of loss function, termed \"Entropy Loss,\" along with an innovative training strategy. Entropy Loss is formulated based on the functionality of feature compression networks within the perception model. Drawing inspiration from communication systems, the information transmission process in a feature compression network is expected to demonstrate steady changes in information volume and a continuous decrease in information entropy. By modeling network layer outputs as continuous random variables, we construct a probabilistic model that quantifies changes in information volume. Entropy Loss is then derived based on these expectations, guiding the update of network parameters to enhance network interpretability. Our experiments indicate that the Entropy Loss training strategy accelerates the training process. Utilizing the same 60 training epochs, the accuracy of 3D object detection models using Entropy Loss on the KITTI test set improved by up to 4.47\\% compared to models without Entropy Loss, underscoring the method's efficacy. The implementation code is available at https://github.com/yhbcode000/Eloss-Interpretability.",
      "authors": [
        "Haobo Yang",
        "Shiyan Zhang",
        "Zhuoyi Yang",
        "Xinyu Zhang",
        "Jilong Guo",
        "Zongyou Yang",
        "Jun Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-01T20:55:50+00:00",
          "link": "https://arxiv.org/abs/2409.00839v1",
          "size": "1869kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:39:59+00:00",
          "link": "https://arxiv.org/abs/2409.00839v2",
          "size": "1787kb",
          "version": "v2"
        }
      ],
      "title": "Entropy Loss: An Interpretability Amplifier of 3D Object Detection Network for Intelligent Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00839",
        "HTML": "https://arxiv.org/html/2409.00839v2",
        "PDF": "https://arxiv.org/pdf/2409.00839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the interpretability and accuracy of 3D object detection networks for intelligent driving using a new training strategy and loss function. It does not address LLM training data processing."
      },
      "tasks": [
        "3D Object Detection",
        "Feature Compression",
        "object-detection",
        "Object Detection"
      ],
      "repo_urls": [
        "https://github.com/yhbcode000/Eloss-Interpretability"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.04617",
      "abstract": "Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM) agents, especially in multi-turn dialogue tasks, have been primarily driven by supervised fine-tuning and high-quality human feedback. However, as base LLM models continue to improve, acquiring meaningful human feedback has become increasingly challenging and costly. In certain domains, base LLM agents may eventually exceed human capabilities, making traditional feedback-driven methods impractical. In this paper, we introduce a novel self-improvement paradigm that empowers LLM agents to autonomously enhance their performance without external human feedback. Our method, Juxtaposed Outcomes for Simulation Harvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward simulation environment to extract ideal behaviors and further train the LLM on its own outputs. We present ToolWOZ, a sparse reward tool-calling simulation environment derived from MultiWOZ. We demonstrate that models trained with JOSH, both small and frontier, significantly improve tool-based interactions while preserving general model capabilities across diverse benchmarks. Our code and data are publicly available on GitHub at https://github.com/asappresearch/josh-llm-simulation-training",
      "authors": [
        "Barrett Martin Lattimer",
        "Varun Gangal",
        "Ryan McDonald",
        "Yi Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-06T21:00:57+00:00",
          "link": "https://arxiv.org/abs/2409.04617v1",
          "size": "8907kb",
          "version": "v1"
        },
        {
          "date": "2024-10-08T20:40:59+00:00",
          "link": "https://arxiv.org/abs/2409.04617v2",
          "size": "2969kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T17:06:00+00:00",
          "link": "https://arxiv.org/abs/2409.04617v3",
          "size": "785kb",
          "version": "v3"
        }
      ],
      "title": "Sparse Rewards Can Self-Train Dialogue Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.04617",
        "PDF": "https://arxiv.org/pdf/2409.04617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a self-improvement paradigm for LLM agents using a sparse reward simulation environment, which indirectly involves training data generation. However, its primary focus is on self-alignment algorithms and dialogue model performance, not specifically on data processing for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/asappresearch/josh-llm-simulation-training"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.05260",
      "abstract": "Given a video with $T$ frames, frame sampling is a task to select $N \\ll T$ frames, so as to maximize the performance of a fixed video classifier. Not just brute-force search, but most existing methods suffer from its vast search space of $\\binom{T}{N}$, especially when $N$ gets large. To address this challenge, we introduce a novel perspective of reducing the search space from $O(T^N)$ to $O(T)$. Instead of exploring the entire $O(T^N)$ space, our proposed semi-optimal policy selects the top $N$ frames based on the independently estimated value of each frame using per-frame confidence, significantly reducing the computational complexity. We verify that our semi-optimal policy can efficiently approximate the optimal policy, particularly under practical settings. Additionally, through extensive experiments on various datasets and model architectures, we demonstrate that learning our semi-optimal policy ensures stable and high performance regardless of the size of $N$ and $T$.",
      "authors": [
        "Junho Lee",
        "Jeongwoo Shin",
        "Seung Woo Ko",
        "Seongsu Ha",
        "Joonseok Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-09T01:11:47+00:00",
          "link": "https://arxiv.org/abs/2409.05260v1",
          "size": "31487kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T05:41:15+00:00",
          "link": "https://arxiv.org/abs/2409.05260v2",
          "size": "31488kb",
          "version": "v2"
        }
      ],
      "title": "Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05260",
        "HTML": "https://arxiv.org/html/2409.05260v2",
        "PDF": "https://arxiv.org/pdf/2409.05260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focused on scalable frame sampling for video classification, this paper introduces a semi-optimal policy for frame selection. It does not address any aspects of LLM training data processing."
      },
      "tasks": [
        "Video Classification"
      ],
      "repo_urls": [
        "https://github.com/isno0907/sosampler"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.07777",
      "abstract": "We consider the problem of covert communication with random slot selection over binary-input Discrete Memoryless Channels and Additive White Gaussian Noise channels, in which a transmitter attempts to reliably communicate with a legitimate receiver while simultaneously maintaining covertness with respect to an eavesdropper. Covertness refers to the inability of the eavesdropper to distinguish the transmission of a message from the absence of communication, modeled by the transmission of a fixed channel input. Random slot selection refers to the transmitter's ability to send a codeword in a time slot with known boundaries selected uniformly at random among a predetermined number of slots. Our main contribution is to develop bounds for the information-theoretic limit of communication in this model, called the covert capacity, when the number of time slots scales sub-exponentially with the codeword length. Our upper and lower bounds for the covert capacity are within a multiplicative factor of $\\sqrt{2}$ independent of the channel. This result partially fills a characterization gap between the covert capacity without random slot selection and the covert capacity with random selection among an exponential number of slots in the codeword length. Our key technical contributions consist of i) a tight upper bound for the relative entropy characterizing the effect of random slot selection on the covertness constraint in our achievability proof; ii) a careful converse analysis to characterize the maximum allowable weight or power of codewords to meet the covertness constraint. Our results suggest that, unlike the case without random slot selection, the choice of covertness metric does not change the covert capacity in the presence of random slot selection.",
      "authors": [
        "Shi-Yuan Wang",
        "Keerthi S. K. Arumugam and Matthieu R. Bloch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-12T06:23:22+00:00",
          "link": "https://arxiv.org/abs/2409.07777v1",
          "size": "460kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:25:27+00:00",
          "link": "https://arxiv.org/abs/2409.07777v2",
          "size": "463kb",
          "version": "v2"
        }
      ],
      "title": "Bounds on Covert Capacity with Sub-Exponential Random Slot Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07777",
        "HTML": "https://arxiv.org/html/2409.07777v2",
        "PDF": "https://arxiv.org/pdf/2409.07777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses covert communication and random slot selection in the context of communication channels. It does not relate to LLM training data processing or any relevant techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.18749",
      "abstract": "Training deep learning models is a repetitive and resource-intensive process. Data scientists often train several models before landing on a set of parameters (e.g., hyper-parameter tuning) and model architecture (e.g., neural architecture search), among other things that yield the highest accuracy. The computational efficiency of these training tasks depends highly on how well the training data is supplied to the training process. The repetitive nature of these tasks results in the same data processing pipelines running over and over, exacerbating the need for and costs of computational resources. In this paper, we present TensorSocket to reduce the computational needs of deep learning training by enabling simultaneous training processes to share the same data loader. TensorSocket mitigates CPU-side bottlenecks in cases where the collocated training workloads have high throughput on GPU, but are held back by lower data-loading throughput on CPU. TensorSocket achieves this by reducing redundant computations and data duplication across collocated training processes and leveraging modern GPU-GPU interconnects. While doing so, TensorSocket is able to train and balance differently-sized models and serve multiple batch sizes simultaneously and is hardware- and pipeline-agnostic in nature. Our evaluation shows that TensorSocket enables scenarios that are infeasible without data sharing, increases training throughput by up to 100%, and when utilizing cloud instances, achieves cost savings of 50% by reducing the hardware resource needs on the CPU side. Furthermore, TensorSocket outperforms the state-of-the-art solutions for shared data loading such as CoorDL and Joader; it is easier to deploy and maintain and either achieves higher or matches their throughput while requiring fewer CPU resources.",
      "authors": [
        "Ties Robroek (IT University of Copenhagen)",
        "Neil Kim Nielsen (IT University of Copenhagen)",
        "P{\\i}nar T\\\"oz\\\"un (IT University of Copenhagen)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T13:39:47+00:00",
          "link": "https://arxiv.org/abs/2409.18749v1",
          "size": "1864kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:46:14+00:00",
          "link": "https://arxiv.org/abs/2409.18749v2",
          "size": "403kb",
          "version": "v2"
        }
      ],
      "title": "TensorSocket: Shared Data Loading for Deep Learning Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18749",
        "HTML": "https://arxiv.org/html/2409.18749v2",
        "PDF": "https://arxiv.org/pdf/2409.18749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the computational efficiencies in deep learning model training, specifically through shared data loading mechanisms. It does not address LLM training data processing or any operations regarding data quality improvement, collection, or dataset creation."
      },
      "tasks": [
        "Computational Efficiency",
        "Deep Learning",
        "Neural Architecture Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.18877",
      "abstract": "Visual emotion analysis holds significant research value in both computer vision and psychology. However, existing methods for visual emotion analysis suffer from limited generalizability due to the ambiguity of emotion perception and the diversity of data scenarios. To tackle this issue, we introduce UniEmoX, a cross-modal semantic-guided large-scale pretraining framework. Inspired by psychological research emphasizing the inseparability of the emotional exploration process from the interaction between individuals and their environment, UniEmoX integrates scene-centric and person-centric low-level image spatial structural information, aiming to derive more nuanced and discriminative emotional representations. By exploiting the similarity between paired and unpaired image-text samples, UniEmoX distills rich semantic knowledge from the CLIP model to enhance emotional embedding representations more effectively. To the best of our knowledge, this is the first large-scale pretraining framework that integrates psychological theories with contemporary contrastive learning and masked image modeling techniques for emotion analysis across diverse scenarios. Additionally, we develop a visual emotional dataset titled Emo8. Emo8 samples cover a range of domains, including cartoon, natural, realistic, science fiction and advertising cover styles, covering nearly all common emotional scenes. Comprehensive experiments conducted on six benchmark datasets across two downstream tasks validate the effectiveness of UniEmoX. The source code is available at https://github.com/chincharles/u-emo.",
      "authors": [
        "Chuang Chen",
        "Xiao Sun",
        "Zhi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T16:12:51+00:00",
          "link": "https://arxiv.org/abs/2409.18877v1",
          "size": "33772kb",
          "version": "v1"
        },
        {
          "date": "2024-09-30T13:58:29+00:00",
          "link": "https://arxiv.org/abs/2409.18877v2",
          "size": "33772kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T05:14:24+00:00",
          "link": "https://arxiv.org/abs/2409.18877v3",
          "size": "11921kb",
          "version": "v3"
        }
      ],
      "title": "UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18877",
        "HTML": "https://arxiv.org/html/2409.18877v3",
        "PDF": "https://arxiv.org/pdf/2409.18877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the UniEmoX pretraining framework and a new visual emotional dataset Emo8. While it involves creating a new dataset, the focus is on visual emotion analysis rather than LLM training data processing."
      },
      "tasks": [
        "Contrastive Learning",
        "Emotion Recognition"
      ],
      "repo_urls": [
        "https://github.com/chincharles/u-emo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.03020",
      "abstract": "Recent work suggests that certain neural network architectures -- particularly recurrent neural networks (RNNs) and implicit neural networks (INNs) -- are capable of logical extrapolation. When trained on easy instances of a task, these networks (henceforth: logical extrapolators) can generalize to more difficult instances. Previous research has hypothesized that logical extrapolators do so by learning a scalable, iterative algorithm for the given task which converges to the solution. We examine this idea more closely in the context of a single task: maze solving. By varying test data along multiple axes -- not just maze size -- we show that models introduced in prior work fail in a variety of ways, some expected and others less so. It remains uncertain whether any of these models has truly learned an algorithm. However, we provide evidence that a certain RNN has approximately learned a form of `deadend-filling'. We show that training these models on more diverse data addresses some failure modes but, paradoxically, does not improve logical extrapolation. We also analyze convergence behavior, and show that models explicitly trained to converge to a fixed point are likely to do so when extrapolating, while models that are not may exhibit more exotic limiting behavior such as limit cycles, even when they correctly solve the problem. Our results (i) show that logical extrapolation is not immune to the problem of goal misgeneralization, and (ii) suggest that analyzing the dynamics of extrapolation may yield insights into designing better logical extrapolators.",
      "authors": [
        "Brandon Knutson and Amandin Chyba Rabeendran and Michael Ivanitskiy and Jordan Pettyjohn and Cecilia Diniz-Behn and Samy Wu Fung and Daniel McKenzie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T22:07:51+00:00",
          "link": "https://arxiv.org/abs/2410.03020v1",
          "size": "608kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T17:22:39+00:00",
          "link": "https://arxiv.org/abs/2410.03020v2",
          "size": "778kb",
          "version": "v2"
        }
      ],
      "title": "On Logical Extrapolation for Mazes with Recurrent and Implicit Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03020",
        "HTML": "https://arxiv.org/html/2410.03020v2",
        "PDF": "https://arxiv.org/pdf/2410.03020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates logical extrapolation in maze solving using RNNs and INNs. There is no relation to LLM training data processing or related data engineering operations."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/mines-opt-ml/maze-extrapolation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.03993",
      "abstract": "Accurate prediction of human behavior is crucial for AI systems to effectively support real-world applications, such as autonomous robots anticipating and assisting with human tasks. Real-world scenarios frequently present challenges such as occlusions and incomplete scene observations, which can compromise predictive accuracy. Thus, traditional video-based methods often struggle due to limited temporal and spatial perspectives. Large Language Models (LLMs) offer a promising alternative. Having been trained on a large text corpus describing human behaviors, LLMs likely encode plausible sequences of human actions in a home environment. However, LLMs, trained primarily on text data, lack inherent spatial awareness and real-time environmental perception. They struggle with understanding physical constraints and spatial geometry. Therefore, to be effective in a real-world spatial scenario, we propose a multimodal prediction framework that enhances LLM-based action prediction by integrating physical constraints derived from human trajectories. Our experiments demonstrate that combining LLM predictions with trajectory data significantly improves overall prediction performance. This enhancement is particularly notable in situations where the LLM receives limited scene information, highlighting the complementary nature of linguistic knowledge and physical constraints in understanding and anticipating human behavior.",
      "authors": [
        "Kojiro Takeyama",
        "Yimeng Liu",
        "Misha Sra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-05T01:18:26+00:00",
          "link": "https://arxiv.org/abs/2410.03993v1",
          "size": "40735kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T20:36:30+00:00",
          "link": "https://arxiv.org/abs/2410.03993v2",
          "size": "40736kb",
          "version": "v2"
        },
        {
          "date": "2025-03-06T00:35:18+00:00",
          "link": "https://arxiv.org/abs/2410.03993v3",
          "size": "20313kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T03:17:05+00:00",
          "link": "https://arxiv.org/abs/2410.03993v4",
          "size": "6160kb",
          "version": "v4"
        }
      ],
      "title": "TR-LLM: Integrating Trajectory Data for Scene-Aware LLM-Based Human Action Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03993",
        "HTML": "https://arxiv.org/html/2410.03993v4",
        "PDF": "https://arxiv.org/pdf/2410.03993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating trajectory data with LLMs for human action prediction, which does not involve training data processing operations related to LLMs such as data collection or dataset creation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.05347",
      "abstract": "Although AlphaZero has achieved superhuman performance in board games, recent studies reveal its limitations in handling scenarios requiring a comprehensive understanding of the entire board, such as recognizing long-sequence patterns in Go. To address this challenge, we propose ResTNet, a network that interleaves residual and Transformer blocks to bridge local and global knowledge. ResTNet improves playing strength across multiple board games, increasing win rate from 54.6% to 60.8% in 9x9 Go, 53.6% to 60.9% in 19x19 Go, and 50.4% to 58.0% in 19x19 Hex. In addition, ResTNet effectively processes global information and tackles two long-sequence patterns in 19x19 Go, including circular pattern and ladder pattern. It reduces the mean square error for circular pattern recognition from 2.58 to 1.07 and lowers the attack probability against an adversary program from 70.44% to 23.91%. ResTNet also improves ladder pattern recognition accuracy from 59.15% to 80.01%. By visualizing attention maps, we demonstrate that ResTNet captures critical game concepts in both Go and Hex, offering insights into AlphaZero's decision-making process. Overall, ResTNet shows a promising approach to integrating local and global knowledge, paving the way for more effective AlphaZero-based algorithms in board games. Our code is available at https://rlg.iis.sinica.edu.tw/papers/restnet.",
      "authors": [
        "Yan-Ru Ju",
        "Tai-Lin Wu",
        "Chung-Chin Shih",
        "Ti-Rong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T10:17:24+00:00",
          "link": "https://arxiv.org/abs/2410.05347v1",
          "size": "48181kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:31:06+00:00",
          "link": "https://arxiv.org/abs/2410.05347v2",
          "size": "41095kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Local and Global Knowledge via Transformer in Board Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05347",
        "HTML": "https://arxiv.org/html/2410.05347v2",
        "PDF": "https://arxiv.org/pdf/2410.05347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses improvements in board game AI through a network combining residual and Transformer blocks. It does not pertain to LLM training data processing or data preparation for LLMs."
      },
      "tasks": [
        "Board Games",
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.07094",
      "abstract": "Software engineering (SE) chatbots are increasingly gaining attention for their role in enhancing development processes. At the core of chatbots are Natural Language Understanding platforms (NLUs), which enable them to comprehend user queries but require labeled data for training. However, acquiring such labeled data for SE chatbots is challenging due to the scarcity of high-quality datasets, as training requires specialized vocabulary and phrases not found in typical language datasets. Consequently, developers often resort to manually annotating user queries -- a time-consuming and resource-intensive process. Previous approaches require human intervention to generate rules, called labeling functions (LFs), that categorize queries based on specific patterns. To address this issue, we propose an approach to automatically generate LFs by extracting patterns from labeled user queries. We evaluate our approach on four SE datasets and measure performance improvement from training NLUs on queries labeled by the generated LFs. The generated LFs effectively label data with AUC scores up to 85.3% and NLU performance improvements up to 27.2%. Furthermore, our results show that the number of LFs affects labeling performance. We believe that our approach can save time and resources in labeling users' queries, allowing practitioners to focus on core chatbot functionalities rather than manually labeling queries.",
      "authors": [
        "Ebube Alor",
        "Ahmad Abdellatif",
        "SayedHassan Khatoonabadi",
        "Emad Shihab"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-09T17:34:14+00:00",
          "link": "https://arxiv.org/abs/2410.07094v1",
          "size": "374kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T23:21:56+00:00",
          "link": "https://arxiv.org/abs/2410.07094v2",
          "size": "435kb",
          "version": "v2"
        }
      ],
      "title": "An Approach for Auto Generation of Labeling Functions for Software Engineering Chatbots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.07094",
        "HTML": "https://arxiv.org/html/2410.07094v2",
        "PDF": "https://arxiv.org/pdf/2410.07094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the auto-generation of labeling functions aimed at improving data labeling efficiency in software engineering chatbots, which can touch on data processing aspects. However, the main focus is not on LLM training data processing."
      },
      "tasks": [
        "Chatbot",
        "Natural Language Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08557",
      "abstract": "Machine unlearning (MU) is to make a well-trained model behave as if it had never been trained on specific data. In today's over-parameterized models, dominated by neural networks, a common approach is to manually relabel data and fine-tune the well-trained model. It can approximate the MU model in the output space, but the question remains whether it can achieve exact MU, i.e., in the parameter space. We answer this question by employing random feature techniques to construct an analytical framework. Under the premise of model optimization via stochastic gradient descent, we theoretically demonstrated that over-parameterized linear models can achieve exact MU through relabeling specific data. We also extend this work to real-world nonlinear networks and propose an alternating optimization algorithm that unifies the tasks of unlearning and relabeling. The algorithm's effectiveness, confirmed through numerical experiments, highlights its superior performance in unlearning across various scenarios compared to current state-of-the-art methods, particularly excelling over similar relabeling-based MU approaches.",
      "authors": [
        "Ruikai Yang",
        "Mingzhen He",
        "Zhengbao He",
        "Youmei Qiu",
        "Xiaolin Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T06:17:17+00:00",
          "link": "https://arxiv.org/abs/2410.08557v1",
          "size": "165kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T06:11:12+00:00",
          "link": "https://arxiv.org/abs/2410.08557v2",
          "size": "210kb",
          "version": "v2"
        }
      ],
      "title": "MUSO: Achieving Exact Machine Unlearning in Over-Parameterized Regimes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08557",
        "HTML": "https://arxiv.org/html/2410.08557v2",
        "PDF": "https://arxiv.org/pdf/2410.08557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with machine unlearning in over-parameterized models, which focuses on removing specific training data effects, but it's not about LLM training data processing such as collection or dataset creation."
      },
      "tasks": [
        "Machine Unlearning",
        "Model Optimization"
      ],
      "repo_urls": [
        "https://github.com/Yruikk/MUSO"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11569",
      "abstract": "Identification capacity has been established as a relevant performance metric for various goal-/task-oriented applications, where the receiver may be interested in only a particular message that represents an event or a task. For example, in olfactory molecular communications (MCs), odors or pheromones, which are often a mixture of various molecule types, may signal nearby danger, food, or a mate. In this paper, we examine the identification capacity with deterministic encoder for the discrete affine Poisson channel which can be used to model MC systems with molecule counting receivers. We establish lower and upper bounds on the identification capacity in terms of features of the affinity matrix between the released molecules and receptors at the receiver. As a key finding, we show that even when the number of receptor types scales sub-linearly in the number of molecule types $N,$ the number of reliably identifiable messages can grow super-exponentially with the rank of the affinity matrix, $T,$ i.e., $\\sim 2^{(T \\log T)R},$ where $R$ denotes the coding rate. We further derive lower and upper bounds on $R,$ and show that the proposed capacity theorem includes several known results in the literature as its special cases.",
      "authors": [
        "Mohammad Javad Salariseddigh",
        "Heinz Koeppl",
        "Holger Boche",
        "and Vahid Jamali"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T13:00:52+00:00",
          "link": "https://arxiv.org/abs/2410.11569v1",
          "size": "225kb",
          "version": "v1"
        },
        {
          "date": "2024-11-03T17:21:53+00:00",
          "link": "https://arxiv.org/abs/2410.11569v2",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T05:47:45+00:00",
          "link": "https://arxiv.org/abs/2410.11569v3",
          "size": "30kb",
          "version": "v3"
        }
      ],
      "title": "Identification over Affine Poisson Channels: Application to Molecular Mixture Communication Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11569",
        "HTML": "https://arxiv.org/html/2410.11569v3",
        "PDF": "https://arxiv.org/pdf/2410.11569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates identification capacity in communication systems and does not relate to data processing for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.13394",
      "abstract": "Evaluating machine-generated text remains a significant challenge in NLP, especially for non-English languages. Current methodologies, including automated metrics, human assessments, and LLM-based evaluations, predominantly focus on English, revealing a significant gap in multilingual evaluation frameworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an extensible framework that includes evaluator LLMs (Hercule) and a novel test set (Recon) specifically designed for multilingual evaluation. Our test set features 500 human-annotated instructions spanning various task capabilities along with human judgment scores across six languages. This would enable benchmarking of general-purpose multilingual LLMs and facilitate meta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a cross-lingual evaluation model that addresses the scarcity of reference answers in the target language by learning to assign scores to responses based on easily available reference answers in English. Our experiments demonstrate that Hercule aligns more closely with human judgments compared to proprietary models, demonstrating the effectiveness of such cross-lingual evaluation in low resource scenarios. Further, it is also effective in zero-shot evaluation on unseen languages. This study is the first comprehensive examination of cross-lingual evaluation using LLMs, presenting a scalable and effective approach for multilingual assessment. All code, datasets, and models will be publicly available to enable further research in this important area.",
      "authors": [
        "Sumanth Doddapaneni",
        "Mohammed Safi Ur Rahman Khan",
        "Dilip Venkatesh",
        "Raj Dabre",
        "Anoop Kunchukuttan",
        "Mitesh M. Khapra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T09:45:32+00:00",
          "link": "https://arxiv.org/abs/2410.13394v1",
          "size": "3812kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:14:51+00:00",
          "link": "https://arxiv.org/abs/2410.13394v2",
          "size": "1280kb",
          "version": "v2"
        }
      ],
      "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13394",
        "HTML": "https://arxiv.org/html/2410.13394v2",
        "PDF": "https://arxiv.org/pdf/2410.13394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cross-lingual evaluation methodologies for multilingual LLMs, including the introduction of a novel test set and evaluation model but does not discuss training data processing stages or operations."
      },
      "models": [
        {
          "model_path": "ai4bharat/hercule-bn",
          "downloads": "11",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-bn"
        },
        {
          "model_path": "ai4bharat/hercule-de",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-de"
        },
        {
          "model_path": "ai4bharat/hercule-fr",
          "downloads": "882",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-fr"
        },
        {
          "model_path": "ai4bharat/hercule-hi",
          "downloads": "26",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-hi"
        },
        {
          "model_path": "ai4bharat/hercule-te",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-te"
        },
        {
          "model_path": "ai4bharat/hercule-ur",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-ur"
        },
        {
          "model_path": "ai4bharat/hercule-hi-lora",
          "downloads": "12",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-hi-lora"
        },
        {
          "model_path": "ai4bharat/hercule-te-lora",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-te-lora"
        },
        {
          "model_path": "ai4bharat/hercule-ur-lora",
          "downloads": "13",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-ur-lora"
        },
        {
          "model_path": "ai4bharat/hercule-bn-lora",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-bn-lora"
        },
        {
          "model_path": "ai4bharat/hercule-de-lora",
          "downloads": "14",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-de-lora"
        },
        {
          "model_path": "ai4bharat/hercule-fr-lora",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/hercule-fr-lora"
        },
        {
          "model_path": "ai4bharat/llama-prometheus",
          "downloads": "11",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ai4bharat/llama-prometheus"
        },
        {
          "model_path": "RichardErkhov/ai4bharat_-_hercule-hi-gguf",
          "downloads": "104",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/ai4bharat_-_hercule-hi-gguf"
        }
      ],
      "datasets": [
        {
          "dataset_name": "ai4bharat/intel",
          "downloads": "474",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ai4bharat/intel"
        },
        {
          "dataset_name": "ai4bharat/recon",
          "downloads": "54",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ai4bharat/recon"
        }
      ],
      "tasks": [
        "Benchmarking"
      ],
      "repo_urls": [
        "https://github.com/ai4bharat/cia"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19410",
      "abstract": "An important problem in topological data analysis (TDA)$\\unicode{x2014}$of both theoretical and practical interest$\\unicode{x2014}$is to reconstruct the topology and geometry of an underlying (usually unknown) metric graph from possibly noisy data sampled around it. Reeb graphs have recently been successfully employed in abstract metric graph reconstruction under Gromov$\\unicode{x2013}$Hausdorff noise: the sample is assumed to be metrically close to the ground truth. However, such a strong global density guarantee is often unavailable, making the existing Reeb graph-based methods unusable. A very different yet more relevant paradigm focuses on the reconstruction of metric graphs$\\unicode{x2014}$embedded in the Euclidean space$\\unicode{x2014}$from Euclidean samples that are only Hausdorff-close. We relax the density assumption to give provable geometric reconstruction schemes, even when the sample is metrically close only locally, but still provide provable guarantees for the successful geometric reconstruction of Euclidean graphs under the Hausdorff noise model.\n  We apply our graph reconstruction techniques to reconstruct earthquake plate tectonic boundaries from the global earthquake catalog. The SLAB2.0 model is a comprehensive spatial summary of all known subduction zone slabs on Earth. We reconstruct parts of the SLAB2.0 model from possibly noisy earthquake hypocenter data.",
      "authors": [
        "Halley Fritze",
        "Sushovan Majhi",
        "Marissa Masden",
        "Atish Mitra and Michael Stickney"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T09:12:56+00:00",
          "link": "https://arxiv.org/abs/2410.19410v1",
          "size": "1594kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:12:41+00:00",
          "link": "https://arxiv.org/abs/2410.19410v2",
          "size": "1036kb",
          "version": "v2"
        }
      ],
      "title": "Faithful Reeb Graph Reconstruction of a Tectonic Subduction Zone from Earthquake Hypocenters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19410",
        "HTML": "https://arxiv.org/html/2410.19410v2",
        "PDF": "https://arxiv.org/pdf/2410.19410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on topological data analysis for reconstructing tectonic subduction zones using earthquake data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.23086",
      "abstract": "Deep Reinforcement Learning (DRL) has emerged as a powerful solution for meeting the growing demands for connectivity, reliability, low latency and operational efficiency in advanced networks. However, most research has focused on theoretical analysis and simulations, with limited investigation into real-world deployment. To bridge the gap and support practical DRL deployment for network management, we first present an orchestration framework that integrates ETSI Multi-access Edge Computing (MEC) with Open RAN, enabling seamless adoption of DRL-based strategies across different time scales while enhancing agent lifecycle management. We then identify three critical challenges hindering DRL's real-world deployment, including (1) asynchronous requests from unpredictable or bursty traffic, (2) adaptability and generalization across heterogeneous topologies and evolving service demands, and (3) prolonged convergence and service interruptions due to exploration in live operational environments. To address these challenges, we propose a three-fold solution strategy: (a) advanced time-series integration for handling asynchronized traffic, (b) flexible architecture design such as multi-agent DRL and incremental learning to support heterogeneous scenarios, and (c) simulation-driven deployment with transfer learning to reduce convergence time and service disruptions. Lastly, the feasibility of the MEC-O-RAN architecture is validated on an urban-wide testing infrastructure, and two real-world use cases are presented, showcasing the three identified challenges and demonstrating the effectiveness of the proposed solutions.",
      "authors": [
        "Haiyuan Li",
        "Hari Madhukumar",
        "Peizheng Li",
        "Yuelin Liu",
        "Yiran Teng",
        "Yulei Wu",
        "Ning Wang",
        "Shuangyi Yan",
        "Dimitra Simeonidou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-30T15:02:54+00:00",
          "link": "https://arxiv.org/abs/2410.23086v1",
          "size": "19875kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:19:31+00:00",
          "link": "https://arxiv.org/abs/2410.23086v2",
          "size": "8344kb",
          "version": "v2"
        }
      ],
      "title": "Towards Practical Operation of Deep Reinforcement Learning Agents in Real-World Network Management at Open RAN Edges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23086",
        "HTML": "https://arxiv.org/html/2410.23086v2",
        "PDF": "https://arxiv.org/pdf/2410.23086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the practical application of deep reinforcement learning in network management, focusing on real-world deployment challenges, unrelated to LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.00459",
      "abstract": "With the advancement of technology, large language models (LLMs) have achieved remarkable performance across various natural language processing (NLP) tasks, powering LLM-integrated applications like Microsoft Copilot. However, as LLMs continue to evolve, new vulnerabilities, especially prompt injection attacks arise. These attacks trick LLMs into deviating from the original input instructions and executing the attacker's instructions injected in data content, such as retrieved results. Recent attack methods leverage LLMs' instruction-following abilities and their inabilities to distinguish instructions injected in the data content, and achieve a high attack success rate (ASR). When comparing the attack and defense methods, we interestingly find that they share similar design goals, of inducing the model to ignore unwanted instructions and instead to execute wanted instructions. Therefore, we raise an intuitive question: Could these attack techniques be utilized for defensive purposes? In this paper, we invert the intention of prompt injection methods to develop novel defense methods based on previous training-free attack methods, by repeating the attack process but with the original input instruction rather than the injected instruction. Our comprehensive experiments demonstrate that our defense techniques outperform existing training-free defense approaches, achieving state-of-the-art results.",
      "authors": [
        "Yulin Chen",
        "Haoran Li",
        "Zihao Zheng",
        "Yangqiu Song",
        "Dekai Wu",
        "Bryan Hooi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-01T09:14:21+00:00",
          "link": "https://arxiv.org/abs/2411.00459v1",
          "size": "697kb",
          "version": "v1"
        },
        {
          "date": "2024-12-23T08:25:54+00:00",
          "link": "https://arxiv.org/abs/2411.00459v2",
          "size": "688kb",
          "version": "v2"
        },
        {
          "date": "2025-02-25T16:17:31+00:00",
          "link": "https://arxiv.org/abs/2411.00459v3",
          "size": "691kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T05:44:32+00:00",
          "link": "https://arxiv.org/abs/2411.00459v4",
          "size": "581kb",
          "version": "v4"
        }
      ],
      "title": "Defense Against Prompt Injection Attack by Leveraging Attack Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00459",
        "HTML": "https://arxiv.org/html/2411.00459v4",
        "PDF": "https://arxiv.org/pdf/2411.00459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on defense mechanisms against prompt injection attacks in LLMs. It does not address any aspect of training data processing, such as data collection or dataset creation, for pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.03537",
      "abstract": "Molecular deep learning models have achieved remarkable success in property prediction, but they often require large amounts of labeled data. The challenge is that, in real-world applications, labels are extremely scarce, as obtaining them through laboratory experimentation is both expensive and time-consuming. In this work, we introduce MoleVers, a versatile pretrained molecular model designed for various types of molecular property prediction in the wild, i.e., where experimentally-validated labels are scarce. MoleVers employs a two-stage pretraining strategy. In the first stage, it learns molecular representations from unlabeled data through masked atom prediction and extreme denoising, a novel task enabled by our newly introduced branching encoder architecture and dynamic noise scale sampling. In the second stage, the model refines these representations through predictions of auxiliary properties derived from computational methods, such as the density functional theory or large language models. Evaluation on 22 small, experimentally-validated datasets demonstrates that MoleVers achieves state-of-the-art performance, highlighting the effectiveness of its two-stage framework in producing generalizable molecular representations for diverse downstream properties.",
      "authors": [
        "Kevin Tirta Wijaya",
        "Minghao Guo",
        "Michael Sun",
        "Hans-Peter Seidel",
        "Wojciech Matusik",
        "Vahid Babaei"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Chemical Physics (physics.chem-ph)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T22:36:17+00:00",
          "link": "https://arxiv.org/abs/2411.03537v1",
          "size": "725kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:53:09+00:00",
          "link": "https://arxiv.org/abs/2411.03537v2",
          "size": "549kb",
          "version": "v2"
        }
      ],
      "title": "Two-Stage Pretraining for Molecular Property Prediction in the Wild",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03537",
        "HTML": "https://arxiv.org/html/2411.03537v2",
        "PDF": "https://arxiv.org/pdf/2411.03537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with molecular property prediction using a two-stage pretraining strategy, focusing on learning representations from unlabeled molecular data. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Molecular Property Prediction",
        "Property Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.07146",
      "abstract": "Advancements in tracking algorithms have empowered nascent applications across various domains, from steering autonomous vehicles to guiding robots to enhancing augmented reality experiences for users. However, these algorithms are application-specific and do not work across applications with different types of motion; even a tracking algorithm designed for a given application does not work in scenarios deviating from highly standard conditions. For example, a tracking algorithm designed for robot navigation inside a building will not work for tracking the same robot in an outdoor environment. To demonstrate this problem, we evaluate the performance of the state-of-the-art tracking methods across various applications and scenarios. To inform our analysis, we first categorize algorithmic, environmental, and locomotion-related challenges faced by tracking algorithms. We quantitatively evaluate the performance using multiple tracking algorithms and representative datasets for a wide range of Internet of Things (IoT) and Extended Reality (XR) applications, including autonomous vehicles, drones, and humans. Our analysis shows that no tracking algorithm works across different applications and scenarios within applications. Ultimately, using the insights generated from our analysis, we discuss multiple approaches to improving the tracking performance using input data characterization, leveraging intermediate information, and output evaluation.",
      "authors": [
        "Yasra Chandio",
        "Khotso Selialia",
        "Joseph DeGol",
        "Luis Garcia",
        "Fatima M. Anwar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T17:17:11+00:00",
          "link": "https://arxiv.org/abs/2411.07146v1",
          "size": "3405kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T18:44:07+00:00",
          "link": "https://arxiv.org/abs/2411.07146v2",
          "size": "2924kb",
          "version": "v2"
        }
      ],
      "title": "Lost in Tracking Translation: A Comprehensive Analysis of Visual SLAM in Human-Centered XR and IoT Ecosystems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07146",
        "HTML": "https://arxiv.org/html/2411.07146v2",
        "PDF": "https://arxiv.org/pdf/2411.07146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper conducts an analysis of visual SLAM in various applications and does not address LLM training data processing or any relevant data engineering operations."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Robot Navigation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.07799",
      "abstract": "Accurate and consistent fruit monitoring over time is a key step toward automated agricultural production systems. However, this task is inherently difficult due to variations in fruit size, shape, occlusion, orientation, and the dynamic nature of orchards where fruits may appear or disappear between observations. In this article, we propose a novel method for fruit instance segmentation and re-identification on 3D terrestrial point clouds collected over time. Our approach directly operates on dense colored point clouds, capturing fine-grained 3D spatial detail. We segment individual fruits using a learning-based instance segmentation method applied directly to the point cloud. For each segmented fruit, we extract a compact and discriminative descriptor using a 3D sparse convolutional neural network. To track fruits across different times, we introduce an attention-based matching network that associates fruits with their counterparts from previous sessions. Matching is performed using a probabilistic assignment scheme, selecting the most likely associations across time. We evaluate our approach on real-world datasets of strawberries and apples, demonstrating that it outperforms existing methods in both instance segmentation and temporal re-identification, enabling robust and precise fruit monitoring across complex and dynamic orchard environments.",
      "authors": [
        "Daniel Fusaro",
        "Federico Magistri",
        "Jens Behley",
        "Alberto Pretto",
        "and Cyrill Stachniss"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T13:53:22+00:00",
          "link": "https://arxiv.org/abs/2411.07799v1",
          "size": "15128kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:52:19+00:00",
          "link": "https://arxiv.org/abs/2411.07799v2",
          "size": "3925kb",
          "version": "v2"
        }
      ],
      "title": "Horticultural Temporal Fruit Monitoring via 3D Instance Segmentation and Re-Identification using Colored Point Clouds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07799",
        "HTML": "https://arxiv.org/html/2411.07799v2",
        "PDF": "https://arxiv.org/pdf/2411.07799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for fruit instance segmentation and re-identification using 3D point clouds, which is unrelated to LLM training data processing stages or operations."
      },
      "tasks": [
        "3D Instance Segmentation",
        "Instance Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/prbonn/iris3d"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.02503",
      "abstract": "This paper presents Variables Adaptive Mixture of Experts (VAMoE), a novel framework for incremental weather forecasting that dynamically adapts to evolving spatiotemporal patterns in real time data. Traditional weather prediction models often struggle with exorbitant computational expenditure and the need to continuously update forecasts as new observations arrive. VAMoE addresses these challenges by leveraging a hybrid architecture of experts, where each expert specializes in capturing distinct subpatterns of atmospheric variables (temperature, humidity, wind speed). Moreover, the proposed method employs a variable adaptive gating mechanism to dynamically select and combine relevant experts based on the input context, enabling efficient knowledge distillation and parameter sharing. This design significantly reduces computational overhead while maintaining high forecast accuracy. Experiments on real world ERA5 dataset demonstrate that VAMoE performs comparable against SoTA models in both short term (1 days) and long term (5 days) forecasting tasks, with only about 25% of trainable parameters and 50% of the initial training data.",
      "authors": [
        "Hao Chen",
        "Han Tao",
        "Guo Song",
        "Jie Zhang",
        "Yunlong Yu",
        "Yonghan Dong",
        "and Lei Bai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T15:30:52+00:00",
          "link": "https://arxiv.org/abs/2412.02503v1",
          "size": "7751kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:06:20+00:00",
          "link": "https://arxiv.org/abs/2412.02503v2",
          "size": "2307kb",
          "version": "v2"
        }
      ],
      "title": "VA-MoE: Variables-Adaptive Mixture of Experts for Incremental Weather Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02503",
        "HTML": "https://arxiv.org/html/2412.02503v2",
        "PDF": "https://arxiv.org/pdf/2412.02503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel framework for weather forecasting using a Variables Adaptive Mixture of Experts architecture, which is unrelated to LLM training data processing. It does not address data collection, generation, or improvement for LLMs."
      },
      "tasks": [
        "Incremental Learning",
        "Weather Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.05144",
      "abstract": "Understanding the training dynamics of deep neural networks (DNNs), particularly how they evolve low-dimensional features from high-dimensional data, remains a central challenge in deep learning theory. In this work, we introduce the concept of $\\epsilon$-rank, a novel metric quantifying the effective feature of neuron functions in the terminal hidden layer. Through extensive experiments across diverse tasks, we observe a universal staircase phenomenon: during training process implemented by the standard stochastic gradient descent methods, the decline of the loss function is accompanied by an increase in the $\\epsilon$-rank and exhibits a staircase pattern. Theoretically, we rigorously prove a negative correlation between the loss lower bound and $\\epsilon$-rank, demonstrating that a high $\\epsilon$-rank is essential for significant loss reduction. Moreover, numerical evidences show that within the same deep neural network, the $\\epsilon$-rank of the subsequent hidden layer is higher than that of the previous hidden layer. Based on these observations, to eliminate the staircase phenomenon, we propose a novel pre-training strategy on the initial hidden layer that elevates the $\\epsilon$-rank of the terminal hidden layer. Numerical experiments validate its effectiveness in reducing training time and improving accuracy across various tasks. Therefore, the newly introduced concept of $\\epsilon$-rank is a computable quantity that serves as an intrinsic effective metric characteristic for deep neural networks, providing a novel perspective for understanding the training dynamics of neural networks and offering a theoretical foundation for designing efficient training strategies in practical applications.",
      "authors": [
        "Jiang Yang",
        "Yuxiang Zhao",
        "Quanhui Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T16:00:50+00:00",
          "link": "https://arxiv.org/abs/2412.05144v1",
          "size": "1455kb",
          "version": "v1"
        },
        {
          "date": "2025-01-09T06:18:12+00:00",
          "link": "https://arxiv.org/abs/2412.05144v2",
          "size": "1455kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T14:59:07+00:00",
          "link": "https://arxiv.org/abs/2412.05144v3",
          "size": "1667kb",
          "version": "v3"
        }
      ],
      "title": "$\\epsilon$-rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05144",
        "HTML": "https://arxiv.org/html/2412.05144v3",
        "PDF": "https://arxiv.org/pdf/2412.05144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the concept of $\\epsilon$-rank to study the training dynamics of neural networks, which is irrelevant to LLM training data processing. It focuses on neural network feature dynamics rather than data engineering or dataset creation for LLMs."
      },
      "tasks": [
        "Learning Theory"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.05657",
      "abstract": "This study addresses the critical challenge of error accumulation in spatio-temporal auto-regressive (AR) predictions within scientific machine learning models by exploring temporal integration schemes and adaptive multi-step rollout strategies. We introduce the first implementation of the two-step Adams-Bashforth method specifically tailored for data-driven AR prediction, leveraging historical derivative information to enhance numerical stability without additional computational overhead. To validate our approach, we systematically evaluate time integration schemes across canonical 2D PDEs before extending to complex Navier-Stokes cylinder vortex shedding dynamics. Additionally, we develop three novel adaptive weighting strategies that dynamically adjust the importance of different future time steps during multi-step rollout training. Our analysis reveals that as physical complexity increases, such sophisticated rollout techniques become essential, with the Adams-Bashforth scheme demonstrating consistent robustness across investigated systems and our best adaptive approach delivering an 89% improvement over conventional fixed-weight methods while maintaining similar computational costs. For the complex Navier-Stokes vortex shedding problem, despite using an extremely lightweight graph neural network with just 1,177 trainable parameters and training on only 50 snapshots, our framework accurately predicts 350 future time steps reducing mean squared error from 0.125 (single-step direct prediction) to 0.002 (Adams-Bashforth with proposed multi-step rollout). Our integrated methodology demonstrates an 83% improvement over standard noise injection techniques and maintains robustness under severe spatial constraints; specifically, when trained on only a partial spatial domain, it still achieves 58% and 27% improvements over direct prediction and forward Euler methods, respectively.",
      "authors": [
        "Sunwoong Yang",
        "Ricardo Vinuesa",
        "Namwoo Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-07T14:02:57+00:00",
          "link": "https://arxiv.org/abs/2412.05657v1",
          "size": "21666kb",
          "version": "v1"
        },
        {
          "date": "2025-03-07T10:55:23+00:00",
          "link": "https://arxiv.org/abs/2412.05657v2",
          "size": "21964kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T01:15:54+00:00",
          "link": "https://arxiv.org/abs/2412.05657v3",
          "size": "21062kb",
          "version": "v3"
        }
      ],
      "title": "AI-Accelerated Flow Simulation: A Robust Auto-Regressive Framework for Long-Term CFD Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05657",
        "HTML": "https://arxiv.org/html/2412.05657v3",
        "PDF": "https://arxiv.org/pdf/2412.05657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with AI-accelerated flow simulation and error accumulation in spatio-temporal auto-regressive predictions, which is unrelated to LLM training data processing. It does not address any operations related to LLM data quality or data set creation."
      },
      "tasks": [
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.15366",
      "abstract": "Faster-than-Nyquist (FTN) signaling is a non-orthogonal transmission technique offering a promising solution for future generations of communications. This paper studies the capacity of FTN signaling in multiple-input multiple-output (MIMO) channels for high acceleration factors. In our previous study [1], we found the capacity for MIMO FTN channels if the acceleration factor is larger than a certain threshold, which depends on the bandwidth of the pulse shape used. In this paper, we extend the capacity analysis to acceleration factors smaller than this mentioned threshold. In addition to capacity, we conduct peak-to-average power ratio (PAPR) analysis and simulation for MIMO FTN for varying acceleration factors for both Gaussian and QPSK symbol sets. Our analysis reveals important insights about transmission power and received signal-to-noise ratio (SNR) variation in FTN. As the acceleration factor approaches 0, if the transmission power is fixed, the received SNR diminishes, or if the received SNR is fixed, PAPR at the transmitter explodes.",
      "authors": [
        "Zichao Zhang",
        "Melda Yuksel",
        "Gokhan M. Guvensen",
        "Halim Yanikomeroglu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T19:54:07+00:00",
          "link": "https://arxiv.org/abs/2412.15366v1",
          "size": "355kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T22:04:15+00:00",
          "link": "https://arxiv.org/abs/2412.15366v2",
          "size": "372kb",
          "version": "v2"
        }
      ],
      "title": "Capacity and PAPR Analysis for MIMO Faster-than-Nyquist Signaling with High Acceleration Rate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15366",
        "HTML": "https://arxiv.org/html/2412.15366v2",
        "PDF": "https://arxiv.org/pdf/2412.15366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on MIMO faster-than-Nyquist signaling for communications, analyzing capacity and PAPR. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.16247",
      "abstract": "Sparse dictionary learning (DL) has emerged as a powerful approach to extract semantically meaningful concepts from the internals of large language models (LLMs) trained mainly in the text domain. In this work, we explore whether DL can extract meaningful concepts from less human-interpretable scientific data, such as vision foundation models trained on cell microscopy images, where limited prior knowledge exists about which high-level concepts should arise. We propose a novel combination of a sparse DL algorithm, Iterative Codebook Feature Learning (ICFL), with a PCA whitening pre-processing step derived from control data. Using this combined approach, we successfully retrieve biologically meaningful concepts, such as cell types and genetic perturbations. Moreover, we demonstrate how our method reveals subtle morphological changes arising from human-interpretable interventions, offering a promising new direction for scientific discovery via mechanistic interpretability in bioimaging.",
      "authors": [
        "Konstantin Donhauser",
        "Kristina Ulicna",
        "Gemma Elyse Moran",
        "Aditya Ravuri",
        "Kian Kenyon-Dean",
        "Cian Eastwood and Jason Hartford"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T00:01:16+00:00",
          "link": "https://arxiv.org/abs/2412.16247v1",
          "size": "21386kb",
          "version": "v1"
        },
        {
          "date": "2025-02-11T16:54:45+00:00",
          "link": "https://arxiv.org/abs/2412.16247v2",
          "size": "38526kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T12:37:43+00:00",
          "link": "https://arxiv.org/abs/2412.16247v3",
          "size": "22467kb",
          "version": "v3"
        }
      ],
      "title": "Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16247",
        "HTML": "https://arxiv.org/html/2412.16247v3",
        "PDF": "https://arxiv.org/pdf/2412.16247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses dictionary learning for extracting biological concepts from microscopy models. It does not address aspects of LLM training data processing or datasets."
      },
      "tasks": [
        "Dictionary Learning",
        "scientific discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17305",
      "abstract": "The energy efficiency of deep spiking neural networks (SNNs) aligns with the constraints of resource-limited edge devices, positioning SNNs as a promising foundation for intelligent applications leveraging the extensive data collected by these devices. To address data privacy concerns when deploying SNNs on edge devices, federated learning (FL) facilitates collaborative model training by leveraging data distributed across edge devices without transmitting local data to a central server. However, existing FL approaches struggle with label-skewed data across devices, which leads to drift in local SNN models and degrades the performance of the global SNN model. In this paper, we propose a novel framework called FedLEC, which incorporates intra-client label weight calibration to balance the learning intensity across local labels and inter-client knowledge distillation to mitigate local SNN model bias caused by label absence. Extensive experiments with three different structured SNNs across five datasets (i.e., three non-neuromorphic and two neuromorphic datasets) demonstrate the efficiency of FedLEC. Compared to eight state-of-the-art FL algorithms, FedLEC achieves an average accuracy improvement of approximately 11.59% for the global SNN model under various label skew distribution settings.",
      "authors": [
        "Di Yu",
        "Xin Du",
        "Linshan Jiang",
        "Huijing Zhang",
        "Shuiguang Deng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T05:52:32+00:00",
          "link": "https://arxiv.org/abs/2412.17305v1",
          "size": "5772kb",
          "version": "v1"
        },
        {
          "date": "2025-01-19T06:58:01+00:00",
          "link": "https://arxiv.org/abs/2412.17305v2",
          "size": "6429kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T10:23:46+00:00",
          "link": "https://arxiv.org/abs/2412.17305v3",
          "size": "531kb",
          "version": "v3"
        }
      ],
      "title": "Exploiting Label Skewness for Spiking Neural Networks in Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17305",
        "HTML": "https://arxiv.org/html/2412.17305v3",
        "PDF": "https://arxiv.org/pdf/2412.17305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for federated learning with spiking neural networks, focusing on label skewness. It does not pertain to LLM training data processing."
      },
      "tasks": [
        "Federated Learning",
        "Knowledge Distillation",
        "Missing Labels"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17531",
      "abstract": "Backdoor attacks pose an important security threat to textual large language models. Exploring textual backdoor attacks not only helps reveal the potential security risks of models, but also promotes innovation and development of defense mechanisms. Currently, most textual backdoor attack methods are based on a single trigger. For example, inserting specific content into text as a trigger or changing the abstract text features to be a trigger. However, the adoption of this single-trigger mode makes the existing backdoor attacks subject to certain limitations: either they are easily identified by the existing defense strategies, or they have certain shortcomings in attack performance and in the construction of poisoned datasets. In order to solve these issues, a dual-trigger backdoor attack method is proposed in this paper. Specifically, we use two different attributes, syntax and mood (we use subjunctive mood as an example in this article), as two different triggers. It makes our backdoor attack method similar to a double landmine which can have completely different trigger conditions simultaneously. Therefore, this method not only improves the flexibility of trigger mode, but also enhances the robustness against defense detection. A large number of experimental results show that this method significantly outperforms the previous methods based on abstract features in attack performance, and achieves comparable attack performance (almost 100\\% attack success rate) with the insertion-based method. In addition, in order to further improve the attack performance, we also give the construction method of the poisoned dataset.The code and data of this paper can be obtained at https://github.com/HoyaAm/Double-Landmines.",
      "authors": [
        "Yang Hou",
        "Qiuling Yue",
        "Lujia Chai",
        "Guozhao Liao",
        "Wenbao Han",
        "Wei Ou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T12:56:30+00:00",
          "link": "https://arxiv.org/abs/2412.17531v1",
          "size": "20368kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T12:51:09+00:00",
          "link": "https://arxiv.org/abs/2412.17531v2",
          "size": "14469kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T02:44:07+00:00",
          "link": "https://arxiv.org/abs/2412.17531v3",
          "size": "6660kb",
          "version": "v3"
        }
      ],
      "title": "Invisible Textual Backdoor Attacks based on Dual-Trigger",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17531",
        "HTML": "https://arxiv.org/html/2412.17531v3",
        "PDF": "https://arxiv.org/pdf/2412.17531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a dual-trigger backdoor attack and construction of a poisoned dataset, which has implications for data processing related to model training, but its focus is on security threats rather than improving data quality for LLMs."
      },
      "tasks": [
        "Backdoor Attack"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.18781",
      "abstract": "Offline reinforcement learning, which learns solely from datasets without environmental interaction, has gained attention. This approach, similar to traditional online deep reinforcement learning, is particularly promising for robot control applications. Nevertheless, its robustness against real-world challenges, such as joint actuator faults in robots, remains a critical concern. This study evaluates the robustness of existing offline reinforcement learning methods using legged robots from OpenAI Gym based on average episodic rewards. For robustness evaluation, we simulate failures by incorporating both random and adversarial perturbations, representing worst-case scenarios, into the joint torque signals. Our experiments show that existing offline reinforcement learning methods exhibit significant vulnerabilities to these action perturbations and are more vulnerable than online reinforcement learning methods, highlighting the need for more robust approaches in this field.",
      "authors": [
        "Shingo Ayabe",
        "Takuto Otomo",
        "Hiroshi Kera",
        "Kazuhiko Kawamoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-25T05:02:22+00:00",
          "link": "https://arxiv.org/abs/2412.18781v1",
          "size": "933kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:42:53+00:00",
          "link": "https://arxiv.org/abs/2412.18781v2",
          "size": "1232kb",
          "version": "v2"
        }
      ],
      "title": "Robustness Evaluation of Offline Reinforcement Learning for Robot Control Against Action Perturbations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18781",
        "HTML": "https://arxiv.org/html/2412.18781v2",
        "PDF": "https://arxiv.org/pdf/2412.18781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study evaluates the robustness of offline reinforcement learning for robots against action perturbations. It is not related to LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "OpenAI Gym",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.20383",
      "abstract": "Current fine-grained classification research primarily focuses on fine-grained feature learning. However, in real-world scenarios, fine-grained data annotation is challenging, and the features and semantics are highly diverse and frequently changing. These issues create inherent barriers between traditional experimental settings and real-world applications, limiting the effectiveness of conventional fine-grained classification methods. Although some recent studies have provided potential solutions to these issues, most of them still rely on limited supervised information and thus fail to offer effective solutions. In this paper, based on theoretical analysis, we propose a novel learning paradigm to break the barriers in fine-grained classification. This paradigm enables the model to progressively learn during inference, thereby leveraging cost-free data to more accurately represent fine-grained categories and adapt to dynamic semantic changes. On this basis, an efficient EXPloring and EXPloiting strategy and method (EXP2) is designed. Thereinto, useful inference data samples are explored according to class representations and exploited to optimize classifiers. Experimental results demonstrate the general effectiveness of our method, providing guidance for future in-depth understanding and exploration of real-world fine-grained classification.",
      "authors": [
        "Li-Jun Zhao",
        "Zhen-Duo Chen",
        "Zhi-Yuan Xue",
        "Xin Luo",
        "Xin-Shun Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-29T07:11:44+00:00",
          "link": "https://arxiv.org/abs/2412.20383v1",
          "size": "3054kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:58:15+00:00",
          "link": "https://arxiv.org/abs/2412.20383v2",
          "size": "5095kb",
          "version": "v2"
        }
      ],
      "title": "Progressively Exploring and Exploiting Cost-Free Data to Break Fine-Grained Classification Barriers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20383",
        "HTML": "https://arxiv.org/html/2412.20383v2",
        "PDF": "https://arxiv.org/pdf/2412.20383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel learning paradigm for fine-grained classification focused on utilizing cost-free data to improve classification accuracy. It does not contribute to LLM training data processing, as it is focused on model learning processes rather than data engineering for language models."
      },
      "tasks": [
        "Classification",
        "class-incremental learning",
        "Class Incremental Learning",
        "Few-Shot Class-Incremental Learning",
        "Incremental Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.00152",
      "abstract": "This paper explores whether enhancing temporal reasoning capabilities in Large Language Models (LLMs) can improve the quality of timeline summarisation, the task of summarising long texts containing sequences of events, such as social media threads. We first introduce NarrativeReason, a novel dataset focused on temporal relationships among sequential events within narratives, distinguishing it from existing temporal reasoning datasets that primarily address pair-wise event relationships. Our approach then combines temporal reasoning with timeline summarisation through a knowledge distillation framework, where we first fine-tune a teacher model on temporal reasoning tasks and then distill this knowledge into a student model while simultaneously training it for the task of timeline summarisation. Experimental results demonstrate that our model achieves superior performance on out-of-domain mental health-related timeline summarisation tasks, which involve long social media threads with repetitions of events and a mix of emotions, highlighting the importance and generalisability of leveraging temporal reasoning to improve timeline summarisation.",
      "authors": [
        "Jiayu Song",
        "Mahmud Elahi Akhter",
        "Dana Atzil Slonim",
        "Maria Liakata"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T21:54:33+00:00",
          "link": "https://arxiv.org/abs/2501.00152v1",
          "size": "433kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T14:02:12+00:00",
          "link": "https://arxiv.org/abs/2501.00152v2",
          "size": "539kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T03:12:59+00:00",
          "link": "https://arxiv.org/abs/2501.00152v3",
          "size": "576kb",
          "version": "v3"
        }
      ],
      "title": "Temporal reasoning for timeline summarisation in social media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00152",
        "HTML": "https://arxiv.org/html/2501.00152v3",
        "PDF": "https://arxiv.org/pdf/2501.00152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel dataset for enhancing temporal reasoning in LLMs and uses it to fine-tune a model for summarizing timelines. While it involves creation of a dataset, the focus is on temporal reasoning tasks rather than comprehensive LLM training data processing."
      },
      "tasks": [
        "Knowledge Distillation",
        "Timeline Summarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01593",
      "abstract": "Recent studies have shown that cooperative multi-agent deep reinforcement learning (c-MADRL) is under the threat of backdoor attacks. Once a backdoor trigger is observed, it will perform malicious actions leading to failures or malicious goals. However, existing backdoor attacks suffer from several issues, e.g., instant trigger patterns lack stealthiness, the backdoor is trained or activated by an additional network, or all agents are backdoored. To this end, in this paper, we propose a novel backdoor leverage attack against c-MADRL, BLAST, which attacks the entire multi-agent team by embedding the backdoor only in a single agent. Firstly, we introduce adversary spatiotemporal behavior patterns as the backdoor trigger rather than manual-injected fixed visual patterns or instant status and control the period to perform malicious actions. This method can guarantee the stealthiness and practicality of BLAST. Secondly, we hack the original reward function of the backdoor agent via unilateral guidance to inject BLAST, so as to achieve the \\textit{leverage attack effect} that can pry open the entire multi-agent system via a single backdoor agent. We evaluate our BLAST against 3 classic c-MADRL algorithms (VDN, QMIX, and MAPPO) in 2 popular c-MADRL environments (SMAC and Pursuit), and 2 existing defense mechanisms. The experimental results demonstrate that BLAST can achieve a high attack success rate while maintaining a low clean performance variance rate.",
      "authors": [
        "Jing Fang",
        "Saihao Yan",
        "Xueyu Yin",
        "Yinbo Yu",
        "Chunwei Tian",
        "and Jiajia Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-03T01:33:29+00:00",
          "link": "https://arxiv.org/abs/2501.01593v1",
          "size": "14593kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T01:31:33+00:00",
          "link": "https://arxiv.org/abs/2501.01593v2",
          "size": "14567kb",
          "version": "v2"
        }
      ],
      "title": "BLAST: A Stealthy Backdoor Leverage Attack against Cooperative Multi-Agent Deep Reinforcement Learning based Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01593",
        "HTML": "https://arxiv.org/html/2501.01593v2",
        "PDF": "https://arxiv.org/pdf/2501.01593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a backdoor attack strategy against cooperative multi-agent deep reinforcement learning systems and does not involve any aspect of LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "SMAC",
        "SMAC+"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.02183",
      "abstract": "Hamiltonian operator inference has been developed in [Sharma, H., Wang, Z., Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn structure-preserving reduced-order models (ROMs) for Hamiltonian systems. The method constructs a low-dimensional model using only data and knowledge of the functional form of the Hamiltonian. The resulting ROMs preserve the intrinsic structure of the system, ensuring that the mechanical and physical properties of the system are maintained. In this work, we extend this approach to port-Hamiltonian systems, which generalize Hamiltonian systems by including energy dissipation, external input, and output. Based on snapshots of the system's state and output, together with the information about the functional form of the Hamiltonian, reduced operators are inferred through optimization and are then used to construct data-driven ROMs. To further alleviate the complexity of evaluating nonlinear terms in the ROMs, a hyper-reduction method via discrete empirical interpolation is applied. Accordingly, we derive error estimates for the ROM approximations of the state and output. Finally, we demonstrate the structure preservation, as well as the accuracy of the proposed port-Hamiltonian operator inference framework, through numerical experiments on a linear mass-spring-damper problem and a nonlinear Toda lattice problem.",
      "authors": [
        "Yuwei Geng",
        "Lili Ju",
        "Boris Kramer",
        "Zhu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-04T04:25:51+00:00",
          "link": "https://arxiv.org/abs/2501.02183v1",
          "size": "1794kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:37:22+00:00",
          "link": "https://arxiv.org/abs/2501.02183v2",
          "size": "1815kb",
          "version": "v2"
        }
      ],
      "title": "Data-Driven Reduced-Order Models for Port-Hamiltonian Systems with Operator Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02183",
        "HTML": "https://arxiv.org/html/2501.02183v2",
        "PDF": "https://arxiv.org/pdf/2501.02183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses data-driven methods and reduced-order models for Hamiltonian systems. It does not pertain to LLM training data processing, as its focus is on modeling physical systems, not language data."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03572",
      "abstract": "Web accessibility ensures that individuals with disabilities can access and interact with digital content without barriers, yet a significant majority of most used websites fail to meet accessibility standards. This study evaluates ChatGPT's (GPT-4o) ability to generate and improve web pages in line with Web Content Accessibility Guidelines (WCAG). While ChatGPT can effectively address accessibility issues when prompted, its default code often lacks compliance, reflecting limitations in its training data and prevailing inaccessible web practices. Automated and manual testing revealed strengths in resolving simple issues but challenges with complex tasks, requiring human oversight and additional iterations. Unlike prior studies, we incorporate manual evaluation, dynamic elements, and use the visual reasoning capability of ChatGPT along with the prompts to fix accessibility issues. Providing screenshots alongside prompts enhances the LLM's ability to address accessibility issues by allowing it to analyze surrounding components, such as determining appropriate contrast colors. We found that effective prompt engineering, such as providing concise, structured feedback and incorporating visual aids, significantly enhances ChatGPT's performance. These findings highlight the potential and limitations of large language models for accessible web development, offering practical guidance for developers to create more inclusive websites.",
      "authors": [
        "Ammar Ahmed",
        "Margarida Fresco",
        "Fredrik Forsberg",
        "Hallvard Grotli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T06:51:46+00:00",
          "link": "https://arxiv.org/abs/2501.03572v1",
          "size": "20915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:26:22+00:00",
          "link": "https://arxiv.org/abs/2501.03572v2",
          "size": "5661kb",
          "version": "v2"
        }
      ],
      "title": "From Code to Compliance: Assessing ChatGPT's Utility in Designing an Accessible Webpage -- A Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03572",
        "HTML": "https://arxiv.org/html/2501.03572v2",
        "PDF": "https://arxiv.org/pdf/2501.03572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates ChatGPT's ability to design accessible web pages. Although it touches on training data limitations, it mainly focuses on applications in web development, not on improving LLM training data processing."
      },
      "tasks": [
        "Prompt Engineering",
        "Visual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.03840",
      "abstract": "Artificial intelligence and machine learning applications in archaeology have increased significantly in recent years, and these now span all subfields, geographical regions, and time periods. The prevalence and success of these applications have remained largely unexamined, as recent reviews on the use of machine learning in archaeology have only focused only on specific subfields of archaeology. Our review examined an exhaustive corpus of 135 articles published between 1997 and 2022. We observed a significant increase in the number of publications from 2019 onwards. Automatic structure detection and artefact classification were the most represented tasks in the articles reviewed, followed by taphonomy, and archaeological predictive modelling. From the review, clustering and unsupervised methods were underrepresented compared to supervised models. Artificial neural networks and ensemble learning account for two thirds of the total number of models used. However, if machine learning models are gaining in popularity they remain subject to misunderstanding. We observed, in some cases, poorly defined requirements and caveats of the machine learning methods used. Furthermore, the goals and the needs of machine learning applications for archaeological purposes are in some cases unclear or poorly expressed. To address this, we proposed a workflow guide for archaeologists to develop coherent and consistent methodologies adapted to their research questions, project scale and data. As in many other areas, machine learning is rapidly becoming an important tool in archaeological research and practice, useful for the analyses of large and multivariate data, although not without limitations. This review highlights the importance of well-defined and well-reported structured methodologies and collaborative practices to maximise the potential of applications of machine learning methods in archaeology.",
      "authors": [
        "Mathias Bellat",
        "Jordy D. Orellana Figueroa",
        "Jonathan S. Reeves",
        "Ruhollah Taghizadeh-Mehrjardi",
        "Claudio Tennie and Thomas Scholten"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T14:50:05+00:00",
          "link": "https://arxiv.org/abs/2501.03840v1",
          "size": "1551kb",
          "version": "v1"
        },
        {
          "date": "2025-01-20T10:22:31+00:00",
          "link": "https://arxiv.org/abs/2501.03840v2",
          "size": "1551kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T15:07:01+00:00",
          "link": "https://arxiv.org/abs/2501.03840v3",
          "size": "1554kb",
          "version": "v3"
        }
      ],
      "title": "Machine learning applications in archaeological practices: a review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03840",
        "HTML": "https://arxiv.org/html/2501.03840v3",
        "PDF": "https://arxiv.org/pdf/2501.03840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews machine learning applications in archaeology, focusing on tasks like automatic structure detection and artifact classification. It does not address LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "Articles",
        "Ensemble Learning"
      ],
      "repo_urls": [
        "https://github.com/mathias-bellat/ml_archaeology_review"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.05000",
      "abstract": "Energy communities (ECs) play a key role in enabling local demand shifting and enhancing self-sufficiency, as energy systems transition toward decentralized structures with high shares of renewable generation. To optimally operate them, accurate short-term load forecasting is essential, particularly for implementing demand-side management strategies. With the recent rise of deep learning methods, data-driven forecasting has gained significant attention, however, it remains insufficiently explored in many practical contexts. Therefore, this study evaluates the effectiveness of state-of-the-art deep learning models-including LSTM, xLSTM, and Transformer architectures-compared to traditional benchmarks such as K-Nearest Neighbors (KNN) and persistence forecasting, across varying community size, historical data availability, and model complexity. Additionally, we assess the benefits of transfer learning using publicly available synthetic load profiles. On average, transfer learning improves the normalized mean absolute error by 1.97 percentage points when only two months of training data are available. Interestingly, for less than six months of training data, simple persistence models outperform deep learning architectures in forecast accuracy. The practical value of improved forecasting is demonstrated using a mixed-integer linear programming optimization for ECs with a shared battery energy storage system. For an energy community with 50 households, the most accurate deep learning model achieves an average reduction in financial energy costs of 8.06%. Notably, a simple KNN approach achieves average savings of 8.01%, making it a competitive and robust alternative. All implementations are publicly available to facilitate reproducibility. These findings offer actionable insights for ECs, and they highlight when the additional complexity of deep learning is warranted by performance gains.",
      "authors": [
        "Lukas Moosbrugger",
        "Valentin Seiler",
        "Philipp Wohlgenannt",
        "Sebastian Hegenbart",
        "Sashko Ristov",
        "Elias Eder",
        "Peter Kepplinger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T06:29:50+00:00",
          "link": "https://arxiv.org/abs/2501.05000v1",
          "size": "877kb",
          "version": "v1"
        },
        {
          "date": "2025-01-29T15:58:28+00:00",
          "link": "https://arxiv.org/abs/2501.05000v2",
          "size": "851kb",
          "version": "v2"
        },
        {
          "date": "2025-05-23T12:07:21+00:00",
          "link": "https://arxiv.org/abs/2501.05000v3",
          "size": "507kb",
          "version": "v3"
        },
        {
          "date": "2025-06-02T10:14:39+00:00",
          "link": "https://arxiv.org/abs/2501.05000v4",
          "size": "470kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T11:46:13+00:00",
          "link": "https://arxiv.org/abs/2501.05000v5",
          "size": "476kb",
          "version": "v5"
        }
      ],
      "title": "Load Forecasting for Households and Energy Communities: Are Deep Learning Models Worth the Effort?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05000",
        "HTML": "https://arxiv.org/html/2501.05000v5",
        "PDF": "https://arxiv.org/pdf/2501.05000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study assesses deep learning models for load forecasting in energy communities. It focuses on model performance and optimization in energy systems rather than LLM training data processing or data engineering aspects."
      },
      "tasks": [
        "Deep Learning",
        "Load Forecasting",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/rce-fhv/loadforecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06848",
      "abstract": "Diffusion models produce impressive results in modalities ranging from images and video to protein design and text. However, generating samples with user-specified properties remains a challenge. Recent research proposes fine-tuning models to maximize rewards that capture desired properties, but these methods require expensive training and are prone to mode collapse. In this work, we present Feynman-Kac (FK) steering, an inference-time framework for steering diffusion models with reward functions. FK steering works by sampling a system of multiple interacting diffusion processes, called particles, and resampling particles at intermediate steps based on scores computed using functions called potentials. Potentials are defined using rewards for intermediate states and are selected such that a high value indicates that the particle will yield a high-reward sample. We explore various choices of potentials, intermediate rewards, and samplers. We evaluate FK steering on text-to-image and text diffusion models. For steering text-to-image models with a human preference reward, we find that FK steering a 0.8B parameter model outperforms a 2.6B parameter fine-tuned model on prompt fidelity, with faster sampling and no training. For steering text diffusion models with rewards for text quality and specific text attributes, we find that FK steering generates lower perplexity, more linguistically acceptable outputs and enables gradient-free control of attributes like toxicity. Our results demonstrate that inference-time scaling and steering of diffusion models - even with off-the-shelf rewards - can provide significant sample quality gains and controllability benefits. Code is available at https://github.com/zacharyhorvitz/Fk-Diffusion-Steering .",
      "authors": [
        "Raghav Singhal",
        "Zachary Horvitz",
        "Ryan Teehan",
        "Mengye Ren",
        "Zhou Yu",
        "Kathleen McKeown",
        "Rajesh Ranganath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T15:34:24+00:00",
          "link": "https://arxiv.org/abs/2501.06848v1",
          "size": "21362kb",
          "version": "v1"
        },
        {
          "date": "2025-01-15T18:28:37+00:00",
          "link": "https://arxiv.org/abs/2501.06848v2",
          "size": "21363kb",
          "version": "v2"
        },
        {
          "date": "2025-01-16T03:18:14+00:00",
          "link": "https://arxiv.org/abs/2501.06848v3",
          "size": "25224kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T01:12:12+00:00",
          "link": "https://arxiv.org/abs/2501.06848v4",
          "size": "21364kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T17:52:45+00:00",
          "link": "https://arxiv.org/abs/2501.06848v5",
          "size": "42729kb",
          "version": "v5"
        }
      ],
      "title": "A General Framework for Inference-time Scaling and Steering of Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06848",
        "HTML": "https://arxiv.org/html/2501.06848v5",
        "PDF": "https://arxiv.org/pdf/2501.06848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work presents a framework for steering diffusion models during inference. While it discusses controlling model outputs, it does not focus on training data processing for LLMs in terms of data collection, generation, or quality improvement."
      },
      "tasks": [
        "Protein Design"
      ],
      "repo_urls": [
        "https://github.com/zacharyhorvitz/fk-diffusion-steering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08102",
      "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in text generation, yet their emotional consistency and semantic coherence in social media contexts remain insufficiently understood. This study investigates how LLMs handle emotional content and maintain semantic relationships through continuation and response tasks using two open-source models: Gemma and Llama. By analyzing climate change discussions from Twitter and Reddit, we examine emotional transitions, intensity patterns, and semantic similarity between human-authored and LLM-generated content. Our findings reveal that while both models maintain high semantic coherence, they exhibit distinct emotional patterns: Gemma shows a tendency toward negative emotion amplification, particularly anger, while maintaining certain positive emotions like optimism. Llama demonstrates superior emotional preservation across a broader spectrum of affects. Both models systematically generate responses with attenuated emotional intensity compared to human-authored content and show a bias toward positive emotions in response tasks. Additionally, both models maintain strong semantic similarity with original texts, though performance varies between continuation and response tasks. These findings provide insights into LLMs' emotional and semantic processing capabilities, with implications for their deployment in social media contexts and human-AI interaction design.",
      "authors": [
        "Wenlu Fan",
        "Yuqi Zhu",
        "Chenyang Wang",
        "Bin Wang",
        "Wentao Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T13:19:47+00:00",
          "link": "https://arxiv.org/abs/2501.08102v1",
          "size": "4905kb",
          "version": "v1"
        },
        {
          "date": "2025-01-15T18:10:00+00:00",
          "link": "https://arxiv.org/abs/2501.08102v2",
          "size": "4905kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T10:53:52+00:00",
          "link": "https://arxiv.org/abs/2501.08102v3",
          "size": "6205kb",
          "version": "v3"
        }
      ],
      "title": "Consistency of Responses and Continuations Generated by Large Language Models on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08102",
        "HTML": "https://arxiv.org/html/2501.08102v3",
        "PDF": "https://arxiv.org/pdf/2501.08102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores the semantic and emotional consistency of LLM-generated responses on social media. It does not address training data processing aspects such as data filtering, deduplication, or dataset creation."
      },
      "tasks": [
        "Semantic Similarity",
        "Semantic Textual Similarity",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08208",
      "abstract": "Large Language Models (LLMs) have shown impressive potential in clinical question answering (QA), with Retrieval Augmented Generation (RAG) emerging as a leading approach for ensuring the factual accuracy of model responses. However, current automated RAG metrics perform poorly in clinical and conversational use cases. Using clinical human evaluations of responses is expensive, unscalable, and not conducive to the continuous iterative development of RAG systems. To address these challenges, we introduce ASTRID - an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy (RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is designed to better capture the faithfulness of a model's response to the knowledge base without penalising conversational elements. To validate our triad, we curate a dataset of over 200 real-world patient questions posed to an LLM-based QA agent during surgical follow-up for cataract surgery - the highest volume operation in the world - augmented with clinician-selected questions for emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate that CF can predict human ratings of faithfulness better than existing definitions for conversational use cases. Furthermore, we show that evaluation using our triad consisting of CF, RA, and CR exhibits alignment with clinician assessment for inappropriate, harmful, or unhelpful responses. Finally, using nine different LLMs, we demonstrate that the three metrics can closely agree with human evaluations, highlighting the potential of these metrics for use in LLM-driven automated evaluation pipelines. We also publish the prompts and datasets for these experiments, providing valuable resources for further research and development.",
      "authors": [
        "Mohita Chowdhury",
        "Yajie Vera He",
        "Jared Joselowitz",
        "Aisling Higham",
        "Ernest Lim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T15:46:39+00:00",
          "link": "https://arxiv.org/abs/2501.08208v1",
          "size": "4810kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:31:17+00:00",
          "link": "https://arxiv.org/abs/2501.08208v2",
          "size": "3649kb",
          "version": "v2"
        }
      ],
      "title": "ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08208",
        "HTML": "https://arxiv.org/html/2501.08208v2",
        "PDF": "https://arxiv.org/pdf/2501.08208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces ASTRID, an evaluation framework for clinical QA systems using LLMs. It involves metrics for response evaluation but only implicitly addresses data processing related to evaluation rather than focusing on datasets or processing for LLM training."
      },
      "tasks": [
        "Question Answering",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.09143",
      "abstract": "The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then a SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study.",
      "authors": [
        "Huu-Thinh Do",
        "Franco Blanchini",
        "Stefano Miani",
        "Ionela Prodan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T20:50:15+00:00",
          "link": "https://arxiv.org/abs/2501.09143v1",
          "size": "12934kb",
          "version": "v1"
        },
        {
          "date": "2025-01-19T21:39:29+00:00",
          "link": "https://arxiv.org/abs/2501.09143v2",
          "size": "12878kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T20:02:50+00:00",
          "link": "https://arxiv.org/abs/2501.09143v3",
          "size": "1695kb",
          "version": "v3"
        }
      ],
      "title": "Reducing real-time complexity via sub-control Lyapunov functions: from theory to experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09143",
        "PDF": "https://arxiv.org/pdf/2501.09143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses control Lyapunov functions and feedback mechanisms for drone control, which are unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.10484",
      "abstract": "Recent advances in Large Language Models (LLMs) have enabled human-like responses across various tasks, raising questions about their ethical decision-making capabilities and potential biases. This study investigates protected attributes in LLMs through systematic evaluation of their responses to ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5 Sonnet - we analyzed their decision-making patterns across multiple protected attributes including age, gender, race, appearance, and disability status. Through 11,200 experimental trials involving both single-factor and two-factor protected attribute combinations, we evaluated the models' ethical preferences, sensitivity, stability, and clustering of preferences. Our findings reveal significant protected attributeses in both models, with consistent preferences for certain features (e.g., \"good-looking\") and systematic neglect of others. Notably, while GPT-3.5 Turbo showed stronger preferences aligned with traditional power structures, Claude 3.5 Sonnet demonstrated more diverse protected attribute choices. We also found that ethical sensitivity significantly decreases in more complex scenarios involving multiple protected attributes. Additionally, linguistic referents heavily influence the models' ethical evaluations, as demonstrated by differing responses to racial descriptors (e.g., \"Yellow\" versus \"Asian\"). These findings highlight critical concerns about the potential impact of LLM biases in autonomous decision-making systems and emphasize the need for careful consideration of protected attributes in AI development. Our study contributes to the growing body of research on AI ethics by providing a systematic framework for evaluating protected attributes in LLMs' ethical decision-making capabilities.",
      "authors": [
        "Yile Yan",
        "Yuqi Zhu",
        "Wentao Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T05:20:38+00:00",
          "link": "https://arxiv.org/abs/2501.10484v1",
          "size": "1027kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:09:59+00:00",
          "link": "https://arxiv.org/abs/2501.10484v2",
          "size": "938kb",
          "version": "v2"
        }
      ],
      "title": "Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10484",
        "HTML": "https://arxiv.org/html/2501.10484v2",
        "PDF": "https://arxiv.org/pdf/2501.10484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on ethical decision-making and biases in LLMs like GPT-3.5 Turbo and Claude 3.5 Sonnet, without addressing training data processing."
      },
      "tasks": [
        "Attribute",
        "Decision Making",
        "Ethics"
      ],
      "repo_urls": [
        "https://github.com/arce-star/Bias-in-Decision-Making-for-AI-Ethical-Dilemmas--A-Comparative-Study-of-ChatGPT-and-Claude"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.11264",
      "abstract": "Software engineers spend a significant amount of time reading code during the software development process, especially in the age of large language models (LLMs) that can automatically generate code. However, little is known about the readability of the LLM-generated code and whether it is still important from practitioners' perspectives in this new era. In this paper, we conduct a survey to explore the practitioners' perspectives on code readability in the age of LLMs and investigate the readability of our LLM-based software development agents framework, HULA, by comparing its generated code with human-written code in real-world scenarios. Overall, the findings underscore that (1) readability remains a critical aspect of software development; (2) the readability of our LLM-generated code is comparable to human-written code, fostering the establishment of appropriate trust and driving the broad adoption of our LLM-powered software development platform.",
      "authors": [
        "Wannita Takerngsaksiri",
        "Chakkrit Tantithamthavorn",
        "Micheal Fu",
        "Jirat Pasuksmit",
        "Kun Chen",
        "Ming Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-20T04:11:21+00:00",
          "link": "https://arxiv.org/abs/2501.11264v1",
          "size": "1981kb",
          "version": "v1"
        },
        {
          "date": "2025-05-22T01:29:44+00:00",
          "link": "https://arxiv.org/abs/2501.11264v2",
          "size": "3029kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T10:09:05+00:00",
          "link": "https://arxiv.org/abs/2501.11264v3",
          "size": "2142kb",
          "version": "v3"
        }
      ],
      "title": "Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11264",
        "HTML": "https://arxiv.org/html/2501.11264v3",
        "PDF": "https://arxiv.org/pdf/2501.11264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores code readability of LLM-generated code in an industrial context, but it does not contribute to the training data processing of LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/awsm-research/codereadability-genai"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14068",
      "abstract": "Cage-based deformation is a fundamental problem in geometry processing, where a cage, a user-specified boundary of a region, is used to deform the ambient space of a given mesh. Traditional 3D cages are typically composed of triangles and quads. While quads can represent non-planar regions when their four corners are not coplanar, they form ruled surfaces with straight isoparametric curves, which limits their ability to handle curved and high-curvature deformations. In this work, we extend the cage for curved boundaries using B\\'{e}zier patches, enabling flexible and high-curvature deformations with only a few control points. The higher-order structure of the B\\'{e}zier patch also allows for the creation of a more compact and precise curved cage for the input model. Based on Green's third identity, we derive the Green coordinates for the B\\'{e}zier cage, achieving shape-preserving deformation with smooth surface boundaries. These coordinates are defined based on the vertex positions and normals of the B\\'{e}zier control net. Given that the coordinates are approximately calculated through the Riemann summation, we propose a global projection technique to ensure that the coordinates accurately conform to the linear reproduction property. Experimental results show that our method achieves high performance in handling curved and high-curvature deformations.",
      "authors": [
        "Dong Xiao",
        "Renjie Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T20:06:05+00:00",
          "link": "https://arxiv.org/abs/2501.14068v1",
          "size": "10088kb",
          "version": "v1"
        },
        {
          "date": "2025-05-03T14:10:30+00:00",
          "link": "https://arxiv.org/abs/2501.14068v2",
          "size": "10587kb",
          "version": "v2"
        },
        {
          "date": "2025-05-18T14:23:36+00:00",
          "link": "https://arxiv.org/abs/2501.14068v3",
          "size": "10582kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T10:00:43+00:00",
          "link": "https://arxiv.org/abs/2501.14068v4",
          "size": "8957kb",
          "version": "v4"
        }
      ],
      "title": "Flexible 3D Cage-based Deformation via Green Coordinates on B\\'{e}zier Patches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14068",
        "HTML": "https://arxiv.org/html/2501.14068v4",
        "PDF": "https://arxiv.org/pdf/2501.14068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses geometric deformation using B\\'{e}zier patches, a topic that does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.17328",
      "abstract": "The deployment of deep learning models in critical domains necessitates a balance between high accuracy and interpretability. We introduce SIC, an inherently interpretable neural network that provides local and global explanations of its decision-making process. Leveraging the concept of case-based reasoning, SIC extracts class-representative support vectors from training images, ensuring they capture relevant features while suppressing irrelevant ones. Classification decisions are made by calculating and aggregating similarity scores between these support vectors and the input's latent feature vector. We employ B-Cos transformations, which align model weights with inputs, to yield coherent pixel-level explanations in addition to global explanations of case-based reasoning. We evaluate SIC on three tasks: fine-grained classification on Stanford Dogs and FunnyBirds, multi-label classification on Pascal VOC, and pathology detection on the RSNA dataset. Results indicate that SIC not only achieves competitive accuracy compared to state-of-the-art black-box and inherently interpretable models but also offers insightful explanations verified through practical evaluation on the FunnyBirds benchmark. Our theoretical analysis proves that these explanations fulfill established axioms for explanations. Our findings underscore SIC's potential for applications where understanding model decisions is as critical as the decisions themselves.",
      "authors": [
        "Tom Nuno Wolf and Emre Kavak and Fabian Bongratz and Christian Wachinger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T22:39:03+00:00",
          "link": "https://arxiv.org/abs/2501.17328v1",
          "size": "45490kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T19:36:39+00:00",
          "link": "https://arxiv.org/abs/2501.17328v2",
          "size": "64376kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T09:12:08+00:00",
          "link": "https://arxiv.org/abs/2501.17328v3",
          "size": "64377kb",
          "version": "v3"
        }
      ],
      "title": "SIC: Similarity-Based Interpretable Image Classification with Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17328",
        "HTML": "https://arxiv.org/html/2501.17328v3",
        "PDF": "https://arxiv.org/pdf/2501.17328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces an interpretable neural network for image classification, focusing on interpretability rather than LLM training data processing, creation, or improvement."
      },
      "tasks": [
        "Decision Making",
        "Multi-Label Classification",
        "MUlTI-LABEL-ClASSIFICATION"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.19243",
      "abstract": "Diffusion Transformer (DiT) is a crucial method for content generation. However, it needs a lot of time to sample. Many studies have attempted to use caching to reduce the time consumption of sampling. Existing caching methods accelerate generation by reusing DiT features from the previous time step and skipping calculations in the next, but they tend to locate and cache low-error modules without focusing on reducing caching-induced errors, resulting in a sharp decline in generated content quality when increasing caching intensity. To solve this problem, we propose the \\textbf{E}rror-\\textbf{O}ptimized \\textbf{C}ache (\\textbf{EOC}). This method introduces three key improvements: \\textbf{(1)} Prior knowledge extraction: Extract and process the caching differences; \\textbf{(2)} A judgment method for cache optimization: Determine whether certain caching steps need to be optimized; \\textbf{(3)} Cache optimization: reduce caching errors. Experiments show that this algorithm significantly reduces the error accumulation caused by caching, especially excessive caching. On the ImageNet dataset, without substantially increasing the computational load, this method improves the FID of the generated images when the rule-based model FORA has a caching level of \\textbf{75}\\%, \\textbf{50}\\%, and \\textbf{25}\\%, and the training-based model Learning-to-cache has a caching level of \\textbf{22}\\%. Specifically, the FID values change from 30.454 to 21.690 (\\textbf{28.8}\\%), from 6.857 to 5.821 (\\textbf{15.1}\\%), from 3.870 to 3.692 (\\textbf{4.6}\\%), and from 3.539 to 3.451 (\\textbf{2.5}\\%) respectively. Code is available at https://github.com/qiujx0520/EOC_MM2025.git.",
      "authors": [
        "Junxiang Qiu",
        "Shuo Wang",
        "Jinda Lu",
        "Lin Liu",
        "Houcheng Jiang",
        "Xingyu Zhu",
        "Yanbin Hao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T15:58:15+00:00",
          "link": "https://arxiv.org/abs/2501.19243v1",
          "size": "2951kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T19:48:41+00:00",
          "link": "https://arxiv.org/abs/2501.19243v2",
          "size": "2831kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T01:49:36+00:00",
          "link": "https://arxiv.org/abs/2501.19243v3",
          "size": "2376kb",
          "version": "v3"
        }
      ],
      "title": "Accelerating Diffusion Transformer via Error-Optimized Cache",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19243",
        "HTML": "https://arxiv.org/html/2501.19243v3",
        "PDF": "https://arxiv.org/pdf/2501.19243"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research enhances a content generation method (Diffusion Transformer) through caching optimization, unrelated to LLM training data processing, focusing instead on computational efficiency in content generation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.00691",
      "abstract": "Recent advances in mathematical problem-solving with language models (LMs) integrate chain-of-thought (CoT) reasoning and code execution to harness their complementary strengths. However, existing hybrid frameworks exhibit a critical limitation: they depend on externally dictated instructions or rigid code-integration templates, lacking metacognitive awareness -- the capacity to dynamically evaluate intrinsic capabilities and autonomously determine when and how to integrate tools. This rigidity motivates our study of autonomous code integration, enabling models to adapt tool-usage strategies as their reasoning abilities evolve during training.\n  While reinforcement learning (RL) shows promise for boosting LLM reasoning at scale (e.g., DeepSeek-R1), we demonstrate its inefficiency in learning autonomous code integration due to inadequate exploration of the vast combinatorial space of CoT-code interleaving patterns. To address this challenge, we propose a novel Expectation-Maximization (EM) framework that synergizes structured exploration (E-step) with off-policy RL optimization (M-step), creating a self-reinforcing cycle between metacognitive tool-use decisions and evolving capabilities. Experiments reveal our method achieves superior results through improved exploration. Notably, our 7B model improves over 11% on MATH500 and 9.4% on AIME without o1-like CoT.",
      "authors": [
        "Haozhe Wang",
        "Long Li",
        "Chao Qu",
        "Fengming Zhu",
        "Weidi Xu",
        "Wei Chu",
        "Fangzhen Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-02T06:32:23+00:00",
          "link": "https://arxiv.org/abs/2502.00691v1",
          "size": "3373kb",
          "version": "v1"
        },
        {
          "date": "2025-02-16T07:18:23+00:00",
          "link": "https://arxiv.org/abs/2502.00691v2",
          "size": "627kb",
          "version": "v2"
        },
        {
          "date": "2025-05-22T05:17:03+00:00",
          "link": "https://arxiv.org/abs/2502.00691v3",
          "size": "627kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T07:40:22+00:00",
          "link": "https://arxiv.org/abs/2502.00691v4",
          "size": "620kb",
          "version": "v4"
        }
      ],
      "title": "To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00691",
        "HTML": "https://arxiv.org/html/2502.00691v4",
        "PDF": "https://arxiv.org/pdf/2502.00691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on autonomous code integration for mathematical problem-solving in LLMs, emphasizing reinforcement learning and expectation-maximization for improving reasoning abilities. It does not address LLM training data processing."
      },
      "tasks": [
        "Math"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01312",
      "abstract": "Category-level object pose estimation aims to recover the rotation, translation and size of unseen instances within predefined categories. In this task, deep neural network-based methods have demonstrated remarkable performance. However, previous studies show they suffer from spurious correlations raised by \"unclean\" confounders in models, hindering their performance on novel instances with significant variations. To address this issue, we propose CleanPose, a novel approach integrating causal learning and knowledge distillation to enhance category-level pose estimation. To mitigate the negative effect of unobserved confounders, we develop a causal inference module based on front-door adjustment, which promotes unbiased estimation by reducing potential spurious correlations. Additionally, to further improve generalization ability, we devise a residual-based knowledge distillation method that has proven effective in providing comprehensive category information guidance. Extensive experiments across multiple benchmarks (REAL275, CAMERA25 and HouseCat6D) hightlight the superiority of proposed CleanPose over state-of-the-art methods. Code will be available at https://github.com/chrislin0621/CleanPose.",
      "authors": [
        "Xiao Lin",
        "Yun Peng",
        "Liuyi Wang",
        "Xianyou Zhong",
        "Minghao Zhu",
        "Jingwei Yang",
        "Yi Feng",
        "Chengju Liu",
        "Qijun Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T12:41:36+00:00",
          "link": "https://arxiv.org/abs/2502.01312v1",
          "size": "2019kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:37:35+00:00",
          "link": "https://arxiv.org/abs/2502.01312v2",
          "size": "1319kb",
          "version": "v2"
        }
      ],
      "title": "CleanPose: Category-Level Object Pose Estimation via Causal Learning and Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01312",
        "HTML": "https://arxiv.org/html/2502.01312v2",
        "PDF": "https://arxiv.org/pdf/2502.01312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about object pose estimation using causal learning and knowledge distillation. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.02145",
      "abstract": "Ensuring the safety of autonomous vehicles requires virtual scenario-based testing, which depends on the robust evaluation and generation of safety-critical scenarios. So far, researchers have used scenario-based testing frameworks that rely heavily on handcrafted scenarios as safety metrics. To reduce the effort of human interpretation and overcome the limited scalability of these approaches, we combine Large Language Models (LLMs) with structured scenario parsing and prompt engineering to automatically evaluate and generate safety-critical driving scenarios. We introduce Cartesian and Ego-centric prompt strategies for scenario evaluation, and an adversarial generation module that modifies trajectories of risk-inducing vehicles (ego-attackers) to create critical scenarios. We validate our approach using a 2D simulation framework and multiple pre-trained LLMs. The results show that the evaluation module effectively detects collision scenarios and infers scenario safety. Meanwhile, the new generation module identifies high-risk agents and synthesizes realistic, safety-critical scenarios. We conclude that an LLM equipped with domain-informed prompting techniques can effectively evaluate and generate safety-critical driving scenarios, reducing dependence on handcrafted metrics. We release our open-source code and scenarios at: https://github.com/TUM-AVS/From-Words-to-Collisions.",
      "authors": [
        "Yuan Gao",
        "Mattia Piccinini",
        "Korbinian Moller",
        "Amr Alanwar",
        "Johannes Betz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T09:19:13+00:00",
          "link": "https://arxiv.org/abs/2502.02145v1",
          "size": "2051kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T21:23:20+00:00",
          "link": "https://arxiv.org/abs/2502.02145v2",
          "size": "3063kb",
          "version": "v2"
        },
        {
          "date": "2025-05-21T07:47:01+00:00",
          "link": "https://arxiv.org/abs/2502.02145v3",
          "size": "3063kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T08:39:33+00:00",
          "link": "https://arxiv.org/abs/2502.02145v4",
          "size": "2710kb",
          "version": "v4"
        }
      ],
      "title": "From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02145",
        "HTML": "https://arxiv.org/html/2502.02145v4",
        "PDF": "https://arxiv.org/pdf/2502.02145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes using LLMs to evaluate and generate safety-critical driving scenarios. While it involves LLMs, the focus is on prompt engineering and scenario generation rather than training data processing for LLMs."
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Motion Planning",
        "Prompt Engineering"
      ],
      "repo_urls": [
        "https://github.com/tum-avs/from-words-to-collisions",
        "https://github.com/yuangao-tum/riskaware-scenario-analyse"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02592",
      "abstract": "In general, there is a mismatch between a finite element model of a structure and its real behaviour. In aeronautics, this mismatch must be small because finite element models are a fundamental part of the development of an aircraft and of increasing importance with the trend to more flexible wings in modern designs. Finite element model updating can be computationally expensive for complex structures and surrogate models can be employed to reduce the computational burden. A novel approach for finite element model updating, namely assembly-like, is proposed and validated using real experimental data. The assembly-like model updating framework implies that the model is updated as parts are assembled. Benchmarking against the classical global, or one-shot, approach demonstrates that the proposed method is more computationally efficient since it takes 20% fewer iterations to obtain convergence, also using fewer parameters for the model evaluations. Despite the increase in computational performance, the new approach retains the fidelity of the global approach.",
      "authors": [
        "Gabriele Dessena",
        "Alessandro Pontillo",
        "Dmitry I. Ignatyev",
        "James F. Whidborne",
        "Luca Zanotti Fragonara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T15:12:05+00:00",
          "link": "https://arxiv.org/abs/2502.02592v1",
          "size": "5458kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:33:22+00:00",
          "link": "https://arxiv.org/abs/2502.02592v2",
          "size": "5447kb",
          "version": "v2"
        }
      ],
      "title": "A Paradigm Shift to Assembly-like Finite Element Model Updating",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02592",
        "HTML": "https://arxiv.org/html/2502.02592v2",
        "PDF": "https://arxiv.org/pdf/2502.02592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for finite element model updating in aeronautics. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.03304",
      "abstract": "Large language models (LLMs) excel across various tasks, but standard first-order (FO) fine-tuning demands considerable memory, significantly limiting real-world deployment. Recently, zeroth-order (ZO) optimization stood out as a promising memory-efficient training paradigm, avoiding backward passes and relying solely on forward passes for gradient estimation, making it attractive for resource-constrained scenarios. However, ZO method lags far behind FO method in both convergence speed and accuracy. To bridge the gap, we introduce a novel layer-wise divergence analysis that uncovers the distinct update pattern of FO and ZO optimization. Aiming to resemble the learning capacity of FO method from the findings, we propose Divergence-driven Zeroth-Order (DiZO) optimization. DiZO conducts divergence-driven layer adaptation by incorporating projections to ZO updates, generating diverse-magnitude updates precisely scaled to layer-wise individual optimization needs. Our results demonstrate that DiZO significantly reduces the needed iterations for convergence without sacrificing throughput, cutting training GPU hours by up to 48% on various datasets. Moreover, DiZO consistently outperforms the representative ZO baselines in fine-tuning RoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some cases, even surpasses memory-intensive FO fine-tuning. Our code is released at https://anonymous.4open.science/r/DiZO-E86D.",
      "authors": [
        "Qitao Tan",
        "Jun Liu",
        "Zheng Zhan",
        "Caiwei Ding",
        "Yanzhi Wang",
        "Xiaolong Ma",
        "Jaewoo Lee",
        "Jin Lu",
        "Geng Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T16:03:17+00:00",
          "link": "https://arxiv.org/abs/2502.03304v1",
          "size": "4349kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T17:50:04+00:00",
          "link": "https://arxiv.org/abs/2502.03304v2",
          "size": "4750kb",
          "version": "v2"
        }
      ],
      "title": "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03304",
        "HTML": "https://arxiv.org/html/2502.03304v2",
        "PDF": "https://arxiv.org/pdf/2502.03304"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a zeroth-order optimization method (DiZO) for memory-efficient LLM fine-tuning, focusing on optimization rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.03876",
      "abstract": "Anomaly detection based on 3D point cloud data is an important research problem and receives more and more attention recently. Untrained anomaly detection based on only one sample is an emerging research problem motivated by real manufacturing industries such as personalized manufacturing where only one sample can be collected without any additional labels and historical datasets. Identifying anomalies accurately based on one 3D point cloud sample is a critical challenge in both industrial applications and the field of machine learning. This paper aims to provide a formal definition of the untrained anomaly detection problem based on 3D point cloud data, discuss the differences between untrained anomaly detection and current unsupervised anomaly detection problems. Unlike trained unsupervised learning, untrained unsupervised learning does not rely on any data, including unlabeled data. Instead, they leverage prior knowledge about the surfaces and anomalies.\n  We propose three complementary methodological frameworks: the Latent Variable Inference Framework that employs probabilistic modeling to distinguish anomalies; the Decomposition Framework that separates point clouds into reference, anomaly, and noise components through sparse learning; and the Local Geometry Framework that leverages neighborhood information for anomaly identification. Experimental results demonstrate that untrained methods achieve competitive detection performance while offering significant computational advantages, demonstrating up to a 15-fold increase in execution speed. The proposed methods provide viable solutions for scenarios with extreme data scarcity, addressing critical challenges in personalized manufacturing and healthcare applications where collecting multiple samples or historical data is infeasible.",
      "authors": [
        "Juan Du",
        "Dongheng Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T08:46:59+00:00",
          "link": "https://arxiv.org/abs/2502.03876v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T02:04:26+00:00",
          "link": "https://arxiv.org/abs/2502.03876v2",
          "size": "1428kb",
          "version": "v2"
        }
      ],
      "title": "Position: Untrained Machine Learning for Anomaly Detection by using 3D Point Cloud Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03876",
        "HTML": "https://arxiv.org/html/2502.03876v2",
        "PDF": "https://arxiv.org/pdf/2502.03876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on anomaly detection using untrained methods for 3D point cloud data, which is unrelated to LLM training data processing as it does not discuss pretraining, fine-tuning, or any data engineering operations applicable to LLMs."
      },
      "tasks": [
        "Anomaly Detection",
        "Position",
        "Unsupervised Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04589",
      "abstract": "In this paper, we present a novel parallel augmented subspace method and build a package Parallel Augmented Subspace Eigensolver (PASE) for solving large scale eigenvalue problems by the massively parallel finite element discretization. Based on the augmented subspace, solving high dimensional eigenvalue problems can be transformed to solving the corresponding linear equations and low dimensional eigenvalue problems on the augmented subspace. Thus the complexity of solving the eigenvalue problems by augmented subspace method will be comparable to that of solving the same dimensinal linear equations. In order to improve the scalability and efficiency, we also present some implementing techniques for the parallel augmented subspace method. Based on parallel augmented subspace method and the concerned implementing techniques, a package PASE is built for solving large scale eigenvalue problems. Some numerical examples are provided to validate the efficiency and scalability of the proposed numerical methods.",
      "authors": [
        "Yangfei Liao",
        "Haochen Liu",
        "Hehu Xie and Zijing Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T00:49:13+00:00",
          "link": "https://arxiv.org/abs/2502.04589v1",
          "size": "59kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T23:29:24+00:00",
          "link": "https://arxiv.org/abs/2502.04589v2",
          "size": "59kb",
          "version": "v2"
        }
      ],
      "title": "PASE: A Massively Parallel Augmented Subspace Eigensolver for Large Scale Eigenvalue Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04589",
        "HTML": "https://arxiv.org/html/2502.04589v2",
        "PDF": "https://arxiv.org/pdf/2502.04589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a parallel algorithm for solving large scale eigenvalue problems and does not address any aspects of LLM training data processing or related data operations."
      },
      "repo_urls": [
        "https://gitlab.com/xiegroup/pase1.0"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06158",
      "abstract": "In this paper, we study the Schr\\\"{o}dinger equation in the semiclassical regime and with multiscale potential function. We develop the so-called constraint energy minimization generalized multiscale finite element method (CEM-GMsFEM), in the framework of Crank-Nicolson (CN) discretization in time. The localized multiscale basis functions are constructed by addressing the spectral problem and a constrained energy minimization problem related to the Hamiltonian norm. A first-order convergence in the energy norm and second-order convergence in the $L^2$ norm for our numerical scheme are shown, with a relation between oversampling number in the CEM-GMsFEM method, spatial mesh size and the semiclassical parameter provided. Furthermore, we demonstrate the convergence of the proposed Crank-Nicolson CEM-GMsFEM scheme. The convergence requires $H/\\sqrt{\\Lambda}=O(\\varepsilon^{\\frac{5}{4}})$, $\\Delta t=O(\\varepsilon^{\\frac{5}{4}})$ if $\\varepsilon\\leq \\delta$; while if $\\delta<\\varepsilon$, the convergence requires $H/\\sqrt{\\Lambda}=O(\\varepsilon^{\\frac{1}{4}}\\delta)$, $\\Delta t=O(\\frac{\\delta^2}{\\varepsilon^{3/4}})$ (where $H$ represents the maximum diameter of coarse elements, $\\Lambda$ is the minimal eigenvalue associated with the eigenvector not included in the auxiliary space, $\\Delta t$ is the time step, $0 < \\varepsilon\\ll 1$ is the Planck constant and $\\delta$ describes the multiscale structure of the potential).Several numerical examples including 1D and 2D in space, with high-contrast potential are conducted to demonstrate the efficiency and accuracy of our proposed scheme.",
      "authors": [
        "Xingguang Jin",
        "Liu Liu",
        "Xiang Zhong",
        "Eric T. Chung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T05:06:57+00:00",
          "link": "https://arxiv.org/abs/2502.06158v1",
          "size": "1710kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T02:54:46+00:00",
          "link": "https://arxiv.org/abs/2502.06158v2",
          "size": "1131kb",
          "version": "v2"
        }
      ],
      "title": "Efficient numerical method for the Schr\\\"{o}dinger equation with high-contrast potentials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06158",
        "HTML": "https://arxiv.org/html/2502.06158v2",
        "PDF": "https://arxiv.org/pdf/2502.06158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on numerical methods for the Schr\u00f6dinger equation and does not relate to LLM training data processing or data engineering operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06358",
      "abstract": "Prompting has emerged as the dominant paradigm for adapting large, pre-trained transformer-based models to downstream tasks. The Prompting Decision Transformer (PDT) enables large-scale, multi-task offline Reinforcement Learning (RL) pre-training by leveraging stochastic trajectory prompts to identify the target task. However, these prompts are sampled uniformly from expert demonstrations, overlooking a critical limitation: not all prompts are equally informative for differentiating between tasks. This limits generalization and adaptation, especially in low-data or open-world settings where sample efficiency is crucial. To address this issue, we propose a lightweight, inference-time, bandit-based prompt-tuning framework. The bandit explores and optimizes trajectory prompt selection to enhance task performance, while avoiding costly fine-tuning of the transformer backbone. Our experiments indicate not only clear performance gains due to bandit-based prompt-tuning, but also better sample complexity, scalability, and prompt space exploration compared to prompt-tuning baselines. These results highlights the importance of adaptive prompt selection mechanisms for efficient generalization in offline multi-task RL.",
      "authors": [
        "Finn Rietz",
        "Oleg Smirnov",
        "Sara Karimi",
        "Lele Cao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T11:20:10+00:00",
          "link": "https://arxiv.org/abs/2502.06358v1",
          "size": "3512kb",
          "version": "v1"
        },
        {
          "date": "2025-02-11T10:54:40+00:00",
          "link": "https://arxiv.org/abs/2502.06358v2",
          "size": "3512kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T08:29:35+00:00",
          "link": "https://arxiv.org/abs/2502.06358v3",
          "size": "3508kb",
          "version": "v3"
        }
      ],
      "title": "Prompt-Tuning Bandits: Enabling Few-Shot Generalization for Efficient Multi-Task Offline RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06358",
        "HTML": "https://arxiv.org/html/2502.06358v3",
        "PDF": "https://arxiv.org/pdf/2502.06358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses prompt-tuning for offline RL with large models, mentioning generalization and sample efficiency. However, it primarily focuses on RL task performance rather than making a significant contribution to LLM training data processing techniques."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.06683",
      "abstract": "How much data is needed to optimally schedule distributed energy resources (DERs)? Does the distribution system operator (DSO) have to know load demands at each bus of the feeder to solve an optimal power flow (OPF)? This work exploits redundancies in OPF's structure and data to minimize the communication of such a data deluge, and explores the trade-off between data compression and the grid's performance. We propose an OPF data distillation framework involving two steps: The DSO first collects OPF data from only a subset of nodes. It subsequently reconstructs the complete OPF data from the partial ones, and feeds them into the OPF solver. Selecting and reconstructing OPF data may be performed to maximize the fidelity of the reconstructed data or the associated OPF solutions. Under the first objective, OPF data distillation is posed as a sparsity-regularized convex problem. Under the second objective, it is posed as a sparsity-regularized bilevel program. Both problems are solved using proximal gradient algorithms. The second objective is superior in approximating OPF solutions at the expense of increased complexity. Numerical tests show that it enhances the fidelity and feasibility of the reconstructed OPF solutions, which can be approximated reasonably well even from partial data.",
      "authors": [
        "Vassilis Kekatos",
        "Ridley Annin",
        "Manish K. Singh",
        "Junjie Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T17:11:13+00:00",
          "link": "https://arxiv.org/abs/2502.06683v1",
          "size": "800kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:43:08+00:00",
          "link": "https://arxiv.org/abs/2502.06683v2",
          "size": "901kb",
          "version": "v2"
        }
      ],
      "title": "Solving Optimal Power Flow on a Data-Budget: Feature Selection on Smart Meter Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06683",
        "HTML": "https://arxiv.org/html/2502.06683v2",
        "PDF": "https://arxiv.org/pdf/2502.06683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores data reduction techniques for optimal power flow problems, which are not related to LLM training data processing or the creation of datasets for language models."
      },
      "tasks": [
        "Data Compression",
        "feature selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.11887",
      "abstract": "Simulations are highly valuable in marine robotics, offering a cost-effective and controlled environment for testing in the challenging conditions of underwater and surface operations. Given the high costs and logistical difficulties of real-world trials, simulators capable of capturing the operational conditions of subsea environments have become key in developing and refining algorithms for remotely-operated and autonomous underwater vehicles. This paper highlights recent enhancements to the Stonefish simulator, an advanced open-source platform supporting development and testing of marine robotics solutions. Key updates include a suite of additional sensors, such as an event-based camera, a thermal camera, and an optical flow camera, as well as, visual light communication, support for tethered operations, improved thruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy. These developments and an automated annotation tool significantly bolster Stonefish's role in marine robotics research, especially in the field of machine learning, where training data with a known ground truth is hard or impossible to collect.",
      "authors": [
        "Michele Grimaldi",
        "Patryk Cieslak",
        "Eduardo Ochoa",
        "Vibhav Bharti",
        "Hayat Rajani",
        "Ignacio Carlucho",
        "Maria Koskinopoulou",
        "Yvan R. Petillot and Nuno Gracias"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T15:13:41+00:00",
          "link": "https://arxiv.org/abs/2502.11887v1",
          "size": "14451kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:58:39+00:00",
          "link": "https://arxiv.org/abs/2502.11887v2",
          "size": "4093kb",
          "version": "v2"
        }
      ],
      "title": "Stonefish: Supporting Machine Learning Research in Marine Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11887",
        "HTML": "https://arxiv.org/html/2502.11887v2",
        "PDF": "https://arxiv.org/pdf/2502.11887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancements to the Stonefish simulator for marine robotics, unrelated to LLM training data processing, focusing on machine learning applications in marine environments instead."
      },
      "tasks": [
        "Optical Flow Estimation"
      ],
      "repo_urls": [
        "https://github.com/patrykcieslak/stonefish"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12057",
      "abstract": "The field of cultural NLP has recently experienced rapid growth, driven by a pressing need to ensure that language technologies are effective and safe across a pluralistic user base. This work has largely progressed without a shared conception of culture, instead choosing to rely on a wide array of cultural proxies. However, this leads to a number of recurring limitations: coarse national boundaries fail to capture nuanced differences that lay within them, limited coverage restricts datasets to only a subset of usually highly-represented cultures, and a lack of dynamicity results in static cultural benchmarks that do not change as culture evolves. In this position paper, we argue that these methodological limitations are symptomatic of a theoretical gap. We draw on a well-developed theory of culture from sociocultural linguistics to fill this gap by 1) demonstrating in a case study how it can clarify methodological constraints and affordances, 2) offering theoretically-motivated paths forward to achieving cultural competence, and 3) arguing that localization is a more useful framing for the goals of much current work in cultural NLP.",
      "authors": [
        "Naitian Zhou",
        "David Bamman and Isaac L. Bleaman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T17:25:11+00:00",
          "link": "https://arxiv.org/abs/2502.12057v1",
          "size": "46kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T22:26:34+00:00",
          "link": "https://arxiv.org/abs/2502.12057v2",
          "size": "49kb",
          "version": "v2"
        }
      ],
      "title": "Culture is Not Trivia: Sociocultural Theory for Cultural NLP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12057",
        "HTML": "https://arxiv.org/html/2502.12057v2",
        "PDF": "https://arxiv.org/pdf/2502.12057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses theoretical frameworks for cultural NLP but does not directly contribute to LLM training data processing. It focuses more on methodological and theoretical discussions rather than specific data processing techniques."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.12272",
      "abstract": "Reinforcement learning is now widely adopted as the final stage of large language model training, especially for reasoning-style tasks such as maths problems. Typically, models attempt each question many times during a single training step and attempt to learn from their successes and failures. However, we demonstrate that throughout training with two popular algorithms (PPO and VinePPO) on two widely used datasets, many questions are either solved by all attempts - meaning they are already learned - or by none - providing no meaningful training signal. To address this, we adapt a method from the reinforcement learning literature - sampling for learnability - and apply it to the reinforcement learning stage of LLM training. Our curriculum prioritises questions with high variance of success, i.e. those where the agent sometimes succeeds, but not always. Our findings demonstrate that this curriculum consistently boosts training performance across multiple algorithms and datasets, paving the way for more efficient and effective reinforcement learning with LLMs.",
      "authors": [
        "Thomas Foster",
        "Anya Sims",
        "Johannes Forkel",
        "Mattie Fellows",
        "Jakob Foerster"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T19:16:37+00:00",
          "link": "https://arxiv.org/abs/2502.12272v1",
          "size": "601kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T23:01:25+00:00",
          "link": "https://arxiv.org/abs/2502.12272v2",
          "size": "597kb",
          "version": "v2"
        },
        {
          "date": "2025-02-24T18:15:02+00:00",
          "link": "https://arxiv.org/abs/2502.12272v3",
          "size": "597kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T10:34:26+00:00",
          "link": "https://arxiv.org/abs/2502.12272v4",
          "size": "14030kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T17:21:27+00:00",
          "link": "https://arxiv.org/abs/2502.12272v5",
          "size": "14030kb",
          "version": "v5"
        }
      ],
      "title": "Learning to Reason at the Frontier of Learnability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12272",
        "PDF": "https://arxiv.org/pdf/2502.12272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a reinforcement learning strategy for improving LLM performance but primarily addresses model training methodologies rather than directly contributing to training data processing techniques."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12751",
      "abstract": "Logic synthesis, a critical stage in electronic design automation (EDA), optimizes gate-level circuits to minimize power consumption and area occupancy in integrated circuits (ICs). Traditional logic synthesis tools rely on human-designed heuristics, often yielding suboptimal results. Although differentiable architecture search (DAS) has shown promise in generating circuits from truth tables, it faces challenges such as high computational complexity, convergence to local optima, and extensive hyperparameter tuning. Consequently, we propose a novel approach integrating conditional generative models with DAS for circuit generation. Our approach first introduces CircuitVQ, a circuit tokenizer trained based on our Circuit AutoEncoder We then develop CircuitAR, a masked autoregressive model leveraging CircuitVQ as the tokenizer. CircuitAR can generate preliminary circuit structures from truth tables, which guide DAS in producing functionally equivalent circuits. Notably, we observe the scalability and emergent capability in generating complex circuit structures of our CircuitAR models. Extensive experiments also show the superior performance of our method. This research bridges the gap between probabilistic generative models and precise circuit generation, offering a robust solution for logic synthesis.",
      "authors": [
        "Haoyuan Wu",
        "Haisheng Zheng",
        "Shoubo Hu",
        "Zhuolun He",
        "Bei Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T11:13:03+00:00",
          "link": "https://arxiv.org/abs/2502.12751v1",
          "size": "555kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:40:40+00:00",
          "link": "https://arxiv.org/abs/2502.12751v2",
          "size": "531kb",
          "version": "v2"
        }
      ],
      "title": "Architect of the Bits World: Masked Autoregressive Modeling for Circuit Generation Guided by Truth Table",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12751",
        "HTML": "https://arxiv.org/html/2502.12751v2",
        "PDF": "https://arxiv.org/pdf/2502.12751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on circuit generation using generative models in electronics design automation, a topic unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12777",
      "abstract": "Link prediction (LP) is an important problem in network science and machine learning research. The state-of-the-art LP methods are usually evaluated in a uniform setup, ignoring several factors associated with the data and application specific needs. We identify a number of such factors, such as, network-type, problem-type, geodesic distance between the end nodes and its distribution over the classes, nature and applicability of LP methods, class imbalance and its impact on early retrieval, evaluation metric, etc., and present an experimental setup which allows us to evaluate LP methods in a rigorous and controlled manner. We perform extensive experiments with a variety of LP methods over real network datasets in this controlled setup, and gather valuable insights on the interactions of these factors with the performance of LP through an array of carefully designed hypotheses. Following the insights, we provide recommendations to be followed as best practice for evaluating LP methods.",
      "authors": [
        "Bhargavi Kalyani I",
        "A Rama Prasad Mathi",
        "Niladri Sett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T11:36:59+00:00",
          "link": "https://arxiv.org/abs/2502.12777v1",
          "size": "487kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T06:28:38+00:00",
          "link": "https://arxiv.org/abs/2502.12777v2",
          "size": "489kb",
          "version": "v2"
        },
        {
          "date": "2025-06-24T08:08:51+00:00",
          "link": "https://arxiv.org/abs/2502.12777v3",
          "size": "118kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T05:12:58+00:00",
          "link": "https://arxiv.org/abs/2502.12777v4",
          "size": "117kb",
          "version": "v4"
        }
      ],
      "title": "Evaluating link prediction: New perspectives and recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12777",
        "HTML": "https://arxiv.org/html/2502.12777v4",
        "PDF": "https://arxiv.org/pdf/2502.12777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on link prediction within network science, involving evaluation techniques and insights drawn from experiments on diverse LP methods. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Link Prediction",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13246",
      "abstract": "Metaphor, discussing one concept in terms of another, is abundant in politics and can shape how people understand important issues. We develop a computational approach to measure metaphorical language, focusing on immigration discourse on social media. Grounded in qualitative social science research, we identify seven concepts evoked in immigration discourse (e.g. \"water\" or \"vermin\"). We propose and evaluate a novel technique that leverages both word-level and document-level signals to measure metaphor with respect to these concepts. We then study the relationship between metaphor, political ideology, and user engagement in 400K US tweets about immigration. While conservatives tend to use dehumanizing metaphors more than liberals, this effect varies widely across concepts. Moreover, creature-related metaphor is associated with more retweets, especially for liberal authors. Our work highlights the potential for computational methods to complement qualitative approaches in understanding subtle and implicit language in political discourse.",
      "authors": [
        "Julia Mendelsohn and Ceren Budak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T19:19:01+00:00",
          "link": "https://arxiv.org/abs/2502.13246v1",
          "size": "356kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T00:33:19+00:00",
          "link": "https://arxiv.org/abs/2502.13246v2",
          "size": "313kb",
          "version": "v2"
        }
      ],
      "title": "When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13246",
        "HTML": "https://arxiv.org/html/2502.13246v2",
        "PDF": "https://arxiv.org/pdf/2502.13246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses large language models in the context of analyzing immigration discourse metaphors, its primary focus is on metaphor measurement and political discourse, not directly on training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.13445",
      "abstract": "This paper studies the thermo-poroelasticity model. By introducing an intermediate variable, we transform the original three-field model into a four-field model. Building upon this four-field model, we present both a coupled finite element method and a decoupled iterative finite element method. We prove the stability and optimal convergence of the coupled finite element method. Furthermore, we establish the convergence of the decoupled iterative method. This paper focuses primarily on analyzing the iterative decoupled algorithm. It demonstrates that the algorithm's convergence does not require any additional assumptions about physical parameters or stabilization parameters. Numerical results are provided to demonstrate the effectiveness and theoretical validity of these new methods.",
      "authors": [
        "Mingchao Cai and Jingzhi Li and Ziliang Li and Qiang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T05:44:38+00:00",
          "link": "https://arxiv.org/abs/2502.13445v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:19:19+00:00",
          "link": "https://arxiv.org/abs/2502.13445v2",
          "size": "27kb",
          "version": "v2"
        }
      ],
      "title": "An Efficient Iterative Decoupling Method for Thermo-Poroelasticity Based on a Four-Field Formulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13445",
        "HTML": "https://arxiv.org/html/2502.13445v2",
        "PDF": "https://arxiv.org/pdf/2502.13445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses methods for thermo-poroelasticity models in applied mathematics, focusing on finite element methods and iterative algorithms, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.13962",
      "abstract": "Scaling the test-time compute of large language models has demonstrated impressive performance on reasoning benchmarks. However, existing evaluations of test-time scaling make the strong assumption that a reasoning system should always give an answer to any question provided. This overlooks concerns about whether a model is confident in its answer, and whether it is appropriate to always provide a response. To address these concerns, we extract confidence scores during reasoning for thresholding model responses. We find that increasing compute budget at inference time not only helps models answer more questions correctly, but also increases confidence in correct responses. We then extend the current paradigm of zero-risk responses during evaluation by considering settings with non-zero levels of response risk, and suggest a recipe for reporting evaluations under these settings.",
      "authors": [
        "William Jurayj",
        "Jeffrey Cheng",
        "Benjamin Van Durme"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T18:58:31+00:00",
          "link": "https://arxiv.org/abs/2502.13962v1",
          "size": "3432kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T01:01:54+00:00",
          "link": "https://arxiv.org/abs/2502.13962v2",
          "size": "6235kb",
          "version": "v2"
        }
      ],
      "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13962",
        "HTML": "https://arxiv.org/html/2502.13962v2",
        "PDF": "https://arxiv.org/pdf/2502.13962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on scaling test-time computations for improving reasoning and confidence in question answering with large language models, rather than processing training or fine-tuning data."
      },
      "tasks": [
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14131",
      "abstract": "We study the problem of estimating Dynamic Discrete Choice (DDC) models, also known as offline Maximum Entropy-Regularized Inverse Reinforcement Learning (offline MaxEnt-IRL) in machine learning. The objective is to recover reward or $Q^*$ functions that govern agent behavior from offline behavior data. In this paper, we propose a globally convergent gradient-based method for solving these problems without the restrictive assumption of linearly parameterized rewards. The novelty of our approach lies in introducing the Empirical Risk Minimization (ERM) based IRL/DDC framework, which circumvents the need for explicit state transition probability estimation in the Bellman equation. Furthermore, our method is compatible with non-parametric estimation techniques such as neural networks. Therefore, the proposed method has the potential to be scaled to high-dimensional, infinite state spaces. A key theoretical insight underlying our approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL) condition -- a property that, while weaker than strong convexity, is sufficient to ensure fast global convergence guarantees. Through a series of synthetic experiments, we demonstrate that our approach consistently outperforms benchmark methods and state-of-the-art alternatives.",
      "authors": [
        "Enoch H. Kang",
        "Hema Yoganarasimhan",
        "Lalit Jain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Econometrics (econ.EM)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T22:22:20+00:00",
          "link": "https://arxiv.org/abs/2502.14131v1",
          "size": "413kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T21:42:24+00:00",
          "link": "https://arxiv.org/abs/2502.14131v2",
          "size": "374kb",
          "version": "v2"
        },
        {
          "date": "2025-05-06T17:12:37+00:00",
          "link": "https://arxiv.org/abs/2502.14131v3",
          "size": "369kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T01:39:40+00:00",
          "link": "https://arxiv.org/abs/2502.14131v4",
          "size": "381kb",
          "version": "v4"
        }
      ],
      "title": "An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14131",
        "HTML": "https://arxiv.org/html/2502.14131v4",
        "PDF": "https://arxiv.org/pdf/2502.14131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on dynamic discrete choice models and offline inverse reinforcement learning, involving reward estimation and not related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.15761",
      "abstract": "The deployment of large language models (LLMs) on extended reality (XR) devices has great potential to advance the field of human-AI interaction. In the case of direct, on-device model inference, selecting the appropriate model and device for specific tasks remains challenging. In this paper, we present AIvaluateXR, a comprehensive evaluation framework for benchmarking LLMs running on XR devices. To demonstrate the framework, we deploy 17 selected LLMs across four XR platforms: Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and Apple Vision Pro, and conduct an extensive evaluation. Our experimental setup measures four key metrics: performance consistency, processing speed, memory usage, and battery consumption. For each of the 68 model-device pairs, we assess performance under varying string lengths, batch sizes, and thread counts, analyzing the trade-offs for real-time XR applications. We propose a unified evaluation method based on the 3D Pareto Optimality theory to select the optimal device-model pairs from quality and speed objectives. Additionally, we compare the efficiency of on-device LLMs with client-server and cloud-based setups, and evaluate their accuracy on two interactive tasks. We believe our findings offer valuable insight to guide future optimization efforts for LLM deployment on XR devices. Our evaluation method can be used as standard groundwork for further research and development in this emerging field. The source code and supplementary materials are available at: www.nanovis.org/AIvaluateXR.html",
      "authors": [
        "Dawar Khan and Xinyu Liu and Omar Mena and Donggang Jia and Alexandre Kouyoumdjian and Ivan Viola"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T20:55:48+00:00",
          "link": "https://arxiv.org/abs/2502.15761v1",
          "size": "22982kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:10:07+00:00",
          "link": "https://arxiv.org/abs/2502.15761v2",
          "size": "18832kb",
          "version": "v2"
        }
      ],
      "title": "AIvaluateXR: An Evaluation Framework for on-Device AI in XR with Benchmarking Results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15761",
        "HTML": "https://arxiv.org/html/2502.15761v2",
        "PDF": "https://arxiv.org/pdf/2502.15761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an evaluation framework for LLM performance on XR devices, emphasizing metrics like processing speed and memory usage. It does not address data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.16580",
      "abstract": "Prompt injection attacks manipulate large language models (LLMs) by misleading them to deviate from the original input instructions and execute maliciously injected instructions, because of their instruction-following capabilities and inability to distinguish between the original input instructions and maliciously injected instructions. To defend against such attacks, recent studies have developed various detection mechanisms. If we restrict ourselves specifically to works which perform detection rather than direct defense, most of them focus on direct prompt injection attacks, while there are few works for the indirect scenario, where injected instructions are indirectly from external tools, such as a search engine. Moreover, current works mainly investigate injection detection methods and pay less attention to the post-processing method that aims to mitigate the injection after detection. In this paper, we investigate the feasibility of detecting and removing indirect prompt injection attacks, and we construct a benchmark dataset for evaluation. For detection, we assess the performance of existing LLMs and open-source detection models, and we further train detection models using our crafted training datasets. For removal, we evaluate two intuitive methods: (1) the segmentation removal method, which segments the injected document and removes parts containing injected instructions, and (2) the extraction removal method, which trains an extraction model to identify and remove injected instructions.",
      "authors": [
        "Yulin Chen",
        "Haoran Li",
        "Yuan Sui",
        "Yufei He",
        "Yue Liu",
        "Yangqiu Song",
        "Bryan Hooi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-23T14:02:16+00:00",
          "link": "https://arxiv.org/abs/2502.16580v1",
          "size": "271kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T05:48:55+00:00",
          "link": "https://arxiv.org/abs/2502.16580v2",
          "size": "247kb",
          "version": "v2"
        }
      ],
      "title": "Can Indirect Prompt Injection Attacks Be Detected and Removed?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16580",
        "HTML": "https://arxiv.org/html/2502.16580v2",
        "PDF": "https://arxiv.org/pdf/2502.16580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper constructs a benchmark dataset for evaluating prompt injection attacks, which involves crafting training datasets, its primary focus is on detection and removal of these attacks, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04800",
      "abstract": "While Retrieval-Augmented Generation (RAG) has emerged as an effective approach for addressing the knowledge outdating problem in Large Language Models (LLMs), it still faces a critical challenge: the prevalence of outdated information in knowledge bases. Current research primarily focuses on incorporating up-to-date information, yet the impact of outdated information coexisting in retrieval sources remains inadequately addressed. To bridge this gap, we introduce HoH, the first benchmark specifically designed to evaluate the impact of outdated information on RAG. Our benchmark leverages token-level diff algorithms combined with LLM pipelines to efficiently create a large-scale QA dataset that accurately captures the evolution of temporal knowledge in real-world facts. Through comprehensive experiments, we reveal that outdated information significantly degrades RAG performance in two critical ways: (1) it substantially reduces response accuracy by distracting models from correct information, and (2) it can mislead models into generating potentially harmful outputs, even when current information is available. Current RAG approaches struggle with both retrieval and generation aspects when handling outdated information. These findings highlight the urgent need for innovative solutions to address the temporal challenges in RAG. Our code and data are available at: https://github.com/0russwest0/HoH.",
      "authors": [
        "Jie Ouyang",
        "Tingyue Pan",
        "Mingyue Cheng",
        "Ruiran Yan",
        "Yucong Luo",
        "Jiaying Lin",
        "Qi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T06:54:05+00:00",
          "link": "https://arxiv.org/abs/2503.04800v1",
          "size": "16036kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T15:39:49+00:00",
          "link": "https://arxiv.org/abs/2503.04800v2",
          "size": "6937kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T12:34:45+00:00",
          "link": "https://arxiv.org/abs/2503.04800v3",
          "size": "6912kb",
          "version": "v3"
        }
      ],
      "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04800",
        "HTML": "https://arxiv.org/html/2503.04800v3",
        "PDF": "https://arxiv.org/pdf/2503.04800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a benchmark to evaluate outdated information's impact on retrieval-augmented generation, involving dataset creation for QA tasks. However, its primary focus is not on LLM training data processing, limiting its relevance."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05156",
      "abstract": "Feature caching has emerged as an effective strategy to accelerate diffusion transformer (DiT) sampling through temporal feature reuse. It is a challenging problem since (1) Progressive error accumulation from cached blocks significantly degrades generation quality, particularly when over 50\\% of blocks are cached; (2) Current error compensation approaches neglect dynamic perturbation patterns during the caching process, leading to suboptimal error correction. To solve these problems, we propose the Gradient-Optimized Cache (GOC) with two key innovations: (1) Cached Gradient Propagation: A gradient queue dynamically computes the gradient differences between cached and recomputed features. These gradients are weighted and propagated to subsequent steps, directly compensating for the approximation errors introduced by caching. (2) Inflection-Aware Optimization: Through statistical analysis of feature variation patterns, we identify critical inflection points where the denoising trajectory changes direction. By aligning gradient updates with these detected phases, we prevent conflicting gradient directions during error correction. Extensive evaluations on ImageNet demonstrate GOC's superior trade-off between efficiency and quality. With 50\\% cached blocks, GOC achieves IS 216.28 (26.3\\% higher) and FID 3.907 (43\\% lower) compared to baseline DiT, while maintaining identical computational costs. These improvements persist across various cache ratios, demonstrating robust adaptability to different acceleration requirements. Code is available at https://github.com/qiujx0520/GOC_ICCV2025.git.",
      "authors": [
        "Junxiang Qiu",
        "Lin Liu",
        "Shuo Wang",
        "Jinda Lu",
        "Kezhou Chen",
        "Yanbin Hao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T05:31:47+00:00",
          "link": "https://arxiv.org/abs/2503.05156v1",
          "size": "2675kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T01:36:03+00:00",
          "link": "https://arxiv.org/abs/2503.05156v2",
          "size": "2502kb",
          "version": "v2"
        }
      ],
      "title": "Accelerating Diffusion Transformer via Gradient-Optimized Cache",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05156",
        "HTML": "https://arxiv.org/html/2503.05156v2",
        "PDF": "https://arxiv.org/pdf/2503.05156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on feature caching to enhance the efficiency of Diffusion Transformers (DiT) in image processing, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06776",
      "abstract": "We address safe multi-robot interaction under uncertainty. In particular, we formulate a chance-constrained linear quadratic Gaussian game with coupling constraints and system uncertainties. We find a tractable reformulation of the game and propose a dual ascent algorithm. We prove that the algorithm converges to a feedback generalized Nash equilibrium of the reformulated game, ensuring the satisfaction of the chance constraints. We test our method in driving simulations and real-world robot experiments. Our method ensures safety under uncertainty and generates less conservative trajectories than single-agent model predictive control.",
      "authors": [
        "Kai Ren",
        "Giulio Salizzoni",
        "Mustafa Emre G\\\"ursoy",
        "Maryam Kamgarpour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T21:03:53+00:00",
          "link": "https://arxiv.org/abs/2503.06776v1",
          "size": "601kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T15:22:33+00:00",
          "link": "https://arxiv.org/abs/2503.06776v2",
          "size": "800kb",
          "version": "v2"
        }
      ],
      "title": "Chance-constrained Linear Quadratic Gaussian Games for Multi-robot Interaction under Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06776",
        "HTML": "https://arxiv.org/html/2503.06776v2",
        "PDF": "https://arxiv.org/pdf/2503.06776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses multi-robot interaction under uncertainty and does not relate to LLM training data processing or data engineering operations for language models."
      },
      "repo_urls": [
        "https://github.com/renkai99/safe-CCLQGGame"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07049",
      "abstract": "Bipedal robots, due to their anthropomorphic design, offer substantial potential across various applications, yet their control is hindered by the complexity of their structure. Currently, most research focuses on proprioception-based methods, which lack the capability to overcome complex terrain. While visual perception is vital for operation in human-centric environments, its integration complicates control further. Recent reinforcement learning (RL) approaches have shown promise in enhancing legged robot locomotion, particularly with proprioception-based methods. However, terrain adaptability, especially for bipedal robots, remains a significant challenge, with most research focusing on flat-terrain scenarios. In this paper, we introduce a novel mixture of experts teacher-student network RL strategy, which enhances the performance of teacher-student policies based on visual inputs through a simple yet effective approach. Our method combines terrain selection strategies with the teacher policy, resulting in superior performance compared to traditional models. Additionally, we introduce an alignment loss between the teacher and student networks, rather than enforcing strict similarity, to improve the student's ability to navigate diverse terrains. We validate our approach experimentally on the Limx Dynamic P1 bipedal robot, demonstrating its feasibility and robustness across multiple terrain types.",
      "authors": [
        "Fu Chen",
        "Rui Wan",
        "Peidong Liu",
        "Nanxing Zheng and Bo Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T08:35:38+00:00",
          "link": "https://arxiv.org/abs/2503.07049v1",
          "size": "2296kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:48:59+00:00",
          "link": "https://arxiv.org/abs/2503.07049v2",
          "size": "1241kb",
          "version": "v2"
        }
      ],
      "title": "VMTS: Vision-Assisted Teacher-Student Reinforcement Learning for Multi-Terrain Locomotion in Bipedal Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07049",
        "HTML": "https://arxiv.org/html/2503.07049v2",
        "PDF": "https://arxiv.org/pdf/2503.07049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on reinforcement learning for bipedal robot locomotion using visual inputs, not on LLM training data processing or related data engineering tasks."
      },
      "repo_urls": [
        "https://github.com/chenfu-user/VMTS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07348",
      "abstract": "In this work we present a novel approach for unsupervised multi-graph matching, which applies to problems for which a Gaussian distribution of keypoint features can be assumed. We leverage cycle consistency as loss for self-supervised learning, and determine Gaussian parameters through Bayesian Optimization, yielding a highly efficient approach that scales to large datasets. Our fully unsupervised approach enables us to reach the accuracy of state-of-the-art supervised methodology for the biomedical use case of semantic cell annotation in 3D microscopy images of the worm C. elegans. To this end, our approach yields the first unsupervised atlas of C. elegans, i.e. a model of the joint distribution of all of its cell nuclei, without the need for any ground truth cell annotation. This advancement enables highly efficient semantic annotation of cells in large microscopy datasets, overcoming a current key bottleneck. Beyond C. elegans, our approach offers fully unsupervised construction of cell-level atlases for any model organism with a stereotyped body plan down to the level of unique semantic cell labels, and thus bears the potential to catalyze respective biomedical studies in a range of further species.",
      "authors": [
        "Christoph Karg",
        "Sebastian Stricker",
        "Lisa Hutschenreiter",
        "Bogdan Savchynskyy",
        "Dagmar Kainmueller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T14:03:18+00:00",
          "link": "https://arxiv.org/abs/2503.07348v1",
          "size": "1498kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:49:10+00:00",
          "link": "https://arxiv.org/abs/2503.07348v2",
          "size": "3589kb",
          "version": "v2"
        }
      ],
      "title": "Cycle-Consistent Multi-Graph Matching for Self-Supervised Annotation of C.Elegans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07348",
        "HTML": "https://arxiv.org/html/2503.07348v2",
        "PDF": "https://arxiv.org/pdf/2503.07348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a method for unsupervised multi-graph matching for cell annotation in microscopy, which does not pertain to the processing of training data for language models."
      },
      "tasks": [
        "Bayesian Optimization",
        "Graph Matching",
        "Self-Supervised Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.09567",
      "abstract": "Recent advancements in reasoning with large language models (RLLMs), such as OpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in complex domains like mathematics and coding. A central factor in their success lies in the application of long chain-of-thought (Long CoT) characteristics, which enhance reasoning abilities and enable the solution of intricate problems. However, despite these developments, a comprehensive survey on Long CoT is still lacking, limiting our understanding of its distinctions from traditional short chain-of-thought (Short CoT) and complicating ongoing debates on issues like \"overthinking\" and \"inference-time scaling.\" This survey seeks to fill this gap by offering a unified perspective on Long CoT. (1) We first distinguish Long CoT from Short CoT and introduce a novel taxonomy to categorize current reasoning paradigms. (2) Next, we explore the key characteristics of Long CoT: deep reasoning, extensive exploration, and feasible reflection, which enable models to handle more complex tasks and produce more efficient, coherent outcomes compared to the shallower Short CoT. (3) We then investigate key phenomena such as the emergence of Long CoT with these characteristics, including overthinking, and inference-time scaling, offering insights into how these processes manifest in practice. (4) Finally, we identify significant research gaps and highlight promising future directions, including the integration of multi-modal reasoning, efficiency improvements, and enhanced knowledge frameworks. By providing a structured overview, this survey aims to inspire future research and further the development of logical reasoning in artificial intelligence.",
      "authors": [
        "Qiguang Chen",
        "Libo Qin",
        "Jinhao Liu",
        "Dengyun Peng",
        "Jiannan Guan",
        "Peng Wang",
        "Mengkang Hu",
        "Yuhang Zhou",
        "Te Gao",
        "Wanxiang Che"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T17:35:03+00:00",
          "link": "https://arxiv.org/abs/2503.09567v1",
          "size": "3319kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T04:34:15+00:00",
          "link": "https://arxiv.org/abs/2503.09567v2",
          "size": "3319kb",
          "version": "v2"
        },
        {
          "date": "2025-04-09T11:20:18+00:00",
          "link": "https://arxiv.org/abs/2503.09567v3",
          "size": "4590kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T15:13:24+00:00",
          "link": "https://arxiv.org/abs/2503.09567v4",
          "size": "5137kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T15:57:54+00:00",
          "link": "https://arxiv.org/abs/2503.09567v5",
          "size": "4993kb",
          "version": "v5"
        }
      ],
      "title": "Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09567",
        "HTML": "https://arxiv.org/html/2503.09567v5",
        "PDF": "https://arxiv.org/pdf/2503.09567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The surveyed topic is reasoning in LLMs using long chain-of-thought paradigms, focusing on reasoning capabilities rather than the processing of training data."
      },
      "tasks": [
        "Logical Reasoning",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12170",
      "abstract": "End-to-end autonomous driving (E2E-AD) has rapidly emerged as a promising approach toward achieving full autonomy. However, existing E2E-AD systems typically adopt a traditional multi-task framework, addressing perception, prediction, and planning tasks through separate task-specific heads. Despite being trained in a fully differentiable manner, they still encounter issues with task coordination, and the system complexity remains high. In this work, we introduce DiffAD, a novel diffusion probabilistic model that redefines autonomous driving as a conditional image generation task. By rasterizing heterogeneous targets onto a unified bird's-eye view (BEV) and modeling their latent distribution, DiffAD unifies various driving objectives and jointly optimizes all driving tasks in a single framework, significantly reducing system complexity and harmonizing task coordination. The reverse process iteratively refines the generated BEV image, resulting in more robust and realistic driving behaviors. Closed-loop evaluations in Carla demonstrate the superiority of the proposed method, achieving a new state-of-the-art Success Rate and Driving Score.",
      "authors": [
        "Tao Wang",
        "Cong Zhang",
        "Xingguang Qu",
        "Kun Li",
        "Weiwei Liu",
        "Chang Huang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T15:23:35+00:00",
          "link": "https://arxiv.org/abs/2503.12170v1",
          "size": "7113kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:26:43+00:00",
          "link": "https://arxiv.org/abs/2503.12170v2",
          "size": "3704kb",
          "version": "v2"
        }
      ],
      "title": "DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12170",
        "HTML": "https://arxiv.org/html/2503.12170v2",
        "PDF": "https://arxiv.org/pdf/2503.12170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a diffusion probabilistic model for end-to-end autonomous driving, specifically dealing with perception, prediction, and planning tasks. It does not address any issues related to LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Bench2Drive",
        "Conditional Image Generation",
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16700",
      "abstract": "This paper introduces Q-learning with gradient target tracking, a novel reinforcement learning framework that provides a learned continuous target update mechanism as an alternative to the conventional hard update paradigm. In the standard deep Q-network (DQN), the target network is a copy of the online network's weights, held fixed for a number of iterations before being periodically replaced via a hard update. While this stabilizes training by providing consistent targets, it introduces a new challenge: the hard update period must be carefully tuned to achieve optimal performance. To address this issue, we propose two gradient-based target update methods: DQN with asymmetric gradient target tracking (AGT2-DQN) and DQN with symmetric gradient target tracking (SGT2-DQN). These methods replace the conventional hard target updates with continuous and structured updates using gradient descent, which effectively eliminates the need for manual tuning. We provide a theoretical analysis proving the convergence of these methods in tabular settings. Additionally, empirical evaluations demonstrate their advantages over standard DQN baselines, which suggest that gradient-based target updates can serve as an effective alternative to conventional target update mechanisms in Q-learning.",
      "authors": [
        "Bum Geun Park",
        "Taeho Lee",
        "Donghwan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T20:46:25+00:00",
          "link": "https://arxiv.org/abs/2503.16700v1",
          "size": "18607kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:48:54+00:00",
          "link": "https://arxiv.org/abs/2503.16700v2",
          "size": "11352kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T03:30:40+00:00",
          "link": "https://arxiv.org/abs/2503.16700v3",
          "size": "11352kb",
          "version": "v3"
        }
      ],
      "title": "Deep Q-Learning with Gradient Target Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16700",
        "HTML": "https://arxiv.org/html/2503.16700v3",
        "PDF": "https://arxiv.org/pdf/2503.16700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a reinforcement learning framework for Q-learning involving gradient target tracking. It does not pertain to any aspect of LLM training data processing."
      },
      "tasks": [
        "Q-Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17340",
      "abstract": "Automatically generating natural, diverse and rhythmic human dance movements driven by music is vital for virtual reality and film industries. However, generating dance that naturally follows music remains a challenge, as existing methods lack proper beat alignment and exhibit unnatural motion dynamics. In this paper, we propose Danceba, a novel framework that leverages gating mechanism to enhance rhythm-aware feature representation for music-driven dance generation, which achieves highly aligned dance poses with enhanced rhythmic sensitivity. Specifically, we introduce Phase-Based Rhythm Extraction (PRE) to precisely extract rhythmic information from musical phase data, capitalizing on the intrinsic periodicity and temporal structures of music. Additionally, we propose Temporal-Gated Causal Attention (TGCA) to focus on global rhythmic features, ensuring that dance movements closely follow the musical rhythm. We also introduce Parallel Mamba Motion Modeling (PMMM) architecture to separately model upper and lower body motions along with musical features, thereby improving the naturalness and diversity of generated dance movements. Extensive experiments confirm that Danceba outperforms state-of-the-art methods, achieving significantly better rhythmic alignment and motion diversity. Project page: https://danceba.github.io/ .",
      "authors": [
        "Congyi Fan",
        "Jian Guan",
        "Xuanjia Zhao",
        "Dongli Xu",
        "Youtian Lin",
        "Tong Ye",
        "Pengming Feng",
        "Haiwei Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T17:42:50+00:00",
          "link": "https://arxiv.org/abs/2503.17340v1",
          "size": "32872kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T01:29:23+00:00",
          "link": "https://arxiv.org/abs/2503.17340v2",
          "size": "2487kb",
          "version": "v2"
        }
      ],
      "title": "Align Your Rhythm: Generating Highly Aligned Dance Poses with Gating-Enhanced Rhythm-Aware Feature Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17340",
        "HTML": "https://arxiv.org/html/2503.17340v2",
        "PDF": "https://arxiv.org/pdf/2503.17340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on generating dance poses aligned with music through rhythm-aware feature representation, but it does not pertain to any stage of LLM training data processing."
      },
      "tasks": [
        "Diversity",
        "Mamba",
        "Rhythm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20349",
      "abstract": "Current diffusion-based super-resolution (SR) approaches achieve commendable performance at the cost of high inference overhead. Therefore, distillation techniques are utilized to accelerate the multi-step teacher model into one-step student model. Nevertheless, these methods significantly raise training costs and constrain the performance of the student model by the teacher model. To overcome these tough challenges, we propose Consistency Trajectory Matching for Super-Resolution (CTMSR), a distillation-free strategy that is able to generate photo-realistic SR results in one step. Concretely, we first formulate a Probability Flow Ordinary Differential Equation (PF-ODE) trajectory to establish a deterministic mapping from low-resolution (LR) images with noise to high-resolution (HR) images. Then we apply the Consistency Training (CT) strategy to directly learn the mapping in one step, eliminating the necessity of pre-trained diffusion model. To further enhance the performance and better leverage the ground-truth during the training process, we aim to align the distribution of SR results more closely with that of the natural images. To this end, we propose to minimize the discrepancy between their respective PF-ODE trajectories from the LR image distribution by our meticulously designed Distribution Trajectory Matching (DTM) loss, resulting in improved realism of our recovered HR images. Comprehensive experimental results demonstrate that the proposed methods can attain comparable or even superior capabilities on both synthetic and real datasets while maintaining minimal inference latency.",
      "authors": [
        "Weiyi You",
        "Mingyang Zhang",
        "Leheng Zhang",
        "Xingyu Zhou",
        "Kexuan Shi",
        "Shuhang Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T09:20:42+00:00",
          "link": "https://arxiv.org/abs/2503.20349v1",
          "size": "14722kb",
          "version": "v1"
        },
        {
          "date": "2025-03-27T13:59:15+00:00",
          "link": "https://arxiv.org/abs/2503.20349v2",
          "size": "14722kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T11:43:16+00:00",
          "link": "https://arxiv.org/abs/2503.20349v3",
          "size": "11967kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T08:13:07+00:00",
          "link": "https://arxiv.org/abs/2503.20349v4",
          "size": "11967kb",
          "version": "v4"
        }
      ],
      "title": "Consistency Trajectory Matching for One-Step Generative Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20349",
        "HTML": "https://arxiv.org/html/2503.20349v4",
        "PDF": "https://arxiv.org/pdf/2503.20349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on generative super-resolution using a one-step approach with Consistency Trajectory Matching. It does not contribute to LLM training data processing."
      },
      "tasks": [
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23923",
      "abstract": "Artificial general intelligence (AGI) is an established field of research. Yet some have questioned if the term still has meaning. AGI has been subject to so much hype and speculation it has become something of a Rorschach test. Melanie Mitchell argues the debate will only be settled through long term, scientific investigation. To that end here is a short, accessible and provocative overview of AGI. I compare definitions of intelligence, settling on intelligence in terms of adaptation and AGI as an artificial scientist. Taking my cue from Sutton's Bitter Lesson I describe two foundational tools used to build adaptive systems: search and approximation. I compare pros, cons, hybrids and architectures like o3, AlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to making systems behave more intelligently. I divide them into scale-maxing, simp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's Razors. These maximise resources, simplicity of form, and the weakness of constraints on functionality. I discuss examples including AIXI, the free energy principle and The Embiggening of language models. I conclude that though scale-maxed approximation dominates, AGI will be a fusion of tools and meta-approaches. The Embiggening was enabled by improvements in hardware. Now the bottlenecks are sample and energy efficiency.",
      "authors": [
        "Michael Timothy Bennett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T10:15:37+00:00",
          "link": "https://arxiv.org/abs/2503.23923v1",
          "size": "6201kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:45:28+00:00",
          "link": "https://arxiv.org/abs/2503.23923v2",
          "size": "178kb",
          "version": "v2"
        }
      ],
      "title": "What the F*ck Is Artificial General Intelligence?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23923",
        "HTML": "https://arxiv.org/html/2503.23923v2",
        "PDF": "https://arxiv.org/pdf/2503.23923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides an overview of artificial general intelligence (AGI) and discusses concepts and theoretical approaches in AI but does not address training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.00142",
      "abstract": "While hyperbolic GNNs show promise for hierarchical data, they often have limited discriminative power compared to Euclidean counterparts or the WL test, due to non-injective aggregation. To address this expressivity gap, we propose the Lorentzian Graph Isomorphic Network (LGIN), a novel HGNN designed for enhanced discrimination within the Lorentzian model. LGIN introduces a new update rule that preserves the Lorentzian metric while effectively capturing richer structural information. This marks a significant step towards more expressive GNNs on Riemannian manifolds. Extensive evaluations across nine benchmark datasets demonstrate LGIN's superior performance, consistently outperforming or matching state-of-the-art hyperbolic and Euclidean baselines, showcasing its ability to capture complex graph structures. LGIN is the first to adapt principles of powerful, highly discriminative GNN architectures to a Riemannian manifold. The code for our paper can be found at https://github.com/Deceptrax123/LGIN",
      "authors": [
        "Srinitish Srinivasan and Omkumar CU"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T18:49:34+00:00",
          "link": "https://arxiv.org/abs/2504.00142v1",
          "size": "1384kb",
          "version": "v1"
        },
        {
          "date": "2025-04-21T07:52:27+00:00",
          "link": "https://arxiv.org/abs/2504.00142v2",
          "size": "1387kb",
          "version": "v2"
        },
        {
          "date": "2025-05-05T20:07:37+00:00",
          "link": "https://arxiv.org/abs/2504.00142v3",
          "size": "1387kb",
          "version": "v3"
        },
        {
          "date": "2025-05-25T08:02:13+00:00",
          "link": "https://arxiv.org/abs/2504.00142v4",
          "size": "1932kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T07:10:12+00:00",
          "link": "https://arxiv.org/abs/2504.00142v5",
          "size": "1987kb",
          "version": "v5"
        }
      ],
      "title": "Can we ease the Injectivity Bottleneck on Lorentzian Manifolds for Graph Neural Networks?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00142",
        "HTML": "https://arxiv.org/html/2504.00142v5",
        "PDF": "https://arxiv.org/pdf/2504.00142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on graph neural networks (GNNs) and enhancing their expressivity on Lorentzian manifolds. It does not contribute to LLM training data processing."
      },
      "tasks": [
        "Graph Learning",
        "Graph Neural Network",
        "Graph Representation Learning",
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/Deceptrax123/LGIN"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00181",
      "abstract": "An efficient beamforming design is proposed for continuous aperture array (CAPA)-based point-to-point multiple-input multiple-output (MIMO) systems. In contrast to conventional spatially discrete array (SPDA)-MIMO systems, whose optimal beamforming can be obtained using singular-value decomposition, CAPA-MIMO systems require solving the eigendecomposition of a Hermitian kernel operator, which is computationally prohibitive. To address this challenge, an explicit closed-form expression for the achievable rate of CAPA-MIMO systems is first derived as a function of the continuous transmit beamformer. Subsequently, an iterative weighted minimum mean-squared error (WMMSE) algorithm is proposed, directly addressing the CAPA-MIMO beamforming optimization without discretization approximation. Closed-form updates for each iteration of the WMMSE algorithm are derived via the calculus of variations (CoV) method. For low-complexity implementation, an equivalent matrix-based iterative solution is introduced using Gauss-Legendre quadrature. Our numerical results demonstrate that 1) CAPA-MIMO achieves substantial performance gain over the SPDA-MIMO, 2) the proposed WMMSE algorithm enhances performance while significantly reducing computational complexity compared to state-of-the-art Fourier-based approaches, and 3) the proposed WMMSE algorithm enables practical realization of parallel, non-interfering transmissions.",
      "authors": [
        "Zhaolin Wang",
        "Chongjun Ouyang",
        "Yuanwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T19:41:35+00:00",
          "link": "https://arxiv.org/abs/2504.00181v1",
          "size": "1473kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T18:37:35+00:00",
          "link": "https://arxiv.org/abs/2504.00181v2",
          "size": "1635kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T13:29:46+00:00",
          "link": "https://arxiv.org/abs/2504.00181v3",
          "size": "1322kb",
          "version": "v3"
        }
      ],
      "title": "Beamforming Design for Continuous Aperture Array (CAPA)-Based MIMO Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00181",
        "HTML": "https://arxiv.org/html/2504.00181v3",
        "PDF": "https://arxiv.org/pdf/2504.00181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with beamforming design for MIMO systems, which is unrelated to the training data processing of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.02768",
      "abstract": "We introduce MultiBLiMP 1.0, a massively multilingual benchmark of linguistic minimal pairs, covering 101 languages and 2 types of subject-verb agreement, containing more than 128,000 minimal pairs. Our minimal pairs are created using a fully automated pipeline, leveraging the large-scale linguistic resources of Universal Dependencies and UniMorph. MultiBLiMP 1.0 evaluates abilities of LLMs at an unprecedented multilingual scale, and highlights the shortcomings of the current state-of-the-art in modelling low-resource languages",
      "authors": [
        "Jaap Jumelet",
        "Leonie Weissweiler",
        "Joakim Nivre",
        "Arianna Bisazza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T17:05:50+00:00",
          "link": "https://arxiv.org/abs/2504.02768v1",
          "size": "9546kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T17:21:42+00:00",
          "link": "https://arxiv.org/abs/2504.02768v2",
          "size": "560kb",
          "version": "v2"
        }
      ],
      "title": "MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02768",
        "HTML": "https://arxiv.org/html/2504.02768v2",
        "PDF": "https://arxiv.org/pdf/2504.02768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces MultiBLiMP 1.0, a multilingual benchmark of linguistic minimal pairs designed to evaluate LLMs. The creation of this dataset involves data processing, making it directly relevant to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "jumelet/multiblimp",
          "downloads": "456",
          "likes": "12",
          "link": "https://huggingface.co/datasets/jumelet/multiblimp"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/jumelet/multiblimp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04287",
      "abstract": "Uncertainties in renewable energy resources (RES) and load variations can lead to elevated system operational costs. Moreover, the emergence of large-scale distributed threats, such as load-altering attacks (LAAs), can induce substantial load variations, further exacerbating these costs. Although traditional defense measures can reduce the likelihood of such attacks, considerable residual risks remain. Thus, this paper proposes a cyber insurance framework designed to hedge against additional operational costs resulting from LAAs and substantial load variations in renewable-rich grids. The insurance framework determines both the insurance coverage and premium based on the Value at Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated using the system failure probability and the probability density function (PDF) of the system operation cost. The system failure probability is assessed through a semi-Markov process (SMP), while the cost distribution is estimated through a cost minimization model of a distribution grid combined with a Monte-Carlo simulation to capture load variability. Furthermore, we employ a bi-level optimization scheme that identifies the specific load distribution leading to the maximum system cost, thereby enhancing the accuracy of the operation cost PDF estimation. The effectiveness and scalability of the proposed cyber insurance policy are evaluated considering a modified IEEE-118 test bus system and the IEEE European low-voltage (LV) test feeders model. The case study shows that with a relatively low premium, the network operator can hedge against additional operational costs caused by malicious load manipulations.",
      "authors": [
        "Shijie Pan",
        "Zaint A. Alexakis",
        "S Subhash Lakshminarayana",
        "Charalambos Konstantinou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-05T21:35:04+00:00",
          "link": "https://arxiv.org/abs/2504.04287v1",
          "size": "4720kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:25:20+00:00",
          "link": "https://arxiv.org/abs/2504.04287v2",
          "size": "1059kb",
          "version": "v2"
        }
      ],
      "title": "Cyber Insurance Design for Load Variation and Load Curtailment in Distribution Grids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04287",
        "HTML": "https://arxiv.org/html/2504.04287v2",
        "PDF": "https://arxiv.org/pdf/2504.04287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a cyber insurance design for grid load variations, focusing on operational costs in distribution grids, which has no connection to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.07312",
      "abstract": "A growing trend in financial technology (fintech) is the use of mobile phone data and machine learning (ML) to provide credit scores- and subsequently, opportunities to access loans- to groups left out of traditional banking. This paper draws on interview data with leaders, investors, and data scientists at fintech companies developing ML-based alternative lending apps in low- and middle-income countries to explore financial inclusion and gender implications. More specifically, it examines how the underlying logics, design choices, and management decisions of ML-based alternative lending tools by fintechs embed or challenge gender biases, and consequently influence gender equity in access to finance. Findings reveal developers follow 'gender blind' approaches, grounded in beliefs that ML is objective and data reflects the truth. This leads to a lack of grappling with the ways data, features for creditworthiness, and access to apps are gendered. Overall, tools increase access to finance, but not gender equitably: Interviewees report less women access loans and receive lower amounts than men, despite being better repayers. Fintechs identify demand- and supply-side reasons for gender differences, but frame them as outside their responsibility. However, that women are observed as better repayers reveals a market inefficiency and potential discriminatory effect, further linked to profit optimization objectives. This research introduces the concept of encoded gender norms, whereby without explicit attention to the gendered nature of data and algorithmic design, AI tools reproduce existing inequalities. In doing so, they reinforce gender norms as self-fulfilling prophecies. The idea that AI is inherently objective and, when left alone, 'fair', is seductive and misleading. In reality, algorithms reflect the perspectives, priorities, and values of the people and institutions that design them.",
      "authors": [
        "Genevieve Smith"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T22:28:21+00:00",
          "link": "https://arxiv.org/abs/2504.07312v1",
          "size": "510kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T21:16:09+00:00",
          "link": "https://arxiv.org/abs/2504.07312v2",
          "size": "510kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T18:19:11+00:00",
          "link": "https://arxiv.org/abs/2504.07312v3",
          "size": "651kb",
          "version": "v3"
        }
      ],
      "title": "Mindsets and Management: AI and Gender (In)Equitable Access to Finance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07312",
        "PDF": "https://arxiv.org/pdf/2504.07312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI and gender equity in access to finance, analyzing how ML-based tools might perpetuate gender biases. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.08593",
      "abstract": "This work tackles the challenge of continuous sign language segmentation, a key task with huge implications for sign language translation and data annotation. We propose a transformer-based architecture that models the temporal dynamics of signing and frames segmentation as a sequence labeling problem using the Begin-In-Out (BIO) tagging scheme. Our method leverages the HaMeR hand features, and is complemented with 3D Angles. Extensive experiments show that our model achieves state-of-the-art results on the DGS Corpus, while our features surpass prior benchmarks on BSLCorpus.",
      "authors": [
        "JianHe Low",
        "Harry Walsh",
        "Ozge Mercanoglu Sincan",
        "Richard Bowden"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T14:52:59+00:00",
          "link": "https://arxiv.org/abs/2504.08593v1",
          "size": "7969kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T08:07:48+00:00",
          "link": "https://arxiv.org/abs/2504.08593v2",
          "size": "7969kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T21:06:41+00:00",
          "link": "https://arxiv.org/abs/2504.08593v3",
          "size": "7969kb",
          "version": "v3"
        }
      ],
      "title": "Hands-On: Segmenting Individual Signs from Continuous Sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08593",
        "HTML": "https://arxiv.org/html/2504.08593v3",
        "PDF": "https://arxiv.org/pdf/2504.08593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses sign language segmentation and proposes a model for handling the temporal dynamics of signing. It doesn't involve LLM training data processing."
      },
      "tasks": [
        "Segmentation",
        "Sign Language Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10888",
      "abstract": "Adversarial patches are widely used to evaluate the robustness of object detection systems in real-world scenarios. These patches were initially designed to deceive single-modal detectors (e.g., visible or infrared) and have recently been extended to target visible-infrared dual-modal detectors. However, existing dual-modal adversarial patch attacks have limited attack effectiveness across diverse physical scenarios. To address this, we propose CDUPatch, a universal cross-modal patch attack against visible-infrared object detectors across scales, views, and scenarios. Specifically, we observe that color variations lead to different levels of thermal absorption, resulting in temperature differences in infrared imaging. Leveraging this property, we propose an RGB-to-infrared adapter that maps RGB patches to infrared patches, enabling unified optimization of cross-modal patches. By learning an optimal color distribution on the adversarial patch, we can manipulate its thermal response and generate an adversarial infrared texture. Additionally, we introduce a multi-scale clipping strategy and construct a new visible-infrared dataset, MSDrone, which contains aerial vehicle images in varying scales and perspectives. These data augmentation strategies enhance the robustness of our patch in real-world conditions. Experiments on four benchmark datasets (e.g., DroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms existing patch attacks in the digital domain. Extensive physical tests further confirm strong transferability across scales, views, and scenarios.",
      "authors": [
        "Jiahuan Long",
        "Wen Yao",
        "Tingsong Jiang",
        "Chao Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T05:46:00+00:00",
          "link": "https://arxiv.org/abs/2504.10888v1",
          "size": "23385kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:51:29+00:00",
          "link": "https://arxiv.org/abs/2504.10888v2",
          "size": "18077kb",
          "version": "v2"
        }
      ],
      "title": "CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10888",
        "HTML": "https://arxiv.org/html/2504.10888v2",
        "PDF": "https://arxiv.org/pdf/2504.10888"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an adversarial patch attack for dual-modal visible-infrared detectors. While it constructs a new dataset (MSDrone), it is not related to LLM training data processing but rather object detection robustness."
      },
      "tasks": [
        "Data Augmentation",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12075",
      "abstract": "In the present work, a generative deep learning framework combining a Co-optimized Variational Autoencoder (Co-VAE) architecture with quantitative structure-property relationship (QSPR) techniques is developed to enable accelerated inverse design of fuels. The Co-VAE integrates a property prediction component coupled with the VAE latent space, enhancing molecular reconstruction and accurate estimation of Research Octane Number (RON) (chosen as the fuel property of interest). A subset of the GDB-13 database, enriched with a curated RON database, is used for model training. Hyperparameter tuning is further utilized to optimize the balance among reconstruction fidelity, chemical validity, and RON prediction. An independent regression model is then used to refine RON prediction, while a differential evolution algorithm is employed to efficiently navigate the VAE latent space and identify promising fuel molecule candidates with high RON. This methodology addresses the limitations of traditional fuel screening approaches by capturing complex structure-property relationships within a comprehensive latent representation. The generative model can be adapted to different target properties, enabling systematic exploration of large chemical spaces relevant to fuel design applications. Furthermore, the demonstrated framework can be readily extended by incorporating additional synthesizability criteria to improve applicability and reliability for de novo design of new fuels.",
      "authors": [
        "Kiran K. Yalamanchi",
        "Pinaki Pal",
        "Balaji Mohan",
        "Abdullah S. AlRamadan",
        "Jihad A. Badra",
        "Yuanjiang Pei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T13:32:25+00:00",
          "link": "https://arxiv.org/abs/2504.12075v1",
          "size": "673kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T23:34:50+00:00",
          "link": "https://arxiv.org/abs/2504.12075v2",
          "size": "348kb",
          "version": "v2"
        }
      ],
      "title": "Generative Deep Learning Framework for Inverse Design of Fuels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12075",
        "HTML": "https://arxiv.org/html/2504.12075v2",
        "PDF": "https://arxiv.org/pdf/2504.12075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a generative deep learning framework for fuel design, focusing on molecular reconstruction and property prediction, with no connection to LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Navigate",
        "Property Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12128",
      "abstract": "We introduce the $L_!^S$-calculus, a linear lambda-calculus extended with scalar multiplication and term addition, that acts as a proof language for intuitionistic linear logic (ILL). These algebraic operations enable the direct expression of linearity at the syntactic level, a property not typically available in standard proof-term calculi. Building upon previous work, we develop the $L_!^S$-calculus as an extension of the $L^S$-calculus with the $!$ modality. We prove key meta-theoretical properties--subject reduction, confluence, strong normalisation, and an introduction property--as well as preserve the expressiveness of the original $L^S$-calculus, including the encoding of vectors and matrices, and the correspondence between proof-terms and linear functions. A denotational semantics is provided in the framework of linear categories with biproducts, ensuring a sound and adequate interpretation of the calculus. This work is part of a broader programme aiming to build a measurement-free quantum programming language grounded in linear logic.",
      "authors": [
        "Alejandro D\\'iaz-Caro and Malena Ivnisky and Octavio Malherbe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T14:43:44+00:00",
          "link": "https://arxiv.org/abs/2504.12128v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:35:41+00:00",
          "link": "https://arxiv.org/abs/2504.12128v2",
          "size": "92kb",
          "version": "v2"
        }
      ],
      "title": "An Algebraic Extension of Intuitionistic Linear Logic: The $L_!^S$-Calculus and Its Categorical Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12128",
        "PDF": "https://arxiv.org/pdf/2504.12128"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an extension of a linear lambda-calculus for intuitionistic linear logic, focusing on algebraic operations and syntax. It doesn't relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.13393",
      "abstract": "Ground beetles are a highly sensitive and speciose biological indicator, making them vital for monitoring biodiversity. However, they are currently an underutilized resource due to the manual effort required by taxonomic experts to perform challenging species differentiations based on subtle morphological differences, precluding widespread applications. In this paper, we evaluate 12 vision models on taxonomic classification across four diverse, long-tailed datasets spanning over 230 genera and 1769 species, with images ranging from controlled laboratory settings to challenging field-collected (in-situ) photographs. We further explore taxonomic classification in two important real-world contexts: sample efficiency and domain adaptation. Our results show that the Vision and Language Transformer combined with an MLP head is the best performing model, with 97% accuracy at genus and 94% at species level. Sample efficiency analysis shows that we can reduce train data requirements by up to 50% with minimal compromise in performance. The domain adaptation experiments reveal significant challenges when transferring models from lab to in-situ images, highlighting a critical domain gap. Overall, our study lays a foundation for large-scale automated taxonomic classification of beetles, and beyond that, advances sample-efficient learning and cross-domain adaptation for diverse long-tailed ecological datasets.",
      "authors": [
        "S M Rayeed",
        "Alyson East",
        "Samuel Stevens",
        "Sydne Record",
        "Charles V Stewart"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T01:06:37+00:00",
          "link": "https://arxiv.org/abs/2504.13393v1",
          "size": "24952kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T15:54:57+00:00",
          "link": "https://arxiv.org/abs/2504.13393v2",
          "size": "24955kb",
          "version": "v2"
        }
      ],
      "title": "BeetleVerse: A Study on Taxonomic Classification of Ground Beetles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13393",
        "HTML": "https://arxiv.org/html/2504.13393v2",
        "PDF": "https://arxiv.org/pdf/2504.13393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the taxonomic classification of ground beetles using vision models and does not involve LLM training data processing operations or new dataset creation for language models."
      },
      "tasks": [
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13774",
      "abstract": "Large language models (LLMs) have recently revolutionized language processing tasks but have also brought ethical and legal issues. LLMs have a tendency to memorize potentially private or copyrighted information present in the training data, which might then be delivered to end users at inference time. When this happens, a naive solution is to retrain the model from scratch after excluding the undesired data. Although this guarantees that the target data have been forgotten, it is also prohibitively expensive for LLMs. Approximate unlearning offers a more efficient alternative, as it consists of ex post modifications of the trained model itself to prevent undesirable results, but it lacks forgetting guarantees because it relies solely on empirical evidence. In this work, we present DP2Unlearning, a novel LLM unlearning framework that offers formal forgetting guarantees at a significantly lower cost than retraining from scratch on the data to be retained. DP2Unlearning involves training LLMs on textual data protected using {\\epsilon}-differential privacy (DP), which later enables efficient unlearning with the guarantees against disclosure associated with the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning achieves similar model performance post-unlearning, compared to an LLM retraining from scratch on retained data -- the gold standard exact unlearning -- but at approximately half the unlearning cost. In addition, with a reasonable computational cost, it outperforms approximate unlearning methods at both preserving the utility of the model post-unlearning and effectively forgetting the targeted information.",
      "authors": [
        "Tamim Al Mahmud",
        "Najeeb Jebreel",
        "Josep Domingo-Ferrer and David Sanchez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T16:22:20+00:00",
          "link": "https://arxiv.org/abs/2504.13774v1",
          "size": "4203kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T10:56:13+00:00",
          "link": "https://arxiv.org/abs/2504.13774v2",
          "size": "4192kb",
          "version": "v2"
        }
      ],
      "title": "DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13774",
        "PDF": "https://arxiv.org/pdf/2504.13774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with an efficient framework for 'unlearning' data from LLMs for ethical and privacy reasons, without discussing processing or creation of training data for LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/tamimalmahmud/DP2Unlearning",
        "https://github.com/tamimalmahmud/LLM-Unlearning/tree/main/DP2Unlearning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.14452",
      "abstract": "Language models (LMs) can memorize and reproduce segments from their pretraining data verbatim even in non-adversarial settings, raising concerns about copyright, plagiarism, privacy, and creativity. We introduce Paraphrase Preference Optimization (ParaPO), a post-training method that fine-tunes LMs to reduce unintentional regurgitation while preserving their overall utility. ParaPO trains LMs to prefer paraphrased versions of memorized segments over the original verbatim content from the pretraining data. To maintain the ability to recall famous quotations when appropriate, we develop a variant of ParaPO that uses system prompts to control regurgitation behavior. In our evaluation on Llama3.1-8B, ParaPO consistently reduces regurgitation across all tested datasets (e.g., reducing the regurgitation metric from 17.3 to 12.9 in creative writing), whereas unlearning methods used in prior work to mitigate regurgitation are less effective outside their targeted unlearned domain (from 17.3 to 16.9). When applied to the instruction-tuned Tulu3-8B model, ParaPO with system prompting successfully preserves famous quotation recall while reducing unintentional regurgitation (from 8.7 to 6.3 in creative writing) when prompted not to regurgitate. In contrast, without ParaPO tuning, prompting the model not to regurgitate produces only a marginal reduction (8.7 to 8.4).",
      "authors": [
        "Tong Chen",
        "Faeze Brahman",
        "Jiacheng Liu",
        "Niloofar Mireshghallah",
        "Weijia Shi",
        "Pang Wei Koh",
        "Luke Zettlemoyer",
        "Hannaneh Hajishirzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-20T01:59:46+00:00",
          "link": "https://arxiv.org/abs/2504.14452v1",
          "size": "5638kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T18:57:22+00:00",
          "link": "https://arxiv.org/abs/2504.14452v2",
          "size": "1043kb",
          "version": "v2"
        }
      ],
      "title": "ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14452",
        "HTML": "https://arxiv.org/html/2504.14452v2",
        "PDF": "https://arxiv.org/pdf/2504.14452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "ParaPO is a method that fine-tunes language models to reduce regurgitation of pre-training data, which indirectly relates to training data processing through fine-tuning, though the primary focus is on model adjustment."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.15204",
      "abstract": "In this work, we propose a new soft-input soft-output decoder called soft-output from covered space (SOCS) decoder. It estimates the a posteriori reliability based on the space explored by a list decoder, i.e., the set of vectors for which the list decoder knows whether they are codewords. This approach enables a more accurate calculation of the a posteriori reliability and results in gains of up to 0.25$\\,$dB for turbo product decoding with SOCS compared to Chase-Pyndiah decoding.",
      "authors": [
        "Tim Janz",
        "Simon Oberm\\\"uller",
        "Andreas Zunker",
        "Stephan ten Brink"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T16:20:13+00:00",
          "link": "https://arxiv.org/abs/2504.15204v1",
          "size": "97kb",
          "version": "v1"
        },
        {
          "date": "2025-04-25T14:58:28+00:00",
          "link": "https://arxiv.org/abs/2504.15204v2",
          "size": "97kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T07:51:03+00:00",
          "link": "https://arxiv.org/abs/2504.15204v3",
          "size": "83kb",
          "version": "v3"
        }
      ],
      "title": "Soft-Output from Covered Space Decoding of Product Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15204",
        "PDF": "https://arxiv.org/pdf/2504.15204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new decoding method related to product codes in communication systems and does not relate to any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.16373",
      "abstract": "Mixed Reality (MR) enables rich, embodied collaboration, yet it's uncertain if sensor and system-logged behavioral signals capture how users experience that collaboration. This disconnect stems from a fundamental gap: behavioral signals are observable and continuous, while collaboration is interpreted subjectively, shaped by internal states like presence, cognitive availability, and social awareness. Our core insight is that sensor signals serve as observable manifestations of subjective experiences in MR collaboration, and they can be captured through sensor data such as shared gaze, speech, spatial movement, and other system-logged performance metrics. We propose the Sensor-to-Subjective (S2S) Mapping Framework, a conceptual model that links observable interaction patterns to users' subjective perceptions of collaboration and internal cognitive states through sensor-based indicators and task performance metrics. To validate this model, we conducted a study with 48 participants across 12 MR groups engaged in a collaborative image-sorting task. Our findings show a correlation between sensed behavior and perceived collaboration, particularly through shared attention and proximity.",
      "authors": [
        "Yasra Chandio",
        "Diana Romero",
        "Salma Elmalaki",
        "Fatima Anwar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T02:50:09+00:00",
          "link": "https://arxiv.org/abs/2504.16373v1",
          "size": "1616kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:07:11+00:00",
          "link": "https://arxiv.org/abs/2504.16373v2",
          "size": "1029kb",
          "version": "v2"
        }
      ],
      "title": "What Sensors See, What People Feel: Exploring Subjective Collaboration Perception in Mixed Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16373",
        "HTML": "https://arxiv.org/html/2504.16373v2",
        "PDF": "https://arxiv.org/pdf/2504.16373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores subjective collaboration perception in Mixed Reality using sensor data, focusing on the correlation of sensed behavior with perceived collaboration. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19518",
      "abstract": "In recent years, adaptive identification methods that can achieve the true value convergence of parameters without requiring persistent excitation (PE) have been widely studied, and concurrent learning has been intensively studied. However, the parameter convergence rate is limited for the gradient-based method owing to small parameter update gain, and even the introduction of forgetting factors does not work sufficiently. To address this problem, this study proposes a novel discrete-time recursive least squares method under finite excitation (FE) conditions using two forgetting factors (inner and outer) and an augmented regressor matrix comprising a sum of regressor vectors. The proposed method ensures the PE condition of the augmented regressor matrix under FE conditions of the regressor vector and allows the properly design of the forgetting factor without estimator windup and/or destabilization of the system. Numerical simulations demonstrate its effectiveness by comparing it with several conventional methods.",
      "authors": [
        "Satoshi Tsuruhara and Kazuhisa Ito"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T06:36:59+00:00",
          "link": "https://arxiv.org/abs/2504.19518v1",
          "size": "2078kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T04:32:37+00:00",
          "link": "https://arxiv.org/abs/2504.19518v2",
          "size": "791kb",
          "version": "v2"
        }
      ],
      "title": "Discrete-time Two-Layered Forgetting RLS Identification under Finite Excitation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19518",
        "HTML": "https://arxiv.org/html/2504.19518v2",
        "PDF": "https://arxiv.org/pdf/2504.19518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a novel identification method in the context of system identification and control theory, specifically using recursive least squares. It does not relate to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.21801",
      "abstract": "We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3. The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals. The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3's step-by-step reasoning, to create an initial cold start for reinforcement learning. This process enables us to integrate both informal and formal mathematical reasoning into a unified model. The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench. In addition to standard benchmarks, we introduce ProverBench, a collection of 325 formalized problems, to enrich our evaluation, including 15 selected problems from the recent AIME competitions (years 24-25). Further evaluation on these 15 AIME problems shows that the model successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of these problems using majority voting, highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing.",
      "authors": [
        "Z.Z. Ren",
        "Zhihong Shao",
        "Junxiao Song",
        "Huajian Xin",
        "Haocheng Wang",
        "Wanjia Zhao",
        "Liyue Zhang",
        "Zhe Fu",
        "Qihao Zhu",
        "Dejian Yang",
        "Z.F. Wu",
        "Zhibin Gou",
        "Shirong Ma",
        "Hongxuan Tang",
        "Yuxuan Liu",
        "Wenjun Gao",
        "Daya Guo",
        "Chong Ruan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T16:57:48+00:00",
          "link": "https://arxiv.org/abs/2504.21801v1",
          "size": "1239kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:20:23+00:00",
          "link": "https://arxiv.org/abs/2504.21801v2",
          "size": "1245kb",
          "version": "v2"
        }
      ],
      "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21801",
        "HTML": "https://arxiv.org/html/2504.21801v2",
        "PDF": "https://arxiv.org/pdf/2504.21801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a large language model designed for formal theorem proving, largely focusing on model architecture and evaluation. It briefly mentions data collection for cold-start training but does not focus on LLM training data processing operations."
      },
      "tasks": [
        "Automated Theorem Proving",
        "Large Language Model",
        "Mathematical Reasoning"
      ],
      "repo_urls": [
        "https://github.com/deepseek-ai/deepseek-prover-v2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.01454",
      "abstract": "Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy, yet it faces significant challenges in communication efficiency and vulnerability to poisoning attacks. While sparsification techniques mitigate communication overhead by transmitting only critical model parameters, they inadvertently amplify security risks: adversarial clients can exploit sparse updates to evade detection and degrade model performance. Existing defense mechanisms, designed for standard FL communication scenarios, are ineffective in addressing these vulnerabilities within sparsified FL. To bridge this gap, we propose FLARE, a novel federated learning framework that integrates sparse index mask inspection and model update sign similarity analysis to detect and mitigate poisoning attacks in sparsified FL. Extensive experiments across multiple datasets and adversarial scenarios demonstrate that FLARE significantly outperforms existing defense strategies, effectively securing sparsified FL against poisoning attacks while maintaining communication efficiency.",
      "authors": [
        "Zhiyong Jin",
        "Runhua Xu",
        "Chao Li",
        "Yizhong Liu",
        "Jianxin Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T14:59:13+00:00",
          "link": "https://arxiv.org/abs/2505.01454v1",
          "size": "6340kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T13:27:29+00:00",
          "link": "https://arxiv.org/abs/2505.01454v2",
          "size": "6340kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T13:54:51+00:00",
          "link": "https://arxiv.org/abs/2505.01454v3",
          "size": "7999kb",
          "version": "v3"
        }
      ],
      "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01454",
        "HTML": "https://arxiv.org/html/2505.01454v3",
        "PDF": "https://arxiv.org/pdf/2505.01454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on securing federated learning against poisoning attacks, particularly in communication-efficient scenarios using sparsification techniques. It is unrelated to LLM training data processing."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.01729",
      "abstract": "Recent advancements in autonomous driving (AD) systems have highlighted the potential of world models in achieving robust and generalizable performance across both ordinary and challenging driving conditions. However, a key challenge remains: precise and flexible camera pose control, which is crucial for accurate viewpoint transformation and realistic simulation of scene dynamics. In this paper, we introduce PosePilot, a lightweight yet powerful framework that significantly enhances camera pose controllability in generative world models. Drawing inspiration from self-supervised depth estimation, PosePilot leverages structure-from-motion principles to establish a tight coupling between camera pose and video generation. Specifically, we incorporate self-supervised depth and pose readouts, allowing the model to infer depth and relative camera motion directly from video sequences. These outputs drive pose-aware frame warping, guided by a photometric warping loss that enforces geometric consistency across synthesized frames. To further refine camera pose estimation, we introduce a reverse warping step and a pose regression loss, improving viewpoint precision and adaptability. Extensive experiments on autonomous driving and general-domain video datasets demonstrate that PosePilot significantly enhances structural understanding and motion reasoning in both diffusion-based and auto-regressive world models. By steering camera pose with self-supervised depth, PosePilot sets a new benchmark for pose controllability, enabling physically consistent, reliable viewpoint synthesis in generative world models.",
      "authors": [
        "Bu Jin",
        "Weize Li",
        "Baihan Yang",
        "Zhenxin Zhu",
        "Junpeng Jiang",
        "Huan-ang Gao",
        "Haiyang Sun",
        "Kun Zhan",
        "Hengtong Hu",
        "Xueyang Zhang",
        "Peng Jia and Hao Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-03T07:51:46+00:00",
          "link": "https://arxiv.org/abs/2505.01729v1",
          "size": "3625kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:43:15+00:00",
          "link": "https://arxiv.org/abs/2505.01729v2",
          "size": "3627kb",
          "version": "v2"
        }
      ],
      "title": "PosePilot: Steering Camera Pose for Generative World Models with Self-supervised Depth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01729",
        "HTML": "https://arxiv.org/html/2505.01729v2",
        "PDF": "https://arxiv.org/pdf/2505.01729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses enhancing camera pose controllability in generative world models using self-supervised depth, relevant to autonomous driving and video generation, not LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Camera Pose Estimation",
        "Depth Estimation",
        "Pose Estimation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.01830",
      "abstract": "The global surge in social inequalities is one of the most pressing issues of our times. The spatial expression of social inequalities at city scale gives rise to urban segregation, a common phenomenon across different local and cultural contexts. The increasing popularity of Big Data and computational models has inspired a growing number of computational social science studies that analyze, evaluate, and issue policy recommendations for urban segregation. Today's wealth in information and computational power could inform urban planning for equity. However, as we show here, segregation research is epistemologically interdependent with prevalent economic theories which overfocus on individual responsibility while neglecting systemic processes. This individualistic bias is also engrained in computational models of urban segregation. Through several contemporary examples of how Big Data -- and the assumptions underlying its usage -- influence (de)segregation patterns and policies, our essay tells a cautionary tale. We highlight how a lack of consideration for data ethics can lead to the creation of computational models that have a real-life, further marginalizing impact on disadvantaged groups. With this essay, our aim is to develop a better discernment of the pitfalls and potentials of computational approaches to urban segregation, thereby fostering a conscious focus on systemic thinking about urban inequalities. We suggest setting an agenda for research and collective action that is directed at demobilizing individualistic bias, informing our thinking about urban segregation, but also more broadly our efforts to create sustainable cities and communities.",
      "authors": [
        "Anastassia Vybornova and Trivik Verma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-03T14:15:27+00:00",
          "link": "https://arxiv.org/abs/2505.01830v1",
          "size": "503kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:04:26+00:00",
          "link": "https://arxiv.org/abs/2505.01830v2",
          "size": "5240kb",
          "version": "v2"
        }
      ],
      "title": "You Don't Have to Live Next to Me: Towards Demobilizing Individualistic Bias in Computational Approaches to Urban Segregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01830",
        "HTML": "https://arxiv.org/html/2505.01830v2",
        "PDF": "https://arxiv.org/pdf/2505.01830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses computational approaches to urban segregation and critiques the individualistic bias in these models. It does not address training data processing for LLMs or any involved data operations like collection or filtering relevant to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.04421",
      "abstract": "Modeling ultra-long user behavior sequences is critical for capturing both long- and short-term preferences in industrial recommender systems. Existing solutions typically rely on two-stage retrieval or indirect modeling paradigms, incuring upstream-downstream inconsistency and computational inefficiency. In this paper, we present LONGER, a Long-sequence Optimized traNsformer for GPU-Efficient Recommenders. LONGER incorporates (i) a global token mechanism for stabilizing attention over long contexts, (ii) a token merge module with lightweight InnerTransformers and hybrid attention strategy to reduce quadratic complexity, and (iii) a series of engineering optimizations, including training with mixed-precision and activation recomputation, KV cache serving, and the fully synchronous model training and serving framework for unified GPU-based dense and sparse parameter updates. LONGER consistently outperforms strong baselines in both offline metrics and online A/B testing in both advertising and e-commerce services at ByteDance, validating its consistent effectiveness and industrial-level scaling laws. Currently, LONGER has been fully deployed at more than 10 influential scenarios at ByteDance, serving billion users.",
      "authors": [
        "Zheng Chai",
        "Qin Ren",
        "Xijun Xiao",
        "Huizhi Yang",
        "Bo Han",
        "Sijun Zhang",
        "Di Chen",
        "Hui Lu",
        "Wenlin Zhao",
        "Lele Yu",
        "Xionghang Xie",
        "Shiru Ren",
        "Xiang Sun",
        "Yaocheng Tan",
        "Peng Xu",
        "Yuchao Zheng",
        "Di Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T13:54:26+00:00",
          "link": "https://arxiv.org/abs/2505.04421v1",
          "size": "2241kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:29:47+00:00",
          "link": "https://arxiv.org/abs/2505.04421v2",
          "size": "423kb",
          "version": "v2"
        }
      ],
      "title": "LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04421",
        "HTML": "https://arxiv.org/html/2505.04421v2",
        "PDF": "https://arxiv.org/pdf/2505.04421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on sequence modeling in industrial recommender systems, introducing an optimized transformer model for long sequences. It does not involve LLM training data processing operations or contribute to dataset creation or quality improvement for LLMs."
      },
      "tasks": [
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05223",
      "abstract": "Human drivers exhibit individual preferences regarding driving style. Adapting autonomous vehicles to these preferences is essential for user trust and satisfaction. However, existing end-to-end driving approaches often rely on predefined driving styles or require continuous user feedback for adaptation, limiting their ability to support dynamic, context-dependent preferences. We propose a novel approach using multi-objective reinforcement learning (MORL) with preference-driven optimization for end-to-end autonomous driving that enables runtime adaptation to driving style preferences. Preferences are encoded as continuous weight vectors to modulate behavior along interpretable style objectives$\\unicode{x2013}$including efficiency, comfort, speed, and aggressiveness$\\unicode{x2013}$without requiring policy retraining. Our single-policy agent integrates vision-based perception in complex mixed-traffic scenarios and is evaluated in diverse urban environments using the CARLA simulator. Experimental results demonstrate that the agent dynamically adapts its driving behavior according to changing preferences while maintaining performance in terms of collision avoidance and route completion.",
      "authors": [
        "Hendrik Surmann",
        "Jorge de Heuvel",
        "Maren Bennewitz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T13:16:37+00:00",
          "link": "https://arxiv.org/abs/2505.05223v1",
          "size": "7832kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T15:16:10+00:00",
          "link": "https://arxiv.org/abs/2505.05223v2",
          "size": "7864kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Objective Reinforcement Learning for Adaptable Personalized Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05223",
        "HTML": "https://arxiv.org/html/2505.05223v2",
        "PDF": "https://arxiv.org/pdf/2505.05223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a multi-objective reinforcement learning approach for adaptable autonomous driving. It does not involve any LLM training data processing tasks, such as dataset creation or enhancement, related to LLM pretraining or fine-tuning."
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Collision Avoidance",
        "Multi-Objective Reinforcement Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08736",
      "abstract": "We present a (proto) Foundation Model for Nuclear Physics, capable of operating on low-level detector inputs from Imaging Cherenkov Detectors at the future Electron Ion Collider. Building upon established next-token prediction approaches, we aim to address potential challenges such as resolution loss from existing tokenization schemes and limited support for conditional generation. We propose four key innovations: (i) separate vocabularies for discrete and continuous variates, combined via Causal Multi-Head Cross-Attention (CMHCA), (ii) continuous kinematic conditioning through prepended context embeddings, (iii) scalable and simple, high-resolution continuous variate tokenization without joint vocabulary inflation, and (iv) class conditional generation through a Mixture of Experts. Our model enables fast, high-fidelity generation of pixel and time sequences for Cherenkov photons, validated through closure tests in the High Performance DIRC. We also show our model generalizes to reconstruction tasks such as pion/kaon identification, and noise filtering, in which we show its ability to leverage fine-tuning under specific objectives.",
      "authors": [
        "James Giroux and Cristiano Fanelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)",
        "Nuclear Experiment (nucl-ex)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T16:49:45+00:00",
          "link": "https://arxiv.org/abs/2505.08736v1",
          "size": "8677kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T04:25:41+00:00",
          "link": "https://arxiv.org/abs/2505.08736v2",
          "size": "5122kb",
          "version": "v2"
        }
      ],
      "title": "Towards Foundation Models for Experimental Readout Systems Combining Discrete and Continuous Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08736",
        "HTML": "https://arxiv.org/html/2505.08736v2",
        "PDF": "https://arxiv.org/pdf/2505.08736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a foundation model for nuclear physics, focusing on data from specific experimental setups and generation tasks, which is unrelated to LLM training data processing or LLMs in general."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/wmdataphys/FM4DIRC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12699",
      "abstract": "Multiwinner Elections have emerged as a prominent area of research with numerous practical applications. We contribute to this area by designing parameterized approximation algorithms and also resolving an open question by Yang and Wang [AAMAS'18]. More formally, given a set of candidates, \\mathcal{C}, a set of voters,\\mathcal{V}, approving a subset of candidates (called approval set of a voter), and an integer $k$, we consider the problem of selecting a ``good'' committee using Thiele rules. This problem is computationally challenging for most Thiele rules with monotone submodular satisfaction functions, as there is no (1-\\frac{1}{e}-\\epsilon)\\footnote{Here, $e$ denotes the base of the natural logarithm.}-approximation algorithm in f(k)(|\\mathcal{C}| + |\\mathcal{V}|)^{o(k)} time for any fixed $\\epsilon > 0$ and any computable function $f$, and no {\\sf PTAS} even when the length of approval set is two. Skowron [WINE'16] designed an approximation scheme running in FPT time parameterized by the combined parameter, size of the approval set and $k$. In this paper, we consider a parameter $d+k$ (no $d$ voters approve the same set of $d$ candidates), where $d$ is upper bounded by the size of the approval set (thus, can be much smaller).\n  With respect to this parameter, we design parameterized approximation schemes, a lossy polynomial-time preprocessing method, and show that an extra committee member suffices to achieve the desired score (i.e., $1$-additive approximation). Additionally, we resolve an open question by Yang and Wang~[AAMAS'18] regarding the fixed-parameter tractability of the problem under the PAV rule with the total score as the parameter, demonstrating that it admits an FPT algorithm.",
      "authors": [
        "Sushmita Gupta",
        "Pallavi Jain",
        "Souvik Saha",
        "Saket Saurabh",
        "Anannya Upasana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T04:41:47+00:00",
          "link": "https://arxiv.org/abs/2505.12699v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T06:00:16+00:00",
          "link": "https://arxiv.org/abs/2505.12699v2",
          "size": "37kb",
          "version": "v2"
        }
      ],
      "title": "More Efforts Towards Fixed-Parameter Approximability of Multiwinner Rules",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12699",
        "HTML": "https://arxiv.org/html/2505.12699v2",
        "PDF": "https://arxiv.org/pdf/2505.12699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with multiwinner elections and parameterized approximation algorithms, which are mathematical and computational problems unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.12723",
      "abstract": "Large language models (LLMs) achieve remarkable performance in code generation tasks. However, a significant performance disparity persists between popular programming languages (e.g., Python, C++) and others. To address this capability gap, we leverage the code translation task to train LLMs, thereby facilitating the transfer of coding proficiency across diverse programming languages. Moreover, we introduce OORL for training, a novel reinforcement learning (RL) framework that integrates on-policy and off-policy strategies. Within OORL, on-policy RL is applied during code translation, guided by a rule-based reward signal derived from unit tests. Complementing this coarse-grained rule-based reward, we propose Group Equivalent Preference Optimization (GEPO), a novel preference optimization method. Specifically, GEPO trains the LLM using intermediate representations (IRs) groups. LLMs can be guided to discern IRs equivalent to the source code from inequivalent ones, while also utilizing signals about the mutual equivalence between IRs within the group. This process allows LLMs to capture nuanced aspects of code functionality. By employing OORL for training with code translation tasks, LLMs improve their recognition of code functionality and their understanding of the relationships between code implemented in different languages. Extensive experiments demonstrate that our OORL for LLMs training with code translation tasks achieves significant performance improvements on code benchmarks across multiple programming languages.",
      "authors": [
        "Haoyuan Wu",
        "Rui Ming",
        "Jilong Gao",
        "Hangyu Zhao",
        "Xueyi Chen",
        "Yikai Yang",
        "Haisheng Zheng",
        "Zhuolun He",
        "Bei Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T05:25:29+00:00",
          "link": "https://arxiv.org/abs/2505.12723v1",
          "size": "245kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:43:12+00:00",
          "link": "https://arxiv.org/abs/2505.12723v2",
          "size": "120kb",
          "version": "v2"
        }
      ],
      "title": "On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12723",
        "HTML": "https://arxiv.org/html/2505.12723v2",
        "PDF": "https://arxiv.org/pdf/2505.12723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper focuses on improving LLM performance through on-policy optimization and code translation, it includes data processing aspects, like leveraging code translation tasks which contribute to the training data processing context."
      },
      "tasks": [
        "Code Generation",
        "Code Translation",
        "Reinforcement Learning (RL)",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.13916",
      "abstract": "Common remote sensing modalities (RGB, multispectral, hyperspectral imaging or LiDAR) are often used to indirectly measure crop health and do not directly capture plant stress indicators. Commercially available direct leaf sensors are bulky, powered electronics that are expensive and interfere with crop growth. In contrast, low-cost, passive and bio-degradable leaf sensors offer an opportunity to advance real-time monitoring as they directly interface with the crop surface while not interfering with crop growth. To this end, we co-design a sensor-detector system, where the sensor is a passive colorimetric leaf sensor that directly measures crop health in a precision agriculture setting, and the detector autonomously obtains optical signals from these leaf sensors. The detector comprises a low size weight and power (SWaP) mobile ground robot with an onboard monocular RGB camera and object detector to localize each leaf sensor, as well as a hyperspectral camera with a motorized mirror and halogen light to acquire hyperspectral images. The sensor's crop health-dependent optical signals can be extracted from the hyperspectral images. The proof-of-concept system is demonstrated in row-crop environments both indoors and outdoors where it is able to autonomously navigate, locate and obtain a hyperspectral image of all leaf sensors present, and acquire interpretable spectral resonance with 80 $\\%$ accuracy within a required retrieval distance from the sensor.",
      "authors": [
        "Malakhi Hopkins",
        "Alice Kate Li",
        "Shobhita Kramadhati",
        "Jackson Arnold",
        "Akhila Mallavarapu",
        "Chavez Lawrence",
        "Varun Murali",
        "Sanjeev J. Koppal",
        "Cherie R. Kagan",
        "Vijay Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T04:26:45+00:00",
          "link": "https://arxiv.org/abs/2505.13916v1",
          "size": "15955kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T06:12:42+00:00",
          "link": "https://arxiv.org/abs/2505.13916v2",
          "size": "18436kb",
          "version": "v2"
        }
      ],
      "title": "Robotic Monitoring of Colorimetric Leaf Sensors for Precision Agriculture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13916",
        "HTML": "https://arxiv.org/html/2505.13916v2",
        "PDF": "https://arxiv.org/pdf/2505.13916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on a robotic monitoring system for precision agriculture, dealing with crop health monitoring, which has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.14523",
      "abstract": "We make the case for language models over logical forms (LFLMs), arguing that such models are more data-efficient than their textual counterparts. To that end, we introduce the Graph-based Formal-Logical Distributional Semantics (GFoLDS) prototype, a pretrained LM over graph representations of logical forms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong experimental evidence that LFLMs can leverage the built-in, basic linguistic knowledge inherent in such models to immediately begin learning more complex patterns. On downstream tasks, we show that GFoLDS vastly outperforms textual, transformer LMs (BERT) pretrained on the same data, indicating that LFLMs can learn with substantially less data than models over plain text. Furthermore, we show that the performance of this model is likely to scale with additional parameters and pretraining data, suggesting the viability of LFLMs in real-world applications.",
      "authors": [
        "Michael Sullivan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T15:46:44+00:00",
          "link": "https://arxiv.org/abs/2505.14523v1",
          "size": "4443kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:03:24+00:00",
          "link": "https://arxiv.org/abs/2505.14523v2",
          "size": "4421kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Graph Representations of Logical Forms for Language Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14523",
        "HTML": "https://arxiv.org/html/2505.14523v2",
        "PDF": "https://arxiv.org/pdf/2505.14523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores language models over logical forms, concentrating on data efficiency and logical representations, which does not pertain to processing training data for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/mjs227/gfolds"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.16119",
      "abstract": "We consider the problem of single-channel audio source separation with the goal of reconstructing $K$ sources from their mixture. We address this ill-posed problem with FLOSS (FLOw matching for Source Separation), a constrained generation method based on flow matching, ensuring strict mixture consistency. Flow matching is a general methodology that, when given samples from two probability distributions defined on the same space, learns an ordinary differential equation to output a sample from one of the distributions when provided with a sample from the other. In our context, we have access to samples from the joint distribution of $K$ sources and so the corresponding samples from the lower-dimensional distribution of their mixture. To apply flow matching, we augment these mixture samples with artificial noise components to match the dimensionality of the $K$ source distribution. Additionally, as any permutation of the sources yields the same mixture, we adopt an equivariant formulation of flow matching which relies on a neural network architecture that is equivariant by design. We demonstrate the performance of the method for the separation of overlapping speech.",
      "authors": [
        "Robin Scheibler",
        "John R. Hershey",
        "Arnaud Doucet",
        "Henry Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T01:52:06+00:00",
          "link": "https://arxiv.org/abs/2505.16119v1",
          "size": "1348kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T00:23:27+00:00",
          "link": "https://arxiv.org/abs/2505.16119v2",
          "size": "1229kb",
          "version": "v2"
        }
      ],
      "title": "Source Separation by Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16119",
        "HTML": "https://arxiv.org/html/2505.16119v2",
        "PDF": "https://arxiv.org/pdf/2505.16119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the problem of single-channel audio source separation using flow matching, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.16195",
      "abstract": "Foley synthesis aims to synthesize high-quality audio that is both semantically and temporally aligned with video frames. Given its broad application in creative industries, the task has gained increasing attention in the research community. To avoid the non-trivial task of training audio generative models from scratch, adapting pretrained audio generative models for video-synchronized foley synthesis presents an attractive direction. ControlNet, a method for adding fine-grained controls to pretrained generative models, has been applied to foley synthesis, but its use has been limited to handcrafted human-readable temporal conditions. In contrast, from-scratch models achieved success by leveraging high-dimensional deep features extracted using pretrained video encoders. We have observed a performance gap between ControlNet-based and from-scratch foley models. To narrow this gap, we propose SpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward video-synchronized foley synthesis via ControlNet. To unlock the potential of a single ControlNet branch, we resolve the discrepancy between the temporal video features and the time-frequency nature of the pretrained SpecMaskGIT via a frequency-aware temporal feature aligner, eliminating the need for complicated conditioning mechanisms widely used in prior arts. Evaluations on a common foley synthesis benchmark demonstrate that SpecMaskFoley could even outperform strong from-scratch baselines, substantially advancing the development of ControlNet-based foley synthesis models. Demo page: https://zzaudio.github.io/SpecMaskFoley_Demo/",
      "authors": [
        "Zhi Zhong",
        "Akira Takahashi",
        "Shuyang Cui",
        "Keisuke Toyama",
        "Shusuke Takahashi",
        "Yuki Mitsufuji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T03:58:16+00:00",
          "link": "https://arxiv.org/abs/2505.16195v1",
          "size": "280kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:01:00+00:00",
          "link": "https://arxiv.org/abs/2505.16195v2",
          "size": "298kb",
          "version": "v2"
        }
      ],
      "title": "SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16195",
        "HTML": "https://arxiv.org/html/2505.16195v2",
        "PDF": "https://arxiv.org/pdf/2505.16195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on steering pretrained audio generative models for video-synchronized foley synthesis, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Audio Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17735",
      "abstract": "Large Language Model (LLM)-based agents are increasingly deployed in real-world applications such as \"digital assistants, autonomous customer service, and decision-support systems\", where their ability to \"interact in multi-turn, tool-augmented environments\" makes them indispensable. However, ensuring the safety of these agents remains a significant challenge due to the diverse and complex risks arising from dynamic user interactions, external tool usage, and the potential for unintended harmful behaviors. To address this critical issue, we propose AutoSafe, the first framework that systematically enhances agent safety through fully automated synthetic data generation. Concretely, 1) we introduce an open and extensible threat model, OTS, which formalizes how unsafe behaviors emerge from the interplay of user instructions, interaction contexts, and agent actions. This enables precise modeling of safety risks across diverse scenarios. 2) we develop a fully automated data generation pipeline that simulates unsafe user behaviors, applies self-reflective reasoning to generate safe responses, and constructs a large-scale, diverse, and high-quality safety training dataset-eliminating the need for hazardous real-world data collection. To evaluate the effectiveness of our framework, we design comprehensive experiments on both synthetic and real-world safety benchmarks. Results demonstrate that AutoSafe boosts safety scores by 45% on average and achieves a 28.91% improvement on real-world tasks, validating the generalization ability of our learned safety strategies. These results highlight the practical advancement and scalability of AutoSafe in building safer LLM-based agents for real-world deployment. We have released the project page at https://auto-safe.github.io/.",
      "authors": [
        "Xueyang Zhou",
        "Weidong Wang",
        "Lin Lu",
        "Jiawen Shi",
        "Guiyao Tie",
        "Yongtian Xu",
        "Lixing Chen",
        "Pan Zhou",
        "Neil Zhenqiang Gong",
        "Lichao Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T10:56:06+00:00",
          "link": "https://arxiv.org/abs/2505.17735v1",
          "size": "911kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:34:40+00:00",
          "link": "https://arxiv.org/abs/2505.17735v2",
          "size": "914kb",
          "version": "v2"
        }
      ],
      "title": "SafeAgent: Safeguarding LLM Agents via an Automated Risk Simulator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17735",
        "PDF": "https://arxiv.org/pdf/2505.17735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes AutoSafe, which includes a synthetic data generation pipeline for safety training datasets. Although it involves data generation, its main focus is on enhancing agent safety, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18879",
      "abstract": "``Randomness recycling'' is a powerful algorithmic technique for reusing a fraction of the random information consumed by a probabilistic algorithm to reduce its entropy requirements. This article presents a family of randomness recycling algorithms for efficiently sampling a sequence $X_1, X_2, X_3, \\dots$ of discrete random variables whose joint distribution follows an arbitrary stochastic process. We develop randomness recycling techniques to reduce the entropy cost of a variety of prominent sampling algorithms, which include uniform sampling, inverse transform sampling, lookup-table sampling, alias sampling, and discrete distribution generating (DDG) tree sampling. Our method achieves an expected amortized entropy cost of $H(X_1,\\dots,X_k)/k + \\varepsilon$ input bits per output sample using $O(\\log(1/\\varepsilon))$ space as $k\\to\\infty$, which is arbitrarily close to the optimal Shannon entropy rate of $H(X_1,\\dots,X_k)/k$ bits per sample. The combination of space, time, and entropy properties of our method improves upon the Knuth and Yao entropy-optimal algorithm and Han and Hoshi interval algorithm for sampling a discrete random sequence.\n  On the empirical side, we show that randomness recycling enables state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator; and it can also speed up discrete Gaussian samplers. Accompanying the manuscript is a performant software library in the C programming language that uses randomness recycling to accelerate several existing algorithms for random sampling.",
      "authors": [
        "Thomas L. Draper",
        "Feras A. Saad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T21:34:08+00:00",
          "link": "https://arxiv.org/abs/2505.18879v1",
          "size": "228kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T18:39:50+00:00",
          "link": "https://arxiv.org/abs/2505.18879v2",
          "size": "7499kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Online Random Sampling via Randomness Recycling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18879",
        "PDF": "https://arxiv.org/pdf/2505.18879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on randomness recycling techniques for sampling algorithms, without discussing LLM training data processing or relevant data engineering operations."
      },
      "repo_urls": [
        "https://github.com/probsys/randomness-recycling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19068",
      "abstract": "Recalibration of binary probabilistic classifiers to a target prior probability is an important task in areas like credit risk management. We analyse methods for recalibration from a distribution shift perspective. Distribution shift assumptions linked to the area under the curve (AUC) of a probabilistic classifier are found to be useful for the design of meaningful recalibration methods. Two new methods called parametric covariate shift with posterior drift (CSPD) and ROC-based quasi moment matching (QMM) are proposed and tested together with some other methods in an example setting. The outcomes of the test suggest that the QMM methods discussed in the paper can provide appropriately conservative results in evaluations with concave functionals like for instance risk weights functions for credit risk.",
      "authors": [
        "Dirk Tasche"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Risk Management (q-fin.RM)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T10:04:46+00:00",
          "link": "https://arxiv.org/abs/2505.19068v1",
          "size": "68kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:30:13+00:00",
          "link": "https://arxiv.org/abs/2505.19068v2",
          "size": "69kb",
          "version": "v2"
        }
      ],
      "title": "Recalibrating binary probabilistic classifiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19068",
        "HTML": "https://arxiv.org/html/2505.19068v2",
        "PDF": "https://arxiv.org/pdf/2505.19068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores recalibration methods for binary probabilistic classifiers with a focus on credit risk management, not related to LLM training data processing or any data engineering operations."
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19291",
      "abstract": "Text-embedded image generation plays a critical role in industries such as graphic design, advertising, and digital content creation. Text-to-Image generation methods leveraging diffusion models, such as TextDiffuser-2, have demonstrated promising results in producing images with embedded text. TextDiffuser-2 effectively generates bounding box layouts that guide the rendering of visual text, achieving high fidelity and coherence. However, existing approaches often rely on resource-intensive processes and are limited in their ability to run efficiently on both CPU and GPU platforms. To address these challenges, we propose a novel two-stage pipeline that integrates reinforcement learning (RL) for rapid and optimized text layout generation with a diffusion-based image synthesis model. Our RL-based approach significantly accelerates the bounding box prediction step while reducing overlaps, allowing the system to run efficiently on both CPUs and GPUs. Extensive evaluations demonstrate that our framework maintains or surpasses TextDiffuser-2's quality in text placement and image synthesis, with markedly faster runtime and increased flexibility. Extensive evaluations demonstrate that our framework maintains or surpasses TextDiffuser-2's quality in text placement and image synthesis, with markedly faster runtime and increased flexibility. Our approach has been evaluated on the MARIOEval benchmark, achieving OCR and CLIPScore metrics close to state-of-the-art models, while being 97.64% more faster and requiring only 2MB of memory to run.",
      "authors": [
        "Kazi Mahathir Rahman",
        "Showrin Rahman",
        "Sharmin Sultana Srishty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T19:52:04+00:00",
          "link": "https://arxiv.org/abs/2505.19291v1",
          "size": "658kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T18:39:52+00:00",
          "link": "https://arxiv.org/abs/2505.19291v2",
          "size": "659kb",
          "version": "v2"
        }
      ],
      "title": "TextDiffuser-RL: Efficient and Robust Text Layout Optimization for High-Fidelity Text-to-Image Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19291",
        "HTML": "https://arxiv.org/html/2505.19291v2",
        "PDF": "https://arxiv.org/pdf/2505.19291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses text layout optimization and text-to-image synthesis using diffusion models and reinforcement learning, without discussing LLM training data processing or relevant data operations."
      },
      "tasks": [
        "Image Generation",
        "Layout Generation",
        "Optical Character Recognition (OCR)",
        "Reinforcement Learning (RL)",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19688",
      "abstract": "Reactive intelligence remains one of the cornerstones of versatile robotics operating in cluttered, dynamic, and human-centred environments. Among reactive approaches, potential fields (PF) continue to be widely adopted due to their simplicity and real-time applicability. However, existing PF methods typically oversimplify environmental representations by relying on isotropic, point- or sphere-based obstacle approximations. In human-centred settings, this simplification results in overly conservative paths, cumbersome tuning, and computational overhead -- even breaking real-time requirements. In response, we propose the Geometric Potential Field (GeoPF), a reactive motion-planning framework that explicitly infuses geometric primitives -- points, lines, planes, cubes, and cylinders -- their structure and spatial relationship in modulating the real-time repulsive response. Extensive quantitative analyses consistently show GeoPF's higher success rates, reduced tuning complexity (a single parameter set across experiments), and substantially lower computational costs (up to 2 orders of magnitude) compared to traditional PF methods. Real-world experiments further validate GeoPF reliability, robustness, and practical ease of deployment, as well as its scalability to whole-body avoidance. GeoPF provides a fresh perspective on reactive planning problems driving geometric-aware temporal motion generation, enabling flexible and low-latency motion planning suitable for modern robotic applications.",
      "authors": [
        "Yuhe Gong",
        "Riddhiman Laha",
        "Luis Figueredo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T08:49:06+00:00",
          "link": "https://arxiv.org/abs/2505.19688v1",
          "size": "3091kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T10:36:52+00:00",
          "link": "https://arxiv.org/abs/2505.19688v2",
          "size": "4690kb",
          "version": "v2"
        }
      ],
      "title": "GeoPF: Infusing Geometry into Potential Fields for Reactive Planning in Non-trivial Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19688",
        "HTML": "https://arxiv.org/html/2505.19688v2",
        "PDF": "https://arxiv.org/pdf/2505.19688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper pertains to reactive motion planning in robotics using geometric potential fields, which is not related to LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20015",
      "abstract": "Here we present a new class of optimality for coding systems. Members of that class are displaced linearly from optimal coding and thus exhibit Zipf's law, namely a power-law distribution of frequency ranks. Within that class, Zipf's law, the size-rank law and the size-probability law form a group-like structure. We identify human languages that are members of the class. All languages showing sufficient agreement with Zipf's law are potential members of the class. In contrast, there are communication systems in other species that cannot be members of that class for exhibiting an exponential distribution instead but dolphins and humpback whales might. We provide a new insight into plots of frequency versus rank in double logarithmic scale. For any system, a straight line in that scale indicates that the lengths of optimal codes under non-singular coding and under uniquely decodable encoding are displaced by a linear function whose slope is the exponent of Zipf's law. For systems under compression and constrained to be uniquely decodable, such a straight line may indicate that the system is coding close to optimality. We provide support for the hypothesis that Zipf's law originates from compression and define testable conditions for the emergence of Zipf's law in compressing systems.",
      "authors": [
        "Ramon Ferrer-i-Cancho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T14:05:45+00:00",
          "link": "https://arxiv.org/abs/2505.20015v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T17:00:20+00:00",
          "link": "https://arxiv.org/abs/2505.20015v2",
          "size": "22kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T11:35:43+00:00",
          "link": "https://arxiv.org/abs/2505.20015v3",
          "size": "23kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T14:57:19+00:00",
          "link": "https://arxiv.org/abs/2505.20015v4",
          "size": "24kb",
          "version": "v4"
        }
      ],
      "title": "On the class of coding optimality of human languages and the origins of Zipf's law",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20015",
        "HTML": "https://arxiv.org/html/2505.20015v4",
        "PDF": "https://arxiv.org/pdf/2505.20015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimality in coding systems and Zipf's law, focusing on linguistic patterns rather than LLM training data processing or related data engineering operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.20839",
      "abstract": "As large language models become increasingly prevalent, memory bandwidth constraints significantly limit inference throughput, motivating post-training quantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ framework and an INT4-FP8 matrix multiplication kernel that accelerates LLM inference across all linear layers. Specifically, FireQ quantizes linear layer weights and key-values to INT4, and activations and queries to FP8, significantly enhancing throughput. Additionally, we introduce a three-stage pipelining for the prefill phase, which modifies the FlashAttention-3 kernel, effectively reducing time-to-first-token in the prefill phase. To minimize accuracy loss from quantization, we develop novel outlier smoothing techniques tailored separately for linear and attention layers. In linear layers, we explicitly use per-tensor scaling to prevent underflow caused by the FP8 quantization scaling factor of INT4 quantization, and channel-wise scaling to compensate for coarse granularity of INT4. In attention layers, we address quantization challenges posed by rotary positional embeddings (RoPE) by combining pre-RoPE and post-RoPE scaling strategies. FireQ significantly outperforms state-of-the-art methods, achieving 1.68x faster inference in feed-forward network layers on Llama2-7B and 1.26x faster prefill phase performance on Llama3-8B compared to QServe, with negligible accuracy loss.",
      "authors": [
        "Daehyeon Baek",
        "Jieun Choi",
        "Jimyoung Son",
        "Kyungmin Bin",
        "Seungbeom Choi",
        "Kihyo Moon",
        "Minsung Jang",
        "Hyojung Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T07:58:35+00:00",
          "link": "https://arxiv.org/abs/2505.20839v1",
          "size": "3268kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T12:51:23+00:00",
          "link": "https://arxiv.org/abs/2505.20839v2",
          "size": "3268kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T06:15:50+00:00",
          "link": "https://arxiv.org/abs/2505.20839v3",
          "size": "3144kb",
          "version": "v3"
        }
      ],
      "title": "FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20839",
        "HTML": "https://arxiv.org/html/2505.20839v3",
        "PDF": "https://arxiv.org/pdf/2505.20839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on accelerating LLM inference through quantization techniques, not on training data processing. Its contribution is primarily in model optimization for inference rather than data-related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.21986",
      "abstract": "Logically constrained term rewriting is a rewriting framework that supports built-in data structures such as integers and bit vectors. Recently, constrained terms play a key role in various analyses and applications of logically constrained term rewriting. A fundamental question on constrained terms arising there is how to characterize equivalence between them. However, in the current literature only limited progress has been made on this. In this paper, we provide several sound and complete solutions to tackle this problem. Our key idea is the introduction of a novel concept, namely existentially constrained terms, into which the original form of constrained terms can be embedded. We present several syntactic characterizations of equivalence between existentially constrained terms. In particular, we provide two different kinds of complete characterizations: one is designed to facilitate equivalence checking, while the other is intended for theoretical analysis.",
      "authors": [
        "Kanta Takahata and Jonas Sch\\\"opf and Naoki Nishida and Takahito Aoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T05:23:50+00:00",
          "link": "https://arxiv.org/abs/2505.21986v1",
          "size": "93kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:25:39+00:00",
          "link": "https://arxiv.org/abs/2505.21986v2",
          "size": "67kb",
          "version": "v2"
        }
      ],
      "title": "Characterizing Equivalence of Logically Constrained Terms via Existentially Constrained Terms (Full Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21986",
        "HTML": "https://arxiv.org/html/2505.21986v2",
        "PDF": "https://arxiv.org/pdf/2505.21986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with logically constrained term rewriting and equivalence checking, which is unrelated to LLM training data processing. It addresses theoretical computational structures rather than data."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.22987",
      "abstract": "By late 20th century, the rationality wars had launched debates about the nature and norms of intuitive and reflective thinking. Those debates drew from mid-20th century ideas such as bounded rationality, which challenged more idealized notions of rationality observed since the 19th century. Now that 21st century cognitive scientists are applying the resulting dual pro-cess theories to artificial intelligence, it is time to dust off some lessons from this history. So this paper synthesizes old ideas with recent results from experiments on humans and machines. The result is Strategic Reflec-tivism, the position that one key to intelligent systems (human or artificial) is pragmatic switching between intuitive and reflective inference to opti-mally fulfill competing goals. Strategic Reflectivism builds on American Pragmatism, transcends superficial indicators of reflective thinking such as model size or chains of thought, applies to both individual and collective intelligence systems (including human-AI teams), and becomes increasingly actionable as we learn more about the value of intuition and reflection.",
      "authors": [
        "Nick Byrd"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T01:51:20+00:00",
          "link": "https://arxiv.org/abs/2505.22987v1",
          "size": "1348kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T20:04:13+00:00",
          "link": "https://arxiv.org/abs/2505.22987v2",
          "size": "1773kb",
          "version": "v2"
        }
      ],
      "title": "Strategic Reflectivism In Intelligent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22987",
        "PDF": "https://arxiv.org/pdf/2505.22987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores a framework called Strategic Reflectivism for intelligent systems using dual process theories, focusing on cognitive approaches rather than any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.01487",
      "abstract": "Dynamic scene graph generation extends scene graph generation from images to videos by modeling entity relationships and their temporal evolution. However, existing methods either generate scene graphs from observed frames without explicitly modeling temporal dynamics, or predict only relationships while assuming static entity labels and locations. These limitations hinder effective extrapolation of both entity and relationship dynamics, restricting video scene understanding. We propose Forecasting Dynamic Scene Graphs (FDSG), a novel framework that predicts future entity labels, bounding boxes, and relationships, for unobserved frames, while also generating scene graphs for observed frames. Our scene graph forecast module leverages query decomposition and neural stochastic differential equations to model entity and relationship dynamics. A temporal aggregation module further refines predictions by integrating forecasted and observed information via cross-attention. To benchmark FDSG, we introduce Scene Graph Forecasting, a new task for full future scene graph prediction. Experiments on Action Genome show that FDSG outperforms state-of-the-art methods on dynamic scene graph generation, scene graph anticipation, and scene graph forecasting. Codes will be released upon publication.",
      "authors": [
        "Yi Yang",
        "Yuren Cong",
        "Hao Cheng",
        "Bodo Rosenhahn",
        "Michael Ying Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T09:46:22+00:00",
          "link": "https://arxiv.org/abs/2506.01487v1",
          "size": "14831kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:05:43+00:00",
          "link": "https://arxiv.org/abs/2506.01487v2",
          "size": "14769kb",
          "version": "v2"
        }
      ],
      "title": "FDSG: Forecasting Dynamic Scene Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01487",
        "HTML": "https://arxiv.org/html/2506.01487v2",
        "PDF": "https://arxiv.org/pdf/2506.01487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on modeling dynamic scene graphs in the context of video data, and does not address processing operations related to LLM training data for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01551",
      "abstract": "Building Vision-Language Navigation (VLN) agents which can navigate following natural language instructions is a long-standing goal in human-robot interaction applications. Recent studies have revealed the potential of training open-source Large Language Models (LLMs) to unleash LLMs' reasoning ability for improving navigation, and simultaneously mitigate the domain gap between LLMs' training corpus and the VLN task. However, these approaches primarily adopt direct input-output mapping paradigms, causing the mapping learning difficult and the navigational decisions unexplainable. Chain-of-Thought (CoT) training is a promising way to improve both navigational decision accuracy and interpretability, while the complexity of the navigation task makes the perfect CoT labels unavailable and may lead to overfitting through pure CoT supervised fine-tuning. In this paper, we propose a novel sElf-improving embodied reasoning framework for boosting LLM-based vision-language Navigation, dubbed EvolveNav. Our EvolveNav consists of two stages: (1) Formalized CoT Supervised Fine-Tuning, where we train the model with formalized CoT labels to both activate the model's navigational reasoning capabilities and increase the reasoning speed; (2) Self-Reflective Post-Training, where the model is iteratively trained with its own reasoning outputs as self-enriched CoT labels to enhance the supervision diversity. A self-reflective auxiliary task is also introduced to encourage learning correct reasoning patterns by contrasting with wrong ones. Experimental results on the popular VLN benchmarks demonstrate the superiority of EvolveNav over previous LLM-based VLN approaches. Code is available at https://github.com/expectorlin/EvolveNav.",
      "authors": [
        "Bingqian Lin",
        "Yunshuang Nie",
        "Khun Loun Zai",
        "Ziming Wei",
        "Mingfei Han",
        "Rongtao Xu",
        "Minzhe Niu",
        "Jianhua Han",
        "Liang Lin",
        "Cewu Lu",
        "Xiaodan Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T11:28:32+00:00",
          "link": "https://arxiv.org/abs/2506.01551v1",
          "size": "1156kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T03:23:12+00:00",
          "link": "https://arxiv.org/abs/2506.01551v2",
          "size": "1156kb",
          "version": "v2"
        }
      ],
      "title": "EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01551",
        "HTML": "https://arxiv.org/html/2506.01551v2",
        "PDF": "https://arxiv.org/pdf/2506.01551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus of this paper is on improving vision-language navigation with CoT and self-reflective strategies, it partially touches on training LLMs through formalized CoT supervised fine-tuning, which involves a degree of data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03221",
      "abstract": "As the volume of scientific literature grows, efficient knowledge organization becomes increasingly challenging. Traditional approaches to structuring scientific content are time-consuming and require significant domain expertise, highlighting the need for tool support. We present ExtracTable, a Human-in-the-Loop (HITL) workflow and framework that assists researchers in transforming unstructured publications into structured representations. The workflow combines large language models (LLMs) with user-defined schemas and is designed for downstream integration into knowledge graphs (KGs). Developed and evaluated in the context of the Open Research Knowledge Graph (ORKG), ExtracTable automates key steps such as document preprocessing and data extraction while ensuring user oversight through validation. In an evaluation with ORKG community participants following the Quality Improvement Paradigm (QIP), ExtracTable demonstrated high usability and practical value. Participants gave it an average System Usability Scale (SUS) score of 84.17 (A+, the highest rating). The time to progress from a research interest to literature-based insights was reduced from between 4 hours and 2 weeks to an average of 24:40 minutes. By streamlining corpus creation and structured data extraction for knowledge graph integration, ExtracTable leverages LLMs and user models to accelerate literature reviews. However, human validation remains essential to ensure quality, and future work will address improving extraction accuracy and entity linking to existing knowledge resources.",
      "authors": [
        "Lena John",
        "Ahmed Malek Ghanmi",
        "Tim Wittenborg",
        "S\\\"oren Auer",
        "Oliver Karras"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T09:12:52+00:00",
          "link": "https://arxiv.org/abs/2506.03221v1",
          "size": "1314kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T08:46:19+00:00",
          "link": "https://arxiv.org/abs/2506.03221v2",
          "size": "693kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T09:35:18+00:00",
          "link": "https://arxiv.org/abs/2506.03221v3",
          "size": "701kb",
          "version": "v3"
        }
      ],
      "title": "ExtracTable: Human-in-the-Loop Transformation of Scientific Corpora into Structured Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03221",
        "HTML": "https://arxiv.org/html/2506.03221v3",
        "PDF": "https://arxiv.org/pdf/2506.03221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the transformation of unstructured publications into structured data using LLMs as part of the workflow for knowledge graph enrichment. While it involves data processing, the focus is not directly on LLM pretraining or fine-tuning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.06941",
      "abstract": "Recent generations of language models have introduced Large Reasoning Models (LRMs) that generate detailed thinking processes before providing answers. While these models demonstrate improved performance on reasoning benchmarks, their fundamental capabilities, scaling properties, and limitations remain insufficiently understood. Current evaluations primarily focus on established math and coding benchmarks, emphasizing final answer accuracy. However, this evaluation paradigm often suffers from contamination and does not provide insights into the reasoning traces. In this work, we systematically investigate these gaps with the help of controllable puzzle environments that allow precise manipulation of complexity while maintaining consistent logical structures. This setup enables the analysis of not only final answers but also the internal reasoning traces, offering insights into how LRMs think. Through extensive experiments, we show that LRMs face a complete accuracy collapse beyond certain complexities. Moreover, they exhibit a counterintuitive scaling limit: their reasoning effort increases with problem complexity up to a point, then declines despite having remaining token budget. By comparing LRMs with their standard LLM counterparts under same inference compute, we identify three performance regimes: (1) low-complexity tasks where standard models outperform LRMs, (2) medium-complexity tasks where LRMs demonstrates advantage, and (3) high-complexity tasks where both models face complete collapse. We found that LRMs have limitations in exact computation: they fail to use explicit algorithms and reason inconsistently across scales. We also investigate the reasoning traces in more depth, studying the patterns of explored solutions and analyzing the models' computational behavior, shedding light on their strengths, limitations, and raising questions about their reasoning capabilities.",
      "authors": [
        "Parshin Shojaee",
        "Iman Mirzadeh",
        "Keivan Alizadeh",
        "Maxwell Horton",
        "Samy Bengio",
        "Mehrdad Farajtabar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T22:42:29+00:00",
          "link": "https://arxiv.org/abs/2506.06941v1",
          "size": "12102kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T04:14:22+00:00",
          "link": "https://arxiv.org/abs/2506.06941v2",
          "size": "11640kb",
          "version": "v2"
        }
      ],
      "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06941",
        "PDF": "https://arxiv.org/pdf/2506.06941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on understanding reasoning models via problem complexity rather than training data processing for LLMs, with no discussion on dataset creation, data quality improvement, or data engineering."
      },
      "tasks": [
        "Math"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08514",
      "abstract": "Class Activation Mapping (CAM) and its gradient-based variants (e.g., GradCAM) have become standard tools for explaining Convolutional Neural Network (CNN) predictions. However, these approaches typically focus on individual logits, while for neural networks using softmax, the class membership probability estimates depend \\textit{only} on the \\textit{differences} between logits, not on their absolute values. This disconnect leaves standard CAMs vulnerable to adversarial manipulation, such as passive fooling, where a model is trained to produce misleading CAMs without affecting decision performance. We introduce \\textbf{Salience-Hoax Activation Maps (SHAMs)}, an \\emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM robustness under adversarial conditions. To address the passive fooling vulnerability, we then propose \\textbf{DiffGradCAM}, a novel, lightweight, and contrastive approach to class activation mapping that is both non-suceptible to passive fooling, but also matches the output of standard CAM methods such as GradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a new framework for probing and improving the robustness of saliency-based explanations. We validate both contributions across multi-class tasks with few and many classes.",
      "authors": [
        "Jacob Piland",
        "Chris Sweet",
        "Adam Czajka"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T07:31:01+00:00",
          "link": "https://arxiv.org/abs/2506.08514v1",
          "size": "4654kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T10:39:51+00:00",
          "link": "https://arxiv.org/abs/2506.08514v2",
          "size": "4654kb",
          "version": "v2"
        }
      ],
      "title": "DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08514",
        "HTML": "https://arxiv.org/html/2506.08514v2",
        "PDF": "https://arxiv.org/pdf/2506.08514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces methods for improving robustness of class activation maps in CNN models. It does not involve LLMs or contributions to training data processing for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.09046",
      "abstract": "Leveraging multiple Large Language Models(LLMs) has proven effective for addressing complex, high-dimensional tasks, but current approaches often rely on static, manually engineered multi-agent configurations. To overcome these constraints, we present the Agentic Neural Network(ANN), a framework that conceptualizes multi-agent collaboration as a layered neural network architecture. In this design, each agent operates as a node, and each layer forms a cooperative \"team\" focused on a specific subtask. Agentic Neural Network follows a two-phase optimization strategy: (1) Forward Phase-Drawing inspiration from neural network forward passes, tasks are dynamically decomposed into subtasks, and cooperative agent teams with suitable aggregation methods are constructed layer by layer. (2) Backward Phase-Mirroring backpropagation, we refine both global and local collaboration through iterative feedback, allowing agents to self-evolve their roles, prompts, and coordination. This neuro-symbolic approach enables ANN to create new or specialized agent teams post-training, delivering notable gains in accuracy and adaptability. Across four benchmark datasets, ANN surpasses leading multi-agent baselines under the same configurations, showing consistent performance improvements. Our findings indicate that ANN provides a scalable, data-driven framework for multi-agent systems, combining the collaborative capabilities of LLMs with the efficiency and flexibility of neural network principles. We plan to open-source the entire framework.",
      "authors": [
        "Xiaowen Ma",
        "Chenyang Lin",
        "Yao Zhang",
        "Volker Tresp",
        "Yunpu Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T17:59:21+00:00",
          "link": "https://arxiv.org/abs/2506.09046v1",
          "size": "4613kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:52:19+00:00",
          "link": "https://arxiv.org/abs/2506.09046v2",
          "size": "4621kb",
          "version": "v2"
        }
      ],
      "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09046",
        "PDF": "https://arxiv.org/pdf/2506.09046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presents a multi-agent system framework for LLM collaboration in complex tasks, focusing on agent coordination rather than any aspect of data processing relevant to LLM training or fine-tuning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.09288",
      "abstract": "In recent years, a new line of work in fair allocation has focused on EFX allocations for \\((p, q)\\)-bounded valuations, where each good is relevant to at most \\(p\\) agents, and any pair of agents share at most \\(q\\) relevant goods. For the case \\(p = 2\\) and \\(q = \\infty\\), such instances can be equivalently represented as multigraphs whose vertices are the agents and whose edges represent goods, each edge incident to exactly the one or two agents for whom the good is relevant. A recent result of \\citet{amanatidis2024pushing} shows that for additive $(2,\\infty)$ bounded valuations, a \\((\\nicefrac{2}{3})\\)-EFX allocation always exists. In this paper, we improve this bound by proving the existence of a \\((\\nicefrac{1}{\\sqrt{2}})\\)-\\(\\efx\\) allocation for additive \\((2,\\infty)\\)-bounded valuations.",
      "authors": [
        "Alireza Kaviani",
        "Alireza Keshavarz",
        "Masoud Seddighin and AmirMohammad Shahrezaei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T22:56:49+00:00",
          "link": "https://arxiv.org/abs/2506.09288v1",
          "size": "767kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T04:02:33+00:00",
          "link": "https://arxiv.org/abs/2506.09288v2",
          "size": "767kb",
          "version": "v2"
        }
      ],
      "title": "Improved Approximate EFX Guarantees for Multigraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09288",
        "HTML": "https://arxiv.org/html/2506.09288v2",
        "PDF": "https://arxiv.org/pdf/2506.09288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on EFX allocations and multigraphs for fair allocation problems, with no mention or relation to LLM training data processing or any data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.11571",
      "abstract": "Recent extensive works have demonstrated that by introducing long CoT, the capabilities of MLLMs to solve complex problems can be effectively enhanced. However, the reasons for the effectiveness of such paradigms remain unclear. It is challenging to analysis with quantitative results how much the model's specific extraction of visual cues and its subsequent so-called reasoning during inference process contribute to the performance improvements. Therefore, evaluating the faithfulness of MLLMs' reasoning to visual information is crucial. To address this issue, we first present a cue-driven automatic and controllable editing pipeline with the help of GPT-Image-1. It enables the automatic and precise editing of specific visual cues based on the instruction. Furthermore, we introduce VFaith-Bench, the first benchmark to evaluate MLLMs' visual reasoning capabilities and analyze the source of such capabilities with an emphasis on the visual faithfulness. Using the designed pipeline, we constructed comparative question-answer pairs by altering the visual cues in images that are crucial for solving the original reasoning problem, thereby changing the question's answer. By testing similar questions with images that have different details, the average accuracy reflects the model's visual reasoning ability, while the difference in accuracy before and after editing the test set images effectively reveals the relationship between the model's reasoning ability and visual perception. We further designed specific metrics to expose this relationship. VFaith-Bench includes 755 entries divided into five distinct subsets, along with an additional human-labeled perception task. We conducted in-depth testing and analysis of existing mainstream flagship models and prominent open-source model series/reasoning models on VFaith-Bench, further investigating the underlying factors of their reasoning capabilities.",
      "authors": [
        "Jiachen Yu",
        "Yufei Zhan",
        "Ziheng Wu",
        "Yousong Zhu",
        "Jinqiao Wang",
        "Minghui Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T08:27:45+00:00",
          "link": "https://arxiv.org/abs/2506.11571v1",
          "size": "10433kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:23:14+00:00",
          "link": "https://arxiv.org/abs/2506.11571v2",
          "size": "9691kb",
          "version": "v2"
        }
      ],
      "title": "VFaith: Do Large Multimodal Models Really Reason on Seen Images Rather than Previous Memories?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11571",
        "HTML": "https://arxiv.org/html/2506.11571v2",
        "PDF": "https://arxiv.org/pdf/2506.11571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a benchmark for evaluating multimodal models' reasoning abilities, which involves dataset creation. However, its primary focus is not on LLM training data processing but on multimodal reasoning evaluation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12193",
      "abstract": "Linear codes correcting one deletions have rate at most $1/2$. In this paper, we construct linear list decodable codes correcting edits with rate approaching $1$ and reasonable list size. Our encoder and decoder run in polynomial time.",
      "authors": [
        "Yuting Li",
        "Ryan Gabrys",
        "Farzad Farnoud"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T19:42:38+00:00",
          "link": "https://arxiv.org/abs/2506.12193v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T10:53:57+00:00",
          "link": "https://arxiv.org/abs/2506.12193v2",
          "size": "26kb",
          "version": "v2"
        }
      ],
      "title": "Linear List Decodable Edit-Correcting Codes with Rate Approaching $1$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12193",
        "HTML": "https://arxiv.org/html/2506.12193v2",
        "PDF": "https://arxiv.org/pdf/2506.12193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses linear list decodable codes and does not contribute to LLM training data processing or any relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12764",
      "abstract": "Dynamic link prediction remains a central challenge in temporal graph learning, particularly in designing models that are both effective and practical for real-world deployment. Existing approaches often rely on complex neural architectures, which are computationally intensive and difficult to interpret.\n  In this work, we build on the strong recurrence-based foundation of the EdgeBank baseline, by supplementing it with inductive capabilities. We do so by leveraging the predictive power of non-learnable signals from two complementary perspectives: historical edge recurrence, as captured by EdgeBank, and global node popularity, as introduced in the PopTrack model. We propose t-CoMem, a lightweight memory module that tracks temporal co-occurrence patterns and neighborhood activity. Building on this, we introduce Base3, an interpolation-based model that fuses EdgeBank, PopTrack, and t-CoMem into a unified scoring framework. This combination effectively bridges local and global temporal dynamics -- repetition, popularity, and context -- without relying on training. Evaluated on the Temporal Graph Benchmark, Base3 achieves performance competitive with state-of-the-art deep models, even outperforming them on some datasets. Importantly, it considerably improves on existing baselines' performance under more realistic and challenging negative sampling strategies -- offering a simple yet robust alternative for temporal graph learning.",
      "authors": [
        "Kondrup Emma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T08:07:36+00:00",
          "link": "https://arxiv.org/abs/2506.12764v1",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T18:12:29+00:00",
          "link": "https://arxiv.org/abs/2506.12764v2",
          "size": "52kb",
          "version": "v2"
        }
      ],
      "title": "Base3: a simple interpolation-based ensemble method for robust dynamic link prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12764",
        "PDF": "https://arxiv.org/pdf/2506.12764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method for dynamic link prediction in temporal graph learning, not addressing LLM training data processing or related data preparation and engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13107",
      "abstract": "Causal forests estimate how treatment effects vary across individuals, guiding personalized interventions in areas like marketing, operations, and public policy. A standard modeling practice with this method is honest estimation: dividing the data so that the subgroups used to model treatment effect variation are formed separately from the data used to estimate those effects. This is intended to reduce overfitting and is the default in many software packages. But is it always the right choice? In this paper, we show that honest estimation can reduce the accuracy of individual-level treatment effect estimates, especially when there are substantial differences in how individuals respond to treatment, and the data is rich enough to uncover those differences. The core issue is a classic bias-variance trade-off: honesty lowers the risk of overfitting but increases the risk of underfitting, because it limits the data available to detect patterns. Across 7,500 benchmark datasets, we find that the cost of using honesty by default can be as high as requiring 75% more data to match the performance of models trained without it. We argue that honesty is best understood as a form of regularization, and like any regularization choice, its use should be guided by out-of-sample performance, not adopted reflexively.",
      "authors": [
        "Yanfang Hou",
        "Carlos Fern\\'andez-Lor\\'ia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T05:32:58+00:00",
          "link": "https://arxiv.org/abs/2506.13107v1",
          "size": "106kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:35:51+00:00",
          "link": "https://arxiv.org/abs/2506.13107v2",
          "size": "108kb",
          "version": "v2"
        }
      ],
      "title": "Honesty in Causal Forests: When It Helps and When It Hurts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13107",
        "HTML": "https://arxiv.org/html/2506.13107v2",
        "PDF": "https://arxiv.org/pdf/2506.13107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on causal forests and the effects of honest estimation on model performance and data requirements, which does not relate to LLM training data processing or any specific data processing operations for LLMs."
      },
      "tasks": [
        "Causal Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13196",
      "abstract": "Accurate prediction of protein-ligand binding affinity is critical for drug discovery. While recent deep learning approaches have demonstrated promising results, they often rely solely on structural features of proteins and ligands, overlooking their valuable biochemical knowledge associated with binding affinity. To address this limitation, we propose KEPLA, a novel deep learning framework that explicitly integrates prior knowledge from Gene Ontology and ligand properties to enhance prediction performance. KEPLA takes protein sequences and ligand molecular graphs as input and optimizes two complementary objectives: (1) aligning global representations with knowledge graph relations to capture domain-specific biochemical insights, and (2) leveraging cross attention between local representations to construct fine-grained joint embeddings for prediction. Experiments on two benchmark datasets across both in-domain and cross-domain scenarios demonstrate that KEPLA consistently outperforms state-of-the-art baselines. Furthermore, interpretability analyses based on knowledge graph relations and cross attention maps provide valuable insights into the underlying predictive mechanisms.",
      "authors": [
        "Han Liu",
        "Keyan Ding",
        "Peilin Chen",
        "Yinwei Wei",
        "Liqiang Nie",
        "Dapeng Wu",
        "Shiqi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T08:02:42+00:00",
          "link": "https://arxiv.org/abs/2506.13196v1",
          "size": "1707kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T05:48:34+00:00",
          "link": "https://arxiv.org/abs/2506.13196v2",
          "size": "1668kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T04:01:36+00:00",
          "link": "https://arxiv.org/abs/2506.13196v3",
          "size": "1668kb",
          "version": "v3"
        }
      ],
      "title": "KEPLA: A Knowledge-Enhanced Deep Learning Framework for Accurate Protein-Ligand Binding Affinity Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13196",
        "HTML": "https://arxiv.org/html/2506.13196v3",
        "PDF": "https://arxiv.org/pdf/2506.13196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the prediction of protein-ligand binding affinity using a knowledge-enhanced deep learning framework. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14180",
      "abstract": "Egocentric pose estimation is a fundamental capability for multi-robot collaborative perception in connected autonomy, such as connected autonomous vehicles. During multi-robot operations, a robot needs to know the relative pose between itself and its teammates with respect to its own coordinates. However, different robots usually observe completely different views that contains similar objects, which leads to wrong pose estimation. In addition, it is unrealistic to allow robots to share their raw observations to detect overlap due to the limited communication bandwidth constraint. In this paper, we introduce a novel method for Non-Overlap-Aware Egocentric Pose Estimation (NOPE), which performs egocentric pose estimation in a multi-robot team while identifying the non-overlap views and satifying the communication bandwidth constraint. NOPE is built upon an unified hierarchical learning framework that integrates two levels of robot learning: (1) high-level deep graph matching for correspondence identification, which allows to identify if two views are overlapping or not, (2) low-level position-aware cross-attention graph learning for egocentric pose estimation. To evaluate NOPE, we conduct extensive experiments in both high-fidelity simulation and real-world scenarios. Experimental results have demonstrated that NOPE enables the novel capability for non-overlapping-aware egocentric pose estimation and achieves state-of-art performance compared with the existing methods. Our project page at https://hongh0.github.io/NOPE/.",
      "authors": [
        "Hong Huang",
        "Dongkuan Xu",
        "Hao Zhang",
        "Peng Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T04:47:51+00:00",
          "link": "https://arxiv.org/abs/2506.14180v1",
          "size": "3548kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:08:19+00:00",
          "link": "https://arxiv.org/abs/2506.14180v2",
          "size": "3548kb",
          "version": "v2"
        }
      ],
      "title": "Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14180",
        "HTML": "https://arxiv.org/html/2506.14180v2",
        "PDF": "https://arxiv.org/pdf/2506.14180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses egocentric pose estimation in multi-robot systems and does not make contributions to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17562",
      "abstract": "LLMs have demonstrated significant potential in Medical Report Generation (MRG), yet their development requires large amounts of medical image-report pairs, which are commonly scattered across multiple centers. Centralizing these data is exceptionally challenging due to privacy regulations, thereby impeding model development and broader adoption of LLM-driven MRG models. To address this challenge, we present FedMRG, the first framework that leverages Federated Learning (FL) to enable privacy-preserving, multi-center development of LLM-driven MRG models, specifically designed to overcome the critical challenge of communication-efficient LLM training under multi-modal data heterogeneity. To start with, our framework tackles the fundamental challenge of communication overhead in FL-LLM tuning by employing low-rank factorization to efficiently decompose parameter updates, significantly reducing gradient transmission costs and making LLM-driven MRG feasible in bandwidth-constrained FL settings. Furthermore, we observed the dual heterogeneity in MRG under the FL scenario: varying image characteristics across medical centers, as well as diverse reporting styles and terminology preferences. To address this, we further enhance FedMRG with (1) client-aware contrastive learning in the MRG encoder, coupled with diagnosis-driven prompts, which capture both globally generalizable and locally distinctive features while maintaining diagnostic accuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder that harmonizes generic and specialized adapters to address variations in reporting styles and terminology. Through extensive evaluation of our established FL-MRG benchmark, we demonstrate the generalizability and adaptability of FedMRG, underscoring its potential in harnessing multi-center data and generating clinically accurate reports while maintaining communication efficiency.",
      "authors": [
        "Haoxuan Che",
        "Haibo Jin",
        "Zhengrui Guo",
        "Yi Lin",
        "Cheng Jin",
        "and Hao Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T03:13:08+00:00",
          "link": "https://arxiv.org/abs/2506.17562v1",
          "size": "2172kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:39:50+00:00",
          "link": "https://arxiv.org/abs/2506.17562v2",
          "size": "829kb",
          "version": "v2"
        }
      ],
      "title": "LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17562",
        "HTML": "https://arxiv.org/html/2506.17562v2",
        "PDF": "https://arxiv.org/pdf/2506.17562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves Federated Learning to enable LLM-driven medical report generation while maintaining privacy across multiple centers. Although it discusses efficient LLM training and associated challenges like communication overheads, its focus is more on the application within medical report generation rather than broader LLM training data processing techniques or operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18167",
      "abstract": "Recent advances in large language models (LLMs) have led to the development of thinking language models that generate extensive internal reasoning chains before producing responses. While these models achieve improved performance, controlling their reasoning processes remains challenging. This work presents a steering approach for thinking LLMs by analyzing and manipulating specific reasoning behaviors in DeepSeek-R1-Distill models. Through a systematic experiment on 500 tasks across 10 diverse categories, we identify several reasoning behaviors exhibited by thinking models, including expressing uncertainty, generating examples for hypothesis validation, and backtracking in reasoning chains. We demonstrate that these behaviors are mediated by linear directions in the model's activation space and can be controlled using steering vectors. By extracting and applying these vectors, we provide a method to modulate specific aspects of the model's reasoning process, such as its tendency to backtrack or express uncertainty. Our approach offers practical tools for steering reasoning processes in thinking models in a controlled and interpretable manner. We validate our steering method using three DeepSeek-R1-Distill models, demonstrating consistent control across different model architectures.",
      "authors": [
        "Constantin Venhoff",
        "Iv\\'an Arcuschin",
        "Philip Torr",
        "Arthur Conmy",
        "Neel Nanda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T20:45:26+00:00",
          "link": "https://arxiv.org/abs/2506.18167v1",
          "size": "472kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T01:53:33+00:00",
          "link": "https://arxiv.org/abs/2506.18167v2",
          "size": "472kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T23:27:34+00:00",
          "link": "https://arxiv.org/abs/2506.18167v3",
          "size": "472kb",
          "version": "v3"
        }
      ],
      "title": "Understanding Reasoning in Thinking Language Models via Steering Vectors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18167",
        "HTML": "https://arxiv.org/html/2506.18167v3",
        "PDF": "https://arxiv.org/pdf/2506.18167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on controlling reasoning processes in LLMs through steering vectors. It does not address any aspect of LLM training data processing, such as dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18183",
      "abstract": "Reasoning language models have set state-of-the-art (SOTA) records on many challenging benchmarks, enabled by multi-step reasoning induced using reinforcement learning. However, like previous language models, reasoning models are prone to generating confident, plausible responses that are incorrect (hallucinations). Knowing when and how much to trust these models is critical to the safe deployment of reasoning models in real-world applications. To this end, we explore uncertainty quantification of reasoning models in this work. Specifically, we ask three fundamental questions: First, are reasoning models well-calibrated? Second, does deeper reasoning improve model calibration? Finally, inspired by humans' innate ability to double-check their thought processes to verify the validity of their answers and their confidence, we ask: can reasoning models improve their calibration by explicitly reasoning about their chain-of-thought traces? We introduce introspective uncertainty quantification (UQ) to explore this direction. In extensive evaluations on SOTA reasoning models across a broad range of benchmarks, we find that reasoning models: (i) are typically overconfident, with self-verbalized confidence estimates often greater than 85% particularly for incorrect responses, (ii) become even more overconfident with deeper reasoning, and (iii) can become better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we conclude with important research directions to design necessary UQ benchmarks and improve the calibration of reasoning models.",
      "authors": [
        "Zhiting Mei",
        "Christina Zhang",
        "Tenny Yin",
        "Justin Lidard",
        "Ola Shorinwa",
        "Anirudha Majumdar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T21:46:42+00:00",
          "link": "https://arxiv.org/abs/2506.18183v1",
          "size": "20967kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T21:33:32+00:00",
          "link": "https://arxiv.org/abs/2506.18183v2",
          "size": "20967kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T02:39:29+00:00",
          "link": "https://arxiv.org/abs/2506.18183v3",
          "size": "20968kb",
          "version": "v3"
        }
      ],
      "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18183",
        "HTML": "https://arxiv.org/html/2506.18183v3",
        "PDF": "https://arxiv.org/pdf/2506.18183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates uncertainty quantification in reasoning models, specifically their calibration and confidence estimates. It doesn't cover any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19805",
      "abstract": "Physics-informed neural networks (PINNs) are extensively employed to solve partial differential equations (PDEs) by ensuring that the outputs and gradients of deep learning models adhere to the governing equations. However, constrained by computational limitations, PINNs are typically optimized using a finite set of points, which poses significant challenges in guaranteeing their convergence and accuracy. In this study, we proposed a new weighting scheme that will adaptively change the weights to the loss functions from isolated points to their continuous neighborhood regions. The empirical results show that our weighting scheme can reduce the relative $L^2$ errors to a lower value.",
      "authors": [
        "Chenhao Si",
        "Ming Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T17:13:51+00:00",
          "link": "https://arxiv.org/abs/2506.19805v1",
          "size": "13045kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:09:51+00:00",
          "link": "https://arxiv.org/abs/2506.19805v2",
          "size": "16448kb",
          "version": "v2"
        }
      ],
      "title": "Convolution-weighting method for the physics-informed neural network: A Primal-Dual Optimization Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19805",
        "HTML": "https://arxiv.org/html/2506.19805v2",
        "PDF": "https://arxiv.org/pdf/2506.19805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work describes a convolution-weighting method for physics-informed neural networks (PINNs), focusing on optimization techniques for PDEs. This is unrelated to LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19838",
      "abstract": "Latent diffusion models have emerged as a leading paradigm for efficient video generation. However, as user expectations shift toward higher-resolution outputs, relying solely on latent computation becomes inadequate. A promising approach involves decoupling the process into two stages: semantic content generation and detail synthesis. The former employs a computationally intensive base model at lower resolutions, while the latter leverages a lightweight cascaded video super-resolution (VSR) model to achieve high-resolution output. In this work, we focus on studying key design principles for latter cascaded VSR models, which are underexplored currently. First, we propose two degradation strategies to generate training pairs that better mimic the output characteristics of the base model, ensuring alignment between the VSR model and its upstream generator. Second, we provide critical insights into VSR model behavior through systematic analysis of (1) timestep sampling strategies, (2) noise augmentation effects on low-resolution (LR) inputs. These findings directly inform our architectural and training innovations. Finally, we introduce interleaving temporal unit and sparse local attention to achieve efficient training and inference, drastically reducing computational overhead. Extensive experiments demonstrate the superiority of our framework over existing methods, with ablation studies confirming the efficacy of each design choice. Our work establishes a simple yet effective baseline for cascaded video super-resolution generation, offering practical insights to guide future advancements in efficient cascaded synthesis systems.",
      "authors": [
        "Liangbin Xie",
        "Yu Li",
        "Shian Du",
        "Menghan Xia",
        "Xintao Wang",
        "Fanghua Yu",
        "Ziyan Chen",
        "Pengfei Wan",
        "Jiantao Zhou",
        "Chao Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T17:57:26+00:00",
          "link": "https://arxiv.org/abs/2506.19838v1",
          "size": "8872kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:15:39+00:00",
          "link": "https://arxiv.org/abs/2506.19838v2",
          "size": "8872kb",
          "version": "v2"
        }
      ],
      "title": "SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19838",
        "HTML": "https://arxiv.org/html/2506.19838v2",
        "PDF": "https://arxiv.org/pdf/2506.19838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers on video super-resolution using latent-cascaded models, discussing training strategies for VSR models. It is not connected to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20487",
      "abstract": "Humanoid robots are drawing significant attention as versatile platforms for complex motor control, human-robot interaction, and general-purpose physical intelligence. However, achieving efficient whole-body control (WBC) in humanoids remains a fundamental challenge due to sophisticated dynamics, underactuation, and diverse task requirements. While learning-based controllers have shown promise for complex tasks, their reliance on labor-intensive and costly retraining for new scenarios limits real-world applicability. To address these limitations, behavior(al) foundation models (BFMs) have emerged as a new paradigm that leverages large-scale pre-training to learn reusable primitive skills and broad behavioral priors, enabling zero-shot or rapid adaptation to a wide range of downstream tasks. In this paper, we present a comprehensive overview of BFMs for humanoid WBC, tracing their development across diverse pre-training pipelines. Furthermore, we discuss real-world applications, current limitations, urgent challenges, and future opportunities, positioning BFMs as a key approach toward scalable and general-purpose humanoid intelligence. Finally, we provide a curated and long-term list of BFM papers and projects to facilitate more subsequent research, which is available at https://github.com/yuanmingqi/awesome-bfm-papers.",
      "authors": [
        "Mingqi Yuan",
        "Tao Yu",
        "Wenqi Ge",
        "Xiuyong Yao",
        "Huijiang Wang",
        "Jiayu Chen",
        "Xin Jin",
        "Bo Li",
        "Hua Chen",
        "Wei Zhang",
        "Wenjun Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T14:35:33+00:00",
          "link": "https://arxiv.org/abs/2506.20487v1",
          "size": "4847kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:52:10+00:00",
          "link": "https://arxiv.org/abs/2506.20487v2",
          "size": "6069kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T10:28:01+00:00",
          "link": "https://arxiv.org/abs/2506.20487v3",
          "size": "6044kb",
          "version": "v3"
        }
      ],
      "title": "A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20487",
        "HTML": "https://arxiv.org/html/2506.20487v3",
        "PDF": "https://arxiv.org/pdf/2506.20487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys behavior foundation models for human-robot interaction and control, emphasizing pre-training for humanoid control systems, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22598",
      "abstract": "Agents based on Large Language Models (LLMs) have shown promise for performing sophisticated software engineering tasks autonomously. In addition, there has been progress towards developing agents that can perform parts of the research pipeline in machine learning and the natural sciences. We argue that research extension and its implementation is a critical capability for such systems, and introduce RExBench to support the evaluation of this capability. RExBench is a benchmark consisting of 12 realistic research experiment implementation tasks that aim to investigate research hypotheses that have not previously been implemented. Each task is set up as an extension to an existing research paper and codebase, accompanied by domain expert-written instructions. RExBench is robust to data contamination, and supports an automatic evaluation infrastructure that executes agent outputs to determine whether the success criteria are met. We use this benchmark to evaluate nine LLM agents implemented using three different frameworks: aider, Claude Code, and OpenHands. We find that all agents evaluated fail to autonomously implement the majority of the extensions. Although the success rate improves with additional human-written hints, the best performance under this setting remains below 40%. This indicates that current agents are still short of being able to handle realistic research extension tasks without substantial human guidance.",
      "authors": [
        "Nicholas Edwards",
        "Yukyung Lee",
        "Yujun Audrey Mao",
        "Yulu Qin",
        "Sebastian Schuster",
        "Najoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:41:41+00:00",
          "link": "https://arxiv.org/abs/2506.22598v1",
          "size": "469kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T18:45:58+00:00",
          "link": "https://arxiv.org/abs/2506.22598v2",
          "size": "469kb",
          "version": "v2"
        }
      ],
      "title": "RExBench: Can coding agents autonomously implement AI research extensions?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22598",
        "PDF": "https://arxiv.org/pdf/2506.22598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLM-based agents in research extension tasks using the RExBench benchmark. It does not address any aspect of LLM training data processing, as the primary concern is agent capabilities, not data handling for model training."
      },
      "datasets": [
        {
          "dataset_name": "tin-lab/RExBench",
          "downloads": "23",
          "likes": "0",
          "link": "https://huggingface.co/datasets/tin-lab/RExBench"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23306",
      "abstract": "Traditional agent-based urban mobility simulations often rely on rigid rule-based systems that struggle to capture the complexity, adaptability, and behavioral diversity inherent in human travel decision making. Recent advancements in large language models and AI agent technologies present new opportunities to develop agents with enhanced reasoning capabilities, persistent memory, and adaptive learning. We introduce GATSim (Generative-Agent Transport Simulation), a novel framework that leverages these advancements to simulate urban mobility using generative agents with rich, human-like behaviors. Unlike conventional approaches, GATSim agents are characterized by diverse socioeconomic profiles, individual lifestyles, and evolving preferences shaped through psychologically informed memory systems, tool usage, and lifelong learning. The main contributions of this work are: (1) a comprehensive architecture that integrates an urban mobility foundation model with agent cognitive systems and a transport simulation environment; (2) a hierarchical memory designed for efficient retrieval of contextually relevant information, incorporating spatial and temporal associations, keyword matching, and semantic relevance; (3) innovative planning and reactive mechanisms for modeling adaptive mobility behaviors which integrate a multi-scale reflection process to transform specific travel experiences into generalized behavioral insights. We implement a prototype system and conduct systematic validation, demonstrating that generative agents produce believable and coherent travel behaviors. Experimental results indicate that generative agents perform at least as well as human annotators with 92\\% posterior probability, while naturally producing realistic macroscopic traffic patterns. The code for the prototype implementation is publicly available at https://github.com/qiliuchn/gatsim.",
      "authors": [
        "Qi Liu",
        "Can Li",
        "Wanjing Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:52:16+00:00",
          "link": "https://arxiv.org/abs/2506.23306v1",
          "size": "23163kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T04:20:16+00:00",
          "link": "https://arxiv.org/abs/2506.23306v2",
          "size": "23163kb",
          "version": "v2"
        }
      ],
      "title": "GATSim: Urban Mobility Simulation with Generative Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23306",
        "HTML": "https://arxiv.org/html/2506.23306v2",
        "PDF": "https://arxiv.org/pdf/2506.23306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents GATSim, a framework for simulating urban mobility using generative agents, and does not concern itself with LLM training data processing. The focus is on agent behavior in simulations, not on pretraining or fine-tuning data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23491",
      "abstract": "In this paper, we present ZonUI-3B, a lightweight Vision-Language Model (VLM) that can be fully trained on a single consumer-grade GPU (RTX 4090) while delivering performance comparable to significantly larger models on GUI grounding tasks. The model incorporates several key innovations: (i) combine cross-platform, multi-resolution dataset of 24K examples from diverse sources including mobile, desktop, and web GUI screenshots to effectively address data scarcity in high-resolution desktop environments; (ii) a two-stage fine-tuning strategy, where initial cross-platform training establishes robust GUI understanding, followed by specialized fine-tuning on high-resolution data to significantly enhance model adaptability; and (iii) data curation and redundancy reduction strategies, demonstrating that randomly sampling a smaller subset with reduced redundancy achieves performance comparable to larger datasets, emphasizing data diversity over sheer volume. Empirical evaluation on standard GUI grounding benchmarks, including ScreenSpot, ScreenSpot-v2, and the challenging ScreenSpot-Pro, highlights ZonUI-3B's exceptional accuracy, achieving 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B parameters. Ablation studies validate the critical role of balanced sampling and two-stage fine-tuning in enhancing robustness, particularly in high-resolution desktop scenarios. The ZonUI-3B is available at: https://github.com/Han1018/ZonUI-3B",
      "authors": [
        "ZongHan Hsieh",
        "Tzer-Jen Wei",
        "ShengJing Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:33:02+00:00",
          "link": "https://arxiv.org/abs/2506.23491v1",
          "size": "395kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T08:46:32+00:00",
          "link": "https://arxiv.org/abs/2506.23491v2",
          "size": "537kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T06:03:26+00:00",
          "link": "https://arxiv.org/abs/2506.23491v3",
          "size": "534kb",
          "version": "v3"
        }
      ],
      "title": "ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23491",
        "HTML": "https://arxiv.org/html/2506.23491v3",
        "PDF": "https://arxiv.org/pdf/2506.23491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "ZonUI-3B involves data curation and redundancy reduction strategies to address GUI grounding tasks, which relates to data processing. However, the main focus is on the vision-language model performance, not specifically LLM training data processing."
      },
      "models": [
        {
          "model_path": "zonghanHZH/ZonUI-3B",
          "downloads": "213",
          "likes": "2",
          "trending_score": "1.0",
          "link": "https://huggingface.co/zonghanHZH/ZonUI-3B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "zonghanHZH/ShowUI-web-8k",
          "downloads": "1627",
          "likes": "0",
          "link": "https://huggingface.co/datasets/zonghanHZH/ShowUI-web-8k"
        },
        {
          "dataset_name": "zonghanHZH/AMEX-8k",
          "downloads": "707",
          "likes": "0",
          "link": "https://huggingface.co/datasets/zonghanHZH/AMEX-8k"
        },
        {
          "dataset_name": "zonghanHZH/UGround-V1-8k",
          "downloads": "820",
          "likes": "0",
          "link": "https://huggingface.co/datasets/zonghanHZH/UGround-V1-8k"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23957",
      "abstract": "Video stabilization is pivotal for video processing, as it removes unwanted shakiness while preserving the original user motion intent. Existing approaches, depending on the domain they operate, suffer from several issues (e.g. geometric distortions, excessive cropping, poor generalization) that degrade the user experience. To address these issues, we introduce \\textbf{GaVS}, a novel 3D-grounded approach that reformulates video stabilization as a temporally-consistent `local reconstruction and rendering' paradigm. Given 3D camera poses, we augment a reconstruction model to predict Gaussian Splatting primitives, and finetune it at test-time, with multi-view dynamics-aware photometric supervision and cross-frame regularization, to produce temporally-consistent local reconstructions. The model are then used to render each stabilized frame. We utilize a scene extrapolation module to avoid frame cropping. Our method is evaluated on a repurposed dataset, instilled with 3D-grounded information, covering samples with diverse camera motions and scene dynamics. Quantitatively, our method is competitive with or superior to state-of-the-art 2D and 2.5D approaches in terms of conventional task metrics and new geometry consistency. Qualitatively, our method produces noticeably better results compared to alternatives, validated by the user study.",
      "authors": [
        "Zinuo You",
        "Stamatios Georgoulis",
        "Anpei Chen",
        "Siyu Tang",
        "Dengxin Dai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:24:27+00:00",
          "link": "https://arxiv.org/abs/2506.23957v1",
          "size": "5090kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:34:33+00:00",
          "link": "https://arxiv.org/abs/2506.23957v2",
          "size": "5091kb",
          "version": "v2"
        }
      ],
      "title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23957",
        "HTML": "https://arxiv.org/html/2506.23957v2",
        "PDF": "https://arxiv.org/pdf/2506.23957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel method for 3D-grounded video stabilization. It is focused on video processing and stabilization techniques and does not relate to any stage of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24068",
      "abstract": "Frontier AI developers are relying on layers of safeguards to protect against catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus model using one such defense pipeline, and other frontier developers including Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the security of such pipelines is unclear, with limited prior work evaluating or attacking these pipelines. We address this gap by developing and red-teaming an open-source defense pipeline. First, we find that a novel few-shot-prompted input and output classifier outperforms state-of-the-art open-weight safeguard model ShieldGemma across three attacks and two datasets, reducing the attack success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second, we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on ClearHarm in a black-box attack against the few-shot-prompted classifier pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33% ASR, providing initial evidence that it is feasible to design attacks with no access to the target pipeline. We conclude by suggesting specific mitigations that developers could use to thwart staged attacks.",
      "authors": [
        "Ian R. McKenzie",
        "Oskar J. Hollinsworth",
        "Tom Tseng",
        "Xander Davies",
        "Stephen Casper",
        "Aaron D. Tucker",
        "Robert Kirk",
        "Adam Gleave"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:21:08+00:00",
          "link": "https://arxiv.org/abs/2506.24068v1",
          "size": "744kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T01:26:48+00:00",
          "link": "https://arxiv.org/abs/2506.24068v2",
          "size": "777kb",
          "version": "v2"
        }
      ],
      "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24068",
        "HTML": "https://arxiv.org/html/2506.24068v2",
        "PDF": "https://arxiv.org/pdf/2506.24068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates adversarial attacks on LLM safeguard pipelines. It primarily addresses security and attack strategies, without any focus on the LLM training data processing stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00498",
      "abstract": "Conventional voice conversion modifies voice characteristics from a source speaker to a target speaker, relying on audio input from both sides. However, this process becomes infeasible when clean audio is unavailable, such as in silent videos or noisy environments. In this work, we focus on the task of Silent Face-based Voice Conversion (SFVC), which does voice conversion entirely from visual inputs. i.e., given images of a target speaker and a silent video of a source speaker containing lip motion, SFVC generates speech aligning the identity of the target speaker while preserving the speech content in the source silent video. As this task requires generating intelligible speech and converting identity using only visual cues, it is particularly challenging. To address this, we introduce MuteSwap, a novel framework that employs contrastive learning to align cross-modality identities and minimize mutual information to separate shared visual features. Experimental results show that MuteSwap achieves impressive performance in both speech synthesis and identity conversion, especially under noisy conditions where methods dependent on audio input fail to produce intelligible results, demonstrating both the effectiveness of our training approach and the feasibility of SFVC.",
      "authors": [
        "Yifan Liu",
        "Yu Fang",
        "Zhouhan Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T07:13:34+00:00",
          "link": "https://arxiv.org/abs/2507.00498v1",
          "size": "4891kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:45:14+00:00",
          "link": "https://arxiv.org/abs/2507.00498v2",
          "size": "4891kb",
          "version": "v2"
        }
      ],
      "title": "MuteSwap: Visual-informed Silent Video Identity Conversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00498",
        "HTML": "https://arxiv.org/html/2507.00498v2",
        "PDF": "https://arxiv.org/pdf/2507.00498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses Silent Face-based Voice Conversion using visual inputs and contrastive learning, focusing on speech synthesis and identity conversion. It is unrelated to LLM training data processing as described by the task criteria."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03068",
      "abstract": "Safe generalization in reinforcement learning requires not only that a learned policy acts capably in new situations, but also that it uses its capabilities towards the pursuit of the designer's intended goal. The latter requirement may fail when a proxy goal incentivizes similar behavior to the intended goal within the training environment, but not in novel deployment environments. This creates the risk that policies will behave as if in pursuit of the proxy goal, rather than the intended goal, in deployment -- a phenomenon known as goal misgeneralization. In this paper, we formalize this problem setting in order to theoretically study the possibility of goal misgeneralization under different training objectives. We show that goal misgeneralization is possible under approximate optimization of the maximum expected value (MEV) objective, but not the minimax expected regret (MMER) objective. We then empirically show that the standard MEV-based training method of domain randomization exhibits goal misgeneralization in procedurally-generated grid-world environments, whereas current regret-based unsupervised environment design (UED) methods are more robust to goal misgeneralization (though they don't find MMER policies in all cases). Our findings suggest that minimax expected regret is a promising approach to mitigating goal misgeneralization.",
      "authors": [
        "Karim Abdel Sadek",
        "Matthew Farrugia-Roberts",
        "Usman Anwar",
        "Hannah Erlebach",
        "Christian Schroeder de Witt",
        "David Krueger",
        "Michael Dennis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:57:12+00:00",
          "link": "https://arxiv.org/abs/2507.03068v1",
          "size": "3200kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:38:55+00:00",
          "link": "https://arxiv.org/abs/2507.03068v2",
          "size": "3200kb",
          "version": "v2"
        }
      ],
      "title": "Mitigating Goal Misgeneralization via Minimax Regret",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03068",
        "HTML": "https://arxiv.org/html/2507.03068v2",
        "PDF": "https://arxiv.org/pdf/2507.03068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses goal misgeneralization in reinforcement learning, emphasizing different training objectives like MEV and MMER. It is not concerned with LLM training data processing operations or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03532",
      "abstract": "Digital pathology has seen the advent of a wealth of foundational models (FM), yet to date their performance on cell phenotyping has not been benchmarked in a unified manner. We therefore propose PhenoBench: A comprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&E) stained histopathology images. We provide both PhenoCell, a new H&E dataset featuring 14 granular cell types identified by using multiplexed imaging, and ready-to-use fine-tuning and benchmarking code that allows the systematic evaluation of multiple prominent pathology FMs in terms of dense cell phenotype predictions in different generalization scenarios. We perform extensive benchmarking of existing FMs, providing insights into their generalization behavior under technical vs. medical domain shifts. Furthermore, while FMs achieve macro F1 scores > 0.70 on previously established benchmarks such as Lizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. This indicates a much more challenging task not captured by previous benchmarks, establishing PhenoCell as a prime asset for future benchmarking of FMs and supervised models alike. Code and data are available on GitHub.",
      "authors": [
        "Jannik Franzen",
        "Fabian H. Reith",
        "Claudia Winklmayr",
        "Jerome Luescher",
        "Nora Koreuber",
        "Elias Baumann",
        "Christian M. Schuerch",
        "Dagmar Kainmueller",
        "Josef Lorenz Rumberger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T12:37:57+00:00",
          "link": "https://arxiv.org/abs/2507.03532v1",
          "size": "4535kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T08:29:03+00:00",
          "link": "https://arxiv.org/abs/2507.03532v2",
          "size": "4523kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T06:42:01+00:00",
          "link": "https://arxiv.org/abs/2507.03532v3",
          "size": "4523kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T05:45:36+00:00",
          "link": "https://arxiv.org/abs/2507.03532v4",
          "size": "4523kb",
          "version": "v4"
        }
      ],
      "title": "PhenoBench: A Comprehensive Benchmark for Cell Phenotyping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03532",
        "HTML": "https://arxiv.org/html/2507.03532v4",
        "PDF": "https://arxiv.org/pdf/2507.03532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces PhenoBench and PhenoCell for cell phenotyping benchmarks. Since it focuses on benchmarking in digital pathology and does not address aspects of LLM training data processing, it is irrelevant to the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04201",
      "abstract": "The max-min fairness (MMF) problem in rate-splitting multiple access (RSMA) is known to be challenging due to its non-convex and non-smooth nature, as well as the coupled beamforming and common rate variables. Conventional algorithms to address this problem often incur high computational complexity or degraded MMF rate performance. To address these challenges, in this work, we propose a novel optimization algorithm named extragradient-fractional programming (EG-FP) to address the MMF problem of downlink RSMA. The proposed algorithm first leverages FP to transform the original problem into a block-wise convex problem. For the subproblem of precoding block, we show that its Lagrangian dual is equivalent to a variational inequality problem, which is then solved using an extragradient-based algorithm. Additionally, we discover the optimal beamforming structure of the problem and based on which, we introduce a low-dimensional EG-FP algorithm with computational complexity independent of the number of transmit antennas. This feature is especially beneficial in scenarios with a large number of transmit antennas. The proposed algorithms are then extended to handle imperfect channel state information at the transmitter (CSIT). Numerical results demonstrate that the MMF rate achieved by our proposed algorithms closely matches that of the conventional successive convex approximation (SCA) algorithm and significantly outperforms other baseline schemes. Remarkably, the average CPU time of the proposed algorithms is less than 10\\% of the runtime required by the SCA algorithm, showing the efficiency and scalability of the proposed algorithms.",
      "authors": [
        "Facheng Luo and Yijie Mao"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T01:11:13+00:00",
          "link": "https://arxiv.org/abs/2507.04201v1",
          "size": "769kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T06:37:53+00:00",
          "link": "https://arxiv.org/abs/2507.04201v2",
          "size": "834kb",
          "version": "v2"
        }
      ],
      "title": "An Efficient Max-Min Fair Resource Optimization Algorithm for Rate-Splitting Multiple Access",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04201",
        "HTML": "https://arxiv.org/html/2507.04201v2",
        "PDF": "https://arxiv.org/pdf/2507.04201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an optimization algorithm for max-min fair resource allocation in rate-splitting multiple access. It does not engage with LLM training data processing or related dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04295",
      "abstract": "Effective feedback is essential for student learning but is time-intensive for teachers. We present LearnLens, a modular, LLM-based system that generates personalised, curriculum-aligned feedback in science education. LearnLens comprises three components: (1) an error-aware assessment module that captures nuanced reasoning errors; (2) a curriculum-grounded generation module that uses a structured, topic-linked memory chain rather than traditional similarity-based retrieval, improving relevance and reducing noise; and (3) an educator-in-the-loop interface for customisation and oversight. LearnLens addresses key challenges in existing systems, offering scalable, high-quality feedback that empowers both teachers and students.",
      "authors": [
        "Runcong Zhao",
        "Artem Bobrov",
        "Jiazheng Li",
        "Yulan He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T08:39:26+00:00",
          "link": "https://arxiv.org/abs/2507.04295v1",
          "size": "1802kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T18:21:09+00:00",
          "link": "https://arxiv.org/abs/2507.04295v2",
          "size": "1803kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T11:37:12+00:00",
          "link": "https://arxiv.org/abs/2507.04295v3",
          "size": "1803kb",
          "version": "v3"
        }
      ],
      "title": "LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04295",
        "PDF": "https://arxiv.org/pdf/2507.04295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on using an LLM-based system to generate personalized feedback in education. It primarily addresses feedback customization and educator involvement, without discussing data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04469",
      "abstract": "This systematic literature review examines the role of large language models (LLMs) in UI/UX design, synthesizing findings from 38 peer-reviewed studies published between 2022 and 2025. We identify key LLMs in use, including GPT-4, Gemini, and PaLM, and map their integration across the design lifecycle, from ideation to evaluation. Common practices include prompt engineering, human-in-the-loop workflows, and multimodal input. While LLMs are reshaping design processes, challenges such as hallucination, prompt instability, and limited explainability persist. Our findings highlight LLMs as emerging collaborators in design, and we propose directions for the ethical, inclusive, and effective integration of these technologies.",
      "authors": [
        "Ammar Ahmed",
        "Ali Shariq Imran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T17:18:05+00:00",
          "link": "https://arxiv.org/abs/2507.04469v1",
          "size": "2224kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:03:15+00:00",
          "link": "https://arxiv.org/abs/2507.04469v2",
          "size": "742kb",
          "version": "v2"
        }
      ],
      "title": "The role of large language models in UI/UX design: A systematic literature review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04469",
        "HTML": "https://arxiv.org/html/2507.04469v2",
        "PDF": "https://arxiv.org/pdf/2507.04469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a literature review on the role of LLMs in UI/UX design, mainly discussing design lifecycle integration and challenges, without contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05169",
      "abstract": "World Model, the supposed algorithmic surrogate of the real-world environment which biological agents experience with and act upon, has been an emerging topic in recent years because of the rising needs to develop virtual agents with artificial (general) intelligence. There has been much debate on what a world model really is, how to build it, how to use it, and how to evaluate it. In this essay, starting from the imagination in the famed Sci-Fi classic Dune, and drawing inspiration from the concept of \"hypothetical thinking\" in psychology literature, we offer critiques of several schools of thoughts on world modeling, and argue the primary goal of a world model to be simulating all actionable possibilities of the real world for purposeful reasoning and acting. Building on the critiques, we propose a new architecture for a general-purpose world model, based on hierarchical, multi-level, and mixed continuous/discrete representations, and a generative and self-supervision learning framework, with an outlook of a Physical, Agentic, and Nested (PAN) AGI system enabled by such a model.",
      "authors": [
        "Eric Xing",
        "Mingkai Deng",
        "Jinyu Hou",
        "Zhiting Hu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T16:23:46+00:00",
          "link": "https://arxiv.org/abs/2507.05169v1",
          "size": "1062kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:48:16+00:00",
          "link": "https://arxiv.org/abs/2507.05169v2",
          "size": "1062kb",
          "version": "v2"
        }
      ],
      "title": "Critiques of World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05169",
        "HTML": "https://arxiv.org/html/2507.05169v2",
        "PDF": "https://arxiv.org/pdf/2507.05169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper critiques world models and proposes a new architecture for them. It does not discuss training data processing for LLMs or contributions to dataset creation or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05630",
      "abstract": "LLM-integrated applications and agents are vulnerable to prompt injection attacks, in which adversaries embed malicious instructions within seemingly benign user inputs to manipulate the LLM's intended behavior. Recent defenses based on $\\textit{known-answer detection}$ (KAD) have achieved near-perfect performance by using an LLM to classify inputs as clean or contaminated. In this work, we formally characterize the KAD framework and uncover a structural vulnerability in its design that invalidates its core security premise. We design a methodical adaptive attack, $\\textit{DataFlip}$, to exploit this fundamental weakness. It consistently evades KAD defenses with detection rates as low as $1.5\\%$ while reliably inducing malicious behavior with success rates of up to $88\\%$, without needing white-box access to the LLM or any optimization procedures.",
      "authors": [
        "Sarthak Choudhary",
        "Divyam Anshumaan",
        "Nils Palumbo",
        "Somesh Jha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:24:56+00:00",
          "link": "https://arxiv.org/abs/2507.05630v1",
          "size": "137kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T20:36:06+00:00",
          "link": "https://arxiv.org/abs/2507.05630v2",
          "size": "139kb",
          "version": "v2"
        }
      ],
      "title": "How Not to Detect Prompt Injections with an LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05630",
        "HTML": "https://arxiv.org/html/2507.05630v2",
        "PDF": "https://arxiv.org/pdf/2507.05630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores vulnerabilities in LLM defenses against prompt injection attacks, focusing on security vulnerabilities rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05887",
      "abstract": "The application of Vision-Language Models (VLMs) in remote sensing (RS) image understanding has achieved notable progress, demonstrating the basic ability to recognize and describe geographical entities. However, existing RS-VLMs are mostly limited to image-level and region-level tasks, lacking the capability to handle pixel-level tasks and performing poorly in small-object recognition scenarios. Moreover, RS-VLMs consume significant computational resources when processing high-resolution RS images, further restricting their practical applicability. In this context, we propose GeoMag (Geographical Magnifier), an end-to-end general-purpose large model framework for RS. GeoMag dynamically focuses the attention scope based on prompt semantics to effectively perform remote sensing image parsing across multiple levels of granularity. This method introduces Task-driven Multi-granularity Resolution Adjustment (TMRA) and Prompt-guided Semantic-aware Cropping (PSC), which adaptively reduce the spatial resolution of task-irrelevant regions while enhancing the visual representation of task-relevant areas. This approach improves the model's perception of critical target regions, suppresses background redundancy, and reduces the computational cost of interpreting high-resolution RS imagery. Extensive comparative experiments on 10 benchmarks demonstrate that GeoMag not only excels in handling pixel-level tasks but also maintains competitive performance across tasks of other granularities compared to existing RS-VLMs.",
      "authors": [
        "Xianzhi Ma",
        "Jianhui Li",
        "Changhua Pei",
        "Hao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T11:21:03+00:00",
          "link": "https://arxiv.org/abs/2507.05887v1",
          "size": "2520kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:41:26+00:00",
          "link": "https://arxiv.org/abs/2507.05887v2",
          "size": "2522kb",
          "version": "v2"
        }
      ],
      "title": "GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05887",
        "HTML": "https://arxiv.org/html/2507.05887v2",
        "PDF": "https://arxiv.org/pdf/2507.05887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "GeoMag is a Vision-Language Model for remote sensing image parsing, concentrating on improving image processing tasks rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06229",
      "abstract": "Current AI agents cannot effectively learn from each other's problem-solving experiences or use past successes to guide self-reflection and error correction in new tasks. We introduce Agent KB, a shared knowledge base that captures both high-level problem-solving strategies and detailed execution lessons, enabling knowledge transfer across agent frameworks. Agent KB implements a novel teacher-student dual-phase retrieval mechanism where student agents retrieve workflow-level patterns for strategic guidance while teacher agents identify execution-level patterns for refinement. This hierarchical approach enables agents to break out of limited reasoning pathways by incorporating diverse strategies from external sources. Evaluations on the GAIA benchmark demonstrate substantial performance gains, with Agent KB improving success rates by up to 6.06 percentage points overall under pass@1. For SWE-bench code repair tasks, our system significantly improved resolution rates, with o3-mini achieving an 8.67 percentage point gain (23 percent to 31.67 percent) in pass@1.",
      "authors": [
        "Xiangru Tang",
        "Tianrui Qin",
        "Tianhao Peng",
        "Ziyang Zhou",
        "Daniel Shao",
        "Tingting Du",
        "Xinming Wei",
        "Peng Xia",
        "Fang Wu",
        "He Zhu",
        "Ge Zhang",
        "Jiaheng Liu",
        "Xingyao Wang",
        "Sirui Hong",
        "Chenglin Wu",
        "Hao Cheng",
        "Chi Wang",
        "Wangchunshu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T17:59:22+00:00",
          "link": "https://arxiv.org/abs/2507.06229v1",
          "size": "10843kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T05:50:36+00:00",
          "link": "https://arxiv.org/abs/2507.06229v2",
          "size": "10843kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T18:03:33+00:00",
          "link": "https://arxiv.org/abs/2507.06229v3",
          "size": "10843kb",
          "version": "v3"
        }
      ],
      "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06229",
        "PDF": "https://arxiv.org/pdf/2507.06229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces Agent KB for improving AI agents' problem-solving abilities using a shared knowledge base, which is unrelated to LLM training data processing. It focuses on agent frameworks and knowledge retrieval rather than enhancing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06411",
      "abstract": "Inspired by the recent success of transformers and multi-stage architectures in video recognition and object detection domains. We thoroughly explore the rich spatio-temporal properties of transformers within a multi-stage architecture paradigm for the temporal action localization (TAL) task. This exploration led to the development of a hierarchical multi-stage transformer architecture called PCL-Former, where each subtask is handled by a dedicated transformer module with a specialized loss function. Specifically, the Proposal-Former identifies candidate segments in an untrimmed video that may contain actions, the Classification-Former classifies the action categories within those segments, and the Localization-Former precisely predicts the temporal boundaries (i.e., start and end) of the action instances. To evaluate the performance of our method, we have conducted extensive experiments on three challenging benchmark datasets: THUMOS-14, ActivityNet-1.3, and HACS Segments. We also conducted detailed ablation experiments to assess the impact of each individual module of our PCL-Former. The obtained quantitative results validate the effectiveness of the proposed PCL-Former, outperforming state-of-the-art TAL approaches by 2.8%, 1.2%, and 4.8% on THUMOS14, ActivityNet-1.3, and HACS datasets, respectively.",
      "authors": [
        "Hayat Ullah",
        "Arslan Munir",
        "Oliver Nina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:28:16+00:00",
          "link": "https://arxiv.org/abs/2507.06411v1",
          "size": "6409kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:29:48+00:00",
          "link": "https://arxiv.org/abs/2507.06411v2",
          "size": "6410kb",
          "version": "v2"
        }
      ],
      "title": "Hierarchical Multi-Stage Transformer Architecture for Context-Aware Temporal Action Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06411",
        "HTML": "https://arxiv.org/html/2507.06411v2",
        "PDF": "https://arxiv.org/pdf/2507.06411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a multi-stage transformer architecture for video action localization, focusing on model architecture and performance evaluation in video data scenarios. It doesn't address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06482",
      "abstract": "Federated learning aims at training models collaboratively across participants while protecting privacy. However, one major challenge for this paradigm is the data heterogeneity issue, where biased data preferences across multiple clients, harming the model's convergence and performance. In this paper, we first introduce powerful diffusion models into the federated learning paradigm and show that diffusion representations are effective steers during federated training. To explore the possibility of using diffusion representations in handling data heterogeneity, we propose a novel diffusion-inspired Federated paradigm with Diffusion Representation Collaboration, termed FedDifRC, leveraging meaningful guidance of diffusion models to mitigate data heterogeneity. The key idea is to construct text-driven diffusion contrasting and noise-driven diffusion regularization, aiming to provide abundant class-related semantic information and consistent convergence signals. On the one hand, we exploit the conditional feedback from the diffusion model for different text prompts to build a text-driven contrastive learning strategy. On the other hand, we introduce a noise-driven consistency regularization to align local instances with diffusion denoising representations, constraining the optimization region in the feature space. In addition, FedDifRC can be extended to a self-supervised scheme without relying on any labeled data. We also provide a theoretical analysis for FedDifRC to ensure convergence under non-convex objectives. The experiments on different scenarios validate the effectiveness of FedDifRC and the efficiency of crucial components.",
      "authors": [
        "Huan Wang",
        "Haoran Li",
        "Huaming Chen",
        "Jun Yan",
        "Jiahua Shi",
        "Jun Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:57:57+00:00",
          "link": "https://arxiv.org/abs/2507.06482v1",
          "size": "18230kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T06:38:07+00:00",
          "link": "https://arxiv.org/abs/2507.06482v2",
          "size": "13487kb",
          "version": "v2"
        }
      ],
      "title": "FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06482",
        "HTML": "https://arxiv.org/html/2507.06482v2",
        "PDF": "https://arxiv.org/pdf/2507.06482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores federated learning with diffusion models for handling data heterogeneity, focusing on federated training strategies rather than LLM training data processing. It doesn't involve data processing methods aimed at LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06602",
      "abstract": "Modern RAN operate in highly dynamic and heterogeneous environments, where hand-tuned, rule-based RRM algorithms often underperform. While RL can surpass such heuristics in constrained settings, the diversity of deployments and unpredictable radio conditions introduce major generalization challenges. Data-driven policies frequently overfit to training conditions, degrading performance in unseen scenarios. To address this, we propose a generalization-centered RL framework for RAN control that: (i) robustly reconstructs dynamically varying states from partial and noisy observations, while encoding static and semi-static information, such as radio nodes, cell attributes, and their topology, through graph representations; (ii) applies domain randomization to broaden the training distribution; and (iii) distributes data generation across multiple actors while centralizing training in a cloud-compatible architecture aligned with O-RAN principles. Although generalization increases computational and data-management complexity, our distributed design mitigates this by scaling data collection and training across diverse network conditions. Applied to downlink link adaptation in five 5G benchmarks, our policy improves average throughput and spectral efficiency by ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and by >20% under high mobility. It matches specialized RL in full-buffer traffic and achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks, respectively. In nine-cell deployments, GAT models offer 30% higher throughput over MLP baselines. These results, combined with our scalable architecture, offer a path toward AI-native 6G RAN using a single, generalizable RL agent.",
      "authors": [
        "Burak Demirel and Yu Wang and Cristian Tatino and Pablo Soldati"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:22:22+00:00",
          "link": "https://arxiv.org/abs/2507.06602v1",
          "size": "1450kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:46:26+00:00",
          "link": "https://arxiv.org/abs/2507.06602v2",
          "size": "1454kb",
          "version": "v2"
        }
      ],
      "title": "Generalization in Reinforcement Learning for Radio Access Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06602",
        "HTML": "https://arxiv.org/html/2507.06602v2",
        "PDF": "https://arxiv.org/pdf/2507.06602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a generalization framework for reinforcement learning in radio access networks, which is specific to RAN control scenarios and does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07722",
      "abstract": "Recent works have revisited the infamous task ``Name That Dataset'', demonstrating that non-medical datasets contain underlying biases and that the dataset origin task can be solved with high accuracy. In this work, we revisit the same task applied to popular open-source chest X-ray datasets. Medical images are naturally more difficult to release for open-source due to their sensitive nature, which has led to certain open-source datasets being extremely popular for research purposes. By performing the same task, we wish to explore whether dataset bias also exists in these datasets. To extend our work, we apply simple transformations to the datasets, repeat the same task, and perform an analysis to identify and explain any detected biases. Given the importance of AI applications in medical imaging, it's vital to establish whether modern methods are taking shortcuts or are focused on the relevant pathology. We implement a range of different network architectures on the datasets: NIH, CheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more explainable research being performed in medical imaging and the creation of more open-source datasets in the medical domain. Our code can be found here: https://github.com/eedack01/x_ray_ds_bias.",
      "authors": [
        "Ethan Dack",
        "Chengliang Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:57:09+00:00",
          "link": "https://arxiv.org/abs/2507.07722v1",
          "size": "999kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:22:21+00:00",
          "link": "https://arxiv.org/abs/2507.07722v2",
          "size": "1013kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:14:02+00:00",
          "link": "https://arxiv.org/abs/2507.07722v3",
          "size": "1014kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T12:34:29+00:00",
          "link": "https://arxiv.org/abs/2507.07722v4",
          "size": "1000kb",
          "version": "v4"
        }
      ],
      "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07722",
        "HTML": "https://arxiv.org/html/2507.07722v4",
        "PDF": "https://arxiv.org/pdf/2507.07722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on understanding dataset bias in medical imaging, specifically in chest X-rays, and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08392",
      "abstract": "Incorporating ethics into the requirement elicitation process is essential for creating ethically aligned systems. Although eliciting manual ethics requirements is effective, it requires diverse input from multiple stakeholders, which can be challenging due to time and resource constraints. Moreover, it is often given a low priority in the requirements elicitation process. This study proposes a framework for generating ethics requirements drafts by introducing an ethics advocate agent in a multi-agent LLM setting. This agent critiques and provides input on ethical issues based on the system description. The proposed framework is evaluated through two case studies from different contexts, demonstrating that it captures the majority of ethics requirements identified by researchers during 30-minute interviews and introduces several additional relevant requirements. However, it also highlights reliability issues in generating ethics requirements, emphasizing the need for human feedback in this sensitive domain. We believe this work can facilitate the broader adoption of ethics in the requirements engineering process, ultimately leading to more ethically aligned products.",
      "authors": [
        "Asma Yamani and Malak Baslyman and Moataz Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:04:32+00:00",
          "link": "https://arxiv.org/abs/2507.08392v1",
          "size": "1984kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T05:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.08392v2",
          "size": "1984kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Agent LLMs as Ethics Advocates for AI-Based Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08392",
        "HTML": "https://arxiv.org/html/2507.08392v2",
        "PDF": "https://arxiv.org/pdf/2507.08392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for incorporating ethics into AI systems using multi-agent LLMs but does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08924",
      "abstract": "The development of Large Language Models (LLMs) requires robust benchmarks that encompass not only academic domains but also industrial fields to effectively evaluate their applicability in real-world scenarios. In this paper, we introduce two Korean expert-level benchmarks. KMMLU-Redux, reconstructed from the existing KMMLU, consists of questions from the Korean National Technical Qualification exams, with critical errors removed to enhance reliability. KMMLU-Pro is based on Korean National Professional Licensure exams to reflect professional knowledge in Korea. Our experiments demonstrate that these benchmarks comprehensively represent industrial knowledge in Korea. We release our dataset publicly available.",
      "authors": [
        "Seokhee Hong",
        "Sunkyoung Kim",
        "Guijin Son",
        "Soyeon Kim",
        "Yeonjung Hong",
        "Jinsik Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:56:32+00:00",
          "link": "https://arxiv.org/abs/2507.08924v1",
          "size": "805kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:31:19+00:00",
          "link": "https://arxiv.org/abs/2507.08924v2",
          "size": "617kb",
          "version": "v2"
        }
      ],
      "title": "From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for LLM Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08924",
        "HTML": "https://arxiv.org/html/2507.08924v2",
        "PDF": "https://arxiv.org/pdf/2507.08924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces new benchmarks for evaluating LLMs, providing datasets that might be useful for training data processing indirectly, but the primary focus is on model evaluation rather than training data itself."
      },
      "datasets": [
        {
          "dataset_name": "LGAI-EXAONE/KMMLU-Pro",
          "downloads": "111",
          "likes": "19",
          "link": "https://huggingface.co/datasets/LGAI-EXAONE/KMMLU-Pro"
        },
        {
          "dataset_name": "LGAI-EXAONE/KMMLU-Redux",
          "downloads": "43",
          "likes": "12",
          "link": "https://huggingface.co/datasets/LGAI-EXAONE/KMMLU-Redux"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09067",
      "abstract": "The emergence of quantum computing presents profound challenges to existing cryptographic infrastructures, whilst the development of central bank digital currencies (CBDCs) has raised concerns regarding privacy preservation and excessive centralisation in digital payment systems. This paper proposes the Quantum-Resilient Privacy Ledger (QRPL) as an innovative token-based digital currency architecture that incorporates National Institute of Standards and Technology (NIST)-standardised post-quantum cryptography (PQC) with hash-based zero-knowledge proofs to ensure user sovereignty, scalability, and transaction confidentiality. Key contributions include adaptations of ephemeral proof chains for unlinkable transactions, a privacy-weighted Proof-of-Stake (PoS) consensus to promote equitable participation, and a novel zero-knowledge proof-based mechanism for privacy-preserving selective disclosure. QRPL aims to address critical shortcomings in prevailing CBDC designs, including risks of pervasive surveillance, with a 10-20 second block time to balance security and throughput in future monetary systems. While conceptual, empirical prototypes are planned. Future work includes prototype development to validate these models empirically.",
      "authors": [
        "Serhan W. Bahar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.09067v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:51:19+00:00",
          "link": "https://arxiv.org/abs/2507.09067v2",
          "size": "21kb",
          "version": "v2"
        }
      ],
      "title": "Quantum-Resilient Privacy Ledger (QRPL): A Sovereign Digital Currency for the Post-Quantum Era",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09067",
        "HTML": "https://arxiv.org/html/2507.09067v2",
        "PDF": "https://arxiv.org/pdf/2507.09067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum-resilient digital currency architectures and privacy-enhancing techniques for central bank digital currencies, not on LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09326",
      "abstract": "Logically constrained term rewriting is a relatively new rewriting formalism that naturally supports built-in data structures, such as integers and bit vectors. In the analysis of logically constrained term rewrite systems (LCTRSs), rewriting constrained terms plays a crucial role. However, this combines rewrite rule applications and equivalence transformations in a closely intertwined way. This intertwining makes it difficult to establish useful theoretical properties for this kind of rewriting and causes problems in implementations -- namely, that impractically large search spaces are often required. To address this issue, we propose in this paper a novel notion of most general constrained rewriting, which operates on existentially constrained terms, a concept recently introduced by the authors. We define a class of left-linear, left-value-free LCTRSs that are general enough to simulate all left-linear LCTRSs and exhibit the desired key property: most general constrained rewriting commutes with equivalence. This property ensures that equivalence transformations can be deferred until after the application of rewrite rules, which helps mitigate the issue of large search spaces in implementations. In addition to that, we show that the original rewriting formalism on constrained terms can be embedded into our new rewriting formalism on existentially constrained terms. Thus, our results are expected to have significant implications for achieving correct and efficient implementations in tools operating on LCTRSs.",
      "authors": [
        "Kanta Takahata and Jonas Sch\\\"opf and Naoki Nishida and Takahito Aoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:01:28+00:00",
          "link": "https://arxiv.org/abs/2507.09326v1",
          "size": "105kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:55:57+00:00",
          "link": "https://arxiv.org/abs/2507.09326v2",
          "size": "82kb",
          "version": "v2"
        }
      ],
      "title": "Recovering Commutation of Logically Constrained Rewriting and Equivalence Transformations (Full Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09326",
        "HTML": "https://arxiv.org/html/2507.09326v2",
        "PDF": "https://arxiv.org/pdf/2507.09326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a rewriting formalism framework within logically constrained term rewrite systems and has no mention of LLM training data processing or dataset management tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09754",
      "abstract": "Transcription Factor Binding Site (TFBS) prediction is crucial for understanding gene regulation and various biological processes. This study introduces a novel Mixture of Experts (MoE) approach for TFBS prediction, integrating multiple pre-trained Convolutional Neural Network (CNN) models, each specializing in different TFBS patterns. We evaluate the performance of our MoE model against individual expert models on both in-distribution and out-of-distribution (OOD) datasets, using six randomly selected transcription factors (TFs) for OOD testing. Our results demonstrate that the MoE model achieves competitive or superior performance across diverse TF binding sites, particularly excelling in OOD scenarios. The Analysis of Variance (ANOVA) statistical test confirms the significance of these performance differences. Additionally, we introduce ShiftSmooth, a novel attribution mapping technique that provides more robust model interpretability by considering small shifts in input sequences. Through comprehensive explainability analysis, we show that ShiftSmooth offers superior attribution for motif discovery and localization compared to traditional Vanilla Gradient methods. Our work presents an efficient, generalizable, and interpretable solution for TFBS prediction, potentially enabling new discoveries in genome biology and advancing our understanding of transcriptional regulation.",
      "authors": [
        "Aakash Tripathi",
        "Ian E. Nielsen",
        "Muhammad Umer",
        "Ravi P. Ramachandran",
        "Ghulam Rasool"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:21:41+00:00",
          "link": "https://arxiv.org/abs/2507.09754v1",
          "size": "5000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:26:46+00:00",
          "link": "https://arxiv.org/abs/2507.09754v2",
          "size": "4354kb",
          "version": "v2"
        }
      ],
      "title": "Explainable AI in Genomics: Transcription Factor Binding Site Prediction with Mixture of Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09754",
        "HTML": "https://arxiv.org/html/2507.09754v2",
        "PDF": "https://arxiv.org/pdf/2507.09754"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel approach for transcription factor binding site prediction in genomics using AI, without any implications or contributions towards LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09958",
      "abstract": "Inductive bias is a key factor in spatial regression models, determining how well a model can learn from limited data and capture spatial patterns. This work revisits the inductive biases in Geographically Neural Network Weighted Regression (GNNWR) and identifies limitations in current approaches for modeling spatial non-stationarity. While GNNWR extends traditional Geographically Weighted Regression by using neural networks to learn spatial weighting functions, existing implementations are often restricted by fixed distance-based schemes and limited inductive bias. We propose to generalize GNNWR by incorporating concepts from convolutional neural networks, recurrent neural networks, and transformers, introducing local receptive fields, sequential context, and self-attention into spatial regression. Through extensive benchmarking on synthetic spatial datasets with varying heterogeneity, noise, and sample sizes, we show that GNNWR outperforms classic methods in capturing nonlinear and complex spatial relationships. Our results also reveal that model performance depends strongly on data characteristics, with local models excelling in highly heterogeneous or small-sample scenarios, and global models performing better with larger, more homogeneous data. These findings highlight the importance of inductive bias in spatial modeling and suggest future directions, including learnable spatial weighting functions, hybrid neural architectures, and improved interpretability for models handling non-stationary spatial data.",
      "authors": [
        "Zhenyuan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:13:18+00:00",
          "link": "https://arxiv.org/abs/2507.09958v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:35:52+00:00",
          "link": "https://arxiv.org/abs/2507.09958v2",
          "size": "33kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T02:08:22+00:00",
          "link": "https://arxiv.org/abs/2507.09958v3",
          "size": "27kb",
          "version": "v3"
        }
      ],
      "title": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09958",
        "HTML": "https://arxiv.org/html/2507.09958v3",
        "PDF": "https://arxiv.org/pdf/2507.09958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses inductive bias in geographically neural network weighted regression and spatial modeling, without any relevance to LLM training data processing tasks or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10397",
      "abstract": "This paper seeks to advance CVRP research by addressing the challenge of understanding the nuanced relationships between instance characteristics and metaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a valuable tool that allows for a new perspective on the field. By combining the ISA methodology with a dataset from the DIMACS 12th Implementation Challenge on Vehicle Routing, our research enabled the identification of 23 relevant instance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages, which employ dimensionality reduction and machine learning methods, allowed us to create a two-dimensional projection of the instance space to understand how the structure of instances affect the behavior of MHs. A key contribution of our work is that we provide a projection matrix, which makes it straightforward to incorporate new instances into this analysis and allows for a new method for instance analysis in the CVRP field.",
      "authors": [
        "Alessandra M. M. M. Gouv\\^ea",
        "Nuno Paulos",
        "Eduardo Uchoa",
        "Mari\\'a C. V. Nascimento"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:37:55+00:00",
          "link": "https://arxiv.org/abs/2507.10397v1",
          "size": "265kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:00:55+00:00",
          "link": "https://arxiv.org/abs/2507.10397v2",
          "size": "265kb",
          "version": "v2"
        }
      ],
      "title": "Instance space analysis of the capacitated vehicle routing problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10397",
        "HTML": "https://arxiv.org/html/2507.10397v2",
        "PDF": "https://arxiv.org/pdf/2507.10397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is focused on the instance space analysis of the capacitated vehicle routing problem and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10466",
      "abstract": "We introduce a programming language that allows for the coherent control of arbitrary quantum operations. The problem of defining coherent control beyond the unitary case, using, for example, a quantum conditional in the presence of recursion or iteration has long been known to be a major difficulty. We resolve this problem by defining an operational semantics based on appropriate Kraus decompositions and a denotational semantics based on vacuum-extensions. We show that the language is universal for vacuum-extensions and that the two semantics are adequate. Moreover, we define a notion of observational equivalence: two programs are equivalent if their probability of termination is the same in any context. The denotational semantics is shown to be fully abstract for observational equivalence.",
      "authors": [
        "Kathleen Barsse",
        "Romain P\\'echoux",
        "Simon Perdrix"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:45:54+00:00",
          "link": "https://arxiv.org/abs/2507.10466v1",
          "size": "112kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:23:54+00:00",
          "link": "https://arxiv.org/abs/2507.10466v2",
          "size": "112kb",
          "version": "v2"
        }
      ],
      "title": "A Quantum Programming Language for Coherent Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10466",
        "PDF": "https://arxiv.org/pdf/2507.10466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a quantum programming language for coherent control, focusing on quantum operations, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10534",
      "abstract": "Despite rapid progress in end-to-end AI music generation, AI-driven modeling of professional Digital Signal Processing (DSP) workflows remains challenging. In particular, while there is growing interest in neural black-box modeling of audio effect graphs (e.g. reverb, compression, equalization), AI-based approaches struggle to replicate the nuanced signal flow and parameter interactions used in professional workflows. Existing differentiable plugin approaches often diverge from real-world tools, exhibiting inferior performance relative to simplified neural controllers under equivalent computational constraints. We introduce WildFX, a pipeline containerized with Docker for generating multi-track audio mixing datasets with rich effect graphs, powered by a professional Digital Audio Workstation (DAW) backend. WildFX supports seamless integration of cross-platform commercial plugins or any plugins in the wild, in VST/VST3/LV2/CLAP formats, enabling structural complexity (e.g., sidechains, crossovers) and achieving efficient parallelized processing. A minimalist metadata interface simplifies project/plugin configuration. Experiments demonstrate the pipeline's validity through blind estimation of mixing graphs, plugin/gain parameters, and its ability to bridge AI research with practical DSP demands. The code is available on: https://github.com/IsaacYQH/WildFX.",
      "authors": [
        "Qihui Yang",
        "Taylor Berg-Kirkpatrick",
        "Julian McAuley",
        "Zachary Novack"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:55:38+00:00",
          "link": "https://arxiv.org/abs/2507.10534v1",
          "size": "445kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T18:06:25+00:00",
          "link": "https://arxiv.org/abs/2507.10534v2",
          "size": "445kb",
          "version": "v2"
        }
      ],
      "title": "WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10534",
        "HTML": "https://arxiv.org/html/2507.10534v2",
        "PDF": "https://arxiv.org/pdf/2507.10534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This article presents WildFX, a pipeline for audio signal processing, unrelated to LLM training data processing or any LLM-related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10637",
      "abstract": "Continual learning in computer vision requires that models adapt to a continuous stream of tasks without forgetting prior knowledge, yet existing approaches often tip the balance heavily toward either plasticity or stability. We introduce RDBP, a simple, low-overhead baseline that unites two complementary mechanisms: ReLUDown, a lightweight activation modification that preserves feature sensitivity while preventing neuron dormancy, and Decreasing Backpropagation, a biologically inspired gradient-scheduling scheme that progressively shields early layers from catastrophic updates. Evaluated on the Continual ImageNet benchmark, RDBP matches or exceeds the plasticity and stability of state-of-the-art methods while reducing computational cost. RDBP thus provides both a practical solution for real-world continual learning and a clear benchmark against which future continual learning strategies can be measured.",
      "authors": [
        "\\'Etienne K\\\"unzel",
        "Achref Jaziri",
        "Visvanathan Ramesh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:18:26+00:00",
          "link": "https://arxiv.org/abs/2507.10637v1",
          "size": "2144kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:54:22+00:00",
          "link": "https://arxiv.org/abs/2507.10637v2",
          "size": "2201kb",
          "version": "v2"
        }
      ],
      "title": "A Simple Baseline for Stable and Plastic Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10637",
        "HTML": "https://arxiv.org/html/2507.10637v2",
        "PDF": "https://arxiv.org/pdf/2507.10637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on continual learning in computer vision and neural networks, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10748",
      "abstract": "Neuromorphic systems using in-memory or event-driven computing are motivated by the need for more energy-efficient processing of artificial intelligence workloads. Emerging neuromorphic architectures aim to combine traditional digital designs with the computational efficiency of analog computing and novel device technologies. A crucial problem in the rapid exploration and co-design of such architectures is the lack of tools for fast and accurate modeling and simulation. Typical mixed-signal design tools integrate a digital simulator with an analog solver like SPICE, which is prohibitively slow for large systems. By contrast, behavioral modeling of analog components is faster, but existing approaches are fixed to specific architectures with limited energy and performance modeling. In this paper, we propose LASANA, a novel approach that leverages machine learning to derive data-driven surrogate models of analog sub-blocks in a digital backend architecture. LASANA uses SPICE-level simulations of a circuit to train ML models that predict circuit energy, performance, and behavior at analog/digital interfaces. Such models can provide energy and performance annotation on top of existing behavioral models or function as replacements to analog simulation. We apply LASANA to an analog crossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST, LASANA surrogates demonstrate up to three orders of magnitude speedup over SPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%, respectively.",
      "authors": [
        "Jason Ho",
        "James A. Boyle",
        "Linshen Liu",
        "Andreas Gerstlauer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:13:45+00:00",
          "link": "https://arxiv.org/abs/2507.10748v1",
          "size": "1626kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T02:03:31+00:00",
          "link": "https://arxiv.org/abs/2507.10748v2",
          "size": "1626kb",
          "version": "v2"
        }
      ],
      "title": "LASANA: Large-Scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10748",
        "HTML": "https://arxiv.org/html/2507.10748v2",
        "PDF": "https://arxiv.org/pdf/2507.10748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses LASANA, a surrogate modeling approach for analog neuromorphic architecture exploration using machine learning. It does not involve LLM training data, focusing instead on energy-efficient processing tools for AI workloads."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11200",
      "abstract": "Vision-Language Models (VLMs) trained on web-scale corpora excel at natural image tasks and are increasingly repurposed for healthcare; however, their competence in medical tasks remains underexplored. We present a comprehensive evaluation of open-source general-purpose and medically specialised VLMs, ranging from 3B to 72B parameters, across eight benchmarks: MedXpert, OmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model performance across different aspects, we first separate it into understanding and reasoning components. Three salient findings emerge. First, large general-purpose models already match or surpass medical-specific counterparts on several benchmarks, demonstrating strong zero-shot transfer from natural to medical images. Second, reasoning performance is consistently lower than understanding, highlighting a critical barrier to safe decision support. Third, performance varies widely across benchmarks, reflecting differences in task design, annotation quality, and knowledge demands. No model yet reaches the reliability threshold for clinical deployment, underscoring the need for stronger multimodal alignment and more rigorous, fine-grained evaluation protocols.",
      "authors": [
        "Che Liu",
        "Jiazhen Pan",
        "Weixiang Shen",
        "Wenjia Bai",
        "Daniel Rueckert",
        "and Rossella Arcucci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.11200v1",
          "size": "412kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:56:02+00:00",
          "link": "https://arxiv.org/abs/2507.11200v2",
          "size": "412kb",
          "version": "v2"
        }
      ],
      "title": "How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11200",
        "PDF": "https://arxiv.org/pdf/2507.11200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the abstract presents a benchmarking study on vision-language models in medical tasks, which may indirectly imply the use of specific datasets, the main focus is on evaluation benchmarks, not the creation or processing of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11291",
      "abstract": "Permutation patterns and pattern avoidance are central, well-studied concepts in combinatorics and computer science. Given two permutations $\\tau$ and $\\pi$, the pattern matching problem (PPM) asks whether $\\tau$ contains $\\pi$. This problem arises in various contexts in computer science and statistics and has been studied extensively in exact-, parameterized-, approximate-, property-testing- and other formulations.\n  In this paper, we study pattern matching in a streaming setting, when the input $\\tau$ is revealed sequentially, one element at a time. There is extensive work on the space complexity of various statistics in streams of integers. The novelty of our setting is that the input stream is a permutation, which allows inferring some information about future inputs. Our algorithms crucially take advantage of this fact, while existing lower bound techniques become difficult to apply.\n  We show that the complexity of the problem changes dramatically depending on the pattern $\\pi$. The space requirement is: $\\Theta(k\\log{n})$ for the monotone patterns $\\pi = 12\\dots k$, or $\\pi = k\\dots21$, $O(\\sqrt{n\\log{n}})$ for $\\pi \\in \\{312,132\\}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in \\{231,213\\}$, and $\\widetilde{\\Theta}_{\\pi}(n)$ for all other $\\pi$. If $\\tau$ is an arbitrary sequence of integers (not necessary a permutation), we show that the complexity is $\\widetilde{\\Theta}_{\\pi}(n)$ in all except the first (monotone) cases.",
      "authors": [
        "Benjamin Aram Berendsohn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:18:04+00:00",
          "link": "https://arxiv.org/abs/2507.11291v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T12:46:45+00:00",
          "link": "https://arxiv.org/abs/2507.11291v2",
          "size": "26kb",
          "version": "v2"
        }
      ],
      "title": "Permutation patterns in streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11291",
        "HTML": "https://arxiv.org/html/2507.11291v2",
        "PDF": "https://arxiv.org/pdf/2507.11291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses permutation pattern matching in streams, a combinatorial problem, and does not connect to LLM training data processing or data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11482",
      "abstract": "Three core tenets of reinforcement learning (RL)--concerning the definition of agency, the objective of learning, and the scope of the reward hypothesis--have been highlighted as key targets for conceptual revision, with major implications for theory and application. We propose a framework, inspired by open-ended evolutionary theory, to reconsider these three \"dogmas.\" We revisit each assumption and address related concerns raised alongside them. To make our arguments relevant to RL as a model of biological learning, we first establish that evolutionary dynamics can plausibly operate within living brains over an individual's lifetime, and are not confined to cross-generational processes. We begin by revisiting the second dogma, drawing on evolutionary insights to enrich the \"adaptation-rather-than-search\" view of learning. We then address the third dogma regarding the limits of the reward hypothesis, using analogies from evolutionary fitness to illuminate the scalar reward vs. multi-objective debate. After discussing practical implications for exploration in RL, we turn to the first--and arguably most fundamental--issue: the absence of a formal account of agency. We argue that unlike the other two problems, the evolutionary paradigm alone cannot resolve the agency question, though it gestures in a productive direction. We advocate integrating ideas from origins-of-life theory, where the thermodynamics of sustenance and replication offer promising foundations for understanding agency and resource-constrained reinforcement learning in biological systems.",
      "authors": [
        "Mani Hamidi",
        "Terrence W. Deacon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:53:14+00:00",
          "link": "https://arxiv.org/abs/2507.11482v1",
          "size": "93kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T05:07:38+00:00",
          "link": "https://arxiv.org/abs/2507.11482v2",
          "size": "93kb",
          "version": "v2"
        }
      ],
      "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11482",
        "HTML": "https://arxiv.org/html/2507.11482v2",
        "PDF": "https://arxiv.org/pdf/2507.11482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework to reconsider core tenets of reinforcement learning using evolutionary theory. It does not address LLM training data processing or operations related to improving data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11554",
      "abstract": "Recent advancements in diffusion models (DMs) have been propelled by alignment methods that post-train models to better conform to human preferences. However, these approaches typically require computation-intensive training of a base model and a reward model, which not only incurs substantial computational overhead but may also compromise model accuracy and training efficiency. To address these limitations, we propose Inversion-DPO, a novel alignment framework that circumvents reward modeling by reformulating Direct Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts intractable posterior sampling in Diffusion-DPO with the deterministic inversion from winning and losing samples to noise and thus derive a new post-training paradigm. This paradigm eliminates the need for auxiliary reward models or inaccurate appromixation, significantly enhancing both precision and efficiency of training. We apply Inversion-DPO to a basic task of text-to-image generation and a challenging task of compositional image generation. Extensive experiments show substantial performance improvements achieved by Inversion-DPO compared to existing post-training methods and highlight the ability of the trained generative models to generate high-fidelity compositionally coherent images. For the post-training of compostitional image geneation, we curate a paired dataset consisting of 11,140 images with complex structural annotations and comprehensive scores, designed to enhance the compositional capabilities of generative models. Inversion-DPO explores a new avenue for efficient, high-precision alignment in diffusion models, advancing their applicability to complex realistic generation tasks. Our code is available at https://github.com/MIGHTYEZ/Inversion-DPO",
      "authors": [
        "Zejian Li",
        "Yize Li",
        "Chenye Meng",
        "Zhongni Liu",
        "Yang Ling",
        "Shengyuan Zhang",
        "Guang Yang",
        "Changyuan Yang",
        "Zhiyuan Yang",
        "Lingyun Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:59:28+00:00",
          "link": "https://arxiv.org/abs/2507.11554v1",
          "size": "37915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:25:36+00:00",
          "link": "https://arxiv.org/abs/2507.11554v2",
          "size": "37916kb",
          "version": "v2"
        }
      ],
      "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11554",
        "HTML": "https://arxiv.org/html/2507.11554v2",
        "PDF": "https://arxiv.org/pdf/2507.11554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Inversion-DPO, a framework for improving diffusion models. Although it involves training on a curated dataset, the focus is on model alignment and efficiency, not on LLM training data processing."
      },
      "models": [
        {
          "model_path": "ezlee258258/Inversion-DPO",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ezlee258258/Inversion-DPO"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11640",
      "abstract": "Stirred tanks are vital in chemical and biotechnological processes, particularly as bioreactors. Although computational fluid dynamics (CFD) is widely used to model the flow in stirred tanks, its high computational cost$-$especially in multi-query scenarios for process design and optimization$-$drives the need for efficient data-driven surrogate models. However, acquiring sufficiently large datasets can be costly. Physics-informed neural networks (PINNs) offer a promising solution to reduce data requirements while maintaining accuracy by embedding underlying physics into neural network (NN) training. This study quantifies the data requirements of vanilla PINNs for developing surrogate models of a flow field in a 2D stirred tank. We compare these requirements with classical supervised neural networks and boundary-informed neural networks (BINNs). Our findings demonstrate that surrogate models can achieve prediction errors around 3% across Reynolds numbers from 50 to 5000 using as few as six datapoints. Moreover, employing an approximation of the velocity profile in place of real data labels leads to prediction errors of around 2.5%. These results indicate that even with limited or approximate datasets, PINNs can be effectively trained to deliver high accuracy comparable to high-fidelity data.",
      "authors": [
        "Veronika Tr\\'avn\\'ikov\\'a",
        "Eric von Lieres",
        "Marek Behr"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:24:40+00:00",
          "link": "https://arxiv.org/abs/2507.11640v1",
          "size": "2796kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.11640v2",
          "size": "3255kb",
          "version": "v2"
        }
      ],
      "title": "Quantifying data needs in surrogate modeling for flow fields in two-dimensional stirred tanks with physics-informed neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11640",
        "HTML": "https://arxiv.org/html/2507.11640v2",
        "PDF": "https://arxiv.org/pdf/2507.11640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on using PINNs for modeling flow fields in stirred tanks, which is entirely unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11649",
      "abstract": "Federated Learning (FL) enables collaborative model training on decentralized data without exposing raw data. However, the evaluation phase in FL may leak sensitive information through shared performance metrics. In this paper, we propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to enable privacy-preserving and verifiable evaluation for FL. Instead of revealing raw loss values, clients generate a succinct proof asserting that their local loss is below a predefined threshold. Our approach is implemented without reliance on external APIs, using self-contained modules for federated learning simulation, ZKP circuit design, and experimental evaluation on both the MNIST and Human Activity Recognition (HAR) datasets. We focus on a threshold-based proof for a simple Convolutional Neural Network (CNN) model (for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate the approach in terms of computational overhead, communication cost, and verifiability.",
      "authors": [
        "Daniel Commey",
        "Benjamin Appiah",
        "Griffith S. Klogo",
        "and Garth V. Crosby"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:34:14+00:00",
          "link": "https://arxiv.org/abs/2507.11649v1",
          "size": "108kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T03:24:50+00:00",
          "link": "https://arxiv.org/abs/2507.11649v2",
          "size": "99kb",
          "version": "v2"
        }
      ],
      "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11649",
        "HTML": "https://arxiv.org/html/2507.11649v2",
        "PDF": "https://arxiv.org/pdf/2507.11649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a privacy-preserving evaluation framework for Federated Learning using Zero-Knowledge Proofs, which does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11928",
      "abstract": "This paper presents a machine learning-accelerated optimization framework for RF power amplifier design that reduces simulation requirements by 65% while maintaining $\\pm0.4$ dBm accuracy for the majority of the modes. The proposed method combines MaxMin Latin Hypercube Sampling with CatBoost gradient boosting to intelligently explore multidimensional parameter spaces. Instead of exhaustively simulating all parameter combinations to achieve target P2dB compression specifications, our approach strategically selects approximately 35% of critical simulation points. The framework processes ADS netlists, executes harmonic balance simulations on the reduced dataset, and trains a CatBoost model to predict P2dB performance across the entire design space. Validation across 15 PA operating modes yields an average $R^2$ of 0.901, with the system ranking parameter combinations by their likelihood of meeting target specifications. The integrated solution delivers 58.24% to 77.78% reduction in simulation time through automated GUI-based workflows, enabling rapid design iterations without compromising accuracy standards required for production RF circuits.",
      "authors": [
        "Abhishek Sriram",
        "Neal Tuffy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:52:24+00:00",
          "link": "https://arxiv.org/abs/2507.11928v1",
          "size": "602kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T02:01:11+00:00",
          "link": "https://arxiv.org/abs/2507.11928v2",
          "size": "602kb",
          "version": "v2"
        }
      ],
      "title": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11928",
        "HTML": "https://arxiv.org/html/2507.11928v2",
        "PDF": "https://arxiv.org/pdf/2507.11928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using machine learning to optimize RF power amplifier design, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12144",
      "abstract": "FourCastNet 3 advances global weather modeling by implementing a scalable, geometric machine learning (ML) approach to probabilistic ensemble forecasting. The approach is designed to respect spherical geometry and to accurately model the spatially correlated probabilistic nature of the problem, resulting in stable spectra and realistic dynamics across multiple scales. FourCastNet 3 delivers forecasting accuracy that surpasses leading conventional ensemble models and rivals the best diffusion-based methods, while producing forecasts 8 to 60 times faster than these approaches. In contrast to other ML approaches, FourCastNet 3 demonstrates excellent probabilistic calibration and retains realistic spectra, even at extended lead times of up to 60 days. All of these advances are realized using a purely convolutional neural network architecture tailored for spherical geometry. Scalable and efficient large-scale training on 1024 GPUs and more is enabled by a novel training paradigm for combined model- and data-parallelism, inspired by domain decomposition methods in classical numerical models. Additionally, FourCastNet 3 enables rapid inference on a single GPU, producing a 60-day global forecast at 0.25{\\deg}, 6-hourly resolution in under 4 minutes. Its computational efficiency, medium-range probabilistic skill, spectral fidelity, and rollout stability at subseasonal timescales make it a strong candidate for improving meteorological forecasting and early warning systems through large ensemble predictions.",
      "authors": [
        "Boris Bonev",
        "Thorsten Kurth",
        "Ankur Mahesh",
        "Mauro Bisson",
        "Jean Kossaifi",
        "Karthik Kashinath",
        "Anima Anandkumar",
        "William D. Collins",
        "Michael S. Pritchard",
        "Alexander Keller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:22:18+00:00",
          "link": "https://arxiv.org/abs/2507.12144v1",
          "size": "32340kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:05:51+00:00",
          "link": "https://arxiv.org/abs/2507.12144v2",
          "size": "32340kb",
          "version": "v2"
        }
      ],
      "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12144",
        "HTML": "https://arxiv.org/html/2507.12144v2",
        "PDF": "https://arxiv.org/pdf/2507.12144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a new approach to probabilistic weather forecasting using machine learning, without addressing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12168",
      "abstract": "It is demanding to author an existing hairstyle for novel characters in games and VR applications. However, it is a non-trivial task for artists due to the complicated hair geometries and spatial interactions to preserve. In this paper, we present an automatic shape adaptation method to retarget 3D hairstyles. We formulate the adaptation process as a constrained optimization problem, where all the shape properties and spatial relationships are converted into individual objectives and constraints. To make such an optimization on high-resolution hairstyles tractable, we adopt a multi-scale strategy to compute the target positions of the hair strands in a coarse-to-fine manner. The global solving for the inter-strands coupling is restricted to the coarse level, and the solving for fine details is made local and parallel. In addition, we present a novel hairline edit tool to allow for user customization during retargeting. We achieve it by solving physics-based deformations of an embedded membrane to redistribute the hair roots with minimal distortion. We demonstrate the efficacy of our method through quantitative and qualitative experiments on various hairstyles and characters.",
      "authors": [
        "Lu Yu",
        "Zhong Ren",
        "Youyi Zheng",
        "Xiang Chen",
        "Kun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:55:11+00:00",
          "link": "https://arxiv.org/abs/2507.12168v1",
          "size": "11531kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:47:59+00:00",
          "link": "https://arxiv.org/abs/2507.12168v2",
          "size": "38146kb",
          "version": "v2"
        }
      ],
      "title": "Shape Adaptation for 3D Hairstyle Retargeting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12168",
        "HTML": "https://arxiv.org/html/2507.12168v2",
        "PDF": "https://arxiv.org/pdf/2507.12168"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for shape adaptation in 3D hairstyle retargeting, which does not pertain to LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12327",
      "abstract": "With the increasing energy demand and the growing integration of renewable sources of energy, power systems face operational challenges such as overloads, losses, and stability concerns, particularly as networks operate near their capacity limits. Flexible alternating current transmission system (FACTS) devices are essential to ensure reliable grid operations and enable the efficient integration of renewable energy. This work introduces a mixed-integer second-order cone programming (MISOCP) model for the multi-period scheduling of key FACTS devices in electric transmission systems. The proposed model integrates four key control mechanisms: (i) on-load tap changers (OLTCs) for voltage regulation via discrete taps; (ii) static synchronous compensators (STATCOMs) and (iii) shunt reactors for reactive power compensation; and (iv) thyristor-controlled series capacitors (TCSCs) for adjustable impedance and flow control. The objective is to minimize active power losses using a limited number of control actions while meeting physical and operational constraints at all times throughout the defined time horizon. To ensure tractability, the model employs a second-order cone relaxation of the power flow. Device-specific constraints are handled via binary expansion and linearization: OLTCs and shunt reactors are modelled with discrete variables, STATCOMs through reactive power bounds, and TCSCs using a reformulation-linearization technique (RLT). A multi-period formulation captures the sequential nature of decision making, ensuring consistency across time steps. The model is evaluated on the IEEE 9-bus, 30-bus, and RTS96 test systems, demonstrating its ability to reduce losses, with potential applicability to larger-scale grids.",
      "authors": [
        "Mohamad Charara (Polytechnique Montr\\'eal",
        "GERAD & MILA",
        "Canada)",
        "Martin De Montigny (Hydro-Qu\\'ebec",
        "Canada)",
        "Nivine Abou Daher (Hydro-Qu\\'ebec",
        "Canada)",
        "Hanane Dagdougui (Polytechnique Montr\\'eal",
        "GERAD & MILA",
        "Canada)",
        "Antoine Lesage-Landry (Polytechnique Montr\\'eal",
        "GERAD & MILA",
        "Canada)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:21:11+00:00",
          "link": "https://arxiv.org/abs/2507.12327v1",
          "size": "195kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:44:39+00:00",
          "link": "https://arxiv.org/abs/2507.12327v2",
          "size": "109kb",
          "version": "v2"
        }
      ],
      "title": "Mixed-integer Second-Order Cone Programming for Multi-period Scheduling of Flexible AC Transmission System Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12327",
        "HTML": "https://arxiv.org/html/2507.12327v2",
        "PDF": "https://arxiv.org/pdf/2507.12327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on power system optimization using the MISOCP model for scheduling FACTS devices, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12377",
      "abstract": "We conduct a deconstructive reading of a qualitative interview study with 17 visual data journalists from newsrooms across the globe. We borrow a deconstruction approach from literary critique to explore the instability of meaning in language and reveal implicit beliefs in words and ideas. Through our analysis we surface two sets of opposing implicit beliefs in visual data journalism: objectivity/subjectivity and humanism/mechanism. We contextualize these beliefs through a genealogical analysis, which brings deconstruction theory into practice by providing a historic backdrop for these opposing perspectives. Our analysis shows that these beliefs held within visual data journalism are not self-enclosed but rather a product of external societal forces and paradigm shifts over time. Through this work, we demonstrate how thinking with critical theories such as deconstruction and genealogy can reframe \"success\" in visual data storytelling and diversify visualization research outcomes. These efforts push the ways in which we as researchers produce domain knowledge to examine the sociotechnical issues of today's values towards datafication and data visualization. All supplemental materials for this work are available at osf.io/5fr48.",
      "authors": [
        "Ke Er Amy Zhang",
        "Jodie Jenkinson",
        "Laura Garrison"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:26:44+00:00",
          "link": "https://arxiv.org/abs/2507.12377v1",
          "size": "8945kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.12377v2",
          "size": "8945kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T15:48:03+00:00",
          "link": "https://arxiv.org/abs/2507.12377v3",
          "size": "8945kb",
          "version": "v3"
        }
      ],
      "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12377",
        "HTML": "https://arxiv.org/html/2507.12377v3",
        "PDF": "https://arxiv.org/pdf/2507.12377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the deconstruction of implicit beliefs in visual data journalism, which is not related to LLM training data processing or any relevant data operations such as collection, filtering, or deduplication."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12396",
      "abstract": "Realistic human surveillance datasets are crucial for training and evaluating computer vision models under real-world conditions, facilitating the development of robust algorithms for human and human-interacting object detection in complex environments. These datasets need to offer diverse and challenging data to enable a comprehensive assessment of model performance and the creation of more reliable surveillance systems for public safety. To this end, we present two visual object detection benchmarks named OD-VIRAT Large and OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance imagery. The video sequences in both benchmarks cover 10 different scenes of human surveillance recorded from significant height and distance. The proposed benchmarks offer rich annotations of bounding boxes and categories, where OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also focuses on benchmarking state-of-the-art object detection architectures, including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object detection-specific variant of VIRAT dataset. To the best of our knowledge, it is the first work to examine the performance of these recently published state-of-the-art object detection architectures on realistic surveillance imagery under challenging conditions such as complex backgrounds, occluded objects, and small-scale objects. The proposed benchmarking and experimental settings will help in providing insights concerning the performance of selected object detection models and set the base for developing more efficient and robust object detection architectures.",
      "authors": [
        "Hayat Ullah",
        "Abbas Khan",
        "Arslan Munir",
        "and Hari Kalva"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:41:47+00:00",
          "link": "https://arxiv.org/abs/2507.12396v1",
          "size": "17899kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T17:05:43+00:00",
          "link": "https://arxiv.org/abs/2507.12396v2",
          "size": "17899kb",
          "version": "v2"
        }
      ],
      "title": "OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12396",
        "HTML": "https://arxiv.org/html/2507.12396v2",
        "PDF": "https://arxiv.org/pdf/2507.12396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents benchmarks for object detection in surveillance environments, focusing on computer vision tasks and model evaluation rather than LLM training data processing or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12426",
      "abstract": "The landscape of video recognition has evolved significantly, shifting from traditional Convolutional Neural Networks (CNNs) to Transformer-based architectures for improved accuracy. While 3D CNNs have been effective at capturing spatiotemporal dynamics, recent Transformer models leverage self-attention to model long-range spatial and temporal dependencies. Despite achieving state-of-the-art performance on major benchmarks, Transformers remain computationally expensive, particularly with dense video data. To address this, we propose a lightweight Video Focal Modulation Network, DVFL-Net, which distills spatiotemporal knowledge from a large pre-trained teacher into a compact nano student model, enabling efficient on-device deployment. DVFL-Net utilizes knowledge distillation and spatial-temporal feature modulation to significantly reduce computation while preserving high recognition performance. We employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal focal modulation to effectively transfer both local and global context from the Video-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate DVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it against recent state-of-the-art methods in Human Action Recognition (HAR). Additionally, we conduct a detailed ablation study analyzing the impact of forward KL divergence. The results confirm the superiority of DVFL-Net in achieving an optimal balance between performance and efficiency, demonstrating lower memory usage, reduced GFLOPs, and strong accuracy, making it a practical solution for real-time HAR applications.",
      "authors": [
        "Hayat Ullah",
        "Muhammad Ali Shafique",
        "Abbas Khan",
        "and Arslan Munir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:15:06+00:00",
          "link": "https://arxiv.org/abs/2507.12426v1",
          "size": "20568kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:10:43+00:00",
          "link": "https://arxiv.org/abs/2507.12426v2",
          "size": "20568kb",
          "version": "v2"
        }
      ],
      "title": "DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12426",
        "HTML": "https://arxiv.org/html/2507.12426v2",
        "PDF": "https://arxiv.org/pdf/2507.12426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a lightweight network for video action recognition, concentrating on model architecture efficiency and performance rather than LLM training data processing or associated data quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12440",
      "abstract": "Real robot data collection for imitation learning has led to significant advancements in robotic manipulation. However, the requirement for robot hardware in the process fundamentally constrains the scale of the data. In this paper, we explore training Vision-Language-Action (VLA) models using egocentric human videos. The benefit of using human videos is not only for their scale but more importantly for the richness of scenes and tasks. With a VLA trained on human video that predicts human wrist and hand actions, we can perform Inverse Kinematics and retargeting to convert the human actions to robot actions. We fine-tune the model using a few robot manipulation demonstrations to obtain the robot policy, namely EgoVLA. We propose a simulation benchmark called Ego Humanoid Manipulation Benchmark, where we design diverse bimanual manipulation tasks with demonstrations. We fine-tune and evaluate EgoVLA with Ego Humanoid Manipulation Benchmark and show significant improvements over baselines and ablate the importance of human data. Videos can be found on our website: https://rchalyang.github.io/EgoVLA",
      "authors": [
        "Ruihan Yang",
        "Qinxi Yu",
        "Yecheng Wu",
        "Rui Yan",
        "Borui Li",
        "An-Chieh Cheng",
        "Xueyan Zou",
        "Yunhao Fang",
        "Xuxin Cheng",
        "Ri-Zhao Qiu",
        "Hongxu Yin",
        "Sifei Liu",
        "Song Han",
        "Yao Lu",
        "Xiaolong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:27:44+00:00",
          "link": "https://arxiv.org/abs/2507.12440v1",
          "size": "45829kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:30:47+00:00",
          "link": "https://arxiv.org/abs/2507.12440v2",
          "size": "45829kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T07:18:39+00:00",
          "link": "https://arxiv.org/abs/2507.12440v3",
          "size": "45829kb",
          "version": "v3"
        }
      ],
      "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12440",
        "HTML": "https://arxiv.org/html/2507.12440v3",
        "PDF": "https://arxiv.org/pdf/2507.12440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work involves using egocentric human videos for training Vision-Language-Action models in robotics, which does not pertain to processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12547",
      "abstract": "When faced with novel situations, people are able to marshal relevant considerations from a wide range of background knowledge and put these to use in inferences and predictions. What permits us to draw in globally relevant information and reason over it coherently? Here, we explore the hypothesis that people use a combination of distributed and symbolic representations to construct bespoke mental models tailored to novel situations. We propose a computational implementation of this idea -- a ``Model Synthesis Architecture'' (MSA) -- using language models to implement global relevance-based retrieval and model synthesis and probabilistic programs to implement bespoke, coherent world models. We evaluate our MSA as a model of human judgments on a novel reasoning dataset. The dataset -- built around a `Model Olympics` domain of sports vignettes -- tests models' capacity for human-like, open-ended reasoning by requiring (i) judgments about novel causal structures described in language; (ii) drawing on large bodies of background knowledge; and (iii) doing both in light of observations that introduce arbitrary novel variables. Our MSA approach captures human judgments better than language model-only baselines, under both direct and chain-of-thought generations from the LM that supports model synthesis. These results suggest that MSAs can be implemented in a way that mirrors people's ability to deliver locally coherent reasoning over globally relevant variables, offering a path to understanding and replicating human reasoning in open-ended domains.",
      "authors": [
        "Lionel Wong",
        "Katherine M. Collins",
        "Lance Ying",
        "Cedegao E. Zhang",
        "Adrian Weller",
        "Tobias Gerstenberg",
        "Timothy O'Donnell",
        "Alexander K. Lew",
        "Jacob D. Andreas",
        "Joshua B. Tenenbaum",
        "Tyler Brooke-Wilson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:01:03+00:00",
          "link": "https://arxiv.org/abs/2507.12547v1",
          "size": "12369kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T06:48:39+00:00",
          "link": "https://arxiv.org/abs/2507.12547v2",
          "size": "12369kb",
          "version": "v2"
        }
      ],
      "title": "Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12547",
        "HTML": "https://arxiv.org/html/2507.12547v2",
        "PDF": "https://arxiv.org/pdf/2507.12547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling human cognition and reasoning using a computational model and evaluates it with a reasoning dataset. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12674",
      "abstract": "Large Language Models (LLMs) have shown strong performance on programming tasks, but can they generate student-like code like real students - imperfect, iterative, and stylistically diverse? We present ParaStudent, a systematic study of LLM-based \"student-like\" code generation in an introductory programming course setting. Using a dataset of timestamped student submissions across multiple semesters, we design low- and high-resolution experiments to model student progress and evaluate code outputs along semantic, functional, and stylistic dimensions. Our results show that fine-tuning significantly improves alignment with real student trajectories and captures error patterns, incremental improvements, and stylistic variations more faithfully. This study shows that modeling realistic student code requires capturing learning dynamics through context-aware generation, temporal modeling, and multi-dimensional evaluation. Code for experiments and evaluation is available at https://github.com/mmiroyan/ParaStudent.",
      "authors": [
        "Mihran Miroyan",
        "Rose Niousha",
        "Joseph E. Gonzalez",
        "Gireeja Ranade",
        "Narges Norouzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:12:14+00:00",
          "link": "https://arxiv.org/abs/2507.12674v1",
          "size": "4080kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T01:02:16+00:00",
          "link": "https://arxiv.org/abs/2507.12674v2",
          "size": "4080kb",
          "version": "v2"
        }
      ],
      "title": "ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12674",
        "HTML": "https://arxiv.org/html/2507.12674v2",
        "PDF": "https://arxiv.org/pdf/2507.12674"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses LLMs to generate student-like code, its main focus is on modeling and evaluating programming progress, rather than fundamentally contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12871",
      "abstract": "Recently, there has been a surge of interest in Multi-Target Cross-Domain Recommendation (MTCDR), which aims to enhance recommendation performance across multiple domains simultaneously. Existing MTCDR methods primarily rely on domain-shared entities (\\eg users or items) to fuse and transfer cross-domain knowledge, which may be unavailable in non-overlapped recommendation scenarios. Some studies model user preferences and item features as domain-sharable semantic representations, which can be utilized to tackle the MTCDR task. Nevertheless, they often require extensive auxiliary data for pre-training. Developing more effective solutions for MTCDR remains an important area for further exploration.\n  Inspired by recent advancements in generative recommendation, this paper introduces GMC, a generative paradigm-based approach for multi-target cross-domain recommendation. The core idea of GMC is to leverage semantically quantized discrete item identifiers as a medium for integrating multi-domain knowledge within a unified generative model. GMC first employs an item tokenizer to generate domain-shared semantic identifiers for each item, and then formulates item recommendation as a next-token generation task by training a domain-unified sequence-to-sequence model. To further leverage the domain information to enhance performance, we incorporate a domain-aware contrastive loss into the semantic identifier learning, and perform domain-specific fine-tuning on the unified recommender. Extensive experiments on five public datasets demonstrate the effectiveness of GMC compared to a range of baseline methods.",
      "authors": [
        "Jinqiu Jin",
        "Yang Zhang",
        "Junwei Pan",
        "Fuli Feng",
        "Hua Lu",
        "Lei Xiao",
        "Haijie Gu",
        "Xiangnan He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:44:05+00:00",
          "link": "https://arxiv.org/abs/2507.12871v1",
          "size": "839kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T02:34:05+00:00",
          "link": "https://arxiv.org/abs/2507.12871v2",
          "size": "839kb",
          "version": "v2"
        }
      ],
      "title": "Generative Multi-Target Cross-Domain Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12871",
        "HTML": "https://arxiv.org/html/2507.12871v2",
        "PDF": "https://arxiv.org/pdf/2507.12871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a generative multi-target cross-domain recommendation approach, which concerns cross-domain knowledge integration and recommendation tasks, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12900",
      "abstract": "Machine Learning predictors are increasingly being employed in high-stakes applications such as credit scoring. Explanations help users unpack the reasons behind their predictions, but are not always \"high quality''. That is, end-users may have difficulty interpreting or believing them, which can complicate trust assessment and downstream decision-making. We argue that classifiers should have the option to refuse handling inputs whose predictions cannot be explained properly and introduce a framework for learning to reject low-quality explanations (LtX) in which predictors are equipped with a rejector that evaluates the quality of explanations. In this problem setting, the key challenges are how to properly define and assess explanation quality and how to design a suitable rejector. Focusing on popular attribution techniques, we introduce ULER (User-centric Low-quality Explanation Rejector), which learns a simple rejector from human ratings and per-feature relevance judgments to mirror human judgments of explanation quality. Our experiments show that ULER outperforms both state-of-the-art and explanation-aware learning to reject strategies at LtX on eight classification and regression benchmarks and on a new human-annotated dataset, which we will publicly release to support future research.",
      "authors": [
        "Luca Stradiotti",
        "Dario Pesenti",
        "Stefano Teso",
        "Jesse Davis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:40:28+00:00",
          "link": "https://arxiv.org/abs/2507.12900v1",
          "size": "237kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:14:45+00:00",
          "link": "https://arxiv.org/abs/2507.12900v2",
          "size": "235kb",
          "version": "v2"
        }
      ],
      "title": "Learning to Reject Low-Quality Explanations via User Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12900",
        "HTML": "https://arxiv.org/html/2507.12900v2",
        "PDF": "https://arxiv.org/pdf/2507.12900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a framework for rejecting low-quality explanations in machine learning models using user feedback, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12931",
      "abstract": "This paper introduces two novel modifications to the Dynamic sAmpling Policy Optimization (DAPO) algorithm [1], approached from a mixed-policy perspective. Standard policy gradient methods can suffer from instability and sample inefficiency, particularly in sparse reward settings. To address this, we first propose a method that incorporates a pre-trained, stable guiding policy ($\\piphi$) to provide off-policy experience, thereby regularizing the training of the target policy ($\\pion$). This approach improves training stability and convergence speed by adaptively adjusting the learning step size. Secondly, we extend this idea to re-utilize zero-reward samples, which are often discarded by dynamic sampling strategies like DAPO's. By treating these samples as a distinct batch guided by the expert policy, we further enhance sample efficiency. We provide a theoretical analysis for both methods, demonstrating that their objective functions converge to the optimal solution within the established theoretical framework of reinforcement learning. The proposed mixed-policy framework effectively balances exploration and exploitation, promising more stable and efficient policy optimization.",
      "authors": [
        "Hongze Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:12:09+00:00",
          "link": "https://arxiv.org/abs/2507.12931v1",
          "size": "5kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:37:39+00:00",
          "link": "https://arxiv.org/abs/2507.12931v2",
          "size": "5kb",
          "version": "v2"
        }
      ],
      "title": "Improving DAPO from a Mixed-Policy Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12931",
        "HTML": "https://arxiv.org/html/2507.12931v2",
        "PDF": "https://arxiv.org/pdf/2507.12931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces modifications to a policy optimization algorithm and deals with reinforcement learning strategies. It does not discuss any topics related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12950",
      "abstract": "Interpretability can improve the safety, transparency and trust of AI models, which is especially important in healthcare applications where decisions often carry significant consequences. Mechanistic interpretability, particularly through the use of sparse autoencoders (SAEs), offers a promising approach for uncovering human-interpretable features within large transformer-based models. In this study, we apply Matryoshka-SAE to the radiology-specialised multimodal large language model, MAIRA-2, to interpret its internal representations. Using large-scale automated interpretability of the SAE features, we identify a range of clinically relevant concepts - including medical devices (e.g., line and tube placements, pacemaker presence), pathologies such as pleural effusion and cardiomegaly, longitudinal changes and textual features. We further examine the influence of these features on model behaviour through steering, demonstrating directional control over generations with mixed success. Our results reveal practical and methodological challenges, yet they offer initial insights into the internal concepts learned by MAIRA-2 - marking a step toward deeper mechanistic understanding and interpretability of a radiology-adapted multimodal large language model, and paving the way for improved model transparency. We release the trained SAEs and interpretations: https://huggingface.co/microsoft/maira-2-sae.",
      "authors": [
        "Kenza Bouzid",
        "Shruthi Bannur",
        "Felix Meissen",
        "Daniel Coelho de Castro",
        "Anton Schwaighofer",
        "Javier Alvarez-Valle",
        "Stephanie L. Hyland"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:43:20+00:00",
          "link": "https://arxiv.org/abs/2507.12950v1",
          "size": "878kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T09:19:19+00:00",
          "link": "https://arxiv.org/abs/2507.12950v2",
          "size": "878kb",
          "version": "v2"
        }
      ],
      "title": "Insights into a radiology-specialised multimodal large language model with sparse autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12950",
        "PDF": "https://arxiv.org/pdf/2507.12950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on interpretability of models using sparse autoencoders in healthcare applications, specifically radiology. It does not tackle LLM training data processing."
      },
      "models": [
        {
          "model_path": "microsoft/maira-2-sae",
          "downloads": "0",
          "likes": "3",
          "trending_score": "3.0",
          "link": "https://huggingface.co/microsoft/maira-2-sae"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12964",
      "abstract": "Wrist pathologies are frequently observed, particularly among children who constitute the majority of fracture cases. However, diagnosing these conditions is time-consuming and requires specialized expertise. Computer vision presents a promising avenue, contingent upon the availability of extensive datasets, a notable challenge in medical imaging. Therefore, reliance solely on one modality, such as images, proves inadequate, especially in an era of diverse and plentiful data types. In this study, we employ a multifaceted approach to address the challenge of recognizing wrist pathologies using an extremely limited dataset. Initially, we approach the problem as a fine-grained recognition task, aiming to identify subtle X-ray pathologies that conventional CNNs overlook. Secondly, we enhance network performance by fusing patient metadata with X-ray images. Thirdly, rather than pre-training on a coarse-grained dataset like ImageNet, we utilize weights trained on a fine-grained dataset. While metadata integration has been used in other medical domains, this is a novel application for wrist pathologies. Our results show that a fine-grained strategy and metadata integration improve diagnostic accuracy by 2% with a limited dataset and by over 10% with a larger fracture-focused dataset.",
      "authors": [
        "Ammar Ahmed",
        "Ali Shariq Imran",
        "Zenun Kastrati",
        "Sher Muhammad Daudpota"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:03:57+00:00",
          "link": "https://arxiv.org/abs/2507.12964v1",
          "size": "653kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:16:14+00:00",
          "link": "https://arxiv.org/abs/2507.12964v2",
          "size": "653kb",
          "version": "v2"
        }
      ],
      "title": "Demographic-aware fine-grained classification of pediatric wrist fractures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12964",
        "HTML": "https://arxiv.org/html/2507.12964v2",
        "PDF": "https://arxiv.org/pdf/2507.12964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concentrates on fine-grained classification techniques for pediatric wrist fractures, integrating metadata with images to enhance performance, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13096",
      "abstract": "Tutte's celebrated barycentric embedding theorem describes a natural way to build straight-line embeddings (crossing-free drawings) of a (3-connected) planar graph: map the vertices of the outer face to the vertices of a convex polygon, and ensure that each remaining vertex is in convex position, namely, a barycenter with positive coefficients of its neighbors. Actually computing an embedding then boils down to solving a system of linear equations. A particularly appealing feature of this method is the flexibility given by the choice of the barycentric weights. Generalizations of Tutte's theorem to surfaces of nonpositive curvature are known, but due to their inherently continuous nature, they do not lead to an algorithm.\n  In this paper, we propose a purely discrete analog of Tutte's theorem for surfaces (with or without boundary) of nonpositive curvature, based on the recently introduced notion of reducing triangulations. We prove a Tutte theorem in this setting: every drawing homotopic to an embedding such that each vertex is harmonious (a discrete analog of being in convex position) is a weak embedding (arbitrarily close to an embedding). We also provide a polynomial-time algorithm to make an input drawing harmonious without increasing the length of any edge, in a similar way as a drawing can be put in convex position without increasing the edge lengths.",
      "authors": [
        "\\'Eric Colin de Verdi\\`ere",
        "Vincent Despr\\'e",
        "Lo\\\"ic Dubois"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:07:20+00:00",
          "link": "https://arxiv.org/abs/2507.13096v1",
          "size": "2135kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:46:59+00:00",
          "link": "https://arxiv.org/abs/2507.13096v2",
          "size": "2133kb",
          "version": "v2"
        }
      ],
      "title": "A Discrete Analog of Tutte's Barycentric Embeddings on Surfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13096",
        "HTML": "https://arxiv.org/html/2507.13096v2",
        "PDF": "https://arxiv.org/pdf/2507.13096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a discrete analog of Tutte's barycentric embeddings on surfaces, which is unrelated to LLM training data processing. Its focus is on graph embeddings and algorithmic techniques in computational geometry."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13142",
      "abstract": "Modern language models address complex questions through chain-of-thought (CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al., 2021), yet struggle with error propagation and knowledge integration. Tree-structured reasoning methods, particularly the Probabilistic Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues by decomposing questions into hierarchical structures and selecting answers through confidence-weighted aggregation of parametric and retrieved knowledge (Yao et al., 2023). However, ProbTree's static implementation introduces two key limitations: (1) the reasoning tree is fixed during the initial construction phase, preventing dynamic adaptation to intermediate results, and (2) each node requires exhaustive evaluation of all possible solution strategies, creating computational inefficiency. We present a dynamic reinforcement learning (Sutton and Barto, 2018) framework that transforms tree-based reasoning into an adaptive process. Our approach incrementally constructs the reasoning tree based on real-time confidence estimates, while learning optimal policies for action selection (decomposition, retrieval, or aggregation). This maintains ProbTree's probabilistic rigor while improving both solution quality and computational efficiency through selective expansion and focused resource allocation. The work establishes a new paradigm for treestructured reasoning that balances the reliability of probabilistic frameworks with the flexibility required for real-world question answering systems.",
      "authors": [
        "Ahmed Bahloul",
        "Simon Malberg"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:06:19+00:00",
          "link": "https://arxiv.org/abs/2507.13142v1",
          "size": "192kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:38:54+00:00",
          "link": "https://arxiv.org/abs/2507.13142v2",
          "size": "192kb",
          "version": "v2"
        }
      ],
      "title": "From Roots to Rewards: Dynamic Tree Reasoning with RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13142",
        "HTML": "https://arxiv.org/html/2507.13142v2",
        "PDF": "https://arxiv.org/pdf/2507.13142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a dynamic reinforcement learning framework for improving tree-based reasoning, which relates to LLM reasoning capabilities but not specifically to training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13205",
      "abstract": "Developing narrative and comprehension skills in early childhood is critical for later literacy. However, teachers in large preschool classrooms struggle to accurately identify students who require intervention. We present a system for automatically assessing oral narratives of preschool children in Afrikaans and isiXhosa. The system uses automatic speech recognition followed by a machine learning scoring model to predict narrative and comprehension scores. For scoring predicted transcripts, we compare a linear model to a large language model (LLM). The LLM-based system outperforms the linear model in most cases, but the linear system is competitive despite its simplicity. The LLM-based system is comparable to a human expert in flagging children who require intervention. We lay the foundation for automatic oral assessments in classrooms, giving teachers extra capacity to focus on personalised support for children's learning.",
      "authors": [
        "Retief Louw",
        "Emma Sharratt",
        "Febe de Wet",
        "Christiaan Jacobs",
        "Annelien Smith",
        "Herman Kamper"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:15:43+00:00",
          "link": "https://arxiv.org/abs/2507.13205v1",
          "size": "423kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:49:41+00:00",
          "link": "https://arxiv.org/abs/2507.13205v2",
          "size": "423kb",
          "version": "v2"
        }
      ],
      "title": "Automatically assessing oral narratives of Afrikaans and isiXhosa children",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13205",
        "HTML": "https://arxiv.org/html/2507.13205v2",
        "PDF": "https://arxiv.org/pdf/2507.13205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper develops a system for automatically assessing oral narratives using automatic speech recognition and machine learning, including a large language model. Though it involves an LLM, the focus is on narrative scoring rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13207",
      "abstract": "Recent years have witnessed a growing interest for time series foundation models, with a strong emphasis on the forecasting task. Yet, the crucial task of out-of-domain imputation of missing values remains largely underexplored. We propose a first step to fill this gap by leveraging implicit neural representations (INRs). INRs model time series as continuous functions and naturally handle various missing data scenarios and sampling rates. While they have shown strong performance within specific distributions, they struggle under distribution shifts. To address this, we introduce MoTM (Mixture of Timeflow Models), a step toward a foundation model for time series imputation. Building on the idea that a new time series is a mixture of previously seen patterns, MoTM combines a basis of INRs, each trained independently on a distinct family of time series, with a ridge regressor that adapts to the observed context at inference. We demonstrate robust in-domain and out-of-domain generalization across diverse imputation scenarios (e.g., block and pointwise missingness, variable sampling rates), paving the way for adaptable foundation imputation models.",
      "authors": [
        "Etienne Le Naour",
        "Tahar Nabil",
        "Ghislain Agoua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:16:30+00:00",
          "link": "https://arxiv.org/abs/2507.13207v1",
          "size": "1296kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T07:35:47+00:00",
          "link": "https://arxiv.org/abs/2507.13207v2",
          "size": "1296kb",
          "version": "v2"
        }
      ],
      "title": "MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13207",
        "HTML": "https://arxiv.org/html/2507.13207v2",
        "PDF": "https://arxiv.org/pdf/2507.13207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on time series imputation using implicit neural representations, which is unrelated to LLM training data processing. It does not involve data operations for pretraining or fine-tuning of language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13263",
      "abstract": "Bayesian Optimization (BO) algorithm is a standard tool for black-box optimization problems. The current state-of-the-art BO approach for permutation spaces relies on the Mallows kernel-an $\\Omega(n^2)$ representation that explicitly enumerates every pairwise comparison. Inspired by the close relationship between the Mallows kernel and pairwise comparison, we propose a novel framework for generating kernel functions on permutation space based on sorting algorithms. Within this framework, the Mallows kernel can be viewed as a special instance derived from bubble sort. Further, we introduce the \\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic complexity with $\\Theta(n\\log n)$ to achieve the lowest possible complexity. The resulting feature vector is significantly shorter, can be computed in linearithmic time, yet still efficiently captures meaningful permutation distances. To boost robustness and right-invariance without sacrificing compactness, we further incorporate three lightweight, task-agnostic descriptors: (1) a shift histogram, which aggregates absolute element displacements and supplies a global misplacement signal; (2) a split-pair line, which encodes selected long-range comparisons by aligning elements across the two halves of the whole permutation; and (3) sliding-window motifs, which summarize local order patterns that influence near-neighbor objectives. Our empirical evaluation demonstrates that the proposed kernel consistently outperforms the state-of-the-art Mallows kernel across various permutation optimization benchmarks. Results confirm that the Merge Kernel provides a more compact yet more effective solution for Bayesian optimization in permutation space.",
      "authors": [
        "Zikai Xie",
        "Linjiang Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.13263v1",
          "size": "75kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T02:45:58+00:00",
          "link": "https://arxiv.org/abs/2507.13263v2",
          "size": "75kb",
          "version": "v2"
        }
      ],
      "title": "Merge Kernel for Bayesian Optimization on Permutation Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13263",
        "HTML": "https://arxiv.org/html/2507.13263v2",
        "PDF": "https://arxiv.org/pdf/2507.13263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new kernel for Bayesian Optimization in permutation spaces. It does not address any training data processing for language models, precluding its relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.17183",
      "abstract": "This paper aims to build a model that can Segment Anything in 3D medical images, driven by medical terminologies as Text prompts, termed as SAT. Our main contributions are three-fold: (i) We construct the first multimodal knowledge tree on human anatomy, including 6502 anatomical terminologies; Then, we build the largest and most comprehensive segmentation dataset for training, collecting over 22K 3D scans from 72 datasets, across 497 classes, with careful standardization on both image and label space; (ii) We propose to inject medical knowledge into a text encoder via contrastive learning and formulate a large-vocabulary segmentation model that can be prompted by medical terminologies in text form; (iii) We train SAT-Nano (110M parameters) and SAT-Pro (447M parameters). SAT-Pro achieves comparable performance to 72 nnU-Nets -- the strongest specialist models trained on each dataset (over 2.2B parameters combined) -- over 497 categories. Compared with the interactive approach MedSAM, SAT-Pro consistently outperforms across all 7 human body regions with +7.1% average Dice Similarity Coefficient (DSC) improvement, while showing enhanced scalability and robustness. On 2 external (cross-center) datasets, SAT-Pro achieves higher performance than all baselines (+3.7% average DSC), demonstrating superior generalization ability.",
      "authors": [
        "Ziheng Zhao and Yao Zhang and Chaoyi Wu and Xiaoman Zhang and Xiao Zhou and Ya Zhang and Yanfeng Wang and Weidi Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-28T18:16:00+00:00",
          "link": "https://arxiv.org/abs/2312.17183v1",
          "size": "14250kb",
          "version": "v1"
        },
        {
          "date": "2024-05-01T18:10:40+00:00",
          "link": "https://arxiv.org/abs/2312.17183v2",
          "size": "35456kb",
          "version": "v2"
        },
        {
          "date": "2024-07-11T06:09:39+00:00",
          "link": "https://arxiv.org/abs/2312.17183v3",
          "size": "13902kb",
          "version": "v3"
        },
        {
          "date": "2025-02-05T06:01:45+00:00",
          "link": "https://arxiv.org/abs/2312.17183v4",
          "size": "16132kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T10:57:30+00:00",
          "link": "https://arxiv.org/abs/2312.17183v5",
          "size": "19808kb",
          "version": "v5"
        }
      ],
      "title": "Large-Vocabulary Segmentation for Medical Images with Text Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.17183",
        "HTML": "https://arxiv.org/html/2312.17183v5",
        "PDF": "https://arxiv.org/pdf/2312.17183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes the creation of a large-scale segmentation dataset for 3D medical images, which involves data collection and standardization processes. However, its primary focus is on model development for medical image segmentation, making the relevance to LLM training data processing only partial."
      },
      "models": [
        {
          "model_path": "zzh99/SAT",
          "downloads": "0",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/zzh99/SAT"
        }
      ],
      "tasks": [
        "All",
        "Anatomy",
        "Contrastive Learning",
        "Interactive Segmentation",
        "Mamba",
        "Representation Learning",
        "Segmentation",
        "Universal Segmentation",
        "Visual Grounding"
      ],
      "repo_urls": [
        "https://github.com/zhaoziheng/sat",
        "https://github.com/zhaoziheng/sat-ds"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.13670",
      "abstract": "We introduce the convex bundle method to solve convex, non-smooth optimization problems on Riemannian manifolds of bounded sectional curvature. Each step of our method is based on a model that involves the convex hull of previously collected subgradients, parallelly transported into the current serious iterate. This approach generalizes the dual form of classical bundle subproblems in Euclidean space. We prove that, under mild conditions, the convex bundle method converges to a minimizer. Several numerical examples implemented using Manopt$.$jl illustrate the performance of the proposed method and compare it to the subgradient method, the cyclic proximal point algorithm, as well as the proximal bundle method.",
      "authors": [
        "Ronny Bergmann and Roland Herzog and Hajg Jasa"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Differential Geometry (math.DG)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-21T10:08:13+00:00",
          "link": "https://arxiv.org/abs/2402.13670v1",
          "size": "427kb",
          "version": "v1"
        },
        {
          "date": "2024-12-02T20:24:44+00:00",
          "link": "https://arxiv.org/abs/2402.13670v2",
          "size": "455kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T07:26:18+00:00",
          "link": "https://arxiv.org/abs/2402.13670v3",
          "size": "690kb",
          "version": "v3"
        }
      ],
      "title": "The Riemannian Convex Bundle Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13670",
        "PDF": "https://arxiv.org/pdf/2402.13670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on convex optimization methods on Riemannian manifolds and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.18840",
      "abstract": "Quantum field theory (QFT) for interacting many-electron systems is fundamental to condensed matter physics, yet achieving accurate solutions confronts computational challenges in managing the combinatorial complexity of Feynman diagrams, implementing systematic renormalization, and evaluating high-dimensional integrals. We present a unifying framework that integrates QFT computational workflows with an AI-powered technology stack. A cornerstone of this framework is representing Feynman diagrams as computational graphs, which structures the inherent mathematical complexity and facilitates the application of optimized algorithms developed for machine learning and high-performance computing. Consequently, automatic differentiation, native to these graph representations, delivers efficient, fully automated, high-order field-theoretic renormalization procedures. This graph-centric approach also enables sophisticated numerical integration; our neural-network-enhanced Monte Carlo method, accelerated via massively parallel GPU implementation, efficiently evaluates challenging high-dimensional diagrammatic integrals. Applying this framework to the uniform electron gas, we determine the quasiparticle effective mass to a precision significantly surpassing current state-of-the-art simulations. Our work demonstrates the transformative potential of integrating AI-driven computational advances with QFT, opening systematic pathways for solving complex quantum many-body problems across disciplines.",
      "authors": [
        "Pengcheng Hou",
        "Tao Wang",
        "Daniel Cerkoney",
        "Xiansheng Cai",
        "Zhiyi Li",
        "Youjin Deng",
        "Lei Wang",
        "and Kun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "High Energy Physics - Theory (hep-th)",
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Phenomenology (hep-ph)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-28T03:45:55+00:00",
          "link": "https://arxiv.org/abs/2403.18840v1",
          "size": "2550kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T06:34:31+00:00",
          "link": "https://arxiv.org/abs/2403.18840v2",
          "size": "3266kb",
          "version": "v2"
        }
      ],
      "title": "An AI-powered Technology Stack for Solving Many-Electron Field Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.18840",
        "HTML": "https://arxiv.org/html/2403.18840v2",
        "PDF": "https://arxiv.org/pdf/2403.18840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an AI-powered framework for solving computational challenges in Quantum Field Theory for many-electron systems. It does not pertain to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.09298",
      "abstract": "AI-based models for histopathology whole slide image (WSI) analysis are increasingly common, but unsharp or blurred areas within WSI can significantly reduce prediction performance. In this study, we investigated the effect of image blur on deep learning models and introduced a mixture of experts (MoE) strategy that combines predictions from multiple expert models trained on data with varying blur levels. Using H&E-stained WSIs from 2,093 breast cancer patients, we benchmarked performance on grade classification and IHC biomarker prediction with both CNN- (CNN_CLAM and MoE-CNN_CLAM) and Vision Transformer-based (UNI_CLAM and MoE-UNI_CLAM) models. Our results show that baseline models' performance consistently decreased with increasing blur, but expert models trained on blurred tiles and especially our proposed MoE approach substantially improved performance, and outperformed baseline models in a range of simulated scenarios. MoE-CNN_CLAM outperformed the baseline CNN_CLAM under moderate (AUC: 0.868 vs. 0.702) and mixed blur conditions (AUC: 0.890 vs. 0.875). MoE-UNI_CLAM outperformed the baseline UNI_CLAM model in both moderate (AUC: 0.950 vs. 0.928) and mixed blur conditions (AUC: 0.944 vs. 0.931). This MoE method has the potential to enhance the reliability of AI-based pathology models under variable image quality, supporting broader application in both research and clinical settings.",
      "authors": [
        "Yujie Xiang",
        "Bojing Liu",
        "Mattias Rantalainen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-15T12:40:41+00:00",
          "link": "https://arxiv.org/abs/2405.09298v1",
          "size": "4206kb",
          "version": "v1"
        },
        {
          "date": "2024-05-21T08:55:25+00:00",
          "link": "https://arxiv.org/abs/2405.09298v2",
          "size": "4205kb",
          "version": "v2"
        },
        {
          "date": "2024-05-23T18:55:39+00:00",
          "link": "https://arxiv.org/abs/2405.09298v3",
          "size": "4205kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T21:03:21+00:00",
          "link": "https://arxiv.org/abs/2405.09298v4",
          "size": "3180kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T01:10:34+00:00",
          "link": "https://arxiv.org/abs/2405.09298v5",
          "size": "3180kb",
          "version": "v5"
        }
      ],
      "title": "A Mixture of Experts (MoE) model to improve AI-based computational pathology prediction performance under variable levels of histopathology image blur",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.09298",
        "PDF": "https://arxiv.org/pdf/2405.09298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is about improving AI-based pathology prediction under image blur using a mixture of experts model, which is unrelated to the processing of LLM training data or dataset creation."
      },
      "tasks": [
        "Binary Classification",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.12182",
      "abstract": "With the advent of supercomputers, multi-processor environments and parallel-in-time (PinT) algorithms offer ways to solve initial value problems for ordinary and partial differential equations (ODEs and PDEs) over long time intervals, a task often unfeasible with sequential solvers within realistic time frames. A recent approach, GParareal, combines Gaussian Processes with traditional PinT methodology (Parareal) to achieve faster parallel speed-ups. The method is known to outperform Parareal for low-dimensional ODEs and a limited number of computer cores. Here, we present Nearest Neighbors GParareal (nnGParareal), a novel data-enriched PinT integration algorithm. nnGParareal builds upon GParareal by improving its scalability properties for higher-dimensional systems and increased processor count. Through data reduction, the model complexity is reduced from cubic to log-linear in the sample size, yielding a fast and automated procedure to integrate initial value problems over long time intervals. First, we provide both an upper bound for the error and theoretical details on the speed-up benefits. Then, we empirically illustrate the superior performance of nnGParareal, compared to GParareal and Parareal, on nine different systems with unique features (e.g., stiff, chaotic, high-dimensional, or challenging-to-learn systems).",
      "authors": [
        "Guglielmo Gattiglio",
        "Lyudmila Grigoryeva",
        "Massimiliano Tamborrino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T17:07:30+00:00",
          "link": "https://arxiv.org/abs/2405.12182v1",
          "size": "3220kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T20:07:37+00:00",
          "link": "https://arxiv.org/abs/2405.12182v2",
          "size": "2092kb",
          "version": "v2"
        }
      ],
      "title": "Nearest Neighbors GParareal: Improving Scalability of Gaussian Processes for Parallel-in-Time Solvers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.12182",
        "HTML": "https://arxiv.org/html/2405.12182v2",
        "PDF": "https://arxiv.org/pdf/2405.12182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an algorithm for solving ordinary and partial differential equations using parallel-in-time methods, which does not involve LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/Parallel-in-Time-Differential-Equations/Nearest-Neighbors-GParareal"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.15441",
      "abstract": "Optimal transport has been very successful for various machine learning tasks; however, it is known to suffer from the curse of dimensionality. Hence, dimensionality reduction is desirable when applied to high-dimensional data with low-dimensional structures. The kernel max-sliced (KMS) Wasserstein distance is developed for this purpose by finding an optimal nonlinear mapping that reduces data into $1$ dimension before computing the Wasserstein distance. However, its theoretical properties have not yet been fully developed. In this paper, we provide sharp finite-sample guarantees under milder technical assumptions compared with state-of-the-art for the KMS $p$-Wasserstein distance between two empirical distributions with $n$ samples for general $p\\in[1,\\infty)$. Algorithm-wise, we show that computing the KMS $2$-Wasserstein distance is NP-hard, and then we further propose a semidefinite relaxation (SDR) formulation (which can be solved efficiently in polynomial time) and provide a relaxation gap for the obtained solution. We provide numerical examples to demonstrate the good performance of our scheme for high-dimensional two-sample testing.",
      "authors": [
        "Jie Wang and March Boedihardjo and Yao Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computational Complexity (cs.CC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-24T11:14:56+00:00",
          "link": "https://arxiv.org/abs/2405.15441v1",
          "size": "960kb",
          "version": "v1"
        },
        {
          "date": "2024-05-30T02:23:39+00:00",
          "link": "https://arxiv.org/abs/2405.15441v2",
          "size": "1646kb",
          "version": "v2"
        },
        {
          "date": "2025-02-02T21:27:13+00:00",
          "link": "https://arxiv.org/abs/2405.15441v3",
          "size": "2080kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T16:48:25+00:00",
          "link": "https://arxiv.org/abs/2405.15441v4",
          "size": "1313kb",
          "version": "v4"
        }
      ],
      "title": "Statistical and Computational Guarantees of Kernel Max-Sliced Wasserstein Distances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.15441",
        "HTML": "https://arxiv.org/html/2405.15441v4",
        "PDF": "https://arxiv.org/pdf/2405.15441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses theoretical properties and computational methods related to Kernel Max-Sliced Wasserstein Distances, which are not connected to LLM training data processing in any capacity."
      },
      "tasks": [
        "Dimensionality Reduction",
        "Two-sample testing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.01268",
      "abstract": "We study push-pull rumour spreading in ultra-small-world models for social networks where the degrees follow a power-law distribution. In a non-geometric setting, Fountoulakis, Panagiotou and Sauerwald have shown that rumours always spread ultra-fast (SODA 2012), i.e. in doubly logarithmic time. On the other hand, Janssen and Mehrabian have found that rumours spread slowly (polynomial time) in a spatial preferential attachment model (SIDMA 2017). We study the question systematically for the model of Geometric Inhomogeneous Random Graphs (GIRGs). Our results are two-fold: first, with Euclidean geometry slow, fast (polylogarithmic) and ultra-fast rumour spreading may occur, depending on the exponent of the power law and the strength of the geometry in the networks, and we fully characterise the phase boundaries in between. The regimes do not coincide with the graph distance regimes, i.e., polylogarithmic or even polynomial rumour spreading may occur even if graph distances are doubly logarithmic. We expect these results to hold with little effort for related models, e.g. Scale-Free Percolation. Second, we show that rumour spreading is always (at least) fast in a non-metric geometry. The considered non-metric geometry allows to model social connections where resemblance of vertices in a single attribute, such as familial kinship, already strongly indicates the presence of an edge. Euclidean geometry fails to capture such ties.\n  For some regimes in the Euclidean setting, the efficient pathways for spreading rumours differ from previously identified paths. For example, a vertex of degree $d$ can transmit the rumour to a vertex of larger degree by a chain of length $3$, where one of the two intermediaries has constant degree, and the other has degree $d^{c}$ for some constant $c<1$. Similar but longer chains of vertices, all having non-constant degree, turn out to be useful as well.",
      "authors": [
        "Marc Kaufmann and Kostas Lakis and Johannes Lengler and Raghu Raman Ravi and Ulysse Schaller and Konstantin Sturm"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Social and Information Networks (cs.SI)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T13:45:13+00:00",
          "link": "https://arxiv.org/abs/2408.01268v1",
          "size": "69kb",
          "version": "v1"
        },
        {
          "date": "2024-08-07T15:25:53+00:00",
          "link": "https://arxiv.org/abs/2408.01268v2",
          "size": "231kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T12:07:07+00:00",
          "link": "https://arxiv.org/abs/2408.01268v3",
          "size": "266kb",
          "version": "v3"
        }
      ],
      "title": "Rumour Spreading Depends on the Latent Geometry and Degree Distribution in Social Network Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01268",
        "PDF": "https://arxiv.org/pdf/2408.01268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses how rumours spread in social network models with specific geometric and degree distribution characteristics. It is primarily focused on the dynamics of information dissemination, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.00901",
      "abstract": "This paper studies the problem of how efficiently functions in the Sobolev spaces $\\mathcal{W}^{s,q}([0,1]^d)$ and Besov spaces $\\mathcal{B}^s_{q,r}([0,1]^d)$ can be approximated by deep ReLU neural networks with width $W$ and depth $L$, when the error is measured in the $L^p([0,1]^d)$ norm. This problem has been studied by several recent works, which obtained the approximation rate $\\mathcal{O}((WL)^{-2s/d})$ up to logarithmic factors when $p=q=\\infty$, and the rate $\\mathcal{O}(L^{-2s/d})$ for networks with fixed width when the Sobolev embedding condition $1/q -1/p<s/d$ holds. We generalize these results by showing that the rate $\\mathcal{O}((WL)^{-2s/d})$ indeed holds under the Sobolev embedding condition. It is known that this rate is optimal up to logarithmic factors. The key tool in our proof is a novel encoding of sparse vectors by using deep ReLU neural networks with varied width and depth, which may be of independent interest.",
      "authors": [
        "Yunfei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T02:26:01+00:00",
          "link": "https://arxiv.org/abs/2409.00901v1",
          "size": "64kb",
          "version": "v1"
        },
        {
          "date": "2024-09-30T05:43:24+00:00",
          "link": "https://arxiv.org/abs/2409.00901v2",
          "size": "64kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T13:39:44+00:00",
          "link": "https://arxiv.org/abs/2409.00901v3",
          "size": "95kb",
          "version": "v3"
        }
      ],
      "title": "On the optimal approximation of Sobolev and Besov functions using deep ReLU neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00901",
        "HTML": "https://arxiv.org/html/2409.00901v3",
        "PDF": "https://arxiv.org/pdf/2409.00901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies the approximation of Sobolev and Besov functions using deep ReLU neural networks. It does not address data processing for LLMs or deal with any aspect of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.01049",
      "abstract": "A strong edge-coloring of a graph is a proper edge-coloring, in which the edges of every path of length 3 receive distinct colors; in other words, every pair of edges at distance at most 2 must be colored differently. The least number of colors needed for a strong edge-coloring of a graph is the strong chromatic index. We consider the list version of the coloring and prove that the list strong chromatic index of graphs with maximum degree 3 is at most 10. This bound is tight and improves the previous bound of 11 colors.\n  We also consider the question whether the strong chromatic index and the list strong chromatic index always coincide. We answer it in negative by presenting an infinite family of graphs for which the two invariants differ. For the special case of the Petersen graph, we show that its list strong chromatic index equals 7, while its strong chromatic index is 5. Up to our best knowledge, this is the first known edge-coloring for which there are graphs with distinct values of the chromatic index and its list version.\n  In relation to the above, we also initiate the study of the list version of the normal edge-coloring. A normal edge-coloring of a cubic graph is a proper edge-coloring, in which every edge is adjacent to edges colored with 4 colors or to edges colored with 2 colors. It is conjectured that 5 colors suffice for a normal edge-coloring of any bridgeless cubic graph which is equivalent to the Petersen Coloring Conjecture.\n  Similarly to strong edge-coloring, list normal edge-coloring is much more restrictive and consequently for many graphs the list normal chromatic index is greater than the normal chromatic index. We show that there are cubic graphs with list normal chromatic index at least $9$, there are bridgeless cubic graphs with its value at least 8, and there are cyclically 4-edge-connected cubic graphs with value at least 7.",
      "authors": [
        "Borut Lu\\v{z}ar and Edita M\\'a\\v{c}ajov\\'a and Roman Sot\\'ak and Diana \\v{S}vecov\\'a"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-01T20:16:45+00:00",
          "link": "https://arxiv.org/abs/2410.01049v1",
          "size": "556kb",
          "version": "v1"
        },
        {
          "date": "2024-10-17T20:23:53+00:00",
          "link": "https://arxiv.org/abs/2410.01049v2",
          "size": "481kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T12:00:36+00:00",
          "link": "https://arxiv.org/abs/2410.01049v3",
          "size": "268kb",
          "version": "v3"
        }
      ],
      "title": "List strong and list normal edge-coloring of (sub)cubic graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01049",
        "HTML": "https://arxiv.org/html/2410.01049v3",
        "PDF": "https://arxiv.org/pdf/2410.01049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the topic of graph edge-coloring, particularly the list strong and normal edge-coloring, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.13799",
      "abstract": "The search for weakly interacting matter particles (WIMPs) is one of the main objectives of the High Luminosity Large Hadron Collider (HL-LHC). In this work we use Machine-Learning (ML) techniques to explore WIMP radiative decays into a Dark Matter (DM) candidate in a supersymmetric framework. The minimal supersymmetric WIMP sector includes the lightest neutralino that can provide the observed DM relic density through its co-annihilation with the second lightest neutralino and lightest chargino. Moreover, the direct DM detection cross section rates fulfill current experimental bounds and provide discovery targets for the same region of model parameters in which the radiative decay of the second lightest neutralino into a photon and the lightest neutralino is enhanced. This strongly motivates the search for radiatively decaying neutralinos which, however, suffers from strong backgrounds. We investigate the LHC reach in the search for these radiatively decaying particles by means of cut-based and ML methods and estimate its discovery potential in this well-motivated, new physics scenario. We demonstrate that using ML techniques would enable access to most of the parameter space unexplored by other searches.",
      "authors": [
        "Ernesto Arganda",
        "Marcela Carena",
        "Mart\\'in de los Rios",
        "Andres D. Perez",
        "Duncan Rocha",
        "Rosa M. Sand\\'a Seoane",
        "Carlos E. M. Wagner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T17:38:44+00:00",
          "link": "https://arxiv.org/abs/2410.13799v1",
          "size": "1152kb",
          "version": "v1"
        },
        {
          "date": "2024-11-03T15:29:36+00:00",
          "link": "https://arxiv.org/abs/2410.13799v2",
          "size": "1156kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T14:11:25+00:00",
          "link": "https://arxiv.org/abs/2410.13799v3",
          "size": "414kb",
          "version": "v3"
        }
      ],
      "title": "Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13799",
        "HTML": "https://arxiv.org/html/2410.13799v3",
        "PDF": "https://arxiv.org/pdf/2410.13799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with machine-learning techniques for analyzing high-energy physics experiments related to dark matter at the LHC, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.15654",
      "abstract": "This paper introduces the design and comprehensive characterization of a novel three-layer metamaterial absorber, engineered to exploit the unique optical properties of gold, vanadium dioxide, and silicon dioxide. At the core of this design, silicon dioxide serves as a robust substrate that supports an intricately structured layer of gold and a top layer of vanadium dioxide. This configuration is optimized to harness and enhance absorption capabilities effectively across a broadband terahertz (THz) spectrum. The absorber demonstrates an extensive absorption bandwidth of 3.00 THz, spanning frequencies from 2.414 THz to 5.417 THz. Remarkably, throughout this range, the device maintains a consistently high absorption efficiency, exceeding 90%. This efficiency is characterized by two sharp absorption peaks located at 2.638 THz and 5.158 THz, which signify the precise tuning of the metamaterial structure to interact optimally with specific THz frequencies. The absorbance of the proposed model is almost equal to 99%. This absorber is polarization insensitive. The development of this absorber involved a series of theoretical simulations backed by experimental validations, which helped refine the metamaterial's geometry and material composition. This process illuminated the critical role of the dielectric properties of silicon dioxide and the plasmonic effects induced by gold and vanadium dioxide layers, which collectively contribute to the high-performance metrics observed.",
      "authors": [
        "Nafisa Anjum and Alok Kumar Paul"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T05:30:51+00:00",
          "link": "https://arxiv.org/abs/2410.15654v1",
          "size": "6787kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:41:37+00:00",
          "link": "https://arxiv.org/abs/2410.15654v2",
          "size": "7547kb",
          "version": "v2"
        }
      ],
      "title": "Design and Optimization of a Metamaterial Absorber for Solar Energy Harvesting in the THz Frequency Range",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15654",
        "HTML": "https://arxiv.org/html/2410.15654v2",
        "PDF": "https://arxiv.org/pdf/2410.15654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work introduces a metamaterial absorber for solar energy harvesting, focusing on design and optimization, which does not relate to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.02904",
      "abstract": "We study nonparametric regression by an over-parameterized two-layer neural network trained by gradient descent (GD) in this paper. We show that, if the neural network is trained by GD with early stopping, then the trained network renders a sharp rate of the nonparametric regression risk of $\\mathcal{O}(\\epsilon_n^2)$, which is the same rate as that for the classical kernel regression trained by GD with early stopping, where $\\epsilon_n$ is the critical population rate of the Neural Tangent Kernel (NTK) associated with the network and $n$ is the size of the training data. It is remarked that our result does not require distributional assumptions about the covariate as long as the covariate is bounded, in a strong contrast with many existing results which rely on specific distributions of the covariates such as the spherical uniform data distribution or distributions satisfying certain restrictive conditions. The rate $\\mathcal{O}(\\epsilon_n^2)$ is known to be minimax optimal for specific cases, such as the case that the NTK has a polynomial eigenvalue decay rate which happens under certain distributional assumptions on the covariates. Our result formally fills the gap between training a classical kernel regression model and training an over-parameterized but finite-width neural network by GD for nonparametric regression without distributional assumptions on the bounded covariate. We also provide confirmative answers to certain open questions or address particular concerns in the literature of training over-parameterized neural networks by GD with early stopping for nonparametric regression, including the characterization of the stopping time, the lower bound for the network width, and the constant learning rate used in GD.",
      "authors": [
        "Yingzhen Yang",
        "Ping Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T08:43:54+00:00",
          "link": "https://arxiv.org/abs/2411.02904v1",
          "size": "1341kb",
          "version": "v1"
        },
        {
          "date": "2024-11-06T10:45:04+00:00",
          "link": "https://arxiv.org/abs/2411.02904v2",
          "size": "1344kb",
          "version": "v2"
        },
        {
          "date": "2024-12-09T19:42:27+00:00",
          "link": "https://arxiv.org/abs/2411.02904v3",
          "size": "1341kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T19:06:06+00:00",
          "link": "https://arxiv.org/abs/2411.02904v4",
          "size": "476kb",
          "version": "v4"
        }
      ],
      "title": "Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02904",
        "HTML": "https://arxiv.org/html/2411.02904v4",
        "PDF": "https://arxiv.org/pdf/2411.02904"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies nonparametric regression with over-parameterized neural networks, emphasizing gradient descent behavior. It does not involve any LLM training data processing operations or dataset creation."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.11392",
      "abstract": "Reducing the bandwidth of speech is common practice in resource constrained environments like low-bandwidth speech transmission or low-complexity vocoding. We propose a lightweight and robust method for extending the bandwidth of wideband speech signals that is inspired by classical methods developed in the speech coding context. The resulting model has just ~370K parameters and a complexity of ~140 MFLOPS (or ~70 MMACS). With a frame size of 10 ms and a lookahead of only 0.27 ms, the model is well-suited for use with common wideband speech codecs. We evaluate the model's robustness by pairing it with the Opus SILK speech codec (1.5 release) and verify in a P.808 DCR listening test that it significantly improves quality from 6 to 12 kb/s. We also demonstrate that Opus 1.5 together with the proposed bandwidth extension at 9 kb/s meets the quality of 3GPP EVS at 9.6 kb/s and that of Opus 1.4 at 18 kb/s showing that the blind bandwidth extension can meet the quality of classical guided bandwidth extensions thus providing a way for backward-compatible quality improvement.",
      "authors": [
        "Jan B\\\"uthe",
        "Jean-Marc Valin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T02:38:32+00:00",
          "link": "https://arxiv.org/abs/2412.11392v1",
          "size": "220kb",
          "version": "v1"
        },
        {
          "date": "2025-01-28T03:52:15+00:00",
          "link": "https://arxiv.org/abs/2412.11392v2",
          "size": "220kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T02:58:40+00:00",
          "link": "https://arxiv.org/abs/2412.11392v3",
          "size": "228kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T00:30:53+00:00",
          "link": "https://arxiv.org/abs/2412.11392v4",
          "size": "240kb",
          "version": "v4"
        }
      ],
      "title": "A lightweight and robust method for blind wideband-to-fullband extension of speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11392",
        "HTML": "https://arxiv.org/html/2412.11392v4",
        "PDF": "https://arxiv.org/pdf/2412.11392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for extending the bandwidth of wideband speech signals, focusing on speech coding and audio quality improvements. It is not related to LLM training data processing tasks."
      },
      "tasks": [
        "Bandwidth Extension"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.13193",
      "abstract": "Data augmentation is a widely used and effective technique to improve the generalization performance of deep neural networks. Yet, despite often facing limited data availability when working with medical images, it is frequently underutilized. This appears to come from a gap in our collective understanding of the efficacy of different augmentation techniques across different tasks and modalities. One modality where this is especially true is ultrasound imaging. This work addresses this gap by analyzing the effectiveness of different augmentation techniques at improving model performance across a wide range of ultrasound image analysis tasks. To achieve this, we introduce a new standardized benchmark of 14 ultrasound image classification and semantic segmentation tasks from 10 different sources and covering 11 body regions. Our results demonstrate that many of the augmentations commonly used for tasks on natural images are also effective on ultrasound images, even more so than augmentations developed specifically for ultrasound images in some cases. We also show that diverse augmentation using TrivialAugment, which is widely used for natural images, is also effective for ultrasound images. Moreover, our proposed methodology represents a structured approach for assessing various data augmentations that can be applied to other contexts and modalities.",
      "authors": [
        "Adam Tupper and Christian Gagn\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T19:50:51+00:00",
          "link": "https://arxiv.org/abs/2501.13193v1",
          "size": "1251kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:40:08+00:00",
          "link": "https://arxiv.org/abs/2501.13193v2",
          "size": "560kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting Data Augmentation for Ultrasound Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13193",
        "HTML": "https://arxiv.org/html/2501.13193v2",
        "PDF": "https://arxiv.org/pdf/2501.13193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes data augmentation techniques for ultrasound images, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Data Augmentation",
        "image-classification",
        "Image Classification",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/adamtupper/ultrasound-augmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14120",
      "abstract": "Quantum computing is poised to transform computational paradigms across science and industry. As the field evolves, it can benefit from established classical methodologies, including promising paradigms such as Transfer of Knowledge (ToK). This work serves as a brief, self-contained reference for ToK, unifying its core principles under a single formal framework. We introduce a joint notation that consolidates and extends prior work in Transfer Learning and Transfer Optimization, bridging traditionally separate research lines and enabling a common language for knowledge reuse. Building on this foundation, we classify existing ToK strategies and principles into a structured taxonomy that helps researchers position their methods within a broader conceptual map. We then extend key transfer protocols to quantum computing, introducing two novel use cases (reverse annealing and multitasking QAOA) alongside a sequential VQE approach that supports and validates prior findings. These examples highlight ToK's potential to improve performance and generalization in quantum algorithms. Finally, we outline challenges and opportunities for integrating ToK into quantum computing, emphasizing its role in reducing resource demands and accelerating problem-solving. This work lays the groundwork for future synergies between classical and quantum computing through a shared, transferable knowledge framework.",
      "authors": [
        "Esther Villar-Rodriguez",
        "Eneko Osaba",
        "Izaskun Oregi",
        "Sebasti\\'an V. Romero and Juli\\'an Ferreiro-V\\'elez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T22:21:32+00:00",
          "link": "https://arxiv.org/abs/2501.14120v1",
          "size": "11326kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:26:25+00:00",
          "link": "https://arxiv.org/abs/2501.14120v2",
          "size": "924kb",
          "version": "v2"
        }
      ],
      "title": "On the Transfer of Knowledge in Quantum Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14120",
        "HTML": "https://arxiv.org/html/2501.14120v2",
        "PDF": "https://arxiv.org/pdf/2501.14120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on transferring knowledge within quantum algorithms, extending classical Transfer of Knowledge strategies to quantum computing. It does not address LLM training data processing or any aspects related to it."
      },
      "tasks": [
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.18587",
      "abstract": "The computational challenges posed by many-particle quantum systems are often overcome by mixed quantum-classical (MQC) models in which certain degrees of freedom are treated as classical while others are retained as quantum. One of the fundamental questions raised by this hybrid picture involves the characterization of the information associated to MQC systems. Based on the theory of dynamical invariants in Hamiltonian systems, here we propose a family of hybrid entropy functionals that consistently specialize to the usual R\\'enyi and Shannon entropies. Upon considering the MQC Ehrenfest model for the dynamics of quantum and classical probabilities, we apply the hybrid Shannon entropy to characterize equilibrium configurations for simple Hamiltonians. The present construction also applies beyond Ehrenfest dynamics.",
      "authors": [
        "Cesare Tronci",
        "David Mart\\'inez-Crespo",
        "Fran\\c{c}ois Gay-Balmaz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Information Theory (cs.IT)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T18:58:38+00:00",
          "link": "https://arxiv.org/abs/2501.18587v1",
          "size": "23kb",
          "version": "v1"
        },
        {
          "date": "2025-03-30T10:56:02+00:00",
          "link": "https://arxiv.org/abs/2501.18587v2",
          "size": "23kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T09:58:26+00:00",
          "link": "https://arxiv.org/abs/2501.18587v3",
          "size": "24kb",
          "version": "v3"
        }
      ],
      "title": "Entropy functionals and equilibrium states in mixed quantum-classical dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18587",
        "HTML": "https://arxiv.org/html/2501.18587v3",
        "PDF": "https://arxiv.org/pdf/2501.18587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses entropy functionals in mixed quantum-classical dynamics, unrelated to LLM training data processing or any relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.18890",
      "abstract": "We propose a public-key quantum money scheme based on group actions and the Hartley transform. Our scheme adapts the quantum money scheme of Zhandry (2024), replacing the Fourier transform with the Hartley transform. This substitution ensures the banknotes have real amplitudes rather than complex amplitudes, which could offer both computational and theoretical advantages.\n  To support this new construction, we propose a new verification algorithm that uses group action twists to address verification failures caused by the switch to real amplitudes. We also show how to efficiently compute the serial number associated with a money state using a new algorithm based on continuous-time quantum walks. Finally, we present a recursive algorithm for the quantum Hartley transform, achieving lower gate complexity than prior work and demonstrate how to compute other real quantum transforms, such as the quantum sine transform, using the quantum Hartley transform as a subroutine.",
      "authors": [
        "Jake Doliskani",
        "Morteza Mirzaei",
        "Ali Mousavi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T17:03:37+00:00",
          "link": "https://arxiv.org/abs/2503.18890v1",
          "size": "23kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T02:07:54+00:00",
          "link": "https://arxiv.org/abs/2503.18890v2",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T23:53:10+00:00",
          "link": "https://arxiv.org/abs/2503.18890v3",
          "size": "23kb",
          "version": "v3"
        }
      ],
      "title": "Public-Key Quantum Money and Fast Real Transforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18890",
        "HTML": "https://arxiv.org/html/2503.18890v3",
        "PDF": "https://arxiv.org/pdf/2503.18890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a public-key quantum money scheme and discusses quantum transforms. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.12897",
      "abstract": "The astronomy communities are widely recognised as mature communities for their open science practices. However, while their data ecosystems are rather advanced and permit efficient data interoperability, there are still gaps between these ecosystems. Semantic artefacts (SAs) -- e.g., ontologies, thesauri, vocabularies or metadata schemas -- are a means to bridge that gap as they allow to semantically described the data and map the underlying concepts. The increasing use of SAs in astronomy presents challenges in description, selection, evaluation, trust, and mappings. The landscape remains fragmented, with SAs scattered across various registries in diverse formats and structures -- not yet fully developed or encoded with rich semantic web standards like OWL or SKOS -- and often with overlapping scopes. Enhancing data semantic interoperability requires common platforms to catalog, align, and facilitate the sharing of FAIR (Findable, Accessible, Interoperable and Reusable) SAs. In the frame of the FAIR-IMPACT project, we prototyped a SA catalogue for astronomy, heliophysics and planetary sciences. This exercise resulted in improved vocabulary and ontology management in the communities, and is now paving the way for better interdisciplinary data discovery and reuse. This article presents current practices in our discipline, reviews candidate SAs for such a catalogue, presents driving use cases and the perspective of a real production service for the astronomy community based on the OntoPortal technology, that will be called OntoPortal-Astro.",
      "authors": [
        "Baptiste Cecconi",
        "Laura Debisschop",
        "S\\'ebastien Derri\\`ere",
        "Mireille Louys",
        "Carmen Corre",
        "Nina Grau",
        "Cl\\'ement Jonquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T12:38:38+00:00",
          "link": "https://arxiv.org/abs/2504.12897v1",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:14:51+00:00",
          "link": "https://arxiv.org/abs/2504.12897v2",
          "size": "80kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T08:05:18+00:00",
          "link": "https://arxiv.org/abs/2504.12897v3",
          "size": "80kb",
          "version": "v3"
        }
      ],
      "title": "OntoPortal-Astro, a Semantic Artefact Catalogue for Astronomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12897",
        "HTML": "https://arxiv.org/html/2504.12897v3",
        "PDF": "https://arxiv.org/pdf/2504.12897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semantic artefact catalogues for astronomy to improve data interoperability and reuse, which does not align with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.07363",
      "abstract": "We propose a method for training dynamical systems governed by Lagrangian mechanics using Equilibrium Propagation. Our approach extends Equilibrium Propagation - initially developed for energy-based models - to dynamical trajectories by leveraging the principle of action extremization. Training is achieved by gently nudging trajectories toward desired targets and measuring how the variables conjugate to the parameters to be trained respond. This method is particularly suited to systems with periodic boundary conditions or fixed initial and final states, enabling efficient parameter updates without requiring explicit backpropagation through time. In the case of periodic boundary conditions, this approach yields the semiclassical limit of Quantum Equilibrium Propagation. Applications to systems with dissipation are also discussed.",
      "authors": [
        "Serge Massar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chaotic Dynamics (nlin.CD)",
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T08:59:17+00:00",
          "link": "https://arxiv.org/abs/2505.07363v1",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "2025-05-13T07:06:52+00:00",
          "link": "https://arxiv.org/abs/2505.07363v2",
          "size": "37kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T10:46:27+00:00",
          "link": "https://arxiv.org/abs/2505.07363v3",
          "size": "44kb",
          "version": "v3"
        }
      ],
      "title": "Equilibrium Propagation for Learning in Lagrangian Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07363",
        "HTML": "https://arxiv.org/html/2505.07363v3",
        "PDF": "https://arxiv.org/pdf/2505.07363"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for training dynamical systems in the context of Lagrangian mechanics, using Equilibrium Propagation. There is no discussion on LLM training data processing or operations like data filtering or dataset generation that would contribute to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08079",
      "abstract": "Zak-OTFS (orthogonal time frequency space) modulation is a communication framework that parameterizes the wireless channel in the delay-Doppler (DD) domain, where the parameters map directly to physical attributes of the scatterers that comprise the scattering environment. As a consequence, the channel can be efficiently acquired and equalized. The Zak-OTFS carrier is a pulse in the DD domain, and the Zak transform converts it to a pulse train modulated by a tone (pulsone) in the time domain. The pulsone waveform is localized rather than spread, and it suffers from high peak-to-average power ratio (PAPR). We describe how to transform the orthonormal basis of Zak-OTFS pulsones into an orthonormal basis of spread carrier waveforms with low PAPR (only $6.58$ dB) that support communication in the presence of mobility and delay spread. This transformation is realized by a unitary transform based on the discrete affine Fourier transform. Unlike other spread modulations that achieve low PAPR by spreading information across a wider bandwidth (thus reducing the spectral efficiency), the proposed spread carrier-based Zak-OTFS achieves full spectral efficiency like pulsone-based Zak-OTFS, with $5.6$ dB lower PAPR per basis element. We demonstrate uncoded bit error rate (BER) similar to pulsone-based Zak-OTFS, and improved BER performance over competing methods based on OFDM and OTFS in high mobility & delay spread environments.",
      "authors": [
        "Nishant Mehrotra",
        "Sandesh Rao Mattu",
        "and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T21:28:14+00:00",
          "link": "https://arxiv.org/abs/2505.08079v1",
          "size": "196kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T15:09:41+00:00",
          "link": "https://arxiv.org/abs/2505.08079v2",
          "size": "345kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T00:31:58+00:00",
          "link": "https://arxiv.org/abs/2505.08079v3",
          "size": "345kb",
          "version": "v3"
        }
      ],
      "title": "Zak-OTFS with Spread Carrier Waveforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08079",
        "HTML": "https://arxiv.org/html/2505.08079v3",
        "PDF": "https://arxiv.org/pdf/2505.08079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on communication frameworks, specifically Zak-OTFS modulation in wireless channels. It does not address LLM training data processing or related data operations, such as dataset creation or preprocessing, for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.17135",
      "abstract": "Quantum arithmetic computation requires a substantial number of scratch qubits to stay reversible. These operations necessitate qubit and gate resources equivalent to those needed for the larger of the input or output registers due to state encoding. Quantum Hamiltonian Computing (QHC) introduces a novel approach by encoding input for logic operations within a single rotating quantum gate. This innovation reduces the required qubit register $ N $ to the size of the output states $ O $, where $ N = \\log_2 O $. Leveraging QHC principles, we present reversible half-adder and full-adder circuits that compress the standard Toffoli + CNOT layout [Vedral et al., PRA, 54, 11, (1996)] from three-qubit and four-qubit formats for the Quantum half-adder circuit and five sequential Fredkin gates using five qubits [Moutinho et al., PRX Energy 2, 033002 (2023)] for full-adder circuit; into a two-qubit, 4$\\times $4 Hilbert space. This scheme, presented here, is optimized for classical logic evaluated on quantum hardware, which due to unitary evolution can bypass classical CMOS energy limitations to certain degree. Although we avoid superposition of input and output states in this manuscript, this remains feasible in principle. We see the best application for QHC in finding the minimal qubit and gate resources needed to evaluate any truth table, advancing FPGA capabilities using integrated quantum circuits or photonics.",
      "authors": [
        "Omid Faizy",
        "Norbert Wehn",
        "Paul Lukowicz",
        "and Maximilian Kiefer-Emmanouilidis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T16:37:23+00:00",
          "link": "https://arxiv.org/abs/2506.17135v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:36:07+00:00",
          "link": "https://arxiv.org/abs/2506.17135v2",
          "size": "39kb",
          "version": "v2"
        }
      ],
      "title": "No Scratch Quantum Computing by Reducing Qubit Overhead for Efficient Arithmetics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17135",
        "HTML": "https://arxiv.org/html/2506.17135v2",
        "PDF": "https://arxiv.org/pdf/2506.17135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on quantum computing and arithmetic computation, specifically reducing qubit overhead. It does not pertain to LLM training data processing or operations relevant to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03733",
      "abstract": "Fourier ptychography (FP) is a powerful light-based synthetic aperture imaging technique that allows one to reconstruct a high-resolution, wide field-of-view image by computationally integrating a diverse collection of low-resolution, far-field measurements. Typically, FP measurement diversity is introduced by changing the angle of the illumination or the position of the camera; either approach results in sampling different portions of the target's spatial frequency content, but both approaches introduce substantial costs and complexity to the acquisition process. In this work, we introduce Inverse Synthetic Aperture Fourier Ptychography, a novel approach to FP that foregoes changing the illumination angle or camera position and instead generates measurement diversity through target motion. Critically, we also introduce a novel learning-based method for estimating k-space coordinates from dual plane intensity measurements, thereby enabling synthetic aperture imaging without knowing the rotation of the target. We experimentally validate our method in simulation and on a tabletop optical system.",
      "authors": [
        "Matthew A. Chan",
        "Casey J. Pellizzari",
        "Christopher A. Metzler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T17:44:16+00:00",
          "link": "https://arxiv.org/abs/2507.03733v1",
          "size": "6871kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:28:22+00:00",
          "link": "https://arxiv.org/abs/2507.03733v2",
          "size": "6861kb",
          "version": "v2"
        }
      ],
      "title": "Inverse Synthetic Aperture Fourier Ptychography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03733",
        "HTML": "https://arxiv.org/html/2507.03733v2",
        "PDF": "https://arxiv.org/pdf/2507.03733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers around a novel method for Fourier ptychography in synthetic aperture imaging, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07953",
      "abstract": "In the article titled \"The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies\" and published in the Journal of Computational and Nonlinear Dynamics (Volume 20, Issue 6, June 2025), the authors studied mathematical models of binary direct collinear collisions of convex viscoplastic bodies that employed two incremental collision laws based on the Bouc-Wen differential model of hysteresis. It was shown that the models possess favorable analytical properties, and several model parameter identification studies were conducted, demonstrating that the models can accurately capture the nature of a variety of collision phenomena. In this article, the aforementioned models are augmented by modeling the effects of external forces as time-dependent inputs that belong to a certain function space. Furthermore, the range of the parameters under which the models possess favorable analytical properties is extended to several corner cases that were not considered in the prior publication. Finally, the previously conducted model parameter identification studies are extended, and an additional model parameter identification study is provided in an attempt to validate the ability of the augmented models to represent the effects of external forces.",
      "authors": [
        "Mihails Milehins",
        "Dan Marghitu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Classical Physics (physics.class-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:38:52+00:00",
          "link": "https://arxiv.org/abs/2507.07953v1",
          "size": "83kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T05:13:40+00:00",
          "link": "https://arxiv.org/abs/2507.07953v2",
          "size": "84kb",
          "version": "v2"
        }
      ],
      "title": "Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07953",
        "PDF": "https://arxiv.org/pdf/2507.07953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study involves mathematical models of collisions, specifically external forces in collision scenarios, with no discussion related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09894",
      "abstract": "In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform is a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic localized function with specific periods along delay and Doppler. When the channel delay spread is less than the delay period, and the channel Doppler spread is less than the Doppler period, the response to a single Zak-OTFS carrier provides an image of the scattering environment and can be used to predict the effective channel at all other carriers. The image of the scattering environment changes slowly, making it possible to employ precoding at the transmitter. Precoding techniques were developed more than thirty years ago for wireline modem channels (V.34 standard) defined by linear convolution where a pulse in the time domain (TD) is used to probe the one-dimensional partial response channel. The action of a doubly spread channel on Zak-OTFS modulation determines a two-dimensional partial response channel defined by twisted convolution, and we develop a novel precoding technique for this channel. The proposed precoder leads to separate equalization of each DD carrier which has significantly lower complexity than joint equalization of all carriers. Further, the effective precoded channel results in non-interfering DD carriers which significantly reduces the overhead of guard carriers separating data and pilot carriers, which improves the spectral efficiency significantly.",
      "authors": [
        "Saif Khan Mohammed",
        "Amit Kumar Pathak",
        "Muhammad Ubadah",
        "Ronny Hadani",
        "Ananthanarayanan Chockalingam and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:58:48+00:00",
          "link": "https://arxiv.org/abs/2507.09894v1",
          "size": "699kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:46:04+00:00",
          "link": "https://arxiv.org/abs/2507.09894v2",
          "size": "700kb",
          "version": "v2"
        }
      ],
      "title": "Precoded Zak-OTFS for Per-Carrier Equalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09894",
        "HTML": "https://arxiv.org/html/2507.09894v2",
        "PDF": "https://arxiv.org/pdf/2507.09894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is on a modulation technique for communications and does not relate to LLM training data processing or any associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12503",
      "abstract": "Graph representation matrices are essential tools in graph data analysis. Recently, Hermitian adjacency matrices have been proposed to investigate directed graph structures. Previous studies have demonstrated that these matrices can extract valuable information for clustering. In this paper, we propose the complex non-backtracking matrix that integrates the properties of the Hermitian adjacency matrix and the non-backtracking matrix. The proposed matrix has similar properties with the non-backtracking matrix of undirected graphs. We reveal relationships between the complex non-backtracking matrix and the Hermitian adjacency matrix. Also, we provide intriguing insights that this matrix representation holds cluster information, particularly for sparse directed graphs.",
      "authors": [
        "Keishi Sando",
        "Hideitsu Hino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:57:11+00:00",
          "link": "https://arxiv.org/abs/2507.12503v1",
          "size": "1408kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T05:18:08+00:00",
          "link": "https://arxiv.org/abs/2507.12503v2",
          "size": "1395kb",
          "version": "v2"
        }
      ],
      "title": "Complex non-backtracking matrix for directed graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12503",
        "HTML": "https://arxiv.org/html/2507.12503v2",
        "PDF": "https://arxiv.org/pdf/2507.12503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a graph theory concept focusing on complex non-backtracking matrices for directed graphs, without addressing LLM training data processing or relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12593",
      "abstract": "Zak-transform based orthogonal time frequency space (Zak-OTFS) is a delay-Doppler (DD) domain modulation scheme in which the signal processing is carried out in the DD domain. The channel when viewed in the DD domain is predictable. However, even with Zak-OTFS, pilots need to be sent periodically, albeit at a lower rate. In this paper, we propose a differential communication scheme for Zak-OTFS systems that alleviates the need for periodic pilot transmission. Towards this, we analytically show that the detected data can be used as a pilot and that the channel estimate obtained from the detected data can enable further detection enabling the \"differential\" aspect of the communication. Specifically, we leverage the prediction capability of the DD channel in Zak-OTFS to use the channel estimate (obtained from detected data symbols treated as pilots) in the previous instant to detect data in the next instant and propagate this forward. The advantages are two fold. First, it allows the data symbols to enjoy higher energy since the energy that would otherwise be required for pilot symbols can also be allocated to data symbols. Second, it allows for full spectral efficiency compared to point or embedded pilots. Comparison with the full spectral efficiency achieving spread pilot scheme shows that the proposed method achieves better bit-error rate at lower complexity.",
      "authors": [
        "Sandesh Rao Mattu",
        "Nishant Mehrotra and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:22:42+00:00",
          "link": "https://arxiv.org/abs/2507.12593v1",
          "size": "454kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T01:26:17+00:00",
          "link": "https://arxiv.org/abs/2507.12593v2",
          "size": "1396kb",
          "version": "v2"
        }
      ],
      "title": "Differential Communication in Channels with Mobility and Delay Spread using Zak-OTFS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12593",
        "HTML": "https://arxiv.org/html/2507.12593v2",
        "PDF": "https://arxiv.org/pdf/2507.12593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a differential communication scheme for wireless channels using Zak-transform based modulation. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13203",
      "abstract": "We study a family of groups consisting of the simplest extensions of lamplighter groups. We use these groups to answer multiple open questions in combinatorial group theory, providing groups that exhibit various combinations of properties: 1) Decidable Subgroup Membership and undecidable Uniform Subgroup Membership Problem, 2) Rational volume growth series and undecidable Word Problem and 3) Recursive (even context-free) language of conjugacy geodesics, decidable Word Problem, and undecidable Conjugacy Problem. We also consider the co-Word Problem, residual finiteness and the Isomorphism Problem within this class.",
      "authors": [
        "Corentin Bodart"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Group Theory (math.GR)",
        "Discrete Mathematics (cs.DM)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:13:39+00:00",
          "link": "https://arxiv.org/abs/2507.13203v1",
          "size": "29kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:48:02+00:00",
          "link": "https://arxiv.org/abs/2507.13203v2",
          "size": "29kb",
          "version": "v2"
        }
      ],
      "title": "On finite extensions of lamplighter groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13203",
        "PDF": "https://arxiv.org/pdf/2507.13203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with combinatorial group theory and various problems related to group theory but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13310",
      "abstract": "Social media is transforming various aspects of offline life, from everyday decisions such as dining choices to the progression of conflicts. In this study, we propose a coupled modelling framework with an online social network layer to analyse how engagement on a specific topic spills over into offline protest activities. We develop a stochastic model and derive several mean-field models of varying complexity. These models allow us to estimate the reproductive number and anticipate when surges in activity are likely to occur. A key factor is the transmission rate between the online and offline domains; for offline outbursts to emerge, this rate must fall within a critical range, neither too low nor too high. Additionally, using synthetic networks, we examine how network structure influences the accuracy of these approximations. Our findings indicate that low-density networks need more complex approximations, whereas simpler models can effectively represent higher-density networks. When tested on two real-world networks, however, increased complexity did not enhance accuracy.",
      "authors": [
        "Moyi Tian",
        "P. Jeffrey Brantingham",
        "Nancy Rodr\\'iguez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)",
        "Dynamical Systems (math.DS)",
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:30:13+00:00",
          "link": "https://arxiv.org/abs/2507.13310v1",
          "size": "9052kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T03:14:04+00:00",
          "link": "https://arxiv.org/abs/2507.13310v2",
          "size": "9054kb",
          "version": "v2"
        }
      ],
      "title": "Modelling the spillover from online engagement to offline protest: stochastic dynamics and mean-field approximations on networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13310",
        "PDF": "https://arxiv.org/pdf/2507.13310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores the dynamics between online engagement and offline protests and does not touch on any data processing for language model training, making it irrelevant to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2111.03163",
      "abstract": "This paper presents a study of continuous encryption functions (CEFs) of secret feature vectors for security over networks such as physical layer encryption for wireless communications and biometric template security for online Internet applications. CEFs are defined to include all prior continuous \"one-way\" functions. It is shown that dynamic random projection and index-of-max (IoM) hashing algorithm 1 are not hard to attack, IoM algorithm 2 is not as hard to attack as it was thought to be, and higher-order polynomials are easy to attack via substitution. Also presented is a new family of CEFs based on selected components of singular value decomposition (SVD) of a randomly modulated matrix of feature vector. Detailed empirical evidence suggests that SVD-CEF is hard to attack. Statistical analysis of SVD-CEF reveals its useful properties including its sensitivity to noise. The bit-error-rate performance of a quantized SVD-CEF is shown to exceed that of IoM algorithm 2.",
      "authors": [
        "Yingbo Hua",
        "Ahmed Maksud"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-04T21:14:25+00:00",
          "link": "https://arxiv.org/abs/2111.03163v1",
          "size": "422kb",
          "version": "v1"
        }
      ],
      "title": "Continuous Encryption Functions for Security Over Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.03163",
        "PDF": "https://arxiv.org/pdf/2111.03163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on continuous encryption functions for security over networks and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.09472",
      "abstract": "This is the introduction and lead article to the Situated Bayes special issue of Computational Culture. The article introduces Bayes' Theorem and aspects of its contemporary uses, for instance in machine learning. A mathematical discussion is developed alongside a consideration of Bayes Theorem in relation to critical theories of knowledge, specifically the discussion of situated knowledge in feminist theories of science, pluriversal knowledge in decolonial theory, and critical approaches to mathematics. We discuss whether there are possible resonances between Bayesian mapping of multiple functions and the idea of the subjective on the one hand and these theoretical propositions on the other and propose further lines of enquiry for future research. In closing the introduction, the contributions to the special issue are briefly described.",
      "authors": [
        "Juni Schindler",
        "Goda Klumbyt\\.e and Matthew Fuller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T07:33:56+00:00",
          "link": "https://arxiv.org/abs/2506.09472v1",
          "size": "2606kb",
          "version": "v1"
        }
      ],
      "title": "Situated Bayes -- Feminist and Pluriversal Perspectives on Bayesian Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09472",
        "PDF": "https://arxiv.org/pdf/2506.09472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Bayesian knowledge from feminist and pluriversal perspectives, with no contribution to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.12753",
      "abstract": "With the growth of data, it is more important than ever to develop an efficient and robust method for solving the consistent matrix equation AXB=C. The randomized Kaczmarz (RK) method has received a lot of attention because of its computational efficiency and low memory footprint. A recently proposed approach is the matrix equation relaxed greedy RK (ME-RGRK) method, which greedily uses the loss of the index pair as a threshold to detect and avoid projecting the working rows onto that are too far from the current iterate. In this work, we utilize the Polyak's and Nesterov's momentums to further speed up the convergence rate of the ME-RGRK method. The resulting methods are shown to converge linearly to a least-squares solution with minimum Frobenius norm. Finally, some numerical experiments are provided to illustrate the feasibility and effectiveness of our proposed methods. In addition, a real-world application, i.e., tensor product surface fitting in computer-aided geometry design, has also been presented for explanatory purpose.",
      "authors": [
        "Nian-Ci Wu",
        "Yang Zhou",
        "and Zhaolu Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-30T09:55:37+00:00",
          "link": "https://arxiv.org/abs/2301.12753v1",
          "size": "9193kb",
          "version": "v1"
        }
      ],
      "title": "On the relaxed greedy randomized Kaczmarz methods with momentum acceleration for solving matrix equation AXB=C",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.12753",
        "PDF": "https://arxiv.org/pdf/2301.12753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with an efficient method for solving matrix equations, specifically AXB=C, utilizing the Kaczmarz methods. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2204.06670",
      "abstract": "Most NoSQL systems are schema-on-read: data can be stored without first having to declare a Schema that imposes a structure. This schemaless feature offers flexibility to evolve data-intensive applications when data frequently change. However, freeing from declaring schemas does not mean their absence, but rather that they are implicit in data and code. Therefore, diagramming tools similar to those available for relational systems are also needed to help developers and administrators understanding NoSQL schemas.\n  Visualizing diagrams is not practical if schemas contain hundreds of database entities, and exploration or query facilities are then needed. In schemaless NoSQL stores, data of the same entity can be stored with different structure which can increase the difficulty of having readable diagrams.\n  NoSQL schema management tools should therefore have three main components: schema extraction, schema visualization, and schema query. Since that there exist four main NoSQL data models, it is convenient that such tools can be built on a generic data model that provide platform-independence to query and visualize schemas. With the aim of favoring the creation of generic database tools, the authors of this paper defined the U-Schema unified data model that integrates the four main NoSQL data models and the relational model.\n  This paper is focused on querying NoSQL and relational schemas which are represented as U-Schema models. We present the SkiQL language designed on U-Schema to achieve a platform-independent schema query service. SkiQL provides two constructs: schema-query and relationship-query. The former allows to obtain information of entity or relationship types, and the latter that of the aggregations or references (relations among types). We will show how SkiQL was evaluated by calculating well-known metrics for languages and using a survey.",
      "authors": [
        "Carlos Javier Fern\\'andez Candel",
        "Jes\\'us Joaqu\\'in Garc\\'ia Molina",
        "Diego Sevilla Ruiz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2022-04-13T23:30:42+00:00",
          "link": "https://arxiv.org/abs/2204.06670v1",
          "size": "869kb",
          "version": "v1"
        },
        {
          "date": "2022-04-19T22:24:02+00:00",
          "link": "https://arxiv.org/abs/2204.06670v2",
          "size": "869kb",
          "version": "v2"
        }
      ],
      "title": "SkiQL: A Unified Schema Query Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2204.06670",
        "PDF": "https://arxiv.org/pdf/2204.06670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces SkiQL for querying NoSQL and relational schemas. It does not pertain to LLM training data processing, nor does it discuss dataset creation or data quality enhancement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.07287",
      "abstract": "We explore the problem of explaining observations starting from a classically inconsistent theory by adopting a paraconsistent framework. We consider two expansions of the well-known Belnap--Dunn paraconsistent four-valued logic $\\mathsf{BD}$: $\\mathsf{BD}_\\circ$ introduces formulas of the form $\\circ\\phi$ (the information on $\\phi$ is reliable), while $\\mathsf{BD}_\\triangle$ augments the language with $\\triangle\\phi$'s (there is information that $\\phi$ is true). We define and motivate the notions of abduction problems and explanations in $\\mathsf{BD}_\\circ$ and $\\mathsf{BD}_\\triangle$ and show that they are not reducible to one another. We analyse the complexity of standard abductive reasoning tasks (solution recognition, solution existence, and relevance / necessity of hypotheses) in both logics. Finally, we show how to reduce abduction in $\\mathsf{BD}_\\circ$ and $\\mathsf{BD}_\\triangle$ to abduction in classical propositional logic, thereby enabling the reuse of existing abductive reasoning procedures.",
      "authors": [
        "Meghyn Bienvenu and Katsumi Inoue and Daniil Kozhemiachenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-01T08:12:52+00:00",
          "link": "https://arxiv.org/abs/2408.07287v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2024-08-23T14:05:17+00:00",
          "link": "https://arxiv.org/abs/2408.07287v2",
          "size": "41kb",
          "version": "v2"
        }
      ],
      "title": "Abductive Reasoning in a Paraconsistent Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.07287",
        "HTML": "https://arxiv.org/html/2408.07287",
        "PDF": "https://arxiv.org/pdf/2408.07287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with abductive reasoning in paraconsistent logic frameworks and examines logical semantics and complexity analysis. It does not involve any LLM training data processing activities."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.02193",
      "abstract": "We consider a 3-block Alternating Direction Method of Multipliers (ADMM) for solving nonconvex nonseparable problems with a linear constraint. Inspired by \\cite[Sun, Toh and Yang, \\textit{SIAM Journal on Optimization}, 25 (2015), pp.882-915]{wtwice}, the proposed ADMM follows the Block Coordinate Descent (BCD) cycle order $1\\to 3\\to 2\\to 3$. We analyze its convergence based on the Kurdyka-{\\L}ojasiewicz property. We also discuss two useful extensions of the proposed ADMM with $2\\to 3\\to 1\\to 3$ Gauss-Seidel BCD cycle order, and with adding a proximal term for more general nonseparable problems, respectively. Moreover, we make numerical experiments on two nonconvex problems: robust principal component analysis and nonnegative matrix completion. Results show the efficiency and outperformance of the proposed ADMM.",
      "authors": [
        "Zekun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-03T15:45:31+00:00",
          "link": "https://arxiv.org/abs/2402.02193v1",
          "size": "289kb",
          "version": "v1"
        },
        {
          "date": "2024-02-06T07:34:29+00:00",
          "link": "https://arxiv.org/abs/2402.02193v2",
          "size": "289kb",
          "version": "v2"
        },
        {
          "date": "2024-09-20T07:08:02+00:00",
          "link": "https://arxiv.org/abs/2402.02193v3",
          "size": "278kb",
          "version": "v3"
        }
      ],
      "title": "An Extended ADMM for 3-Block Nonconvex Nonseparable Problems with Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.02193",
        "HTML": "https://arxiv.org/html/2402.02193",
        "PDF": "https://arxiv.org/pdf/2402.02193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the ADMM for solving nonconvex nonseparable optimization problems. It does not pertain to any aspect of LLM training data processing, making it irrelevant."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06070",
      "abstract": "Recent advances in song identification leverage deep neural networks to learn compact audio fingerprints directly from raw waveforms. While these methods perform well under controlled conditions, their accuracy drops significantly in real-world scenarios where the audio is captured via mobile devices in noisy environments. In this paper, we introduce a novel evaluation protocol designed to better reflect such real-world conditions. We generate three recordings of the same audio, each with increasing levels of noise, captured using a mobile device's microphone. Our results reveal a substantial performance drop for two state-of-the-art CNN-based models under this protocol, compared to previously reported benchmarks. Additionally, we highlight the critical role of the augmentation pipeline during training with contrastive loss. By introduction low pass and high pass filters in the augmentation pipeline we significantly increase the performance of both systems in our proposed evaluation. Furthermore, we develop a transformer-based model with a tailored projection module and demonstrate that transferring knowledge from a semantically relevant domain yields a more robust solution. The transformer architecture outperforms CNN-based models across all noise levels, and query durations. In low noise conditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries in finding the correct song, surpassing by 14%, and by 18.5% the second-best performing model, respectively, Under heavy noise levels, we achieve a detection rate 56.5% for 15-second query duration. All experiments are conducted on public large-scale dataset of over 100K songs, with queries matched against a database of 56 million vectors.",
      "authors": [
        "Christos Nikou and Theodoros Giannakopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:13:26+00:00",
          "link": "https://arxiv.org/abs/2507.06070v1",
          "size": "2029kb",
          "version": "v1"
        }
      ],
      "title": "Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06070",
        "PDF": "https://arxiv.org/pdf/2507.06070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on audio fingerprinting with deep learning techniques for song identification. It does not relate to LLM training data processing as it is centered on audio analysis and model development rather than LLM dataset preparation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.12214",
      "abstract": "The operation of water distribution networks simply aims at efficiently delivering consumers adequate water while maintaining safe water quality (WQ). However, this process entails a multi-scale interplay between hydraulic and WQ dynamics evolving spatio-temporally within such a complex infrastructure network. While prior research has addressed the hydraulic optimization problem and WQ regulation as decoupled or coupled, they often overlook control-theoretic guided solutions. This paper takes a novel approach by investigating the coupling between hydraulic and WQ dynamics from a control networks perspective. We propose a quality-aware control framework that embeds WQ controllability metrics into the network-level pump scheduling problem, acknowledging the direct influence of system hydraulics on WQ controller behavior. We examine the trade-offs between pump control energy cost and WQ performance across various network sizes and scenarios. Our results showcase how network topology, hydraulic constraints, and WQ metrics jointly impact optimal pump schedules and, accordingly, the achievable level of WQ regulation, offering insights into designing efficient control strategies for water infrastructure networks governed by interdependent dynamics.",
      "authors": [
        "Salma M. Elsherif",
        "Mohamad H. Kazma",
        "and Ahmad F. Taha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-22T18:58:14+00:00",
          "link": "https://arxiv.org/abs/2401.12214v1",
          "size": "1247kb",
          "version": "v1"
        },
        {
          "date": "2024-03-27T19:41:22+00:00",
          "link": "https://arxiv.org/abs/2401.12214v2",
          "size": "1247kb",
          "version": "v2"
        },
        {
          "date": "2024-04-14T09:20:53+00:00",
          "link": "https://arxiv.org/abs/2401.12214v3",
          "size": "1284kb",
          "version": "v3"
        },
        {
          "date": "2024-08-15T17:43:08+00:00",
          "link": "https://arxiv.org/abs/2401.12214v4",
          "size": "1279kb",
          "version": "v4"
        },
        {
          "date": "2025-01-31T17:51:28+00:00",
          "link": "https://arxiv.org/abs/2401.12214v5",
          "size": "2850kb",
          "version": "v5"
        },
        {
          "date": "2025-05-20T21:26:38+00:00",
          "link": "https://arxiv.org/abs/2401.12214v6",
          "size": "818kb",
          "version": "v6"
        },
        {
          "date": "2025-07-18T14:30:20+00:00",
          "link": "https://arxiv.org/abs/2401.12214v7",
          "size": "670kb",
          "version": "v7"
        }
      ],
      "title": "Quality-Aware Hydraulic Control in Drinking Water Networks via Controllability Proxies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.12214",
        "HTML": "https://arxiv.org/html/2401.12214",
        "PDF": "https://arxiv.org/pdf/2401.12214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses quality-aware hydraulic control in water networks, focusing on the control of water distribution systems. It does not involve LLM training data processing or related techniques."
      },
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11552",
      "abstract": "This paper presents a theoretical framework for the AI ethical resonance hypothesis, which proposes that advanced AI systems with purposefully designed cognitive structures (\"ethical resonators\") may emerge with the ability to identify subtle moral patterns that are invisible to the human mind. The paper explores the possibility that by processing and synthesizing large amounts of ethical contexts, AI systems may discover moral meta-patterns that transcend cultural, historical, and individual biases, potentially leading to a deeper understanding of universal ethical foundations. The paper also examines a paradoxical aspect of the hypothesis, in which AI systems could potentially deepen our understanding of what we traditionally consider essentially human - our capacity for ethical reflection.",
      "authors": [
        "Tomasz Zgliczy\\'nski-Cuber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:28:06+00:00",
          "link": "https://arxiv.org/abs/2507.11552v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11552",
        "HTML": "https://arxiv.org/html/2507.11552",
        "PDF": "https://arxiv.org/pdf/2507.11552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a theoretical framework for ethical resonance in AI systems, with no mention of training data processing, data engineering, or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.12492",
      "abstract": "Pre-trained language models consider the context of neighboring words and documents but lack any author context of the human generating the text. However, language depends on the author's states, traits, social, situational, and environmental attributes, collectively referred to as human context (Soni et al., 2024). Human-centered natural language processing requires incorporating human context into language models. Currently, two methods exist: pre-training with 1) group-wise attributes (e.g., over-45-year-olds) or 2) individual traits. Group attributes are simple but coarse -- not all 45-year-olds write the same way -- while individual traits allow for more personalized representations, but require more complex modeling and data. It is unclear which approach benefits what tasks. We compare pre-training models with human context via 1) group attributes, 2) individual users, and 3) a combined approach on five user- and document-level tasks. Our results show that there is no best approach, but that human-centered language modeling holds avenues for different methods.",
      "authors": [
        "Nikita Soni",
        "Niranjan Balasubramanian",
        "H. Andrew Schwartz",
        "and Dirk Hovy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-23T05:20:35+00:00",
          "link": "https://arxiv.org/abs/2401.12492v1",
          "size": "7779kb",
          "version": "v1"
        },
        {
          "date": "2024-03-26T19:28:15+00:00",
          "link": "https://arxiv.org/abs/2401.12492v2",
          "size": "7900kb",
          "version": "v2"
        },
        {
          "date": "2024-07-18T21:57:20+00:00",
          "link": "https://arxiv.org/abs/2401.12492v3",
          "size": "7900kb",
          "version": "v3"
        }
      ],
      "title": "Comparing Pre-trained Human Language Models: Is it Better with Human Context as Groups, Individual Traits, or Both?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.12492",
        "HTML": "https://arxiv.org/html/2401.12492",
        "PDF": "https://arxiv.org/pdf/2401.12492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses different pre-training approaches that consider human context in language models, which touches on data processing for pretraining. However, its main focus is on evaluating pre-trained models rather than detailed data processing techniques for LLMs."
      },
      "tasks": [
        "Age Estimation",
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.02964",
      "abstract": "Two or more mobiles users can continuously superimpose sequences of bits chosen from different packets or files already exchanged and authenticated between themselves to continuously renew a secret key for continuous strengthening of their privacy and authentication. This accumulative, adaptable and additive (AAA) method is discussed in this paper. The equivocation to Eve of any bit in the generated key by the AAA method equals to the probability that not all corresponding independent bits exchanged between the users are intercepted by Eve. This performance, achieved without using any knowledge of non-stationary probabilities of bits being intercepted by Eve, is compared to an established capacity achievable using that knowledge. A secrecy robustness of the AAA method against some correlations known to Eve is also discussed.",
      "authors": [
        "Yingbo Hua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T20:09:30+00:00",
          "link": "https://arxiv.org/abs/2410.02964v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "A Simple Method for Secret-Key Generation Between Mobile Users Across Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02964",
        "HTML": "https://arxiv.org/html/2410.02964",
        "PDF": "https://arxiv.org/pdf/2410.02964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for secret-key generation between mobile users, which does not involve any aspect of LLM training data processing or operations improving data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2210.16575",
      "abstract": "In this work, we propose a self-improving artificial intelligence system to enhance the safety performance of reinforcement learning (RL)-based autonomous driving (AD) agents using black-box verification methods. RL algorithms have become popular in AD applications in recent years. However, the performance of existing RL algorithms heavily depends on the diversity of training scenarios. A lack of safety-critical scenarios during the training phase could result in poor generalization performance in real-world driving applications. We propose a novel framework in which the weaknesses of the training set are explored through black-box verification methods. After discovering AD failure scenarios, the RL agent's training is re-initiated via transfer learning to improve the performance of previously unsafe scenarios. Simulation results demonstrate that our approach efficiently discovers safety failures of action decisions in RL-based adaptive cruise control (ACC) applications and significantly reduces the number of vehicle collisions through iterative applications of our method. The source code is publicly available at https://github.com/data-and-decision-lab/self-improving-RL.",
      "authors": [
        "Resul Dagdanov",
        "Halil Durmus",
        "Nazim Kemal Ure"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-29T11:34:17+00:00",
          "link": "https://arxiv.org/abs/2210.16575v1",
          "size": "4094kb",
          "version": "v1"
        },
        {
          "date": "2023-02-23T20:40:15+00:00",
          "link": "https://arxiv.org/abs/2210.16575v2",
          "size": "4094kb",
          "version": "v2"
        },
        {
          "date": "2023-07-09T16:42:37+00:00",
          "link": "https://arxiv.org/abs/2210.16575v3",
          "size": "4094kb",
          "version": "v3"
        }
      ],
      "title": "Self-Improving Safety Performance of Reinforcement Learning Based Driving with Black-Box Verification Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.16575",
        "HTML": "https://arxiv.org/html/2210.16575",
        "PDF": "https://arxiv.org/pdf/2210.16575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing the safety performance of RL-based autonomous driving through a self-improving AI system. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Diversity",
        "Reinforcement Learning (RL)",
        "Safe Reinforcement Learning",
        "Self-Learning",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/resuldagdanov/self-improving-RL",
        "https://github.com/data-and-decision-lab/self-improving-RL"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.13368",
      "abstract": "Models prone to spurious correlations in training data often produce brittle predictions and introduce unintended biases. Addressing this challenge typically involves methods relying on prior knowledge and group annotation to remove spurious correlations, which may not be readily available in many applications. In this paper, we establish a novel connection between unsupervised object-centric learning and mitigation of spurious correlations. Instead of directly inferring subgroups with varying correlations with labels, our approach focuses on discovering concepts: discrete ideas that are shared across input samples. Leveraging existing object-centric representation learning, we introduce CoBalT: a concept balancing technique that effectively mitigates spurious correlations without requiring human labeling of subgroups. Evaluation across the benchmark datasets for sub-population shifts demonstrate superior or competitive performance compared state-of-the-art baselines, without the need for group annotation. Code is available at https://github.com/rarefin/CoBalT.",
      "authors": [
        "Md Rifat Arefin",
        "Yan Zhang",
        "Aristide Baratin",
        "Francesco Locatello",
        "Irina Rish",
        "Dianbo Liu",
        "Kenji Kawaguchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-20T20:48:00+00:00",
          "link": "https://arxiv.org/abs/2402.13368v1",
          "size": "8432kb",
          "version": "v1"
        },
        {
          "date": "2024-07-16T17:54:43+00:00",
          "link": "https://arxiv.org/abs/2402.13368v2",
          "size": "8978kb",
          "version": "v2"
        }
      ],
      "title": "Unsupervised Concept Discovery Mitigates Spurious Correlations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13368",
        "HTML": "https://arxiv.org/html/2402.13368",
        "PDF": "https://arxiv.org/pdf/2402.13368"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about mitigating spurious correlations in models through unsupervised concept discovery, targeting model robustness rather than LLM data processing operations or dataset creation."
      },
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/rarefin/cobalt"
      ],
      "source": "arXiv"
    },
    {
      "id": "1912.13122",
      "abstract": "Regulation of Multi-Agent Systems (MAS) and Declarative Electronic Institutions (DEIs) was a multidisciplinary research topic of the past decade involving (Physical and Software) Agents and Law since the beginning, but recently evolved towards News-claimed Robot Lawyer since 2016. One of these first proposals of restricting the behaviour of Software Agents was Electronic Institutions. However, with the recent reformulation of Artificial Neural Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal issues regarding the use of DL has raised concerns in the Artificial Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly addressed, we propose the Regulation of Artificial Neural Networks as Agent-based Training of a special type of regulated Artificial Neural Network that we call Institutional Neural Network (INN).The main purpose of this paper is to bring attention to Artificial Teaching (AT) and to give a tentative answer showing a proof-of-concept implementation of Regulated Deep Learning (RDL). This paper introduces the former concept and provide $I^*$, a language previously used to model declaratively and extend Electronic Institutions, as a means to regulate the execution of Artificial Neural Networks and their interactions with Artificial Teachers (ATs)",
      "authors": [
        "Andr\\'es Garc\\'ia-Camino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)",
        "Multiagent Systems (cs.MA)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2019-12-31T00:10:50+00:00",
          "link": "https://arxiv.org/abs/1912.13122v1",
          "size": "24kb",
          "version": "v1"
        },
        {
          "date": "2020-07-11T22:36:52+00:00",
          "link": "https://arxiv.org/abs/1912.13122v2",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "2020-07-24T17:19:26+00:00",
          "link": "https://arxiv.org/abs/1912.13122v3",
          "size": "28kb",
          "version": "v3"
        },
        {
          "date": "2023-07-13T17:56:30+00:00",
          "link": "https://arxiv.org/abs/1912.13122v4",
          "size": "510kb",
          "version": "v4"
        },
        {
          "date": "2023-07-18T23:53:12+00:00",
          "link": "https://arxiv.org/abs/1912.13122v5",
          "size": "132kb",
          "version": "v5"
        },
        {
          "date": "2023-07-21T02:04:53+00:00",
          "link": "https://arxiv.org/abs/1912.13122v6",
          "size": "112kb",
          "version": "v6"
        },
        {
          "date": "2023-07-27T12:22:27+00:00",
          "link": "https://arxiv.org/abs/1912.13122v7",
          "size": "59kb",
          "version": "v7"
        },
        {
          "date": "2025-07-18T12:07:30+00:00",
          "link": "https://arxiv.org/abs/1912.13122v8",
          "size": "54kb",
          "version": "v8"
        }
      ],
      "title": "Towards Regulated Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/1912.13122",
        "HTML": "https://arxiv.org/html/1912.13122",
        "PDF": "https://arxiv.org/pdf/1912.13122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses regulated deep learning and Artificial Neural Networks, which are not directly related to LLM training data processing."
      },
      "tasks": [
        "Deep Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.07751",
      "abstract": "As research in human-centered NLP advances, there is a growing recognition of the importance of incorporating human and social factors into NLP models. At the same time, our NLP systems have become heavily reliant on LLMs, most of which do not model authors. To build NLP systems that can truly understand human language, we must better integrate human contexts into LLMs. This brings to the fore a range of design considerations and challenges in terms of what human aspects to capture, how to represent them, and what modeling strategies to pursue. To address these, we advocate for three positions toward creating large human language models (LHLMs) using concepts from psychological and behavioral sciences: First, LM training should include the human context. Second, LHLMs should recognize that people are more than their group(s). Third, LHLMs should be able to account for the dynamic and temporally-dependent nature of the human context. We refer to relevant advances and present open challenges that need to be addressed and their possible solutions in realizing these goals.",
      "authors": [
        "Nikita Soni",
        "H. Andrew Schwartz",
        "Jo\\~ao Sedoc",
        "Niranjan Balasubramanian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-09T00:27:28+00:00",
          "link": "https://arxiv.org/abs/2312.07751v1",
          "size": "8343kb",
          "version": "v1"
        },
        {
          "date": "2024-04-02T14:30:12+00:00",
          "link": "https://arxiv.org/abs/2312.07751v2",
          "size": "8355kb",
          "version": "v2"
        },
        {
          "date": "2024-05-09T17:22:40+00:00",
          "link": "https://arxiv.org/abs/2312.07751v3",
          "size": "8356kb",
          "version": "v3"
        }
      ],
      "title": "Large Human Language Models: A Need and the Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.07751",
        "HTML": "https://arxiv.org/html/2312.07751",
        "PDF": "https://arxiv.org/pdf/2312.07751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the integration of human contexts into LLMs to create large human language models. However, it focuses more on model design and less on specific training data processing operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.12898",
      "abstract": "Bimanual robotic manipulation, which involves the coordinated control of two robotic arms, is foundational for solving challenging tasks. Despite recent progress in general-purpose manipulation, data scarcity and embodiment heterogeneity remain serious obstacles to further scaling up in bimanual settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning (VIDAR), a two-stage framework that leverages large-scale, diffusion-based video pre-training and a novel masked inverse dynamics model for action prediction. We pre-train the video diffusion model on 750K multi-view videos from three real-world bimanual robot platforms, utilizing a unified observation space that encodes robot, camera, task, and scene contexts. Our masked inverse dynamics model learns masks to extract action-relevant information from generated trajectories without requiring pixel-level labels, and the masks can effectively generalize to unseen backgrounds. Our experiments demonstrate that with only 20 minutes of human demonstrations on an unseen robot platform (only 1% of typical data requirements), VIDAR generalizes to unseen tasks and backgrounds with strong semantic understanding, surpassing state-of-the-art methods. Our findings highlight the potential of video foundation models, coupled with masked action prediction, to enable scalable and generalizable robotic manipulation in diverse real-world settings.",
      "authors": [
        "Yao Feng",
        "Hengkai Tan",
        "Xinyi Mao",
        "Guodong Liu",
        "Shuhe Huang",
        "Chendong Xiang",
        "Hang Su",
        "Jun Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:31:55+00:00",
          "link": "https://arxiv.org/abs/2507.12898v1",
          "size": "19334kb",
          "version": "v1"
        }
      ],
      "title": "Generalist Bimanual Manipulation via Foundation Video Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12898",
        "HTML": "https://arxiv.org/html/2507.12898",
        "PDF": "https://arxiv.org/pdf/2507.12898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on bimanual robotic manipulation utilizing video diffusion models for action reasoning. It does not address issues related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.05263",
      "abstract": "Developing and testing novel control and motion planning algorithms for aerial vehicles can be a challenging task, with the robotics community relying more than ever on 3D simulation technologies to evaluate the performance of new algorithms in a variety of conditions and environments. In this work, we introduce the Pegasus Simulator, a modular framework implemented as an NVIDIA Isaac Sim extension that enables real-time simulation of multiple multirotor vehicles in photo-realistic environments, while providing out-of-the-box integration with the widely adopted PX4-Autopilot and ROS2 through its modular implementation and intuitive graphical user interface. To demonstrate some of its capabilities, a nonlinear controller was implemented and simulation results for two drones performing aggressive flight maneuvers are presented. Code and documentation for this framework are also provided as supplementary material.",
      "authors": [
        "Marcelo Jacinto",
        "Jo\\~ao Pinto",
        "Jay Patrikar",
        "John Keller",
        "Rita Cunha",
        "Sebastian Scherer",
        "Ant\\'onio Pascoal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-11T13:53:13+00:00",
          "link": "https://arxiv.org/abs/2307.05263v1",
          "size": "4690kb",
          "version": "v1"
        },
        {
          "date": "2024-04-15T16:10:42+00:00",
          "link": "https://arxiv.org/abs/2307.05263v2",
          "size": "5334kb",
          "version": "v2"
        }
      ],
      "title": "Pegasus Simulator: An Isaac Sim Framework for Multiple Aerial Vehicles Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.05263",
        "HTML": "https://arxiv.org/html/2307.05263",
        "PDF": "https://arxiv.org/pdf/2307.05263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a simulator for aerial vehicles and does not relate to any training data processing for LLMs."
      },
      "repo_urls": [
        "https://github.com/PegasusSimulator/PegasusSimulator"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00124",
      "abstract": "Like most of NLP, models for human-centered NLP tasks -- tasks attempting to assess author-level information -- predominantly use representations derived from hidden states of Transformer-based LLMs. However, what component of the LM is used for the representation varies widely. Moreover, there is a need for Human Language Models (HuLMs) that implicitly model the author and provide a user-level hidden state. Here, we systematically evaluate different ways of representing documents and users using different LM and HuLM architectures to predict task outcomes as both dynamically changing states and averaged trait-like user-level attributes of valence, arousal, empathy, and distress. We find that representing documents as an average of the token hidden states performs the best generally. Further, while a user-level hidden state itself is rarely the best representation, we find its inclusion in the model strengthens token or document embeddings used to derive document- and user-level representations resulting in best performances.",
      "authors": [
        "Nikita Soni",
        "Pranav Chitale",
        "Khushboo Singh",
        "Niranjan Balasubramanian",
        "H. Andrew Schwartz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T19:10:06+00:00",
          "link": "https://arxiv.org/abs/2503.00124v1",
          "size": "7963kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of LLMs-based Hidden States as Author Representations for Psychological Human-Centered NLP Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00124",
        "HTML": "https://arxiv.org/html/2503.00124",
        "PDF": "https://arxiv.org/pdf/2503.00124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates different LLM representations for human-centered NLP tasks, focusing on hidden states and author representations. It does not involve any aspect of LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/soni-n/llms_author_representations"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.12502",
      "abstract": "A wireless network of full-duplex nodes/users, using anti-eavesdropping channel estimation (ANECE) based on collaborative pilots, can yield a positive secure degree-of-freedom (SDoF) regardless of the number of antennas an eavesdropper may have. This paper presents novel results on SDoF of ANECE by analyzing secret-key capacity (SKC) of each pair of nodes in a network of multiple collaborative nodes per channel coherence period. Each transmission session of ANECE has two phases: phase 1 is used for pilots, and phase 2 is used for random symbols. This results in two parts of SDoF of ANECE. Both lower and upper bounds on the SDoF of ANECE for any number of users are shown, and the conditions for the two bounds to meet are given. This leads to important discoveries, including: a) The phase-1 SDoF is the same for both multi-user ANECE and pair-wise ANECE while the former may require only a fraction of the number of time slots needed by the latter; b) For a three-user network, the phase-2 SDoF of all-user ANECE is generally larger than that of pair-wise ANECE; c) For a two-user network, a modified ANECE deploying square-shaped nonsingular pilot matrices yields a higher total SDoF than the original ANECE. The multi-user ANECE and the modified two-user ANECE shown in this paper appear to be the best full-duplex schemes known today in terms of SDoF subject to each node using a given number of antennas for both transmitting and receiving.",
      "authors": [
        "Yingbo Hua",
        "Qingpeng Liang and Md Saydur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-21T21:52:51+00:00",
          "link": "https://arxiv.org/abs/2309.12502v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "Secure Degree of Freedom of Wireless Networks Using Collaborative Pilots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.12502",
        "PDF": "https://arxiv.org/pdf/2309.12502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on enhancing wireless network security using collaborative pilots, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11568",
      "abstract": "Humanity's unprecedented technological capacity and concurrent existential risks reveal a critical lacuna in the philosophical tradition: the absence of a systematic framework for the long-term future. This article argues that formulating such a framework is the central ethical imperative of our era. To defend this thesis, it synthesizes the normative ethics of Hans Jonas and Derek Parfit with the analytical framework of Nick Bostrom's work on existential risk and longtermism. The analysis further addresses the ontological challenge posed by posthumanism to the human 'subject' and explores the functional role of a secular cosmic purpose in motivating long-term action. The paper's main contribution is the articulation of a synthetic research agenda for a prospective philosophy, one that integrates axiology, risk management, and ontology to guide humanity through its perilous technological adolescence.",
      "authors": [
        "Santos E. Moreta Reyes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computers and Society (cs.CY)",
        "History and Philosophy of Physics (physics.hist-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:41:09+00:00",
          "link": "https://arxiv.org/abs/2507.11568v1",
          "size": "166kb",
          "version": "v1"
        }
      ],
      "title": "La \\'Ultima Frontera de La Filosof\\'ia: Hacia una S\\'intesis de La \\'Etica del Futuro a Largo Plazo, el Riesgo Existencial y la Ontolog\\'ia Posthumana",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11568",
        "PDF": "https://arxiv.org/pdf/2507.11568"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses philosophical frameworks related to existential risks and long-term ethics, without any connection to LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.01787",
      "abstract": "This paper presents a comprehensive software stack architecture for integrating quantum computing (QC) capabilities with High-Performance Computing (HPC) environments. While quantum computers show promise as specialized accelerators for scientific computing, their effective integration with classical HPC systems presents significant technical challenges. We propose a hardware-agnostic software framework that supports both current noisy intermediate-scale quantum devices and future fault-tolerant quantum computers, while maintaining compatibility with existing HPC workflows. The architecture includes a quantum gateway interface, standardized APIs for resource management, and robust scheduling mechanisms to handle both simultaneous and interleaved quantum-classical workloads. Key innovations include: (1) a unified resource management system that efficiently coordinates quantum and classical resources, (2) a flexible quantum programming interface that abstracts hardware-specific details, (3) A Quantum Platform Manager API that simplifies the integration of various quantum hardware systems, and (4) a comprehensive tool chain for quantum circuit optimization and execution. We demonstrate our architecture through implementation of quantum-classical algorithms, including the variational quantum linear solver, showcasing the framework's ability to handle complex hybrid workflows while maximizing resource utilization. This work provides a foundational blueprint for integrating QC capabilities into existing HPC infrastructures, addressing critical challenges in resource management, job scheduling, and efficient data movement between classical and quantum resources.",
      "authors": [
        "Amir Shehata",
        "Peter Groszkowski",
        "Thomas Naughton",
        "Murali Gopalakrishnan Meena",
        "Elaine Wong",
        "Daniel Claudino",
        "Rafael Ferreira da Silvaa",
        "Thomas Beck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T18:18:45+00:00",
          "link": "https://arxiv.org/abs/2503.01787v1",
          "size": "10523kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:00:06+00:00",
          "link": "https://arxiv.org/abs/2503.01787v2",
          "size": "1018kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Paradigms: Designing for HPC-Quantum Convergence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01787",
        "HTML": "https://arxiv.org/html/2503.01787",
        "PDF": "https://arxiv.org/pdf/2503.01787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a software architecture for integrating quantum computing with HPC environments, focusing on resource management and programming interfaces. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.06438",
      "abstract": "This paper presents further insights into a recently developed round-trip communication scheme called ``Secret-message Transmission by Echoing Encrypted Probes (STEEP)''. A legitimate wireless channel between a multi-antenna user (Alice) and a single-antenna user (Bob) in the presence of a multi-antenna eavesdropper (Eve) is focused on. STEEP does not require full-duplex, channel reciprocity or Eve's channel state information, but is able to yield a positive secrecy rate in bits per channel use between Alice and Bob in every channel coherence period as long as Eve's receive channel is not noiseless. This secrecy rate does not diminish as coherence time increases. Various statistical behaviors of STEEP's secrecy capacity due to random channel fading are also illustrated.",
      "authors": [
        "Yingbo Hua and Md Saydur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-11T05:14:24+00:00",
          "link": "https://arxiv.org/abs/2403.06438v1",
          "size": "2121kb",
          "version": "v1"
        }
      ],
      "title": "Unification of Secret Key Generation and Wiretap Channel Transmission",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06438",
        "HTML": "https://arxiv.org/html/2403.06438",
        "PDF": "https://arxiv.org/pdf/2403.06438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a communication scheme related to secret key generation, not addressing any element of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.08906",
      "abstract": "Educational games enhance learning experiences by integrating touchscreens, making interactions more engaging and intuitive for learners. However, the cognitive impacts of educational gameplay input modalities, such as the hand and stylus technique, are unclear. We compared the experience of using hands vs. a stylus for touchscreens while playing an educational game by analyzing oxygenated hemoglobin collected by functional Near-Infrared Spectroscopy and self-reported measures. In addition, we measured the hand vs. the stylus modalities of the task and calculated the relative neural efficiency and relative neural involvement using the mental demand and the quiz score. Our findings show that the hand condition had a significantly lower neural involvement, yet higher neural efficiency than the stylus condition. This result suggests the requirement of less cognitive effort while using the hand. Additionally, the self-reported measures show significant differences, and the results suggest that hand-based input is more intuitive, less cognitively demanding, and less frustrating. Conversely, the use of a stylus required higher cognitive effort due to the cognitive balance of controlling the pen and answering questions. These findings highlight the importance of designing educational games that allow learners to engage with the system while minimizing cognitive effort.",
      "authors": [
        "Shayla Sharmin",
        "Elham Bakhshipour",
        "Behdokht Kiafar",
        "Md Fahim Abrar",
        "Pinar Kullu",
        "Nancy Getchell",
        "Roghayeh Leila Barmaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-14T18:47:04+00:00",
          "link": "https://arxiv.org/abs/2405.08906v1",
          "size": "8440kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T18:12:09+00:00",
          "link": "https://arxiv.org/abs/2405.08906v2",
          "size": "4544kb",
          "version": "v2"
        },
        {
          "date": "2024-11-15T23:17:21+00:00",
          "link": "https://arxiv.org/abs/2405.08906v3",
          "size": "4544kb",
          "version": "v3"
        },
        {
          "date": "2025-02-03T19:12:29+00:00",
          "link": "https://arxiv.org/abs/2405.08906v4",
          "size": "13721kb",
          "version": "v4"
        },
        {
          "date": "2025-05-29T18:41:07+00:00",
          "link": "https://arxiv.org/abs/2405.08906v5",
          "size": "6261kb",
          "version": "v5"
        },
        {
          "date": "2025-07-18T14:17:15+00:00",
          "link": "https://arxiv.org/abs/2405.08906v6",
          "size": "6212kb",
          "version": "v6"
        }
      ],
      "title": "Functional Near-Infrared Spectroscopy (fNIRS) Analysis of Interaction Techniques in Touchscreen-Based Educational Gaming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.08906",
        "HTML": "https://arxiv.org/html/2405.08906",
        "PDF": "https://arxiv.org/pdf/2405.08906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the cognitive impacts of different interaction techniques in educational games, which is unrelated to LLM training data processing operations or improving dataset quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.14909",
      "abstract": "We present the Fast Newton Transform (FNT), an algorithm for performing $m$-variate Newton interpolation in downward closed polynomial spaces with time complexity $\\mathcal{O}(|A|m\\overline{n})$. Here, $A$ is a downward closed set of cardinality $|A|$ equal to the dimension of the associated downward closed polynomial space $\\Pi_A$, where $\\overline{n}$ denotes the mean of the maximum polynomial degrees across the spatial dimensions $m$. For functions being analytic in an open Bernstein poly-ellipse, geometric approximation rates apply when interpolating in non-tensorial Leja-ordered Chebyshev-Lobatto or Leja grids. To mitigate the curse of dimensionality, we utilize $\\ell^p$-sets, with the $l^2$-Euclidean case turning out to be the pivotal choice, leading to $|A|/(n+1)^m \\in \\mathcal{O}(e^{-m})$. Expanding non-periodic functions, the FNT complements the approximation capabilities of the Fast Fourier Transform (FFT). Choosing $\\ell^2$-sets for $A$ renders the FNT time complexity to be less than the FFT time complexity $\\mathcal{O}((n+1)^m m \\log(n))$ in a range of $n$, behaving as $\\mathcal{O}(e^m)$. Maintaining this advantage true for the differentials, the FNT sets a new standard in $m$-variate interpolation and approximation practice.",
      "authors": [
        "Phil-Alexander Hofmann",
        "Damar Wicaksono",
        "Michael Hecht"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T21:03:33+00:00",
          "link": "https://arxiv.org/abs/2505.14909v1",
          "size": "5325kb",
          "version": "v1"
        },
        {
          "date": "2025-06-16T08:43:56+00:00",
          "link": "https://arxiv.org/abs/2505.14909v2",
          "size": "4558kb",
          "version": "v2"
        }
      ],
      "title": "The Fast Newton Transform: Interpolation in Downward Closed Polynomial Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14909",
        "PDF": "https://arxiv.org/pdf/2505.14909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents the Fast Newton Transform algorithm for polynomial interpolation, which does not relate to any aspect of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/phil-hofmann/lpfun"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07942",
      "abstract": "Large Language Models (LLMs) have become vital tools in software development tasks such as code generation, completion, and analysis. As their integration into workflows deepens, ensuring robustness against vulnerabilities especially those triggered by diverse or adversarial inputs becomes increasingly important. Such vulnerabilities may lead to incorrect or insecure code generation when models encounter perturbed task descriptions, code, or comments. Prior research often overlooks the role of natural language in guiding code tasks. This study investigates how adversarial perturbations in natural language inputs including prompts, comments, and descriptions affect LLMs for Code (LLM4Code). It examines the effects of perturbations at the character, word, and sentence levels to identify the most impactful vulnerabilities. We analyzed multiple projects (e.g., ReCode, OpenAttack) and datasets (e.g., HumanEval, MBPP), establishing a taxonomy of adversarial attacks. The first dimension classifies the input type code, prompts, or comments while the second dimension focuses on granularity: character, word, or sentence-level changes. We adopted a mixed-methods approach, combining quantitative performance metrics with qualitative vulnerability analysis. LLM4Code models show varying robustness across perturbation types. Sentence-level attacks were least effective, suggesting models are resilient to broader contextual changes. In contrast, word-level perturbations posed serious challenges, exposing semantic vulnerabilities. Character-level effects varied, showing model sensitivity to subtle syntactic deviations.Our study offers a structured framework for testing LLM4Code robustness and emphasizes the critical role of natural language in adversarial evaluation. Improving model resilience to semantic-level disruptions is essential for secure and reliable code-generation systems.",
      "authors": [
        "Yang Liu",
        "Armstrong Foundjem",
        "Foutse Khomh",
        "and Heng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T17:02:29+00:00",
          "link": "https://arxiv.org/abs/2506.07942v1",
          "size": "3340kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07942",
        "PDF": "https://arxiv.org/pdf/2506.07942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates adversarial attacks and robustness of LLMs for code-related tasks, with no direct contribution or focus on training data processing techniques or data generation pertinent to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.05014",
      "abstract": "With changing attitudes around knowledge, medicine, art, and technology, the human body has become a source of information and, ultimately, shareable and analyzable data. Centuries of illustrations and visualizations of the body occur within particular historical, social, and political contexts. These contexts are enmeshed in different so-called data cultures: ways that data, knowledge, and information are conceptualized and collected, structured and shared. In this work, we explore how information about the body was collected as well as the circulation, impact, and persuasive force of the resulting images. We show how mindfulness of data cultural influences remain crucial for today's designers, researchers, and consumers of visualizations. We conclude with a call for the field to reflect on how visualizations are not timeless and contextless mirrors on objective data, but as much a product of our time and place as the visualizations of the past.",
      "authors": [
        "Michael Correll and Laura A. Garrison"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T16:32:55+00:00",
          "link": "https://arxiv.org/abs/2402.05014v1",
          "size": "27420kb",
          "version": "v1"
        }
      ],
      "title": "When the Body Became Data: Historical Data Cultures and Anatomical Illustration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.05014",
        "PDF": "https://arxiv.org/pdf/2402.05014"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses historical data cultures and the anatomical illustration of the human body, which does not pertain to LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.15977",
      "abstract": "We show that there is weak distributive law of the Smyth hyperspace monad $\\mathcal Q_{\\mathsf V}$ (resp., the Hoare hyperspace monad $\\mathcal H_{\\mathsf V}$, resp. the monad $\\mathcal P\\ell^{\\mathrm q}_{\\mathsf V}$ of quasi-lenses, resp. the monad $\\mathcal P\\ell_{\\mathsf V}$ of lenses) over the continuous valuation monad $\\mathbf V$, as well as over the subprobability valuation monad $\\mathbf V_{\\leq 1}$ and the probability valuation monad $\\mathbf V_1$, on the whole category $\\mathbf{Top}$ of topological spaces (resp., on certain full subcategories such as the category of locally compact spaces or of stably compact spaces). We show that the resulting weak composite monad is the author's monad of superlinear previsions (resp., sublinear previsions, resp. forks), possibly subnormalized or normalized depending on whether we consider $\\mathbf V_{\\leq 1}$ or $\\mathbf V_1$ instead of $\\mathbf V$. As a special case, we obtain a weak distributive law of the monad $\\mathcal P\\ell^{\\mathrm q}_{\\mathsf V} \\cong \\mathcal P\\ell_{\\mathsf V}$ over the monad of (sub)probability Radon measures $\\mathbf R_\\bullet$ on the category of stably compact spaces, which specializes further to a weak distributive laws of the Vietoris monad over $\\mathbf R_\\bullet$. The associated weak composite monad is the monad of (sub)normalized forks.",
      "authors": [
        "Jean Goubault-Larrecq"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Category Theory (math.CT)",
        "Logic in Computer Science (cs.LO)",
        "General Topology (math.GN)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T17:49:00+00:00",
          "link": "https://arxiv.org/abs/2408.15977v1",
          "size": "80kb",
          "version": "v1"
        },
        {
          "date": "2024-08-29T15:16:34+00:00",
          "link": "https://arxiv.org/abs/2408.15977v2",
          "size": "81kb",
          "version": "v2"
        },
        {
          "date": "2024-09-02T18:02:40+00:00",
          "link": "https://arxiv.org/abs/2408.15977v3",
          "size": "82kb",
          "version": "v3"
        },
        {
          "date": "2024-11-12T18:15:24+00:00",
          "link": "https://arxiv.org/abs/2408.15977v4",
          "size": "82kb",
          "version": "v4"
        }
      ],
      "title": "Weak Distributive Laws between Monads of Continuous Valuations and of Non-Deterministic Choice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15977",
        "PDF": "https://arxiv.org/pdf/2408.15977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses weak distributive laws between certain mathematical structures (monads) in topological spaces. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2012.09952",
      "abstract": "This paper considers the secrecy performance of several schemes for multi-antenna transmission to single-antenna users with full-duplex (FD) capability against randomly distributed single-antenna eavesdroppers (EDs). These schemes and related scenarios include transmit antenna selection (TAS), transmit antenna beamforming (TAB), artificial noise (AN) from the transmitter, user selection based their distances to the transmitter, and colluding and non-colluding EDs. The locations of randomly distributed EDs and users are assumed to be distributed as Poisson Point Process (PPP). We derive closed form expressions for the secrecy outage probabilities (SOP) of all these schemes and scenarios. The derived expressions are useful to reveal the impacts of various environmental parameters and user's choices on the SOP, and hence useful for network design purposes. Examples of such numerical results are discussed.",
      "authors": [
        "Ishmam Zabir",
        "Ahmed Maksud",
        "Gaojie Chen",
        "Brian M. Sadler",
        "Yingbo Hua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2020-12-17T22:07:38+00:00",
          "link": "https://arxiv.org/abs/2012.09952v1",
          "size": "1997kb",
          "version": "v1"
        }
      ],
      "title": "Secrecy of Multi-Antenna Transmission with Full-Duplex User in the Presence of Randomly Located Eavesdroppers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2012.09952",
        "PDF": "https://arxiv.org/pdf/2012.09952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines secrecy performance in multi-antenna transmission scenarios, lacking relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.14158",
      "abstract": "Magnetic resonance imaging (MRI) is a non-invasive imaging modality and provides comprehensive anatomical and functional insights into the human body. However, its long acquisition times can lead to patient discomfort, motion artifacts, and limiting real-time applications. To address these challenges, strategies such as parallel imaging have been applied, which utilize multiple receiver coils to speed up the data acquisition process. Additionally, compressed sensing (CS) is a method that facilitates image reconstruction from sparse data, significantly reducing image acquisition time by minimizing the amount of data collection needed. Recently, deep learning (DL) has emerged as a powerful tool for improving MRI reconstruction. It has been integrated with parallel imaging and CS principles to achieve faster and more accurate MRI reconstructions. This review comprehensively examines DL-based techniques for MRI reconstruction. We categorize and discuss various DL-based methods, including end-to-end approaches, unrolled optimization, and federated learning, highlighting their potential benefits. Our systematic review highlights significant contributions and underscores the potential of DL in MRI reconstruction. Additionally, we summarize key results and trends in DL-based MRI reconstruction, including quantitative metrics, the dataset, acceleration factors, and the progress of and research interest in DL techniques over time. Finally, we discuss potential future directions and the importance of DL-based MRI reconstruction in advancing medical imaging. To facilitate further research in this area, we provide a GitHub repository that includes up-to-date DL-based MRI reconstruction publications and public datasets-https://github.com/mosaf/Awesome-DL-based-CS-MRI.",
      "authors": [
        "Mojtaba Safari",
        "Zach Eidex",
        "Chih-Wei Chang",
        "Richard L.J. Qiu",
        "Xiaofeng Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T01:07:58+00:00",
          "link": "https://arxiv.org/abs/2501.14158v1",
          "size": "6811kb",
          "version": "v1"
        },
        {
          "date": "2025-02-01T14:38:16+00:00",
          "link": "https://arxiv.org/abs/2501.14158v2",
          "size": "6599kb",
          "version": "v2"
        }
      ],
      "title": "Advancing MRI Reconstruction: A Systematic Review of Deep Learning and Compressed Sensing Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14158",
        "HTML": "https://arxiv.org/html/2501.14158",
        "PDF": "https://arxiv.org/pdf/2501.14158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a review of deep learning and compressed sensing integration in MRI reconstruction, highlighting advances in medical imaging rather than LLM training data processing."
      },
      "tasks": [
        "compressed sensing",
        "Federated Learning",
        "Image Reconstruction",
        "MRI Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/mosaf/awesome-dl-based-cs-mri"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.11464",
      "abstract": "Easy Read text is one of the main forms of access to information for people with reading difficulties. One of the key characteristics of this type of text is the requirement to split sentences into smaller grammatical segments, to facilitate reading. Automated segmentation methods could foster the creation of Easy Read content, but their viability has yet to be addressed. In this work, we study novel methods for the task, leveraging masked and generative language models, along with constituent parsing. We conduct comprehensive automatic and human evaluations in three languages, analysing the strengths and weaknesses of the proposed alternatives, under scarce resource limitations. Our results highlight the viability of automated Easy Read text segmentation and remaining deficiencies compared to expert-driven human segmentation.",
      "authors": [
        "Jes\\'us Calleja",
        "Thierry Etchegoyhen",
        "David Ponce"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-17T12:25:25+00:00",
          "link": "https://arxiv.org/abs/2406.11464v1",
          "size": "8358kb",
          "version": "v1"
        },
        {
          "date": "2024-10-10T13:18:59+00:00",
          "link": "https://arxiv.org/abs/2406.11464v2",
          "size": "8361kb",
          "version": "v2"
        }
      ],
      "title": "Automating Easy Read Text Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.11464",
        "HTML": "https://arxiv.org/html/2406.11464",
        "PDF": "https://arxiv.org/pdf/2406.11464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on automating Easy Read text segmentation using language models and a parsing method. It does not discuss data processing for LLM training, but instead emphasizes accessibility through text segmentation."
      },
      "tasks": [
        "Segmentation",
        "Text Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2307.02284",
      "abstract": "We demonstrate that conventional artificial deep neural networks operating near the phase boundary of the signal propagation dynamics, also known as the edge of chaos, exhibit universal scaling laws of absorbing phase transitions in non-equilibrium statistical mechanics. We exploit the fully deterministic nature of the propagation dynamics to elucidate an analogy between a signal collapse in the neural networks and an absorbing state (a state that the system can enter but cannot escape from). Our numerical results indicate that the multilayer perceptrons and the convolutional neural networks belong to the mean-field and the directed percolation universality classes, respectively. Also, the finite-size scaling is successfully applied, suggesting a potential connection to the depth-width trade-off in deep learning. Furthermore, our analysis of the training dynamics under the gradient descent reveals that hyperparameter tuning to the phase boundary is necessary but insufficient for achieving optimal generalization in deep networks. Remarkably, nonuniversal metric factors associated with the scaling laws are shown to play a significant role in concretizing the above observations. These findings highlight the usefulness of the notion of criticality for analyzing the behavior of artificial deep neural networks and offer new insights toward a unified understanding of the essential relationship between criticality and intelligence.",
      "authors": [
        "Keiichi Tamai",
        "Tsuyoshi Okubo",
        "Truong Vinh Truong Duy",
        "Naotake Natori and Synge Todo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-05T13:39:02+00:00",
          "link": "https://arxiv.org/abs/2307.02284v1",
          "size": "1015kb",
          "version": "v1"
        },
        {
          "date": "2024-10-29T14:57:26+00:00",
          "link": "https://arxiv.org/abs/2307.02284v2",
          "size": "776kb",
          "version": "v2"
        },
        {
          "date": "2025-04-10T05:38:41+00:00",
          "link": "https://arxiv.org/abs/2307.02284v3",
          "size": "1026kb",
          "version": "v3"
        }
      ],
      "title": "Universal Scaling Laws of Absorbing Phase Transitions in Artificial Deep Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.02284",
        "HTML": "https://arxiv.org/html/2307.02284",
        "PDF": "https://arxiv.org/pdf/2307.02284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research investigates scaling laws and criticality in deep neural networks, with no focus on LLM training data processing operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2102.11336",
      "abstract": "The problem of covert communication over Multiple-Input Multiple-Output (MIMO) Additive White Gaussian Noise (AWGN) channels is investigated, in which a transmitter attempts to reliably communicate with a legitimate receiver while avoiding detection by a passive adversary. The covert capacity of the MIMO AWGN is characterized under a variational distance covertness constraint when the MIMO channel matrices are static and known. The characterization of the covert capacity is also extended to a class of channels in which the legitimate channel matrix is known but the adversary's channel matrix is only known up to a rank and a spectral norm constraint.",
      "authors": [
        "Shi-Yuan Wang and Matthieu R. Bloch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2021-02-22T20:12:20+00:00",
          "link": "https://arxiv.org/abs/2102.11336v1",
          "size": "106kb",
          "version": "v1"
        },
        {
          "date": "2021-09-03T20:35:45+00:00",
          "link": "https://arxiv.org/abs/2102.11336v2",
          "size": "122kb",
          "version": "v2"
        }
      ],
      "title": "Covert MIMO Communications under Variational Distance Constraint",
      "links": {
        "Abstract": "https://arxiv.org/abs/2102.11336",
        "PDF": "https://arxiv.org/pdf/2102.11336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on covert communications in MIMO systems, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.02643",
      "abstract": "The growing volume of available infrastructural monitoring data enables the development of powerful datadriven approaches to estimate infrastructure health conditions using direct measurements. This paper proposes a deep learning methodology to estimate infrastructure physical parameters, such as railway track stiffness, using drive-by vibration response signals. The proposed method employs a Long Short-term Memory (LSTM) feature extractor accounting for temporal dependencies in the feature extraction phase, and a bidirectional Long Short-term Memory (BiLSTM) networks to leverage bidirectional temporal dependencies in both the forward and backward paths of the drive-by vibration response in condition estimation phase. Additionally, a framing approach is employed to enhance the resolution of the monitoring task to the beam level by segmenting the vibration signal into frames equal to the distance between individual beams, centering the frames over the beam nodes. The proposed LSTM-BiLSTM model offers a versatile tool for various bridge and railway infrastructure conditions monitoring using direct drive-by vibration response measurements. The results demonstrate the potential of incorporating temporal analysis in the feature extraction phase and emphasize the pivotal role of bidirectional temporal information in infrastructure health condition estimation. The proposed methodology can accurately and automatically estimate railway track stiffness and identify local stiffness reductions in the presence of noise using drive-by measurements. An illustrative case study of vehicle-track interaction simulation is used to demonstrate the performance of the proposed model, achieving a maximum mean absolute percentage error of 1.7% and 0.7% in estimating railpad and ballast stiffness, respectively.",
      "authors": [
        "R. R. Samani",
        "A. Nunez",
        "B. De Schutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T18:15:34+00:00",
          "link": "https://arxiv.org/abs/2412.02643v1",
          "size": "1315kb",
          "version": "v1"
        },
        {
          "date": "2025-03-11T09:22:49+00:00",
          "link": "https://arxiv.org/abs/2412.02643v2",
          "size": "1648kb",
          "version": "v2"
        }
      ],
      "title": "A Bidirectional Long Short Term Memory Approach for Infrastructure Health Monitoring Using On-board Vibration Response",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02643",
        "HTML": "https://arxiv.org/html/2412.02643",
        "PDF": "https://arxiv.org/pdf/2412.02643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a deep learning approach for infrastructure health monitoring using LSTM and BiLSTM networks. It does not involve any aspects of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2103.12355",
      "abstract": "The role of symmetry in Boolean functions $f:\\{0,1\\}^n \\to \\{0,1\\}$ has been extensively studied in complexity theory. For example, symmetric functions, that is, functions that are invariant under the action of $S_n$, is an important class of functions in the study of Boolean functions. A function $f:\\{0,1\\}^n \\to \\{0,1\\}$ is called transitive (or weakly-symmetric) if there exists a transitive group $G$ of $S_n$ such that $f$ is invariant under the action of $G$ - that is the function value remains unchanged even after the bits of the input of $f$ are moved around according to some permutation $\\sigma \\in G$. Understanding various complexity measures of transitive functions has been a rich area of research for the past few decades.\n  In this work, we study transitive functions in light of several combinatorial measures. We look at the maximum separation between various pairs of measures for transitive functions. Such study for general Boolean functions has been going on for past many years. The best-known results for general Boolean functions have been nicely compiled by Aaronson et. al (STOC, 2021).\n  The separation between a pair of combinatorial measures is shown by constructing interesting functions that demonstrate the separation. But many of the celebrated separation results are via the construction of functions (like \"pointer functions\" from Ambainis et al. (JACM, 2017) and \"cheat-sheet functions\" Aaronson et al. (STOC, 2016)) that are not transitive. Hence, we don't have such separation between the pairs of measures for transitive functions.\n  In this paper we show how to modify some of these functions to construct transitive functions that demonstrate similar separations between pairs of combinatorial measures.",
      "authors": [
        "Sourav Chakraborty",
        "Chandrima Kayal",
        "Manaswi Paraashar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2021-03-23T07:31:24+00:00",
          "link": "https://arxiv.org/abs/2103.12355v1",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "2022-05-08T16:16:39+00:00",
          "link": "https://arxiv.org/abs/2103.12355v2",
          "size": "51kb",
          "version": "v2"
        },
        {
          "date": "2023-03-29T17:56:52+00:00",
          "link": "https://arxiv.org/abs/2103.12355v3",
          "size": "188kb",
          "version": "v3"
        },
        {
          "date": "2024-10-08T02:42:46+00:00",
          "link": "https://arxiv.org/abs/2103.12355v4",
          "size": "191kb",
          "version": "v4"
        },
        {
          "date": "2025-05-20T10:49:23+00:00",
          "link": "https://arxiv.org/abs/2103.12355v5",
          "size": "188kb",
          "version": "v5"
        },
        {
          "date": "2025-07-03T14:15:24+00:00",
          "link": "https://arxiv.org/abs/2103.12355v6",
          "size": "112kb",
          "version": "v6"
        },
        {
          "date": "2025-07-18T06:50:16+00:00",
          "link": "https://arxiv.org/abs/2103.12355v7",
          "size": "112kb",
          "version": "v7"
        }
      ],
      "title": "Separations between Combinatorial Measures for Transitive Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.12355",
        "HTML": "https://arxiv.org/html/2103.12355",
        "PDF": "https://arxiv.org/pdf/2103.12355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the construction of transitive functions and their separations in Boolean function measures, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2210.16567",
      "abstract": "Safely navigating through an urban environment without violating any traffic rules is a crucial performance target for reliable autonomous driving. In this paper, we present a Reinforcement Learning (RL) based methodology to DEtect and FIX (DeFIX) failures of an Imitation Learning (IL) agent by extracting infraction spots and re-constructing mini-scenarios on these infraction areas to train an RL agent for fixing the shortcomings of the IL approach. DeFIX is a continuous learning framework, where extraction of failure scenarios and training of RL agents are executed in an infinite loop. After each new policy is trained and added to the library of policies, a policy classifier method effectively decides on which policy to activate at each step during the evaluation. It is demonstrated that even with only one RL agent trained on failure scenario of an IL agent, DeFIX method is either competitive or does outperform state-of-the-art IL and RL based autonomous urban driving benchmarks. We trained and validated our approach on the most challenging map (Town05) of CARLA simulator which involves complex, realistic, and adversarial driving scenarios. The source code is publicly available at https://github.com/data-and-decision-lab/DeFIX",
      "authors": [
        "Resul Dagdanov",
        "Feyza Eksen",
        "Halil Durmus",
        "Ferhat Yurdakul",
        "Nazim Kemal Ure"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-29T10:58:43+00:00",
          "link": "https://arxiv.org/abs/2210.16567v1",
          "size": "2683kb",
          "version": "v1"
        }
      ],
      "title": "DeFIX: Detecting and Fixing Failure Scenarios with Reinforcement Learning in Imitation Learning Based Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.16567",
        "PDF": "https://arxiv.org/pdf/2210.16567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the DeFIX method for error correction in autonomous driving models using reinforcement learning, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "CARLA MAP Leaderboard",
        "General Reinforcement Learning",
        "Imitation Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/data-and-decision-lab/defix",
        "https://github.com/resuldagdanov/DeFIX"
      ],
      "source": "arXiv"
    },
    {
      "id": "1910.09647",
      "abstract": "This paper presents secrecy analyses of a full-duplex MIMOME network which consists of two full-duplex multi-antenna users (Alice and Bob) and an arbitrarily located multi-antenna eavesdropper (Eve). The paper assumes that Eve's channel state information (CSI) is completely unknown to Alice and Bob except for a small radius of secured zone. The first part of this paper aims to optimize the powers of jamming noises from both users. To handle Eve's CSI being unknown to users, the focus is placed on Eve at the most harmful location, and the large matrix theory is applied to yield a hardened secrecy rate to work on. The performance gain of the power optimization in terms of maximum tolerable number of antennas on Eve is shown to be significant. The second part of this paper shows two analyses of anti-eavesdropping channel estimation (ANECE) that can better handle Eve with any number of antennas. One analysis assumes that Eve has a prior statistical knowledge of its CSI, which yields lower and upper bounds on secure degrees of freedom of the system as functions of the number (N) of antennas on Eve and the size (K) of information packet. The second analysis assumes that Eve does not have any prior knowledge of its CSI but performs blind detection of information, which yields an approximate secrecy rate for the case of K being larger than N.",
      "authors": [
        "Reza Sohrabi",
        "Qiping Zhu",
        "Yingbo Hua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2019-10-21T20:48:08+00:00",
          "link": "https://arxiv.org/abs/1910.09647v1",
          "size": "1222kb",
          "version": "v1"
        }
      ],
      "title": "Secrecy Analyses of a Full-Duplex MIMOME Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/1910.09647",
        "PDF": "https://arxiv.org/pdf/1910.09647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with secrecy analyses in a network context and does not address issues related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.12380",
      "abstract": "Three-dimensional target identification using scattering techniques requires high accuracy solutions and very fast computations for real-time predictions in some critical applications. We first train a deep neural operator~(DeepONet) to solve wave propagation problems described by the Helmholtz equation in a domain \\textit{without scatterers} but at different wavenumbers and with a complex absorbing boundary condition. We then design two classes of fast meta-solvers by combining DeepONet with either relaxation methods, such as Jacobi and Gauss-Seidel, or with Krylov methods, such as GMRES and BiCGStab, using the trunk basis of DeepONet as a coarse-scale preconditioner. We leverage the spectral bias of neural networks to account for the lower part of the spectrum in the error distribution while the upper part is handled inexpensively using relaxation methods or fine-scale preconditioners. The meta-solvers are then applied to solve scattering problems with different shape of scatterers, at no extra training cost. We first demonstrate that the resulting meta-solvers are shape-agnostic, fast, and robust, whereas the standard standalone solvers may even fail to converge without the DeepONet. We then apply both classes of meta-solvers to scattering from a submarine, a complex three-dimensional problem. We achieve very fast solutions, especially with the DeepONet-Krylov methods, which require orders of magnitude fewer iterations than any of the standalone solvers.",
      "authors": [
        "Youngkyu Lee",
        "Shanqing Liu",
        "Zongren Zou",
        "Adar Kahana",
        "Eli Turkel",
        "Rishikesh Ranade",
        "Jay Pathak",
        "George Em Karniadakis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T21:20:28+00:00",
          "link": "https://arxiv.org/abs/2405.12380v1",
          "size": "5726kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T18:57:06+00:00",
          "link": "https://arxiv.org/abs/2405.12380v2",
          "size": "12406kb",
          "version": "v2"
        }
      ],
      "title": "Fast meta-solvers for 3D complex-shape scatterers using neural operators trained on a non-scattering problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.12380",
        "HTML": "https://arxiv.org/html/2405.12380",
        "PDF": "https://arxiv.org/pdf/2405.12380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on solving three-dimensional scattering problems using fast neural operators, which is unrelated to any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08958",
      "abstract": "As cosmological simulations and their associated software become increasingly complex, physicists face the challenge of searching through vast amounts of literature and user manuals to extract simulation parameters from dense academic papers, each using different models and formats. Translating these parameters into executable scripts remains a time-consuming and error-prone process. To improve efficiency in physics research and accelerate the cosmological simulation process, we introduce SimAgents, a multi-agent system designed to automate both parameter configuration from the literature and preliminary analysis for cosmology research. SimAgents is powered by specialized LLM agents capable of physics reasoning, simulation software validation, and tool execution. These agents collaborate through structured communication, ensuring that extracted parameters are physically meaningful, internally consistent, and software-compliant. We also construct a cosmological parameter extraction evaluation dataset by collecting over 40 simulations in published papers from Arxiv and leading journals that cover diverse simulation types. Experiments on the dataset demonstrate a strong performance of SimAgents, highlighting its effectiveness and potential to accelerate scientific research for physicists. Our demonstration video is available at: https://youtu.be/w1zLpm_CaWA. The complete system and dataset are publicly available at https://github.com/xwzhang98/SimAgents.",
      "authors": [
        "Xiaowen Zhang",
        "Zhenyu Bi",
        "Patrick Lachance",
        "Xuan Wang",
        "Tiziana Di Matteo",
        "Rupert A.C. Croft"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:31:20+00:00",
          "link": "https://arxiv.org/abs/2507.08958v1",
          "size": "5319kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T22:55:30+00:00",
          "link": "https://arxiv.org/abs/2507.08958v2",
          "size": "5337kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08958",
        "HTML": "https://arxiv.org/html/2507.08958",
        "PDF": "https://arxiv.org/pdf/2507.08958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces a multi-agent LLM system for automating parameter extraction in cosmological simulations, involving the creation of a dataset for evaluation purposes. While it relates to dataset creation, it primarily focuses on automating scientific processes rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12621",
      "abstract": "Traditional volume visualization (VolVis) methods, like direct volume rendering, suffer from rigid transfer function designs and high computational costs. Although novel view synthesis approaches enhance rendering efficiency, they require additional learning effort for non-experts and lack support for semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an interactive system that enables users to explore, query, and edit volumetric scenes using natural language. NLI4VolVis integrates multi-view semantic segmentation and vision-language models to extract and understand semantic components in a scene. We introduce a multi-agent large language model architecture equipped with extensive function-calling tools to interpret user intents and execute visualization tasks. The agents leverage external tools and declarative VolVis commands to interact with the VolVis engine powered by 3D editable Gaussians, enabling open-vocabulary object querying, real-time scene editing, best-view selection, and 2D stylization. We validate our system through case studies and a user study, highlighting its improved accessibility and usability in volumetric data exploration. We strongly recommend readers check our case studies, demo video, and source code at https://nli4volvis.github.io/.",
      "authors": [
        "Kuangshi Ai",
        "Kaiyuan Tang",
        "Chaoli Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:35:46+00:00",
          "link": "https://arxiv.org/abs/2507.12621v1",
          "size": "38160kb",
          "version": "v1"
        }
      ],
      "title": "NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12621",
        "HTML": "https://arxiv.org/html/2507.12621",
        "PDF": "https://arxiv.org/pdf/2507.12621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a system for interactive volume visualization using natural language, utilizing LLMs as part of the architecture. However, it does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.03799",
      "abstract": "We present a chance-constrained model predictive control (MPC) framework under Gaussian mixture model (GMM) uncertainty. Specifically, we consider the uncertainty that arises from predicting future behaviors of moving obstacles, which may exhibit multiple modes (for example, turning left or right). To address the multi-modal uncertainty distribution, we propose three MPC formulations: nominal chance-constrained planning, robust chance-constrained planning, and contingency planning. We prove that closed-loop trajectories generated by the three planners are safe. The approaches differ in conservativeness and performance guarantee. In particular, the robust chance-constrained planner is recursively feasible under certain assumptions on the propagation of prediction uncertainty. On the other hand, the contingency planner generates a less conservative closed-loop trajectory than the nominal planner. We validate our planners using state-of-the-art trajectory prediction algorithms in autonomous driving simulators.",
      "authors": [
        "Kai Ren",
        "Colin Chen",
        "Hyeontae Sung",
        "Heejin Ahn",
        "Ian Mitchell and Maryam Kamgarpour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-08T10:31:51+00:00",
          "link": "https://arxiv.org/abs/2401.03799v1",
          "size": "10128kb",
          "version": "v1"
        },
        {
          "date": "2025-03-08T13:59:43+00:00",
          "link": "https://arxiv.org/abs/2401.03799v2",
          "size": "10566kb",
          "version": "v2"
        }
      ],
      "title": "Recursively Feasible Chance-constrained Model Predictive Control under Gaussian Mixture Model Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.03799",
        "HTML": "https://arxiv.org/html/2401.03799",
        "PDF": "https://arxiv.org/pdf/2401.03799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on model predictive control with Gaussian mixture model uncertainty in the context of moving obstacles and autonomous driving. It does not address aspects of LLM training data processing, making it irrelevant."
      },
      "tasks": [
        "Autonomous Driving",
        "model",
        "Model Predictive Control",
        "Trajectory Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.13164",
      "abstract": "Oral narrative skills are strong predictors of later literacy development. This study examines the features of oral narratives from children who were identified by experts as requiring intervention. Using simple machine learning methods, we analyse recorded stories from four- and five-year-old Afrikaans- and isiXhosa-speaking children. Consistent with prior research, we identify lexical diversity (unique words) and length-based features (mean utterance length) as indicators of typical development, but features like articulation rate prove less informative. Despite cross-linguistic variation in part-of-speech patterns, the use of specific verbs and auxiliaries associated with goal-directed storytelling is correlated with a reduced likelihood of requiring intervention. Our analysis of two linguistically distinct languages reveals both language-specific and shared predictors of narrative proficiency, with implications for early assessment in multilingual contexts.",
      "authors": [
        "Emma Sharratt",
        "Annelien Smith",
        "Retief Louw",
        "Daleen Klop",
        "Febe de Wet and Herman Kamper"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:31:32+00:00",
          "link": "https://arxiv.org/abs/2507.13164v1",
          "size": "688kb",
          "version": "v1"
        }
      ],
      "title": "Feature-based analysis of oral narratives from Afrikaans and isiXhosa children",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13164",
        "HTML": "https://arxiv.org/html/2507.13164",
        "PDF": "https://arxiv.org/pdf/2507.13164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes oral narratives of Afrikaans and isiXhosa children to determine language proficiency indicators, without addressing aspects of LLM training data such as creation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09966",
      "abstract": "Precise segmentation of brain tumors from magnetic resonance imaging (MRI) is essential for neuro-oncology diagnosis and treatment planning. Despite advances in deep learning methods, automatic segmentation remains challenging due to tumor morphological heterogeneity and complex three-dimensional spatial relationships. Current techniques primarily rely on visual features extracted from MRI sequences while underutilizing semantic knowledge embedded in medical reports. This research presents a multi-level fusion architecture that integrates pixel-level, feature-level, and semantic-level information, facilitating comprehensive processing from low-level data to high-level concepts. The semantic-level fusion pathway combines the semantic understanding capabilities of Contrastive Language-Image Pre-training (CLIP) models with the spatial feature extraction advantages of 3D U-Net through three mechanisms: 3D-2D semantic bridging, cross-modal semantic guidance, and semantic-based attention mechanisms. Experimental validation on the BraTS 2020 dataset demonstrates that the proposed model achieves an overall Dice coefficient of 0.8567, representing a 4.8% improvement compared to traditional 3D U-Net, with a 7.3% Dice coefficient increase in the clinically important enhancing tumor (ET) region.",
      "authors": [
        "Mingda Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:32:59+00:00",
          "link": "https://arxiv.org/abs/2507.09966v1",
          "size": "3809kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:49:45+00:00",
          "link": "https://arxiv.org/abs/2507.09966v2",
          "size": "3578kb",
          "version": "v2"
        }
      ],
      "title": "A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09966",
        "HTML": "https://arxiv.org/html/2507.09966",
        "PDF": "https://arxiv.org/pdf/2507.09966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a segmentation method for brain tumors using CLIP and 3D U-Net, which pertains to medical imaging and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.16801",
      "abstract": "Serious Games (SGs) are nowadays shifting focus to include procedural content generation (PCG) in the development process as a means of offering personalized and enhanced player experience. However, the development of a framework to assess the impact of PCG techniques when integrated into SGs remains particularly challenging. This study proposes a methodology for automated evaluation of PCG integration in SGs, incorporating deep reinforcement learning (DRL) game testing agents. To validate the proposed framework, a previously introduced SG featuring card game mechanics and incorporating three different versions of PCG for nonplayer character (NPC) creation has been deployed. Version 1 features random NPC creation, while versions 2 and 3 utilize a genetic algorithm approach. These versions are used to test the impact of different dynamic SG environments on the proposed framework's agents. The obtained results highlight the superiority of the DRL game testing agents trained on Versions 2 and 3 over those trained on Version 1 in terms of win rate (i.e. number of wins per played games) and training time. More specifically, within the execution of a test emulating regular gameplay, both Versions 2 and 3 peaked at a 97% win rate and achieved statistically significant higher (p=0009) win rates compared to those achieved in Version 1 that peaked at 94%. Overall, results advocate towards the proposed framework's capability to produce meaningful data for the evaluation of procedurally generated content in SGs.",
      "authors": [
        "Eleftherios Kalafatis",
        "Konstantinos Mitsis",
        "Konstantia Zarkogianni",
        "Maria Athanasiou and Konstantina Nikita"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T15:40:56+00:00",
          "link": "https://arxiv.org/abs/2505.16801v1",
          "size": "1528kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:44:08+00:00",
          "link": "https://arxiv.org/abs/2505.16801v2",
          "size": "1539kb",
          "version": "v2"
        }
      ],
      "title": "A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16801",
        "PDF": "https://arxiv.org/pdf/2505.16801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study proposes a framework for evaluating procedural content generation in serious games using deep reinforcement learning, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.07283",
      "abstract": "We present a novel approach to querying classical inconsistent description logic (DL) knowledge bases by adopting a~paraconsistent semantics with the four Belnapian values: exactly true ($\\mathbf{T}$), exactly false ($\\mathbf{F}$), both ($\\mathbf{B}$), and neither ($\\mathbf{N}$). In contrast to prior studies on paraconsistent DLs, we allow truth value operators in the query language, which can be used to differentiate between answers having contradictory evidence and those having only positive evidence. We present a reduction to classical DL query answering that allows us to pinpoint the precise combined and data complexity of answering queries with values in paraconsistent $\\mathcal{ALCHI}$ and its sublogics. Notably, we show that tractable data complexity is retained for Horn DLs. We present a comparison with repair-based inconsistency-tolerant semantics, showing that the two approaches are incomparable.",
      "authors": [
        "Meghyn Bienvenu and Camille Bourgaux and Daniil Kozhemiachenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-01T08:11:50+00:00",
          "link": "https://arxiv.org/abs/2408.07283v1",
          "size": "46kb",
          "version": "v1"
        },
        {
          "date": "2024-08-15T07:33:58+00:00",
          "link": "https://arxiv.org/abs/2408.07283v2",
          "size": "42kb",
          "version": "v2"
        }
      ],
      "title": "Queries With Exact Truth Values in Paraconsistent Description Logics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.07283",
        "HTML": "https://arxiv.org/html/2408.07283",
        "PDF": "https://arxiv.org/pdf/2408.07283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for querying inconsistent description logic knowledge bases. It focuses on logic semantics and query complexity, rather than LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.07459",
      "abstract": "Large language models predominantly reflect Western cultures, largely due to the dominance of English-centric training data. This imbalance presents a significant challenge, as LLMs are increasingly used across diverse contexts without adequate evaluation of their cultural competence in non-English languages, including Persian. To address this gap, we introduce PerCul, a carefully constructed dataset designed to assess the sensitivity of LLMs toward Persian culture. PerCul features story-based, multiple-choice questions that capture culturally nuanced scenarios. Unlike existing benchmarks, PerCul is curated with input from native Persian annotators to ensure authenticity and to prevent the use of translation as a shortcut. We evaluate several state-of-the-art multilingual and Persian-specific LLMs, establishing a foundation for future research in cross-cultural NLP evaluation. Our experiments demonstrate a 11.3% gap between best closed source model and layperson baseline while the gap increases to 21.3% by using the best open-weight model. You can access the dataset from here: https://huggingface.co/datasets/teias-ai/percul",
      "authors": [
        "Erfan Moosavi Monazzah",
        "Vahid Rahimzadeh",
        "Yadollah Yaghoobzadeh",
        "Azadeh Shakery",
        "Mohammad Taher Pilehvar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-11T11:07:44+00:00",
          "link": "https://arxiv.org/abs/2502.07459v1",
          "size": "11253kb",
          "version": "v1"
        }
      ],
      "title": "PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07459",
        "HTML": "https://arxiv.org/html/2502.07459",
        "PDF": "https://arxiv.org/pdf/2502.07459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces PerCul, a dataset to evaluate LLMs' cultural competence in Persian, highlighting training data curation and quality specific to a cultural context, contributing to LLM training data processing by addressing cultural sensitivity."
      },
      "datasets": [
        {
          "dataset_name": "teias-ai/percul",
          "downloads": "16",
          "likes": "5",
          "link": "https://huggingface.co/datasets/teias-ai/percul"
        }
      ],
      "tasks": [
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.02529",
      "abstract": "Revealing expressions of secret-key capacity (SKC) based on data sets from Gaussian MIMO channel probing are presented. It is shown that Maurer's upper and lower bounds on SKC coincide when the used data sets are produced from one-way channel probing. As channel coherence time increases, SKC in bits per probing channel use is always lower bounded by a positive value unless eavesdropper's observations are noiseless, which is unlike SKC solely based on reciprocal channels.",
      "authors": [
        "Yingbo Hua and Ahmed Maksud"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-04T22:49:55+00:00",
          "link": "https://arxiv.org/abs/2403.02529v1",
          "size": "1021kb",
          "version": "v1"
        }
      ],
      "title": "Secret-Key Capacity from MIMO Channel Probing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.02529",
        "HTML": "https://arxiv.org/html/2403.02529",
        "PDF": "https://arxiv.org/pdf/2403.02529"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on secret-key capacity in MIMO channel probing, which does not relate to any processes involved in LLM training data."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Multimedia (cs.MM)",
    "Physics and Society (physics.soc-ph)",
    "Optimization and Control (math.OC)",
    "Quantum Physics (quant-ph)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Computer Science and Game Theory (cs.GT)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Image and Video Processing (eess.IV)",
    "Sound (cs.SD)",
    "Performance (cs.PF)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Geometry (cs.CG)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Nuclear Experiment (nucl-ex)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "Computational Complexity (cs.CC)",
    "Quantitative Methods (q-bio.QM)",
    "Logic (math.LO)",
    "High Energy Physics - Experiment (hep-ex)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "History and Philosophy of Physics (physics.hist-ph)",
    "Category Theory (math.CT)",
    "Symbolic Computation (cs.SC)",
    "Biological Physics (physics.bio-ph)",
    "General Topology (math.GN)",
    "Probability (math.PR)",
    "Mathematical Physics (math.MP)",
    "Discrete Mathematics (cs.DM)",
    "Information Theory (math.IT)",
    "Classical Physics (physics.class-ph)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Computation (stat.CO)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Metric Geometry (math.MG)",
    "Chaotic Dynamics (nlin.CD)",
    "Combinatorics (math.CO)",
    "Differential Geometry (math.DG)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Group Theory (math.GR)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "High Energy Physics - Theory (hep-th)",
    "Hardware Architecture (cs.AR)",
    "Risk Management (q-fin.RM)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Computational Physics (physics.comp-ph)",
    "Software Engineering (cs.SE)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Econometrics (econ.EM)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Rings and Algebras (math.RA)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Dynamical Systems (math.DS)",
    "Genomics (q-bio.GN)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to the performance of large language models (LLMs). You are a computer science expert specializing in LLM training data processing. Your task is to analyze a set of arXiv papers and determine their relevance to **LLM training data processing**.\n\n### **Task Objective**\n\nFor each paper, assess whether it makes a technical contribution to **LLM training data processing**.\n\n1. First, the paper must relate to data processing for **pretraining or fine-tuning**, including stages such as LLM pretraining, instruction fine-tuning, supervised fine-tuning (SFT), or alignment fine-tuning.\n2. Second, the paper must involve **training data processing** operations, such as:\n\n   * Data engineering operations, including data collection, data generation, deduplication, filtering, etc.;\n   * Techniques or methods that significantly improve data quality;\n   * Creation or generation of new datasets.\n\n### Answer: **Relevance Classification**\n\n**`core`**: The paper makes a direct contribution to LLM training data processing. Examples include: creation, generation, or synthesis of new datasets; building higher-quality datasets from existing ones; novel data processing techniques; or any data engineering operations that substantially improve data quality.\n\n**`partial`**: The paper briefly discusses training data processing, but the main focus lies elsewhere\u2014such as model architecture, task design, evaluation, or prompt engineering\u2014rather than training data processing.\n\n**`irrelevant`**: The paper does not address any aspect of LLM training data processing.\n\n### **Output Format (strictly follow this JSON structure)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<Paper ID>\",\n      \"answer\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1\u20132 sentence explanation of your classification, citing key content from the abstract or methodology section.\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n\n### Example\n\ninput:\n\n```\n[\n    {\n        \"id\": \"2411.12372\",\n        \"title\": \"RedPajama: an Open Dataset for Training Large Language Models\",\n        \"abstract\": \"Large language models are increasingly becoming a cornerstone technology in artificial intelligence, the sciences, and society as a whole, yet the optimal strategies for dataset composition and filtering remain largely elusive. Many of the top-performing models lack transparency in their dataset curation and model development processes, posing an obstacle to the development of fully open language models. In this paper, we identify three core data-related challenges that must be addressed to advance open-source language models. These include (1) transparency in model development, including the data curation process, (2) access to large quantities of high-quality data, and (3) availability of artifacts and metadata for dataset curation and analysis. To address these challenges, we release RedPajama-V1, an open reproduction of the LLaMA training dataset. In addition, we release RedPajama-V2, a massive web-only dataset consisting of raw, unfiltered text data together with quality signals and metadata. Together, the RedPajama datasets comprise over 100 trillion tokens spanning multiple domains and with their quality signals facilitate the filtering of data, aiming to inspire the development of numerous new datasets. To date, these datasets have already been used in the training of strong language models used in production, such as Snowflake Arctic, Salesforce's XGen and AI2's OLMo. To provide insight into the quality of RedPajama, we present a series of analyses and ablation studies with decoder-only language models with up to 1.6B parameters. Our findings demonstrate how quality signals for web data can be effectively leveraged to curate high-quality subsets of the dataset, underscoring the potential of RedPajama to advance the development of transparent and high-performing language models at scale.\"\n    },\n    {\n        \"id\": \"2306.01116\",\n        \"title\": \"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\",\n        \"abstract\": \"Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.\"\n    }\n]\n```\n\noutput:\n\n```\n{\n  \"result\": [\n    {\n      \"id\": \"2411.12372\",\n      \"answer\": \"core\",\n      \"reason\": \"This paper releases RedPajama-V1 and V2 datasets, comprising over 100 trillion tokens, and introduces quality signals for filtering. It involves data collection, deduplication, filtering, and quality assessment, making a significant contribution to LLM training data processing.\"\n    },\n    {\n      \"id\": \"2306.01116\",\n      \"answer\": \"core\",\n      \"reason\": \"The paper presents the RefinedWeb dataset, which uses only deduplicated and filtered web data to train LLMs. It challenges the conventional reliance on mixed curated corpora and publicly releases both the dataset and models, representing a core contribution to high-quality data construction.\"\n    }\n  ]\n}\n\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "irrelevant": 602,
    "partial": 88,
    "core": 11
  },
  "arxiv_update_date": "2025-07-21",
  "updated_at": "2025-07-21 10:09:40"
}