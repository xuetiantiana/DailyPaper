{
  "data": [
    {
      "id": "2506.20748",
      "abstract": "Chatbots are increasingly integrated into people's lives and are widely used to help people. Recently, there has also been growing interest in the reverse direction-humans help chatbots-due to a wide range of benefits including better chatbot performance, human well-being, and collaborative outcomes. However, little research has explored the factors that motivate people to help chatbots. To address this gap, we draw on the Computers Are Social Actors (CASA) framework to examine how chatbot anthropomorphism-including human-like identity, emotional expression, and non-verbal expression-influences human empathy toward chatbots and their subsequent prosocial behaviors and intentions. We also explore people's own interpretations of their prosocial behaviors toward chatbots. We conducted an online experiment (N = 244) in which chatbots made mistakes in a collaborative image labeling task and explained the reasons to participants. We then measured participants' prosocial behaviors and intentions toward the chatbots. Our findings revealed that human identity and emotional expression of chatbots increased participants' prosocial behavior and intention toward chatbots, with empathy mediating these effects. Qualitative analysis further identified two motivations for participants' prosocial behaviors: empathy for the chatbot and perceiving the chatbot as human-like. We discuss the implications of these results for understanding and promoting human prosocial behaviors toward chatbots.",
      "authors": [
        "Jingshu Li",
        "Zicheng Zhu",
        "Renwen Zhang",
        "Yi-Chieh Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20748",
        "HTML": "https://arxiv.org/html/2506.20748",
        "PDF": "https://arxiv.org/pdf/2506.20748"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T18:16:14+00:00",
          "link": "https://arxiv.org/abs/2506.20748v1",
          "size": "2445kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper focuses on anthropomorphism and empathy's effect on prosocial behavior toward chatbots, not on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20884",
      "abstract": "''TikTok, Do Your Thing'' is a viral trend where users attempt to identify strangers they see in public via information crowd-sourcing. The trend started as early as 2021 and users typically engage with it for romantic purposes (similar to a ''Missed Connections'' personal advertisement). This practice includes acts of surveillance and identification in the public sphere, although by peers rather than governments or corporations. To understand users' reactions to this trend we conducted a qualitative analysis of 60 TikTok videos and 1,901 user comments. Of the 60 videos reviewed, we find 19 individuals were successfully identified. We also find that while there were comments expressing disapproval (n=310), more than double the number expressed support (n=883). Supportive comments demonstrated genuine interest and empathy, reflecting evolving conceptions of community and algorithmic engagement. On the other hand, disapproving comments highlighted concerns about inappropriate relationships, stalking, consent, and gendered double standards. We discuss these insights in relation to the normalization of interpersonal surveillance, online stalking, and as an evolution of social surveillance to offer a new perspective on user perceptions surrounding interpersonal surveillance and identification in the public sphere.",
      "authors": [
        "Meira Gilbert",
        "Miranda Wei",
        "Lindah Kotut"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20884",
        "HTML": "https://arxiv.org/html/2506.20884",
        "PDF": "https://arxiv.org/pdf/2506.20884"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T23:13:43+00:00",
          "link": "https://arxiv.org/abs/2506.20884v1",
          "size": "1215kb",
          "version": "v1"
        }
      ],
      "title": "\"TikTok, Do Your Thing\": User Reactions to Social Surveillance in the Public Sphere",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The study focuses on social surveillance and user reactions on TikTok, unrelated to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20952",
      "abstract": "Human crowd simulation in virtual reality (VR) is a powerful tool with potential applications including emergency evacuation training and assessment of building layout. While haptic feedback in VR enhances immersive experience, its effect on walking behavior in dense and dynamic pedestrian flows is unknown. Through a user study, we investigated how haptic feedback changes user walking motion in crowded pedestrian flows in VR. The results indicate that haptic feedback changed users' collision avoidance movements, as measured by increased walking trajectory length and change in pelvis angle. The displacements of users' lateral position and pelvis angle were also increased in the instantaneous response to a collision with a non-player character (NPC), even when the NPC was inside the field of view. Haptic feedback also enhanced users' awareness and visual exploration when an NPC approached from the side and back. Furthermore, variation in walking speed was increased by the haptic feedback. These results suggested that the haptic feedback enhanced users' sensitivity to a collision in VR environment.",
      "authors": [
        "Kyosuke Ishibashi",
        "Atsushi Saito",
        "Zin Y. Tun",
        "Lucas Ray",
        "Megan C. Coram",
        "Akihiro Sakurai",
        "Allison M. Okamura",
        "and Ko Yamamoto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20952",
        "HTML": "https://arxiv.org/html/2506.20952",
        "PDF": "https://arxiv.org/pdf/2506.20952"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T02:37:46+00:00",
          "link": "https://arxiv.org/abs/2506.20952v1",
          "size": "9167kb",
          "version": "v1"
        }
      ],
      "title": "Effect of Haptic Feedback on Avoidance Behavior and Visual Exploration in Dynamic VR Pedestrian Environment",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper explores haptic feedback in VR environments, without relating to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21195",
      "abstract": "Have you wondered how cross-functional teams balance between maximizing value that users derive and business growth leading to win-win situations? This case study shows how User Experience Research (UXR) and Data Science teams used mixed methods research to strategically influence Product Led Growth (PLG) for a Password Manager used by million+ users, thus allowing our users, internal teams, and business to win. The audience will take away practical lessons/techniques related to leveraging mixed methods to: a. Maximize user value while meeting business growth goals b. Influence cross-functional teams c. Measure user and business impact This case study can be easily tied to the UXR Point of view pyramid (POV) [2] that represents a methodological approach to construct a POV and further dives into actioning POV to create measurable user and business impact.",
      "authors": [
        "Neha Raghuvanshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21195",
        "HTML": "https://arxiv.org/html/2506.21195",
        "PDF": "https://arxiv.org/pdf/2506.21195"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T12:54:41+00:00",
          "link": "https://arxiv.org/abs/2506.21195v1",
          "size": "232kb",
          "version": "v1"
        }
      ],
      "title": "Follow the user meaningfully and product growth will follow: A mixed methods case study tying UX Point of View & Growth leading to measurable impact",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper discusses user experience and product growth strategies without touching on creativity as a concept or main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21201",
      "abstract": "The consumption of subtitles via TVs, laptops and smartphones has the potential to marginalize people based on their complex accessibility needs. The current one-size-fits-all approach to this accessibility aid is no longer fit for purpose and work is required to look at how it can be adapted to be personalised for individual users based on individual context, content, and consumption habits. People with Aphasia, for example, encounter significant challenges in understanding subtitle texts.\n  We see our work as a call to action for more inclusive practices, focusing on how the thoughts and opinions of people with aphasia can be included in media research. Our work investigates how to develop future media solutions for people with aphasia to create a more inclusive media viewing environment. We believe the key to this is appropriate prototyping tools and methods to allow equitable inclusion in the system design process.",
      "authors": [
        "Zihao You and Michael Crabb"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21201",
        "HTML": "https://arxiv.org/html/2506.21201",
        "PDF": "https://arxiv.org/pdf/2506.21201"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T12:59:25+00:00",
          "link": "https://arxiv.org/abs/2506.21201v1",
          "size": "266kb",
          "version": "v1"
        }
      ],
      "title": "Subtitled Media Adaptations for People with Aphasia: Ongoing Accessibility Barriers and Emerging Design Practices",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper concentrates on accessibility and inclusive design for people with aphasia without addressing creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21319",
      "abstract": "Visualizations are crucial for data communication, yet understanding them requires comprehension of both visual elements and their underlying data relationships. Current multimodal large models, while effective in natural image understanding, struggle with visualization due to their inability to decode the data-to-visual mapping rules and extract structured information. To address these challenges, we present a novel dataset and train multimodal visualization LLMs specifically designed for understanding. Our approach combines chart images with their corresponding vectorized representations, encoding schemes, and data features. The proposed vector format enables compact and accurate reconstruction of visualization content. Experimental results demonstrate significant improvements in both data extraction accuracy and chart reconstruction quality.",
      "authors": [
        "Can Liu and Chunlin Da and Xiaoxiao Long and Yuxiao Yang and Yu Zhang and Yong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21319",
        "HTML": "https://arxiv.org/html/2506.21319",
        "PDF": "https://arxiv.org/pdf/2506.21319"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:35:59+00:00",
          "link": "https://arxiv.org/abs/2506.21319v1",
          "size": "5645kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal LLMs for Visualization Reconstruction and Understanding",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper deals with multimodal models for visualization reconstruction, focusing on data comprehension rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21322",
      "abstract": "Advancements in robotic capabilities for providing physical assistance, psychological support, and daily health management are making the deployment of intelligent healthcare robots in home environments increasingly feasible in the near future. However, challenges arise when the information provided by these robots contradicts users' memory, raising concerns about user trust and decision-making. This paper presents a study that examines how varying a robot's level of transparency and sociability influences user interpretation, decision-making and perceived trust when faced with conflicting information from a robot. In a 2 x 2 between-subjects online study, 176 participants watched videos of a Furhat robot acting as a family healthcare assistant and suggesting a fictional user to take medication at a different time from that remembered by the user. Results indicate that robot transparency influenced users' interpretation of information discrepancies: with a low transparency robot, the most frequent assumption was that the user had not correctly remembered the time, while with the high transparency robot, participants were more likely to attribute the discrepancy to external factors, such as a partner or another household member modifying the robot's information. Additionally, participants exhibited a tendency toward overtrust, often prioritizing the robot's recommendations over the user's memory, even when suspecting system malfunctions or third-party interference. These findings highlight the impact of transparency mechanisms in robotic systems, the complexity and importance associated with system access control for multi-user robots deployed in home environments, and the potential risks of users' over reliance on robots in sensitive domains such as healthcare.",
      "authors": [
        "Hong Wang",
        "Natalia Calvo-Barajas",
        "Katie Winkle",
        "and Ginevra Castellano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21322",
        "HTML": "https://arxiv.org/html/2506.21322",
        "PDF": "https://arxiv.org/pdf/2506.21322"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:37:54+00:00",
          "link": "https://arxiv.org/abs/2506.21322v1",
          "size": "5117kb",
          "version": "v1"
        }
      ],
      "title": "\"Who Should I Believe?\": User Interpretation and Decision-Making When a Family Healthcare Robot Contradicts Human Memory",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper examines user trust and decision-making with robotic assistance, without exploring creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21333",
      "abstract": "The co creativity community is making significant progress in developing more sophisticated and tailored systems to support and enhance human creativity. Design considerations from prior work can serve as a valuable and efficient foundation for future systems. To support this effort, we conducted a systematic literature review of 62 papers on co-creative systems. These papers cover a diverse range of applications, including visual arts, design, and writing, where the AI acts not just as a tool but as an active collaborator in the creative process. From this review, we identified several key dimensions relevant to system design: phase of the creative process, creative task, proactive behavior of the system, user control, system embodiment, and AI model type. Our findings suggest that systems offering high user control lead to greater satisfaction, trust, and a stronger sense of ownership over creative outcomes. Furthermore, proactive systems, when adaptive and context sensitive, can enhance collaboration. We also extracted 24 design considerations, highlighting the value of encouraging users to externalize their thoughts and of increasing the system's social presence and transparency to foster trust. Despite recent advancements, important gaps remain, such as limited support for early creative phases like problem clarification, and challenges related to user adaptation to AI systems.",
      "authors": [
        "Saloni Singh",
        "Koen Hndriks",
        "Drik Heylen",
        "Kim Baraka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21333",
        "HTML": "https://arxiv.org/html/2506.21333",
        "PDF": "https://arxiv.org/pdf/2506.21333"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:44:52+00:00",
          "link": "https://arxiv.org/abs/2506.21333v1",
          "size": "1851kb",
          "version": "v1"
        }
      ],
      "title": "A Systematic Review of Human-AI Co-Creativity",
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper explicitly focuses on creativity through an examination of human-AI co-creativity systems aimed at enhancing human creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21417",
      "abstract": "This study presents a lightweight, wearable fingertip haptic device that provides physics-based haptic feedback for dexterous manipulation in virtual environments without hindering real-world interactions. The device, designed with thin strings and actuators attached to the fingernails, ensures minimal weight (1.55 g per finger) and preserves finger flexibility. Integrating the software with a physics engine renders multiple types of haptic feedback (grip force, collision, and sliding vibration feedback). We evaluated the device's performance in pressure perception, slip feedback, typical dexterous manipulation tasks, and daily operations, and we gathered user experience through subjective assessments. Our results show that participants could perceive and respond to pressure and vibration feedback. Through dexterous manipulation experiments, we further demonstrated that these minimal haptic cues significantly improved virtual task efficiency, showcasing how lightweight haptic feedback can enhance manipulation performance without complex mechanisms. The device's ability to preserve tactile sensations and minimize hindrance to real-world operations is a key advantage over glove-type haptic devices. This research offers a potential solution for designing haptic interfaces that balance lightweight construction, haptic feedback for dexterous manipulation, and daily wearability.",
      "authors": [
        "Yunxiu Xu",
        "Siyu Wang",
        "and Shoichi Hasegawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21417",
        "HTML": "https://arxiv.org/html/2506.21417",
        "PDF": "https://arxiv.org/pdf/2506.21417"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:06:04+00:00",
          "link": "https://arxiv.org/abs/2506.21417v1",
          "size": "11847kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Fingernail Haptic Device: Unobstructed Fingerpad Force and Vibration Feedback for Enhanced Virtual Dexterous Manipulation",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The focus is on haptic feedback for virtual manipulation, not related to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21441",
      "abstract": "A paradigm for the design of systems that manage level of detail in virtual environments is proposed. As an example of the prototyping step in this paradigm, a user study was performed to evaluate the effectiveness of high detail insets used with head-mounted displays. Ten subjects were given a simple search task that required the location and identification of a single target object. All subjects used seven different displays (the independent variable), varying in inset size and peripheral detail, to perform this task. Frame rate, target location, subject input method, and order of display use were all controlled. Primary dependent measures were search time on trials with correct identification, and the percentage of all trials correctly identified. ANOVAs of the results showed that insetless, high detail displays did not lead to significantly different search times or accuracies than displays with insets. In fact, only the insetless, low detail display returned significantly different results. Further research is being performed to examine the effect of varying task complexity, inset size, and level of detail.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "Larry F Hodges",
        "Martin Reddy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21441",
        "HTML": "https://arxiv.org/html/2506.21441",
        "PDF": "https://arxiv.org/pdf/2506.21441"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:26:36+00:00",
          "link": "https://arxiv.org/abs/2506.21441v1",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "title": "An evaluation of level of detail degradation in head-mounted display peripheries",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper deals with display detail optimization in virtual environments, with no connection to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21456",
      "abstract": "Previous work has demonstrated the utility of reductions in the level of detail (LOD) in the periphery of head-tracked, large field of view displays. This paper provides a psychophysically based model, centered around an eye/head movement tradeoff, that explains the effectiveness of peripheral degradation and suggests how peripherally degraded displays should be designed. An experiment evaluating the effect on search performance of the shape and area of the high detail central area (inset) in peripherally degraded displays was performed, results indicated that inset shape is not a significant factor in performance. Inset area, however, was significant: performance with displays subtending at least 30 degrees of horizontal and vertical angle was not significantly different from performance with an undegraded display. These results agreed with the proposed model.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "Larry F Hodges"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21456",
        "HTML": "https://arxiv.org/html/2506.21456",
        "PDF": "https://arxiv.org/pdf/2506.21456"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:35:38+00:00",
          "link": "https://arxiv.org/abs/2506.21456v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Managing level of detail through head-tracked peripheral degradation: a model and resulting design principles",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "This paper discusses principles for display design based on peripheral degradation, unrelated to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20795",
      "abstract": "Gestures enable non-verbal human-robot communication, especially in noisy environments like agile production. Traditional deep learning-based gesture recognition relies on task-specific architectures using images, videos, or skeletal pose estimates as input. Meanwhile, Vision Foundation Models (VFMs) and Vision Language Models (VLMs) with their strong generalization abilities offer potential to reduce system complexity by replacing dedicated task-specific modules. This study investigates adapting such models for dynamic, full-body gesture recognition, comparing V-JEPA (a state-of-the-art VFM), Gemini Flash 2.0 (a multimodal VLM), and HD-GCN (a top-performing skeleton-based approach). We introduce NUGGET, a dataset tailored for human-robot communication in intralogistics environments, to evaluate the different gesture recognition approaches. In our experiments, HD-GCN achieves best performance, but V-JEPA comes close with a simple, task-specific classification head - thus paving a possible way towards reducing system complexity, by using it as a shared multi-task model. In contrast, Gemini struggles to differentiate gestures based solely on textual descriptions in the zero-shot setting, highlighting the need of further research on suitable input representations for gestures.",
      "authors": [
        "Stephanie K\\\"as",
        "Anton Burenko",
        "Louis Markert",
        "Onur Alp Culha",
        "Dennis Mack",
        "Timm Linder",
        "Bastian Leibe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20795",
        "HTML": "https://arxiv.org/html/2506.20795",
        "PDF": "https://arxiv.org/pdf/2506.20795"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T19:36:45+00:00",
          "link": "https://arxiv.org/abs/2506.20795v1",
          "size": "5209kb",
          "version": "v1"
        }
      ],
      "title": "How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper addresses gesture recognition in human-robot interaction, with no mention of creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20803",
      "abstract": "Large Language Models (LLMs) have shown promise in accelerating the scientific research pipeline. A key capability for this process is the ability to generate novel research ideas, and prior studies have found settings in which LLM-generated research ideas were judged as more novel than human-expert ideas. However, a good idea should not simply appear to be novel, it should also result in better research after being executed. To test whether AI-generated ideas lead to better research outcomes, we conduct an execution study by recruiting 43 expert researchers to execute randomly-assigned ideas, either written by experts or generated by an LLM. Each expert spent over 100 hours implementing the idea and wrote a 4-page short paper to document the experiments. All the executed projects are then reviewed blindly by expert NLP researchers. Comparing the review scores of the same ideas before and after execution, the scores of the LLM-generated ideas decrease significantly more than expert-written ideas on all evaluation metrics (novelty, excitement, effectiveness, and overall; p < 0.05), closing the gap between LLM and human ideas observed at the ideation stage. When comparing the aggregated review scores from the execution study, we even observe that for many metrics there is a flip in rankings where human ideas score higher than LLM ideas. This ideation-execution gap highlights the limitations of current LLMs in generating truly effective research ideas and the challenge of evaluating research ideas in the absence of execution outcomes.",
      "authors": [
        "Chenglei Si",
        "Tatsunori Hashimoto",
        "Diyi Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20803",
        "HTML": "https://arxiv.org/html/2506.20803",
        "PDF": "https://arxiv.org/pdf/2506.20803"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T19:47:23+00:00",
          "link": "https://arxiv.org/abs/2506.20803v1",
          "size": "5606kb",
          "version": "v1"
        }
      ],
      "title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas",
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper explicitly discusses the generation of novel research ideas by LLMs, a key aspect of creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20993",
      "abstract": "Large language models (LLMs) have gained significant traction across a wide range of fields in recent years. There is also a growing expectation for them to display human-like personalities during interactions. To meet this expectation, numerous studies have proposed methods for modelling LLM personalities through psychometric evaluations. However, most existing models face two major limitations: they rely on the Big Five (OCEAN) framework, which only provides coarse personality dimensions, and they lack mechanisms for controlling trait intensity. In this paper, we address this gap by extending the Machine Personality Inventory (MPI), which originally used the Big Five model, to incorporate the 16 Personality Factor (16PF) model, allowing expressive control over sixteen distinct traits. We also developed a structured framework known as Specific Attribute Control (SAC) for evaluating and dynamically inducing trait intensity in LLMs. Our method introduces adjective-based semantic anchoring to guide trait intensity expression and leverages behavioural questions across five intensity factors: \\textit{Frequency}, \\textit{Depth}, \\textit{Threshold}, \\textit{Effort}, and \\textit{Willingness}. Through experimentation, we find that modelling intensity as a continuous spectrum yields substantially more consistent and controllable personality expression compared to binary trait toggling. Moreover, we observe that changes in target trait intensity systematically influence closely related traits in psychologically coherent directions, suggesting that LLMs internalize multi-dimensional personality structures rather than treating traits in isolation. Our work opens new pathways for controlled and nuanced human-machine interactions in domains such as healthcare, education, and interviewing processes, bringing us one step closer to truly human-like social machines.",
      "authors": [
        "Adithya Chittem",
        "Aishna Shrivastava",
        "Sai Tarun Pendela",
        "Jagat Sesh Challa",
        "Dhruv Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20993",
        "HTML": "https://arxiv.org/html/2506.20993",
        "PDF": "https://arxiv.org/pdf/2506.20993"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T04:12:15+00:00",
          "link": "https://arxiv.org/abs/2506.20993v1",
          "size": "102kb",
          "version": "v1"
        }
      ],
      "title": "SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper focuses on extending personality trait models in LLMs for human-machine interaction, with no mention or focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21338",
      "abstract": "Brain-computer interface (BCI) technology utilizing electroencephalography (EEG) marks a transformative innovation, empowering motor-impaired individuals to engage with their environment on equal footing. Despite its promising potential, developing subject-invariant and session-invariant BCI systems remains a significant challenge due to the inherent complexity and variability of neural activity across individuals and over time, compounded by EEG hardware constraints. While prior studies have sought to develop robust BCI systems, existing approaches remain ineffective in capturing the intricate spatiotemporal dependencies within multichannel EEG signals. This study addresses this gap by introducing the attentive graph-temporal convolutional network (AGTCNet), a novel graph-temporal model for motor imagery EEG (MI-EEG) classification. Specifically, AGTCNet leverages the topographic configuration of EEG electrodes as an inductive bias and integrates graph convolutional attention network (GCAT) to jointly learn expressive spatiotemporal EEG representations. The proposed model significantly outperformed existing MI-EEG classifiers, achieving state-of-the-art performance while utilizing a compact architecture, underscoring its effectiveness and practicality for BCI deployment. With a 49.87% reduction in model size, 64.65% faster inference time, and shorter input EEG signal, AGTCNet achieved a moving average accuracy of 66.82% for subject-independent classification on the BCI Competition IV Dataset 2a, which further improved to 82.88% when fine-tuned for subject-specific classification. On the EEG Motor Movement/Imagery Dataset, AGTCNet achieved moving average accuracies of 64.14% and 85.22% for 4-class and 2-class subject-independent classifications, respectively, with further improvements to 72.13% and 90.54% for subject-specific classifications.",
      "authors": [
        "Galvin Brice S. Lim",
        "Brian Godwin S. Lim",
        "Argel A. Bandala",
        "John Anthony C. Jose",
        "Timothy Scott C. Chu",
        "Edwin Sybingco"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21338",
        "HTML": "https://arxiv.org/html/2506.21338",
        "PDF": "https://arxiv.org/pdf/2506.21338"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:49:10+00:00",
          "link": "https://arxiv.org/abs/2506.21338v1",
          "size": "8661kb",
          "version": "v1"
        }
      ],
      "title": "AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper focuses on brain-computer interface technology for motor-impaired individuals, with no mention of creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21490",
      "abstract": "Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.",
      "authors": [
        "Tin Dizdarevi\\'c",
        "Ravi Hammond",
        "Tobias Gessler",
        "Anisoara Calinescu",
        "Jonathan Cook",
        "Matteo Gallici",
        "Andrei Lupu",
        "Jakob Nicolaus Foerster"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21490",
        "HTML": "https://arxiv.org/html/2506.21490",
        "PDF": "https://arxiv.org/pdf/2506.21490"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:19:52+00:00",
          "link": "https://arxiv.org/abs/2506.21490v1",
          "size": "1683kb",
          "version": "v1"
        }
      ],
      "title": "Ad-Hoc Human-AI Coordination Challenge",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper focuses on AI-human coordination in playing Hanabi, a card game. Creativity is not an explicit focus or topic in this paper."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21536",
      "abstract": "With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health. However, existing models still have deficiencies in dialogue safety, detailed scenario handling, and lightweight deployment. To address these issues, this study proposes PsyLite, a lightweight psychological counseling large language model agent developed based on the base model InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation data fine-tuning and ORPO preference optimization), PsyLite enhances the model's deep-reasoning ability, psychological counseling ability, and safe dialogue ability. After deployment using Ollama and Open WebUI, a custom workflow is created with Pipelines. An innovative conditional RAG is designed to introduce crosstalk humor elements at appropriate times during psychological counseling to enhance user experience and decline dangerous requests to strengthen dialogue safety. Evaluations show that PsyLite outperforms the baseline models in the Chinese general evaluation (CEval), psychological counseling professional evaluation (CPsyCounE), and dialogue safety evaluation (SafeDialBench), particularly in psychological counseling professionalism (CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score improvement of 2.4\\%). Additionally, the model uses quantization technology (GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient for operation), providing a feasible solution for psychological counseling applications in resource-constrained environments.",
      "authors": [
        "Fangjun Ding and Renyu Zhang and Xinyu Feng and Chengye Xie and Zheng Zhang and Yanting Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21536",
        "HTML": "https://arxiv.org/html/2506.21536",
        "PDF": "https://arxiv.org/pdf/2506.21536"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:54:42+00:00",
          "link": "https://arxiv.org/abs/2506.21536v1",
          "size": "3209kb",
          "version": "v1"
        }
      ],
      "title": "PsyLite Technical Report",
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While the paper is about AI-driven psychological counseling, it introduces humor elements during counseling sessions, which could touch on creativity in terms of interaction design. However, creativity is not the main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.09910",
      "abstract": "Apologies serve essential functions for moral agents such as expressing remorse, taking responsibility, and repairing trust. LLM-based chatbots routinely produce output that has the linguistic form of an apology. However, they do this simply because they are echoing the kinds of things that humans say. Moreover, there are reasons to think that chatbots are not the kind of linguistic or moral agents capable of apology. To put the point bluntly: Chatbot apologies are bullshit. This paper explores this concern and develops it beyond the epithet, drawing on the nature of morally serious apologies, the linguistic agency required to perform them, and the moral agency required for them to matter. We conclude by considering some consequences for how chatbots should be designed and how we ought to think about them.",
      "authors": [
        "P.D. Magnus",
        "Alessandra Buccella",
        "Jason D'Cruz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09910",
        "HTML": "https://arxiv.org/html/2501.09910",
        "PDF": "https://arxiv.org/pdf/2501.09910"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T01:48:15+00:00",
          "link": "https://arxiv.org/abs/2501.09910v1",
          "size": "281kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T20:44:57+00:00",
          "link": "https://arxiv.org/abs/2501.09910v2",
          "size": "185kb",
          "version": "v2"
        }
      ],
      "title": "Chatbot apologies: Beyond bullshit",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper discusses chatbot apologies and moral implications, without any relation to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19268",
      "abstract": "We present HARPT, a large-scale annotated corpus of mobile health app store reviews aimed at advancing research in user privacy and trust. The dataset comprises over 480,000 user reviews labeled into seven categories that capture critical aspects of trust in applications, trust in providers and privacy concerns. Creating HARPT required addressing multiple complexities, such as defining a nuanced label schema, isolating relevant content from large volumes of noisy data, and designing an annotation strategy that balanced scalability with accuracy. This strategy integrated rule-based filtering, iterative manual labeling with review, targeted data augmentation, and weak supervision using transformer-based classifiers to accelerate coverage. In parallel, a carefully curated subset of 7,000 reviews was manually annotated to support model development and evaluation. We benchmark a broad range of classification models, demonstrating that strong performance is achievable and providing a baseline for future research. HARPT is released as a public resource to support work in health informatics, cybersecurity, and natural language processing.",
      "authors": [
        "Timoteo Kelly",
        "Abdulkadir Korkmaz",
        "Samuel Mallet",
        "Connor Souders",
        "Sadra Aliakbarpour",
        "Praveen Rao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19268",
        "HTML": "https://arxiv.org/html/2506.19268",
        "PDF": "https://arxiv.org/pdf/2506.19268"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T02:59:14+00:00",
          "link": "https://arxiv.org/abs/2506.19268v1",
          "size": "213kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T15:23:54+00:00",
          "link": "https://arxiv.org/abs/2506.19268v2",
          "size": "213kb",
          "version": "v2"
        }
      ],
      "title": "HARPT: A Corpus for Analyzing Consumers' Trust and Privacy Concerns in Mobile Health Apps",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper presents a corpus for analyzing trust and privacy in mobile health apps, with no mention or focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.18313",
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, but their effectiveness in financial decision-making remains inadequately evaluated. Current benchmarks primarily assess LLMs' understanding on financial documents rather than the ability to manage assets or dig out trading opportunities in dynamic market conditions. Despite the release of new benchmarks for evaluating diversified tasks on the financial domain, we identified four major problems in these benchmarks, which are data leakage, navel-gazing, over-intervention, and maintenance-hard. To pave the research gap, we introduce DeepFund, a comprehensive arena platform for evaluating LLM-based trading strategies in a live environment. Our approach implements a multi-agent framework where they serve as multiple key roles that realize the real-world investment decision processes. Moreover, we provide a web interface that visualizes LLMs' performance with fund investment metrics across different market conditions, enabling detailed comparative analysis. Through DeepFund, we aim to provide a more realistic and fair assessment on LLM's capabilities in fund investment, offering diversified insights and revealing their potential applications in real-world financial markets. Our code is publicly available at https://github.com/HKUSTDial/DeepFund.",
      "authors": [
        "Changlun Li",
        "Yao Shi",
        "Yuyu Luo",
        "Nan Tang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18313",
        "HTML": "https://arxiv.org/html/2503.18313",
        "PDF": "https://arxiv.org/pdf/2503.18313"
      },
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T03:32:13+00:00",
          "link": "https://arxiv.org/abs/2503.18313v1",
          "size": "21574kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T03:57:07+00:00",
          "link": "https://arxiv.org/abs/2503.18313v2",
          "size": "8541kb",
          "version": "v2"
        }
      ],
      "title": "Will LLMs be Professional at Fund Investment? DeepFund: A Live Arena Perspective",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "This paper evaluates LLMs in financial decision-making, which is unrelated to creativity."
      },
      "tasks": [
        "Decision Making"
      ],
      "repo_urls": [
        "https://github.com/hkustdial/deepfund"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15928",
      "abstract": "This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
      "authors": [
        "Myke C. Cohen",
        "Zhe Su",
        "Hsien-Te Kao",
        "Daniel Nguyen",
        "Spencer Lynch",
        "Maarten Sap",
        "Svitlana Volkova"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15928",
        "HTML": "https://arxiv.org/html/2506.15928",
        "PDF": "https://arxiv.org/pdf/2506.15928"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T00:14:56+00:00",
          "link": "https://arxiv.org/abs/2506.15928v1",
          "size": "633kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T23:42:18+00:00",
          "link": "https://arxiv.org/abs/2506.15928v2",
          "size": "633kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper explores AI in negotiation contexts and its relation to personality traits, without any focus on creativity."
      },
      "tasks": [
        "AI Agent",
        "Causal Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2308.09424",
      "abstract": "Mid-air haptic interfaces employ focused ultrasound waves to generate touchless haptic sensations on the skin. Prior studies have demonstrated the potential positive impact of mid-air haptic feedback on virtual experiences, enhancing aspects such as enjoyment, immersion, and sense of agency. As a highly immersive environment, Virtual Reality (VR) is being explored as a tool for stress management and relaxation in current research. However, the impact of incorporating mid-air haptic stimuli into relaxing experiences in VR has not been studied thus far. In this paper, for the first time, we design a mid-air haptic stimulation that is congruent with a relaxing scene in VR, and conduct a user study investigating the effectiveness of this experience. Our user study encompasses three different conditions: a control group with no relaxation intervention, a VR-only relaxation experience, and a VR+Haptics relaxation experience that includes the mid-air haptic feedback. While we did not find any significant differences between the conditions, a trend suggesting that the VR+Haptics condition might be associated with greater pleasure emerged, requiring further validation with a larger sample size. These initial findings set the foundation for future investigations into leveraging multimodal interventions in VR, utilising mid-air haptics to potentially enhance relaxation experiences.",
      "authors": [
        "Naga Sai Surya Vamsy Malladi",
        "Viktorija Paneva",
        "J\\\"org M\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.09424",
        "HTML": "https://arxiv.org/html/2308.09424",
        "PDF": "https://arxiv.org/pdf/2308.09424"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-18T09:45:42+00:00",
          "link": "https://arxiv.org/abs/2308.09424v1",
          "size": "4998kb",
          "version": "v1"
        }
      ],
      "title": "Feel the Breeze: Promoting Relaxation in Virtual Reality using Mid-Air Haptics",
      "relevance": {
        "keyword": "creativity",
        "level": "none-irrelevant",
        "reason": "The paper focuses on promoting relaxation in virtual reality using mid-air haptics, with no mention of creativity."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Artificial Intelligence (cs.AI)",
    "Emerging Technologies (cs.ET)",
    "Computers and Society (cs.CY)",
    "Multiagent Systems (cs.MA)",
    "Human-Computer Interaction (cs.HC)",
    "Graphics (cs.GR)",
    "Machine Learning (cs.LG)"
  ],
  "prompt": {
    "creativity": "\nYou are an expert in information retrieval. I will provide you with a list of research papers from arXiv, specifically in the *cs.HC* (Human-Computer Interaction) category.\n\nYour task is to analyze each paper and determine its relevance to the topic of **Creativity**.\n\nClassify each paper into one of the following relevance levels:\n\n* `\"strong\"`: The paper is explicitly focused on creativity.\n* `\"weak\"`: The paper mentions or touches on creativity, but it is not the main focus.\n* `\"none\"`: The paper is not related to creativity.\n\nReturn your results in the following JSON format:\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"paper id\",\n      \"level\": \"strong | weak | none\",\n      \"reason\": \"Brief justification based on the paper content\"\n    },\n    {\n      \"id\": \"paper id\",\n      \"level\": \"strong | weak | none\",\n      \"reason\": \"Brief justification based on the paper content\"\n    }\n  ]\n}\n```\n\nBe concise but specific in your reasoning, referencing key terms or sections when applicable.\n"
  },
  "description": "Data source: https://arxiv.org/list/cs.HC/new"
}