[
  {
    "id": "2506.15883",
    "abstract": "Drawing connections between interesting groupings of data and their real-world meaning is an important, yet difficult, part of encountering a new dataset. A lay reader might see an interesting visual pattern in a chart but lack the domain expertise to explain its meaning. Or, a reader might be familiar with a real-world concept but struggle to express it in terms of a dataset's fields. In response, we developed semantic scaffolding, a technique for using domain-specific information from large language models (LLMs) to identify, explain, and formalize semantically meaningful data groupings. We present groupings in two ways: as semantic bins, which segment a field into domain-specific intervals and categories; and data highlights, which annotate subsets of data records with their real-world meaning. We demonstrate and evaluate this technique in Olli, an accessible visualization tool that exemplifies tensions around explicitly defining groupings while respecting the agency of readers to conduct independent data exploration. We conducted a study with 15 blind and low-vision (BLV) users and found that readers used semantic scaffolds to quickly understand the meaning of the data, but were often also critically aware of its influence on their interpretation.",
    "authors": [
      "Zong, Jonathan",
      "Pineros, Isabella Pedraza",
      "Chen, Mengzhu Katie",
      "Hajas, Daniel",
      "Satyanarayan, Arvind"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15883v1",
      "Other Formats": "https://arxiv.org/format/2506.15883",
      "TeX Source": "https://arxiv.org/src/2506.15883",
      "View PDF": "https://arxiv.org/pdf/2506.15883"
    },
    "reason": "The paper focuses on semantic scaffolding and the use of domain-specific groupings for accessible data exploration, particularly for blind and low-vision users. It does not explicitly address creativity in its objectives or methodology.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 21:18:10 UTC (2,730 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Semantic Scaffolding: Augmenting Textual Structures with Domain-Specific Groupings for Accessible Data Exploration"
  },
  {
    "id": "2506.09707",
    "abstract": "Prolonged Exposure (PE) therapy is an effective treatment for post-traumatic stress disorder (PTSD), but evaluating therapist fidelity remains labor-intensive due to the need for manual review of session recordings. We present a method for the automatic temporal localization of key PE fidelity elements -- identifying their start and stop times -- directly from session audio and transcripts. Our approach fine-tunes a large pre-trained audio-language model, Qwen2-Audio, using Low-Rank Adaptation (LoRA) to process focused 30-second windows of audio-transcript input. Fidelity labels for three core protocol phases -- therapist orientation (P1), imaginal exposure (P2), and post-imaginal processing (P3) -- are generated via LLM-based prompting and verified by trained raters. The model is trained to predict normalized boundary offsets using soft supervision guided by task-specific prompts. On a dataset of 313 real PE sessions, our best configuration (LoRA rank 8, 30s windows) achieves a mean absolute error (MAE) of 5.3 seconds across tasks. We further analyze the effects of window size and LoRA rank, highlighting the importance of context granularity and model adaptation. This work introduces a scalable framework for fidelity tracking in PE therapy, with potential to support clinician training, supervision, and quality assurance.",
    "authors": [
      "BN, Suhas",
      "Sherrill, Andrew M.",
      "Alaparthi, Jyoti",
      "Mattioli, Dominik",
      "Arriaga, Rosa I.",
      "Wiese, Chris W.",
      "Abdullah, Saeed"
    ],
    "comments": "5 pages, 2 figures",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.09707v2",
      "Other Formats": "https://arxiv.org/format/2506.09707",
      "TeX Source": "https://arxiv.org/src/2506.09707",
      "View PDF": "https://arxiv.org/pdf/2506.09707"
    },
    "reason": "The paper focuses on temporal localization in therapy sessions for PTSD treatment using audio-language models. It does not address creativity as a topic or related concept.",
    "relevance": "none",
    "subjects": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 11 Jun 2025 13:21:06 UTC (1,662 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 19:02:49 UTC (1,662 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/11",
    "title": "Fine-Tuning Large Audio-Language Models with LoRA for Precise Temporal Localization of Prolonged Exposure Therapy Elements",
    "tasks": [
      "Temporal Localization"
    ]
  },
  {
    "id": "2506.15834",
    "abstract": "Mobile health (mHealth) systems help researchers monitor and care for patients in real-world settings. Studies utilizing mHealth applications use Ecological Momentary Assessment (EMAs), passive sensing, and contextual features to develop emotion recognition models, which rely on EMA responses as ground truth. Due to this, it is crucial to consider EMA compliance when conducting a successful mHealth study. Utilizing machine learning is one approach that can solve this problem by sending EMAs based on the predicted likelihood of a response. However, literature suggests that this approach may lead to prompting participants more frequently during emotions associated with responsiveness, thereby narrowing the range of emotions collected. We propose a multi-objective function that utilizes machine learning to identify optimal times for sending EMAs. The function identifies optimal moments by combining predicted response likelihood with model uncertainty in emotion predictions. Uncertainty would lead the function to prioritize time points when the model is less confident, which often corresponds to underrepresented emotions. We demonstrate that this objective function would result in EMAs being sent when participants are responsive and experiencing less commonly observed emotions. The evaluation is conducted offline using two datasets: (1) 91 spousal caregivers of individuals with Alzheimer's Disease and Related dementias (ADRD), (2) 45 healthy participants. Results show that the multi-objective function tends to be higher when participants respond to EMAs and report less commonly observed emotions. This suggests that using the proposed objective function to guide EMA delivery could improve receptivity rates and capture a broader range of emotions.",
    "authors": [
      "King, Zachary D",
      "Khalid, Maryam",
      "Yu, Han",
      "Shibuya, Kei",
      "Zanna, Khadija",
      "Majd, Marzieh",
      "Brown, Ryan L",
      "Shen, Yufei",
      "Vaessen, Thomas",
      "Kypriotakis, George",
      "Fagundes, Christopher P",
      "Sano, Akane"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15834v1",
      "Other Formats": "https://arxiv.org/format/2506.15834",
      "TeX Source": "https://arxiv.org/src/2506.15834",
      "View PDF": "https://arxiv.org/pdf/2506.15834"
    },
    "reason": "The paper focuses on enhancing mHealth systems' EMA delivery through machine learning to improve emotion recognition and receptivity, without any explicit mention or focus on creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 19:20:47 UTC (649 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Machine Learning-based Context-Aware EMAs: An Offline Feasibility Study"
  },
  {
    "id": "2411.02263",
    "abstract": "Let's transform our robot secretaries into Socratic gadflies.",
    "authors": [
      "Sarkar, Advait"
    ],
    "comments": "Advait Sarkar. 2024. AI Should Challenge, Not Obey. Commun. ACM 67, 10 (October 2024), 18-21. this https URL",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2411.02263v2",
      "Other Formats": "https://arxiv.org/format/2411.02263",
      "TeX Source": "https://arxiv.org/src/2411.02263",
      "View PDF": "https://arxiv.org/pdf/2411.02263"
    },
    "reason": "The paper abstract suggests a focus on transforming AI to challenge rather than just follow orders, which could imply fostering creative thinking in human-AI interaction. However, creativity is not the central theme of the abstract.",
    "relevance": "weak",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 4 Nov 2024 16:54:48 UTC (33 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 15:30:47 UTC (22 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/11/04",
    "title": "AI Should Challenge, Not Obey"
  },
  {
    "id": "2506.15794",
    "abstract": "The proliferation of misinformation poses a significant threat to society, exacerbated by the capabilities of generative AI. This demo paper introduces Veracity, an open-source AI system designed to empower individuals to combat misinformation through transparent and accessible fact-checking. Veracity leverages the synergy between Large Language Models (LLMs) and web retrieval agents to analyze user-submitted claims and provide grounded veracity assessments with intuitive explanations. Key features include multilingual support, numerical scoring of claim veracity, and an interactive interface inspired by familiar messaging applications. This paper will showcase Veracity's ability to not only detect misinformation but also explain its reasoning, fostering media literacy and promoting a more informed society.",
    "authors": [
      "Curtis, Taylor Lynn",
      "Touzel, Maximilian Puelma",
      "Garneau, William",
      "Gruaz, Manon",
      "Pinder, Mike",
      "Wang, Li Wei",
      "Krishna, Sukanya",
      "Cohen, Luda",
      "Godbout, Jean-Fran\u00e7ois",
      "Rabbany, Reihaneh",
      "Pelrine, Kellin"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15794v1",
      "Other Formats": "https://arxiv.org/format/2506.15794",
      "TeX Source": "https://arxiv.org/src/2506.15794",
      "View PDF": "https://arxiv.org/pdf/2506.15794"
    },
    "reason": "The paper is focused on combating misinformation and fact-checking using AI systems, without any mention of creativity.",
    "relevance": "none",
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 18:24:59 UTC (1,583 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Veracity: An Open-Source AI Fact-Checking System"
  },
  {
    "id": "2506.10964",
    "abstract": "Urban digital twins are increasingly perceived as a way to pool the growing digital resources of cities for the purpose of a more sustainable and integrated urban planning. Models and simulations are central to this undertaking: They enable \"what if?\" scenarios, create insights and describe relationships between the vast data that is being collected. However, the process of integrating and subsequently using models in urban digital twins is an inherently complex undertaking. It raises questions about how to represent urban complexity, how to deal with uncertain assumptions and modeling paradigms, and how to capture underlying power relations. Existent approaches in the domain largely focus on monolithic and centralized solutions in the tradition of neoliberal city-making, oftentimes prohibiting pluralistic and open interoperable models. Using a participatory design for participatory systems approach together with the City of Hamburg, Germany, we find that an open Urban Model Platform can function both as a public technological backbone for modeling and simulation in urban digital twins and as a socio-technical framework for a collaborative and pluralistic representation of urban processes. Such a platform builds on open standards, allows for a decentralized integration of models, enables communication between models and supports a multi-model approach to representing urban systems.",
    "authors": [
      "Herzog, Rico H",
      "Degkwitz, Till",
      "Verma, Trivik"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.10964",
      "TeX Source": "https://arxiv.org/src/2506.10964",
      "View PDF": "https://arxiv.org/pdf/2506.10964"
    },
    "reason": "The paper focuses on urban digital twins and modeling in urban planning. It does not mention creativity or involve creative processes as a central theme.",
    "relevance": "none",
    "subjects": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 12 Jun 2025 17:58:10 UTC (752 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 16 Jun 2025 16:41:20 UTC (752 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 10:57:13 UTC (752 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/06/12",
    "title": "The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins"
  },
  {
    "id": "2506.14854",
    "abstract": "Accurate video annotation plays a vital role in modern retail applications, including customer behavior analysis, product interaction detection, and in-store activity recognition. However, conventional annotation methods heavily rely on time-consuming manual labeling by human annotators, introducing non-robust frame selection and increasing operational costs. To address these challenges in the retail domain, we propose a deep learning-based approach that automates key-frame identification in retail videos and provides automatic annotations of products and customers. Our method leverages deep neural networks to learn discriminative features by embedding video frames and incorporating object detection-based techniques tailored for retail environments. Experimental results showcase the superiority of our approach over traditional methods, achieving accuracy comparable to human annotator labeling while enhancing the overall efficiency of retail video annotation. Remarkably, our approach leads to an average of 2 times cost savings in video annotation. By allowing human annotators to verify/adjust less than 5% of detected frames in the video dataset, while automating the annotation process for the remaining frames without reducing annotation quality, retailers can significantly reduce operational costs. The automation of key-frame detection enables substantial time and effort savings in retail video labeling tasks, proving highly valuable for diverse retail applications such as shopper journey analysis, product interaction detection, and in-store security monitoring.",
    "authors": [
      "Mannam, Varun",
      "Shi, Zhenyu"
    ],
    "comments": "Submitting to ICCV 2025 workshop: this https URL",
    "last_revised_date": "2025/06/17",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.14854v1",
      "Other Formats": "https://arxiv.org/format/2506.14854",
      "TeX Source": "https://arxiv.org/src/2506.14854",
      "View PDF": "https://arxiv.org/pdf/2506.14854"
    },
    "reason": "The paper focuses on video annotation efficiency in retail environments using deep learning techniques. It does not address creativity explicitly or implicitly.",
    "relevance": "none",
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 17 Jun 2025 06:42:58 UTC (1,859 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/17",
    "title": "Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis",
    "tasks": [
      "Activity Recognition"
    ]
  },
  {
    "id": "2506.15928",
    "abstract": "This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
    "authors": [
      "Cohen, Myke C.",
      "Su, Zhe",
      "Kao, Hsien-Te",
      "Nguyen, Daniel",
      "Lynch, Spencer",
      "Sap, Maarten",
      "Volkova, Svitlana"
    ],
    "comments": "Under review for KDD 2025 Workshop on Evaluation and Trustworthiness of Agentic and Generative AI Models",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15928v1",
      "Other Formats": "https://arxiv.org/format/2506.15928",
      "TeX Source": "https://arxiv.org/src/2506.15928",
      "View PDF": "https://arxiv.org/pdf/2506.15928"
    },
    "reason": "The paper is focused on evaluating AI systems in negotiation contexts with regard to personality traits and operational reliability, without specific emphasis or connection to creativity.",
    "relevance": "none",
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 00:14:56 UTC (633 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues"
  },
  {
    "id": "2506.16312",
    "abstract": "This study investigated the impact of a theory-driven, explainable Learning Analytics Dashboard (LAD) on university students' human-AI collaborative academic abstract writing task. Grounded in Self-Regulated Learning (SRL) theory and incorporating Explainable AI (XAI) principles, our LAD featured a three-layered design (Visual, Explainable, Interactive). In an experimental study, participants were randomly assigned to either an experimental group (using the full explainable LAD) or a control group (using a visual-only LAD) to collaboratively write an academic abstract with a Generative AI. While quantitative analysis revealed no significant difference in the quality of co-authored abstracts between the two groups, a significant and noteworthy difference emerged in conceptual understanding: students in the explainable LAD group demonstrated a superior grasp of abstract writing principles, as evidenced by their higher scores on a knowledge test (p= .026). These findings highlight that while basic AI-generated feedback may suffice for immediate task completion, the provision of explainable feedback is crucial for fostering deeper learning, enhancing conceptual understanding, and developing transferable skills fundamental to self-regulated learning in academic writing contexts.",
    "authors": [
      "Chen, Angxuan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16312",
      "View PDF": "https://arxiv.org/pdf/2506.16312"
    },
    "reason": "The study involves human-AI collaboration in academic writing, which can be linked to creativity in terms of producing creative written content. However, the main focus is on learning analytics and explainable AI rather than creativity itself.",
    "relevance": "weak",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 13:38:17 UTC (533 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "When learning analytics dashboard is explainable: An exploratory study on the effect of GenAI-supported learning analytics dashboard"
  },
  {
    "id": "2404.15564",
    "abstract": "This paper proposes a new gradient-based XAI method called Guided AbsoluteGrad for saliency map explanations. We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction. We also introduce a novel evaluation metric named ReCover And Predict (RCAP), which considers the Localization and Visual Noise Level objectives of the explanations. We propose two propositions for these two objectives and prove the necessity of evaluating them. We evaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the RCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset with ResNet50 model; (2) International Skin Imaging Collaboration (ISIC) dataset with EfficientNet model; (3) the Places365 dataset with DenseNet161 model. Our method surpasses other gradient-based approaches, showcasing the quality of enhanced saliency map explanations through gradient magnitude.",
    "authors": [
      "Huang, Jun",
      "Liu, Yan"
    ],
    "comments": "CAI2024 Camera-ready Submission and Correction",
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2404.15564v2",
      "Other Formats": "https://arxiv.org/format/2404.15564",
      "TeX Source": "https://arxiv.org/src/2404.15564",
      "View PDF": "https://arxiv.org/pdf/2404.15564"
    },
    "reason": "The paper focuses on a new gradient-based explainable AI method for creating saliency maps and evaluates them on several datasets. It does not address creativity as a central theme or mention it in its proposed method or evaluations.",
    "relevance": "none",
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 23 Apr 2024 23:26:02 UTC (12,966 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 20:44:52 UTC (12,971 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/04/23",
    "title": "Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation's Localization and Saliency",
    "repo_urls": [
      "https://github.com/youyinnn/guided-absolutegrad"
    ],
    "tasks": []
  },
  {
    "id": "2506.17011",
    "abstract": "This study compares the impact of \"juiciness\" on user engagement and short-term information retention in interactive infographics. Juicy designs generally showed a slight advantage in overall user engagement scores compared to dry designs. Specifically, the juicy version of the Burcalories infographic had the highest engagement score. However, the differences in engagement were often small. Regarding information retention, the results were mixed. The juicy versions of The Daily Routines of Famous Creative People and The Main Chakras infographics showed marginally better average recall and more participants with higher recall. Conversely, the dry version of Burcalories led to more correct answers in multiple-choice questions. The study suggests that while juicy design elements can enhance user engagement and, in some cases, short-term information retention, their effectiveness depends on careful implementation. Excessive juiciness could be overwhelming or distracting, while well-implemented juicy elements contributed to a more entertaining experience. The findings emphasize the importance of balancing engaging feedback with clarity and usability.",
    "authors": [
      "Campos, Bruno"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.17011",
      "View PDF": "https://arxiv.org/pdf/2506.17011"
    },
    "reason": "The paper mentions 'The Daily Routines of Famous Creative People,' which implies a focus on creative individuals, and it examines information retention linked to designs that could influence creative thinking. However, the main focus is on user engagement and information retention in interactive infographics, not on creativity itself.",
    "relevance": "weak",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 14:10:11 UTC (1,150 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Juicy or Dry? A Comparative Study of User Engagement and Information Retention in Interactive Infographics"
  },
  {
    "id": "2506.15873",
    "abstract": "Generative AI promises to allow people to create high-quality personalized media. Although powerful, we identify three fundamental design problems with existing tooling through a literature review. We introduce a multimodal generative AI tool, DeckFlow, to address these problems. First, DeckFlow supports task decomposition by allowing users to maintain multiple interconnected subtasks on an infinite canvas populated by cards connected through visual dataflow affordances. Second, DeckFlow supports a specification decomposition workflow where an initial goal is iteratively decomposed into smaller parts and combined using feature labels and clusters. Finally, DeckFlow supports generative space exploration by generating multiple prompt and output variations, presented in a grid, that can feed back recursively into the next design iteration. We evaluate DeckFlow for text-to-image generation against a state-of-practice conversational AI baseline for image generation tasks. We then add audio generation and investigate user behaviors in a more open-ended creative setting with text, image, and audio outputs.",
    "authors": [
      "Croisdale, Gregory",
      "Huang, Emily",
      "Chung, John Joon Young",
      "Guo, Anhong",
      "Wang, Xu",
      "Henley, Austin Z.",
      "Omar, Cyrus"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15873v1",
      "Other Formats": "https://arxiv.org/format/2506.15873",
      "TeX Source": "https://arxiv.org/src/2506.15873",
      "View PDF": "https://arxiv.org/pdf/2506.15873"
    },
    "reason": "The paper focuses on a multimodal generative AI tool, DeckFlow, and explores generative space exploration in a creative setting. It addresses issues related to creating personalized media and supports open-ended creative processes, indicating a strong relevance to the topic of creativity.",
    "relevance": "strong",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 20:40:31 UTC (6,058 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "DeckFlow: Iterative Specification on a Multimodal Generative Canvas"
  },
  {
    "id": "2506.16697",
    "abstract": "Large language models (LLMs) are rapidly being adopted across psychology, serving as research tools, experimental subjects, human simulators, and computational models of cognition. However, the application of human measurement tools to these systems can produce contradictory results, raising concerns that many findings are measurement phantoms--statistical artifacts rather than genuine psychological phenomena. In this Perspective, we argue that building a robust science of AI psychology requires integrating two of our field's foundational pillars: the principles of reliable measurement and the standards for sound causal inference. We present a dual-validity framework to guide this integration, which clarifies how the evidence needed to support a claim scales with its scientific ambition. Using an LLM to classify text may require only basic accuracy checks, whereas claiming it can simulate anxiety demands a far more rigorous validation process. Current practice systematically fails to meet these requirements, often treating statistical pattern matching as evidence of psychological phenomena. The same model output--endorsing \"I am anxious\"--requires different validation strategies depending on whether researchers claim to measure, characterize, simulate, or model psychological constructs. Moving forward requires developing computational analogues of psychological constructs and establishing clear, scalable standards of evidence rather than the uncritical application of human measurement tools.",
    "authors": [
      "Lin, Zhicheng"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16697",
      "View PDF": "https://arxiv.org/pdf/2506.16697"
    },
    "reason": "The paper focuses on the application of LLMs in psychology and the need for reliable measurement and validation processes. It does not mention creativity or relate to how these models might influence or interact with creative processes.",
    "relevance": "none",
    "subjects": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 02:38:42 UTC (439 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology"
  },
  {
    "id": "2506.16702",
    "abstract": "Large language models (LLMs) offer emerging opportunities for psychological and behavioral research, but methodological guidance is lacking. This article provides a framework for using LLMs as psychological simulators across two primary applications: simulating roles and personas to explore diverse contexts, and serving as computational models to investigate cognitive processes. For simulation, we present methods for developing psychologically grounded personas that move beyond demographic categories, with strategies for validation against human data and use cases ranging from studying inaccessible populations to prototyping research instruments. For cognitive modeling, we synthesize emerging approaches for probing internal representations, methodological advances in causal interventions, and strategies for relating model behavior to human cognition. We address overarching challenges including prompt sensitivity, temporal limitations from training data cutoffs, and ethical considerations that extend beyond traditional human subjects review. Throughout, we emphasize the need for transparency about model capabilities and constraints. Together, this framework integrates emerging empirical evidence about LLM performance--including systematic biases, cultural limitations, and prompt brittleness--to help researchers wrangle these challenges and leverage the unique capabilities of LLMs in psychological research.",
    "authors": [
      "Lin, Zhicheng"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16702",
      "View PDF": "https://arxiv.org/pdf/2506.16702"
    },
    "reason": "While the paper primarily focuses on using large language models for psychological simulations, it touches upon diverse contexts and personas that could implicitly relate to creativity in exploring human cognition and behavior. However, creativity is not the main focus.",
    "relevance": "weak",
    "subjects": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 02:45:23 UTC (410 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Large Language Models as Psychological Simulators: A Methodological Guide"
  },
  {
    "id": "2506.16473",
    "abstract": "As conversational agents increasingly engage in emotionally supportive dialogue, it is important to understand how closely their interactions resemble those in traditional therapy settings. This study investigates whether the concerns shared with a robot align with those shared in human-to-human (H2H) therapy sessions, and whether robot responses semantically mirror those of human therapists. We analyzed two datasets: one of interactions between users and professional therapists (Hugging Face's NLP Mental Health Conversations), and another involving supportive conversations with a social robot (QTrobot from LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence embeddings and K-means clustering, we assessed cross-agent thematic alignment by applying a distance-based cluster-fitting method that evaluates whether responses from one agent type map to clusters derived from the other, and validated it using Euclidean distances. Results showed that 90.88% of robot conversation disclosures could be mapped to clusters from the human therapy dataset, suggesting shared topical structure. For matched clusters, we compared the subjects as well as therapist and robot responses using Transformer, Word2Vec, and BERT embeddings, revealing strong semantic overlap in subjects' disclosures in both datasets, as well as in the responses given to similar human disclosure themes across agent types (robot vs. human therapist). These findings highlight both the parallels and boundaries of robot-led support conversations and their potential for augmenting mental health interventions.",
    "authors": [
      "Chiang, Sophie",
      "Laban, Guy",
      "Gunes, Hatice"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16473v1",
      "Other Formats": "https://arxiv.org/format/2506.16473",
      "TeX Source": "https://arxiv.org/src/2506.16473",
      "View PDF": "https://arxiv.org/pdf/2506.16473"
    },
    "reason": "The paper focuses on language alignment and emotional support in human-robot interactions, with an emphasis on therapy-like conversations. It does not address creativity or creative processes.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:20:30 UTC (6,452 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support"
  },
  {
    "id": "2502.15242",
    "abstract": "Current image generation paradigms prioritize actualizing user intention - \"see what you intend\" - but often neglect the sociopolitical dimensions of this process. However, it is increasingly evident that image generation is political, contributing to broader social struggles over visual meaning. This sociopolitical aspect was highlighted by the March 2024 Gemini controversy, where Gemini faced criticism for inappropriately injecting demographic diversity into user prompts. Although the developers sought to redress image generation's sociopolitical dimension by introducing diversity \"corrections,\" their opaque imposition of a standard for \"diversity\" ultimately proved counterproductive. In this paper, we present an alternative approach: an image generation interface designed to embrace open negotiation along the sociopolitical dimensions of image creation. Grounded in the principles of agonistic pluralism (from the Greek agon, meaning struggle), our interface actively engages users with competing visual interpretations of their prompts. Through a lab study with 29 participants, we evaluate our agonistic interface on its ability to facilitate reflection - engagement with other perspectives and challenging dominant assumptions - a core principle that underpins agonistic contestation. We compare it to three existing paradigms: a standard interface, a Gemini-style interface that produces \"diverse\" images, and an intention-centric interface suggesting prompt refinements. Our findings demonstrate that the agonistic interface enhances reflection across multiple measures, but also that reflection depends on users perceiving the interface as both appropriate and empowering; introducing diversity without grounding it in relevant political contexts was perceived as inauthentic. Our results suggest that diversity and user intention should not be treated as opposing values to be balanced.",
    "authors": [
      "Shaw, Andrew",
      "Ye, Andre",
      "Krishna, Ranjay",
      "Zhang, Amy X."
    ],
    "comments": "Accepted to ACM Fairness, Accountability, Transparency 2025 -- Athens, Greece",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.15242v3",
      "Other Formats": "https://arxiv.org/format/2502.15242",
      "TeX Source": "https://arxiv.org/src/2502.15242",
      "View PDF": "https://arxiv.org/pdf/2502.15242"
    },
    "reason": "The paper focuses on agonistic image generation and the sociopolitical dimensions of image creation rather than creativity itself. Creativity is not the main focus, but the concept of 'open negotiation' and engagement with different perspectives could indirectly relate to creative processes.",
    "relevance": "weak",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 21 Feb 2025 06:30:42 UTC (27,634 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sat, 1 Mar 2025 22:19:48 UTC (27,634 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 00:02:22 UTC (10,035 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/02/21",
    "title": "Agonistic Image Generation: Unsettling the Hegemony of Intention"
  },
  {
    "id": "2506.16199",
    "abstract": "Explainable Artificial Intelligence (XAI) plays a critical role in fostering user trust and understanding in AI-driven systems. However, the design of effective XAI interfaces presents significant challenges, particularly for UX professionals who may lack technical expertise in AI or machine learning. Existing explanation methods, such as SHAP, LIME, and counterfactual explanations, often rely on complex technical language and assumptions that are difficult for non-expert users to interpret. To address these gaps, we propose a UX Research (UXR) Playbook for XAI - a practical framework aimed at supporting UX professionals in designing accessible, transparent, and trustworthy AI experiences. Our playbook offers actionable guidance to help bridge the gap between technical explainability methods and user centred design, empowering designers to create AI interactions that foster better understanding, trust, and responsible AI adoption.",
    "authors": [
      "Naiseh, Mohammad",
      "Dogan, Huseyin",
      "Giff, Stephen",
      "Jiang, Nan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16199",
      "View PDF": "https://arxiv.org/pdf/2506.16199"
    },
    "reason": "The paper focuses on developing a User Experience Research framework for Explainable Artificial Intelligence, aiming to improve user trust and understanding in AI. It does not address creativity either as a main focus or a secondary topic.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 10:26:58 UTC (700 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Development of a persuasive User Experience Research (UXR) Point of View for Explainable Artificial Intelligence (XAI)"
  },
  {
    "id": "2506.16677",
    "abstract": "Trust prediction is a key issue in human-robot collaboration, especially in construction scenarios where maintaining appropriate trust calibration is critical for safety and efficiency. This paper introduces the Performance-guided Physiological signal-based Trust Prediction (PPTP), a novel framework designed to improve trust assessment. We designed a human-robot construction scenario with three difficulty levels to induce different trust states. Our approach integrates synchronized multimodal physiological signals (ECG, GSR, and EMG) with collaboration performance evaluation to predict human trust levels. Individual physiological signals are processed using collaboration performance information as guiding cues, leveraging the standardized nature of collaboration performance to compensate for individual variations in physiological responses. Extensive experiments demonstrate the efficacy of our cross-modality fusion method in significantly improving trust classification performance. Our model achieves over 81% accuracy in three-level trust classification, outperforming the best baseline method by 6.7%, and notably reaches 74.3% accuracy in high-resolution seven-level classification, which is a first in trust prediction research. Ablation experiments further validate the superiority of physiological signal processing guided by collaboration performance assessment.",
    "authors": [
      "Guo, Hao",
      "Fan, Wei",
      "Liu, Shaohui",
      "Jiang, Feng",
      "Yi, Chunzhi"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16677v1",
      "Other Formats": "https://arxiv.org/format/2506.16677",
      "TeX Source": "https://arxiv.org/src/2506.16677",
      "View PDF": "https://arxiv.org/pdf/2506.16677"
    },
    "reason": "The paper is focused on trust prediction in human-robot collaboration using physiological signals and does not discuss creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 01:41:09 UTC (5,212 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "PPTP: Performance-Guided Physiological Signal-Based Trust Prediction in Human-Robot Collaboration"
  },
  {
    "id": "2506.16168",
    "abstract": "Imagine unlocking the power of the mind to communicate, create, and even interact with the world around us. Recent breakthroughs in Artificial Intelligence (AI), especially in how machines \"see\" and \"understand\" language, are now fueling exciting progress in decoding brain signals from scalp electroencephalography (EEG). Prima facie, this opens the door to revolutionary brain-computer interfaces (BCIs) designed for real life, moving beyond traditional uses to envision Brain-to-Speech, Brain-to-Image, and even a Brain-to-Internet of Things (BCIoT). However, the journey is not as straightforward as it was for Computer Vision (CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based BCIs, particularly in building powerful foundational models, presents unique and intricate hurdles that could affect their reliability. Here, we unfold a guided exploration of this dynamic and rapidly evolving research area. Rather than barely outlining a map of current endeavors and results, the goal is to provide a principled navigation of this hot and cutting-edge research landscape. We consider the basic paradigms that emerge from a causal perspective and the attendant challenges presented to AI-based models. Looking ahead, we then discuss promising research avenues that could overcome today's technological, methodological, and ethical limitations. Our aim is to lay out a clear roadmap for creating truly practical and effective EEG-based BCI solutions that can thrive in everyday environments.",
    "authors": [
      "Barbera, Thomas",
      "Burger, Jacopo",
      "D'Amelio, Alessandro",
      "Zini, Simone",
      "Bianco, Simone",
      "Lanzarotti, Raffaella",
      "Napoletano, Paolo",
      "Boccignone, Giuseppe",
      "Contreras-Vidal, Jose Luis"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16168v1",
      "Other Formats": "https://arxiv.org/format/2506.16168",
      "TeX Source": "https://arxiv.org/src/2506.16168",
      "View PDF": "https://arxiv.org/pdf/2506.16168"
    },
    "reason": "The paper discusses brain-computer interfaces which can be used for creative activities like Brain-to-Image, but creativity is not the central focus of the paper.",
    "relevance": "weak",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 09:43:17 UTC (442 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "On using AI for EEG-based BCI applications: problems, current challenges and future trends"
  },
  {
    "id": "2506.16310",
    "abstract": "State-of-the-art text-to-speech (TTS) systems realize high naturalness in monolingual environments, synthesizing speech with correct multilingual accents (especially for Indic languages) and context-relevant emotions still poses difficulty owing to cultural nuance discrepancies in current frameworks. This paper introduces a new TTS architecture integrating accent along with preserving transliteration with multi-scale emotion modelling, in particularly tuned for Hindi and Indian English accent. Our approach extends the Parler-TTS model by integrating A language-specific phoneme alignment hybrid encoder-decoder architecture, and culture-sensitive emotion embedding layers trained on native speaker corpora, as well as incorporating a dynamic accent code switching with residual vector quantization. Quantitative tests demonstrate 23.7% improvement in accent accuracy (Word Error Rate reduction from 15.4% to 11.8%) and 85.3% emotion recognition accuracy from native listeners, surpassing METTS and VECL-TTS baselines. The novelty of the system is that it can mix code in real time - generating statements such as \"Namaste, let's talk about <Hindi phrase>\" with uninterrupted accent shifts while preserving emotional consistency. Subjective evaluation with 200 users reported a mean opinion score (MOS) of 4.2/5 for cultural correctness, much better than existing multilingual systems (p<0.01). This research makes cross-lingual synthesis more feasible by showcasing scalable accent-emotion disentanglement, with direct application in South Asian EdTech and accessibility software.",
    "authors": [
      "Pawar, Pranav",
      "Dwivedi, Akshansh",
      "Boricha, Jenish",
      "Gohil, Himanshu",
      "Dubey, Aditya"
    ],
    "comments": "12 pages, 8 figures",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16310v1",
      "Other Formats": "https://arxiv.org/format/2506.16310",
      "TeX Source": "https://arxiv.org/src/2506.16310",
      "View PDF": "https://arxiv.org/pdf/2506.16310"
    },
    "reason": "The paper focuses on optimizing multilingual text-to-speech systems with a focus on accents and emotions, particularly in South Asian languages. It does not address creativity.",
    "relevance": "none",
    "subjects": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 13:35:05 UTC (3,204 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Optimizing Multilingual Text-To-Speech with Accents & Emotions"
  },
  {
    "id": "2506.14777",
    "abstract": "This article introduces WebXAII, an open-source web framework designed to facilitate research on human interaction with eXplainable Artificial Intelligence (XAI) systems. The field of XAI is rapidly expanding, driven by the growing societal implications of the widespread adoption of AI (and in particular machine learning) across diverse applications. Researchers who study the interaction between humans and XAI techniques typically develop ad hoc interfaces in order to conduct their studies. These interfaces are usually not shared alongside the results of the studies, which limits their reusability and the reproducibility of experiments. In response, we design and implement WebXAII, a web-based platform that can embody full experimental protocols, meaning that it can present all aspects of the experiment to human participants and record their responses. The experimental protocols are translated into a composite architecture of generic views and modules, which offers a lot of flexibility. The architecture is defined in a structured configuration file, so that protocols can be implemented with minimal programming skills. We demonstrate that WebXAII can effectively embody relevant protocols, by reproducing the protocol of a state-of-the-art study of the literature. The framework is available at https://github.com/PAJEAN/WebXAII.",
    "authors": [
      "Leguy, Jules",
      "Jean, Pierre-Antoine",
      "Figueroa, Felipe Torres",
      "Harispe, S\u00e9bastien"
    ],
    "last_revised_date": "2025/05/16",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.14777v1",
      "Other Formats": "https://arxiv.org/format/2506.14777",
      "TeX Source": "https://arxiv.org/src/2506.14777",
      "View PDF": "https://arxiv.org/pdf/2506.14777"
    },
    "reason": "The paper focuses on a web framework for studying human interaction with Explainable AI systems, with no mention or implication of creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 16 May 2025 10:12:53 UTC (629 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/16",
    "title": "WebXAII: an open-source web framework to study human-XAI interaction",
    "repo_urls": [
      "https://github.com/pajean/webxaii"
    ],
    "tasks": [
      "Explainable artificial intelligence",
      "Explainable Artificial Intelligence (XAI)"
    ]
  },
  {
    "id": "2502.05731",
    "abstract": "Environmental experts have developed the DPSIR (Driver, Pressure, State, Impact, Response) framework to systematically study and communicate key relationships between society and the environment. Using this framework requires experts to construct a DPSIR taxonomy from a corpus, annotate the documents, and identify DPSIR variables and relationships, which is laborious and inflexible. Automating it with conventional text mining faces technical challenges, primarily because the taxonomy often begins with abstract definitions, which experts progressively refine and contextualize as they annotate the corpus. In response, we develop GreenMine, a system that supports interactive text mining with prompt engineering. The system implements a prompting pipeline consisting of three simple and evaluable subtasks. In each subtask, the DPSIR taxonomy can be defined in natural language and iteratively refined as experts analyze the corpus. To support users evaluate the taxonomy, we introduce an uncertainty score based on response consistency. Then, we design a radial uncertainty chart that visualizes uncertainties and corpus topics, which supports interleaved evaluation and exploration. Using the system, experts can progressively construct the DPSIR taxonomy and annotate the corpus with LLMs. Using real-world interview transcripts, we present a case study to demonstrate the capability of the system in supporting interactive mining of DPSIR relationships, and an expert review in the form of collaborative discussion to understand the potential and limitations of the system. We discuss the lessons learned from developing the system and future opportunities for supporting interactive text mining in knowledge-intensive tasks for other application scenarios.",
    "authors": [
      "Lee, Sam Yu-Te",
      "Hung, Cheng-Wei",
      "Yuan, Mei-Hua",
      "Ma, Kwan-Liu"
    ],
    "comments": "IEEE PacificVis 2025 Information systems, Information systems applications, Data Mining; Human-centered computing, Visualization, Visualization systems and tools",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.05731v2",
      "Other Formats": "https://arxiv.org/format/2502.05731",
      "TeX Source": "https://arxiv.org/src/2502.05731",
      "View PDF": "https://arxiv.org/pdf/2502.05731"
    },
    "reason": "The paper focuses on visual text mining and taxonomy construction within the DPSIR framework for environmental studies. It does not explicitly address or focus on creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 9 Feb 2025 00:25:41 UTC (4,594 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 05:05:12 UTC (3,981 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/09",
    "title": "Visual Text Mining with Progressive Taxonomy Construction for Environmental Studies",
    "repo_urls": [
      "https://github.com/SamLee-dedeboy/GreenMine"
    ]
  },
  {
    "id": "2410.20564",
    "abstract": "Conversational systems rely heavily on speech recognition to interpret and respond to user commands and queries. Despite progress on speech recognition accuracy, errors may still sometimes occur and can significantly affect the end-user utility of such systems. While visual feedback can help detect errors, it may not always be practical, especially for people who are blind or low-vision. In this study, we investigate ways to improve error detection by manipulating the audio output of the transcribed text based on the recognizer's confidence level in its result. Our findings show that selectively slowing down the audio when the recognizer exhibited uncertainty led to a 12% relative increase in participants' ability to detect errors compared to uniformly slowing the audio. It also reduced the time it took participants to listen to the recognition result and decide if there was an error by 11%.",
    "authors": [
      "Nowrin, Sadia",
      "Vertanen, Keith"
    ],
    "comments": "To appear in PErvasive Technologies Related to Assistive Environments (PETRA '25)",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2410.20564v3",
      "Other Formats": "https://arxiv.org/format/2410.20564",
      "TeX Source": "https://arxiv.org/src/2410.20564",
      "View PDF": "https://arxiv.org/pdf/2410.20564"
    },
    "reason": "The paper focuses on improving error detection in speech recognition systems using confidence scores and does not address creativity or its enhancement.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 27 Oct 2024 19:33:01 UTC (350 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sun, 19 Jan 2025 02:21:53 UTC (359 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 13:16:41 UTC (355 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/10/27",
    "title": "Using Confidence Scores to Improve Eyes-free Detection of Speech Recognition Errors"
  },
  {
    "id": "2506.16571",
    "abstract": "Prior natural language datasets for data visualization have focused on tasks such as visualization literacy assessment, insight generation, and visualization generation from natural language instructions. These studies often rely on controlled setups with purpose-built visualizations and artificially constructed questions. As a result, they tend to prioritize the interpretation of visualizations, focusing on decoding visualizations rather than understanding their encoding. In this paper, we present a new dataset and methodology for probing visualization design rationale through natural language. We leverage a unique source of real-world visualizations and natural language narratives: literate visualization notebooks created by students as part of a data visualization course. These notebooks combine visual artifacts with design exposition, in which students make explicit the rationale behind their design decisions. We also use large language models (LLMs) to generate and categorize question-answer-rationale triples from the narratives and articulations in the notebooks. We then carefully validate the triples and curate a dataset that captures and distills the visualization design choices and corresponding rationales of the students.",
    "authors": [
      "Hutchinson, Maeve",
      "Jianu, Radu",
      "Slingsby, Aidan",
      "Wood, Jo",
      "Madhyastha, Pranava"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16571v1",
      "Other Formats": "https://arxiv.org/format/2506.16571",
      "TeX Source": "https://arxiv.org/src/2506.16571",
      "View PDF": "https://arxiv.org/pdf/2506.16571"
    },
    "reason": "The paper focuses on visualization design rationale and does not mention or imply a connection to the topic of creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 19:52:53 UTC (22,329 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Capturing Visualization Design Rationale"
  },
  {
    "id": "2506.16468",
    "abstract": "Restoring movement of a paralyzed foot is a key challenge in helping individuals with neurological conditions such as spinal cord injury (SCI) to improve their quality of life. Neuroprostheses based on functional electrical stimulation (FES) can restore the physiological range of motion by stimulating the affected muscles using surface electrodes. We have previously shown that, despite chronic motor-complete SCI, it is possible to capture paralyzed hand movements in individuals with tetraplegia using spared and modulated motor unit (MU) activity decoded with non-invasive electromyography (EMG) sensors. This study investigated whether a wearable high-density surface EMG system could capture and control paralyzed foot kinematics in closed-loop control with an FES system. We found that all our participants with SCI (2 with chronic SCI and 3 with acute SCI) retained distinct spared EMG activity for at least three ankle movements, which allowed them to reliably control a digital cursor using their spared tibialis anterior and triceps surae MU activity. Movement separability was further reconfirmed by extracting task-modulated MU activity during foot flexion/extension (3-7 modulated MUs/participant). Three participants were further able to modulate and maintain their foot flexion/extension EMG levels with an accuracy of >70%. Lastly, we show that real-time control of a FES system using EMG from the affected limb can restore foot movements in a highly intuitive way, significantly improving the lost or pathological foot range of motion. Our system provides an intuitive approach for closed-loop control of FES that has the potential to assist individuals with SCI in regaining lost motor functions.",
    "authors": [
      "Cnejevici, Vlad",
      "Ponfick, Matthias",
      "S\u00eempetru, Raul C.",
      "Del Vecchio, Alessandro"
    ],
    "comments": "26 pages, 7 figures",
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16468",
      "View PDF": "https://arxiv.org/pdf/2506.16468"
    },
    "reason": "The paper focuses on restoring movement through closed-loop control of electrical stimulation in individuals with spinal cord injury. It does not discuss creativity or related processes.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:08:16 UTC (2,441 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Closed-Loop Control of Electrical Stimulation through Spared Motor Unit Ensembles Restores Foot Movements after Spinal Cord Injury"
  },
  {
    "id": "2506.16010",
    "abstract": "Panel discussion allows the audience to learn different perspectives through interactive discussions among experts moderated by a host and a Q&A session with the audience. Despite its benefits, panel discussion in the real world is inaccessible to many who do not have the privilege to participate due to geographical, financial, and time constraints. We present SimuPanel, which simulates panel discussions among academic experts through LLM-based multi-agent interaction. It enables users to define topics of interest for the panel, observe the expert discussion, engage in Q&A, and take notes. SimuPanel employs a host-expert architecture where each panel member is simulated by an agent with specialized expertise, and the panel is visualized in an immersive 3D environment to enhance engagement. Traditional dialogue generation struggles to capture the depth and interactivity of real-world panel discussions. To address this limitation, we propose a novel multi-agent interaction framework that simulates authentic panel dynamics by modeling reasoning strategies and personas of experts grounded in multimedia sources. This framework enables agents to dynamically recall and contribute to the discussion based on past experiences from diverse perspectives. Our technical evaluation and the user study with university students show that SimuPanel was able to simulate more in-depth discussions and engage participants to interact with and reflect on the discussions. As a first step in this direction, we offer design implications for future avenues to improve and harness the power of panel discussion for multimedia learning.",
    "authors": [
      "He, Xiangyang",
      "Li, Jiale",
      "Chen, Jiahao",
      "Yang, Yang",
      "Fan, Mingming"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16010v1",
      "Other Formats": "https://arxiv.org/format/2506.16010",
      "TeX Source": "https://arxiv.org/src/2506.16010",
      "View PDF": "https://arxiv.org/pdf/2506.16010"
    },
    "reason": "The paper focuses on simulating panel discussions using multi-agent systems for enhanced learning and engagement, but it does not explicitly mention or center on creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 04:06:43 UTC (3,037 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "SimuPanel: A Novel Immersive Multi-Agent System to Simulate Interactive Expert Panel Discussion"
  },
  {
    "id": "2412.16402",
    "abstract": "Data visualization is a core part of statistical practice and is ubiquitous in many fields. Although there are numerous books on data visualization, instructors in statistics and data science may be unsure how to teach data visualization, because it is such a broad discipline. To give guidance on teaching data visualization from a statistical perspective, we make two contributions. First, we conduct a survey of data visualization courses at top colleges and universities in the United States, in order to understand the landscape of data visualization courses. We find that most courses are not taught by statistics and data science departments and do not focus on statistical topics, especially those related to inference. Instead, most courses focus on visual storytelling, aesthetic design, dashboard design, and other topics specialized for other disciplines. Second, we outline three teaching principles for incorporating statistical inference in data visualization courses, and provide several examples that demonstrate how to follow these principles. The dataset from our survey allows others to explore the diversity of data visualization courses, and our teaching principles give guidance for encouraging statistical thinking when teaching data visualization.",
    "authors": [
      "Branson, Zach",
      "Parra, Monica Paz",
      "Yurko, Ronald"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2412.16402v2",
      "Other Formats": "https://arxiv.org/format/2412.16402",
      "TeX Source": "https://arxiv.org/src/2412.16402",
      "View PDF": "https://arxiv.org/pdf/2412.16402"
    },
    "reason": "The paper is focused on the teaching of data visualization with a statistical perspective and outlines teaching principles. It does not discuss creativity or its enhancement, apart from potentially implicit mentions related to visual storytelling.",
    "relevance": "none",
    "subjects": [
      "Other Statistics (stat.OT)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Dec 2024 23:32:53 UTC (6,833 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 18:30:21 UTC (6,443 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/12/20",
    "title": "The Landscape of College-level Data Visualization Courses, and the Benefits of Incorporating Statistical Thinking",
    "repo_urls": [
      "https://github.com/ryurko/teaching-data-viz"
    ]
  },
  {
    "id": "2506.16542",
    "abstract": "Technical interviews are a critical yet stressful step in the hiring process for computer science graduates, often hindered by limited access to practice opportunities. This formative qualitative study (n=20) explores whether a multimodal AI system can realistically simulate technical interviews and support confidence-building among candidates. Participants engaged with an AI-driven mock interview tool featuring whiteboarding tasks and real-time feedback. Many described the experience as realistic and helpful, noting increased confidence and improved articulation of problem-solving decisions. However, challenges with conversational flow and timing were noted. These findings demonstrate the potential of AI-driven technical interviews as scalable and realistic preparation tools, suggesting that future research could explore variations in interviewer behavior and their potential effects on candidate preparation.",
    "authors": [
      "Gomez, Nathalia",
      "Batham, S. Sue",
      "Volonte, Mathias",
      "Do, Tiffany D."
    ],
    "comments": "6 pages, To Appear in Companion Publication of the 2025 Conference on Computer-Supported Cooperative Work and Social Computing (CSCW Companion '25)",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16542v1",
      "Other Formats": "https://arxiv.org/format/2506.16542",
      "TeX Source": "https://arxiv.org/src/2506.16542",
      "View PDF": "https://arxiv.org/pdf/2506.16542"
    },
    "reason": "The paper focuses on AI-driven mock technical interviews for building student readiness and confidence in technical interviews. It does not address or explore creativity as a main theme.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 18:58:05 UTC (91 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Virtual Interviewers, Real Results: Exploring AI-Driven Mock Technical Interviews on Student Readiness and Confidence"
  },
  {
    "id": "2506.16345",
    "abstract": "Heuristic evaluation is a widely used method in Human-Computer Interaction (HCI) to inspect interfaces and identify issues based on heuristics. Recently, Large Language Models (LLMs), such as GPT-4o, have been applied in HCI to assist in persona creation, the ideation process, and the analysis of semi-structured interviews. However, considering the need to understand heuristics and the high degree of abstraction required to evaluate them, LLMs may have difficulty conducting heuristic evaluation. However, prior research has not investigated GPT-4o's performance in heuristic evaluation compared to HCI experts in web-based systems. In this context, this study aims to compare the results of a heuristic evaluation performed by GPT-4o and human experts. To this end, we selected a set of screenshots from a web system and asked GPT-4o to perform a heuristic evaluation based on Nielsen's Heuristics from a literature-grounded prompt. Our results indicate that only 21.2% of the issues identified by human experts were also identified by GPT-4o, despite it found 27 new issues. We also found that GPT-4o performed better for heuristics related to aesthetic and minimalist design and match between system and real world, whereas it has difficulty identifying issues in heuristics related to flexibility, control, and user efficiency. Additionally, we noticed that GPT-4o generated several false positives due to hallucinations and attempts to predict issues. Finally, we highlight five takeaways for the conscious use of GPT-4o in heuristic evaluations.",
    "authors": [
      "Guerino, Guilherme",
      "Rodrigues, Luiz",
      "Capeleti, Bruna",
      "Mello, Rafael Ferreira",
      "Freire, Andr\u00e9",
      "Zaina, Luciana"
    ],
    "comments": "Paper accepted at the 20th IFIP TC13 International Conference on Human-Computer Interaction (INTERACT) 2025",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16345v1",
      "Other Formats": "https://arxiv.org/format/2506.16345",
      "TeX Source": "https://arxiv.org/src/2506.16345",
      "View PDF": "https://arxiv.org/pdf/2506.16345"
    },
    "reason": "The paper focuses on evaluating usability using heuristic evaluation and the comparative study between GPT-4o and human experts. It does not explicitly involve creativity or explore creative processes.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 14:22:44 UTC (539 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Can GPT-4o Evaluate Usability Like Human Experts? A Comparative Study on Issue Identification in Heuristic Evaluation"
  },
  {
    "id": "2506.10932",
    "abstract": "Individuals with schizophrenia frequently experience intense emotions and often turn to vlogging as a medium for emotional expression. While previous research has predominantly focused on text based disclosure, little is known about how individuals construct narratives around emotions and emotional experiences in video blogs. Our study addresses this gap by analyzing 200 YouTube videos created by individuals with schizophrenia. Drawing on media research and self presentation theories, we developed a visual analysis framework to disentangle these videos. Our analysis revealed diverse practices of emotion disclosure through both verbal and visual channels, highlighting the dynamic interplay between these modes of expression. We found that the deliberate construction of visual elements, including environmental settings and specific aesthetic choices, appears to foster more supportive and engaged viewer responses. These findings underscore the need for future large scale quantitative research examining how visual features shape video mediated communication on social media platforms. Such investigations would inform the development of care centered video sharing platforms that better support individuals managing illness experiences.",
    "authors": [
      "Liu, Jiaying Lizzy",
      "Zhang, Yan"
    ],
    "comments": "10 pages",
    "last_revised_date": "2025/06/18",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.10932",
      "View PDF": "https://arxiv.org/pdf/2506.10932"
    },
    "reason": "The paper focuses on emotion disclosure and expression in individuals with schizophrenia through video blogs. While it touches on narrative construction and visual elements, the main focus is on emotional expression and video-mediated communication, not creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Multimedia (cs.MM)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 12 Jun 2025 17:39:54 UTC (558 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 22:19:28 UTC (559 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/12",
    "title": "Video-Mediated Emotion Disclosure: Expressions of Fear, Sadness, and Joy by People with Schizophrenia on YouTube"
  },
  {
    "id": "2506.16107",
    "abstract": "In 2021 the Technical Infrastructure (TI) User Experience (UX) team sent a survey to 10,000 Google Developers (Googlers) and uncovered that Google's internal infrastructure tools were fragmented and inefficient, hindering developers' productivity. Using user centered research and design methodologies the team first created a story map and service blueprint to visualize the relationship between internal applications, then formulated a strategic vision to consolidate tools, streamline workflows, and measure the impact of their work. We secured executive buy-in and delivered incremental improvements.",
    "authors": [
      "Smith, Mariann Kornelia",
      "Meijer-Irons, Jacqueline",
      "Millar, Andrew"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16107",
      "View PDF": "https://arxiv.org/pdf/2506.16107"
    },
    "reason": "The paper focuses on improving productivity through tool consolidation and workflow streamlining rather than creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 07:59:37 UTC (691 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "From 600 Tools to 1 Console: A UX-Driven Transformation"
  },
  {
    "id": "2503.14103",
    "abstract": "Planning a trip into a potentially unsafe area is a difficult task. We conducted a formative study on travelers' information needs, finding that most of them turn to search engines for trip planning. Search engines, however, fail to provide easily interpretable results adapted to the context and personal information needs of a traveler. Large language models (LLMs) create new possibilities for providing personalized travel safety advice. To explore this idea, we developed DangerMaps, a mapping system that assists its users in researching the safety of an urban travel destination, whether it is pre-travel or on-location. DangerMaps plots safety ratings onto a map and provides explanations on demand. This late breaking work specifically emphasizes the challenges of designing real-world applications with large language models. We provide a detailed description of our approach to prompt design and highlight future areas of research.",
    "authors": [
      "Oppenlaender, Jonas"
    ],
    "comments": "14 pages, 3 figures, 1 table",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.14103v3",
      "Other Formats": "https://arxiv.org/format/2503.14103",
      "TeX Source": "https://arxiv.org/src/2503.14103",
      "View PDF": "https://arxiv.org/pdf/2503.14103"
    },
    "reason": "The paper focuses on providing personalized safety advice for travel using a language model. It emphasizes travel safety and system design rather than creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 18 Mar 2025 10:18:07 UTC (11,657 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 20 Mar 2025 10:20:29 UTC (11,685 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 06:05:48 UTC (6,647 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/03/18",
    "title": "DangerMaps: Personalized Safety Advice for Travel in Urban Environments using a Retrieval-Augmented Language Model"
  },
  {
    "id": "2506.11015",
    "abstract": "In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as \"grokking\" and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological \"schemata\" and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.",
    "authors": [
      "Oakley, Barbara",
      "Johnston, Michael",
      "Chen, Ken-Zen",
      "Jung, Eulho",
      "Sejnowski, Terrence J."
    ],
    "comments": "50 pages, 8 figures",
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.11015",
      "View PDF": "https://arxiv.org/pdf/2506.11015"
    },
    "reason": "The paper focuses on the effects of AI on human memory systems and cognition, discussing neuroscience and cognitive psychology. It doesn't address creativity as a main topic.",
    "relevance": "none",
    "subjects": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 3 May 2025 03:41:33 UTC (2,496 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 17:05:41 UTC (2,496 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/03",
    "title": "The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI",
    "tasks": []
  },
  {
    "id": "2506.12699",
    "abstract": "Large language models (LLMs) are sophisticated artificial intelligence systems that enable machines to generate human-like text with remarkable precision. While LLMs offer significant technological progress, their development using vast amounts of user data scraped from the web and collected from extensive user interactions poses risks of sensitive information leakage. Most existing surveys focus on the privacy implications of the training data but tend to overlook privacy risks from user interactions and advanced LLM capabilities. This paper aims to fill that gap by providing a comprehensive analysis of privacy in LLMs, categorizing the challenges into four main areas: (i) privacy issues in LLM training data, (ii) privacy challenges associated with user prompts, (iii) privacy vulnerabilities in LLM-generated outputs, and (iv) privacy challenges involving LLM agents. We evaluate the effectiveness and limitations of existing mitigation mechanisms targeting these proposed privacy challenges and identify areas for further research.",
    "authors": [
      "Shanmugarasa, Yashothara",
      "Ding, Ming",
      "Chamikara, M. A. P",
      "Rakotoarivelo, Thierry"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12699v2",
      "Other Formats": "https://arxiv.org/format/2506.12699",
      "TeX Source": "https://arxiv.org/src/2506.12699",
      "View PDF": "https://arxiv.org/pdf/2506.12699"
    },
    "reason": "The paper focuses on privacy concerns related to large language models, including training data, user interactions, and model outputs. It does not discuss creativity or explore creative applications or implications of these technologies.",
    "relevance": "none",
    "subjects": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 15 Jun 2025 03:14:03 UTC (971 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 06:30:24 UTC (970 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/15",
    "title": "SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation"
  },
  {
    "id": "2412.14195",
    "abstract": "This work presents the IMPROVE dataset, a multimodal resource designed to evaluate the effects of mobile phone usage on learners during online education. It includes behavioral, biometric, physiological, and academic performance data collected from 120 learners divided into three groups with different levels of phone interaction, enabling the analysis of the impact of mobile phone usage and related phenomena such as nomophobia. A setup involving 16 synchronized sensors -- including EEG, eye tracking, video cameras, smartwatches, and keystroke dynamics -- was used to monitor learner activity during 30-minute sessions involving educational videos, document reading, and multiple-choice tests. Mobile phone usage events, including both controlled interventions and uncontrolled interactions, were labeled by supervisors and refined through a semi-supervised re-labeling process. Technical validation confirmed signal quality, and statistical analyses revealed biometric changes associated with phone usage. The dataset is publicly available for research through GitHub and Science Data Bank, with synchronized recordings from three platforms (edBB, edX, and LOGGE), provided in standard formats (.csv, .mp4, .wav, and .tsv), and accompanied by a detailed guide.",
    "authors": [
      "Daza, Roberto",
      "Becerra, Alvaro",
      "Cobos, Ruth",
      "Fierrez, Julian",
      "Morales, Aythami"
    ],
    "comments": "Article under review in the journal Scientific Data. GitHub repository of the dataset at: this https URL",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2412.14195v2",
      "Other Formats": "https://arxiv.org/format/2412.14195",
      "TeX Source": "https://arxiv.org/src/2412.14195",
      "View PDF": "https://arxiv.org/pdf/2412.14195"
    },
    "reason": "The paper focuses on the impact of mobile phone usage on online education, analyzing behavioral and biometric data. Creativity is not mentioned or implied as a focus in the dataset or its intended applications.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 13 Dec 2024 11:29:05 UTC (18,612 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 15:11:05 UTC (5,454 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/12/13",
    "title": "A multimodal dataset for understanding the impact of mobile phones on remote online virtual education",
    "repo_urls": [
      "https://github.com/bidalab/improve"
    ],
    "tasks": [
      "Head Pose Estimation",
      "Pose Estimation"
    ]
  },
  {
    "id": "2506.16716",
    "abstract": "Automatic video commentary systems are widely used on multimedia social media platforms to extract factual information about video content. However, current systems may overlook essential para-linguistic cues, including emotion and attitude, which are critical for fully conveying the meaning of visual content. The absence of these cues can limit user understanding or, in some cases, distort the video's original intent. Expressive speech effectively conveys these cues and enhances the user's comprehension of videos. Building on these insights, this paper explores the usage of vision-context-aware expressive speech in enhancing users' understanding of videos in video commentary systems. Firstly, our formatting study indicates that semantic-only speech can lead to ambiguity, and misaligned emotions between speech and visuals may distort content interpretation. To address this, we propose a method called vision-context-aware speech synthesis (V-CASS). It analyzes para-linguistic cues from visuals using a vision-language model and leverages a knowledge-infused language model to guide the expressive speech model in generating context-aligned speech. User studies show that V-CASS enhances emotional and attitudinal resonance, as well as user audio-visual understanding and engagement, with 74.68% of participants preferring the system. Finally, we explore the potential of our method in helping blind and low-vision users navigate web videos, improving universal accessibility.",
    "authors": [
      "Wang, Qixin",
      "Zhou, Songtao",
      "Jin, Zeyu",
      "Guo, Chenglin",
      "Sun, Shikun",
      "Qin, Xiaoyu"
    ],
    "comments": "Accepted by IJCNN 2025",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16716v1",
      "Other Formats": "https://arxiv.org/format/2506.16716",
      "TeX Source": "https://arxiv.org/src/2506.16716",
      "View PDF": "https://arxiv.org/pdf/2506.16716"
    },
    "reason": "The paper focuses on expressive speech synthesis for enhancing user understanding of videos, specifically addressing emotional and attitudinal resonance. It does not discuss or imply any aspect of creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 03:24:34 UTC (2,323 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "V-CASS: Vision-context-aware Expressive Speech Synthesis for Enhancing User Understanding of Videos"
  },
  {
    "id": "2407.11823",
    "abstract": "The United States Food and Drug Administration's (FDA's) Premarket Notification 510(k) pathway allows manufacturers to gain approval for a medical device by demonstrating its substantial equivalence to another legally marketed device. However, the inherent ambiguity of this regulatory procedure has led to high recall rates for many devices cleared through this pathway. This trend has raised significant concerns regarding the efficacy of the FDA's current approach, prompting a reassessment of the 510(k) regulatory framework. In this paper, we develop a combined human-algorithm approach to assist the FDA in improving its 510(k) medical device clearance process by reducing the risk of recalls and the workload imposed on the FDA. We first develop machine learning methods to estimate the risk of recall of 510(k) medical devices based on the information available at submission time. We then propose a data-driven clearance policy that recommends acceptance, rejection, or deferral to FDA's committees for in-depth evaluation. We conduct an empirical study using a unique large-scale dataset of over 31,000 medical devices that we assembled based on data sources from the FDA and Centers for Medicare and Medicaid Service (CMS). A conservative evaluation of our proposed policy based on this data shows a 32.9% improvement in the recall rate and a 40.5% reduction in the FDA's workload. Our analyses also indicate that implementing our policy could result in significant annual cost savings of $1.7 billion, which highlights the value of using a holistic and data-driven approach to improve the FDA's current 510(k) medical device evaluation pathway.",
    "authors": [
      "Zhalechian, Mohammad",
      "Saghafian, Soroush",
      "Robles, Omar"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2407.11823v2",
      "Other Formats": "https://arxiv.org/format/2407.11823",
      "TeX Source": "https://arxiv.org/src/2407.11823",
      "View PDF": "https://arxiv.org/pdf/2407.11823"
    },
    "reason": "The paper is focused on improving the FDA's medical device clearance process using machine learning and data-driven approaches. It does not address creativity or mention terms related to creativity in its abstract or primary focus.",
    "relevance": "none",
    "subjects": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 16 Jul 2024 15:11:29 UTC (999 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 21:50:48 UTC (2,247 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/07/16",
    "title": "Harmonizing Safety and Speed: A Human-Algorithm Approach to Enhance the FDA's Medical Device Clearance Policy",
    "tasks": []
  },
  {
    "id": "2310.07019",
    "abstract": "From moderating content within an online community to producing socially-appropriate generative outputs, decision-making tasks -- conducted by either humans or AI -- often depend on subjective or socially-established criteria. To ensure such decisions are consistent, prevailing processes primarily make use of high-level rules and guidelines to ground decisions, similar to applying \"constitutions\" in the legal context. However, inconsistencies in specifying and interpreting constitutional grounding can lead to undesirable and even incorrect decisions being made. In this work, we introduce \"case law grounding\" (CLG) -- an approach for grounding subjective decision-making using past decisions, similar to how precedents are used in case law. We present how this grounding approach can be implemented in both human and AI decision-making contexts, introducing both a human-led process and a large language model (LLM) prompting setup. Evaluating with five groups and communities across two decision-making task domains, we find that decisions produced with CLG were significantly more accurately aligned to ground truth in 4 out of 5 groups, achieving a 16.0--23.3 %-points higher accuracy in the human process, and 20.8--32.9 %-points higher with LLMs. We also examined the impact of different configurations with the retrieval window size and binding nature of decisions and find that binding decisions and larger retrieval windows were beneficial. Finally, we discuss the broader implications of using CLG to augment existing constitutional grounding when it comes to aligning human and AI decisions.",
    "authors": [
      "Chen, Quan Ze",
      "Zhang, Amy X."
    ],
    "comments": "Accepted at ACM Collective Intelligence 2025",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2310.07019v4",
      "Other Formats": "https://arxiv.org/format/2310.07019",
      "TeX Source": "https://arxiv.org/src/2310.07019",
      "View PDF": "https://arxiv.org/pdf/2310.07019"
    },
    "reason": "The paper focuses on decision-making processes for humans and AI using case law grounding, without mentioning creativity or related terms.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 10 Oct 2023 21:12:15 UTC (1,332 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 6 Sep 2024 15:56:01 UTC (1,141 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Wed, 18 Dec 2024 18:41:41 UTC (936 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Fri, 20 Jun 2025 01:12:55 UTC (904 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2023/10/10",
    "title": "Case Law Grounding: Using Precedents to Align Decision-Making for Humans and AI"
  },
  {
    "id": "2506.17196",
    "abstract": "The increasing availability of large language models (LLMs) has raised concerns about their potential misuse in online learning. While tools for detecting LLM-generated text exist and are widely used by researchers and educators, their reliability varies. Few studies have compared the accuracy of detection methods, defined criteria to identify content generated by LLM, or evaluated the effect on learner performance from LLM misuse within learning. In this study, we define LLM-generated text within open responses as those produced by any LLM without paraphrasing or refinement, as evaluated by human coders. We then fine-tune GPT-4o to detect LLM-generated responses and assess the impact on learning from LLM misuse. We find that our fine-tuned LLM outperforms the existing AI detection tool GPTZero, achieving an accuracy of 80% and an F1 score of 0.78, compared to GPTZero's accuracy of 70% and macro F1 score of 0.50, demonstrating superior performance in detecting LLM-generated responses. We also find that learners suspected of LLM misuse in the open response question were more than twice as likely to correctly answer the corresponding posttest MCQ, suggesting potential misuse across both question types and indicating a bypass of the learning process. We pave the way for future work by demonstrating a structured, code-based approach to improve LLM-generated response detection and propose using auxiliary statistical indicators such as unusually high assessment scores on related tasks, readability scores, and response duration. In support of open science, we contribute data and code to support the fine-tuning of similar models for similar use cases.",
    "authors": [
      "Bhushan, Shambhavi",
      "Thomas, Danielle R",
      "Borchers, Conrad",
      "Raghuvanshi, Isha",
      "Abboud, Ralph",
      "Gatz, Erin",
      "Gupta, Shivang",
      "Koedinger, Kenneth"
    ],
    "comments": "Accepted for publication at the 19th European Conference on Technology Enhanced Learning (ECTEL 2025). This is the author's accepted manuscript",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17196v1",
      "Other Formats": "https://arxiv.org/format/2506.17196",
      "TeX Source": "https://arxiv.org/src/2506.17196",
      "View PDF": "https://arxiv.org/pdf/2506.17196"
    },
    "reason": "The paper focuses on detecting LLM-generated text within online learning environments and its effect on learner performance, without any mention of creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:47:36 UTC (59 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Detecting LLM-Generated Short Answers and Effects on Learner Performance"
  },
  {
    "id": "2506.16051",
    "abstract": "Reproducibility remains a central challenge in machine learning (ML), especially in collaborative eScience projects where teams iterate over data, features, and models. Current ML workflows are often dynamic yet fragmented, relying on informal data sharing, ad hoc scripts, and loosely connected tools. This fragmentation impedes transparency, reproducibility, and the adaptability of experiments over time. This paper introduces a data-centric framework for lifecycle-aware reproducibility, centered around six structured artifacts: Dataset, Feature, Workflow, Execution, Asset, and Controlled Vocabulary. These artifacts formalize the relationships between data, code, and decisions, enabling ML experiments to be versioned, interpretable, and traceable over time. The approach is demonstrated through a clinical ML use case of glaucoma detection, illustrating how the system supports iterative exploration, improves reproducibility, and preserves the provenance of collaborative decisions across the ML lifecycle.",
    "authors": [
      "Li, Zhiwei",
      "Kesselman, Carl",
      "Nguyen, Tran Huy",
      "Xu, Benjamin Yixing",
      "Bolo, Kyle",
      "Yu, Kimberley"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16051v1",
      "Other Formats": "https://arxiv.org/format/2506.16051",
      "TeX Source": "https://arxiv.org/src/2506.16051",
      "View PDF": "https://arxiv.org/pdf/2506.16051"
    },
    "reason": "The paper focuses on reproducibility in machine learning workflows, particularly in collaborative eScience projects, which is unrelated to creativity.",
    "relevance": "none",
    "subjects": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Digital Libraries (cs.DL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 06:09:01 UTC (805 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "From Data to Decision: Data-Centric Infrastructure for Reproducible ML in Collaborative eScience"
  },
  {
    "id": "2503.01769",
    "abstract": "A growing body of work has shown that AI-assisted methods -- leveraging large language models, social choice methods, and collective dialogues -- can help navigate polarization and surface common ground in controlled lab settings. But what can these approaches contribute in real-world contexts? We present a case study applying these techniques to find common ground between Israeli and Palestinian peacebuilders in the period following October 7th, 2023. From April to July 2024 an iterative deliberative process combining LLMs, bridging-based ranking, and collective dialogues was conducted in partnership with the Alliance for Middle East Peace. Around 138 civil society peacebuilders participated including Israeli Jews, Palestinian citizens of Israel, and Palestinians from the West Bank and Gaza. The process resulted in a set of collective statements, including demands to world leaders, with at least 84% agreement from participants on each side. In this paper, we document the process, results, challenges, and important open questions.",
    "authors": [
      "Konya, Andrew",
      "Thorburn, Luke",
      "Almasri, Wasim",
      "Leshem, Oded Adomi",
      "Procaccia, Ariel D.",
      "Schirch, Lisa",
      "Bakker, Michiel A."
    ],
    "comments": "Accepted at FAccT 2025",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.01769v3",
      "Other Formats": "https://arxiv.org/format/2503.01769",
      "TeX Source": "https://arxiv.org/src/2503.01769",
      "View PDF": "https://arxiv.org/pdf/2503.01769"
    },
    "reason": "The paper focuses on AI-assisted methods for negotiating political polarization and common ground in peacebuilding contexts. It does not address topics related to creativity, such as creative thinking processes, tools, or the enhancement of creativity.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 3 Mar 2025 17:49:30 UTC (1,147 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 7 Mar 2025 22:22:40 UTC (1,161 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 16:59:29 UTC (1,428 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/03/03",
    "title": "Using Collective Dialogues and AI to Find Common Ground Between Israeli and Palestinian Peacebuilders"
  },
  {
    "id": "2506.16617",
    "abstract": "Predictive Process Monitoring (PPM) often uses deep learning models to predict the future behavior of ongoing processes, such as predicting process outcomes. While these models achieve high accuracy, their lack of interpretability undermines user trust and adoption. Explainable AI (XAI) aims to address this challenge by providing the reasoning behind the predictions. However, current evaluations of XAI in PPM focus primarily on functional metrics (such as fidelity), overlooking user-centered aspects such as their effect on task performance and decision-making. This study investigates the effects of explanation styles (feature importance, rule-based, and counterfactual) and perceived AI accuracy (low or high) on decision-making in PPM. We conducted a decision-making experiment, where users were presented with the AI predictions, perceived accuracy levels, and explanations of different styles. Users' decisions were measured both before and after receiving explanations, allowing the assessment of objective metrics (Task Performance and Agreement) and subjective metrics (Decision Confidence). Our findings show that perceived accuracy and explanation style have a significant effect.",
    "authors": [
      "Chae, Soobin",
      "Lee, Suhwan",
      "Hauptmann, Hanna",
      "Reijers, Hajo A.",
      "Lu, Xixi"
    ],
    "comments": "Accepted at CAiSE'25",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16617v1",
      "Other Formats": "https://arxiv.org/format/2506.16617",
      "TeX Source": "https://arxiv.org/src/2506.16617",
      "View PDF": "https://arxiv.org/pdf/2506.16617"
    },
    "reason": "The paper focuses on explanation styles and perceived accuracy in predictive process monitoring, specifically examining decision-making in the context of explainable AI. It does not address creativity as a topic.",
    "relevance": "none",
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 21:30:28 UTC (449 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring"
  },
  {
    "id": "2412.00630",
    "abstract": "Cosplay commission (cos-commission) is a new form of commodified romantic companionship within the Otome game community in China. To explore the motivations, practices, experiences, and challenges, we conducted semi-structured interviews with 15 participants in different roles. Our findings reveal that cos-commission, as a hybrid activity, provides participants with a chance to collaboratively build meaningful connections. It also offers a pathway for personal exploration and emotional recovery. However, the vague boundary between performative roles and intimate interactions can give rise to unexpected negative outcomes, such as attachment-driven entanglements and post-commission \"withdrawal symptoms.\" While digital platforms facilitate communication in cos-commissions, they often lack sufficient safeguards. This preliminary work provides insights into the formation process of hybrid intimate relationship and its potential to foster personalized, long-term support for mental well-being, and reveals potential privacy and security challenges.",
    "authors": [
      "Zhou, Yihao",
      "Xu, Haowei",
      "Zhang, Lili",
      "Zhao, Shengdong"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2412.00630v2",
      "Other Formats": "https://arxiv.org/format/2412.00630",
      "TeX Source": "https://arxiv.org/src/2412.00630",
      "View PDF": "https://arxiv.org/pdf/2412.00630"
    },
    "reason": "The paper primarily focuses on the intimacy and personal relationships within the cosplay commission practice in the Otome game community, which may involve aspects of personal exploration that can be related to creativity. However, creativity is not the explicit focus of the study.",
    "relevance": "weak",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 1 Dec 2024 01:00:57 UTC (1,201 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 18:44:44 UTC (993 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/12/01",
    "title": "Collective Creation of Intimacy: Exploring the Cosplay Commission Practice within the Otome Game Community in China"
  },
  {
    "id": "2506.16044",
    "abstract": "With recent advancements in AI and computational tools, intelligent paradigms have emerged to enhance fields like shared autonomy and human-machine teaming in healthcare. Advanced AI algorithms (e.g., reinforcement learning) can autonomously make decisions to achieve planning and motion goals. However, in healthcare, where human intent is crucial, fully independent machine decisions may not be ideal. This chapter presents a comprehensive review of human-centered shared autonomy AI frameworks, focusing on upper limb biosignal-based machine interfaces and associated motor control systems, including computer cursors, robotic arms, and planar platforms. We examine motor planning, learning (rehabilitation), and control, covering conceptual foundations of human-machine teaming in reach-and-grasp tasks and analyzing both theoretical and practical implementations. Each section explores how human and machine inputs can be blended for shared autonomy in healthcare applications. Topics include human factors, biosignal processing for intent detection, shared autonomy in brain-computer interfaces (BCI), rehabilitation, assistive robotics, and Large Language Models (LLMs) as the next frontier. We propose adaptive shared autonomy AI as a high-performance paradigm for collaborative human-AI systems, identify key implementation challenges, and outline future directions, particularly regarding AI reasoning agents. This analysis aims to bridge neuroscientific insights with robotics to create more intuitive, effective, and ethical human-machine teaming frameworks.",
    "authors": [
      "Farhadi, MH",
      "Rabiee, Ali",
      "Ghafoori, Sima",
      "Cetera, Anna",
      "Xu, Wei",
      "Abiri, Reza"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16044v1",
      "Other Formats": "https://arxiv.org/format/2506.16044",
      "TeX Source": "https://arxiv.org/src/2506.16044",
      "View PDF": "https://arxiv.org/pdf/2506.16044"
    },
    "reason": "The paper focuses on human-centered shared autonomy, motor planning, learning, and control in healthcare applications. It does not explicitly address creativity or its enhancement.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 05:44:12 UTC (6,216 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Human-Centered Shared Autonomy for Motor Planning, Learning, and Control Applications"
  },
  {
    "id": "2506.15860",
    "abstract": "Visual analysis of relational data is essential for many real-world analytics tasks, with layout quality being key to interpretability. However, existing layout algorithms often require users to navigate complex parameters to express their intent. We present a user-guided force-directed layout approach that enables intuitive control through freehand sketching. Our method uses classical image analysis techniques to extract structural information from sketches, which is then used to generate positional constraints that guide the layout process. We evaluate the approach on various real and synthetic graphs ranging from small to medium scale, demonstrating its ability to produce layouts aligned with user expectations. An implementation of our method along with documentation and a demo page is freely available on GitHub at https://github.com/sciluna/uggly.",
    "authors": [
      "Balci, Hasan",
      "Luna, Augustin"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15860v1",
      "Other Formats": "https://arxiv.org/format/2506.15860",
      "TeX Source": "https://arxiv.org/src/2506.15860",
      "View PDF": "https://arxiv.org/pdf/2506.15860"
    },
    "reason": "The paper focuses on a user-guided approach to graph layout using freehand sketching without mentioning creativity or creative processes.",
    "relevance": "none",
    "subjects": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 20:11:46 UTC (8,283 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "User-Guided Force-Directed Graph Layout"
  },
  {
    "id": "2506.17032",
    "abstract": "The literature describes many visualization techniques for different types of data, tasks, and application contexts, and new techniques are proposed on a regular basis. Visualization surveys try to capture the immense space of techniques and structure it with meaningful categorizations. Yet, it remains difficult to understand the similarity of visualization techniques in general. We approach this open research question from two angles. First, we follow a model-driven approach that is based on defining the signature of visualization techniques and interpreting the similarity of signatures as the similarity of their associated techniques. Second, following an expert-driven approach, we asked visualization experts in a small online study for their ad-hoc intuitive assessment of the similarity of pairs visualization techniques. From both approaches, we gain insight into the similarity of a set of 13 basic and advanced visualizations for different types of data. While our results are so far preliminary and academic, they are first steps toward better understanding the similarity of visualization techniques.",
    "authors": [
      "Salako, Abdulhaq Adetunji",
      "Tominski, Christian"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17032v1",
      "Other Formats": "https://arxiv.org/format/2506.17032",
      "TeX Source": "https://arxiv.org/src/2506.17032",
      "View PDF": "https://arxiv.org/pdf/2506.17032"
    },
    "reason": "The paper focuses on understanding the similarity of visualization techniques rather than creativity. It does not address creativity in visualization or in human-computer interaction.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 14:42:16 UTC (910 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Toward Understanding Similarity of Visualization Techniques"
  },
  {
    "id": "2506.16851",
    "abstract": "Recent studies show that users often interpret social media algorithms as mystical or spiritual because of their unpredictability. This invites new questions about how such perceptions affect the content that creators create and the communities they form online. In this study, 14 creators of algorithmic conspirituality content on TikTok were interviewed to explore their interpretations and creation processes influenced by the platform's For You Page algorithm. We illustrate how creators' beliefs interact with TikTok's algorithmic mediation to reinforce and shape their spiritual or relational themes. Furthermore, we show how algorithmic conspirituality content impacts viewers, highlighting its role in generating significant emotional and affective labor for creators, stemming from complex relational dynamics inherent in this content creation. We discuss implications for design to support creators aimed at recognizing the unexpected spiritual and religious experiences algorithms prompt, as well as supporting creators in effectively managing these challenges.",
    "authors": [
      "De, Ankolika",
      "Cotter, Kelley",
      "Kanthawala, Shaheen",
      "McAtee, Haley",
      "Ritchart, Amy",
      "Kadur, Gahana"
    ],
    "comments": "27 pages, Proc. ACM Hum.-Comput. Interact. 8",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16851v1",
      "Other Formats": "https://arxiv.org/format/2506.16851",
      "TeX Source": "https://arxiv.org/src/2506.16851",
      "View PDF": "https://arxiv.org/pdf/2506.16851"
    },
    "reason": "The paper touches on creativity in terms of content creation influenced by social media algorithms but does not focus explicitly on creativity. It explores motivations and processes behind creating algorithmic content, which indirectly involves creative aspects, but the primary focus is on perceptions of algorithms and emotional labor.",
    "relevance": "weak",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 08:58:56 UTC (108 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "\"Whoever needs to see it, will see it\": Motivations and Labor of Creating Algorithmic Conspirituality Content on TikTok"
  },
  {
    "id": "2506.17116",
    "abstract": "In this workshop paper, we discuss the potential for measures of user-centric benefits (such as emotional well-being) that could be explored when evaluating explainable AI (XAI) systems within the arts. As a background to this, we draw from our recent review of creativity support tool (CST) evaluations, that found a paucity of studies evaluating CSTs for user-centric measures that benefit the user themselves. Specifically, we discuss measures of: (1) developing intrinsic abilities, (2) emotional well-being, (3) self-reflection, and (4) self-perception. By discussing these user-centric measures within the context of XAI and the arts, we wish to provoke discussion regarding the potential of such measures.",
    "authors": [
      "Cox, Samuel Rhys",
      "Djern\u00e6s, Helena B\u00f8jer",
      "van Berkel, Niels"
    ],
    "comments": "Workshop paper presented at XAIxArts'25 - the third international workshop on eXplainable AI for the Arts, held in conjunction with the ACM Creativity and Cognition conference 2025, June 23rd, 2025. 3 pages",
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17116v1",
      "Other Formats": "https://arxiv.org/format/2506.17116",
      "TeX Source": "https://arxiv.org/src/2506.17116",
      "View PDF": "https://arxiv.org/pdf/2506.17116"
    },
    "reason": "The paper discusses creativity support tools (CST) and evaluates measures that can enhance user-centric benefits in a creative context, explicitly linking explainable AI with creativity and the arts.",
    "relevance": "strong",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:15:15 UTC (98 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Reflecting Human Values in XAI: Emotional and Reflective Benefits in Creativity Support Tools"
  },
  {
    "id": "2506.16008",
    "abstract": "Engaging in smooth conversations with others is a crucial social skill. However, differences in knowledge between conversation participants can sometimes hinder effective communication. To tackle this issue, this study proposes a real-time support system that integrates head-mounted display (HMD)-based augmented reality (AR) technology with large language models (LLMs). This system facilitates conversation by recognizing keywords during dialogue, generating relevant information using the LLM, reformatting it, and presenting it to the user via the HMD. A significant issue with this system is that the user's eye movements may reveal to the conversation partner that they are reading the displayed text. This study also proposes a method for presenting information that takes into account appropriate eye movements during conversation. Two experiments were conducted to evaluate the effectiveness of the proposed system. The first experiment revealed that the proposed information presentation method reduces the likelihood of the conversation partner noticing that the user is reading the displayed text. The second experiment demonstrated that the proposed method led to a more balanced speech ratio between the user and the conversation partner, as well as a increase in the perceived excitement of the conversation.",
    "authors": [
      "Fujimoto, Yuichiro"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16008v1",
      "Other Formats": "https://arxiv.org/format/2506.16008",
      "TeX Source": "https://arxiv.org/src/2506.16008",
      "View PDF": "https://arxiv.org/pdf/2506.16008"
    },
    "reason": "The paper focuses on enhancing conversation skills using augmented reality and large language models. It does not explicitly address creativity, as its main objective is to improve knowledge sharing and communication rather than creative processes.",
    "relevance": "none",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 03:59:44 UTC (867 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "ChatAR: Conversation Support using Large Language Model and Augmented Reality"
  },
  {
    "id": "2506.16874",
    "abstract": "The integration of Generative Artificial Intelligence (GenAI) in K-6 project-based art courses presents both opportunities and challenges for enhancing creativity, engagement, and group collaboration. This study introduces a four-phase field study, involving in total two experienced K-6 art teachers and 132 students in eight offline course sessions, to investigate the usage and impact of GenAI. Specifically, based on findings in Phases 1 and 2, we developed AskArt, an interactive interface that combines DALL-E and GPT and is tailored to support elementary school students in their art projects, and deployed it in Phases 3 and 4. Our findings revealed the benefits of GenAI in providing background information, inspirations, and personalized guidance. However, challenges in query formulation for generating expected content were also observed. Moreover, students employed varied collaboration strategies, and teachers noted increased engagement alongside concerns regarding misuse and interface suitability. This study offers insights into the effective integration of GenAI in elementary education, presents AskArt as a practical tool, and provides recommendations for educators and researchers to enhance project-based learning with GenAI technologies.",
    "authors": [
      "Wang, Zhiqing",
      "Fan, Haoxiang",
      "Wu, Shiwei",
      "Chen, Qiaoyi",
      "Liang, Yongqi",
      "Peng, Zhenhui"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16874v1",
      "Other Formats": "https://arxiv.org/format/2506.16874",
      "TeX Source": "https://arxiv.org/src/2506.16874",
      "View PDF": "https://arxiv.org/pdf/2506.16874"
    },
    "reason": "The paper explicitly focuses on enhancing creativity in elementary art courses through the integration of Generative AI, highlighting benefits such as providing inspirations and personalized guidance, which directly relate to fostering creativity.",
    "relevance": "strong",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 09:46:09 UTC (9,820 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Exploring the Usage of Generative AI for Group Project-Based Offline Art Courses in Elementary Schools"
  },
  {
    "id": "2506.16622",
    "abstract": "Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.",
    "authors": [
      "Pei, Jiaxin",
      "Wright, Dustin",
      "Augenstin, Isabelle",
      "Jurgens, David"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16622v1",
      "Other Formats": "https://arxiv.org/format/2506.16622",
      "TeX Source": "https://arxiv.org/src/2506.16622",
      "View PDF": "https://arxiv.org/pdf/2506.16622"
    },
    "reason": "The paper focuses on modeling public perceptions of science in media and does not address creativity. Its primary concerns are public engagement, perception modeling, and science communication.",
    "relevance": "none",
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 21:49:28 UTC (462 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Modeling Public Perceptions of Science in Media"
  },
  {
    "id": "2506.16202",
    "abstract": "Explicit labeling of online content produced by artificial intelligence (AI) is a widely mooted policy for ensuring transparency and promoting public confidence. Yet little is known about the scope of AI labeling effects on public assessments of labeled content. We contribute new evidence on this question from a survey experiment using a high-quality nationally representative probability sample (n = 3,861). First, we demonstrate that explicit AI labeling of a news article about a proposed public policy reduces its perceived accuracy. Second, we test whether there are spillover effects in terms of policy interest, policy support, and general concerns about online misinformation. We find that AI labeling reduces interest in the policy, but neither influences support for the policy nor triggers general concerns about online misinformation. We further find that increasing the salience of AI use reduces the negative impact of AI labeling on perceived accuracy, while one-sided versus two-sided framing of the policy has no moderating effect. Overall, our findings suggest that the effects of algorithm aversion induced by AI labeling of online content are limited in scope.",
    "authors": [
      "Wang, Chuyao",
      "Sturgis, Patrick",
      "de Kadt, Daniel"
    ],
    "comments": "30 pages, 5 figures, 10 tables",
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16202",
      "TeX Source": "https://arxiv.org/src/2506.16202",
      "View PDF": "https://arxiv.org/pdf/2506.16202"
    },
    "reason": "The paper focuses on the impact of AI labeling on the perceived accuracy of online content and associated policy interest. It does not address topics related to creativity.",
    "relevance": "none",
    "subjects": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Applications (stat.AP)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 10:32:52 UTC (3,196 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "AI labeling reduces the perceived accuracy of online content but has limited broader effects"
  },
  {
    "id": "2502.04599",
    "abstract": "Linkography -- the analysis of links between the design moves that make up an episode of creative ideation or design -- can be used for both visual and quantitative assessment of creative activity traces. Traditional linkography, however, is time-consuming, requiring a human coder to manually annotate both the design moves within an episode and the connections between them. As a result, linkography has not yet been much applied at scale. To address this limitation, we introduce fuzzy linkography: a means of automatically constructing a linkograph from a sequence of recorded design moves via a \"fuzzy\" computational model of semantic similarity, enabling wider deployment and new applications of linkographic techniques. We apply fuzzy linkography to three markedly different kinds of creative activity traces (text-to-image prompting journeys, LLM-supported ideation sessions, and researcher publication histories) and discuss our findings, as well as strengths, limitations, and potential future applications of our approach.",
    "authors": [
      "Smith, Amy",
      "Anderson, Barrett R.",
      "Otto, Jasmine Tan",
      "Karth, Isaac",
      "Sun, Yuqian",
      "Chung, John Joon Young",
      "Roemmele, Melissa",
      "Kreminski, Max"
    ],
    "comments": "ACM C&C 2025. Code available at this https URL",
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.04599v2",
      "Other Formats": "https://arxiv.org/format/2502.04599",
      "TeX Source": "https://arxiv.org/src/2502.04599",
      "View PDF": "https://arxiv.org/pdf/2502.04599"
    },
    "reason": "The paper explicitly focuses on creativity by analyzing 'creative activity traces' through the method of linkography, which is tied to understanding creative ideation and design processes.",
    "relevance": "strong",
    "subjects": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 7 Feb 2025 01:16:59 UTC (5,481 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 04:41:19 UTC (5,477 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/07",
    "title": "Fuzzy Linkography: Automatic Graphical Summarization of Creative Activity Traces",
    "repo_urls": [
      "https://github.com/mkremins/fuzzy-linkography"
    ]
  }
]