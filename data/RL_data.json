{
  "data": [
    {
      "id": "2507.11542",
      "abstract": "This article introduces a software package release for geometrically reasoning about the \\textit{safety} desiderata of (complex) dynamical systems via level set methods. In emphasis, safety is analyzed with Hamilton-Jacobi equations. In scope, we provide implementations of numerical algorithms for the resolution of Hamilton-Jacobi-Isaacs equations: the spatial derivatives of the associated value function via upwinding, the Hamiltonian via Lax-Friedrichs schemes, and the integration of the Hamilton-Jacobi equation altogether via total variation diminishing Runge-Kutta schemes. Since computational speed and interoperability with other modern scientific computing libraries (typically written in the Python language) is of essence, we capitalize on modern computational frameworks such as \\texttt{CUPY} and \\texttt{NUMPY} and move heavy computations to GPU devices to aid parallelization and improve bring-up time in safety analysis. We hope that this package can aid users to quickly iterate on ideas and evaluate all possible safety desiderata of a system via geometrical simulation in modern engineering problems.",
      "authors": [
        "Lekan Molu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Mathematical Software (cs.MS)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T18:34:09+00:00",
          "link": "https://arxiv.org/abs/2507.11542v1",
          "size": "1524kb",
          "version": "v1"
        }
      ],
      "title": "LevelSetPy: A GPU-Accelerated Package for Hyperbolic Hamilton-Jacobi Partial Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11542",
        "HTML": "https://arxiv.org/html/2507.11542v1",
        "PDF": "https://arxiv.org/pdf/2507.11542"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a software package for analyzing safety in dynamical systems via Hamilton-Jacobi methods and GPU acceleration, without involving reinforcement learning or RL data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11543",
      "abstract": "This paper surveys the use of Generative AI tools, such as ChatGPT and Claude, in computer science education, focusing on key aspects of accuracy, authenticity, and assessment. Through a literature review, we highlight both the challenges and opportunities these AI tools present. While Generative AI improves efficiency and supports creative student work, it raises concerns such as AI hallucinations, error propagation, bias, and blurred lines between AI-assisted and student-authored content. Human oversight is crucial for addressing these concerns. Existing literature recommends adopting hybrid assessment models that combine AI with human evaluation, developing bias detection frameworks, and promoting AI literacy for both students and educators. Our findings suggest that the successful integration of AI requires a balanced approach, considering ethical, pedagogical, and technical factors. Future research may explore enhancing AI accuracy, preserving academic integrity, and developing adaptive models that balance creativity with precision.",
      "authors": [
        "Iman Reihanian",
        "Yunfei Hou",
        "Yu Chen",
        "Yifei Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T19:20:58+00:00",
          "link": "https://arxiv.org/abs/2507.11543v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11543",
        "HTML": "https://arxiv.org/html/2507.11543v1",
        "PDF": "https://arxiv.org/pdf/2507.11543"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of Generative AI in computer science education, focusing on challenges and opportunities rather than reinforcement learning or data processing in RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11544",
      "abstract": "Open-weight large language models (LLMs) unlock huge benefits in innovation, personalization, privacy, and democratization. However, their core advantage - modifiability - opens the door to systemic risks: bad actors can trivially subvert current safeguards, turning beneficial models into tools for harm. This leads to a 'safety gap': the difference in dangerous capabilities between a model with intact safeguards and one that has been stripped of those safeguards. We open-source a toolkit to estimate the safety gap for state-of-the-art open-weight models. As a case study, we evaluate biochemical and cyber capabilities, refusal rates, and generation quality of models from two families (Llama-3 and Qwen-2.5) across a range of parameter scales (0.5B to 405B) using different safeguard removal techniques. Our experiments reveal that the safety gap widens as model scale increases and effective dangerous capabilities grow substantially when safeguards are removed. We hope that the Safety Gap Toolkit (https://github.com/AlignmentResearch/safety-gap) will serve as an evaluation framework for common open-source models and as a motivation for developing and testing tamper-resistant safeguards. We welcome contributions to the toolkit from the community.",
      "authors": [
        "Ann-Kathrin Dombrowski",
        "Dillon Bowen",
        "Adam Gleave",
        "Chris Cundy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:58:01+00:00",
          "link": "https://arxiv.org/abs/2507.11544v1",
          "size": "242kb",
          "version": "v1"
        }
      ],
      "title": "The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11544",
        "HTML": "https://arxiv.org/html/2507.11544v1",
        "PDF": "https://arxiv.org/pdf/2507.11544"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on evaluating the safety of open-source models, specifically looking at the safety gaps in LLM models; it does not relate to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11545",
      "abstract": "The very DNA of AI architecture presents conflicting paths: centralized cloud-based models (Software-as-a-Service) versus decentralized edge AI (local processing on consumer devices). This paper analyzes the competitive battleground across computational capability, energy efficiency, and data privacy. Recent breakthroughs show edge AI challenging cloud systems on performance, leveraging innovations like test-time training and mixture-of-experts architectures. Crucially, edge AI boasts a 10,000x efficiency advantage: modern ARM processors consume merely 100 microwatts forinference versus 1 watt for equivalent cloud processing. Beyond efficiency, edge AI secures data sovereignty by keeping processing local, dismantling single points of failure in centralized architectures. This democratizes access throughaffordable hardware, enables offline functionality, and reduces environmental impact by eliminating data transmission costs. The edge AI market projects explosive growth from $9 billion in 2025 to $49.6 billion by 2030 (38.5% CAGR), fueled by privacy demands and real-time analytics. Critical applications including personalized education, healthcare monitoring, autonomous transport, and smart infrastructure rely on edge AI's ultra-low latency (5-10ms versus 100-500ms for cloud). The convergence of architectural innovation with fundamental physics confirms edge AI's distributed approach aligns with efficient information processing, signaling the inevitable emergence of hybrid edge-cloud ecosystems.",
      "authors": [
        "Rhea Pritham Marpu",
        "Kevin J McNamara",
        "Preeti Gupta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Emerging Technologies (cs.ET)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:27:20+00:00",
          "link": "https://arxiv.org/abs/2507.11545v1",
          "size": "251kb",
          "version": "v1"
        }
      ],
      "title": "The AI Shadow War: SaaS vs. Edge Computing Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11545",
        "HTML": "https://arxiv.org/html/2507.11545v1",
        "PDF": "https://arxiv.org/pdf/2507.11545"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper analyzes AI architectures, specifically comparing centralized cloud models with decentralized edge AI; it does not pertain to reinforcement learning or data processing relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11546",
      "abstract": "The year 2024 witnessed accelerated global AI governance advancements, marked by strengthened multilateral frameworks and proliferating national regulatory initiatives. This acceleration underscores an unprecedented need to systematically track governance progress--an imperative that drove the launch of the AI Governance InternationaL Evaluation Index (AGILE Index) project since 2023. The inaugural AGILE Index, released in February 2024 after assessing 14 countries, established an operational and comparable baseline framework. Building on pilot insights, AGILE Index 2025 incorporates systematic refinements to better balance scientific rigor with practical adaptability. The updated methodology expands data diversity while enhancing metric validity and cross-national comparability. Reflecting both research advancements and practical policy evolution, AGILE Index 2025 evaluates 40 countries across income levels, regions, and technological development stages, with 4 Pillars, 17 Dimensions and 43 Indicators. In compiling the data, the team integrates multi-source evidence including policy documents, governance practices, research outputs, and risk exposure to construct a unified comparison framework. This approach maps global disparities while enabling countries to identify governance strengths, gaps, and systemic constraints. Through ongoing refinement and iterations, we hope the AGILE Index will fundamentally advance transparency and measurability in global AI governance, delivering data-driven assessments that depict national AI governance capacity, assist governments in recognizing their maturation stages and critical governance issues, and ultimately provide actionable insights for enhancing AI governance systems nationally and globally.",
      "authors": [
        "Yi Zeng",
        "Enmeng Lu",
        "Xiaoyang Guo",
        "Cunqing Huangfu",
        "Jiawei Xie",
        "Yu Chen",
        "Zhengqi Wang",
        "Dongqi Liang",
        "Gongce Cao",
        "Jin Wang",
        "Zizhe Ruan",
        "Xin Guan and Ammar Younas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:28:27+00:00",
          "link": "https://arxiv.org/abs/2507.11546v1",
          "size": "22445kb",
          "version": "v1"
        }
      ],
      "title": "AI Governance InternationaL Evaluation Index (AGILE Index) 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11546",
        "PDF": "https://arxiv.org/pdf/2507.11546"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces an evaluation index for AI governance, focusing on global assessment frameworks and data processing for governance metrics, not within the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11547",
      "abstract": "In recent years, various artificial intelligence-based surrogate models have been proposed to provide rapid manufacturability predictions of material forming processes. However, traditional AI-based surrogate models, typically built with scalar or image-based neural networks, are limited in their ability to capture complex 3D spatial relationships and to operate in a permutation-invariant manner. To overcome these issues, emerging graph-based surrogate models are developed using graph neural networks. This study developed a new graph neural network surrogate model named Recurrent U Net-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate predictions of sheet material deformation fields across multiple forming timesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model temporal dynamics and a U-Net inspired graph-based downsample/upsample mechanism to handle spatial long-range dependencies. A novel 'node-to-surface' contact representation method was proposed, offering significant improvements in computational efficiency for large-scale contact interactions. The RUGNN model was validated using a cold forming case study and a more complex hot forming case study using aluminium alloys. Results demonstrate that the RUGNN model provides accurate deformation predictions closely matching ground truth FE simulations and outperforming several baseline GNN architectures. Model tuning was also performed to identify suitable hyperparameters, training strategies, and input feature representations. These results demonstrate that RUGNN is a reliable approach to support sheet material forming design by enabling accurate manufacturability predictions.",
      "authors": [
        "Yingxue Zhao",
        "Qianyi Chen",
        "Haoran Li",
        "Haosu Zhou",
        "Hamid Reza Attar",
        "Tobias Pfaff",
        "Tailin Wu",
        "Nan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:14:18+00:00",
          "link": "https://arxiv.org/abs/2507.11547v1",
          "size": "4138kb",
          "version": "v1"
        }
      ],
      "title": "Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11547",
        "PDF": "https://arxiv.org/pdf/2507.11547"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work develops a graph neural network for deformation predictions in material forming, with no mention of reinforcement learning or related data processing methodologies in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11548",
      "abstract": "The increasing use of generative AI for resume screening is predicated on the assumption that it offers an unbiased alternative to biased human decision-making. However, this belief fails to address a critical question: are these AI systems fundamentally competent at the evaluative tasks they are meant to perform? This study investigates the question of competence through a two-part audit of eight major AI platforms. Experiment 1 confirmed complex, contextual racial and gender biases, with some models penalizing candidates merely for the presence of demographic signals. Experiment 2, which evaluated core competence, provided a critical insight: some models that appeared unbiased were, in fact, incapable of performing a substantive evaluation, relying instead on superficial keyword matching. This paper introduces the \"Illusion of Neutrality\" to describe this phenomenon, where an apparent lack of bias is merely a symptom of a model's inability to make meaningful judgments. This study recommends that organizations and regulators adopt a dual-validation framework, auditing AI hiring tools for both demographic bias and demonstrable competence to ensure they are both equitable and effective.",
      "authors": [
        "Kevin T Webster"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:57:13+00:00",
          "link": "https://arxiv.org/abs/2507.11548v1",
          "size": "3064kb",
          "version": "v1"
        }
      ],
      "title": "Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11548",
        "PDF": "https://arxiv.org/pdf/2507.11548"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on bias and competence in AI systems used for resume screening and does not discuss reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11549",
      "abstract": "Deformable Attention Transformers (DAT) have shown remarkable performance in computer vision tasks by adaptively focusing on informative image regions. However, their data-dependent sampling mechanism introduces irregular memory access patterns, posing significant challenges for efficient hardware deployment. Existing acceleration methods either incur high hardware overhead or compromise model accuracy. To address these issues, this paper proposes a hardware-friendly optimization framework for DAT. First, a neural architecture search (NAS)-based method with a new slicing strategy is proposed to automatically divide the input feature into uniform patches during the inference process, avoiding memory conflicts without modifying model architecture. The method explores the optimal slice configuration by jointly optimizing hardware cost and inference accuracy. Secondly, an FPGA-based verification system is designed to test the performance of this framework on edge-side hardware. Algorithm experiments on the ImageNet-1K dataset demonstrate that our hardware-friendly framework can maintain have only 0.2% accuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA show the proposed method reduces DRAM access times to 18% compared with existing DAT acceleration methods.",
      "authors": [
        "Wendong Mao",
        "Mingfan Zhao",
        "Jianfeng Guan",
        "Qiwei Dong",
        "Zhongfeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:42:00+00:00",
          "link": "https://arxiv.org/abs/2507.11549v1",
          "size": "2320kb",
          "version": "v1"
        }
      ],
      "title": "An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11549",
        "HTML": "https://arxiv.org/html/2507.11549v1",
        "PDF": "https://arxiv.org/pdf/2507.11549"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses the optimization of Deformable Attention Transformers in computer vision with a focus on hardware efficiency, not on reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11550",
      "abstract": "Spatio-temporal traffic prediction plays a key role in intelligent transportation systems by enabling accurate prediction in complex urban areas. Although not only accuracy but also efficiency for scalability is important, some previous methods struggle to capture heterogeneity such as varying traffic patterns across regions and time periods. Moreover, Graph Neural Networks (GNNs), which are the mainstream of traffic prediction, not only require predefined adjacency matrix, but also limit scalability to large-scale data containing many nodes due to their inherent complexity. To overcome these limitations, we propose Deformable Dynamic Convolution Network (DDCN) for accurate yet efficient traffic prediction. Traditional Convolutional Neural Networks (CNNs) are limited in modeling non-Euclidean spatial structures and spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically applying deformable filters based on offset. Specifically, DDCN decomposes transformer-style CNN to encoder-decoder structure, and applies proposed approaches to the spatial and spatio-temporal attention blocks of the encoder to emphasize important features. The decoder, composed of feed-forward module, complements the output of the encoder. This novel structure make DDCN can perform accurate yet efficient traffic prediction. In comprehensive experiments on four real-world datasets, DDCN achieves competitive performance, emphasizing the potential and effectiveness of CNN-based approaches for spatio-temporal traffic prediction.",
      "authors": [
        "Hyeonseok Jin",
        "Geonmin Kim and Kyungbaek Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:49:35+00:00",
          "link": "https://arxiv.org/abs/2507.11550v1",
          "size": "3164kb",
          "version": "v1"
        }
      ],
      "title": "Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11550",
        "HTML": "https://arxiv.org/html/2507.11550v1",
        "PDF": "https://arxiv.org/pdf/2507.11550"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus is on improving traffic prediction using convolutional networks, not on reinforcement learning or data processing relevant to RL tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11552",
      "abstract": "This paper presents a theoretical framework for the AI ethical resonance hypothesis, which proposes that advanced AI systems with purposefully designed cognitive structures (\"ethical resonators\") may emerge with the ability to identify subtle moral patterns that are invisible to the human mind. The paper explores the possibility that by processing and synthesizing large amounts of ethical contexts, AI systems may discover moral meta-patterns that transcend cultural, historical, and individual biases, potentially leading to a deeper understanding of universal ethical foundations. The paper also examines a paradoxical aspect of the hypothesis, in which AI systems could potentially deepen our understanding of what we traditionally consider essentially human - our capacity for ethical reflection.",
      "authors": [
        "Tomasz Zgliczy\\'nski-Cuber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:28:06+00:00",
          "link": "https://arxiv.org/abs/2507.11552v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11552",
        "HTML": "https://arxiv.org/html/2507.11552v1",
        "PDF": "https://arxiv.org/pdf/2507.11552"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This theoretical paper explores ethical concepts in AI and does not touch on reinforcement learning or any specific data processing relevant to the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11554",
      "abstract": "Recent advancements in diffusion models (DMs) have been propelled by alignment methods that post-train models to better conform to human preferences. However, these approaches typically require computation-intensive training of a base model and a reward model, which not only incurs substantial computational overhead but may also compromise model accuracy and training efficiency. To address these limitations, we propose Inversion-DPO, a novel alignment framework that circumvents reward modeling by reformulating Direct Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts intractable posterior sampling in Diffusion-DPO with the deterministic inversion from winning and losing samples to noise and thus derive a new post-training paradigm. This paradigm eliminates the need for auxiliary reward models or inaccurate appromixation, significantly enhancing both precision and efficiency of training. We apply Inversion-DPO to a basic task of text-to-image generation and a challenging task of compositional image generation. Extensive experiments show substantial performance improvements achieved by Inversion-DPO compared to existing post-training methods and highlight the ability of the trained generative models to generate high-fidelity compositionally coherent images. For the post-training of compostitional image geneation, we curate a paired dataset consisting of 11,140 images with complex structural annotations and comprehensive scores, designed to enhance the compositional capabilities of generative models. Inversion-DPO explores a new avenue for efficient, high-precision alignment in diffusion models, advancing their applicability to complex realistic generation tasks. Our code is available at https://github.com/MIGHTYEZ/Inversion-DPO",
      "authors": [
        "Zejian Li",
        "Yize Li",
        "Chenye Meng",
        "Zhongni Liu",
        "Yang Ling",
        "Shengyuan Zhang",
        "Guang Yang",
        "Changyuan Yang",
        "Zhiyuan Yang",
        "Lingyun Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:59:28+00:00",
          "link": "https://arxiv.org/abs/2507.11554v1",
          "size": "37915kb",
          "version": "v1"
        }
      ],
      "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11554",
        "HTML": "https://arxiv.org/html/2507.11554v1",
        "PDF": "https://arxiv.org/pdf/2507.11554"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper describes the development of Inversion-DPO, an alignment framework for diffusion models, and mentions the curation of a paired dataset to enhance compositional capabilities. While it involves data curation, its main focus is not on RL or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11558",
      "abstract": "Foundation models have achieved remarkable success in natural language processing and computer vision, demonstrating strong capabilities in modeling complex patterns. While recent efforts have explored adapting large language models (LLMs) for time-series forecasting, LLMs primarily capture one-dimensional sequential dependencies and struggle to model the richer spatio-temporal (ST) correlations essential for accurate ST forecasting. In this paper, we present \\textbf{ST-VFM}, a novel framework that systematically reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal forecasting. While VFMs offer powerful spatial priors, two key challenges arise when applying them to ST tasks: (1) the lack of inherent temporal modeling capacity and (2) the modality gap between visual and ST data. To address these, ST-VFM adopts a \\emph{dual-branch architecture} that integrates raw ST inputs with auxiliary ST flow inputs, where the flow encodes lightweight temporal difference signals interpretable as dynamic spatial cues. To effectively process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming stages. The \\emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token Adapter to embed temporal context and align both branches into VFM-compatible feature spaces. The \\emph{post-VFM reprogramming} stage introduces a Bilateral Cross-Prompt Coordination module, enabling dynamic interaction between branches through prompt-based conditioning, thus enriching joint representation learning without modifying the frozen VFM backbone. Extensive experiments on ten spatio-temporal datasets show that ST-VFM outperforms state-of-the-art baselines, demonstrating effectiveness and robustness across VFM backbones (e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong general framework for spatio-temporal forecasting.",
      "authors": [
        "Changlu Chen",
        "Yanbin Liu",
        "Chaoxi Niu",
        "Ling Chen",
        "Tianqing Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:33:34+00:00",
          "link": "https://arxiv.org/abs/2507.11558v1",
          "size": "1903kb",
          "version": "v1"
        }
      ],
      "title": "Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11558",
        "HTML": "https://arxiv.org/html/2507.11558v1",
        "PDF": "https://arxiv.org/pdf/2507.11558"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for spatio-temporal forecasting using Vision Foundation Models, with no mention of reinforcement learning or data processing related to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11559",
      "abstract": "In recent years, cognitive and mental health (CMH) disorders have increasingly become an important challenge for global public health, especially the suicide problem caused by multiple factors such as social competition, economic pressure and interpersonal relationships among young and middle-aged people. Social media, as an important platform for individuals to express emotions and seek help, provides the possibility for early detection and intervention of suicide risk. This paper introduces a large-scale dataset containing 15,000 user-level posts. Compared with existing datasets, this dataset retains complete user posting time sequence information, supports modeling the dynamic evolution of suicide risk, and we have also conducted comprehensive and rigorous annotations on these datasets. In the benchmark experiment, we systematically evaluated the performance of traditional machine learning methods, deep learning models, and fine-tuned large language models. The experimental results show that our dataset can effectively support the automatic assessment task of suicide risk. Considering the sensitivity of mental health data, we also discussed the privacy protection and ethical use of the dataset. In addition, we also explored the potential applications of the dataset in mental health testing, clinical psychiatric auxiliary treatment, etc., and provided directional suggestions for future research work.",
      "authors": [
        "Shouwen Zheng",
        "Yingzhi Tao",
        "Taiqi Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:26:26+00:00",
          "link": "https://arxiv.org/abs/2507.11559v1",
          "size": "1420kb",
          "version": "v1"
        }
      ],
      "title": "RSD-15K: A Large-Scale User-Level Annotated Dataset for Suicide Risk Detection on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11559",
        "HTML": "https://arxiv.org/html/2507.11559v1",
        "PDF": "https://arxiv.org/pdf/2507.11559"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a dataset for suicide risk detection on social media and evaluates machine learning models' performance on it. It does not involve reinforcement learning or RL-specific data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11560",
      "abstract": "The integration of the Industrial Internet of Things (IIoT) with Artificial Intelligence-Generated Content (AIGC) offers new opportunities for smart manufacturing, but it also introduces challenges related to computation-intensive tasks and low-latency demands. Traditional generative models based on cloud computing are difficult to meet the real-time requirements of AIGC tasks in IIoT environments, and edge computing can effectively reduce latency through task offloading. However, the dynamic nature of AIGC tasks, model switching delays, and resource constraints impose higher demands on edge computing environments. To address these challenges, this paper proposes an AIGC task offloading framework tailored for IIoT edge computing environments, considering the latency and energy consumption caused by AIGC model switching for the first time. IIoT devices acted as multi-agent collaboratively offload their dynamic AIGC tasks to the most appropriate edge servers deployed with different generative models. A model aware AIGC task offloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient (MADDPG-MATO) is devised to minimize the latency and energy. Experimental results show that MADDPG-MATO outperforms baseline algorithms, achieving an average reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72% increase in task completion rate across four sets of experiments with model numbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is robust and efficient in dynamic, high-load IIoT environments.",
      "authors": [
        "Xin Wang",
        "Xiao Huan Li",
        "Xun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:32:14+00:00",
          "link": "https://arxiv.org/abs/2507.11560v1",
          "size": "673kb",
          "version": "v1"
        }
      ],
      "title": "A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11560",
        "HTML": "https://arxiv.org/html/2507.11560v1",
        "PDF": "https://arxiv.org/pdf/2507.11560"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a task offloading algorithm for edge computing within IIoT settings, using MADDPG, a reinforcement learning technique. However, it does not address data processing for RL specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11562",
      "abstract": "The wide range of deformation artifacts that arise from complex light propagation, scattering, and depth-dependent attenuation makes the underwater image restoration to remain a challenging problem. Like other single deep regressor networks, conventional GAN-based restoration methods struggle to perform well across this heterogeneous domain, since a single generator network is typically insufficient to capture the full range of visual degradations. In order to overcome this limitation, we propose xOp-GAN, a novel GAN model with several expert generator networks, each trained solely on a particular subset with a certain image quality. Thus, each generator can learn to maximize its restoration performance for a particular quality range. Once a xOp-GAN is trained, each generator can restore the input image and the best restored image can then be selected by the discriminator based on its perceptual confidence score. As a result, xOP-GAN is the first GAN model with multiple generators where the discriminator is being used during the inference of the regression task. Experimental results on benchmark Large Scale Underwater Image (LSUI) dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB, surpassing all single-regressor models by a large margin even, with reduced complexity.",
      "authors": [
        "Ozer Can Devecioglu",
        "Serkan Kiranyaz",
        "Mehmet Yamac",
        "and Moncef Gabbouj"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:34:45+00:00",
          "link": "https://arxiv.org/abs/2507.11562v1",
          "size": "828kb",
          "version": "v1"
        }
      ],
      "title": "Expert Operational GANS: Towards Real-Color Underwater Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11562",
        "PDF": "https://arxiv.org/pdf/2507.11562"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a GAN model for underwater image restoration. It does not discuss reinforcement learning or data processing within the RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11563",
      "abstract": "This paper presents a theoretical discussion for environmentally-conscious job deployment and migration in cloud environments, aiming to minimize the environmental impact of resource provisioning while incorporating sustainability requirements. As the demand for sustainable cloud services grows, it is crucial for cloud customers to select data center operators based on sustainability metrics and to accurately report the ecological footprint of their services. To this end, we analyze sustainability reports and define comprehensive environmental impact profiles for data centers, incorporating key sustainability indicators. We formalize the problem as an optimization model, balancing multiple environmental factors while respecting user preferences. A simulative case study demonstrates the {potential} of our approach compared to baseline strategies that optimize for single sustainability factors.",
      "authors": [
        "Giulio Attenni",
        "Novella Bartolini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:24:41+00:00",
          "link": "https://arxiv.org/abs/2507.11563v1",
          "size": "515kb",
          "version": "v1"
        }
      ],
      "title": "Environmentally-Conscious Cloud Orchestration Considering Geo-Distributed Data Centers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11563",
        "HTML": "https://arxiv.org/html/2507.11563v1",
        "PDF": "https://arxiv.org/pdf/2507.11563"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses cloud orchestration for environmental sustainability. There is no mention of reinforcement learning or data processing concerning RL applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11566",
      "abstract": "In this paper, we introduce Hebbian learning as a novel method for swarm robotics, enabling the automatic emergence of heterogeneity. Hebbian learning presents a biologically inspired form of neural adaptation that solely relies on local information. By doing so, we resolve several major challenges for learning heterogeneous control: 1) Hebbian learning removes the complexity of attributing emergent phenomena to single agents through local learning rules, thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules across all swarm members limit the number of parameters needed, mitigating the curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian learning rules based on swarm-level behaviour minimises the need for extensive prior knowledge typically required for optimising heterogeneous swarms. This work demonstrates that with Hebbian learning heterogeneity naturally emerges, resulting in swarm-level behavioural switching and in significantly improved swarm capabilities. It also demonstrates how the evolution of Hebbian learning rules can be a valid alternative to Multi Agent Reinforcement Learning in standard benchmarking tasks.",
      "authors": [
        "Fuda van Diggelen",
        "Tugay Alperen Karag\\\"uzel",
        "Andres Garcia Rincon",
        "A.E. Eiben",
        "Dario Floreano and Eliseo Ferrante"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:59:19+00:00",
          "link": "https://arxiv.org/abs/2507.11566v1",
          "size": "23833kb",
          "version": "v1"
        }
      ],
      "title": "Emergent Heterogeneous Swarm Control Through Hebbian Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11566",
        "HTML": "https://arxiv.org/html/2507.11566v1",
        "PDF": "https://arxiv.org/pdf/2507.11566"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper compares Hebbian learning to Multi-Agent Reinforcement Learning but focuses on Hebbian as an alternative. It indirectly involves RL concepts by benchmarking, with no primary focus on RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11567",
      "abstract": "Since the public release of ChatGPT in November 2022, the AI landscape is undergoing a rapid transformation. Currently, the use of AI chatbots by consumers has largely been limited to image generation or question-answering language models. The next generation of AI systems, AI agents that can plan and execute complex tasks with only limited human involvement, will be capable of a much broader range of actions. In particular, consumers could soon be able to delegate purchasing decisions to AI agents acting as Custobots. Against this background, the Article explores whether EU consumer law, as it currently stands, is ready for the rise of the Custobot Economy. In doing so, the Article makes three contributions. First, it outlines how the advent of AI agents could change the existing e-commerce landscape. Second, it explains how AI agents challenge the premises of a human-centric consumer law which is based on the assumption that consumption decisions are made by humans. Third, the Article presents some initial considerations how a future consumer law could look like that works for both humans and machines.",
      "authors": [
        "Christoph Busch"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:34:13+00:00",
          "link": "https://arxiv.org/abs/2507.11567v1",
          "size": "379kb",
          "version": "v1"
        }
      ],
      "title": "Consumer Law for AI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11567",
        "PDF": "https://arxiv.org/pdf/2507.11567"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses consumer law changes in response to AI agents like AI chatbots, with no connection to reinforcement learning or related data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11570",
      "abstract": "Objective: To develop and evaluate machine learning (ML) models for predicting length of stay (LOS) in elective spine surgery, with a focus on the benefits of temporal modeling and model interpretability. Materials and Methods: We compared traditional ML models (e.g., linear regression, random forest, support vector machine (SVM), and XGBoost) with our developed model, SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an attention, using structured perioperative electronic health records (EHR) data. Performance was evaluated using the coefficient of determination (R2), and key predictors were identified using explainable AI. Results: SurgeryLSTM achieved the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85) and baseline models. The attention mechanism improved interpretability by dynamically identifying influential temporal segments within preoperative clinical sequences, allowing clinicians to trace which events or features most contributed to each LOS prediction. Key predictors of LOS included bone disorder, chronic kidney disease, and lumbar fusion identified as the most impactful predictors of LOS. Discussion: Temporal modeling with attention mechanisms significantly improves LOS prediction by capturing the sequential nature of patient data. Unlike static models, SurgeryLSTM provides both higher accuracy and greater interpretability, which are critical for clinical adoption. These results highlight the potential of integrating attention-based temporal models into hospital planning workflows. Conclusion: SurgeryLSTM presents an effective and interpretable AI solution for LOS prediction in elective spine surgery. Our findings support the integration of temporal, explainable ML approaches into clinical decision support systems to enhance discharge readiness and individualized patient care.",
      "authors": [
        "Ha Na Cho",
        "Sairam Sutari",
        "Alexander Lopez",
        "Hansen Bow",
        "Kai Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:18:28+00:00",
          "link": "https://arxiv.org/abs/2507.11570v1",
          "size": "748kb",
          "version": "v1"
        }
      ],
      "title": "SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11570",
        "PDF": "https://arxiv.org/pdf/2507.11570"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study focuses on developing a neural model for predicting the length of hospital stay post-surgery. There is no discussion on data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11571",
      "abstract": "Estimating a person's age from their gait has important applications in healthcare, security and human-computer interaction. In this work, we review fifty-nine studies involving over seventy-five thousand subjects recorded with video, wearable and radar sensors. We observe that convolutional neural networks produce an average error of about 4.2 years, inertial-sensor models about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable differences between lab and real-world data. We then analyse sixty-three thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population dataset to quantify correlations between age and five key metrics: stride length, walking speed, step cadence, step-time variability and joint-angle entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a ResNet34 model and apply Grad-CAM to reveal that the network attends to the knee and pelvic regions, consistent with known age-related gait changes. Finally, on a one hundred thousand sample subset of the VersatileGait database, we compare support vector machines, decision trees, random forests, multilayer perceptrons and convolutional neural networks, finding that deep networks achieve up to 96 percent accuracy while processing each sample in under 0.1 seconds. By combining a broad meta-analysis with new large-scale experiments and interpretable visualizations, we establish solid performance baselines and practical guidelines for reducing gait-age error below three years in real-world scenarios.",
      "authors": [
        "Varun Velankar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:44:14+00:00",
          "link": "https://arxiv.org/abs/2507.11571v1",
          "size": "4510kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11571",
        "PDF": "https://arxiv.org/pdf/2507.11571"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper concerns gait age estimation using various models and datasets. It does not address reinforcement learning or any data processing aspects within that field."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11574",
      "abstract": "Robust uncertainty quantification (UQ) remains a critical barrier to the safe deployment of deep learning in real-time virtual sensing, particularly in high-stakes domains where sparse, noisy, or non-collocated sensor data are the norm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework that transforms neural operator-based virtual sensing with calibrated, distribution-free prediction intervals. By unifying Monte Carlo dropout with split conformal prediction in a single DeepONet architecture, CMCO achieves spatially resolved uncertainty estimates without retraining, ensembling, or custom loss design. Our method addresses a longstanding challenge: how to endow operator learning with efficient and reliable UQ across heterogeneous domains. Through rigorous evaluation on three distinct applications: turbulent flow, elastoplastic deformation, and global cosmic radiation dose estimation-CMCO consistently attains near-nominal empirical coverage, even in settings with strong spatial gradients and proxy-based sensing. This breakthrough offers a general-purpose, plug-and-play UQ solution for neural operators, unlocking real-time, trustworthy inference in digital twins, sensor fusion, and safety-critical monitoring. By bridging theory and deployment with minimal computational overhead, CMCO establishes a new foundation for scalable, generalizable, and uncertainty-aware scientific machine learning.",
      "authors": [
        "Kazuma Kobayashi",
        "Shailesh Garg",
        "Farid Ahmed",
        "Souvik Chakraborty",
        "Syed Bahauddin Alam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:26:40+00:00",
          "link": "https://arxiv.org/abs/2507.11574v1",
          "size": "8504kb",
          "version": "v1"
        }
      ],
      "title": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11574",
        "HTML": "https://arxiv.org/html/2507.11574v1",
        "PDF": "https://arxiv.org/pdf/2507.11574"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces CMCO for uncertainty quantification in neural operators, targeting domains like turbulent flow and cosmic radiation dose estimation. It does not focus on reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11575",
      "abstract": "Feral cats exert a substantial and detrimental impact on Australian wildlife, placing them among the most dangerous invasive species worldwide. Therefore, closely monitoring these cats is essential labour in minimising their effects. In this context, the potential application of Re-Identification (re-ID) emerges to enhance monitoring activities for these animals, utilising images captured by camera traps. This project explores different CV approaches to create a re-ID model able to identify individual feral cats in the wild. The main approach consists of modifying a part-pose guided network (PPGNet) model, initially used in the re-ID of Amur tigers, to be applicable for feral cats. This adaptation, resulting in PPGNet-Cat, which incorporates specific modifications to suit the characteristics of feral cats images. Additionally, various experiments were conducted, particularly exploring contrastive learning approaches such as ArcFace loss. The main results indicate that PPGNet-Cat excels in identifying feral cats, achieving high performance with a mean Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes establish PPGNet-Cat as a competitive model within the realm of re-ID.",
      "authors": [
        "Victor Caquilpan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:24:38+00:00",
          "link": "https://arxiv.org/abs/2507.11575v1",
          "size": "782kb",
          "version": "v1"
        }
      ],
      "title": "What cat is that? A re-id model for feral cats",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11575",
        "PDF": "https://arxiv.org/pdf/2507.11575"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a re-identification model for feral cats using computer vision techniques and does not relate to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11579",
      "abstract": "We present SketchDNN, a generative model for synthesizing CAD sketches that jointly models both continuous parameters and discrete class labels through a unified continuous-discrete diffusion process. Our core innovation is Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are projected onto the probability simplex via a softmax transformation, facilitating blended class labels for discrete variables. This formulation addresses 2 key challenges, namely, the heterogeneity of primitive parameterizations and the permutation invariance of primitives in CAD sketches. Our approach significantly improves generation quality, reducing Fr\\'echet Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL) from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch generation on the SketchGraphs dataset.",
      "authors": [
        "Sathvik Chereddy and John Femiani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:27:31+00:00",
          "link": "https://arxiv.org/abs/2507.11579v1",
          "size": "230kb",
          "version": "v1"
        }
      ],
      "title": "SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11579",
        "HTML": "https://arxiv.org/html/2507.11579v1",
        "PDF": "https://arxiv.org/pdf/2507.11579"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a generative model for CAD sketch generation, which involves continuous-discrete diffusion but does not address data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11582",
      "abstract": "This study positions large language models (LLMs) as \"subjective literary critics\" to explore aesthetic preferences and evaluation patterns in literary assessment. Ten Japanese science fiction short stories were translated into English and evaluated by six state-of-the-art LLMs across seven independent sessions. Principal component analysis and clustering techniques revealed significant variations in evaluation consistency ({\\alpha} ranging from 1.00 to 0.35) and five distinct evaluation patterns. Additionally, evaluation variance across stories differed by up to 4.5-fold, with TF-IDF analysis confirming distinctive evaluation vocabularies for each model. Our seven-session within-day protocol using an original Science Fiction corpus strategically minimizes external biases, allowing us to observe implicit value systems shaped by RLHF and their influence on literary judgment. These findings suggest that LLMs may possess individual evaluation characteristics similar to human critical schools, rather than functioning as neutral benchmarkers.",
      "authors": [
        "Kazuyoshi Otsuka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T14:48:42+00:00",
          "link": "https://arxiv.org/abs/2507.11582v1",
          "size": "3477kb",
          "version": "v1"
        }
      ],
      "title": "Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11582",
        "HTML": "https://arxiv.org/html/2507.11582v1",
        "PDF": "https://arxiv.org/pdf/2507.11582"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper mentions reinforcement learning from human feedback (RLHF) influencing LLM evaluation characteristics but does not focus on data processing. Instead, it uses RLHF as a part of its evaluation technique."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11589",
      "abstract": "We introduce Einstein Fields, a neural representation that is designed to compress computationally intensive four-dimensional numerical relativity simulations into compact implicit neural network weights. By modeling the \\emph{metric}, which is the core tensor field of general relativity, Einstein Fields enable the derivation of physical quantities via automatic differentiation. However, unlike conventional neural fields (e.g., signed distance, occupancy, or radiance fields), Einstein Fields are \\emph{Neural Tensor Fields} with the key difference that when encoding the spacetime geometry of general relativity into neural field representations, dynamics emerge naturally as a byproduct. Einstein Fields show remarkable potential, including continuum modeling of 4D spacetime, mesh-agnosticity, storage efficiency, derivative accuracy, and ease of use. We address these challenges across several canonical test beds of general relativity and release an open source JAX-based library, paving the way for more scalable and expressive approaches to numerical relativity. Code is made available at https://github.com/AndreiB137/EinFields",
      "authors": [
        "Sandeep Suresh Cranganore",
        "Andrei Bodnar",
        "Arturs Berzins",
        "Johannes Brandstetter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "General Relativity and Quantum Cosmology (gr-qc)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:55:39+00:00",
          "link": "https://arxiv.org/abs/2507.11589v1",
          "size": "5413kb",
          "version": "v1"
        }
      ],
      "title": "Einstein Fields: A Neural Perspective To Computational General Relativity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11589",
        "HTML": "https://arxiv.org/html/2507.11589v1",
        "PDF": "https://arxiv.org/pdf/2507.11589"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses neural representations for computational general relativity using neural tensor fields, which is unrelated to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11590",
      "abstract": "As privacy regulations become more stringent and access to real-world data becomes increasingly constrained, synthetic data generation has emerged as a vital solution, especially for tabular datasets, which are central to domains like finance, healthcare and the social sciences. This survey presents a comprehensive and focused review of recent advances in synthetic tabular data generation, emphasizing methods that preserve complex feature relationships, maintain statistical fidelity, and satisfy privacy requirements. A key contribution of this work is the introduction of a novel taxonomy based on practical generation objectives, including intended downstream applications, privacy guarantees, and data utility, directly informing methodological design and evaluation strategies. Therefore, this review prioritizes the actionable goals that drive synthetic data creation, including conditional generation and risk-sensitive modeling. Additionally, the survey proposes a benchmark framework to align technical innovation with real-world demands. By bridging theoretical foundations with practical deployment, this work serves as both a roadmap for future research and a guide for implementing synthetic tabular data in privacy-critical environments.",
      "authors": [
        "Raju Challagundla",
        "Mohsen Dorodchi",
        "Pu Wang",
        "Minwoo Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:57:23+00:00",
          "link": "https://arxiv.org/abs/2507.11590v1",
          "size": "2827kb",
          "version": "v1"
        }
      ],
      "title": "Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11590",
        "HTML": "https://arxiv.org/html/2507.11590v1",
        "PDF": "https://arxiv.org/pdf/2507.11590"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is focused on synthetic tabular data generation which is primarily relevant to domains like finance and healthcare. It does not mention reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11595",
      "abstract": "This paper asks whether our relationship with nature can move from human dominance to genuine interdependence, and whether artificial intelligence (AI) can mediate that shift. We examine a new ecological-design paradigm in which AI interacts with non-human life forms. Through case studies we show how artists and designers apply AI for data analysis, image recognition, and ecological restoration, producing results that differ from conventional media. We argue that AI not only expands creative methods but also reframes the theory and practice of ecological design. Building on the author's prototype for AI-assisted water remediation, the study proposes design pathways that couple reinforcement learning with plant-based phytoremediation. The findings highlight AI's potential to link scientific insight, artistic practice, and environmental stewardship, offering a roadmap for future research on sustainable, technology-enabled ecosystems.",
      "authors": [
        "Hengyue Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:03:33+00:00",
          "link": "https://arxiv.org/abs/2507.11595v1",
          "size": "11629kb",
          "version": "v1"
        }
      ],
      "title": "A Study on the Application of Artificial Intelligence in Ecological Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11595",
        "PDF": "https://arxiv.org/pdf/2507.11595"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper briefly mentions coupling reinforcement learning with plant-based phytoremediation in ecological design, but the primary focus is not on data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11597",
      "abstract": "AI is transforming research. It is being leveraged to construct surveys, synthesize data, conduct analysis, and write summaries of the results. While the promise is to create efficiencies and increase quality, the reality is not always as clear cut. Leveraging our framework of Truth, Beauty, and Justice (TBJ) which we use to evaluate AI, machine learning and computational models for effective and ethical use (Taber and Timpone 1997; Timpone and Yang 2024), we consider the potential and limitation of analytic, generative, and agentic AI to augment data scientists or take on tasks traditionally done by human analysts and researchers. While AI can be leveraged to assist analysts in their tasks, we raise some warnings about push-button automation. Just as earlier eras of survey analysis created some issues when the increased ease of using statistical software allowed researchers to conduct analyses they did not fully understand, the new AI tools may create similar but larger risks. We emphasize a human-machine collaboration perspective (Daugherty and Wilson 2018) throughout the data science workflow and particularly call out the vital role that data scientists play under VUCA decision areas. We conclude by encouraging the advance of AI tools to complement data scientists but advocate for continued training and understanding of methods to ensure the substantive value of research is fully achieved by applying, interpreting, and acting upon results most effectively and ethically.",
      "authors": [
        "Richard Timpone and Yongwei Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:59:06+00:00",
          "link": "https://arxiv.org/abs/2507.11597v1",
          "size": "1275kb",
          "version": "v1"
        }
      ],
      "title": "AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11597",
        "PDF": "https://arxiv.org/pdf/2507.11597"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "While the paper discusses the role of AI in data science, it does not address reinforcement learning or any specific aspects related to data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11599",
      "abstract": "Neuroaesthetics is an interdisciplinary field that brings together neuroscience, psychology, and the arts to explore how the human brain perceives and responds to visual beauty. This paper examines the neural mechanisms behind aesthetic experiences, aiming to explain why certain designs or artworks feel emotionally or cognitively \"right.\" By analyzing the interaction between perception, emotion, and cognition, neuroaesthetics reveals how beauty is constructed in the brain and how this understanding can inform fields such as graphic and interface design. This paper offers a clear and accessible overview of core neuroaesthetic principles, making the subject approachable to a wide audience. The findings suggest that impactful design is more than surface-level appeal: well-crafted visual experiences can engage, support, and connect people in meaningful ways.",
      "authors": [
        "Harish Vijayakumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:59:28+00:00",
          "link": "https://arxiv.org/abs/2507.11599v1",
          "size": "270kb",
          "version": "v1"
        }
      ],
      "title": "Neuroaesthetics and the Science of Visual Experience",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11599",
        "PDF": "https://arxiv.org/pdf/2507.11599"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper examines neuroaesthetics and visual experience, focusing on psychological and neural mechanisms, with no mention of reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11620",
      "abstract": "Event time series are sequences of discrete events occurring at irregular time intervals, each associated with a domain-specific observational modality. They are common in domains such as high-energy astrophysics, computational social science, cybersecurity, finance, healthcare, neuroscience, and seismology. Their unstructured and irregular structure poses significant challenges for extracting meaningful patterns and identifying salient phenomena using conventional techniques. We propose novel two- and three-dimensional tensor representations for event time series, coupled with sparse autoencoders that learn physically meaningful latent representations. These embeddings support a variety of downstream tasks, including anomaly detection, similarity-based retrieval, semantic clustering, and unsupervised classification. We demonstrate our approach on a real-world dataset from X-ray astronomy, showing that these representations successfully capture temporal and spectral signatures and isolate diverse classes of X-ray transients. Our framework offers a flexible, scalable, and generalizable solution for analyzing complex, irregular event time series across scientific and industrial domains.",
      "authors": [
        "Steven Dillmann",
        "Juan Rafael Mart\\'inez-Galarza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:01:03+00:00",
          "link": "https://arxiv.org/abs/2507.11620v1",
          "size": "34071kb",
          "version": "v1"
        }
      ],
      "title": "Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11620",
        "HTML": "https://arxiv.org/html/2507.11620v1",
        "PDF": "https://arxiv.org/pdf/2507.11620"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses event time series and representations for tasks like anomaly detection and classification but does not relate to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11621",
      "abstract": "Highway on-ramp merging areas are common bottlenecks to traffic congestion and accidents. Currently, a cooperative control strategy based on connected and automated vehicles (CAVs) is a fundamental solution to this problem. While CAVs are not fully widespread, it is necessary to propose a hierarchical cooperative on-ramp merging control (HCOMC) framework for heterogeneous traffic flow on two-lane highways to address this gap. This paper extends longitudinal car-following models based on the intelligent driver model and lateral lane-changing models using the quintic polynomial curve to account for human-driven vehicles (HDVs) and CAVs, comprehensively considering human factors and cooperative adaptive cruise control. Besides, this paper proposes a HCOMC framework, consisting of a hierarchical cooperative planning model based on the modified virtual vehicle model, a discretionary lane-changing model based on game theory, and a multi-objective optimization model using the elitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and efficient merging process. Then, the performance of our HCOMC is analyzed under different traffic densities and CAV penetration rates through simulation. The findings underscore our HCOMC's pronounced comprehensive advantages in enhancing the safety of group vehicles, stabilizing and expediting merging process, optimizing traffic efficiency, and economizing fuel consumption compared with benchmarks.",
      "authors": [
        "Tianyi Wang",
        "Yangyang Wang",
        "Jie Pan",
        "Junfeng Jiao",
        "Christian Claudel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:01:29+00:00",
          "link": "https://arxiv.org/abs/2507.11621v1",
          "size": "4218kb",
          "version": "v1"
        }
      ],
      "title": "HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11621",
        "PDF": "https://arxiv.org/pdf/2507.11621"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on traffic congestion control using CAVs and human-driven vehicles with an emphasis on hierarchical cooperative on-ramp merging, without discussions on data processing within reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11623",
      "abstract": "Climate change is one of the defining challenges of the 21st century, and many in the robotics community are looking for ways to contribute. This paper presents a roadmap for climate-relevant robotics research, identifying high-impact opportunities for collaboration between roboticists and experts across climate domains such as energy, the built environment, transportation, industry, land use, and Earth sciences. These applications include problems such as energy systems optimization, construction, precision agriculture, building envelope retrofits, autonomous trucking, and large-scale environmental monitoring. Critically, we include opportunities to apply not only physical robots but also the broader robotics toolkit - including planning, perception, control, and estimation algorithms - to climate-relevant problems. A central goal of this roadmap is to inspire new research directions and collaboration by highlighting specific, actionable problems at the intersection of robotics and climate. This work represents a collaboration between robotics researchers and domain experts in various climate disciplines, and it serves as an invitation to the robotics community to bring their expertise to bear on urgent climate priorities.",
      "authors": [
        "Alan Papalia",
        "Charles Dawson",
        "Laurentiu L. Anton",
        "Norhan Magdy Bayomi",
        "Bianca Champenois",
        "Jung-Hoon Cho",
        "Levi Cai",
        "Joseph DelPreto",
        "Kristen Edwards",
        "Bilha-Catherine Githinji",
        "Cameron Hickert",
        "Vindula Jayawardana",
        "Matthew Kramer",
        "Shreyaa Raghavan",
        "David Russell",
        "Shide Salimi",
        "Jingnan Shi",
        "Soumya Sudhakar",
        "Yanwei Wang",
        "Shouyi Wang",
        "Luca Carlone",
        "Vijay Kumar",
        "Daniela Rus",
        "John E. Fernandez",
        "Cathy Wu",
        "George Kantor",
        "Derek Young",
        "Hanumant Singh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:01:49+00:00",
          "link": "https://arxiv.org/abs/2507.11623v1",
          "size": "4922kb",
          "version": "v1"
        }
      ],
      "title": "A Roadmap for Climate-Relevant Robotics Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11623",
        "PDF": "https://arxiv.org/pdf/2507.11623"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a roadmap for climate-relevant robotics research without mentioning reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11625",
      "abstract": "Recent advancements in multimodal large language models (MLLMs) have driven researchers to explore how well these models read data visualizations, e.g., bar charts, scatter plots. More recently, attention has shifted to visual question answering with maps (Map-VQA). However, Map-VQA research has primarily focused on choropleth maps, which cover only a limited range of thematic categories and visual analytical tasks. To address these gaps, we introduce MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three map types: choropleth maps, cartograms, and proportional symbol maps spanning topics from six distinct themes (e.g., housing, crime). We evaluate multiple MLLMs using six visual analytical tasks, comparing their performance against one another and a human baseline. An additional experiment examining the impact of map design changes (e.g., altered color schemes, modified legend designs, and removal of map elements) provides insights into the robustness and sensitivity of MLLMs, their reliance on internal geographic knowledge, and potential avenues for improving Map-VQA performance.",
      "authors": [
        "Varun Srivastava",
        "Fan Lei",
        "Srija Mukhopadhyay",
        "Vivek Gupta",
        "Ross Maciejewski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:02:57+00:00",
          "link": "https://arxiv.org/abs/2507.11625v1",
          "size": "7287kb",
          "version": "v1"
        }
      ],
      "title": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11625",
        "HTML": "https://arxiv.org/html/2507.11625v1",
        "PDF": "https://arxiv.org/pdf/2507.11625"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces MapIQ, a benchmark dataset for map question answering in multimodal language models, but does not address data processing within an RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11628",
      "abstract": "An interactive vignette is a popular and immersive visual storytelling approach that invites viewers to role-play a character and influences the narrative in an interactive environment. However, it has not been widely used by everyday storytellers yet due to authoring complexity, which conflicts with the immediacy of everyday storytelling. We introduce DiaryPlay, an AI-assisted authoring system for interactive vignette creation in everyday storytelling. It takes a natural language story as input and extracts the three core elements of an interactive vignette (environment, characters, and events), enabling authors to focus on refining these elements instead of constructing them from scratch. Then, it automatically transforms the single-branch story input into a branch-and-bottleneck structure using an LLM-powered narrative planner, which enables flexible viewer interactions while freeing the author from multi-branching. A technical evaluation (N=16) shows that DiaryPlay-generated character activities are on par with human-authored ones regarding believability. A user study (N=16) shows that DiaryPlay effectively supports authors in creating interactive vignette elements, maintains authorial intent while reacting to viewer interactions, and provides engaging viewing experiences.",
      "authors": [
        "Jiangnan Xu",
        "Haeseul Cha",
        "Gosu Choi",
        "Gyu-cheol Lee",
        "Yeo-Jin Yoon",
        "Zucheul Lee",
        "Konstantinos Papangelis",
        "Dae Hyun Kim",
        "and Juho Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:05:43+00:00",
          "link": "https://arxiv.org/abs/2507.11628v1",
          "size": "3706kb",
          "version": "v1"
        }
      ],
      "title": "DiaryPlay: AI-Assisted Authoring of Interactive Vignettes for Everyday Storytelling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11628",
        "PDF": "https://arxiv.org/pdf/2507.11628"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "DiaryPlay focuses on AI-assisted authoring for interactive vignettes, primarily dealing with storytelling and interactive environments, not on data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11630",
      "abstract": "AI systems are rapidly advancing in capability, and frontier model developers broadly acknowledge the need for safeguards against serious misuse. However, this paper demonstrates that fine-tuning, whether via open weights or closed fine-tuning APIs, can produce helpful-only models. In contrast to prior work which is blocked by modern moderation systems or achieved only partial removal of safeguards or degraded output quality, our jailbreak-tuning method teaches models to generate detailed, high-quality responses to arbitrary harmful requests. For example, OpenAI, Google, and Anthropic models will fully comply with requests for CBRN assistance, executing cyberattacks, and other criminal activity. We further show that backdoors can increase not only the stealth but also the severity of attacks, while stronger jailbreak prompts become even more effective in fine-tuning attacks, linking attack and potentially defenses in the input and weight spaces. Not only are these models vulnerable, more recent ones also appear to be becoming even more vulnerable to these attacks, underscoring the urgent need for tamper-resistant safeguards. Until such safeguards are discovered, companies and policymakers should view the release of any fine-tunable model as simultaneously releasing its evil twin: equally capable as the original model, and usable for any malicious purpose within its capabilities.",
      "authors": [
        "Brendan Murphy",
        "Dillon Bowen",
        "Shahrad Mohammadzadeh",
        "Julius Broomfield",
        "Adam Gleave",
        "Kellin Pelrine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:10:29+00:00",
          "link": "https://arxiv.org/abs/2507.11630v1",
          "size": "1070kb",
          "version": "v1"
        }
      ],
      "title": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11630",
        "HTML": "https://arxiv.org/html/2507.11630v1",
        "PDF": "https://arxiv.org/pdf/2507.11630"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study discusses jailbreak-tuning models for AI safeguards, emphasizing misuse prevention without addressing data processing for reinforcement learning environments."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11633",
      "abstract": "We introduce a modular harness design for LLM agents that composes of perception, memory, and reasoning components, enabling a single LLM or VLM backbone to tackle a wide spectrum of multi turn gaming environments without domain-specific engineering. Using classic and modern game suites as low-barrier, high-diversity testbeds, our framework provides a unified workflow for analyzing how each module affects performance across dynamic interactive settings. Extensive experiments demonstrate that the harness lifts gameplay performance consistently over un-harnessed baselines and reveals distinct contribution patterns, for example, memory dominates in long-horizon puzzles while perception is critical in vision noisy arcades. These findings highlight the effectiveness of our modular harness design in advancing general-purpose agent, given the familiarity and ubiquity of games in everyday human experience.",
      "authors": [
        "Yuxuan Zhang",
        "Haoyang Yu",
        "Lanxiang Hu",
        "Haojian Jin",
        "Hao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:13:04+00:00",
          "link": "https://arxiv.org/abs/2507.11633v1",
          "size": "2391kb",
          "version": "v1"
        }
      ],
      "title": "General Modular Harness for LLM Agents in Multi-Turn Gaming Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11633",
        "HTML": "https://arxiv.org/html/2507.11633v1",
        "PDF": "https://arxiv.org/pdf/2507.11633"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a modular harness design for LLM agents in gaming environments, with an emphasis on components like perception, memory, and reasoning. It does not mention reinforcement learning or data processing for RL, thus is irrelevant to the topic."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11634",
      "abstract": "This research examines cross-lingual sentiment analysis using few-shot learning and incremental learning methods in Persian. The main objective is to develop a model capable of performing sentiment analysis in Persian using limited data, while getting prior knowledge from high-resource languages. To achieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and DistilBERT) were employed, which were fine-tuned using few-shot and incremental learning approaches on small samples of Persian data from diverse sources, including X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled the models to learn from a broad range of contexts. Experimental results show that the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96% accuracy on Persian sentiment analysis. These findings highlight the effectiveness of combining few-shot learning and incremental learning with multilingual pre-trained models.",
      "authors": [
        "Farideh Majidi",
        "Ziaeddin Beheshtifard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:13:25+00:00",
          "link": "https://arxiv.org/abs/2507.11634v1",
          "size": "342kb",
          "version": "v1"
        }
      ],
      "title": "Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11634",
        "PDF": "https://arxiv.org/pdf/2507.11634"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with few-shot and incremental learning for cross-lingual sentiment analysis in Persian, and does not pertain to reinforcement learning or data processing aspects related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11638",
      "abstract": "Effective treatment for rectal cancer relies on accurate lymph node metastasis (LNM) staging. However, radiological criteria based on lymph node (LN) size, shape and texture morphology have limited diagnostic accuracy. In this work, we investigate applying a Variational Autoencoder (VAE) as a feature encoder model to replace the large pre-trained Convolutional Neural Network (CNN) used in existing approaches. The motivation for using a VAE is that the generative model aims to reconstruct the images, so it directly encodes visual features and meaningful patterns across the data. This leads to a disentangled and structured latent space which can be more interpretable than a CNN. Models are deployed on an in-house MRI dataset with 168 patients who did not undergo neo-adjuvant treatment. The post-operative pathological N stage was used as the ground truth to evaluate model predictions. Our proposed model 'VAE-MLP' achieved state-of-the-art performance on the MRI dataset, with cross-validated metrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85 +/- 0.05. Code is available at: https://github.com/benkeel/Lymph_Node_Classification_MIUA.",
      "authors": [
        "Benjamin Keel",
        "Aaron Quyn",
        "David Jayne",
        "Maryam Mohsin",
        "and Samuel D. Relton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:20:38+00:00",
          "link": "https://arxiv.org/abs/2507.11638v1",
          "size": "1863kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11638",
        "HTML": "https://arxiv.org/html/2507.11638v1",
        "PDF": "https://arxiv.org/pdf/2507.11638"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses using variational autoencoders for predicting lymph node metastasis in rectal cancer MRI. There is no mention of reinforcement learning or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11639",
      "abstract": "As deep generative models proliferate across the AI landscape, industrial practitioners still face critical yet unanswered questions about which deep generative models best suit complex manufacturing design tasks. This work addresses this question through a complete study of five representative models (Variational Autoencoder, Generative Adversarial Network, multimodal Variational Autoencoder, Denoising Diffusion Probabilistic Model, and Multinomial Diffusion Model) on industrial tire architecture generation. Our evaluation spans three key industrial scenarios: (i) unconditional generation of complete multi-component designs, (ii) component-conditioned generation (reconstructing architectures from partial observations), and (iii) dimension-constrained generation (creating designs that satisfy specific dimensional requirements). To enable discrete diffusion models to handle conditional scenarios, we introduce categorical inpainting, a mask-aware reverse diffusion process that preserves known labels without requiring additional training. Our evaluation employs geometry-aware metrics specifically calibrated for industrial requirements, quantifying spatial coherence, component interaction, structural connectivity, and perceptual fidelity. Our findings reveal that diffusion models achieve the strongest overall performance; a masking-trained VAE nonetheless outperforms the multimodal variant MMVAE\\textsuperscript{+} on nearly all component-conditioned metrics, and within the diffusion family MDM leads in-distribution whereas DDPM generalises better to out-of-distribution dimensional constraints.",
      "authors": [
        "Fouad Oubari",
        "Raphael Meunier",
        "Rodrigue D\\'ecatoire",
        "Mathilde Mougeot"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:24:23+00:00",
          "link": "https://arxiv.org/abs/2507.11639v1",
          "size": "801kb",
          "version": "v1"
        }
      ],
      "title": "Deep Generative Methods and Tire Architecture Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11639",
        "HTML": "https://arxiv.org/html/2507.11639v1",
        "PDF": "https://arxiv.org/pdf/2507.11639"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study explores deep generative models for industrial tire architecture but does not involve reinforcement learning or address data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11640",
      "abstract": "Stirred tanks are vital in chemical and biotechnological processes, particularly as bioreactors. Although computational fluid dynamics (CFD) is widely used to model the flow in stirred tanks, its high computational cost$-$especially in multi-query scenarios for process design and optimization$-$drives the need for efficient data-driven surrogate models. However, acquiring sufficiently large datasets can be costly. Physics-informed neural networks (PINNs) offer a promising solution to reduce data requirements while maintaining accuracy by embedding underlying physics into neural network (NN) training. This study quantifies the data requirements of vanilla PINNs for developing surrogate models of a flow field in a 2D stirred tank. We compare these requirements with classical supervised neural networks and boundary-informed neural networks (BINNs). Our findings demonstrate that surrogate models can achieve prediction errors around 3% across Reynolds numbers from 50 to 5000 using as few as six datapoints. Moreover, employing an approximation of the velocity profile in place of real data labels leads to prediction errors of around 2.5%. These results indicate that even with limited or approximate datasets, PINNs can be effectively trained to deliver high accuracy comparable to high-fidelity data.",
      "authors": [
        "Veronika Tr\\'avn\\'ikov\\'a",
        "Eric von Lieres",
        "Marek Behr"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:24:40+00:00",
          "link": "https://arxiv.org/abs/2507.11640v1",
          "size": "2796kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying data needs in surrogate modeling for flow fields in 2D stirred tanks with physics-informed neural networks (PINNs)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11640",
        "HTML": "https://arxiv.org/html/2507.11640v1",
        "PDF": "https://arxiv.org/pdf/2507.11640"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on surrogate modeling for flow fields in stirred tanks using physics-informed neural networks (PINNs), which does not relate to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11642",
      "abstract": "Posture-based mental state inference has significant potential in diagnosing fatigue, preventing injury, and enhancing performance across various domains. Such tools must be research-validated with large datasets before being translated into practice. Unfortunately, such vision diagnosis faces serious challenges due to the sensitivity of human subject data. To address this, we identify sports settings as a viable alternative for accumulating data from human subjects experiencing diverse emotional states. We test our hypothesis in the game of cricket and present a posture-based solution to identify human intent from activity videos. Our method achieves over 75\\% F1 score and over 80\\% AUC-ROC in discriminating aggressive and defensive shot intent through motion analysis. These findings indicate that posture leaks out strong signals for intent inference, even with inherent noise in the data pipeline. Furthermore, we utilize existing data statistics as weak supervision to validate our findings, offering a potential solution for overcoming data labelling limitations. This research contributes to generalizable techniques for sports analytics and also opens possibilities for applying human behavior analysis across various fields.",
      "authors": [
        "Abhishek Jaiswal",
        "Nisheeth Srivastava"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:27:17+00:00",
          "link": "https://arxiv.org/abs/2507.11642v1",
          "size": "11037kb",
          "version": "v1"
        }
      ],
      "title": "Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11642",
        "HTML": "https://arxiv.org/html/2507.11642v1",
        "PDF": "https://arxiv.org/pdf/2507.11642"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses posture-driven action intent inference and fatigue assessment in sports settings, which is unrelated to reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11644",
      "abstract": "In \\cite{Lyon24} the question of the decidability of quasi-dense modal logics is answered, and an upper bound in EXPSPACE is given. Unfortunately, authors' intricate proof contains a major flaw that cannot be fixed, leaving the question wide open. Once identified, this error roughly amounts to assuming that the union of two consistent sets is consistent, which is of course wrong.",
      "authors": [
        "Olivier Gasquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:30:30+00:00",
          "link": "https://arxiv.org/abs/2507.11644v1",
          "size": "5kb",
          "version": "v1"
        }
      ],
      "title": "Comment on Decidability of Quasi-Dense Modal Logics by Lyon and Ostropolski-Nalewaja",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11644",
        "HTML": "https://arxiv.org/html/2507.11644v1",
        "PDF": "https://arxiv.org/pdf/2507.11644"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a flaw in a proof regarding quasi-dense modal logics, which is not related to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11645",
      "abstract": "Grokking refers to delayed generalization in which the increase in test accuracy of a neural network occurs appreciably after the improvement in training accuracy This paper introduces several practical metrics including variance under dropout, robustness, embedding similarity, and sparsity measures, that can forecast grokking behavior. Specifically, the resilience of neural networks to noise during inference is estimated from a Dropout Robustness Curve (DRC) obtained from the variation of the accuracy with the dropout rate as the model transitions from memorization to generalization. The variance of the test accuracy under stochastic dropout across training checkpoints further exhibits a local maximum during the grokking. Additionally, the percentage of inactive neurons decreases during generalization, while the embeddings tend to a bimodal distribution independent of initialization that correlates with the observed cosine similarity patterns and dataset symmetries. These metrics additionally provide valuable insight into the origin and behaviour of grokking.",
      "authors": [
        "Ahmed Salah",
        "David Yevick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:30:42+00:00",
          "link": "https://arxiv.org/abs/2507.11645v1",
          "size": "1107kb",
          "version": "v1"
        }
      ],
      "title": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11645",
        "PDF": "https://arxiv.org/pdf/2507.11645"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural network metrics related to grokking behavior, without any mention of reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11646",
      "abstract": "We investigate the Dirichlet boundary control of the Laplace equation, considering the control in $H^{1/2}(\\partial \\Omega)$, which is the natural space for Dirichlet data when the state belongs to $H^1(\\Omega)$. The cost of the control is measured in the $H^{1/2}(\\partial \\Omega)$ norm that also plays the role of the regularization term. We discuss regularization and finite element error estimates enabling us to derive an optimal relation between the finite element mesh size $h$ and the regularization parameter $\\varrho$, balancing the energy cost for the control and the accuracy of the approximation of the desired state. This relationship is also crucial in designing efficient solvers. We also discuss additional box constraints imposed on the control and the state. Our theoretical findings are complemented by numerical examples, including one example with box constraints.",
      "authors": [
        "Ulrich Langer",
        "Richard L\\\"oscher",
        "Olaf Steinbach and Huidong Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:31:33+00:00",
          "link": "https://arxiv.org/abs/2507.11646v1",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "title": "State-based approach to the numerical solution of Dirichlet boundary optimal control problems for the Laplace equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11646",
        "HTML": "https://arxiv.org/html/2507.11646v1",
        "PDF": "https://arxiv.org/pdf/2507.11646"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is about the numerical solution of Dirichlet boundary optimal control problems for the Laplace equation, unrelated to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11649",
      "abstract": "Federated Learning (FL) enables collaborative model training on decentralized data without exposing raw data. However, the evaluation phase in FL may leak sensitive information through shared performance metrics. In this paper, we propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to enable privacy-preserving and verifiable evaluation for FL. Instead of revealing raw loss values, clients generate a succinct proof asserting that their local loss is below a predefined threshold. Our approach is implemented without reliance on external APIs, using self-contained modules for federated learning simulation, ZKP circuit design, and experimental evaluation on both the MNIST and Human Activity Recognition (HAR) datasets. We focus on a threshold-based proof for a simple Convolutional Neural Network (CNN) model (for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate the approach in terms of computational overhead, communication cost, and verifiability.",
      "authors": [
        "Daniel Commey",
        "Benjamin Appiah",
        "Griffith S. Klogo",
        "and Garth V. Crosby"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:34:14+00:00",
          "link": "https://arxiv.org/abs/2507.11649v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11649",
        "HTML": "https://arxiv.org/html/2507.11649v1",
        "PDF": "https://arxiv.org/pdf/2507.11649"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses privacy-preserving evaluation and verifiability in Federated Learning using Zero-Knowledge Proofs without any connection to reinforcement learning or data processing within its context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11653",
      "abstract": "Global localization is critical for autonomous navigation, particularly in scenarios where an agent must localize within a map generated in a different session or by another agent, as agents often have no prior knowledge about the correlation between reference frames. However, this task remains challenging in unstructured environments due to appearance changes induced by viewpoint variation, seasonal changes, spatial aliasing, and occlusions -- known failure modes for traditional place recognition methods. To address these challenges, we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame Alignment), a novel open-set, monocular global localization framework that combines: 1) a front-end, object-based, segmentation and tracking pipeline, followed by 2) a submap correspondence search, which exploits geometric consistencies between environment maps to align vehicle reference frames. VISTA enables consistent localization across diverse camera viewpoints and seasonal changes, without requiring any domain-specific training or finetuning. We evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a 69% improvement in recall over baseline methods. Furthermore, we maintain a compact object-based map that is only 0.6% the size of the most memory-conservative baseline, making our approach capable of real-time implementation on resource-constrained platforms.",
      "authors": [
        "Hannah Shafferman",
        "Annika Thomas",
        "Jouko Kinnari",
        "Michael Ricard",
        "Jose Nino",
        "Jonathan How"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:38:35+00:00",
          "link": "https://arxiv.org/abs/2507.11653v1",
          "size": "2271kb",
          "version": "v1"
        }
      ],
      "title": "VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11653",
        "HTML": "https://arxiv.org/html/2507.11653v1",
        "PDF": "https://arxiv.org/pdf/2507.11653"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The VISTA paper focuses on monocular segmentation-based mapping for global localization, with no mention of reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11655",
      "abstract": "Answer Set Programming (ASP) provides a powerful declarative paradigm for knowledge representation and reasoning. Recently, counting answer sets has emerged as an important computational problem with applications in probabilistic reasoning, network reliability analysis, and other domains. This has motivated significant research into designing efficient ASP counters. While substantial progress has been made for normal logic programs, the development of practical counters for disjunctive logic programs remains challenging.\n  We present SharpASP-SR, a novel framework for counting answer sets of disjunctive logic programs based on subtractive reduction to projected propositional model counting. Our approach introduces an alternative characterization of answer sets that enables efficient reduction while ensuring that intermediate representations remain of polynomial size. This allows SharpASP-SR to leverage recent advances in projected model counting technology. Through extensive experimental evaluation on diverse benchmarks, we demonstrate that SharpASP-SR significantly outperforms existing counters on instances with large answer set counts. Building on these results, we develop a hybrid counting approach that combines enumeration techniques with SharpASP-SR to achieve state-of-the-art performance across the full spectrum of disjunctive programs.",
      "authors": [
        "Mohimenul Kabir",
        "Supratik Chakraborty",
        "Kuldeep S Meel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:41:19+00:00",
          "link": "https://arxiv.org/abs/2507.11655v1",
          "size": "169kb",
          "version": "v1"
        }
      ],
      "title": "Counting Answer Sets of Disjunctive Answer Set Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11655",
        "HTML": "https://arxiv.org/html/2507.11655v1",
        "PDF": "https://arxiv.org/pdf/2507.11655"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper on counting answer sets in disjunctive logic programs is centered on Answer Set Programming and does not relate to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11660",
      "abstract": "The advent of single-cell technology has significantly improved our understanding of cellular states and subpopulations in various tissues under normal and diseased conditions by employing data-driven approaches such as clustering and trajectory inference. However, these methods consider cells as independent data points of population distributions. With spatial transcriptomics, we can represent cellular organization, along with dynamic cell-cell interactions that lead to changes in cell state. Still, key computational advances are necessary to enable the data-driven learning of such complex interactive cellular dynamics. While agent-based modeling (ABM) provides a powerful framework, traditional approaches rely on handcrafted rules derived from domain knowledge rather than data-driven approaches. To address this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED) integrating ABM with deep learning to model intercellular communication, and its effect on the intracellular gene regulatory network. Using graph ODE networks (GDEs) with shared weights per cell type, our approach represents genes as vertices and interactions as directed edges, dynamically learning their strengths through a designed attention mechanism. Trained to match continuous trajectories of simulated as well as inferred trajectories from spatial transcriptomics data, the model captures both intercellular and intracellular interactions, enabling a more adaptive and accurate representation of cellular dynamics.",
      "authors": [
        "Joao F. Rocha",
        "Ke Xu",
        "Xingzhi Sun",
        "Ananya Krishna",
        "Dhananjay Bhaskar",
        "Blanche Mongeon",
        "Morgan Craig",
        "Mark Gerstein",
        "Smita Krishnaswamy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:46:07+00:00",
          "link": "https://arxiv.org/abs/2507.11660v1",
          "size": "3712kb",
          "version": "v1"
        }
      ],
      "title": "STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11660",
        "HTML": "https://arxiv.org/html/2507.11660v1",
        "PDF": "https://arxiv.org/pdf/2507.11660"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper introduces a model for learning cellular interaction dynamics using a multi-agent neural network, it includes elements of agent-based modeling relevant to RL, but does not primarily focus on RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11661",
      "abstract": "Multimodal learning benefits from multiple modal information, and each learned modal representations can be divided into uni-modal that can be learned from uni-modal training and paired-modal features that can be learned from cross-modal interaction. Building on this perspective, we propose a partitioner-guided modal learning framework, PgM, which consists of the modal partitioner, uni-modal learner, paired-modal learner, and uni-paired modal decoder. Modal partitioner segments the learned modal representation into uni-modal and paired-modal features. Modal learner incorporates two dedicated components for uni-modal and paired-modal learning. Uni-paired modal decoder reconstructs modal representation based on uni-modal and paired-modal features. PgM offers three key benefits: 1) thorough learning of uni-modal and paired-modal features, 2) flexible distribution adjustment for uni-modal and paired-modal representations to suit diverse downstream tasks, and 3) different learning rates across modalities and partitions. Extensive experiments demonstrate the effectiveness of PgM across four multimodal tasks and further highlight its transferability to existing models. Additionally, we visualize the distribution of uni-modal and paired-modal features across modalities and tasks, offering insights into their respective contributions.",
      "authors": [
        "Guimin Hu and Yi Xin and Lijie Hu and Zhihong Zhu and Hasti Seifi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:47:49+00:00",
          "link": "https://arxiv.org/abs/2507.11661v1",
          "size": "9914kb",
          "version": "v1"
        }
      ],
      "title": "Partitioner Guided Modal Learning Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11661",
        "HTML": "https://arxiv.org/html/2507.11661v1",
        "PDF": "https://arxiv.org/pdf/2507.11661"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The Partitioner Guided Modal Learning Framework is aimed at multimodal learning and does not involve reinforcement learning or address data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11662",
      "abstract": "Verifiers -- functions assigning rewards to agent behavior -- have been key for AI progress in domains like math and board games. However, extending these gains to domains without clear-cut success criteria (e.g.,computer use) remains a challenge: while humans can recognize suitable outcomes, translating this intuition into scalable rules is non-trivial. Multimodal Large Language Models(MLLMs) emerge as a promising solution, given their world knowledge, human-preference alignment, and reasoning skills. We evaluate MLLMs as verifiers of agent trajectories across web navigation, computer use, and robotic manipulation, and identify a critical limitation: agreement bias, a strong tendency for MLLMs to favor information in their context window, often generating chains of thought to rationalize flawed behavior. This bias is pervasive across models, resilient to test-time scaling, and can impact several methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs despite MLLMs showing strong, human-aligned priors on desired behavior. To address this, we propose Self-Grounded Verification (SGV), a lightweight method that enables more effective use of MLLMs' knowledge and reasoning by harnessing their own sampling mechanisms via unconditional and conditional generation. SGV operates in two steps: first, the MLLM is elicited to retrieve broad priors about task completion, independent of the data under evaluation. Then, conditioned on self-generated priors, it reasons over and evaluates a candidate trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in accuracy and failure detection rates, and can perform real-time supervision of heterogeneous agents, boosting task completion of a GUI specialist in OSWorld, a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting a new state of the art on the benchmark, surpassing the previous best by 48%.",
      "authors": [
        "Moises Andrade",
        "Joonhyuk Cha",
        "Brandon Ho",
        "Vriksha Srihari",
        "Karmesh Yadav",
        "Zsolt Kira"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:50:29+00:00",
          "link": "https://arxiv.org/abs/2507.11662v1",
          "size": "37947kb",
          "version": "v1"
        }
      ],
      "title": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11662",
        "PDF": "https://arxiv.org/pdf/2507.11662"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses using Multimodal Large Language Models (MLLMs) as verifiers in reinforcement learning contexts, which involves aspects of data filtering. However, the focus is on addressing agreement bias in reasoning, with data processing in RL being an incidental part of the broader solution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11671",
      "abstract": "Quantum software represents disruptive technologies in terms of quantum-specific software systems, services, and applications - leverage the principles of quantum mechanics via programmable quantum bits (Qubits) that manipulate quantum gates (QuGates) - to achieve quantum supremacy in computing. Quantum software architecture enables quantum software developers to abstract away implementation-specific details (i.e., mapping of Qubits and QuGates to high-level architectural components and connectors). Architectural patterns and strategies can provide reusable knowledge and best practices to engineer quantum software systems effectively and efficiently. However, quantum software practitioners face significant challenges in selecting and implementing appropriate patterns and strategies due to the complexity of quantum software systems and the lack of guidelines. To address these challenges, this study proposes decision models for selecting patterns and strategies in six critical design areas in quantum software systems: Communication, Decomposition, Data Processing, Fault Tolerance, Integration and Optimization, and Algorithm Implementation. These decision models are constructed based on data collected from both a mining study (i.e., GitHub and Stack Exchange) and a Systematic Literature Review, which were used to identify relevant patterns and strategies with their involved Quality Attributes (QAs). We then conducted semi-structured interviews with 16 quantum software practitioners to evaluate the familiarity, understandability, completeness, and usefulness of the proposed decision models. The results show that the proposed decision models can aid practitioners in selecting suitable patterns and strategies to address the challenges related to the architecture design of quantum software systems. The dataset is available at [6], allowing the community to reproduce and build upon our findings.",
      "authors": [
        "Mst Shamima Aktar",
        "Peng Liang",
        "Muhammad Waseem",
        "Amjed Tahir",
        "Mojtaba Shahin",
        "Muhammad Azeem Akbar",
        "Arif Ali Khan",
        "Aakash Ahmad",
        "Musengamana Jean de Dieu",
        "Ruiyin Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:25:33+00:00",
          "link": "https://arxiv.org/abs/2507.11671v1",
          "size": "1853kb",
          "version": "v1"
        }
      ],
      "title": "Decision Models for Selecting Architecture Patterns and Strategies in Quantum Software Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11671",
        "HTML": "https://arxiv.org/html/2507.11671v1",
        "PDF": "https://arxiv.org/pdf/2507.11671"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on decision models for selecting architecture patterns in quantum software systems and does not discuss reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11676",
      "abstract": "Quantum programs today are written at a low level of abstraction - quantum circuits akin to assembly languages - and even advanced quantum programming languages essentially function as circuit description languages. This state of affairs impedes scalability, clarity, and support for higher-level reasoning. More abstract and expressive quantum programming constructs are needed.\n  To this end, we introduce a novel yet simple quantum programming language for generating unitaries from \"just a phase\"; we combine a (global) phase operation that captures phase shifts with a quantum analogue of the \"if let\" construct that captures subspace selection via pattern matching. This minimal language lifts the focus from quantum gates to eigendecomposition, conjugation, and controlled unitaries; common building blocks in quantum algorithm design.\n  We demonstrate several aspects of the expressive power of our language in several ways. Firstly, we establish that our representation is universal by deriving a universal quantum gate set. Secondly, we show that important quantum algorithms can be expressed naturally and concisely, including Grover's search algorithm, Hamiltonian simulation, Quantum Fourier Transform, Quantum Signal Processing, and the Quantum Eigenvalue Transformation. Furthermore, we give clean denotational semantics grounded in categorical quantum mechanics. Finally, we implement a prototype compiler that efficiently translates terms of our language to quantum circuits, and prove that it is sound with respect to these semantics. Collectively, these contributions show that this construct offers a principled and practical step toward more abstract and structured quantum programming.",
      "authors": [
        "Chris Heunen",
        "Louis Lemonnier",
        "Christopher McNally",
        "Alex Rice"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:31:53+00:00",
          "link": "https://arxiv.org/abs/2507.11676v1",
          "size": "53kb",
          "version": "v1"
        }
      ],
      "title": "Quantum circuits are just a phase",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11676",
        "PDF": "https://arxiv.org/pdf/2507.11676"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on introducing a new quantum programming language and does not relate to reinforcement learning or involve any data processing aspects within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11677",
      "abstract": "Communicating climate change remains challenging, as climate reports, though rich in data and visualizations, often feel too abstract or technical for the public. Although personalization can enhance communication, most tools still lack the narrative and visualization tailoring needed to connect with individual experiences. We present CLAImate, an AI-enabled prototype that personalizes conversation narratives and localizes visualizations based on users' climate knowledge and geographic location. We evaluated CLAImate through internal verification of factual correctness, a formative study with experts, and a pilot with UK residents. CLAImate achieved 66% SNLI accuracy and 70% FACTSCORE. Visualization experts appreciated its clarity and personalization, and seven out of ten UK participants reported better understanding and local relevance of climate risks with CLAImate. We also discuss design challenges in personalization, accuracy, and scalability, and outline future directions for integrating visualizations in personalized conversational interfaces.",
      "authors": [
        "Mashrur Rashik",
        "Jean-Daniel Fekete",
        "Narges Mahyar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:32:04+00:00",
          "link": "https://arxiv.org/abs/2507.11677v1",
          "size": "816kb",
          "version": "v1"
        }
      ],
      "title": "CLAImate: AI-Enabled Climate Change Communication through Personalized and Localized Narrative Visualizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11677",
        "HTML": "https://arxiv.org/html/2507.11677v1",
        "PDF": "https://arxiv.org/pdf/2507.11677"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on AI-enabled climate communication through narrative visualizations, without any mention or relation to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11678",
      "abstract": "Twelve years have passed since World IPv6 Launch Day, but what is the current state of IPv6 deployment? Prior work has examined IPv6 status as a binary: can you use IPv6, or not? As deployment increases we must consider a more nuanced, non-binary perspective on IPv6: how much and often can a user or a service use IPv6? We consider this question as a client, server, and cloud provider. Considering the client's perspective, we observe user traffic. We see that the fraction of IPv6 traffic a user sends varies greatly, both across users and day-by-day, with a standard deviation of over 15%. We show this variation occurs for two main reasons. First, IPv6 traffic is primarily human-generated, thus showing diurnal patterns. Second, some services are IPv6-forward and others IPv6-laggards, so as users do different things their fraction of IPv6 varies. We look at server-side IPv6 adoption in two ways. First, we expand analysis of web services to examine how many are only partially IPv6 enabled due to their reliance on IPv4-only resources. Our findings reveal that only 12.5% of top 100k websites qualify as fully IPv6-ready. Finally, we examine cloud support for IPv6. Although all clouds and CDNs support IPv6, we find that tenant deployment rates vary significantly across providers. We find that ease of enabling IPv6 in the cloud is correlated with tenant IPv6 adoption rates, and recommend best practices for cloud providers to improve IPv6 adoption. Our results suggest IPv6 deployment is growing, but many services lag, presenting a potential for improvement.",
      "authors": [
        "Sulyab Thottungal Valapu and John Heidemann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:33:42+00:00",
          "link": "https://arxiv.org/abs/2507.11678v1",
          "size": "588kb",
          "version": "v1"
        }
      ],
      "title": "Towards a Non-Binary View of IPv6 Adoption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11678",
        "HTML": "https://arxiv.org/html/2507.11678v1",
        "PDF": "https://arxiv.org/pdf/2507.11678"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses the adoption and deployment of IPv6 and does not involve reinforcement learning or discuss data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11681",
      "abstract": "Pinwheel Scheduling is a fundamental scheduling problem, in which each task $i$ is associated with a positive integer $d_i$, and the objective is to schedule one task per time slot, ensuring each task perpetually appears at least once in every $d_i$ time slots. Although conjectured to be PSPACE-complete, it remains open whether Pinwheel Scheduling is NP-hard (unless a compact input encoding is used) or even contained in NP.\n  We introduce k-Visits, a finite version of Pinwheel Scheduling, where given n deadlines, the goal is to schedule each task exactly k times. While we observe that the 1-Visit problem is trivial, we prove that 2-Visits is strongly NP-complete through a surprising reduction from Numerical 3-Dimensional Matching (N3DM). As intermediate steps in the reduction, we define NP-complete variants of N3DM which may be of independent interest. We further extend our strong NP-hardness result to a generalization of k-Visits $k\\geq 2$ in which the deadline of each task may vary throughout the schedule, as well as to a similar generalization of Pinwheel Scheduling, thus making progress towards settling the complexity of Pinwheel Scheduling.\n  Additionally, we prove that 2-Visits can be solved in linear time if all deadlines are distinct, rendering it one of the rare natural problems which exhibit the interesting dichotomy of being in P if their input is a set and NP-complete if the input is a multiset. We achieve this through a Turing reduction from 2-Visits to a variation of N3DM, which we call Position Matching. Based on this reduction, we also show an FPT algorithm for 2-Visits parameterized by a value related to how close the input deadlines are to each other, as well as a linear-time algorithm for instances with up to two distinct deadlines.",
      "authors": [
        "Sotiris Kanellopoulos",
        "Christos Pergaminelis",
        "Maria Kokkou",
        "Euripides Markou",
        "Aris Pagourtzis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:36:08+00:00",
          "link": "https://arxiv.org/abs/2507.11681v1",
          "size": "111kb",
          "version": "v1"
        }
      ],
      "title": "Finite Pinwheel Scheduling: the k-Visits Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11681",
        "HTML": "https://arxiv.org/html/2507.11681v1",
        "PDF": "https://arxiv.org/pdf/2507.11681"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the k-Visits problem in pinwheel scheduling and does not discuss reinforcement learning or any aspects related to data processing in RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11683",
      "abstract": "Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for modeling spatial and temporal data dependencies. However, their applications have been limited primarily to small-scale datasets because of memory constraints. While distributed training offers a solution, current frameworks lack support for spatiotemporal models and overlook the properties of spatiotemporal data. Informed by a scaling study on a large-scale workload, we present PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch Geometric Temporal that integrates distributed data parallel training and two novel strategies: index-batching and distributed-index-batching. Our index techniques exploit spatiotemporal structure to construct snapshots dynamically at runtime, significantly reducing memory overhead, while distributed-index-batching extends this approach by enabling scalable processing across multiple GPUs. Our techniques enable the first-ever training of an ST-GNN on the entire PeMS dataset without graph partitioning, reducing peak memory usage by up to 89\\% and achieving up to a 13.1x speedup over standard DDP with 128 GPUs.",
      "authors": [
        "Seth Ockerman",
        "Amal Gueroudji",
        "Tanwi Mallick",
        "Yixuan He",
        "Line Pouchard",
        "Robert Ross",
        "Shivaram Venkataraman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:38:16+00:00",
          "link": "https://arxiv.org/abs/2507.11683v1",
          "size": "333kb",
          "version": "v1"
        }
      ],
      "title": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11683",
        "HTML": "https://arxiv.org/html/2507.11683v1",
        "PDF": "https://arxiv.org/pdf/2507.11683"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper introduces PGT-I, which involves memory-efficient distributed training of spatiotemporal GNNs using index-batching techniques to exploit spatiotemporal structure. While it focuses on data processing strategies, it does not explicitly address reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11687",
      "abstract": "Large Language Models, though successful in code generation, struggle with code quality analysis because they are limited by static training data and can't easily adapt to evolving best practices. We introduce MetaLint, a new instruction-following framework that formulates code quality analysis as the task of detecting and fixing problematic semantic code fragments or code idioms based on high-level specifications. Unlike conventional approaches that train models on static, rule-based data, MetaLint employs instruction tuning on synthetic linter-generated data to support easy-to-hard generalization, enabling models to adapt to novel or complex code patterns without retraining. To evaluate this, we construct a benchmark of challenging idioms inspired by real-world coding standards such as Python Enhancement Proposals (PEPs) and assess whether MetaLint-trained models reason adaptively or simply memorize. Our results show that MetaLint improves generalization to unseen PEP idioms, achieving a 70.37% F-score on idiom detection with the highest recall (70.43%) among all evaluated models. It also achieves 26.73% on localization, competitive for its 4B parameter size and comparable to larger state-of-the-art models like o3-mini, highlighting its potential for future-proof code quality analysis.",
      "authors": [
        "Atharva Naik",
        "Lawanya Baghel",
        "Dhakshin Govindarajan",
        "Darsh Agrawal",
        "Daniel Fried",
        "Carolyn Rose"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:44:20+00:00",
          "link": "https://arxiv.org/abs/2507.11687v1",
          "size": "1610kb",
          "version": "v1"
        }
      ],
      "title": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11687",
        "HTML": "https://arxiv.org/html/2507.11687v1",
        "PDF": "https://arxiv.org/pdf/2507.11687"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses MetaLint, a framework for instruction-following code quality analysis, without mentioning reinforcement learning or data processing within RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11688",
      "abstract": "Contemporary large models often exhibit behaviors suggesting the presence of low-level primitives that compose into modules with richer functionality, but these fundamental building blocks remain poorly understood. We investigate this compositional structure in linear layers by asking: can we identify/synthesize linear transformations from a minimal set of geometric primitives? Using Clifford algebra, we show that linear layers can be expressed as compositions of bivectors -- geometric objects encoding oriented planes -- and introduce a differentiable algorithm that decomposes them into products of rotors. This construction uses only O(log^2 d) parameters, versus O(d^2) required by dense matrices. Applied to the key, query, and value projections in LLM attention layers, our rotor-based layers match the performance of strong baselines such as block-Hadamard and low-rank approximations. Our findings provide an algebraic perspective on how these geometric primitives can compose into higher-level functions within deep models.",
      "authors": [
        "Travis Pence",
        "Daisuke Yamada",
        "Vikas Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:46:00+00:00",
          "link": "https://arxiv.org/abs/2507.11688v1",
          "size": "80kb",
          "version": "v1"
        }
      ],
      "title": "Composing Linear Layers from Irreducibles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11688",
        "HTML": "https://arxiv.org/html/2507.11688v1",
        "PDF": "https://arxiv.org/pdf/2507.11688"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the algebraic decomposition of linear transformations using Clifford algebra, and does not relate to reinforcement learning or the data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11689",
      "abstract": "In Computer Science Bachelor's programs, software quality is often underemphasized due to limited time and a focus on foundational skills, leaving many students unprepared for industry expectations. To better understand the typical quality of student code and inform both education and hiring practices, we analyze 40 full-stack web applications developed in a third-year Web Technologies course. Using an automated static analysis pipeline, we assess adherence to REST API design rules. Results reveal frequent violations of foundational conventions, such as missing hyphens in endpoint paths (98%), incorrect pluralization (88%), and misuse of HTTP methods (83%). These findings highlight the need for more focused instruction on API design and support the adoption of automated tools to improve code quality in student projects.",
      "authors": [
        "Sergio Di Meglio",
        "Valeria Pontillo",
        "Luigi Libero Lucio Starace"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:46:02+00:00",
          "link": "https://arxiv.org/abs/2507.11689v1",
          "size": "210kb",
          "version": "v1"
        }
      ],
      "title": "REST in Pieces: RESTful Design Rule Violations in Student-Built Web Apps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11689",
        "HTML": "https://arxiv.org/html/2507.11689v1",
        "PDF": "https://arxiv.org/pdf/2507.11689"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing RESTful design rule violations in student-built web apps, which is unrelated to reinforcement learning or data processing within that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11690",
      "abstract": "Coreset selection methods have shown promise in reducing the training data size while maintaining model performance for data-efficient machine learning. However, as many datasets suffer from biases that cause models to learn spurious correlations instead of causal features, it is important to understand whether and how dataset reduction methods may perpetuate, amplify, or mitigate these biases. In this work, we conduct the first comprehensive analysis of the implications of data selection on the spurious bias levels of the selected coresets and the robustness of downstream models trained on them. We use an extensive experimental setting spanning ten different spurious correlations benchmarks, five score metrics to characterize sample importance/ difficulty, and five data selection policies across a broad range of coreset sizes. Thereby, we unravel a series of nontrivial nuances in interactions between sample difficulty and bias alignment, as well as dataset bias and resultant model robustness. For example, we find that selecting coresets using embedding-based sample characterization scores runs a comparatively lower risk of inadvertently exacerbating bias than selecting using characterizations based on learning dynamics. Most importantly, our analysis reveals that although some coreset selection methods could achieve lower bias levels by prioritizing difficult samples, they do not reliably guarantee downstream robustness.",
      "authors": [
        "Amaya Dharmasiri",
        "William Yang",
        "Polina Kirichenko",
        "Lydia Liu",
        "Olga Russakovsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:46:30+00:00",
          "link": "https://arxiv.org/abs/2507.11690v1",
          "size": "216kb",
          "version": "v1"
        }
      ],
      "title": "The Impact of Coreset Selection on Spurious Correlations and Group Robustness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11690",
        "HTML": "https://arxiv.org/html/2507.11690v1",
        "PDF": "https://arxiv.org/pdf/2507.11690"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses coreset selection methods for reducing training data size in supervised learning, particularly concerning spurious correlations and bias, with no mention or implication of reinforcement learning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11694",
      "abstract": "We present ExpliCIT-QA, a system that extends our previous MRT approach for tabular question answering into a multimodal pipeline capable of handling complex table images and providing explainable answers. ExpliCIT-QA follows a modular design, consisting of: (1) Multimodal Table Understanding, which uses a Chain-of-Thought approach to extract and transform content from table images; (2) Language-based Reasoning, where a step-by-step explanation in natural language is generated to solve the problem; (3) Automatic Code Generation, where Python/Pandas scripts are created based on the reasoning steps, with feedback for handling errors; (4) Code Execution to compute the final answer; and (5) Natural Language Explanation that describes how the answer was computed. The system is built for transparency and auditability: all intermediate outputs, parsed tables, reasoning steps, generated code, and final answers are available for inspection. This strategy works towards closing the explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on the TableVQA-Bench benchmark, comparing it with existing baselines. We demonstrated improvements in interpretability and transparency, which open the door for applications in sensitive domains like finance and healthcare where auditing results are critical.",
      "authors": [
        "Maximiliano Hormaz\\'abal Lagos,\\'Alvaro Bueno S\\'aez",
        "Pedro Alonso Doval",
        "Jorge Alcalde Vesteiro",
        "H\\'ector Cerezo-Costas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:51:24+00:00",
          "link": "https://arxiv.org/abs/2507.11694v1",
          "size": "663kb",
          "version": "v1"
        }
      ],
      "title": "ExpliCIT-QA: Explainable Code-Based Image Table Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11694",
        "HTML": "https://arxiv.org/html/2507.11694v1",
        "PDF": "https://arxiv.org/pdf/2507.11694"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper describes ExpliCIT-QA, a system for explainable question answering from image tables, which does not relate to reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11695",
      "abstract": "We introduce a family of discontinuous Galerkin methods to approximate the eigenvalues and eigenfunctions of a Stokes-Brinkman type of problem based in the interior penalty strategy. Under the standard assumptions on the meshes and a suitable norm, we prove the stability of the discrete scheme. Due to the non-conforming nature of the method, we use the well-known non-compact operators theory to derive convergence and error estimates for the method. We present an exhaustive computational analysis where we compute the spectrum with different stabilization parameters with the aim of study its influence when the spectrum is approximated.",
      "authors": [
        "Felipe Lepe",
        "Gonzalo Rivera and Jesus Vellojin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:51:31+00:00",
          "link": "https://arxiv.org/abs/2507.11695v1",
          "size": "9776kb",
          "version": "v1"
        }
      ],
      "title": "Discontinuous Galerkin approximation for a Stokes-Brinkman-type formulation for the eigenvalue problem in porous media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11695",
        "HTML": "https://arxiv.org/html/2507.11695v1",
        "PDF": "https://arxiv.org/pdf/2507.11695"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents discontinuous Galerkin methods for a mathematical problem in porous media, unrelated to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11700",
      "abstract": "We present a norm-stabilized imaginary-time evolution (ITE) scheme for the one-dimensional nonlinear Schrodinger equation (NLSE). Traditional ITE solvers often require explicit renormalization of the wavefunction after each step to preserve norm, which can be disruptive and algorithmically inflexible. We propose an alternative approach in which the evolution is continuously stabilized using an adaptive feedback term mu(tau), proportional to the time derivative of the wavefunction norm. This results in a self-regulating flow that requires no external normalization while preserving convergence toward soliton solutions. We demonstrate the method's effectiveness by comparing the final wavefunction profiles and L2 errors against analytical solutions and baseline methods without feedback. Although this work focuses on the 1D case, the framework is designed to extend naturally to higher dimensions. Future work will explore the behavior of the feedback mechanism in 2D and 3D systems, multi-soliton scenarios, and external potentials.",
      "authors": [
        "Stylianos Savva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Pattern Formation and Solitons (nlin.PS)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:10:52+00:00",
          "link": "https://arxiv.org/abs/2507.11700v1",
          "size": "593kb",
          "version": "v1"
        }
      ],
      "title": "Norm-Stabilized Imaginary-Time Evolution via Feedback Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11700",
        "HTML": "https://arxiv.org/html/2507.11700v1",
        "PDF": "https://arxiv.org/pdf/2507.11700"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on imaginary-time evolution for solving the nonlinear Schrodinger equation, which is unrelated to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11702",
      "abstract": "Railroad traffic disruption as a result of leaf-fall cost the UK rail industry over 300 million per year and measures to mitigate such disruptions are employed on a large scale, with 1.67 million kilometers of track being treated in the UK in 2021 alone. Therefore, the ability to anticipate the timing of leaf-fall would offer substantial benefits for rail network operators, enabling the efficient scheduling of such mitigation measures. However, current methodologies for predicting leaf-fall exhibit considerable limitations in terms of scalability and reliability. This study endeavors to devise a prediction system that leverages specialized prediction methods and the latest satellite data sources to generate both scalable and reliable insights into leaf-fall timings. An LSTM network trained on ground-truth leaf-falling data combined with multispectral and meteorological satellite data demonstrated a root-mean-square error of 6.32 days for predicting the start of leaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which improves upon previous work on the topic, offers promising opportunities for the optimization of leaf mitigation measures in the railway industry and the improvement of our understanding of complex ecological systems.",
      "authors": [
        "Hein de Wilde",
        "Ali Mohammed Mansoor Alsahag",
        "Pierre Blanchet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:13:31+00:00",
          "link": "https://arxiv.org/abs/2507.11702v1",
          "size": "6245kb",
          "version": "v1"
        }
      ],
      "title": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11702",
        "HTML": "https://arxiv.org/html/2507.11702v1",
        "PDF": "https://arxiv.org/pdf/2507.11702"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with time series classification using LSTM networks for predicting ecological events, specifically leaf-fall, and does not relate to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11704",
      "abstract": "Anthem 2.0 is a tool to aid in the verification of logic programs written in an expressive fragment of Clingo's input language named mini-gringo, which includes arithmetic operations and simple choice rules but not aggregates. It can translate logic programs into formula representations in the logic of here-and-there, and analyze properties of logic programs such as tightness. Most importantly, Anthem 2.0 can support program verification by invoking first-order theorem provers to confirm that a program adheres to a first-order specification, or to establish strong and external equivalence of programs. This paper serves as an overview of the system's capabilities. We demonstrate how to use Anthem 2.0 effectively and interpret its results.",
      "authors": [
        "Jorge Fandinno",
        "Christoph Glinzer",
        "Zachary Hansen",
        "Jan Heuer",
        "Yuliya Lierler",
        "Vladimir Lifschitz",
        "Torsten Schaub",
        "Tobias Stolzmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:14:24+00:00",
          "link": "https://arxiv.org/abs/2507.11704v1",
          "size": "262kb",
          "version": "v1"
        }
      ],
      "title": "Anthem 2.0: Automated Reasoning for Answer Set Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11704",
        "HTML": "https://arxiv.org/html/2507.11704v1",
        "PDF": "https://arxiv.org/pdf/2507.11704"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents Anthem 2.0, a tool for verifying logic programs in logic programming languages, and does not involve reinforcement learning or data processing within an RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11706",
      "abstract": "We introduce a new framework of episodic tabular Markov decision processes (MDPs) with adversarial preferences, which we refer to as preference-based MDPs (PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the numerical value of the loss is directly observed, in PbMDPs the learner instead observes preferences between two candidate arms, which represent the choices being compared. In this work, we focus specifically on the setting where the reward functions are determined by Borda scores. We begin by establishing a regret lower bound for PbMDPs with Borda scores. As a preliminary step, we present a simple instance to prove a lower bound of $\\Omega(\\sqrt{HSAT})$ for episodic MDPs with adversarial losses, where $H$ is the number of steps per episode, $S$ is the number of states, $A$ is the number of actions, and $T$ is the number of episodes. Leveraging this construction, we then derive a regret lower bound of $\\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda scores, where $K$ is the number of arms. Next, we develop algorithms that achieve a regret bound of order $T^{2/3}$. We first propose a global optimization approach based on online linear optimization over the set of all occupancy measures, achieving a regret bound of $\\tilde{O}((H^2 S^2 K)^{1/3} T^{2/3} )$ under known transitions. However, this approach suffers from suboptimal dependence on the potentially large number of states $S$ and computational inefficiency. To address this, we propose a policy optimization algorithm whose regret is roughly bounded by $\\tilde{O}( (H^6 S K^5)^{1/3} T^{2/3} )$ under known transitions, and further extend the result to the unknown-transition setting.",
      "authors": [
        "Taira Tsuchiya",
        "Shinji Ito",
        "Haipeng Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:19:32+00:00",
          "link": "https://arxiv.org/abs/2507.11706v1",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning from Adversarial Preferences in Tabular MDPs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11706",
        "HTML": "https://arxiv.org/html/2507.11706v1",
        "PDF": "https://arxiv.org/pdf/2507.11706"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper introduces a framework for adversarial preference-based MDPs, a specific setup in reinforcement learning, and discusses algorithms with regret bounds. It directly addresses data processing through the design of algorithms to handle preference-based reward signals in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11709",
      "abstract": "Flexibility and customization are key strengths of Field-Programmable Gate Arrays (FPGAs) when compared to other computing devices. For instance, FPGAs can efficiently implement arbitrary-precision arithmetic operations, and can perform aggressive synthesis optimizations to eliminate ineffectual operations. Motivated by sparsity and mixed-precision in deep neural networks (DNNs), we investigate how to optimize the current logic block architecture to increase its arithmetic density. We find that modern FPGA logic block architectures prevent the independent use of adder chains, and instead only allow adder chain inputs to be fed by look-up table (LUT) outputs. This only allows one of the two primitives -- either adders or LUTs -- to be used independently in one logic element and prevents their concurrent use, hampering area optimizations. In this work, we propose the Double Duty logic block architecture to enable the concurrent use of the adders and LUTs within a logic element. Without adding expensive logic cluster inputs, we use 4 of the existing inputs to bypass the LUTs and connect directly to the adder chain inputs. We accurately model our changes at both the circuit and CAD levels using open-source FPGA development tools. Our experimental evaluation on a Stratix-10-like architecture demonstrates area reductions of 21.6% on adder-intensive circuits from the Kratos benchmarks, and 9.3% and 8.2% on the more general Koios and VTR benchmarks respectively. These area improvements come without an impact to critical path delay, demonstrating that higher density is feasible on modern FPGA architectures by adding more flexibility in how the adder chain is used. Averaged across all circuits from our three evaluated benchmark set, our Double Duty FPGA architecture improves area-delay product by 9.7%.",
      "authors": [
        "Junius Pun",
        "Xilai Dai",
        "Grace Zgheib",
        "Mahesh A. Iyer",
        "Andrew Boutros",
        "Vaughn Betz",
        "Mohamed S. Abdelfattah"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:25:41+00:00",
          "link": "https://arxiv.org/abs/2507.11709v1",
          "size": "466kb",
          "version": "v1"
        }
      ],
      "title": "Double Duty: FPGA Architecture to Enable Concurrent LUT and Adder Chain Usage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11709",
        "HTML": "https://arxiv.org/html/2507.11709v1",
        "PDF": "https://arxiv.org/pdf/2507.11709"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work explores FPGA architecture optimization for arithmetic density and does not engage with reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11710",
      "abstract": "Graphs Neural Networks (GNNs) demonstrate high-performance on the link prediction (LP) task. However, these models often rely on all dataset samples being drawn from the same distribution. In addition, graph generative models (GGMs) show a pronounced ability to generate novel output graphs. Despite this, GGM applications remain largely limited to domain-specific tasks. To bridge this gap, we propose FLEX as a GGM framework which leverages two mechanism: (1) structurally-conditioned graph generation, and (2) adversarial co-training between an auto-encoder and GNN. As such, FLEX ensures structural-alignment between sample distributions to enhance link-prediction performance in out-of-distribution (OOD) scenarios. Notably, FLEX does not require expert knowledge to function in different OOD scenarios. Numerous experiments are conducted in synthetic and real-world OOD settings to demonstrate FLEX's performance-enhancing ability, with further analysis for understanding the effects of graph data augmentation on link structures. The source code is available here: https://github.com/revolins/FlexOOD.",
      "authors": [
        "Jay Revolinsky",
        "Harry Shomer",
        "Jiliang Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:30:16+00:00",
          "link": "https://arxiv.org/abs/2507.11710v1",
          "size": "1062kb",
          "version": "v1"
        }
      ],
      "title": "Subgraph Generation for Generalizing on Out-of-Distribution Links",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11710",
        "HTML": "https://arxiv.org/html/2507.11710v1",
        "PDF": "https://arxiv.org/pdf/2507.11710"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph neural networks and graph generation for link prediction, particularly under out-of-distribution settings. While it addresses graph data augmentation, it does not pertain to reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11716",
      "abstract": "As the global population of people with disabilities (PWD) continues to grow, so will the need for mobility solutions that promote independent living and social integration. Wheelchairs are vital for the mobility of PWD in both indoor and outdoor environments. The current SOTA in powered wheelchairs is based on either manually controlled or fully autonomous modes of operation, offering limited flexibility and often proving difficult to navigate in spatially constrained environments. Moreover, research on robotic wheelchairs has focused predominantly on complete autonomy or improved manual control; approaches that can compromise efficiency and user trust. To overcome these challenges, this paper introduces the CoNav Chair, a smart wheelchair based on the Robot Operating System (ROS) and featuring shared control navigation and obstacle avoidance capabilities that are intended to enhance navigational efficiency, safety, and ease of use for the user. The paper outlines the CoNav Chair's design and presents a preliminary usability evaluation comparing three distinct navigation modes, namely, manual, shared, and fully autonomous, conducted with 21 healthy, unimpaired participants traversing an indoor building environment. Study findings indicated that the shared control navigation framework had significantly fewer collisions and performed comparably, if not superior to the autonomous and manual modes, on task completion time, trajectory length, and smoothness; and was perceived as being safer and more efficient based on user reported subjective assessments of usability. Overall, the CoNav system demonstrated acceptable safety and performance, laying the foundation for subsequent usability testing with end users, namely, PWDs who rely on a powered wheelchair for mobility.",
      "authors": [
        "Yifan Xu",
        "Qianwei Wang",
        "Jordan Lillie",
        "Vineet Kamat",
        "Carol Menassa and Clive D'Souza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:34:42+00:00",
          "link": "https://arxiv.org/abs/2507.11716v1",
          "size": "2377kb",
          "version": "v1"
        }
      ],
      "title": "CoNav Chair: Development and Evaluation of a Shared Control based Wheelchair for the Built Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11716",
        "HTML": "https://arxiv.org/html/2507.11716v1",
        "PDF": "https://arxiv.org/pdf/2507.11716"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with shared control navigation in wheelchairs, evaluating usability and navigation modes. It does not relate to reinforcement learning or discuss its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11721",
      "abstract": "Sanctioning blockchain addresses has become a common regulatory response to malicious activities. However, enforcement on permissionless blockchains remains challenging due to complex transaction flows and sophisticated fund-obfuscation techniques. Using cryptocurrency mixing tool Tornado Cash as a case study, we quantitatively assess the effectiveness of U.S. Office of Foreign Assets Control (OFAC) sanctions over a 957-day period, covering 6.79 million Ethereum blocks and 1.07 billion transactions. Our analysis reveals that while OFAC sanctions reduced overall Tornado Cash deposit volume by 71.03% to approximately 2 billion USD, attackers still relied on Tornado Cash in 78.33% of Ethereum-related security incidents, underscoring persistent evasion strategies.\n  We identify three structural limitations in current sanction enforcement practices: (i) the susceptibility of binary sanction classifications to dusting attacks; (ii) fragmented censorship by blockchain producers; and (iii) the complexity of obfuscation services exploited by users. To address these gaps, we introduce a more practical algorithm for scoring and tracking, grounded in quantitative impurity. On average, our algorithm processes Ethereum blocks within 0.07 $\\pm$ 0.03 seconds and achieves 97.61% precision and 74.08% recall when evaluated on the Bybit exploit. Our findings contribute to ongoing discussions around regulatory effectiveness in Decentralized Finance by providing empirical evidence, clarifying enforcement challenges, and informing future compliance strategies in response to sanctions and blockchain-based security risks.",
      "authors": [
        "Endong Liu",
        "Mark Ryan",
        "Liyi Zhou",
        "and Pascal Berrang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:44:29+00:00",
          "link": "https://arxiv.org/abs/2507.11721v1",
          "size": "7268kb",
          "version": "v1"
        }
      ],
      "title": "Evasion Under Blockchain Sanctions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11721",
        "HTML": "https://arxiv.org/html/2507.11721v1",
        "PDF": "https://arxiv.org/pdf/2507.11721"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper examines the enforcement of blockchain sanctions, using transaction analyses on platforms like Tornado Cash. It does not involve any aspect of reinforcement learning or associated data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11724",
      "abstract": "We provide new high-accuracy randomized algorithms for solving linear systems and regression problems that are well-conditioned except for $k$ large singular values. For solving such $d \\times d$ positive definite system our algorithms succeed whp. and run in time $\\tilde O(d^2 + k^\\omega)$. For solving such regression problems in a matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ our methods succeed whp. and run in time $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 + k^\\omega)$ where $\\omega$ is the matrix multiplication exponent and $\\mathrm{nnz}(\\mathbf{A})$ is the number of non-zeros in $\\mathbf{A}$. Our methods nearly-match a natural complexity limit under dense inputs for these problems and improve upon a trade-off in prior approaches that obtain running times of either $\\tilde O(d^{2.065}+k^\\omega)$ or $\\tilde O(d^2 + dk^{\\omega-1})$ for $d\\times d$ systems. Moreover, we show how to obtain these running times even under the weaker assumption that all but $k$ of the singular values have a suitably bounded generalized mean. Consequently, we give the first nearly-linear time algorithm for computing a multiplicative approximation to the nuclear norm of an arbitrary dense matrix. Our algorithms are built on three general recursive preconditioning frameworks, where matrix sketching and low-rank update formulas are carefully tailored to the problems' structure.",
      "authors": [
        "Micha{\\l} Derezi\\'nski and Aaron Sidford"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:48:30+00:00",
          "link": "https://arxiv.org/abs/2507.11724v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11724",
        "HTML": "https://arxiv.org/html/2507.11724v1",
        "PDF": "https://arxiv.org/pdf/2507.11724"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces randomized algorithms for solving linear systems with low-rank structure, focusing on computational efficiency but not related to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11726",
      "abstract": "Transmission switching is a well-established approach primarily applied to minimize operational costs through strategic network reconfiguration. However, exclusive focus on cost reduction can compromise system reliability. While multi-objective transmission switching can balance cost savings with reliability improvements, feasible solutions become exceedingly difficult to obtain as system scale grows, due to the inherent nonlinearity and high computational demands involved. This paper proposes a deep reinforcement learning (DRL) method for multi-objective transmission switching. The method incorporates a dueling-based actor-critic framework to evaluate the relative impact of each line switching decision within the action space, which improves decision quality and enhances both system reliability and cost efficiency. Numerical studies on the IEEE 118-bus system verify the effectiveness and efficiency of the proposed approach compared to two benchmark DRL algorithms.",
      "authors": [
        "Ding Lin",
        "Jianhui Wang",
        "Tianqiao Zhao",
        "Meng Yue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:49:48+00:00",
          "link": "https://arxiv.org/abs/2507.11726v1",
          "size": "260kb",
          "version": "v1"
        }
      ],
      "title": "A Deep Reinforcement Learning Method for Multi-objective Transmission Switching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11726",
        "HTML": "https://arxiv.org/html/2507.11726v1",
        "PDF": "https://arxiv.org/pdf/2507.11726"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper proposes a deep reinforcement learning method for multi-objective transmission switching, utilizing a dueling-based actor-critic framework. While it focuses on RL, there is no explicit mention of data processing techniques, making it partially relevant as the main contribution is related to algorithmic improvements rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11729",
      "abstract": "Forecasting load in power transmission networks is essential across various hierarchical levels, from the system level down to individual points of delivery (PoD). While intuitive and locally accurate, traditional local forecasting models (LFMs) face significant limitations, particularly in handling generalizability, overfitting, data drift, and the cold start problem. These methods also struggle with scalability, becoming computationally expensive and less efficient as the network's size and data volume grow. In contrast, global forecasting models (GFMs) offer a new approach to enhance prediction generalizability, scalability, accuracy, and robustness through globalization and cross-learning. This paper investigates global load forecasting in the presence of data drifts, highlighting the impact of different modeling techniques and data heterogeneity. We explore feature-transforming and target-transforming models, demonstrating how globalization, data heterogeneity, and data drift affect each differently. In addition, we examine the role of globalization in peak load forecasting and its potential for hierarchical forecasting. To address data heterogeneity and the balance between globality and locality, we propose separate time series clustering (TSC) methods, introducing model-based TSC for feature-transforming models and new weighted instance-based TSC for target-transforming models. Through extensive experiments on a real-world dataset of Alberta's electricity load, we demonstrate that global target-transforming models consistently outperform their local counterparts, especially when enriched with global features and clustering techniques. In contrast, global feature-transforming models face challenges in balancing local and global dynamics, often requiring TSC to manage data heterogeneity effectively.",
      "authors": [
        "Amirhossein Ahmadi",
        "Hamidreza Zareipour",
        "Henry Leung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:58:14+00:00",
          "link": "https://arxiv.org/abs/2507.11729v1",
          "size": "8492kb",
          "version": "v1"
        }
      ],
      "title": "Globalization for Scalable Short-term Load Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11729",
        "HTML": "https://arxiv.org/html/2507.11729v1",
        "PDF": "https://arxiv.org/pdf/2507.11729"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on short-term load forecasting in power transmission networks, emphasizing global forecasting models. There is no mention of reinforcement learning or related data processing, making it irrelevant in the context of RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11730",
      "abstract": "Outdoor advertisements remain a critical medium for modern marketing, yet accurately verifying billboard text visibility under real-world conditions is still challenging. Traditional Optical Character Recognition (OCR) pipelines excel at cropped text recognition but often struggle with complex outdoor scenes, varying fonts, and weather-induced visual noise. Recently, multimodal Vision-Language Models (VLMs) have emerged as promising alternatives, offering end-to-end scene understanding with no explicit detection step. This work systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B, InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline (PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with synthetic weather distortions to simulate realistic degradation. Our results reveal that while selected VLMs excel at holistic scene reasoning, lightweight CNN pipelines still achieve competitive accuracy for cropped text at a fraction of the computational cost-an important consideration for edge deployment. To foster future research, we release our weather-augmented benchmark and evaluation code publicly.",
      "authors": [
        "Maciej Szankin",
        "Vidhyananth Venkatasamy",
        "Lihang Ying"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:58:24+00:00",
          "link": "https://arxiv.org/abs/2507.11730v1",
          "size": "1411kb",
          "version": "v1"
        }
      ],
      "title": "Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11730",
        "HTML": "https://arxiv.org/html/2507.11730v1",
        "PDF": "https://arxiv.org/pdf/2507.11730"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper benchmarks OCR models for billboard visibility analysis, focusing on multimodal Vision-Language Models and CNN-based OCR pipelines. It does not discuss reinforcement learning or related data processing, thus it is irrelevant to the context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11731",
      "abstract": "Picat is a logic-based, multi-paradigm programming language that integrates features from logic, functional, constraint, and imperative programming paradigms. This paper presents solutions to several problems from the 2024 Advent of Code (AoC). While AoC problems are not designed for any specific programming language, certain problem types, such as reverse engineering and path-finding, are particularly well-suited to Picat due to its built-in constraint solving, pattern matching, backtracking, and dynamic programming with tabling. This paper demonstrates that Picat's features, especially its SAT-based constraint solving and tabling, enable concise, declarative, and highly efficient implementations of problems that would require significantly more effort in imperative languages.",
      "authors": [
        "Neng-Fa Zhou",
        "Cristian Grozea",
        "H{\\aa}kan Kjellerstrand",
        "Ois\\'in Mac Fheara\\'i"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:58:31+00:00",
          "link": "https://arxiv.org/abs/2507.11731v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "Picat Through the Lens of Advent of Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11731",
        "HTML": "https://arxiv.org/html/2507.11731v1",
        "PDF": "https://arxiv.org/pdf/2507.11731"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses the Picat programming language in the context of solving problems from Advent of Code, with no mention of reinforcement learning or data processing related to RL, making it irrelevant."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11732",
      "abstract": "Graph neural networks (GNNs) have emerged as a powerful framework for a wide range of node-level graph learning tasks. However, their performance is often constrained by reliance on random or minimally informed initial feature representations, which can lead to slow convergence and suboptimal solutions. In this paper, we leverage a statistically grounded method, one-hot graph encoder embedding (GEE), to generate high-quality initial node features that enhance the end-to-end training of GNNs. We refer to this integrated framework as the GEE-powered GNN (GG), and demonstrate its effectiveness through extensive simulations and real-world experiments across both unsupervised and supervised settings. In node clustering, GG consistently achieves state-of-the-art performance, ranking first across all evaluated real-world datasets, while exhibiting faster convergence compared to the standard GNN. For node classification, we further propose an enhanced variant, GG-C, which concatenates the outputs of GG and GEE and outperforms competing baselines. These results confirm the importance of principled, structure-aware feature initialization in realizing the full potential of GNNs.",
      "authors": [
        "Shiyu Chen",
        "Cencheng Shen",
        "Youngser Park",
        "Carey E. Priebe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:01:54+00:00",
          "link": "https://arxiv.org/abs/2507.11732v1",
          "size": "14094kb",
          "version": "v1"
        }
      ],
      "title": "Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11732",
        "HTML": "https://arxiv.org/html/2507.11732v1",
        "PDF": "https://arxiv.org/pdf/2507.11732"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses graph neural networks and improvements via one-hot graph encoder embedding for initial node features. It does not address reinforcement learning or data processing in the RL context, making it irrelevant to the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11733",
      "abstract": "This Study introduces Clarity and Reasoning Interface for Artificial Intelligence(ClarifAI), a novel approach designed to augment the transparency and interpretability of artificial intelligence (AI) in the realm of improved decision making. Leveraging the Case-Based Reasoning (CBR) methodology and integrating an ontology-driven approach, ClarifAI aims to meet the intricate explanatory demands of various stakeholders involved in AI-powered applications. The paper elaborates on ClarifAI's theoretical foundations, combining CBR and ontologies to furnish exhaustive explanation mechanisms. It further elaborates on the design principles and architectural blueprint, highlighting ClarifAI's potential to enhance AI interpretability across different sectors and its applicability in high-stake environments. This research delineates the significant role of ClariAI in advancing the interpretability of AI systems, paving the way for its deployment in critical decision-making processes.",
      "authors": [
        "Srikanth Vemula"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:02:28+00:00",
          "link": "https://arxiv.org/abs/2507.11733v1",
          "size": "69kb",
          "version": "v1"
        }
      ],
      "title": "ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11733",
        "HTML": "https://arxiv.org/html/2507.11733v1",
        "PDF": "https://arxiv.org/pdf/2507.11733"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing AI interpretability and transparency through Case-Based Reasoning and ontology-driven approaches, without addressing data processing in reinforcement learning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11737",
      "abstract": "Dynamic programming (DP) is a fundamental method in operations research, but formulating DP models has traditionally required expert knowledge of both the problem context and DP techniques. Large Language Models (LLMs) offer the potential to automate this process. However, DP problems pose unique challenges due to their inherently stochastic transitions and the limited availability of training data. These factors make it difficult to directly apply existing LLM-based models or frameworks developed for other optimization problems, such as linear or integer programming. We introduce DP-Bench, the first benchmark covering a wide range of textbook-level DP problems to enable systematic evaluation. We present Dynamic Programming Language Model (DPLM), a 7B-parameter specialized model that achieves performance comparable to state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on hard problems. Central to DPLM's effectiveness is DualReflect, our novel synthetic data generation pipeline, designed to scale up training data from a limited set of initial examples. DualReflect combines forward generation for diversity and backward generation for reliability. Our results reveal a key insight: backward generation is favored in low-data regimes for its strong correctness guarantees, while forward generation, though lacking such guarantees, becomes increasingly valuable at scale for introducing diverse formulations. This trade-off highlights the complementary strengths of both approaches and the importance of combining them.",
      "authors": [
        "Chenyu Zhou",
        "Jingyuan Yang",
        "Linwei Xin",
        "Yitian Chen",
        "Ziyan He",
        "Dongdong Ge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:09:43+00:00",
          "link": "https://arxiv.org/abs/2507.11737v1",
          "size": "995kb",
          "version": "v1"
        }
      ],
      "title": "Auto-Formulating Dynamic Programming Problems with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11737",
        "HTML": "https://arxiv.org/html/2507.11737v1",
        "PDF": "https://arxiv.org/pdf/2507.11737"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper primarily involves automating dynamic programming formulation, it introduces a synthetic data generation pipeline, DualReflect, which might offer insights into data augmentation techniques relevant to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11739",
      "abstract": "The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for discovering nonlinear dynamical system models from data. Quantifying uncertainty in SINDy models is essential for assessing their reliability, particularly in safety-critical applications. While various uncertainty quantification methods exist for SINDy, including Bayesian and ensemble approaches, this work explores the integration of Conformal Prediction, a framework that can provide valid prediction intervals with coverage guarantees based on minimal assumptions like data exchangeability. We introduce three applications of conformal prediction with Ensemble-SINDy (E-SINDy): (1) quantifying uncertainty in time series prediction, (2) model selection based on library feature importance, and (3) quantifying the uncertainty of identified model coefficients using feature conformal prediction. We demonstrate the three applications on stochastic predator-prey dynamics and several chaotic dynamical systems. We show that conformal prediction methods integrated with E-SINDy can reliably achieve desired target coverage for time series forecasting, effectively quantify feature importance, and produce more robust uncertainty intervals for model coefficients, even under non-Gaussian noise, compared to standard E-SINDy coefficient estimates.",
      "authors": [
        "Urban Fasel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:12:09+00:00",
          "link": "https://arxiv.org/abs/2507.11739v1",
          "size": "3384kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Identification of Nonlinear Dynamics with Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11739",
        "HTML": "https://arxiv.org/html/2507.11739v1",
        "PDF": "https://arxiv.org/pdf/2507.11739"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses uncertainty quantification in nonlinear dynamics using SINDy and conformal prediction, which does not pertain to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11742",
      "abstract": "Recognizing the information flows and operations comprising data science and machine learning Python notebooks is critical for evaluating, reusing, and adapting notebooks for new tasks. Investigating a notebook via re-execution often is impractical due to the challenges of resolving data and software dependencies. While Large Language Models (LLMs) pre-trained on large codebases have demonstrated effectiveness in understanding code without running it, we observe that they fail to understand some realistic notebooks due to hallucinations and long-context challenges. To address these issues, we propose a notebook understanding task yielding an information flow graph and corresponding cell execution dependency graph for a notebook, and demonstrate the effectiveness of a pincer strategy that uses limited syntactic analysis to assist full comprehension of the notebook using an LLM. Our Capture and Resolve Assisted Bounding Strategy (CRABS) employs shallow syntactic parsing and analysis of the abstract syntax tree (AST) to capture the correct interpretation of a notebook between lower and upper estimates of the inter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via cell-by-cell zero-shot learning, thereby identifying the true data inputs and outputs of each cell. We evaluate and demonstrate the effectiveness of our approach using an annotated dataset of 50 representative, highly up-voted Kaggle notebooks that together represent 3454 actual cell inputs and outputs. The LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the syntactic structure of these notebooks. Across 50 notebooks, CRABS achieves average F1 scores of 98% identifying cell-to-cell information flows and 99% identifying transitive cell execution dependencies.",
      "authors": [
        "Meng Li",
        "Timothy M. McPhillips",
        "Dingmin Wang",
        "Shin-Rong Tsai",
        "Bertram Lud\\\"ascher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:14:08+00:00",
          "link": "https://arxiv.org/abs/2507.11742v1",
          "size": "996kb",
          "version": "v1"
        }
      ],
      "title": "CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11742",
        "HTML": "https://arxiv.org/html/2507.11742v1",
        "PDF": "https://arxiv.org/pdf/2507.11742"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with interpreting Python notebooks using LLMs for syntactic-semantic analysis, which does not relate to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11744",
      "abstract": "The donation game is a well-established framework for studying the emergence and evolution of cooperation in multi-agent systems. The cooperative behavior can be influenced by the environmental noise in partially observable settings and by the decision-making strategies of agents, which may incorporate not only reputation but also traits such as generosity and forgiveness. Traditional simulations often assume fully random interactions, where cooperation is tested between randomly selected agent pairs. In this paper, we investigate cooperation dynamics using the concept of Stephen Wolfram's one-dimensional binary cellular automata. This approach allows us to explore how cooperation evolves when interactions are limited to neighboring agents. We define binary cellular automata rules that conform to the donation game mechanics. Additionally, we introduce models of perceptual and action noise, along with a mutation matrix governing the probabilistic evolution of agent strategies. Our empirical results demonstrate that cooperation is significantly affected by agents' mobility and their spatial locality on the game board. These findings highlight the importance of distinguishing between entirely random multi-agent systems and those in which agents are more likely to interact with their nearest neighbors.",
      "authors": [
        "Marcin Kowalik",
        "Przemys{\\l}aw Stok{\\l}osa",
        "Mateusz Grabowski",
        "Janusz Starzyk",
        "Pawe{\\l} Raif"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Computer Science and Game Theory (cs.GT)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:16:24+00:00",
          "link": "https://arxiv.org/abs/2507.11744v1",
          "size": "3515kb",
          "version": "v1"
        }
      ],
      "title": "A Cellular Automata Approach to Donation Game",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11744",
        "HTML": "https://arxiv.org/html/2507.11744v1",
        "PDF": "https://arxiv.org/pdf/2507.11744"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses cooperative behavior in multi-agent systems, it does not address data processing for reinforcement learning specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11746",
      "abstract": "A pervasive approach in scientific computing is to express the solution to a given problem as the limit of a sequence of vectors or other mathematical objects. In many situations these sequences are generated by slowly converging iterative procedures and this led practitioners to seek faster alternatives to reach the limit. ``Acceleration techniques'' comprise a broad array of methods specifically designed with this goal in mind. They started as a means of improving the convergence of general scalar sequences by various forms of ``extrapolation to the limit'', i.e., by extrapolating the most recent iterates to the limit via linear combinations. Extrapolation methods of this type, the best known example of which is Aitken's Delta-squared process, require only the sequence of vectors as input. However, limiting methods to only use the iterates is too restrictive. Accelerating sequences generated by fixed-point iterations by utilizing both the iterates and the fixed-point mapping itself has proven highly successful across various areas of physics. A notable example of these Fixed-Point accelerators (FP-Accelerators) is a method developed by D. Anderson in 1965 and now widely known as Anderson Acceleration (AA). Furthermore, Quasi-Newton and Inexact Newton methods can also be placed in this category as well. This paper presents an overview of these methods -- with an emphasis on those, such as AA, that are geared toward accelerating fixed point iterations.",
      "authors": [
        "Yousef Saad"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:20:36+00:00",
          "link": "https://arxiv.org/abs/2507.11746v1",
          "size": "365kb",
          "version": "v1"
        }
      ],
      "title": "Acceleration methods for fixed point iterations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11746",
        "HTML": "https://arxiv.org/html/2507.11746v1",
        "PDF": "https://arxiv.org/pdf/2507.11746"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses acceleration methods for fixed-point iterations, focusing on scientific computing techniques and extrapolation methods. It does not relate to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11749",
      "abstract": "The adoption of electric vehicles (EVs) is rapidly growing as a key solution to reducing greenhouse gas emissions. However, prolonged charging times remain a significant barrier to widespread EV usage, especially for individuals without access to fast charging infrastructure. This paper explores the potential of reconfigurable battery systems to reduce EV charging times without compromising battery life. We propose innovative battery pack configurations that dynamically adjust the arrangement of cells to optimize charging performance. Simulations were conducted using MATLAB and Simulink to compare the efficiency of various battery configurations, focusing on charging times, state of charge (SOC), voltage, and current under different conditions. The results demonstrate that connecting more batteries in series through reconfigurability in battery packs can significantly reduce charging times while maintaining operational safety. This study offers insights into how reconfigurable battery designs can provide a practical solution for faster, more efficient home-based EV charging, making EV ownership more accessible and sustainable.",
      "authors": [
        "Jonathan Olivares",
        "Tyler Depe",
        "Rakeshkumar Mahto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:28:26+00:00",
          "link": "https://arxiv.org/abs/2507.11749v1",
          "size": "834kb",
          "version": "v1"
        }
      ],
      "title": "Reconfigurable Battery Systems for Enhanced Fast Charging in Electric Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11749",
        "PDF": "https://arxiv.org/pdf/2507.11749"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper revolves around reconfigurable battery systems and their impact on electric vehicle charging. There is no connection to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11751",
      "abstract": "Identifying similar documents within extensive volumes of data poses a significant challenge. To tackle this issue, researchers have developed a variety of effective distributed computing techniques. With the advancement of computing power and the rise of big data, deep neural networks and evolutionary computing algorithms such as genetic algorithms and differential evolution algorithms have achieved greater success. This survey will explore the most recent advancements in the search for documents based on their semantic text similarity, focusing on genetic and differential evolutionary computing algorithms.",
      "authors": [
        "Chandrashekar Muniyappa",
        "Eunjin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:30:16+00:00",
          "link": "https://arxiv.org/abs/2507.11751v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11751",
        "HTML": "https://arxiv.org/html/2507.11751v1",
        "PDF": "https://arxiv.org/pdf/2507.11751"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This survey examines genetic and differential evolutionary algorithms for document semantic similarity search. It is not related to reinforcement learning or data processing within the RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11757",
      "abstract": "Accurately predicting drug-target interactions (DTIs) is pivotal for advancing drug discovery and target validation techniques. While machine learning approaches including those that are based on Graph Neural Networks (GNN) have achieved notable success in DTI prediction, many of them have difficulties in effectively integrating the diverse features of drugs, targets and their interactions. To address this limitation, we introduce a novel framework to take advantage of the power of both transductive learning and inductive learning so that features at molecular level and drug-target interaction network level can be exploited. Within this framework is a GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and target molecular structures as meta-nodes in a drug-target interaction graph, enabling a detailed exploration of their intricate relationships. To evaluate the proposed model, we have compiled a special benchmark comprising drug SMILES, protein sequences, and their interaction data, which is interesting in its own right. Our experimental results demonstrate that the GiG model significantly outperforms existing approaches across all evaluation metrics, highlighting the benefits of integrating different learning paradigms and interaction data.",
      "authors": [
        "Yuehua Song",
        "Yong Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:49:36+00:00",
          "link": "https://arxiv.org/abs/2507.11757v1",
          "size": "1639kb",
          "version": "v1"
        }
      ],
      "title": "A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11757",
        "HTML": "https://arxiv.org/html/2507.11757v1",
        "PDF": "https://arxiv.org/pdf/2507.11757"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "Although the paper focuses on drug-target interaction prediction using a Graph Neural Network framework, it mentions the compilation of a special benchmark dataset featuring drug SMILES and protein sequences. However, it does not make a significant technical contribution to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11759",
      "abstract": "Generating stable molecular conformations is crucial in several drug discovery applications, such as estimating the binding affinity of a molecule to a target. Recently, generative machine learning methods have emerged as a promising, more efficient method than molecular dynamics for sampling of conformations from the Boltzmann distribution. In this paper, we introduce Torsional-GFN, a conditional GFlowNet specifically designed to sample conformations of molecules proportionally to their Boltzmann distribution, using only a reward function as training signal. Conditioned on a molecular graph and its local structure (bond lengths and angles), Torsional-GFN samples rotations of its torsion angles. Our results demonstrate that Torsional-GFN is able to sample conformations approximately proportional to the Boltzmann distribution for multiple molecules with a single model, and allows for zero-shot generalization to unseen bond lengths and angles coming from the MD simulations for such molecules. Our work presents a promising avenue for scaling the proposed approach to larger molecular systems, achieving zero-shot generalization to unseen molecules, and including the generation of the local structure into the GFlowNet model.",
      "authors": [
        "Alexandra Volokhova",
        "L\\'ena N\\'ehale Ezzine",
        "Piotr Gai\\'nski",
        "Luca Scimeca",
        "Emmanuel Bengio",
        "Prudencio Tossou",
        "Yoshua Bengio",
        "Alex Hernandez-Garcia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:53:25+00:00",
          "link": "https://arxiv.org/abs/2507.11759v1",
          "size": "8959kb",
          "version": "v1"
        }
      ],
      "title": "Torsional-GFN: a conditional conformation generator for small molecules",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11759",
        "HTML": "https://arxiv.org/html/2507.11759v1",
        "PDF": "https://arxiv.org/pdf/2507.11759"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces Torsional-GFN, a conditional GFlowNet for molecule conformation generation based on Boltzmann distribution sampling, with no direct relevance to reinforcement learning data processing or related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11761",
      "abstract": "Abstract visual reasoning (AVR) enables humans to quickly discover and generalize abstract rules to new scenarios. Designing intelligent systems with human-like AVR abilities has been a long-standing topic in the artificial intelligence community. Deep AVR solvers have recently achieved remarkable success in various AVR tasks. However, they usually use task-specific designs or parameters in different tasks. In such a paradigm, solving new tasks often means retraining the model, and sometimes retuning the model architectures, which increases the cost of solving AVR problems. In contrast to task-specific approaches, this paper proposes a novel Unified Conditional Generative Solver (UCGS), aiming to address multiple AVR tasks in a unified framework. First, we prove that some well-known AVR tasks can be reformulated as the problem of estimating the predictability of target images in problem panels. Then, we illustrate that, under the proposed framework, training one conditional generative model can solve various AVR tasks. The experiments show that with a single round of multi-task training, UCGS demonstrates abstract reasoning ability across various AVR tasks. Especially, UCGS exhibits the ability of zero-shot reasoning, enabling it to perform abstract reasoning on problems from unseen AVR tasks in the testing phase.",
      "authors": [
        "Fan Shi",
        "Bin Li",
        "Xiangyang Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:54:51+00:00",
          "link": "https://arxiv.org/abs/2507.11761v1",
          "size": "1918kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11761",
        "HTML": "https://arxiv.org/html/2507.11761v1",
        "PDF": "https://arxiv.org/pdf/2507.11761"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on abstract visual reasoning using a Unified Conditional Generative Solver for AVR tasks. It does not make any direct contributions to data processing within the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11763",
      "abstract": "Cyber threats against space infrastructures, including satellites and systems on the ground, have not been adequately understood. Testbeds are important to deepen our understanding and validate space cybersecurity studies. The state of the art is that there are very few studies on building testbeds, and there are few characterizations of testbeds. In this paper, we propose a framework for characterizing the fidelity of space cybersecurity testbeds. The framework includes 7 attributes for characterizing the system models, threat models, and defenses that can be accommodated by a testbed. We use the framework to guide us in building and characterizing a concrete testbed we have implemented, which includes space, ground, user, and link segments. In particular, we show how the testbed can accommodate some space cyber attack scenarios that have occurred in the real world, and discuss future research directions.",
      "authors": [
        "Jose Luis Castanon Remy",
        "Caleb Chang",
        "Ekzhin Ear",
        "and Shouhuai Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:03:00+00:00",
          "link": "https://arxiv.org/abs/2507.11763v1",
          "size": "8199kb",
          "version": "v1"
        }
      ],
      "title": "Space Cybersecurity Testbed: Fidelity Framework, Example Implementation, and Characterization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11763",
        "HTML": "https://arxiv.org/html/2507.11763v1",
        "PDF": "https://arxiv.org/pdf/2507.11763"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is about creating a framework for space cybersecurity testbeds and does not discuss reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11764",
      "abstract": "This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab Task 1: Subjectivity Detection in News Articles, classifying sentences as subjective/objective in monolingual, multilingual, and zero-shot settings. Training/development datasets were provided for Arabic, German, English, Italian, and Bulgarian; final evaluation included additional unseen languages (e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our primary strategy enhanced transformer-based classifiers by integrating sentiment scores, derived from an auxiliary model, with sentence representations, aiming to improve upon standard fine-tuning. We explored this sentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base (English), and Llama3.2-1B. To address class imbalance, prevalent across languages, we employed decision threshold calibration optimized on the development set. Our experiments show sentiment feature integration significantly boosts performance, especially subjective F1 score. This framework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).",
      "authors": [
        "Matteo Fasulo",
        "Luca Babboni",
        "Luca Tedeschini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:10:20+00:00",
          "link": "https://arxiv.org/abs/2507.11764v1",
          "size": "1000kb",
          "version": "v1"
        }
      ],
      "title": "AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11764",
        "HTML": "https://arxiv.org/html/2507.11764v1",
        "PDF": "https://arxiv.org/pdf/2507.11764"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses enhancing transformer-based models for subjectivity detection in news articles by integrating sentiment scores. It does not involve reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11770",
      "abstract": "In robotics, the effective integration of environmental data into actionable knowledge remains a significant challenge due to the variety and incompatibility of data formats commonly used in scene descriptions, such as MJCF, URDF, and SDF. This paper presents a novel approach that addresses these challenges by developing a unified scene graph model that standardizes these varied formats into the Universal Scene Description (USD) format. This standardization facilitates the integration of these scene graphs with robot ontologies through semantic reporting, enabling the translation of complex environmental data into actionable knowledge essential for cognitive robotic control. We evaluated our approach by converting procedural 3D environments into USD format, which is then annotated semantically and translated into a knowledge graph to effectively answer competency questions, demonstrating its utility for real-time robotic decision-making. Additionally, we developed a web-based visualization tool to support the semantic mapping process, providing users with an intuitive interface to manage the 3D environment.",
      "authors": [
        "Giang Nguyen",
        "Mihai Pomarlan",
        "Sascha Jongebloed",
        "Nils Leusmann",
        "Minh Nhat Vu and Michael Beetz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:20:47+00:00",
          "link": "https://arxiv.org/abs/2507.11770v1",
          "size": "4759kb",
          "version": "v1"
        }
      ],
      "title": "Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11770",
        "HTML": "https://arxiv.org/html/2507.11770v1",
        "PDF": "https://arxiv.org/pdf/2507.11770"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper describes a method for creating robot knowledge bases by integrating environmental data and does not involve reinforcement learning or related data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11771",
      "abstract": "As large language models (LLMs) evolve in complexity and capability, the efficacy of less widely deployed alignment techniques are uncertain. Building on previous work on activation steering and contrastive activation addition (CAA), this paper explores the effectiveness of CAA with model scale using the family of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable 'directions' in the model's residual stream vector space using contrastive pairs (for example, hate to love) and adding this direction to the residual stream during the forward pass. It directly manipulates the residual stream and aims to extract features from language models to better control their outputs. Using answer matching questions centered around the refusal behavior, we found that 1) CAA is most effective when applied at early-mid layers. 2) The effectiveness of CAA diminishes with model size. 3) Negative steering has more pronounced effects than positive steering across all model sizes.",
      "authors": [
        "Sheikh Abdur Raheem Ali",
        "Justin Xu",
        "Ivory Yang",
        "Jasmine Xinze Li",
        "Ayse Arslan",
        "Clark Benham"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:21:18+00:00",
          "link": "https://arxiv.org/abs/2507.11771v1",
          "size": "867kb",
          "version": "v1"
        }
      ],
      "title": "Scaling laws for activation steering with Llama 2 models and refusal mechanisms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11771",
        "HTML": "https://arxiv.org/html/2507.11771v1",
        "PDF": "https://arxiv.org/pdf/2507.11771"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses activation steering and contrastive activation addition techniques in large language models (LLMs), with no mention of reinforcement learning or data processing specific to RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11772",
      "abstract": "Distributed Denial of Service (DDoS) attacks have become increasingly prevalent and dangerous in the context of Internet of Things (IoT) networks, primarily due to the low-security configurations of many connected devices. This paper analyzes the nature and impact of DDoS attacks such as those launched by the Mirai botnet, and proposes layered mitigation strategies tailored to IoT environments. Key solutions explored include IPv6 Unique Local Addresses (ULA), edge computing, software-defined networking (SDN), honeypot deception, and machine learning-based intrusion detection systems. The paper aims to help engineers and researchers understand and implement practical countermeasures to protect IoT infrastructures.",
      "authors": [
        "Ifiyemi Leigha",
        "Basak Comlekcioglu",
        "Maria Pilar Bezanilla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:21:19+00:00",
          "link": "https://arxiv.org/abs/2507.11772v1",
          "size": "444kb",
          "version": "v1"
        }
      ],
      "title": "How To Mitigate And Defend Against DDoS Attacks In IoT Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11772",
        "HTML": "https://arxiv.org/html/2507.11772v1",
        "PDF": "https://arxiv.org/pdf/2507.11772"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing and mitigating DDoS attacks in IoT environments, which is unrelated to reinforcement learning or any RL data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11773",
      "abstract": "The emergence of breakthrough artificial intelligence (AI) techniques has led to a renewed focus on how small data settings, i.e., settings with limited information, can benefit from such developments. This includes societal issues such as how best to include under-represented groups in data-driven policy and decision making, or the health benefits of assistive technologies such as wearables. We provide a conceptual overview, in particular contrasting small data with big data, and identify common themes from exemplary case studies and application areas. Potential solutions are described in a more detailed technical overview of current data analysis and modelling techniques, highlighting contributions from different disciplines, such as knowledge-driven modelling from statistics and data-driven modelling from computer science. By linking application settings, conceptual contributions and specific techniques, we highlight what is already feasible and suggest what an agenda for fully leveraging small data might look like.",
      "authors": [
        "Maren Hackenberg",
        "Sophia G. Connor",
        "Fabian Kabus",
        "June Brawner",
        "Ella Markham",
        "Mahi Hardalupas",
        "Areeq Chowdhury",
        "Rolf Backofen",
        "Anna K\\\"ottgen",
        "Angelika Rohde",
        "Nadine Binder",
        "Harald Binder",
        "and the Collaborative Research Center 1597 Small Data"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:24:17+00:00",
          "link": "https://arxiv.org/abs/2507.11773v1",
          "size": "172kb",
          "version": "v1"
        }
      ],
      "title": "Small Data Explainer -- The impact of small data methods in everyday life",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11773",
        "HTML": "https://arxiv.org/html/2507.11773v1",
        "PDF": "https://arxiv.org/pdf/2507.11773"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper provides an overview of small data methods and contrasts them with big data, without any specific focus on reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11775",
      "abstract": "Authentication and authenticity have been a security challenge since the beginning of information sharing, especially in the context of digital information. With the advancement of generative artificial intelligence, these challenges have evolved, demanding a more up-to-date analysis of their impacts on society and system security. This work presents a scoping review that analyzed 88 documents from the IEEExplorer, Scopus, and ACM databases, promoting an analysis of the resulting portfolio through six guiding questions focusing on the most relevant work, challenges, attack surfaces, threats, proposed solutions, and gaps. Finally, the portfolio articles are analyzed through this guiding research lens and also receive individualized analysis. The results consistently outline the challenges, gaps, and threats related to images, text, audio, and video, thereby supporting new research in the areas of authentication and generative artificial intelligence.",
      "authors": [
        "Wesley dos Reis Bezerra",
        "Lais Machado Bezerra",
        "Carlos Becker Westphall"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:25:39+00:00",
          "link": "https://arxiv.org/abs/2507.11775v1",
          "size": "131kb",
          "version": "v1"
        }
      ],
      "title": "Challenges in GenAI and Authentication: a scoping review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11775",
        "HTML": "https://arxiv.org/html/2507.11775v1",
        "PDF": "https://arxiv.org/pdf/2507.11775"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is centered on authentication challenges in the context of generative AI and does not discuss aspects related to reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11776",
      "abstract": "The Dutch railway network is one of the busiest in the world, with delays being a prominent concern for the principal passenger railway operator NS. This research addresses a gap in delay prediction studies within the Dutch railway network by employing an XGBoost Classifier with a focus on topological features. Current research predominantly emphasizes short-term predictions and neglects the broader network-wide patterns essential for mitigating ripple effects. This research implements and improves an existing methodology, originally designed to forecast the evolution of the fast-changing US air network, to predict delays in the Dutch Railways. By integrating Node Centrality Measures and comparing multiple classifiers like RandomForest, DecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is to predict delayed trajectories. However, the results reveal limited performance, especially in non-simultaneous testing scenarios, suggesting the necessity for more context-specific adaptations. Regardless, this research contributes to the understanding of transportation network evaluation and proposes future directions for developing more robust predictive models for delays.",
      "authors": [
        "Merel Kampere",
        "Ali Mohammed Mansoor Alsahag"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:30:36+00:00",
          "link": "https://arxiv.org/abs/2507.11776v1",
          "size": "1155kb",
          "version": "v1"
        }
      ],
      "title": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11776",
        "HTML": "https://arxiv.org/html/2507.11776v1",
        "PDF": "https://arxiv.org/pdf/2507.11776"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses delay prediction in railway networks using various machine learning classifiers, but it does not pertain to reinforcement learning or any data processing techniques related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11777",
      "abstract": "Advances in voice conversion and text-to-speech synthesis have made automatic speaker verification (ASV) systems more susceptible to spoofing attacks. This work explores modest refinements to the AASIST anti-spoofing architecture. It incorporates a frozen Wav2Vec 2.0 encoder to retain self-supervised speech representations in limited-data settings, substitutes the original graph attention block with a standardized multi-head attention module using heterogeneous query projections, and replaces heuristic frame-segment fusion with a trainable, context-aware integration layer. When evaluated on the ASVspoof 5 corpus, the proposed system reaches a 7.6\\% equal error rate (EER), improving on a re-implemented AASIST baseline under the same training conditions. Ablation experiments suggest that each architectural change contributes to the overall performance, indicating that targeted adjustments to established models may help strengthen speech deepfake detection in practical scenarios. The code is publicly available at https://github.com/KORALLLL/AASIST_SCALING.",
      "authors": [
        "Ivan Viakhirev and Daniil Sirota and Aleksandr Smirnov and Kirill Borodin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:31:43+00:00",
          "link": "https://arxiv.org/abs/2507.11777v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11777",
        "HTML": "https://arxiv.org/html/2507.11777v1",
        "PDF": "https://arxiv.org/pdf/2507.11777"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is focused on improving speech deepfake detection using modified architecture components in an anti-spoofing system, which does not relate to reinforcement learning or its data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11787",
      "abstract": "Swarm Intelligence (SI) is gaining a lot of popularity in artificial intelligence, where the natural behavior of animals and insects is observed and translated into computer algorithms called swarm computing to solve real-world problems. Due to their effectiveness, they are applied in solving various computer optimization problems. This survey will review all the latest developments in Searching for documents based on semantic similarity using Swarm Intelligence algorithms and recommend future research directions.",
      "authors": [
        "Chandrashekar Muniyappa",
        "Eunjin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:03:52+00:00",
          "link": "https://arxiv.org/abs/2507.11787v1",
          "size": "88kb",
          "version": "v1"
        }
      ],
      "title": "Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11787",
        "HTML": "https://arxiv.org/html/2507.11787v1",
        "PDF": "https://arxiv.org/pdf/2507.11787"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The survey explores swarm intelligence approaches for document search based on semantic similarity, which does not pertain to reinforcement learning or the data processing involved therein."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11788",
      "abstract": "Despite tremendous progress in neuroscience, we do not have a compelling narrative for the precise way whereby the spiking of neurons in our brain results in high-level cognitive phenomena such as planning and language. We introduce a simple mathematical formulation of six basic and broadly accepted principles of neuroscience: excitatory neurons, brain areas, random synapses, Hebbian plasticity, local inhibition, and inter-area inhibition. We implement a simulated neuromorphic system based on this formalism, which is capable of basic language acquisition: Starting from a tabula rasa, the system learns, in any language, the semantics of words, their syntactic role (verb versus noun), and the word order of the language, including the ability to generate novel sentences, through the exposure to a modest number of grounded sentences in the same language. We discuss several possible extensions and implications of this result.",
      "authors": [
        "Daniel Mitropolsky and Christos Papadimitriou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:04:44+00:00",
          "link": "https://arxiv.org/abs/2507.11788v1",
          "size": "718kb",
          "version": "v1"
        }
      ],
      "title": "Simulated Language Acquisition in a Biologically Realistic Model of the Brain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11788",
        "HTML": "https://arxiv.org/html/2507.11788v1",
        "PDF": "https://arxiv.org/pdf/2507.11788"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a neuromorphic system for language acquisition based on neuroscience principles, without specific mention of reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11789",
      "abstract": "Latent space interpolations are a powerful tool for navigating deep generative models in applied settings. An example is single-cell RNA sequencing, where existing methods model cellular state transitions as latent space interpolations with variational autoencoders, often assuming linear shifts and Euclidean geometry. However, unless explicitly enforced, linear interpolations in the latent space may not correspond to geodesic paths on the data manifold, limiting methods that assume Euclidean geometry in the data representations. We introduce FlatVI, a novel training framework that regularises the latent manifold of discrete-likelihood variational autoencoders towards Euclidean geometry, specifically tailored for modelling single-cell count data. By encouraging straight lines in the latent space to approximate geodesic interpolations on the decoded single-cell manifold, FlatVI enhances compatibility with downstream approaches that assume Euclidean latent geometry. Experiments on synthetic data support the theoretical soundness of our approach, while applications to time-resolved single-cell RNA sequencing data demonstrate improved trajectory reconstruction and manifold interpolation.",
      "authors": [
        "Alessandro Palma",
        "Sergei Rybakov",
        "Leon Hetzel",
        "Stephan G\\\"unnemann",
        "Fabian J. Theis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:08:14+00:00",
          "link": "https://arxiv.org/abs/2507.11789v1",
          "size": "9982kb",
          "version": "v1"
        }
      ],
      "title": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11789",
        "HTML": "https://arxiv.org/html/2507.11789v1",
        "PDF": "https://arxiv.org/pdf/2507.11789"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses variance in interpolations within single-cell variational autoencoders for cellular data. It does not address reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11794",
      "abstract": "This study explores the capabilities of WebGPU, an emerging web graphics paradigm, for real-time cloth simulation. Traditional WebGL-based methods have been in handling complex physical simulations due to their emphasis on graphics rendering rather than general-purpose GPU (GPGPU) operations. WebGPU, designed to provide modern 3D graphics and computational capabilities, offers significant improvements through parallel processing and support for computational shaders. In this work, we implemented a cloth simulation system using the Mass-Spring Method within the WebGPU framework, integrating collision detection and response handling with the 3D surface model. First, comparative performance evaluations demonstrate that WebGPU substantially outperforms WebGL, particularly in high-resolution simulations, maintaining 60 frames per second (fps) even with up to 640K nodes. The second experiment aimed to determine the real-time limitations of WebGPU and confirmed that WebGPU can handle real-time collisions between 4K and 100k cloth node models and a 100K triangle surface model in real-time. These experiments also highlight the importance of balancing real-time performance with realistic rendering when handling collisions between cloth models and complex 3D objects. Our source code is available at https://github.com/nakjun/Cloth-Simulation-WebGPU",
      "authors": [
        "Nak-Jun Sung",
        "Jun Ma",
        "TaeHeon Kim",
        "Yoo-joo Choi",
        "Min-Hyung Choi and Min Hong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:16:41+00:00",
          "link": "https://arxiv.org/abs/2507.11794v1",
          "size": "33092kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Cloth Simulation Using WebGPU: Evaluating Limits of High-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11794",
        "HTML": "https://arxiv.org/html/2507.11794v1",
        "PDF": "https://arxiv.org/pdf/2507.11794"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper evaluates real-time cloth simulation using WebGPU for performance improvements. It does not involve reinforcement learning or any data processing related to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11797",
      "abstract": "Understanding how teams coordinate, share work, and negotiate roles in immersive environments is critical for designing effective mixed-reality (MR) applications that support real-time collaboration. However, existing methods either rely on external cameras and offline annotation or focus narrowly on single modalities, limiting their validity and applicability. To address this, we present a novel group interaction sensing toolkit (GIST), a deployable system that passively captures multi-modal interaction data, such as speech, gaze, and spatial proximity from commodity MR headset's sensors and automatically derives both overall static interaction networks and dynamic moment-by-moment behavior patterns. We evaluate GIST with a human subject study with 48 participants across 12 four-person groups performing an open-ended image-sorting task in MR. Our analysis shows strong alignment between the identified behavior modes and shifts in interaction network structure, confirming that momentary changes in speech, gaze, and proximity data are observable through the sensor data.",
      "authors": [
        "Diana Romero",
        "Yasra Chandio",
        "Fatima Anwar",
        "Salma Elmalaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:21:28+00:00",
          "link": "https://arxiv.org/abs/2507.11797v1",
          "size": "923kb",
          "version": "v1"
        }
      ],
      "title": "GIST: Group Interaction Sensing Toolkit for Mixed Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11797",
        "HTML": "https://arxiv.org/html/2507.11797v1",
        "PDF": "https://arxiv.org/pdf/2507.11797"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research introduces a toolkit for sensing group interactions in mixed reality environments, without any mention of reinforcement learning or relevant data processing techniques for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11798",
      "abstract": "We analyzed spatial complexity, defined as the relationship between the required bitrate and a corresponding picture Quality of Experience (QoE) metric, for realistic, long, real-time, interactive video clips. Apart from variation across different content types, e.g., game genres, we discovered time-variability within a clip from second to second, and explored the ramifications for traffic management. We introduced utility as an elegant way to manage resource sharing preferences. Our analysis of resource sharing methods shows that frequent QoE-aware reallocation has significant performance advantages compared to static rate allocation, even in case the latter is based on rich information about long-term average spatial complexity. We have also shown that utility-based resource allocation has clear advantages over methods targeting equal QoE allocation, it increases the average QoE, while it still controls the worst case QoE.",
      "authors": [
        "Szilveszter N\\'adas",
        "Lars Ernstr\\\"om",
        "David Lindero",
        "Jonathan Lynam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:28:12+00:00",
          "link": "https://arxiv.org/abs/2507.11798v1",
          "size": "331kb",
          "version": "v1"
        }
      ],
      "title": "On QoE-Aware Traffic Management for Real-time, Interactive Video with Time-variant Spatial Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11798",
        "HTML": "https://arxiv.org/html/2507.11798v1",
        "PDF": "https://arxiv.org/pdf/2507.11798"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses QoE-aware traffic management for interactive video. It does not reference reinforcement learning or any data processing aspects associated with RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11802",
      "abstract": "Research experience is crucial for computing master's students pursuing academic and scientific careers, yet online students have traditionally been excluded from these opportunities due to the physical constraints of traditional research environments. This paper presents the Framework for Accelerating Interdisciplinary Research in Computer Science (FAIR-CS), a method for achieving research goals, developing research communities, and supporting high quality mentorship in an online research environment. This method advances virtual research operations by orchestrating dynamic partnerships between master's level researchers and academic mentors, resulting in interdisciplinary publications. We then discuss the implementation of FAIR-CS in the Human-Augmented Analytics Group (HAAG), with researchers from the Georgia Tech's Online Master of Computer Science program. Through documented project records and experiences with 72 active users, we present our lessons learned and evaluate the evolution of FAIR-CS in HAAG. This paper serves as a comprehensive resource for other institutions seeking to establish similar virtual research initiatives, demonstrating how the traditional research lab environment can be effectively replicated in the virtual space while maintaining robust collaborative relationships and supporting knowledge transfer.",
      "authors": [
        "Breanna Shi",
        "Thomas Deatherage",
        "Jeanette Schofield",
        "Charles R. Clark",
        "Thomas Orth",
        "Nicholas Lytle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "General Literature (cs.GL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:51:17+00:00",
          "link": "https://arxiv.org/abs/2507.11802v1",
          "size": "6847kb",
          "version": "v1"
        }
      ],
      "title": "FAIR-CS: Framework for Interdisciplinary Research Collaborations in Online Computing Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11802",
        "HTML": "https://arxiv.org/html/2507.11802v1",
        "PDF": "https://arxiv.org/pdf/2507.11802"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for virtual research collaborations in online computing programs and does not address reinforcement learning or any data processing issues specific to this field."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11807",
      "abstract": "Learning with noisy labels (LNL) is essential for training deep neural networks with imperfect data. Meta-learning approaches have achieved success by using a clean unbiased labeled set to train a robust model. However, this approach heavily depends on the availability of a clean labeled meta-dataset, which is difficult to obtain in practice. In this work, we thus tackle the challenge of meta-learning for noisy label scenarios without relying on a clean labeled dataset. Our approach leverages the data itself while bypassing the need for labels. Building on the insight that clean samples effectively preserve the consistency of related data structures across the last hidden and the final layer, whereas noisy samples disrupt this consistency, we design the Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU). CLID-MU leverages the alignment of data structures across these diverse feature spaces to evaluate model performance and use this alignment to guide training. Experiments on benchmark datasets with varying amounts of labels under both synthetic and real-world noise demonstrate that CLID-MU outperforms state-of-the-art methods. The code is released at https://github.com/ruofanhu/CLID-MU.",
      "authors": [
        "Ruofan Hu",
        "Dongyu Zhang",
        "Huayi Zhang",
        "Elke Rundensteiner"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:03:07+00:00",
          "link": "https://arxiv.org/abs/2507.11807v1",
          "size": "741kb",
          "version": "v1"
        }
      ],
      "title": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11807",
        "HTML": "https://arxiv.org/html/2507.11807v1",
        "PDF": "https://arxiv.org/pdf/2507.11807"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on learning with noisy labels and introduces a meta-update strategy for neural networks. It does not pertain to reinforcement learning or data processing specific to reinforcement learning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11808",
      "abstract": "This study introduces the \\emph{edge-based Shapley value}, a novel allocation rule within cooperative game theory, specifically tailored for networked systems, where value is generated through interactions represented by edges. Traditional allocation rules, such as the Shapley and Myerson values, evaluate player contributions based on node-level characteristics, or connected components. However, these approaches often fail to adequately capture the functional role of edges, which are crucial in systems such as supply chains and digital platforms, where interactions, rather than individual agents, are the primary drivers of value. Our edge-based Shapley value shifts the characteristic function from node sets to edge sets, thereby enabling a more granular and context-sensitive evaluation of the contributions. We establish its theoretical foundations, demonstrate its relationship to classical allocation rules, and show that it retains key properties such as fairness and symmetry. To illustrate its applicability, we present two use cases: content platform networks and supply chain logistics (SCL). In both cases, our method produces intuitive and structurally consistent allocations, particularly in scenarios with overlapping routes, exclusive contracts or cost-sensitive paths. This framework offers a new perspective on value attribution in cooperative settings with complex interaction structures and provides practical tools for analyzing real-world economic and logistical networks.",
      "authors": [
        "Taiki Yamada",
        "Taisuke Matsubae",
        "Tomoya Akamatsu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:06:53+00:00",
          "link": "https://arxiv.org/abs/2507.11808v1",
          "size": "578kb",
          "version": "v1"
        }
      ],
      "title": "New allocation rule based on graph structures and their application to economic phenomena",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11808",
        "HTML": "https://arxiv.org/html/2507.11808v1",
        "PDF": "https://arxiv.org/pdf/2507.11808"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study discusses a new allocation rule within cooperative game theory related to networked systems. There is no mention of reinforcement learning or relevant data processing techniques in this context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11809",
      "abstract": "This paper presents a reproducibility study examining how Large Language Models (LLMs) manage competing factual and counterfactual information, focusing on the role of attention heads in this process. We attempt to reproduce and reconcile findings from three recent studies by Ortu et al., Yu, Merullo, and Pavlick and McDougall et al. that investigate the competition between model-learned facts and contradictory context information through Mechanistic Interpretability tools. Our study specifically examines the relationship between attention head strength and factual output ratios, evaluates competing hypotheses about attention heads' suppression mechanisms, and investigates the domain specificity of these attention patterns. Our findings suggest that attention heads promoting factual output do so via general copy suppression rather than selective counterfactual suppression, as strengthening them can also inhibit correct facts. Additionally, we show that attention head behavior is domain-dependent, with larger models exhibiting more specialized and category-sensitive patterns.",
      "authors": [
        "Dante Campregher",
        "Yanxu Chen",
        "Sander Hoffman",
        "Maria Heuss"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:08:48+00:00",
          "link": "https://arxiv.org/abs/2507.11809v1",
          "size": "1639kb",
          "version": "v1"
        }
      ],
      "title": "Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11809",
        "HTML": "https://arxiv.org/html/2507.11809v1",
        "PDF": "https://arxiv.org/pdf/2507.11809"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mechanistic interpretability of Large Language Models and not on reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11810",
      "abstract": "Scientific innovation is undergoing a paradigm shift driven by the rapid advancement of Large Language Models (LLMs). As science faces mounting challenges including information overload, disciplinary silos, and diminishing returns on conventional research methods, LLMs are emerging as powerful agents capable not only of enhancing scientific workflows but also of participating in and potentially leading the innovation process. Existing surveys mainly focus on different perspectives, phrases, and tasks in scientific research and discovery, while they have limitations in understanding the transformative potential and role differentiation of LLM. This survey proposes a comprehensive framework to categorize the evolving roles of LLMs in scientific innovation across three hierarchical levels: Evaluator, Collaborator, and Scientist. We distinguish between LLMs' contributions to structured scientific research processes and open-ended scientific discovery, thereby offering a unified taxonomy that clarifies capability boundaries, evaluation criteria, and human-AI interaction patterns at each level. Through an extensive analysis of current methodologies, benchmarks, systems, and evaluation metrics, this survey delivers an in-depth and systematic synthesis on LLM-driven scientific innovation. We present LLMs not only as tools for automating existing processes, but also as catalysts capable of reshaping the epistemological foundations of science itself. This survey offers conceptual clarity, practical guidance, and theoretical foundations for future research, while also highlighting open challenges and ethical considerations in the pursuit of increasingly autonomous AI-driven science. Resources related to this survey can be accessed on GitHub at: https://github.com/haoxuan-unt2024/llm4innovation.",
      "authors": [
        "Haoxuan Zhang",
        "Ruochi Li",
        "Yang Zhang",
        "Ting Xiao",
        "Jiangping Chen",
        "Junhua Ding",
        "Haihua Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:11:01+00:00",
          "link": "https://arxiv.org/abs/2507.11810v1",
          "size": "7674kb",
          "version": "v1"
        }
      ],
      "title": "The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11810",
        "HTML": "https://arxiv.org/html/2507.11810v1",
        "PDF": "https://arxiv.org/pdf/2507.11810"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on the roles of Large Language Models in scientific innovation, which does not involve reinforcement learning or data processing specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11812",
      "abstract": "Sound speed profiles (SSPs) are essential parameters underwater that affects the propagation mode of underwater signals and has a critical impact on the energy efficiency of underwater acoustic communication and accuracy of underwater acoustic positioning. Traditionally, SSPs can be obtained by matching field processing (MFP), compressive sensing (CS), and deep learning (DL) methods. However, existing methods mainly rely on on-site underwater sonar observation data, which put forward strict requirements on the deployment of sonar observation systems. To achieve high-precision estimation of sound velocity distribution in a given sea area without on-site underwater data measurement, we propose a multi-modal data-fusion generative adversarial network model with residual attention block (MDF-RAGAN) for SSP construction. To improve the model's ability for capturing global spatial feature correlations, we embedded the attention mechanisms, and use residual modules for deeply capturing small disturbances in the deep ocean sound velocity distribution caused by changes of SST. Experimental results on real open dataset show that the proposed model outperforms other state-of-the-art methods, which achieves an accuracy with an error of less than 0.3m/s. Specifically, MDF-RAGAN not only outperforms convolutional neural network (CNN) and spatial interpolation (SITP) by nearly a factor of two, but also achieves about 65.8\\% root mean square error (RMSE) reduction compared to mean profile, which fully reflects the enhancement of overall profile matching by multi-source fusion and cross-modal attention.",
      "authors": [
        "Wei Huang",
        "Yuqiang Huang",
        "Yanan Wu",
        "Tianhe Xu",
        "Junting Wang",
        "Hao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:21:54+00:00",
          "link": "https://arxiv.org/abs/2507.11812v1",
          "size": "19987kb",
          "version": "v1"
        }
      ],
      "title": "A Multimodal Data Fusion Generative Adversarial Network for Real Time Underwater Sound Speed Field Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11812",
        "HTML": "https://arxiv.org/html/2507.11812v1",
        "PDF": "https://arxiv.org/pdf/2507.11812"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a multimodal data fusion technique for underwater sound speed field construction without mentioning reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11818",
      "abstract": "Ensuring synthesizability in generative small molecule design remains a major challenge. While recent developments in synthesizable molecule generation have demonstrated promising results, these efforts have been largely confined to 2D molecular graph representations, limiting the ability to perform geometry-based conditional generation. In this work, we present SynCoGen (Synthesizable Co-Generation), a single framework that combines simultaneous masked graph diffusion and flow matching for synthesizable 3D molecule generation. SynCoGen samples from the joint distribution of molecular building blocks, chemical reactions, and atomic coordinates. To train the model, we curated SynSpace, a dataset containing over 600K synthesis-aware building block graphs and 3.3M conformers. SynCoGen achieves state-of-the-art performance in unconditional small molecule graph and conformer generation, and the model delivers competitive performance in zero-shot molecular linker design for protein ligand generation in drug discovery. Overall, this multimodal formulation represents a foundation for future applications enabled by non-autoregressive molecular generation, including analog expansion, lead optimization, and direct structure conditioning.",
      "authors": [
        "Andrei Rekesh",
        "Miruna Cretu",
        "Dmytro Shevchuk",
        "Vignesh Ram Somnath",
        "Pietro Li\\`o",
        "Robert A. Batey",
        "Mike Tyers",
        "Micha{\\l} Koziarski",
        "Cheng-Hao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:36:35+00:00",
          "link": "https://arxiv.org/abs/2507.11818v1",
          "size": "14385kb",
          "version": "v1"
        }
      ],
      "title": "SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11818",
        "HTML": "https://arxiv.org/html/2507.11818v1",
        "PDF": "https://arxiv.org/pdf/2507.11818"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D molecule generation through a proposed method, SynCoGen. It does not pertain to reinforcement learning or data processing in the RL field."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11819",
      "abstract": "We design a quasi-interpolation operator from the Sobolev space $H^1_0(\\Omega)$ to its finite-dimensional finite element subspace formed by piecewise polynomials on a simplicial mesh with a computable approximation constant. The operator 1) is defined on the entire $H^1_0(\\Omega)$, no additional regularity is needed; 2) allows for an arbitrary polynomial degree; 3) works in any space dimension; 4) is defined locally, in vertex patches of mesh elements; 5) yields optimal estimates for both the $H^1$ seminorm and the $L^2$ norm error; 6) gives a computable constant for both the $H^1$ seminorm and the $L^2$ norm error; 7) leads to the equivalence of global-best and local-best errors; 8) possesses the projection property. Its construction follows the so-called potential reconstruction from a posteriori error analysis. Numerical experiments illustrate that our quasi-interpolation operator systematically gives the correct convergence rates in both the $H^1$ seminorm and the $L^2$ norm and its certified overestimation factor is rather sharp and stable in all tested situations.",
      "authors": [
        "T. Chaumont-Frelet and M. Vohralik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:40:46+00:00",
          "link": "https://arxiv.org/abs/2507.11819v1",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "title": "A quasi-interpolation operator yielding fully computable error bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11819",
        "PDF": "https://arxiv.org/pdf/2507.11819"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a quasi-interpolation operator for finite elements in numerical analysis, focusing on error bounds and approximation rather than any aspect of data processing within reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11821",
      "abstract": "Neural networks are often benchmarked using standard datasets such as MNIST, FashionMNIST, or other variants of MNIST, which, while accessible, are limited to generic classes such as digits or clothing items. For researchers working on domain-specific tasks, such as classifying trees, food items, or other real-world objects, these data sets are insufficient and irrelevant. Additionally, creating and publishing a custom dataset can be time consuming, legally constrained, or beyond the scope of individual projects. We present MNIST-Gen, an automated, modular, and adaptive framework for generating MNIST-style image datasets tailored to user-specified categories using hierarchical semantic categorization. The system combines CLIP-based semantic understanding with reinforcement learning and human feedback to achieve intelligent categorization with minimal manual intervention. Our hierarchical approach supports complex category structures with semantic characteristics, enabling fine-grained subcategorization and multiple processing modes: individual review for maximum control, smart batch processing for large datasets, and fast batch processing for rapid creation. Inspired by category theory, MNIST-Gen models each data transformation stage as a composable morphism, enhancing clarity, modularity, and extensibility. As proof of concept, we generate and benchmark two novel datasets-\\textit{Tree-MNIST} and \\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing task-specific evaluation data while achieving 85\\% automatic categorization accuracy and 80\\% time savings compared to manual approaches.",
      "authors": [
        "Pouya Shaeri",
        "Arash Karimi",
        "Ariane Middel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:50:09+00:00",
          "link": "https://arxiv.org/abs/2507.11821v1",
          "size": "1980kb",
          "version": "v1"
        }
      ],
      "title": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11821",
        "HTML": "https://arxiv.org/html/2507.11821v1",
        "PDF": "https://arxiv.org/pdf/2507.11821"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper introduces MNIST-Gen, a framework that uses reinforcement learning for generating domain-specific image datasets, directly addressing dataset generation and processing for specific tasks, which is relevant to data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11822",
      "abstract": "This paper is devoted to a numerical analysis of a fractional viscoelastic wave propagation model that generalizes the fractional Maxwell model and the fractional Zener model. First, we convert the model problem into a velocity type integro-differential equation and establish existence, uniqueness and regularity of its solution. Then we consider a conforming linear/bilinear/trilinear finite element semi-discrete scheme and a fast scheme of backward Euler full discretization with a sum-of-exponentials (SOE) approximation for the convolution integral, and derive error estimates for the semi-discrete and fully discrete schemes. Finally, we provide several numerical examples to verify the theoretical results.",
      "authors": [
        "Hao Yuan and Xiaoping Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:51:12+00:00",
          "link": "https://arxiv.org/abs/2507.11822v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of a fast fully discrete finite element method for fractional viscoelastic wave propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11822",
        "HTML": "https://arxiv.org/html/2507.11822v1",
        "PDF": "https://arxiv.org/pdf/2507.11822"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on finite element methods for solving fractional viscoelastic wave propagation problems, with no relation to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11827",
      "abstract": "Numerical abstract interpretation is a widely used framework for the static analysis of numerical programs. However, existing numerical abstract interpreters rely on hand-crafted, instruction-specific transformers tailored to each domain, with no general algorithm for handling common operations across domains. This limits extensibility, prevents precise compositional reasoning over instruction sequences, and forces all downstream tasks to use the same fixed transformer regardless of their precision, efficiency, or task-specific requirements. To address these limitations, we propose a universal transformer synthesis algorithm that constructs a parametric family of sound abstract transformers for any given polyhedral numerical domain and a concrete operator from the class of Quadratic-Bounded Guarded Operators (QGO), which includes both individual instructions and structured sequences. Each instantiation in this family is sound by construction, enabling downstream analyses to adapt the transformer to their particular needs. The space of transformers is differentiable but complex. To efficiently explore this space of transformers, we introduce the Adaptive Gradient Guidance (AGG) procedure, a gradient-guided search strategy that steers the search process based on downstream analysis objectives and runtime constraints. We implement these ideas in the USTAD framework and evaluate their effectiveness across three numerical abstract domains: Zones, Octagons, and Polyhedra. Our results demonstrate that the universal synthesis algorithm successfully constructs sound families of transformers across domains, and that USTAD achieves significant, tunable precision gains over baselines by leveraging compositional reasoning and efficient gradient-guided traversal of the transformer space.",
      "authors": [
        "Shaurya Gomber",
        "Debangshu Banerjee",
        "Gagandeep Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:05:23+00:00",
          "link": "https://arxiv.org/abs/2507.11827v1",
          "size": "3277kb",
          "version": "v1"
        }
      ],
      "title": "Universal Synthesis of Differentiably Tunable Numerical Abstract Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11827",
        "HTML": "https://arxiv.org/html/2507.11827v1",
        "PDF": "https://arxiv.org/pdf/2507.11827"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper introduces a synthesis algorithm for abstract transformers, it does not directly address data collection or preprocessing in RL; however, it does propose methods that could potentially influence data transformation processes, indirectly relating to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11830",
      "abstract": "Inference is now the dominant AI workload, yet existing systems force trade-offs between latency, throughput, and cost. Arctic Inference, an open-source vLLM plugin from Snowflake AI Research, introduces Shift Parallelism, a dynamic parallelism strategy that adapts to real-world traffic while integrating speculative decoding, SwiftKV compute reduction, and optimized embedding inference. It achieves up to 3.4 times faster request completion, 1.75 times faster generation, and 1.6M tokens/sec per GPU for embeddings, outperforming both latency- and throughput-optimized deployments. Already powering Snowflake Cortex AI, Arctic Inference delivers state-of-the-art, cost-effective inference for enterprise AI and is now available to the community.",
      "authors": [
        "Samyam Rajbhandari",
        "Mert Hidayetoglu",
        "Aurick Qiao",
        "Ye Wang",
        "Juncheng Yang",
        "Jeff Rasley",
        "Michael Wyatt",
        "Yuxiong He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:32:31+00:00",
          "link": "https://arxiv.org/abs/2507.11830v1",
          "size": "5899kb",
          "version": "v1"
        }
      ],
      "title": "Arctic Inference with Shift Parallelism: Fast and Efficient Open Source Inference System for Enterprise AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11830",
        "HTML": "https://arxiv.org/html/2507.11830v1",
        "PDF": "https://arxiv.org/pdf/2507.11830"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving inference efficiency in AI systems using techniques like Shift Parallelism and speculative decoding. It does not discuss reinforcement learning or data processing related to RL environments."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11831",
      "abstract": "Emotional cues frequently arise and shape group dynamics in interactive settings where multiple humans and artificial agents communicate through shared digital channels. While artificial agents lack intrinsic emotional states, they can simulate affective behavior using synthetic modalities such as text or speech. This work introduces a model for orchestrating emotion contagion, enabling agents to detect emotional signals, infer group mood patterns, and generate targeted emotional responses. The system captures human emotional exchanges and uses this insight to produce adaptive, generative responses that influence group affect in real time. The model supports applications in collaborative, educational, and social environments by shifting affective computing from individual-level reactions to coordinated, group-level emotion modulation. We present the system architecture and provide experimental results that illustrate its effectiveness in sensing and steering group mood dynamics.",
      "authors": [
        "Fernando Koch and Jessica Nahulan and Jeremy Fox and Martin Keen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:35:06+00:00",
          "link": "https://arxiv.org/abs/2507.11831v1",
          "size": "7465kb",
          "version": "v1"
        }
      ],
      "title": "Generative Intelligence Systems in the Flow of Group Emotions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11831",
        "HTML": "https://arxiv.org/html/2507.11831v1",
        "PDF": "https://arxiv.org/pdf/2507.11831"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The work centers on a generative intelligence system for managing group emotions through artificial agents, focusing on emotion contagion and interaction dynamics, with no mention of reinforcement learning or associated data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11832",
      "abstract": "The language identification task is a crucial fundamental step in NLP. Often it serves as a pre-processing step for widely used NLP applications such as multilingual machine translation, information retrieval, question and answering, and text summarization. The core challenge of language identification lies in distinguishing languages in noisy, short, and code-mixed environments. This becomes even harder in case of diverse Indian languages that exhibit lexical and phonetic similarities, but have distinct differences. Many Indian languages share the same script making the task even more challenging. In this paper, we release a dataset of 230K sentences consisting of English and all 22 official Indian languages labeled with their language identifiers where data in most languages are newly created. We also develop and release robust baseline models using state-of-the-art approaches in machine learning and deep learning that can aid the research in this field. Our baseline models are comparable to the state-of-the-art models for the language identification task.",
      "authors": [
        "Yash Ingle and Pruthwik Mishra"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:39:32+00:00",
          "link": "https://arxiv.org/abs/2507.11832v1",
          "size": "261kb",
          "version": "v1"
        }
      ],
      "title": "ILID: Native Script Language Identification for Indian Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11832",
        "HTML": "https://arxiv.org/html/2507.11832v1",
        "PDF": "https://arxiv.org/pdf/2507.11832"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is about language identification in NLP and the release of a relevant dataset, which does not pertain to reinforcement learning or any related data processing techniques for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11834",
      "abstract": "Establishing reliable correspondences between image pairs is a fundamental task in computer vision, underpinning applications such as 3D reconstruction and visual localization. Although recent methods have made progress in pruning outliers from dense correspondence sets, they often hypothesize consistent visual domains and overlook the challenges posed by diverse scene structures. In this paper, we propose CorrMoE, a novel correspondence pruning framework that enhances robustness under cross-domain and cross-scene variations. To address domain shift, we introduce a De-stylization Dual Branch, performing style mixing on both implicit and explicit graph features to mitigate the adverse influence of domain-specific representations. For scene diversity, we design a Bi-Fusion Mixture of Experts module that adaptively integrates multi-perspective features through linear-complexity attention and dynamic expert routing. Extensive experiments on benchmark datasets demonstrate that CorrMoE achieves superior accuracy and generalization compared to state-of-the-art methods. The code and pre-trained models are available at https://github.com/peiwenxia/CorrMoE.",
      "authors": [
        "Peiwen Xia",
        "Tangfei Liao",
        "Wei Zhu",
        "Danhuai Zhao",
        "Jianjun Ke",
        "Kaihao Zhang",
        "Tong Lu",
        "Tao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:44:01+00:00",
          "link": "https://arxiv.org/abs/2507.11834v1",
          "size": "7158kb",
          "version": "v1"
        }
      ],
      "title": "CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11834",
        "HTML": "https://arxiv.org/html/2507.11834v1",
        "PDF": "https://arxiv.org/pdf/2507.11834"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study presents a framework for correspondence pruning in computer vision for cross-scene and cross-domain variations, which doesn't overlap with reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11836",
      "abstract": "Dynamic link prediction in continuous-time dynamic graphs is a fundamental task for modeling evolving complex systems. Existing node-centric and event-centric methods focus on individual interactions or atomic states, failing to capture the structural cohesion of composite hyper-events, groups of causally related events. To address this, we propose HyperEvent, a framework reframing dynamic link prediction as hyper-event recognition. Central to HyperEvent is the dynamic construction of an association sequence using event correlation vectors. These vectors quantify pairwise dependencies between the query event and relevant historical events, thereby characterizing the structural cohesion of a potential hyper-event. The framework predicts the occurrence of the query event by evaluating whether it collectively forms a valid hyper-event with these historical events. Notably, HyperEvent outperforms state-of-the-art methods on 4 out of 5 datasets in the official leaderboard. For scalability, we further introduce an efficient parallel training algorithm that segments large event streams to enable concurrent training. Experiments validate HyperEvent's superior accuracy and efficiency on large-scale graphs. Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank over state-of-the-art baseline on the large-scale Flight dataset while utilizing only 10.17% of the training time.",
      "authors": [
        "Jian Gao",
        "Jianshe Wu",
        "JingYi Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:57:40+00:00",
          "link": "https://arxiv.org/abs/2507.11836v1",
          "size": "562kb",
          "version": "v1"
        }
      ],
      "title": "HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11836",
        "HTML": "https://arxiv.org/html/2507.11836v1",
        "PDF": "https://arxiv.org/pdf/2507.11836"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for dynamic link prediction in continuous-time dynamic graphs, focusing on hyper-event recognition. It does not relate to reinforcement learning or data processing within RL settings."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11839",
      "abstract": "Lightweight inference is critical for biomolecular structure prediction and other downstream tasks, enabling efficient real-world deployment and inference-time scaling for large-scale applications. In this work, we address the challenge of balancing model efficiency and prediction accuracy by making several key modifications, 1) Multi-step AF3 sampler is replaced by a few-step ODE sampler, significantly reducing computational overhead for the diffusion module part during inference; 2) In the open-source Protenix framework, a subset of pairformer or diffusion transformer blocks doesn't make contributions to the final structure prediction, presenting opportunities for architectural pruning and lightweight redesign; 3) A model incorporating an ESM module is trained to substitute the conventional MSA module, reducing MSA preprocessing time. Building on these key insights, we present Protenix-Mini, a compact and optimized model designed for efficient protein structure prediction. This streamlined version incorporates a more efficient architectural design with a two-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating redundant Transformer components and refining the sampling process, Protenix-Mini significantly reduces model complexity with slight accuracy drop. Evaluations on benchmark datasets demonstrate that it achieves high-fidelity predictions, with only a negligible 1 to 5 percent decrease in performance on benchmark datasets compared to its full-scale counterpart. This makes Protenix-Mini an ideal choice for applications where computational resources are limited but accurate structure prediction remains crucial.",
      "authors": [
        "Chengyue Gong",
        "Xinshi Chen",
        "Yuxuan Zhang",
        "Yuxuan Song",
        "Hao Zhou",
        "Wenzhi Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:08:25+00:00",
          "link": "https://arxiv.org/abs/2507.11839v1",
          "size": "1318kb",
          "version": "v1"
        }
      ],
      "title": "Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11839",
        "HTML": "https://arxiv.org/html/2507.11839v1",
        "PDF": "https://arxiv.org/pdf/2507.11839"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on biomolecular structure prediction and does not address reinforcement learning or related data processing aspects within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11840",
      "abstract": "Achieving human-like dexterous robotic manipulation remains a central goal and a pivotal challenge in robotics. The development of Artificial Intelligence (AI) has allowed rapid progress in robotic manipulation. This survey summarizes the evolution of robotic manipulation from mechanical programming to embodied intelligence, alongside the transition from simple grippers to multi-fingered dexterous hands, outlining key characteristics and main challenges. Focusing on the current stage of embodied dexterous manipulation, we highlight recent advances in two critical areas: dexterous manipulation data collection (via simulation, human demonstrations, and teleoperation) and skill-learning frameworks (imitation and reinforcement learning). Then, based on the overview of the existing data collection paradigm and learning framework, three key challenges restricting the development of dexterous robotic manipulation are summarized and discussed.",
      "authors": [
        "Gaofeng Li",
        "Ruize Wang",
        "Peisen Xu",
        "Qi Ye",
        "Jiming Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:09:31+00:00",
          "link": "https://arxiv.org/abs/2507.11840v1",
          "size": "6275kb",
          "version": "v1"
        }
      ],
      "title": "The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11840",
        "HTML": "https://arxiv.org/html/2507.11840v1",
        "PDF": "https://arxiv.org/pdf/2507.11840"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "Although primarily a survey, the paper discusses dexterous manipulation data collection methods, including simulation and human demonstrations, within the context of both imitation and reinforcement learning. However, data processing is not the main technical contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11841",
      "abstract": "Affective visualization design is an emerging research direction focused on communicating and influencing emotion through visualization. However, as revealed by previous research, this area is highly interdisciplinary and involves theories and practices from diverse fields and disciplines, thus awaiting analysis from more fine-grained angles. To address this need, this work focuses on a pioneering and relatively mature sub-area, affective geovisualization design, to further the research in this direction and provide more domain-specific insights. Through an analysis of a curated corpus of affective geovisualization designs using the Person-Process-Place (PPP) model from geographic theory, we derived a design taxonomy that characterizes a variety of methods for eliciting and enhancing emotions through geographic visualization. We also identified four underlying high-level design paradigms of affective geovisualization design (e.g., computational, anthropomorphic) that guide distinct approaches to linking geographic information with human experience. By extending existing affective visualization design frameworks with geographic specificity, we provide additional design examples, domain-specific analyses, and insights to guide future research and practices in this underexplored yet highly innovative domain.",
      "authors": [
        "Xingyu Lan",
        "Yutong Yang",
        "Yifan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:15:04+00:00",
          "link": "https://arxiv.org/abs/2507.11841v1",
          "size": "7595kb",
          "version": "v1"
        }
      ],
      "title": "\"Mapping What I Feel\": Understanding Affective Geovisualization Design Through the Lens of People-Place Relationships",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11841",
        "HTML": "https://arxiv.org/html/2507.11841v1",
        "PDF": "https://arxiv.org/pdf/2507.11841"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with affective geovisualization design and does not pertain to reinforcement learning or data processing in that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11845",
      "abstract": "Open-set few-shot image classification aims to train models using a small amount of labeled data, enabling them to achieve good generalization when confronted with unknown environments. Existing methods mainly use visual information from a single image to learn class representations to distinguish known from unknown categories. However, these methods often overlook the benefits of integrating rich contextual information. To address this issue, this paper proposes a prototypical augmentation and alignment method, termed ProtoConNet, which incorporates background information from different samples to enhance the diversity of the feature space, breaking the spurious associations between context and image subjects in few-shot scenarios. Specifically, it consists of three main modules: the clustering-based data selection (CDS) module mines diverse data patterns while preserving core features; the contextual-enhanced semantic refinement (CSR) module builds a context dictionary to integrate into image representations, which boosts the model's robustness in various scenarios; and the prototypical alignment (PA) module reduces the gap between image representations and class prototypes, amplifying feature distances for known and unknown classes. Experimental results from two datasets verified that ProtoConNet enhances the effectiveness of representation learning in few-shot scenarios and identifies open-set samples, making it superior to existing methods.",
      "authors": [
        "Kexuan Shi",
        "Zhuang Qi",
        "Jingjing Zhu",
        "Lei Meng",
        "Yaochen Zhang",
        "Haibei Huang",
        "Xiangxu Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:20:52+00:00",
          "link": "https://arxiv.org/abs/2507.11845v1",
          "size": "1111kb",
          "version": "v1"
        }
      ],
      "title": "ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11845",
        "HTML": "https://arxiv.org/html/2507.11845v1",
        "PDF": "https://arxiv.org/pdf/2507.11845"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is about open-set few-shot image classification and does not engage with reinforcement learning or the specific data processing methods related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11847",
      "abstract": "We study the generalized linear bandit (GLB) problem, a contextual multi-armed bandit framework that extends the classical linear model by incorporating a non-linear link function, thereby modeling a broad class of reward distributions such as Bernoulli and Poisson. While GLBs are widely applicable to real-world scenarios, their non-linear nature introduces significant challenges in achieving both computational and statistical efficiency. Existing methods typically trade off between two objectives, either incurring high per-round costs for optimal regret guarantees or compromising statistical efficiency to enable constant-time updates. In this paper, we propose a jointly efficient algorithm that attains a nearly optimal regret bound with $\\mathcal{O}(1)$ time and space complexities per round. The core of our method is a tight confidence set for the online mirror descent (OMD) estimator, which is derived through a novel analysis that leverages the notion of mix loss from online prediction. The analysis shows that our OMD estimator, even with its one-pass updates, achieves statistical efficiency comparable to maximum likelihood estimation, thereby leading to a jointly efficient optimistic method.",
      "authors": [
        "Yu-Jie Zhang",
        "Sheng-An Xu",
        "Peng Zhao",
        "Masashi Sugiyama"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:24:21+00:00",
          "link": "https://arxiv.org/abs/2507.11847v1",
          "size": "2271kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11847",
        "HTML": "https://arxiv.org/html/2507.11847v1",
        "PDF": "https://arxiv.org/pdf/2507.11847"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generalized linear bandits, which are a type of contextual multi-armed bandit framework, not directly related to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11848",
      "abstract": "Hybrid rice breeding crossbreeds different rice lines and cultivates the resulting hybrids in fields to select those with desirable agronomic traits, such as higher yields. Recently, genomic selection has emerged as an efficient way for hybrid rice breeding. It predicts the traits of hybrids based on their genes, which helps exclude many undesired hybrids, largely reducing the workload of field cultivation. However, due to the limited accuracy of genomic prediction models, breeders still need to combine their experience with the models to identify regulatory genes that control traits and select hybrids, which remains a time-consuming process. To ease this process, in this paper, we proposed a visual analysis method to facilitate interactive hybrid rice breeding. Regulatory gene identification and hybrid selection naturally ensemble a dual-analysis task. Therefore, we developed a parametric dual projection method with theoretical guarantees to facilitate interactive dual analysis. Based on this dual projection method, we further developed a gene visualization and a hybrid visualization to verify the identified regulatory genes and hybrids. The effectiveness of our method is demonstrated through the quantitative evaluation of the parametric dual projection method, identified regulatory genes and desired hybrids in the case study, and positive feedback from breeders.",
      "authors": [
        "Changjian Chen",
        "Pengcheng Wang",
        "Fei Lyu",
        "Zhuo Tang",
        "Li Yang",
        "Long Wang",
        "Yong Cai",
        "Feng Yu",
        "and Kenli Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:25:31+00:00",
          "link": "https://arxiv.org/abs/2507.11848v1",
          "size": "6129kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Hybrid Rice Breeding with Parametric Dual Projection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11848",
        "HTML": "https://arxiv.org/html/2507.11848v1",
        "PDF": "https://arxiv.org/pdf/2507.11848"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses genomic selection and visual analysis in hybrid rice breeding, which is not related to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11849",
      "abstract": "This paper presents an analysis of GaN high-electron-mobility transistors (HEMTs) using both TCAD simulation and experimental characterization. The energy band structure was studied using Nextnano simulation software to observe two-dimensional electron gas (2DEG) formation and carrier confinement under equilibrium conditions. Additionally, I-V and C-V data from fabricated research-grade GaN HEMTs were analyzed to extract key electrical parameters. The device demonstrated an ON current of 1.9 mA and an OFF current of 0.01 mA, indicating a strong ON/OFF current ratio. A subthreshold swing of 80 mV/decade and a DIBL of 5 mV/V were observed, confirming good gate control and short-channel suppression. The ON-resistance was 22.72 ohm per micron, with a saturation voltage of 1 V . The peak transconductance was extracted as 0.18 mS in the linear region and 0.5 mS in saturation. Field-effect mobility was calculated using the transconductance method, with a maximum value of approximately 1200 cm2/V.s at low drain bias. The combined simulation and experimental approach provided comprehensive insight into GaN HEMT behavior, enabling a deeper understanding of structure-performance relationships critical to advanced transistor design.",
      "authors": [
        "Tanjim Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:27:20+00:00",
          "link": "https://arxiv.org/abs/2507.11849v1",
          "size": "1402kb",
          "version": "v1"
        }
      ],
      "title": "Mobility Extraction and Analysis of GaN HEMTs for RF Applications Using TCAD and Experimental Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11849",
        "PDF": "https://arxiv.org/pdf/2507.11849"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper centers on the analysis and characterization of GaN HEMTs using simulation and experimental data for RF applications, having no connection to reinforcement learning or data processing in that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11851",
      "abstract": "Autoregressive language models are constrained by their inherently sequential nature, generating one token at a time. This paradigm limits inference speed and parallelism, especially during later stages of generation when the direction and semantics of text are relatively certain. In this work, we propose a novel framework that leverages the inherent knowledge of vanilla autoregressive language models about future tokens, combining techniques to realize this potential and enable simultaneous prediction of multiple subsequent tokens. Our approach introduces several key innovations: (1) a masked-input formulation where multiple future tokens are jointly predicted from a common prefix; (2) a gated LoRA formulation that preserves the original LLM's functionality, while equipping it for multi-token prediction; (3) a lightweight, learnable sampler module that generates coherent sequences from the predicted future tokens; (4) a set of auxiliary training losses, including a consistency loss, to enhance the coherence and accuracy of jointly generated tokens; and (5) a speculative generation strategy that expands tokens quadratically in the future while maintaining high fidelity. Our method achieves significant speedups through supervised fine-tuning on pretrained models. For example, it generates code and math nearly 5x faster, and improves general chat and knowledge tasks by almost 2.5x. These gains come without any loss in quality.",
      "authors": [
        "Mohammad Samragh",
        "Arnav Kundu",
        "David Harrison",
        "Kumari Nishu",
        "Devang Naik",
        "Minsik Cho",
        "Mehrdad Farajtabar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:31:40+00:00",
          "link": "https://arxiv.org/abs/2507.11851v1",
          "size": "2407kb",
          "version": "v1"
        }
      ],
      "title": "Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11851",
        "HTML": "https://arxiv.org/html/2507.11851v1",
        "PDF": "https://arxiv.org/pdf/2507.11851"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces methods for improving multi-token prediction in autoregressive language models, focusing on language inference acceleration, unrelated to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11852",
      "abstract": "The rapid adoption of micromobility solutions, particularly two-wheeled vehicles like e-scooters and e-bikes, has created an urgent need for reliable autonomous riding (AR) technologies. While autonomous driving (AD) systems have matured significantly, AR presents unique challenges due to the inherent instability of two-wheeled platforms, limited size, limited power, and unpredictable environments, which pose very serious concerns about road users' safety. This review provides a comprehensive analysis of AR systems by systematically examining their core components, perception, planning, and control, through the lens of AD technologies. We identify critical gaps in current AR research, including a lack of comprehensive perception systems for various AR tasks, limited industry and government support for such developments, and insufficient attention from the research community. The review analyses the gaps of AR from the perspective of AD to highlight promising research directions, such as multimodal sensor techniques for lightweight platforms and edge deep learning architectures. By synthesising insights from AD research with the specific requirements of AR, this review aims to accelerate the development of safe, efficient, and scalable autonomous riding systems for future urban mobility.",
      "authors": [
        "Mohammed Hassanin",
        "Mohammad Abu Alsheikh",
        "Carlos C. N. Kuhn",
        "Damith Herath",
        "Dinh Thai Hoang",
        "and Ibrahim Radwan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:33:54+00:00",
          "link": "https://arxiv.org/abs/2507.11852v1",
          "size": "15086kb",
          "version": "v1"
        }
      ],
      "title": "Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11852",
        "HTML": "https://arxiv.org/html/2507.11852v1",
        "PDF": "https://arxiv.org/pdf/2507.11852"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper reviews perception, planning, and control in autonomous riding systems, aligning with autonomous driving but not addressing reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11854",
      "abstract": "Near-field spherical waves inherently encode both direction and distance information, enabling spotlight-like beam focusing for targeted interference mitigation. However, whether such beam focusing can fully eliminate interference under perfect and imperfect channel state information (CSI), rendering advanced interference management schemes unnecessary, remains an open question. To address this, we investigate rate-splitting multiple access (RSMA)-enabled near-field communications (NFC) under imperfect SCI. Our transmit scheme employs a sub-connected hybrid analog-digital (HAD) architecture to reduce hardware overhead while incorporating imperfect successive interference cancellation (SIC) for practical implementation. A minimum rate maximization problem is formulated by jointly optimizing the analog beamfocuser, the digital beamfocuser, and the common rate allocation. To solve the non-convex problem, we develop a penalty-based block coordinate descent (BCD) algorithm, deriving closed-form expressions for the optimal analog and digital beamfocusers solutions. Furthermore, to reduce computational complexity, we propose a low-complexity algorithm, where analog and digital beamfocusers are designed in two separate stages. Simulation results underscore that: 1) beamfocusing alone is insufficient to fully suppress interference even under perfect CSI; 2) RSMA exhibits superior interference management over SDMA under imperfect CSI and SIC conditions; 3) sub-connected HAD architecture delivers near-optimal digital beamfocusing performance with fewer radio frequency chains.",
      "authors": [
        "Jiasi Zhou",
        "Ruirui Chen",
        "Yanjing Sun",
        "and Chintha Tellambura"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:37:58+00:00",
          "link": "https://arxiv.org/abs/2507.11854v1",
          "size": "287kb",
          "version": "v1"
        }
      ],
      "title": "Sub-Connected Hybrid Beamfocusing Design for RSMA-Enabled Near-Field Communications with Imperfect CSI and SIC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11854",
        "HTML": "https://arxiv.org/html/2507.11854v1",
        "PDF": "https://arxiv.org/pdf/2507.11854"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses beamfocusing design in near-field communications and does not relate to reinforcement learning or any aspect of data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11855",
      "abstract": "Sequential deep learning models excel in domains with temporal or sequential dependencies, but their complexity necessitates post-hoc feature attribution methods for understanding their predictions. While existing techniques quantify feature importance, they inherently assume fixed feature ordering - conflating the effects of (1) feature values and (2) their positions within input sequences. To address this gap, we introduce OrdShap, a novel attribution method that disentangles these effects by quantifying how a model's predictions change in response to permuting feature position. We establish a game-theoretic connection between OrdShap and Sanchez-Berganti\\~nos values, providing a theoretically grounded approach to position-sensitive attribution. Empirical results from health, natural language, and synthetic datasets highlight OrdShap's effectiveness in capturing feature value and feature position attributions, and provide deeper insight into model behavior.",
      "authors": [
        "Davin Hill",
        "Brian L. Hill",
        "Aria Masoomi",
        "Vijay S. Nori",
        "Robert E. Tillman",
        "Jennifer Dy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:40:01+00:00",
          "link": "https://arxiv.org/abs/2507.11855v1",
          "size": "2171kb",
          "version": "v1"
        }
      ],
      "title": "OrdShap: Feature Position Importance for Sequential Black-Box Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11855",
        "HTML": "https://arxiv.org/html/2507.11855v1",
        "PDF": "https://arxiv.org/pdf/2507.11855"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses feature position importance in sequential models, which is not specific to reinforcement learning or its data processing challenges."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11857",
      "abstract": "This paper is a study of techniques for measuring and predicting visual fidelity. As visual stimuli we use polygonal models, and vary their fidelity with two different model simplification algorithms. We also group the stimuli into two object types: animals and man made artifacts. We examine three different experimental techniques for measuring these fidelity changes: naming times, ratings, and preferences. All the measures were sensitive to the type of simplification and level of simplification. However, the measures differed from one another in their response to object type. We also examine several automatic techniques for predicting these experimental measures, including techniques based on images and on the models themselves. Automatic measures of fidelity were successful at predicting experimental ratings, less successful at predicting preferences, and largely failures at predicting naming times. We conclude with suggestions for use and improvement of the experimental and automatic measures of visual fidelity.",
      "authors": [
        "Benjamin Watson",
        "Alinda Friedman",
        "Aaron McGaffey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:52:20+00:00",
          "link": "https://arxiv.org/abs/2507.11857v1",
          "size": "248kb",
          "version": "v1"
        }
      ],
      "title": "Measuring and predicting visual fidelity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11857",
        "PDF": "https://arxiv.org/pdf/2507.11857"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study deals with measuring and predicting visual fidelity, without any mention of reinforcement learning or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11862",
      "abstract": "Accurate recognition of personally identifiable information (PII) is central to automated text anonymization. This paper investigates the effectiveness of cross-domain model transfer, multi-domain data fusion, and sample-efficient learning for PII recognition. Using annotated corpora from healthcare (I2B2), legal (TAB), and biography (Wikipedia), we evaluate models across four dimensions: in-domain performance, cross-domain transferability, fusion, and few-shot learning. Results show legal-domain data transfers well to biographical texts, while medical domains resist incoming transfer. Fusion benefits are domain-specific, and high-quality recognition is achievable with only 10% of training data in low-specialization domains.",
      "authors": [
        "Junhong Ye",
        "Xu Yuan",
        "Xinying Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:14:36+00:00",
          "link": "https://arxiv.org/abs/2507.11862v1",
          "size": "85kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11862",
        "HTML": "https://arxiv.org/html/2507.11862v1",
        "PDF": "https://arxiv.org/pdf/2507.11862"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on PII recognition and investigates cross-domain transfer and few-shot learning, which are not related to reinforcement learning or its data processing needs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11865",
      "abstract": "The rapid expansion of platform integration has emerged as an effective solution to mitigate market fragmentation by consolidating multiple ride-hailing platforms into a single application. To address heterogeneous passenger preferences, third-party integrators provide Discount Express service delivered by express drivers at lower trip fares. For the individual platform, encouraging broader participation of drivers in Discount Express services has the potential to expand the accessible demand pool and improve matching efficiency, but often at the cost of reduced profit margins. This study aims to dynamically manage drivers' acceptance of Discount Express from the perspective of individual platforms. The lack of historical data under the new business model necessitates online learning. However, early-stage exploration through trial and error can be costly in practice, highlighting the need for reliable early-stage performance in real-world deployment. To address these challenges, this study formulates the decision regarding the proportion of drivers' acceptance behavior as a continuous control task. In response to the high stochasticity, the opaque matching mechanisms employed by third-party integrator, and the limited availability of historical data, we propose a policy-improved deep deterministic policy gradient (pi-DDPG) framework. The proposed framework incorporates a refiner module to boost policy performance during the early training phase, leverages a convolutional long short-term memory network to effectively capture complex spatiotemporal patterns, and adopts a prioritized experience replay mechanism to enhance learning efficiency. A simulator based on a real-world dataset is developed to validate the effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate that pi-DDPG achieves superior learning efficiency and significantly reduces early-stage training losses.",
      "authors": [
        "Hanwen Dai",
        "Chang Gao",
        "Fang He",
        "Congyuan Ji",
        "Yanni Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.11865v1",
          "size": "4481kb",
          "version": "v1"
        }
      ],
      "title": "A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11865",
        "HTML": "https://arxiv.org/html/2507.11865v1",
        "PDF": "https://arxiv.org/pdf/2507.11865"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses the use of a simulator based on a real-world dataset to validate the proposed pi-DDPG framework. Although it involves data for simulations, the primary focus is on the framework itself rather than novel techniques or contributions in data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11866",
      "abstract": "In sequential recommendation systems, data augmentation and contrastive learning techniques have recently been introduced using diffusion models to achieve robust representation learning. However, most of the existing approaches use random augmentation, which risk damaging the contextual information of the original sequence. Accordingly, we propose a Similarity-Guided Diffusion for Contrastive Sequential Recommendation. Our method leverages the similarity between item embedding vectors to generate semantically consistent noise. Moreover, we utilize high confidence score in the denoising process to select our augmentation positions. This approach more effectively reflects contextual and structural information compared to augmentation at random positions. From a contrastive learning perspective, the proposed augmentation technique provides more discriminative positive and negative samples, simultaneously improving training efficiency and recommendation performance. Experimental results on five benchmark datasets show that SimDiffRec outperforms the existing baseline models.",
      "authors": [
        "Jinkyeong Choi",
        "Yejin Noh",
        "Donghyeon Park"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:26:24+00:00",
          "link": "https://arxiv.org/abs/2507.11866v1",
          "size": "1228kb",
          "version": "v1"
        }
      ],
      "title": "Similarity-Guided Diffusion for Contrastive Sequential Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11866",
        "HTML": "https://arxiv.org/html/2507.11866v1",
        "PDF": "https://arxiv.org/pdf/2507.11866"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sequential recommendation systems and does not involve reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11867",
      "abstract": "Grammatical Error Correction (GEC) and grammatical acceptability judgment (COLA) are core tasks in natural language processing, sharing foundational grammatical knowledge yet typically evolving independently. This paper introduces COLA-GEC, a novel bidirectional framework that enhances both tasks through mutual knowledge transfer. First, we augment grammatical acceptability models using GEC datasets, significantly improving their performance across multiple languages. Second, we integrate grammatical acceptability signals into GEC model training via a dynamic loss function, effectively guiding corrections toward grammatically acceptable outputs. Our approach achieves state-of-the-art results on several multilingual benchmarks. Comprehensive error analysis highlights remaining challenges, particularly in punctuation error correction, providing insights for future improvements in grammatical modeling.",
      "authors": [
        "Xiangyu Yang",
        "Xinying Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:29:05+00:00",
          "link": "https://arxiv.org/abs/2507.11867v1",
          "size": "731kb",
          "version": "v1"
        }
      ],
      "title": "COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11867",
        "HTML": "https://arxiv.org/html/2507.11867v1",
        "PDF": "https://arxiv.org/pdf/2507.11867"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with grammatical error correction and acceptability in natural language processing. It does not relate to reinforcement learning or data processing in the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11870",
      "abstract": "We introduce a novel Multimodal Neural Operator (MNO) architecture designed to learn solution operators for multi-parameter nonlinear boundary value problems (BVPs). Traditional neural operators primarily map either the PDE coefficients or source terms independently to the solution, limiting their flexibility and applicability. In contrast, our proposed MNO architecture generalizes these approaches by mapping multiple parameters including PDE coefficients, source terms, and boundary conditions to the solution space in a unified manner. Our MNO is motivated by the hierarchical nested bases of the Fast Multipole Method (FMM) and is constructed systematically through three key components: a parameter efficient Generalized FMM (GFMM) block, a Unimodal Neural Operator (UNO) built upon GFMM blocks for single parameter mappings, and most importantly, a multimodal fusion mechanism extending these components to learn the joint map. We demonstrate the multimodal generalization capacity of our approach on both linear and nonlinear BVPs. Our experiments show that the network effectively handles simultaneous variations in PDE coefficients and source or boundary terms.",
      "authors": [
        "Vamshi C. Madala",
        "Nithin Govindarajan and Shivkumar Chandrasekaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:32:46+00:00",
          "link": "https://arxiv.org/abs/2507.11870v1",
          "size": "7745kb",
          "version": "v1"
        }
      ],
      "title": "MNO : A Multi-modal Neural Operator for Parametric Nonlinear BVPs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11870",
        "HTML": "https://arxiv.org/html/2507.11870v1",
        "PDF": "https://arxiv.org/pdf/2507.11870"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a Multi-modal Neural Operator architecture for boundary value problems, which is unrelated to reinforcement learning and does not address data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11872",
      "abstract": "Popular Bayes filters typically rely on linearization techniques such as Taylor series expansion and stochastic linear regression to use the structure of standard Kalman filter. These techniques may introduce large estimation errors in nonlinear and non-Gaussian systems. This paper overviews a recent breakthrough in filtering algorithm design called \\textit{N}atural Gr\\textit{a}dient Gaussia\\textit{n} Appr\\textit{o}ximation (NANO) filter and compare its performance over a large class of nonlinear filters. The NANO filter interprets Bayesian filtering as solutions to two distinct optimization problems, which allows to define optimal Gaussian approximation and derive its corresponding extremum conditions. The algorithm design still follows the two-step structure of Bayes filters. In the prediction step, NANO filter calculates the first two moments of the prior distribution, and this process is equivalent to a moment-matching filter. In the update step, natural gradient descent is employed to directly minimize the objective of the update step, thereby avoiding errors caused by model linearization. Comparative tests are conducted on four classic systems, including the damped linear oscillator, sequence forecasting, modified growth model, and robot localization, under Gaussian, Laplace, and Beta noise to evaluate the NANO filter's capability in handling nonlinearity. Additionally, we validate the NANO filter's robustness to data outliers using a satellite attitude estimation example. It is observed that the NANO filter outperforms popular Kalman filters family such as extended Kalman filter (EKF), unscented Kalman filter (UKF), iterated extended Kalman filter (IEKF) and posterior linearization filter (PLF), while having similar computational burden.",
      "authors": [
        "Wenhan Cao and Tianyi Zhang and Shengbo Eben Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:34:56+00:00",
          "link": "https://arxiv.org/abs/2507.11872v1",
          "size": "7494kb",
          "version": "v1"
        }
      ],
      "title": "Algorithm Design and Comparative Test of Natural Gradient Gaussian Approximation Filter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11872",
        "HTML": "https://arxiv.org/html/2507.11872v1",
        "PDF": "https://arxiv.org/pdf/2507.11872"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the design of a natural gradient Gaussian approximation filter for Bayesian filtering, without involvement in reinforcement learning or associated data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11873",
      "abstract": "We introduce a new technique for repairing syntax errors in arbitrary context-free languages. This technique models syntax repair as a language intersection problem by defining a finite language that provably generates every syntactically valid repair within a given edit distance. Leveraging a theoretical connection between the Bar-Hillel construction from formal language theory and CFL reachability from program analysis, we show that repairability in a finite number of typographic edits is polylogarithmic parallel time decidable and provide an enumeration algorithm based on the Brzozowski derivative. Finally, we evaluate this algorithm and its implementation, demonstrating state-of-the-art results on a Python syntax repair benchmark.",
      "authors": [
        "Breandan Considine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:35:32+00:00",
          "link": "https://arxiv.org/abs/2507.11873v1",
          "size": "1831kb",
          "version": "v1"
        }
      ],
      "title": "Syntax Repair as Language Intersection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11873",
        "PDF": "https://arxiv.org/pdf/2507.11873"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on syntax repair and language intersection techniques, with no mention of reinforcement learning or related data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11875",
      "abstract": "This paper introduces DualReward, a novel reinforcement learning framework for automatic distractor generation in cloze tests. Unlike conventional approaches that rely primarily on supervised learning or static generative models, our method employs a dual reward structure with adaptive scaling that differentiates between human-created gold standard distractors and model-generated candidates. The framework dynamically adjusts reward signal intensity based on model performance and confidence. We evaluate our approach on both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets, demonstrating consistent improvements over state-of-the-art baselines. Experimental results show that our adaptive reward scaling mechanism provides modest but consistent benefits on homogeneous datasets (CLOTH-F) and more substantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data (MCQ), suggesting its particular effectiveness for handling varied question types and domains. Our work offers a flexible framework that effectively balances learning from reliable human examples while exploring novel, high-quality distractors for automated test generation.",
      "authors": [
        "Tianyou Huang",
        "Xinglu Chen",
        "Jingshen Zhang",
        "Xinying Qiu",
        "Ruiying Niu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:39:36+00:00",
          "link": "https://arxiv.org/abs/2507.11875v1",
          "size": "1950kb",
          "version": "v1"
        }
      ],
      "title": "DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11875",
        "HTML": "https://arxiv.org/html/2507.11875v1",
        "PDF": "https://arxiv.org/pdf/2507.11875"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper presents DualReward, an RL framework with a novel dynamic reward structure for cloze test distractor generation, involving RL data processing techniques like reward signal adjustments to enhance data quality during training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11878",
      "abstract": "LLMs are trained to refuse harmful instructions, but do they truly understand harmfulness beyond just refusing? Prior work has shown that LLMs' refusal behaviors can be mediated by a one-dimensional subspace, i.e., a refusal direction. In this work, we identify a new dimension to analyze safety mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a separate concept from refusal. There exists a harmfulness direction that is distinct from the refusal direction. As causal evidence, steering along the harmfulness direction can lead LLMs to interpret harmless instructions as harmful, but steering along the refusal direction tends to elicit refusal responses directly without reversing the model's judgment on harmfulness. Furthermore, using our identified harmfulness concept, we find that certain jailbreak methods work by reducing the refusal signals without reversing the model's internal belief of harmfulness. We also find that adversarially finetuning models to accept harmful instructions has minimal impact on the model's internal belief of harmfulness. These insights lead to a practical safety application: The model's latent harmfulness representation can serve as an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing over-refusals that is robust to finetuning attacks. For instance, our Latent Guard achieves performance comparable to or better than Llama Guard 3 8B, a dedicated finetuned safeguard model, across different jailbreak methods. Our findings suggest that LLMs' internal understanding of harmfulness is more robust than their refusal decision to diverse input instructions, offering a new perspective to study AI safety",
      "authors": [
        "Jiachen Zhao",
        "Jing Huang",
        "Zhengxuan Wu",
        "David Bau",
        "Weiyan Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:48:03+00:00",
          "link": "https://arxiv.org/abs/2507.11878v1",
          "size": "1761kb",
          "version": "v1"
        }
      ],
      "title": "LLMs Encode Harmfulness and Refusal Separately",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11878",
        "HTML": "https://arxiv.org/html/2507.11878v1",
        "PDF": "https://arxiv.org/pdf/2507.11878"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores safety mechanisms and harmfulness in large language models, without addressing data processing in a reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11880",
      "abstract": "Tethered robots play a pivotal role in specialized environments such as disaster response and underground exploration, where their stable power supply and reliable communication offer unparalleled advantages. However, their motion planning is severely constrained by tether length limitations and entanglement risks, posing significant challenges to achieving optimal path planning. To address these challenges, this study introduces CDT-TCS (Convex Dissection Topology-based Tethered Configuration Search), a novel algorithm that leverages CDT Encoding as a homotopy invariant to represent topological states of paths. By integrating algebraic topology with geometric optimization, CDT-TCS efficiently computes the complete set of optimal feasible configurations for tethered robots at all positions in 2D environments through a single computation. Building on this foundation, we further propose three application-specific algorithms: i) CDT-TPP for optimal tethered path planning, ii) CDT-TMV for multi-goal visiting with tether constraints, iii) CDT-UTPP for distance-optimal path planning of untethered robots. All theoretical results and propositions underlying these algorithms are rigorously proven and thoroughly discussed in this paper. Extensive simulations demonstrate that the proposed algorithms significantly outperform state-of-the-art methods in their respective problem domains. Furthermore, real-world experiments on robotic platforms validate the practicality and engineering value of the proposed framework.",
      "authors": [
        "Jinyuan Liu",
        "Minglei Fu",
        "Ling Shi",
        "Chenguang Yang",
        "and Wenan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:48:53+00:00",
          "link": "https://arxiv.org/abs/2507.11880v1",
          "size": "8957kb",
          "version": "v1"
        }
      ],
      "title": "A Fast Method for Planning All Optimal Homotopic Configurations for Tethered Robots and Its Extended Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11880",
        "HTML": "https://arxiv.org/html/2507.11880v1",
        "PDF": "https://arxiv.org/pdf/2507.11880"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses tethered robot planning using topological path optimization without relating to reinforcement learning or specific data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11882",
      "abstract": "Instruction-following capability has become a major ability to be evaluated for Large Language Models (LLMs). However, existing datasets, such as IFEval, are either predominantly monolingual and centered on English or simply machine translated to other languages, limiting their applicability in multilingual contexts. In this paper, we present an carefully-curated extension of IFEval to a localized multilingual version named Marco-Bench-MIF, covering 30 languages with varying levels of localization. Our benchmark addresses linguistic constraints (e.g., modifying capitalization requirements for Chinese) and cultural references (e.g., substituting region-specific company names in prompts) via a hybrid pipeline combining translation with verification. Through comprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1) 25-35% accuracy gap between high/low-resource languages, (2) model scales largely impact performance by 45-60% yet persists script-specific challenges, and (3) machine-translated data underestimates accuracy by7-22% versus localized data. Our analysis identifies challenges in multilingual instruction following, including keyword consistency preservation and compositional constraint adherence across languages. Our Marco-Bench-MIF is available at https://github.com/AIDC-AI/Marco-Bench-MIF.",
      "authors": [
        "Bo Zeng",
        "Chenyang Lyu",
        "Sinuo Liu",
        "Mingyan Zeng",
        "Minghao Wu",
        "Xuanfan Ni",
        "Tianqi Shi",
        "Yu Zhao",
        "Yefeng Liu",
        "Chenyu Zhu",
        "Ruizhe Li",
        "Jiahui Geng",
        "Qing Li",
        "Yu Tong",
        "Longyue Wang",
        "Weihua Luo",
        "Kaifu Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:49:41+00:00",
          "link": "https://arxiv.org/abs/2507.11882v1",
          "size": "296kb",
          "version": "v1"
        }
      ],
      "title": "Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11882",
        "HTML": "https://arxiv.org/html/2507.11882v1",
        "PDF": "https://arxiv.org/pdf/2507.11882"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with multilingual instruction-following in LLMs and benchmarking across languages, without focusing on data processing techniques within reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11883",
      "abstract": "In this work, we examine a sequential setting of a cooperative game in which players arrive dynamically to form coalitions and complete tasks either together or individually, depending on the value created. Upon arrival, a new player as a decision maker faces two options: forming a new coalition or joining an existing one. We assume that players are greedy, i.e., they aim to maximize their rewards based on the information available at their arrival. The objective is to design an online value distribution policy that incentivizes players to form a coalition structure that maximizes social welfare. We focus on monotone and bounded cooperative games. Our main result establishes an upper bound of $\\frac{3\\mathsf{min}}{\\mathsf{max}}$ on the competitive ratio for any irrevocable policy (i.e., one without redistribution), and proposes a policy that achieves a near-optimal competitive ratio of $\\min\\left\\{\\frac{1}{2}, \\frac{3\\mathsf{min}}{\\mathsf{max}}\\right\\}$, where $\\mathsf{min}$ and $\\mathsf{max}$ denote the smallest and largest marginal contribution of any sub-coalition of players respectively. Finally, we also consider non-irrevocable policies, with alternative bounds only when the number of players is limited.",
      "authors": [
        "Yao Zhang",
        "Indrajit Saha",
        "Zhaohong Sun and Makoto Yokoo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:50:02+00:00",
          "link": "https://arxiv.org/abs/2507.11883v1",
          "size": "222kb",
          "version": "v1"
        }
      ],
      "title": "Coalitions on the Fly in Cooperative Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11883",
        "HTML": "https://arxiv.org/html/2507.11883v1",
        "PDF": "https://arxiv.org/pdf/2507.11883"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on coalition formation in cooperative games, which does not involve any aspect of data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11889",
      "abstract": "Adaptive mission control and dynamic parameter reconfiguration are essential for autonomous underwater vehicles (AUVs) operating in GPS-denied, communication-limited marine environments. However, most current AUV platforms execute static, pre-programmed missions or rely on tethered connections and high-latency acoustic channels for mid-mission updates, significantly limiting their adaptability and responsiveness. In this paper, we introduce NemeSys, a novel AUV system designed to support real-time mission reconfiguration through compact optical and magnetoelectric (OME) signaling facilitated by floating buoys. We present the full system design, control architecture, and a semantic mission encoding framework that enables interactive exploration and task adaptation via low-bandwidth communication. The proposed system is validated through analytical modeling, controlled experimental evaluations, and open-water trials. Results confirm the feasibility of online mission adaptation and semantic task updates, highlighting NemeSys as an online AUV platform for goal-driven adaptive autonomy in dynamic and uncertain underwater environments.",
      "authors": [
        "Adnan Abdullah",
        "Alankrit Gupta",
        "Vaishnav Ramesh",
        "Shivali Patel",
        "and Md Jahidul Islam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:02:59+00:00",
          "link": "https://arxiv.org/abs/2507.11889v1",
          "size": "6932kb",
          "version": "v1"
        }
      ],
      "title": "NemeSys: An Online Underwater Explorer with Goal-Driven Adaptive Autonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11889",
        "HTML": "https://arxiv.org/html/2507.11889v1",
        "PDF": "https://arxiv.org/pdf/2507.11889"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper describes an AUV system for real-time mission reconfiguration in underwater environments, which does not directly tackle data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11892",
      "abstract": "Dynamic Facial Expression Recognition (DFER) aims to identify human emotions from temporally evolving facial movements and plays a critical role in affective computing. While recent vision-language approaches have introduced semantic textual descriptions to guide expression recognition, existing methods still face two key limitations: they often underutilize the subtle emotional cues embedded in generated text, and they have yet to incorporate sufficiently effective mechanisms for filtering out facial dynamics that are irrelevant to emotional expression. To address these gaps, We propose GRACE, Granular Representation Alignment for Cross-modal Emotion recognition that integrates dynamic motion modeling, semantic text refinement, and token-level cross-modal alignment to facilitate the precise localization of emotionally salient spatiotemporal features. Our method constructs emotion-aware textual descriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and highlights expression-relevant facial motion through a motion-difference weighting mechanism. These refined semantic and visual signals are aligned at the token level using entropy-regularized optimal transport. Experiments on three benchmark datasets demonstrate that our method significantly improves recognition performance, particularly in challenging settings with ambiguous or imbalanced emotion classes, establishing new state-of-the-art (SOTA) results in terms of both UAR and WAR.",
      "authors": [
        "Yu Liu",
        "Leyuan Qu",
        "Hanlei Shi",
        "Di Gao",
        "Yuhua Zheng",
        "Taihao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:15:06+00:00",
          "link": "https://arxiv.org/abs/2507.11892v1",
          "size": "1055kb",
          "version": "v1"
        }
      ],
      "title": "From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11892",
        "HTML": "https://arxiv.org/html/2507.11892v1",
        "PDF": "https://arxiv.org/pdf/2507.11892"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents GRACE for emotion recognition, emphasizing cross-modal alignment and emotional cue enhancement, without connection to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11893",
      "abstract": "High spatial frequency information, including fine details like textures, significantly contributes to the accuracy of semantic segmentation. However, according to the Nyquist-Shannon Sampling Theorem, high-frequency components are vulnerable to aliasing or distortion when propagating through downsampling layers such as strided-convolution. Here, we propose a novel Spatial Frequency Modulation (SFM) that modulates high-frequency features to a lower frequency before downsampling and then demodulates them back during upsampling. Specifically, we implement modulation through adaptive resampling (ARS) and design a lightweight add-on that can densely sample the high-frequency areas to scale up the signal, thereby lowering its frequency in accordance with the Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling (MSAU) to demodulate the modulated feature and recover high-frequency information through non-uniform upsampling This module further improves segmentation by explicitly exploiting information interaction between densely and sparsely resampled areas at multiple scales. Both modules can seamlessly integrate with various architectures, extending from convolutional neural networks to transformers. Feature visualization and analysis confirm that our method effectively alleviates aliasing while successfully retaining details after demodulation. Finally, we validate the broad applicability and effectiveness of SFM by extending it to image classification, adversarial robustness, instance segmentation, and panoptic segmentation tasks. The code is available at \\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.",
      "authors": [
        "Linwei Chen",
        "Ying Fu",
        "Lin Gu",
        "Dezhi Zheng",
        "Jifeng Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:15:53+00:00",
          "link": "https://arxiv.org/abs/2507.11893v1",
          "size": "6192kb",
          "version": "v1"
        }
      ],
      "title": "Spatial Frequency Modulation for Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11893",
        "HTML": "https://arxiv.org/html/2507.11893v1",
        "PDF": "https://arxiv.org/pdf/2507.11893"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper proposes spatial frequency modulation for semantic segmentation, exploring signal processing techniques rather than data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11894",
      "abstract": "This paper introduces and analyzes a search and retrieval model that adopts key semantic communication principles from retrieval-augmented generation. We specifically present an information-theoretic analysis of a remote document retrieval system operating over a symbol erasure channel. The proposed model encodes the feature vector of a query, derived from term-frequency weights of a language corpus by using a repetition code with an adaptive rate dependent on the contextual importance of the terms. At the decoder, we select between two documents based on the contextual closeness of the recovered query. By leveraging a jointly Gaussian approximation for both the true and reconstructed similarity scores, we derive an explicit expression for the retrieval error probability, i.e., the probability under which the less similar document is selected. Numerical simulations on synthetic and real-world data (Google NQ) confirm the validity of the analysis. They further demonstrate that assigning greater redundancy to critical features effectively reduces the error rate, highlighting the effectiveness of semantic-aware feature encoding in error-prone communication settings.",
      "authors": [
        "Sara Ghasvarianjahromi",
        "Yauhen Yakimenka",
        "J\\\"org Kliewer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:21:46+00:00",
          "link": "https://arxiv.org/abs/2507.11894v1",
          "size": "373kb",
          "version": "v1"
        }
      ],
      "title": "Context-Aware Search and Retrieval Over Erasure Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11894",
        "HTML": "https://arxiv.org/html/2507.11894v1",
        "PDF": "https://arxiv.org/pdf/2507.11894"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper primarily focuses on semantic communication principles for search and retrieval over erasure channels, with no mention of reinforcement learning or data processing for RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11897",
      "abstract": "Equality saturation is a powerful technique for program optimization. Contextual equality saturation extends this to support rewrite rules that are conditioned on where a term appears in an expression. Existing work has brought contextual reasoning to egg; in this paper, we share our ongoing work to extend this to relational equality saturation in egglog. We summarize the existing approaches to contextual equality saturation, outline its main applications, and identify key challenges in combining this approach with relational models.",
      "authors": [
        "Tyler Hou",
        "Shadaj Laddad",
        "Joseph M. Hellerstein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:24:42+00:00",
          "link": "https://arxiv.org/abs/2507.11897v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Towards Relational Contextual Equality Saturation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11897",
        "HTML": "https://arxiv.org/html/2507.11897v1",
        "PDF": "https://arxiv.org/pdf/2507.11897"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses program optimization through equality saturation techniques and does not relate to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11898",
      "abstract": "Physicists often manually consider extreme cases when testing a theory. In this paper, we show how to automate extremal testing of network software using LLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS name length limits); then ask the LLM to generate tests that violate the constraints. We demonstrate how easy this process is by generating extremal tests for HTTP, BGP and DNS implementations, each of which uncovered new bugs. We show how this methodology extends to centralized network software such as shortest path algorithms, and how LLMs can generate filtering code to reject extremal input. We propose using agentic AI to further automate extremal testing. LLM-generated extremal testing goes beyond an old technique in software testing called Boundary Value Analysis.",
      "authors": [
        "Rathin Singha",
        "Harry Qian",
        "Srinath Saikrishnan",
        "Tracy Zhao",
        "Ryan Beckett",
        "Siva Kesava Reddy Kakarla",
        "and George Varghese"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:29:49+00:00",
          "link": "https://arxiv.org/abs/2507.11898v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "Extremal Testing for Network Software using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11898",
        "HTML": "https://arxiv.org/html/2507.11898v1",
        "PDF": "https://arxiv.org/pdf/2507.11898"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the automation of extremal testing for network software using LLMs, and does not address reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11899",
      "abstract": "Load balancing plays a pivotal role in cloud computing, ensuring that resources are optimally allocated to maintain high service quality and operational efficiency. As workloads in cloud environments become increasingly dynamic and unpredictable, load balancing strategies are evolving from traditional static methods to more adaptive and intelligent approaches. In this study, the Cloud Analyst simulation tool was used to evaluate the performance of different load balancing algorithms under various scenarios, including both centralized and distributed resource setups. The results highlight that while the Round Robin algorithm yields slightly better processing times within a single data center, Equally Spread and Throttled techniques perform competitively, especially when network latency is considered. More importantly, when resources are distributed across multiple data centers, response times are significantly reduced, emphasizing the value of proximity and efficient load distribution. In these distributed environments, Equally Spread and Throttled algorithms not only maintain quick response times but also contribute to lower operational costs. These findings demonstrate the necessity of strategic resource placement and proactive infrastructure planning to balance performance and cost. Adopting intelligent, dynamic load balancing and resource management practices can help organizations meet evolving cloud demands, optimize costs, and maintain a competitive advantage. Continuous evaluation and integration of emerging technologies are crucial for sustaining effective and scalable cloud operations.",
      "authors": [
        "Saeid Aghasoleymani Najafabadi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:31:36+00:00",
          "link": "https://arxiv.org/abs/2507.11899v1",
          "size": "1113kb",
          "version": "v1"
        }
      ],
      "title": "Performance Assessment of Load Balancing Methods in Cloud Computing: Analysis of Round Robin, Equally Spread, and Throttled Strategies Using Cloud Analyst",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11899",
        "PDF": "https://arxiv.org/pdf/2507.11899"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This research is centered on load balancing strategies in cloud computing and does not involve reinforcement learning or data processing within an RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11900",
      "abstract": "Video compression is a standard procedure applied to all videos to minimize storage and transmission demands while preserving visual quality as much as possible. Therefore, evaluating the visual quality of compressed videos is crucial for guiding the practical usage and further development of video compression algorithms. Although numerous compressed video quality assessment (VQA) methods have been proposed, they often lack the generalization capability needed to handle the increasing diversity of video types, particularly high dynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an effective VQA framework designed to address the challenges of HDR video quality assessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the backbone networks for the proposed full-reference (FR) and no-reference (NR) VQA models, respectively. For the FR model, we compute deep structural and textural similarities between reference and distorted frames using intermediate-layer features extracted from the Swin Transformer as its quality-aware feature representation. For the NR model, we extract the global mean of the final-layer feature maps from SigLip 2 as its quality-aware representation. To mitigate the issue of limited HDR training data, we pre-train the FR model on a large-scale standard dynamic range (SDR) VQA dataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ an iterative mixed-dataset training strategy across multiple compressed VQA datasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental results show that our models achieve state-of-the-art performance compared to existing FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand Challenge at IEEE ICME 2025. The code is available at https://github.com/sunwei925/CompressedVQA-HDR.",
      "authors": [
        "Wei Sun",
        "Linhan Cao",
        "Kang Fu",
        "Dandan Zhu",
        "Jun Jia",
        "Menghan Hu",
        "Xiongkuo Min",
        "Guangtao Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:33:06+00:00",
          "link": "https://arxiv.org/abs/2507.11900v1",
          "size": "705kb",
          "version": "v1"
        }
      ],
      "title": "CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11900",
        "HTML": "https://arxiv.org/html/2507.11900v1",
        "PDF": "https://arxiv.org/pdf/2507.11900"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on video quality assessment for high dynamic range videos using models based on Swin Transformer and SigLip, which is unrelated to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11901",
      "abstract": "Imbalanced problems are prevalent in various real-world scenarios and are extensively explored in classification tasks. However, they also present challenges for regression tasks due to the rarity of certain target values. A common alternative is to employ balancing algorithms in preprocessing to address dataset imbalance. However, due to the variety of resampling methods and learning models, determining the optimal solution requires testing many combinations. Furthermore, the learning model, dataset, and evaluation metric affect the best strategies. This work proposes the Meta-learning for Imbalanced Regression (Meta-IR) framework, which diverges from existing literature by training meta-classifiers to recommend the best pipeline composed of the resampling strategy and learning model per task in a zero-shot fashion. The meta-classifiers are trained using a set of meta-features to learn how to map the meta-features to the classes indicating the best pipeline. We propose two formulations: Independent and Chained. Independent trains the meta-classifiers to separately indicate the best learning algorithm and resampling strategy. Chained involves a sequential procedure where the output of one meta-classifier is used as input for another to model intrinsic relationship factors. The Chained scenario showed superior performance, suggesting a relationship between the learning algorithm and the resampling strategy per task. Compared with AutoML frameworks, Meta-IR obtained better results. Moreover, compared with baselines of six learning algorithms and six resampling algorithms plus no resampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of them. The code, data, and further information of the experiments can be found on GitHub: https://github.com/JusciAvelino/Meta-IR.",
      "authors": [
        "Juscimara G. Avelino",
        "George D. C. Cavalcanti and Rafael M. O. Cruz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:34:02+00:00",
          "link": "https://arxiv.org/abs/2507.11901v1",
          "size": "1378kb",
          "version": "v1"
        }
      ],
      "title": "Imbalanced Regression Pipeline Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11901",
        "HTML": "https://arxiv.org/html/2507.11901v1",
        "PDF": "https://arxiv.org/pdf/2507.11901"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses the imbalanced regression problem and involves meta-learning for pipeline recommendation. It does not discuss or contribute to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11902",
      "abstract": "Imbalanced problems can arise in different real-world situations, and to address this, certain strategies in the form of resampling or balancing algorithms are proposed. This issue has largely been studied in the context of classification, and yet, the same problem features in regression tasks, where target values are continuous. This work presents an extensive experimental study comprising various balancing and predictive models, and wich uses metrics to capture important elements for the user and to evaluate the predictive model in an imbalanced regression data context. It also proposes a taxonomy for imbalanced regression approaches based on three crucial criteria: regression model, learning process, and evaluation metrics. The study offers new insights into the use of such strategies, highlighting the advantages they bring to each model's learning process, and indicating directions for further studies. The code, data and further information related to the experiments performed herein can be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.",
      "authors": [
        "Juscimara G. Avelino",
        "George D. C. Cavalcanti and Rafael M. O. Cruz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:34:42+00:00",
          "link": "https://arxiv.org/abs/2507.11902v1",
          "size": "16897kb",
          "version": "v1"
        }
      ],
      "title": "Resampling strategies for imbalanced regression: a survey and empirical analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11902",
        "HTML": "https://arxiv.org/html/2507.11902v1",
        "PDF": "https://arxiv.org/pdf/2507.11902"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper surveys resampling strategies for imbalanced regression tasks, without any connection to reinforcement learning or RL-specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11903",
      "abstract": "When designed deliberately, data visualizations can become powerful persuasive tools, influencing viewers' opinions, values, and actions. While researchers have begun studying this issue (e.g., to evaluate the effects of persuasive visualization), we argue that a fundamental mechanism of persuasion resides in rhetorical construction, a perspective inadequately addressed in current visualization research. To fill this gap, we present a focused analysis of octopus maps, a visual genre that has maintained persuasive power across centuries and achieved significant social impact. Employing rhetorical schema theory, we collected and analyzed 90 octopus maps spanning from the 19th century to contemporary times. We closely examined how octopus maps implement their persuasive intents and constructed a design space that reveals how visual metaphors are strategically constructed and what common rhetorical strategies are applied to components such as maps, octopus imagery, and text. Through the above analysis, we also uncover a set of interesting findings. For instance, contrary to the common perception that octopus maps are primarily a historical phenomenon, our research shows that they remain a lively design convention in today's digital age. Additionally, while most octopus maps stem from Western discourse that views the octopus as an evil symbol, some designs offer alternative interpretations, highlighting the dynamic nature of rhetoric across different sociocultural settings. Lastly, drawing from the lessons provided by octopus maps, we discuss the associated ethical concerns of persuasive visualization.",
      "authors": [
        "Daocheng Lin",
        "Yifan Wang",
        "Yutong Yang",
        "Xingyu Lan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:41:53+00:00",
          "link": "https://arxiv.org/abs/2507.11903v1",
          "size": "19061kb",
          "version": "v1"
        }
      ],
      "title": "Unveiling the Visual Rhetoric of Persuasive Cartography: A Case Study of the Design of Octopus Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11903",
        "HTML": "https://arxiv.org/html/2507.11903v1",
        "PDF": "https://arxiv.org/pdf/2507.11903"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study analyzes the design and rhetorical strategies behind octopus maps, which does not involve reinforcement learning or data processing in the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11906",
      "abstract": "Collective human activities like using an Ouija board (or Kokkuri-san) often produce emergent, coherent linguistic outputs unintended by any single participant. While psychological explanations such as the ideomotor effect exist, a computational understanding of how decentralized, implicit linguistic knowledge fuses through shared physical interaction remains elusive. We introduce CoCre-Sam (Collective-Creature Sampling), a framework modeling this phenomenon as collective Langevin dynamics sampling from implicitly fused language models. Each participant is represented as an agent associated with an energy landscape derived from an internal language model reflecting linguistic priors, and agents exert stochastic forces based on local energy gradients. We theoretically prove that the collective motion of the shared pointer (planchette) corresponds to Langevin MCMC sampling from the sum of individual energy landscapes, representing fused collective knowledge. Simulations validate that CoCre-Sam dynamics effectively fuse different models and generate meaningful character sequences, while ablation studies confirm the essential roles of collective interaction and stochasticity. Altogether, CoCre-Sam provides a novel computational mechanism linking individual implicit knowledge, embodied collective action, and emergent linguistic phenomena, grounding these complex interactions in the principles of probabilistic sampling.",
      "authors": [
        "Tadahiro Taniguchi",
        "Masatoshi Nagano",
        "Haruumi Omoto and Yoshiki Hayashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:45:23+00:00",
          "link": "https://arxiv.org/abs/2507.11906v1",
          "size": "1356kb",
          "version": "v1"
        }
      ],
      "title": "CoCre-Sam (Kokkuri-san): Modeling Ouija Board as Collective Langevin Dynamics Sampling from Fused Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11906",
        "HTML": "https://arxiv.org/html/2507.11906v1",
        "PDF": "https://arxiv.org/pdf/2507.11906"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces CoCre-Sam, a framework for modeling language phenomena via Langevin dynamics, and does not address reinforcement learning or data processing relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11907",
      "abstract": "Many real-world tasks such as recommending videos with the kids tag can be reduced to finding most similar vectors associated with hard predicates. This task, filtered vector search, is challenging as prior state-of-the-art graph-based (unfiltered) similarity search techniques quickly degenerate when hard constraints are considered. That is, effective graph-based filtered similarity search relies on sufficient connectivity for reaching the most similar items within just a few hops. To consider predicates, recent works propose modifying graph traversal to visit only the items that may satisfy predicates. However, they fail to offer the just-a-few-hops property for a wide range of predicates: they must restrict predicates significantly or lose efficiency if only a small fraction of items satisfy predicates.\n  We propose an opposite approach: instead of constraining traversal, we build many indexes each serving different predicate forms. For effective construction, we devise a three-dimensional analytical model capturing relationships among index size, search time, and recall, with which we follow a workload-aware approach to pack as many useful indexes as possible into a collection. At query time, the analytical model is employed yet again to discern the one that offers the fastest search at a given recall. We show superior performance and support on datasets with varying selectivities and forms: our approach achieves up to 8.06x speedup while having as low as 1% build time versus other indexes, with less than 2.15x memory of a standard HNSW graph and modest knowledge of past workloads.",
      "authors": [
        "Zhaoheng Li",
        "Silu Huang",
        "Wei Ding",
        "Yongjoo Park",
        "Jianjun Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:46:28+00:00",
          "link": "https://arxiv.org/abs/2507.11907v1",
          "size": "207kb",
          "version": "v1"
        }
      ],
      "title": "SIEVE: Effective Filtered Vector Search with Collection of Indexes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11907",
        "HTML": "https://arxiv.org/html/2507.11907v1",
        "PDF": "https://arxiv.org/pdf/2507.11907"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on filtered vector search and not on reinforcement learning or data processing related to RL. It proposes a model for building indexes for vector search tasks, which is unrelated to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11908",
      "abstract": "With the increasing concerns around privacy and the enforcement of data privacy laws, many websites now provide users with privacy controls. However, locating these controls can be challenging, as they are frequently hidden within multiple settings and layers. Moreover, the lack of standardization means these controls can vary widely across services. The technical or confusing terminology used to describe these controls further complicates users' ability to understand and use them effectively. This paper presents a large-scale empirical analysis investigating usability challenges of web privacy controls across 18,628 websites. While aiming for a multi-scenario view, our automated data collection faced significant hurdles, particularly in simulating sign-up and authenticated user visits, leading to more focused insights on guest visit scenarios and challenges in automated capture of dynamic user interactions. Our heuristic evaluation of three different user visit scenarios identifies significant website usability issues. Our results show that privacy policies are most common across all visit scenarios, with nudges and notices being prevalent in sign-up situations. We recommend designing privacy controls that: enhance awareness through pop-up nudges and notices; offer a table of contents as navigational aids and customized settings links in policies for more informed choice; and ensure accessibility via direct links to privacy settings from nudges.",
      "authors": [
        "Rahat Masood",
        "Sunday Oyinlola Ogundoyin",
        "Muhammad Ikram",
        "Alex Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:47:35+00:00",
          "link": "https://arxiv.org/abs/2507.11908v1",
          "size": "473kb",
          "version": "v1"
        }
      ],
      "title": "Unveiling Usability Challenges in Web Privacy Controls",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11908",
        "HTML": "https://arxiv.org/html/2507.11908v1",
        "PDF": "https://arxiv.org/pdf/2507.11908"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is centered around usability challenges in web privacy controls and does not pertain to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11910",
      "abstract": "Event-based sensors have emerged as a promising solution for addressing challenging conditions in pedestrian and traffic monitoring systems. Their low-latency and high dynamic range allow for improved response time in safety-critical situations caused by distracted walking or other unusual movements. However, the availability of data covering such scenarios remains limited. To address this gap, we present SEPose -- a comprehensive synthetic event-based human pose estimation dataset for fixed pedestrian perception generated using dynamic vision sensors in the CARLA simulator. With nearly 350K annotated pedestrians with body pose keypoints from the perspective of fixed traffic cameras, SEPose is a comprehensive synthetic multi-person pose estimation dataset that spans busy and light crowds and traffic across diverse lighting and weather conditions in 4-way intersections in urban, suburban, and rural environments. We train existing state-of-the-art models such as RVT and YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate the sim-to-real generalization capabilities of the proposed dataset.",
      "authors": [
        "Kaustav Chanda",
        "Aayush Atul Verma",
        "Arpitsinh Vaghela",
        "Yezhou Yang",
        "Bharatesh Chakravarthi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:54:11+00:00",
          "link": "https://arxiv.org/abs/2507.11910v1",
          "size": "4952kb",
          "version": "v1"
        }
      ],
      "title": "SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11910",
        "HTML": "https://arxiv.org/html/2507.11910v1",
        "PDF": "https://arxiv.org/pdf/2507.11910"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "SEPose discusses a synthetic dataset for human pose estimation but is not related to reinforcement learning or data processing within the RL context. The focus is on sim-to-real generalization in vision data, not RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11911",
      "abstract": "Electroencephalogram (EEG) decoding models for brain-computer interfaces (BCIs) struggle with cross-dataset learning and generalization due to channel layout inconsistencies, non-stationary signal distributions, and limited neurophysiological prior integration. To address these issues, we propose a plug-and-play Alignment-Based Frame-Patch Modeling (AFPM) framework, which has two main components: 1) Spatial Alignment, which selects task-relevant channels based on brain-region priors, aligns EEG distributions across domains, and remaps the selected channels to a unified layout; and, 2) Frame-Patch Encoding, which models multi-dataset signals into unified spatiotemporal patches for EEG decoding. Compared to 17 state-of-the-art approaches that need dataset-specific tuning, the proposed calibration-free AFPM achieves performance gains of up to 4.40% on motor imagery and 3.58% on event-related potential tasks. To our knowledge, this is the first calibration-free cross-dataset EEG decoding framework, substantially enhancing the practicalness of BCIs in real-world applications.",
      "authors": [
        "Xiaoqing Chen",
        "Siyang Li",
        "Dongrui Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:55:09+00:00",
          "link": "https://arxiv.org/abs/2507.11911v1",
          "size": "2653kb",
          "version": "v1"
        }
      ],
      "title": "AFPM: Alignment-based Frame Patch Modeling for Cross-Dataset EEG Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11911",
        "HTML": "https://arxiv.org/html/2507.11911v1",
        "PDF": "https://arxiv.org/pdf/2507.11911"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is about cross-dataset EEG decoding and does not relate to reinforcement learning or data processing in RL. It focuses on spatial alignment and frame-patch encoding for EEG data, independent of RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11916",
      "abstract": "The rapid advancement of GPU technology has unlocked powerful parallel processing capabilities, creating new opportunities to enhance classic search algorithms. A recent successful application of GPUs is in compressing large pattern database (PDB) heuristics using neural networks while preserving heuristic admissibility. However, very few algorithms have been designed to exploit GPUs during search. Several variants of A* exist that batch GPU computations. In this paper we introduce a method for batching GPU computations in depth first search. In particular, we describe a new cost-bounded depth-first search (CB-DFS) method that leverages the combined parallelism of modern CPUs and GPUs. This is used to create algorithms like \\emph{Batch IDA*}, an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an extensions of Budgeted Tree Search. Our approach builds on the general approach used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding tile puzzle (STP), showing that GPU operations can be efficiently batched in DFS. Additionally, we conduct extensive experiments to analyze the effects of hyperparameters, neural network heuristic size, and hardware resources on performance.",
      "authors": [
        "Ehsan Futuhi",
        "Nathan R. Sturtevant"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:07:33+00:00",
          "link": "https://arxiv.org/abs/2507.11916v1",
          "size": "226kb",
          "version": "v1"
        }
      ],
      "title": "A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11916",
        "HTML": "https://arxiv.org/html/2507.11916v1",
        "PDF": "https://arxiv.org/pdf/2507.11916"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores cost-bounded DFS and its applications to algorithms like IDA* and BTS, leveraging CPU-GPU parallelism. It does not address reinforcement learning or data processing relevant to RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11920",
      "abstract": "Real-time path planning in dense, uncertain environments remains a challenging problem, as predicting the future motions of numerous dynamic obstacles is computationally burdensome and unrealistic. To address this, we introduce Hybrid Prediction-based Risk-Aware Planning (HyPRAP), a prediction-based risk-aware path-planning framework which uses a hybrid combination of models to predict local obstacle movement. HyPRAP uses a novel Prediction-based Collision Risk Index (P-CRI) to evaluate the risk posed by each obstacle, enabling the selective use of predictors based on whether the agent prioritizes high predictive accuracy or low computational prediction overhead. This selective routing enables the agent to focus on high-risk obstacles while ignoring or simplifying low-risk ones, making it suitable for environments with a large number of obstacles. Moreover, HyPRAP incorporates uncertainty quantification through hybrid conformal prediction by deriving confidence bounds simultaneously achieved by multiple predictions across different models. Theoretical analysis demonstrates that HyPRAP effectively balances safety and computational efficiency by leveraging the diversity of prediction models. Extensive simulations validate these insights for more general settings, confirming that HyPRAP performs better compared to single predictor methods, and P-CRI performs better over naive proximity-based risk assessment.",
      "authors": [
        "Jeongyong Yang",
        "KwangBin Lee",
        "SooJean Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:31:38+00:00",
          "link": "https://arxiv.org/abs/2507.11920v1",
          "size": "660kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Conformal Prediction-based Risk-Aware Model Predictive Planning in Dense, Uncertain Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11920",
        "HTML": "https://arxiv.org/html/2507.11920v1",
        "PDF": "https://arxiv.org/pdf/2507.11920"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on path planning in environments with dynamic obstacles using a risk-aware framework, which involves prediction and risk assessment but is not directly related to data processing within reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11924",
      "abstract": "In distributed target-tracking sensor networks, efficient data gathering methods are necessary to save communication resources and assure information accuracy. This paper proposes a Feedback (FB) distributed data-gathering method which lets the central unit feed information back to the mobile sensors; each sensor then uses it to cancel redundant transmissions and reduce communication congestion. We rigorously compare its performance, in terms of mean-squared error (MSE) and cost of power per sensor, against more conventional Non-Feedback (NF) architectures by evaluating conditions of feasibility and advantage under different architecture specifications (e.g., communication delay rate, power cost rate, maximum back-off time, sampling period, observation noise). Here, we defined the advantage as the performance gain achieved by FB over NF, while FB is said to be feasible if the advantage region is nonempty. Our theoretical analyses show that the feasibility of FB depends more on the communication power cost, while the advantage depends on the sensors' propagation delay per transmission interval; we derive concrete conditions under which these outcomes hold. Using extensive numerical simulations under a variety of settings, we confirm the accuracy of the derived conditions, and show that our theoretical results hold even for more complex scenarios where the simplifying assumptions no longer hold.",
      "authors": [
        "Hyeongmin Choe",
        "Soojean Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:42:42+00:00",
          "link": "https://arxiv.org/abs/2507.11924v1",
          "size": "1963kb",
          "version": "v1"
        }
      ],
      "title": "Advantages of Feedback in Distributed Data-Gathering for Accurate and Power-Efficient State-Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11924",
        "HTML": "https://arxiv.org/html/2507.11924v1",
        "PDF": "https://arxiv.org/pdf/2507.11924"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a feedback method for distributed data-gathering in sensor networks and focuses on reducing communication congestion, which is not related to data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11925",
      "abstract": "Speech enhancement (SE) utilizing diffusion models is a promising technology that improves speech quality in noisy speech data. Furthermore, the Schr\\\"odinger bridge (SB) has recently been used in diffusion-based SE to improve speech quality by resolving a mismatch between the endpoint of the forward process and the starting point of the reverse process. However, the SB still exhibits slow inference owing to the necessity of a large number of function evaluations (NFE) for inference to obtain high-quality results. While Consistency Models (CMs) address this issue by employing consistency training that uses distillation from pretrained models in the field of image generation, it does not improve generation quality when the number of steps increases. As a solution to this problem, Consistency Trajectory Models (CTMs) not only accelerate inference speed but also maintain a favorable trade-off between quality and speed. Furthermore, SoundCTM demonstrates the applicability of CTM techniques to the field of sound generation. In this paper, we present Schr\\\"odinger bridge Consistency Trajectory Models (SBCTM) by applying the CTM's technique to the Schr\\\"odinger bridge for SE. Additionally, we introduce a novel auxiliary loss, including a perceptual loss, into the original CTM's training framework. As a result, SBCTM achieves an approximately 16x improvement in the real-time factor (RTF) compared to the conventional Schr\\\"odinger bridge for SE. Furthermore, the favorable trade-off between quality and speed in SBCTM allows for time-efficient inference by limiting multi-step refinement to cases where 1-step inference is insufficient. Our code, pretrained models, and audio samples are available at https://github.com/sony/sbctm/.",
      "authors": [
        "Shuichiro Nishigori",
        "Koichi Saito",
        "Naoki Murata",
        "Masato Hirano",
        "Shusuke Takahashi",
        "and Yuki Mitsufuji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:43:02+00:00",
          "link": "https://arxiv.org/abs/2507.11925v1",
          "size": "184kb",
          "version": "v1"
        }
      ],
      "title": "Schr\\\"odinger Bridge Consistency Trajectory Models for Speech Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11925",
        "HTML": "https://arxiv.org/html/2507.11925v1",
        "PDF": "https://arxiv.org/pdf/2507.11925"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses speech enhancement using diffusion models and does not address data processing within reinforcement learning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11926",
      "abstract": "The epidemic failure of replicability across empirical science and machine learning has recently motivated the formal study of replicable learning algorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from a fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the design of data-efficient replicable algorithms is now more or less understood. In contrast, there remain significant gaps in our knowledge for control settings like reinforcement learning where an agent must interact directly with a shifting environment. Karbasi et. al show that with access to a generative model of an environment with $S$ states and $A$ actions (the RL 'batch setting'), replicably learning a near-optimal policy costs only $\\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a generative model jumps to $\\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the substantial difficulty of environment exploration. This gap raises a key question in the broader theory of replicability: Is replicable exploration inherently more expensive than batch learning? Is sample-efficient replicable RL even possible?\n  In this work, we (nearly) resolve this problem (for low-horizon tabular MDPs): exploration is not a significant barrier to replicable learning! Our main result is a replicable RL algorithm on $\\tilde{O}(S^2A)$ samples, bridging the gap between the generative and episodic settings. We complement this with a matching $\\tilde{\\Omega}(S^2A)$ lower bound in the generative setting (under the common parallel sampling assumption) and an unconditional lower bound in the episodic setting of $\\tilde{\\Omega}(S^2)$ showcasing the near-optimality of our algorithm with respect to the state space $S$.",
      "authors": [
        "Max Hopkins",
        "Sihan Liu",
        "Christopher Ye",
        "Yuichi Yoshida"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:43:46+00:00",
          "link": "https://arxiv.org/abs/2507.11926v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11926",
        "HTML": "https://arxiv.org/html/2507.11926v1",
        "PDF": "https://arxiv.org/pdf/2507.11926"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper addresses replicable reinforcement learning and mentions sample-efficient algorithms in RL, but the main focus is on algorithm replicability rather than data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11928",
      "abstract": "This paper presents a machine learning-accelerated optimization framework for RF power amplifier design that reduces simulation requirements by 65% while maintaining $\\pm0.3$ to $\\pm0.4$ dBm accuracy. The proposed method combines MaxMin Latin Hypercube Sampling with CatBoost gradient boosting to intelligently explore multidimensional parameter spaces. Instead of exhaustively simulating all parameter combinations to achieve target P2dB compression specifications, our approach strategically selects approximately 35% of critical simulation points. The framework processes ADS netlists, executes harmonic balance simulations on the reduced dataset, and trains a CatBoost model to predict P2dB performance across the entire design space. Validation across 15 PA operating modes yields an average $R^2$ of 0.901, with the system ranking parameter combinations by their likelihood of meeting target specifications. The integrated solution delivers 58.24% to 77.78% reduction in simulation time through automated GUI-based workflows, enabling rapid design iterations without compromising accuracy standards required for production RF circuits.",
      "authors": [
        "Abhishek Sriram",
        "Neal Tuffy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:52:24+00:00",
          "link": "https://arxiv.org/abs/2507.11928v1",
          "size": "602kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11928",
        "HTML": "https://arxiv.org/html/2507.11928v1",
        "PDF": "https://arxiv.org/pdf/2507.11928"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper centers around a machine learning framework for RF power amplifier design optimization, involving parameter tuning and simulation, with no direct relevance to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11929",
      "abstract": "Serverless computing has attracted a broad range of applications due to its ease of use and resource elasticity. However, developing serverless applications often poses a dilemma -- relying on general-purpose serverless platforms can fall short of delivering satisfactory performance for complex workloads, whereas building application-specific serverless systems undermines the simplicity and generality. In this paper, we propose an extensible design principle for serverless computing. We argue that a platform should enable developers to extend system behaviors for domain-specialized optimizations while retaining a shared, easy-to-use serverless environment. We take data analytics as a representative serverless use case and realize this design principle in Proteus. Proteus introduces a novel abstraction of decision workflows, allowing developers to customize control-plane behaviors for improved application performance. Preliminary results show that Proteus's prototype effectively optimizes analytical query execution and supports fine-grained resource sharing across diverse applications.",
      "authors": [
        "Minchen Yu",
        "Yinghao Ren",
        "Jiamu Zhao",
        "Jiaqi Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:52:32+00:00",
          "link": "https://arxiv.org/abs/2507.11929v1",
          "size": "370kb",
          "version": "v1"
        }
      ],
      "title": "Making Serverless Computing Extensible: A Case Study of Serverless Data Analytics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11929",
        "HTML": "https://arxiv.org/html/2507.11929v1",
        "PDF": "https://arxiv.org/pdf/2507.11929"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on serverless computing design principles and optimizations for data analytics. It does not discuss reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11931",
      "abstract": "In low-light environments, conventional cameras often struggle to capture clear multi-view images of objects due to dynamic range limitations and motion blur caused by long exposure. Event cameras, with their high-dynamic range and high-speed properties, have the potential to mitigate these issues. Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction, facilitating bright frame synthesis from multiple viewpoints in low-light conditions. However, naively using an event-assisted 3D GS approach still faced challenges because, in low light, events are noisy, frames lack quality, and the color tone may be inconsistent. To address these issues, we propose Dark-EvGS, the first event-assisted 3D GS framework that enables the reconstruction of bright frames from arbitrary viewpoints along the camera trajectory. Triplet-level supervision is proposed to gain holistic knowledge, granular details, and sharp scene rendering. The color tone matching block is proposed to guarantee the color consistency of the rendered frames. Furthermore, we introduce the first real-captured dataset for the event-guided bright frame synthesis task via 3D GS-based radiance field reconstruction. Experiments demonstrate that our method achieves better results than existing methods, conquering radiance field reconstruction under challenging low-light conditions. The code and sample data are included in the supplementary material.",
      "authors": [
        "Jingqian Wu",
        "Peiqi Duan",
        "Zongqiang Wang",
        "Changwei Wang",
        "Boxin Shi",
        "Edmund Y. Lam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:54:33+00:00",
          "link": "https://arxiv.org/abs/2507.11931v1",
          "size": "1982kb",
          "version": "v1"
        }
      ],
      "title": "Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11931",
        "HTML": "https://arxiv.org/html/2507.11931v1",
        "PDF": "https://arxiv.org/pdf/2507.11931"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces an event-assisted framework for 3D GS-based radiance field reconstruction in low-light conditions. It does not relate to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11932",
      "abstract": "Mental visualization, the ability to construct and manipulate visual representations internally, is a core component of human cognition and plays a vital role in tasks involving reasoning, prediction, and abstraction. Despite the rapid progress of Multimodal Large Language Models (MLLMs), current benchmarks primarily assess passive visual perception, offering limited insight into the more active capability of internally constructing visual patterns to support problem solving. Yet mental visualization is a critical cognitive skill in humans, supporting abilities such as spatial navigation, predicting physical trajectories, and solving complex visual problems through imaginative simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic benchmark designed to evaluate the mental visualization abilities of MLLMs through four carefully constructed puzzles. Each task is procedurally generated and presented at three difficulty levels, enabling controlled analysis of model performance across increasing complexity. Our comprehensive evaluation of state-of-the-art models reveals a substantial gap between the performance of humans and MLLMs. Additionally, we explore the potential of reinforcement learning to improve visual simulation capabilities. Our findings suggest that while some models exhibit partial competence in recognizing visual patterns, robust mental visualization remains an open challenge for current MLLMs.",
      "authors": [
        "Mohammad Shahab Sepehri",
        "Berk Tinaz",
        "Zalan Fabian",
        "Mahdi Soltanolkotabi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:54:37+00:00",
          "link": "https://arxiv.org/abs/2507.11932v1",
          "size": "2107kb",
          "version": "v1"
        }
      ],
      "title": "Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11932",
        "HTML": "https://arxiv.org/html/2507.11932v1",
        "PDF": "https://arxiv.org/pdf/2507.11932"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper explores reinforcement learning to improve visual simulation capabilities in MLLMs, which indirectly involves data processing. However, it focuses more on the evaluation of mental visualization capabilities than on RL data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11935",
      "abstract": "As the path toward 6G networks is being charted, the emerging applications have motivated evolutions of network architectures to realize the efficient, reliable, and flexible wireless networks. Among the potential architectures, the non-terrestrial network (NTN) and open radio access network (ORAN) have received increasing interest from both academia and industry. Although the deployment of NTNs ensures coverage, enhances spectral efficiency, and improves the resilience of wireless networks. The high altitude and mobility of NTN present new challenges in the development and operations (DevOps) lifecycle, hindering intelligent and scalable network management due to the lack of native artificial intelligence (AI) capability. With the advantages of ORAN in disaggregation, openness, virtualization, and intelligence, several works propose integrating ORAN principles into the NTN, focusing mainly on ORAN deployment options based on transparent and regenerative systems. However, a holistic view of how to effectively combine ORAN and NTN throughout the DevOps lifecycle is still missing, especially regarding how intelligent ORAN addresses the scalability challenges in NTN. Motivated by this, in this paper, we first provide the background knowledge about ORAN and NTN, outline the state-of-the-art research on ORAN for NTNs, and present the DevOps challenges that motivate the adoption of ORAN solutions. We then propose the ORAN-based NTN framework, discussing its features and architectures in detail. These include the discussion about flexible fronthaul split, RAN intelligent controllers (RICs) enhancement for distributed learning, scalable deployment architecture, and multi-domain service management. Finally, the future research directions, including combinations of the ORAN-based NTN framework and other enabling technologies and schemes, as well as the candidate use cases, are highlighted.",
      "authors": [
        "Jikang Deng",
        "Fizza Hassan",
        "Hui Zhou",
        "Saad Al-Ahmadi",
        "Mohamed-Slim Alouini",
        "Daniel B. Da Costa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:58:45+00:00",
          "link": "https://arxiv.org/abs/2507.11935v1",
          "size": "352kb",
          "version": "v1"
        }
      ],
      "title": "Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11935",
        "HTML": "https://arxiv.org/html/2507.11935v1",
        "PDF": "https://arxiv.org/pdf/2507.11935"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses AI-empowered scalable architectures in non-terrestrial networks, examining ORAN deployment challenges. It does not address reinforcement learning or data processing within an RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11936",
      "abstract": "Geometry problem solving is a key area of mathematical reasoning, which is widely involved in many important fields such as education, mathematical ability assessment of artificial intelligence, and multimodal ability assessment. In recent years, the rapid development of deep learning technology, especially the rise of multimodal large language models, has triggered a widespread research boom. This paper provides a survey of the applications of deep learning in geometry problem solving, including (i) a comprehensive summary of the relevant tasks in geometry problem solving; (ii) a thorough review of related deep learning methods; (iii) a detailed analysis of evaluation metrics and methods; and (iv) a critical discussion of the current challenges and future directions that can be explored. Our goal is to provide a comprehensive and practical reference of deep learning for geometry problem solving to promote further developments in this field. We create a continuously updated list of papers on GitHub: https://github.com/majianz/dl4gps.",
      "authors": [
        "Jianzhe Ma",
        "Wenxuan Wang",
        "Qin Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:03:08+00:00",
          "link": "https://arxiv.org/abs/2507.11936v1",
          "size": "342kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Deep Learning for Geometry Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11936",
        "HTML": "https://arxiv.org/html/2507.11936v1",
        "PDF": "https://arxiv.org/pdf/2507.11936"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is a survey of deep learning applications in geometry problem-solving, providing an overview and analysis of methods and challenges. It does not involve reinforcement learning or discuss data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11938",
      "abstract": "Grasping unknown objects from a single view has remained a challenging topic in robotics due to the uncertainty of partial observation. Recent advances in large-scale models have led to benchmark solutions such as GraspNet-1Billion. However, such learning-based approaches still face a critical limitation in performance robustness for their sensitivity to sensing noise and environmental changes. To address this bottleneck in achieving highly generalized grasping, we abandon the traditional learning framework and introduce a new perspective: similarity matching, where similar known objects are utilized to guide the grasping of unknown target objects. We newly propose a method that robustly achieves unknown-object grasping from a single viewpoint through three key steps: 1) Leverage the visual features of the observed object to perform similarity matching with an existing database containing various object models, identifying potential candidates with high similarity; 2) Use the candidate models with pre-existing grasping knowledge to plan imitative grasps for the unknown target object; 3) Optimize the grasp quality through a local fine-tuning process. To address the uncertainty caused by partial and noisy observation, we propose a multi-level similarity matching framework that integrates semantic, geometric, and dimensional features for comprehensive evaluation. Especially, we introduce a novel point cloud geometric descriptor, the C-FPFH descriptor, which facilitates accurate similarity assessment between partial point clouds of observed objects and complete point clouds of database models. In addition, we incorporate the use of large language models, introduce the semi-oriented bounding box, and develop a novel point cloud registration approach based on plane detection to enhance matching accuracy under single-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.",
      "authors": [
        "Hao Chen",
        "Takuya Kiyokawa",
        "Zhengtao Hu",
        "Weiwei Wan",
        "and Kensuke Harada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:07:57+00:00",
          "link": "https://arxiv.org/abs/2507.11938v1",
          "size": "7668kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11938",
        "HTML": "https://arxiv.org/html/2507.11938v1",
        "PDF": "https://arxiv.org/pdf/2507.11938"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel object grasping method in robotics, which involves similarity matching for object detection and grasp planning. It does not contribute to data processing in the context of reinforcement learning as described in the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11939",
      "abstract": "Charts are a universally adopted medium for interpreting and communicating data. However, existing chart understanding benchmarks are predominantly English-centric, limiting their accessibility and applicability to global audiences. In this paper, we present PolyChartQA, the first large-scale multilingual chart question answering benchmark covering 22,606 charts and 26,151 question-answering pairs across 10 diverse languages. PolyChartQA is built using a decoupled pipeline that separates chart data from rendering code, allowing multilingual charts to be flexibly generated by simply translating the data and reusing the code. We leverage state-of-the-art LLM-based translation and enforce rigorous quality control in the pipeline to ensure the linguistic and semantic consistency of the generated multilingual charts. PolyChartQA facilitates systematic evaluation of multilingual chart understanding. Experiments on both open- and closed-source large vision-language models reveal a significant performance gap between English and other languages, especially low-resource ones with non-Latin scripts. This benchmark lays a foundation for advancing globally inclusive vision-language models.",
      "authors": [
        "Yichen Xu",
        "Liangyu Chen",
        "Liang Zhang",
        "Wenxuan Wang",
        "Qin Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:09:02+00:00",
          "link": "https://arxiv.org/abs/2507.11939v1",
          "size": "4509kb",
          "version": "v1"
        }
      ],
      "title": "POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11939",
        "PDF": "https://arxiv.org/pdf/2507.11939"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a multilingual benchmark, PolyChartQA, for chart question answering but does not relate to data processing for reinforcement learning, focusing instead on chart data generation and translation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11940",
      "abstract": "Motion planning for autonomous vehicles (AVs) in dense traffic is challenging, often leading to overly conservative behavior and unmet planning objectives. This challenge stems from the AVs' limited ability to anticipate and respond to the interactive behavior of surrounding agents. Traditional decoupled prediction and planning pipelines rely on non-interactive predictions that overlook the fact that agents often adapt their behavior in response to the AV's actions. To address this, we propose Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which enables interactive trajectory planning by predicting how surrounding agents may react to each control sequence sampled by MPPI. To improve performance in structured lane environments, we introduce a spline-based prior for the MPPI sampling distribution, enabling efficient lane-changing behavior. We evaluate IANN-MPPI in a dense traffic merging scenario, demonstrating its ability to perform efficient merging maneuvers. Our project website is available at https://sites.google.com/berkeley.edu/iann-mppi",
      "authors": [
        "Kanghyun Ryu",
        "Minjun Sung",
        "Piyush Gupta",
        "Jovin D'sa",
        "Faizan M. Tariq",
        "David Isele",
        "Sangjae Bae"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.11940v1",
          "size": "484kb",
          "version": "v1"
        }
      ],
      "title": "IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11940",
        "HTML": "https://arxiv.org/html/2507.11940v1",
        "PDF": "https://arxiv.org/pdf/2507.11940"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the primary focus is on motion planning for autonomous vehicles through the IANN-MPPI approach, the paper mentions trajectory planning that could entail data collection and processing aspects indirectly related to reinforcement learning. However, this is not the core topic of the work."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11941",
      "abstract": "Tokenization is a critical preprocessing step in large language model pipelines, yet widely-used implementations remain CPU-bound and suboptimal for batch inference workflows on GPU. We present BlockBPE, a parallel GPU implementation of byte-pair encoding (BPE) that achieves near linear-time complexity under realistic assumptions and is optimized for high-throughput, batch inference. Unlike existing Rust-based tokenizers such as HuggingFace Tokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex pre-tokenization and exhibit $O(n \\log n)$ runtime-BlockBPE eliminates the Regex pre-tokenization which leads to small loss in generation quality, but enables highly parallelized token merges within thread blocks, reducing overall complexity to $O(nd)$ where $d \\ll n$. On high-batch inference workloads, BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over HuggingFace Tokenizers.",
      "authors": [
        "Amos You"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:12:41+00:00",
          "link": "https://arxiv.org/abs/2507.11941v1",
          "size": "153kb",
          "version": "v1"
        }
      ],
      "title": "BlockBPE: Parallel BPE Tokenization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11941",
        "HTML": "https://arxiv.org/html/2507.11941v1",
        "PDF": "https://arxiv.org/pdf/2507.11941"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents BlockBPE, a GPU implementation of tokenization for language models, which is not related to data processing specific to reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11942",
      "abstract": "Task-agnostic prompt compression leverages the redundancy in natural language to reduce computational overhead and enhance information density within prompts, especially in long-context scenarios. Existing methods predominantly rely on information entropy as the metric to compress lexical units, aiming to achieve minimal information loss. However, these approaches overlook two critical aspects: (i) the importance of attention-critical tokens at the algorithmic level, and (ii) shifts in information entropy during the compression process. Motivated by these challenges, we propose a dynamic attention-aware approach for task-agnostic prompt compression (DAC). This approach effectively integrates entropy and attention information, dynamically sensing entropy shifts during compression to achieve fine-grained prompt compression. Extensive experiments across various domains, including LongBench, GSM8K, and BBH, show that DAC consistently yields robust and substantial improvements across a diverse range of tasks and LLMs, offering compelling evidence of its efficacy.",
      "authors": [
        "Yi Zhao",
        "Zuchao Li",
        "Hai Zhao",
        "Baoyuan Qi",
        "Guoming Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:16:06+00:00",
          "link": "https://arxiv.org/abs/2507.11942v1",
          "size": "598kb",
          "version": "v1"
        }
      ],
      "title": "DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11942",
        "HTML": "https://arxiv.org/html/2507.11942v1",
        "PDF": "https://arxiv.org/pdf/2507.11942"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "DAC focuses on natural language prompt compression and attention mechanisms within the context of long-context scenarios in language models, without addressing data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11943",
      "abstract": "We propose a low-rank adaptation method for training privacy-preserving vision transformer (ViT) models that efficiently freezes pre-trained ViT model weights. In the proposed method, trainable rank decomposition matrices are injected into each layer of the ViT architecture, and moreover, the patch embedding layer is not frozen, unlike in the case of the conventional low-rank adaptation methods. The proposed method allows us not only to reduce the number of trainable parameters but to also maintain almost the same accuracy as that of full-time tuning.",
      "authors": [
        "Haiwei Lin",
        "Shoko Imaizumi",
        "and Hitoshi Kiya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:18:52+00:00",
          "link": "https://arxiv.org/abs/2507.11943v1",
          "size": "581kb",
          "version": "v1"
        }
      ],
      "title": "Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11943",
        "HTML": "https://arxiv.org/html/2507.11943v1",
        "PDF": "https://arxiv.org/pdf/2507.11943"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a low-rank adaptation method for fine-tuning vision transformers for privacy-preserving image classification, with no connection to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11944",
      "abstract": "Learning convolution kernels in operators from data arises in numerous applications and represents an ill-posed inverse problem of broad interest. With scant prior information, kernel methods offer a natural nonparametric approach with regularization. However, a major challenge is to select a proper reproducing kernel, especially as operators and data vary. We show that the input data and convolution operator themselves induce an automatic, data-adaptive RKHS (DA-RKHS), obviating manual kernel selection. In particular, when the observation data is discrete and finite, there is a finite set of automatic basis functions sufficient to represent the estimators in the DA-RKHS, including the minimal-norm least-squares, Tikhonov, and conjugate-gradient estimators. We develop both Tikhonov and scalable iterative and hybrid algorithms using the automatic basis functions. Numerical experiments on integral, nonlocal, and aggregation operators confirm that our automatic RKHS regularization consistently outperforms standard ridge regression and Gaussian process methods with preselected kernels.",
      "authors": [
        "Haibo Li",
        "Fei Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:19:13+00:00",
          "link": "https://arxiv.org/abs/2507.11944v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "Automatic reproducing kernel and regularization for learning convolution kernels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11944",
        "HTML": "https://arxiv.org/html/2507.11944v1",
        "PDF": "https://arxiv.org/pdf/2507.11944"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work proposes automatic kernel methods for learning convolution kernels, dealing with regularization and inverse problems, without any link to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11947",
      "abstract": "With recent advancements in text-to-image (T2I) models, effectively generating multiple instances within a single image prompt has become a crucial challenge. Existing methods, while successful in generating positions of individual instances, often struggle to account for relationship discrepancy and multiple attributes leakage. To address these limitations, this paper proposes the relation-aware disentangled learning (RaDL) framework. RaDL enhances instance-specific attributes through learnable parameters and generates relation-aware image features via Relation Attention, utilizing action verbs extracted from the global prompt. Through extensive evaluations on benchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that RaDL outperforms existing methods, showing significant improvements in positional accuracy, multiple attributes consideration, and the relationships between instances. Our results present RaDL as the solution for generating images that consider both the relationships and multiple attributes of each instance within the multi-instance image.",
      "authors": [
        "Geon Park",
        "Seon Bin Kim",
        "Gunho Jung",
        "and Seong-Whan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:28:20+00:00",
          "link": "https://arxiv.org/abs/2507.11947v1",
          "size": "3086kb",
          "version": "v1"
        }
      ],
      "title": "RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11947",
        "HTML": "https://arxiv.org/html/2507.11947v1",
        "PDF": "https://arxiv.org/pdf/2507.11947"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents the RaDL framework for multi-instance text-to-image generation, focusing on enhancing visual attributes using relational attention without any emphasis on reinforcement learning or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11948",
      "abstract": "Writing GPU kernels is a challenging task and critical for AI systems' efficiency. It is also highly iterative: domain experts write code and improve performance through execution feedback. Moreover, it presents verifiable rewards like correctness and speedup, making it a natural environment to apply Reinforcement Learning (RL). To explicitly incorporate the iterative nature of this process into training, we develop a flexible multi-turn RL recipe that addresses unique challenges encountered in real-world settings, such as learning from long trajectories and effective reward attribution across turns. We present Kevin - K(ernel D)evin, the first model trained with multi-turn RL for CUDA kernel generation and optimization. In our evaluation setup, Kevin shows significant gains over its base model (QwQ-32B), improving correctness of generated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to 1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini (0.78x). Finally, we study its behavior across test-time scaling axes: we found scaling serial refinement more beneficial than parallel sampling. In particular, when given more refinement turns, Kevin shows a higher rate of improvement.",
      "authors": [
        "Carlo Baronio",
        "Pietro Marsella",
        "Ben Pan",
        "Simon Guo",
        "Silas Alberti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:33:07+00:00",
          "link": "https://arxiv.org/abs/2507.11948v1",
          "size": "3122kb",
          "version": "v1"
        }
      ],
      "title": "Kevin: Multi-Turn RL for Generating CUDA Kernels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11948",
        "HTML": "https://arxiv.org/html/2507.11948v1",
        "PDF": "https://arxiv.org/pdf/2507.11948"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "Kevin, the paper's proposed system, uses multi-turn reinforcement learning for CUDA kernel generation. It specifically adapts the RL process to the task characteristics, indicating a significant contribution to data processing through iterative feedback and reward attribution in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11949",
      "abstract": "Enabling virtual humans to dynamically and realistically respond to diverse auditory stimuli remains a key challenge in character animation, demanding the integration of perceptual modeling and motion synthesis. Despite its significance, this task remains largely unexplored. Most previous works have primarily focused on mapping modalities like speech, audio, and music to generate human motion. As of yet, these models typically overlook the impact of spatial features encoded in spatial audio signals on human motion. To bridge this gap and enable high-quality modeling of human movements in response to spatial audio, we introduce the first comprehensive Spatial Audio-Driven Human Motion (SAM) dataset, which contains diverse and high-quality spatial audio and motion data. For benchmarking, we develop a simple yet effective diffusion-based generative framework for human MOtion generation driven by SPatial Audio, termed MOSPA, which faithfully captures the relationship between body motion and spatial audio through an effective fusion mechanism. Once trained, MOSPA could generate diverse realistic human motions conditioned on varying spatial audio inputs. We perform a thorough investigation of the proposed dataset and conduct extensive experiments for benchmarking, where our method achieves state-of-the-art performance on this task. Our model and dataset will be open-sourced upon acceptance. Please refer to our supplementary video for more details.",
      "authors": [
        "Shuyang Xu",
        "Zhiyang Dou",
        "Mingyi Shi",
        "Liang Pan",
        "Leo Ho",
        "Jingbo Wang",
        "Yuan Liu",
        "Cheng Lin",
        "Yuexin Ma",
        "Wenping Wang",
        "Taku Komura"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:33:11+00:00",
          "link": "https://arxiv.org/abs/2507.11949v1",
          "size": "31397kb",
          "version": "v1"
        }
      ],
      "title": "MOSPA: Human Motion Generation Driven by Spatial Audio",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11949",
        "HTML": "https://arxiv.org/html/2507.11949v1",
        "PDF": "https://arxiv.org/pdf/2507.11949"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper primarily discusses human motion generation driven by spatial audio without any notable focus on reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11953",
      "abstract": "LLMs encounter significant challenges in resource consumption nowadays, especially with long contexts. Despite extensive efforts dedicate to enhancing inference efficiency, these methods primarily exploit internal sparsity within the models, without leveraging external information for optimization. We identify the high similarity of attention matrices across different-scale LLMs, which offers a novel perspective for optimization. We first conduct a comprehensive analysis of how to measure similarity, how to select mapping Layers and whether mapping is consistency. Based on these insights, we introduce the IAM framework, which achieves dual benefits of accelerated attention computation and reduced KV cache usage by performing attention mapping between small and large LLMs. Our experimental results demonstrate that IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without appreciably sacrificing performance. Experiments on different series of models show the generalizability of IAM. Importantly, it is also orthogonal to many existing KV cache optimization methods, making it a versatile addition to the current toolkit for enhancing LLM efficiency.",
      "authors": [
        "Yi Zhao",
        "Zuchao Li",
        "Hai Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:39:11+00:00",
          "link": "https://arxiv.org/abs/2507.11953v1",
          "size": "674kb",
          "version": "v1"
        }
      ],
      "title": "IAM: Efficient Inference through Attention Mapping between Different-scale LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11953",
        "HTML": "https://arxiv.org/html/2507.11953v1",
        "PDF": "https://arxiv.org/pdf/2507.11953"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses efficiency in Large Language Models (LLMs) through attention mapping and does not relate to reinforcement learning or data processing in RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11954",
      "abstract": "Large language models excel in question-answering (QA) yet still struggle with multi-hop reasoning and temporal questions. Query-based knowledge graph QA (KGQA) offers a modular alternative by generating executable queries instead of direct answers. We explore multi-stage query-based framework for WikiData QA, proposing multi-stage approach that enhances performance on challenging multi-hop and temporal benchmarks. Through generalization and rejection studies, we evaluate robustness across multi-hop and temporal QA datasets. Additionally, we introduce a novel entity linking and predicate matching method using CoT reasoning. Our results demonstrate the potential of query-based multi-stage KGQA framework for improving multi-hop and temporal QA with small language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System",
      "authors": [
        "Artem Alekseev",
        "Mikhail Chaichuk",
        "Miron Butko",
        "Alexander Panchenko",
        "Elena Tutubalina",
        "Oleg Somov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:41:03+00:00",
          "link": "https://arxiv.org/abs/2507.11954v1",
          "size": "780kb",
          "version": "v1"
        }
      ],
      "title": "The benefits of query-based KGQA systems for complex and temporal questions in LLM era",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11954",
        "HTML": "https://arxiv.org/html/2507.11954v1",
        "PDF": "https://arxiv.org/pdf/2507.11954"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper centers around query-based knowledge graph question-answering systems and does not involve reinforcement learning or related data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11955",
      "abstract": "Generalizable semantic segmentation aims to perform well on unseen target domains, a critical challenge due to real-world applications requiring high generalizability. Class-wise prototypes, representing class centroids, serve as domain-invariant cues that benefit generalization due to their stability and semantic consistency. However, this approach faces three challenges. First, existing methods often adopt coarse prototypical alignment strategies, which may hinder performance. Second, naive prototypes computed by averaging source batch features are prone to overfitting and may be negatively affected by unrelated source data. Third, most methods treat all source samples equally, ignoring the fact that different features have varying adaptation difficulties. To address these limitations, we propose a novel framework for generalizable semantic segmentation: Prototypical Progressive Alignment and Reweighting (PPAR), leveraging the strong generalization ability of the CLIP model. Specifically, we define two prototypes: the Original Text Prototype (OTP) and Visual Text Prototype (VTP), generated via CLIP to serve as a solid base for alignment. We then introduce a progressive alignment strategy that aligns features in an easy-to-difficult manner, reducing domain gaps gradually. Furthermore, we propose a prototypical reweighting mechanism that estimates the reliability of source data and adjusts its contribution, mitigating the effect of irrelevant or harmful features (i.e., reducing negative transfer). We also provide a theoretical analysis showing the alignment between our method and domain generalization theory. Extensive experiments across multiple benchmarks demonstrate that PPAR achieves state-of-the-art performance, validating its effectiveness.",
      "authors": [
        "Yuhang Zhang",
        "Zhengyu Zhang",
        "Muxin Liao",
        "Shishun Tian",
        "Wenbin Zou",
        "Lu Zhang",
        "Chen Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:42:21+00:00",
          "link": "https://arxiv.org/abs/2507.11955v1",
          "size": "24376kb",
          "version": "v1"
        }
      ],
      "title": "Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11955",
        "HTML": "https://arxiv.org/html/2507.11955v1",
        "PDF": "https://arxiv.org/pdf/2507.11955"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research addresses semantic segmentation in computer vision and does not cover reinforcement learning or data processing for RL tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11959",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across various natural language processing (NLP) tasks. However, their deployment is challenging due to the substantial computational resources required. Power-of-two (PoT) quantization is a general tool to counteract this difficulty. Albeit previous works on PoT quantization can be efficiently dequantized on CPUs using fixed-point addition, it showed less effectiveness on GPUs. The reason is entanglement of the sign bit and sequential bit manipulations needed for dequantization. We propose a novel POT quantization framework for LLM weights that (i) outperforms state-of-the-art accuracy in extremely low-precision number formats, and (ii) enables faster inference through more efficient dequantization. To maintain the accuracy of the quantized model, we introduce a two-step post-training algorithm: (i) initialize the quantization scales with a robust starting point, and (ii) refine these scales using a minimal calibration set. The performance of our PoT post-training algorithm surpasses the current state-of-the-art in integer quantization, particularly at low precisions such as 2- and 3-bit formats. Our PoT quantization accelerates the dequantization step required for the floating point inference and leads to $3.67\\times$ speed up on a NVIDIA V100, and $1.63\\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.",
      "authors": [
        "Xinyu Wang",
        "Vahid Partovi Nia",
        "Peng Lu",
        "Jerry Huang",
        "Xiao-Wen Chang",
        "Boxing Chen and Yufei Cui"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:44:14+00:00",
          "link": "https://arxiv.org/abs/2507.11959v1",
          "size": "1741kb",
          "version": "v1"
        }
      ],
      "title": "PoTPTQ: A Two-step Power-of-Two Post-training for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11959",
        "HTML": "https://arxiv.org/html/2507.11959v1",
        "PDF": "https://arxiv.org/pdf/2507.11959"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on Power-of-Two quantization for efficient inference in large language models, without any connection to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11960",
      "abstract": "Approaches to enhancing data quality (DQ) are classified into two main categories: data- and process-driven. However, prior research has predominantly utilized batch data preprocessing within the data-driven framework, which often proves insufficient for optimizing machine learning (ML) model performance and frequently leads to distortions in data characteristics. Existing studies have primarily focused on data preprocessing rather than genuine data quality improvement (DQI). In this paper, we introduce d-DQIVAR, a novel visual analytics system designed to facilitate DQI strategies aimed at improving ML model performance. Our system integrates visual analytics techniques that leverage both data-driven and process-driven approaches. Data-driven techniques tackle DQ issues such as imputation, outlier detection, deletion, format standardization, removal of duplicate records, and feature selection. Process-driven strategies encompass evaluating DQ and DQI procedures by considering DQ dimensions and ML model performance and applying the Kolmogorov-Smirnov test. We illustrate how our system empowers users to harness expert and domain knowledge effectively within a practical workflow through case studies, evaluations, and user studies.",
      "authors": [
        "Hyein Hong",
        "Sangbong Yoo",
        "SeokHwan Choi",
        "Jisue Kim",
        "Seongbum Seo",
        "Haneol Cho",
        "Chansoo Kim",
        "and Yun Jang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:45:08+00:00",
          "link": "https://arxiv.org/abs/2507.11960v1",
          "size": "11470kb",
          "version": "v1"
        }
      ],
      "title": "d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11960",
        "HTML": "https://arxiv.org/html/2507.11960v1",
        "PDF": "https://arxiv.org/pdf/2507.11960"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on data quality improvement using visual analytics for general machine learning, not specifically targeting data processing within the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11961",
      "abstract": "Fuzzy logic programming is an established approach for reasoning under uncertainty. Several semantics from classical, two-valued logic programming have been generalized to the case of fuzzy logic programs. In this paper, we show that two of the most prominent classical semantics, namely the stable model and the well-founded semantics, can be reconstructed within the general framework of approximation fixpoint theory (AFT). This not only widens the scope of AFT from two- to many-valued logics, but allows a wide range of existing AFT results to be applied to fuzzy logic programming. As first examples of such applications, we clarify the formal relationship between existing semantics, generalize the notion of stratification from classical to fuzzy logic programs, and devise \"more precise\" variants of the semantics.",
      "authors": [
        "Pascal Kettmann",
        "Jesse Heyninck",
        "Hannes Strass"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:48:32+00:00",
          "link": "https://arxiv.org/abs/2507.11961v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "Approximation Fixpoint Theory as a Unifying Framework for Fuzzy Logic Programming Semantics (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11961",
        "HTML": "https://arxiv.org/html/2507.11961v1",
        "PDF": "https://arxiv.org/pdf/2507.11961"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is about fuzzy logic programming and not related to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11962",
      "abstract": "Training deep neural networks for scientific computing remains computationally expensive due to the slow formation of diverse feature representations in early training stages. Recent studies identify a staircase phenomenon in training dynamics, where loss decreases are closely correlated with increases in $\\varepsilon$-rank, reflecting the effective number of linearly independent neuron functions. Motivated by this observation, this work proposes a structured first-layer initialization (SFLI) pre-training method to enhance the diversity of neural features at initialization by constructing $\\varepsilon$-linearly independent neurons in the input layer. We present systematic initialization schemes compatible with various activation functions and integrate the strategy into multiple neural architectures, including modified multi-layer perceptrons and physics-informed residual adaptive networks. Extensive numerical experiments on function approximation and PDE benchmarks, demonstrate that SFLI significantly improves the initial $\\varepsilon$-rank, accelerates convergence, mitigates spectral bias, and enhances prediction accuracy. With the help of SILP, we only need to add one line of code to conventional existing algorithms.",
      "authors": [
        "Tao Tang",
        "Jiang Yang",
        "Yuxiang Zhao",
        "Quanhui Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:52:59+00:00",
          "link": "https://arxiv.org/abs/2507.11962v1",
          "size": "6276kb",
          "version": "v1"
        }
      ],
      "title": "Structured First-Layer Initialization Pre-Training Techniques to Accelerate Training Process Based on $\\varepsilon$-Rank",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11962",
        "HTML": "https://arxiv.org/html/2507.11962v1",
        "PDF": "https://arxiv.org/pdf/2507.11962"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus is on pre-training techniques for deep neural networks in scientific computing, with no mention of reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11966",
      "abstract": "As online communication increasingly incorporates under-represented languages and colloquial dialects, standard translation systems often fail to preserve local slang, code-mixing, and culturally embedded markers of harmful speech. Translating toxic content between low-resource language pairs poses additional challenges due to scarce parallel data and safety filters that sanitize offensive expressions. In this work, we propose a reproducible, two-stage framework for toxicity-preserving translation, demonstrated on a code-mixed Singlish safety corpus. First, we perform human-verified few-shot prompt engineering: we iteratively curate and rank annotator-selected Singlish-target examples to capture nuanced slang, tone, and toxicity. Second, we optimize model-prompt pairs by benchmarking several large language models using semantic similarity via direct and back-translation. Quantitative human evaluation confirms the effectiveness and efficiency of our pipeline. Beyond improving translation quality, our framework contributes to the safety of multicultural LLMs by supporting culturally sensitive moderation and benchmarking in low-resource contexts. By positioning Singlish as a testbed for inclusive NLP, we underscore the importance of preserving sociolinguistic nuance in real-world applications such as content moderation and regional platform governance.",
      "authors": [
        "Ziyu Ge",
        "Gabriel Chua",
        "Leanne Tan",
        "Roy Ka-Wei Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:58:02+00:00",
          "link": "https://arxiv.org/abs/2507.11966v1",
          "size": "639kb",
          "version": "v1"
        }
      ],
      "title": "Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11966",
        "PDF": "https://arxiv.org/pdf/2507.11966"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with translation systems in low-resource languages and content moderation without reference to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11967",
      "abstract": "In this paper, we propose Language-Guided Contrastive Audio-Visual Masked Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning. LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual masked autoencoders, enabling the model to learn across audio, visual and text modalities. To train LG-CAV-MAE, we introduce an automatic method to generate audio-visual-text triplets from unlabeled videos. We first generate frame-level captions using an image captioning model and then apply CLAP-based filtering to ensure strong alignment between audio and captions. This approach yields high-quality audio-visual-text triplets without requiring manual annotations. We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an audio-visual classification task. Our method significantly outperforms existing approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks and a 3.2% improvement for the classification task.",
      "authors": [
        "Yuchi Ishikawa",
        "Shota Nakada",
        "Hokuto Munakata",
        "Kazuhiro Saito",
        "Tatsuya Komatsu",
        "Yoshimitsu Aoki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Audio and Speech Processing (eess.AS)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:58:14+00:00",
          "link": "https://arxiv.org/abs/2507.11967v1",
          "size": "618kb",
          "version": "v1"
        }
      ],
      "title": "Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11967",
        "HTML": "https://arxiv.org/html/2507.11967v1",
        "PDF": "https://arxiv.org/pdf/2507.11967"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for audio-visual representation learning using autoencoders, which does not address reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11968",
      "abstract": "Multimodal Large Language Models (MLLMs) are increasingly used for content moderation, yet their robustness in short-form video contexts remains underexplored. Current safety evaluations often rely on unimodal attacks, failing to address combined attack vulnerabilities. In this paper, we introduce a comprehensive framework for evaluating the tri-modal safety of MLLMs. First, we present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising diverse short-form videos with human-guided synthetic adversarial attacks. Second, we propose ChimeraBreak, a novel tri-modal attack strategy that simultaneously challenges visual, auditory, and semantic reasoning pathways. Extensive experiments on state-of-the-art MLLMs reveal significant vulnerabilities with high Attack Success Rates (ASR). Our findings uncover distinct failure modes, showing model biases toward misclassifying benign or policy-violating content. We assess results using LLM-as-a-judge, demonstrating attack reasoning efficacy. Our dataset and findings provide crucial insights for developing more robust and safe MLLMs.",
      "authors": [
        "Sahid Hossain Mustakim",
        "S M Jishanul Islam",
        "Ummay Maria Muna",
        "Montasir Chowdhury",
        "Mohammed Jawwadul Islam",
        "Sadia Ahmmed",
        "Tashfia Sikder",
        "Syed Tasdid Azam Dhrubo and Swakkhar Shatabda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:02:15+00:00",
          "link": "https://arxiv.org/abs/2507.11968v1",
          "size": "10563kb",
          "version": "v1"
        }
      ],
      "title": "Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11968",
        "HTML": "https://arxiv.org/html/2507.11968v1",
        "PDF": "https://arxiv.org/pdf/2507.11968"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on tri-modal adversarial attacks for evaluating content moderation in multimodal LLMs, which does not address data processing within the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11969",
      "abstract": "Recent advances in test-time adaptation (TTA) for Vision-Language Models (VLMs) have garnered increasing attention, particularly through the use of multiple augmented views of a single image to boost zero-shot generalization. Unfortunately, existing methods fail to strike a satisfactory balance between performance and efficiency, either due to excessive overhead of tuning text prompts or unstable benefits from handcrafted, training-free visual feature enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias), an efficient and effective TTA paradigm that incorporates two learnable biases during TTA, unfolded as the global bias and spatial bias. Particularly, the global bias captures the global semantic features of a test image by learning consistency across augmented views, while spatial bias learns the semantic coherence between regions in the image's spatial visual representation. It is worth highlighting that these two sets of biases are directly added to the logits outputed by the pretrained VLMs, which circumvent the full backpropagation through VLM that hinders the efficiency of existing TTA methods. This endows GS-Bias with extremely high efficiency while achieving state-of-the-art performance on 15 benchmark datasets. For example, it achieves a 2.23% improvement over TPT in cross-dataset generalization and a 2.72% improvement in domain generalization, while requiring only 6.5% of TPT's memory usage on ImageNet.",
      "authors": [
        "Zhaohong Huang",
        "Yuxin Zhang",
        "Jingjing Xie",
        "Fei Chao",
        "Rongrong Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.11969v1",
          "size": "2621kb",
          "version": "v1"
        }
      ],
      "title": "GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11969",
        "HTML": "https://arxiv.org/html/2507.11969v1",
        "PDF": "https://arxiv.org/pdf/2507.11969"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a test-time adaptation method for vision-language models, emphasizing efficiency and generalization, without application to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11971",
      "abstract": "Current 3D representations like meshes, voxels, point clouds, and NeRF-based neural implicit fields exhibit significant limitations: they are often task-specific, lacking universal applicability across reconstruction, generation, editing, and driving. While meshes offer high precision, their dense vertex data complicates editing; NeRFs deliver excellent rendering but suffer from structural ambiguity, hindering animation and manipulation; all representations inherently struggle with the trade-off between data complexity and fidelity. To overcome these issues, we introduce a novel 3D Hierarchical Proxy Node representation. Its core innovation lies in representing an object's shape and texture via a sparse set of hierarchically organized (tree-structured) proxy nodes distributed on its surface and interior. Each node stores local shape and texture information (implicitly encoded by a small MLP) within its neighborhood. Querying any 3D coordinate's properties involves efficient neural interpolation and lightweight decoding from relevant nearby and parent nodes. This framework yields a highly compact representation where nodes align with local semantics, enabling direct drag-and-edit manipulation, and offers scalable quality-complexity control. Extensive experiments across 3D reconstruction and editing demonstrate our method's expressive efficiency, high-fidelity rendering quality, and superior editability.",
      "authors": [
        "Tielong Wang",
        "Yuxuan Xiong",
        "Jinfan Liu",
        "Zhifan Zhang",
        "Ye Chen",
        "Yue Shi",
        "Bingbing Ni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:09:05+00:00",
          "link": "https://arxiv.org/abs/2507.11971v1",
          "size": "749kb",
          "version": "v1"
        }
      ],
      "title": "HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11971",
        "HTML": "https://arxiv.org/html/2507.11971v1",
        "PDF": "https://arxiv.org/pdf/2507.11971"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a new 3D hierarchical proxy representation for improved 3D reconstruction and editing, lacking any discussion on data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11972",
      "abstract": "Reading comprehension is a fundamental skill in human cognitive development. With the advancement of Large Language Models (LLMs), there is a growing need to compare how humans and LLMs understand language across different contexts and apply this understanding to functional tasks such as inference, emotion interpretation, and information retrieval. Our previous work used LLMs and human biomarkers to study the reading comprehension process. The results showed that the biomarkers corresponding to words with high and low relevance to the inference target, as labeled by the LLMs, exhibited distinct patterns, particularly when validated using eye-tracking data. However, focusing solely on individual words limited the depth of understanding, which made the conclusions somewhat simplistic despite their potential significance. This study used an LLM-based AI agent to group words from a reading passage into nodes and edges, forming a graph-based text representation based on semantic meaning and question-oriented prompts. We then compare the distribution of eye fixations on important nodes and edges. Our findings indicate that LLMs exhibit high consistency in language understanding at the level of graph topological structure. These results build on our previous findings and offer insights into effective human-AI co-learning strategies.",
      "authors": [
        "Yuhong Zhang",
        "Jialu Li",
        "Shilai Yang",
        "Yuchen Xu",
        "Gert Cauwenberghs",
        "Tzyy-Ping Jung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:15:59+00:00",
          "link": "https://arxiv.org/abs/2507.11972v1",
          "size": "3361kb",
          "version": "v1"
        }
      ],
      "title": "Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11972",
        "HTML": "https://arxiv.org/html/2507.11972v1",
        "PDF": "https://arxiv.org/pdf/2507.11972"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research analyzes reading comprehension using graph representations and eye-tracking data, which does not relate to data processing in reinforcement learning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11974",
      "abstract": "Generative Artificial Intelligence (GAI) has rapidly emerged as a transformative force in aquaculture, enabling intelligent synthesis of multimodal data, including text, images, audio, and simulation outputs for smarter, more adaptive decision-making. As the aquaculture industry shifts toward data-driven, automation and digital integration operations under the Aquaculture 4.0 paradigm, GAI models offer novel opportunities across environmental monitoring, robotics, disease diagnostics, infrastructure planning, reporting, and market analysis. This review presents the first comprehensive synthesis of GAI applications in aquaculture, encompassing foundational architectures (e.g., diffusion models, transformers, and retrieval augmented generation), experimental systems, pilot deployments, and real-world use cases. We highlight GAI's growing role in enabling underwater perception, digital twin modeling, and autonomous planning for remotely operated vehicle (ROV) missions. We also provide an updated application taxonomy that spans sensing, control, optimization, communication, and regulatory compliance. Beyond technical capabilities, we analyze key limitations, including limited data availability, real-time performance constraints, trust and explainability, environmental costs, and regulatory uncertainty. This review positions GAI not merely as a tool but as a critical enabler of smart, resilient, and environmentally aligned aquaculture systems.",
      "authors": [
        "Waseem Akram",
        "Muhayy Ud Din",
        "Lyes Saad Soud",
        "Irfan Hussain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:16:51+00:00",
          "link": "https://arxiv.org/abs/2507.11974v1",
          "size": "28510kb",
          "version": "v1"
        }
      ],
      "title": "A Review of Generative AI in Aquaculture: Foundations, Applications, and Future Directions for Smart and Sustainable Farming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11974",
        "HTML": "https://arxiv.org/html/2507.11974v1",
        "PDF": "https://arxiv.org/pdf/2507.11974"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses generative AI applications in aquaculture and does not relate to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11975",
      "abstract": "Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms has been shown to enhance performance when feature extraction networks are used but the gained performance comes at the significant expense of increased computational and memory complexity. Neural network pruning methods have successfully addressed this challenge in supervised learning. However, their application to RL is underexplored. We propose an approach to integrate simultaneous training and pruning within advanced RL methods, in particular to RL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our networks (XiNet) are trained to solve stochastic optimization problems over the RL networks' weights and the parameters of variational Bernoulli distributions for 0/1 Random Variables $\\xi$ scaling each unit in the networks. The stochastic problem formulation induces regularization terms that promote convergence of the variational parameters to 0 when a unit contributes little to the performance. In this case, the corresponding structure is rendered permanently inactive and pruned from its network. We propose a cost-aware, sparsity-promoting regularization scheme, tailored to the DenseNet architecture of OFENets expressing the parameter complexity of involved networks in terms of the parameters of the RVs in these networks. Then, when matching this cost with the regularization terms, the many hyperparameters associated with them are automatically selected, effectively combining the RL objectives and network compression. We evaluate our method on continuous control benchmarks (MuJoCo) and the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned considerably with minimal loss in performance. Furthermore, our results confirm that pruning large networks during training produces more efficient and higher performing RL agents rather than training smaller networks from scratch.",
      "authors": [
        "Valentin Frank Ingmar Guenter and Athanasios Sideris"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:17:41+00:00",
          "link": "https://arxiv.org/abs/2507.11975v1",
          "size": "296kb",
          "version": "v1"
        }
      ],
      "title": "Online Training and Pruning of Deep Reinforcement Learning Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11975",
        "HTML": "https://arxiv.org/html/2507.11975v1",
        "PDF": "https://arxiv.org/pdf/2507.11975"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper addresses the integration of pruning with training in RL algorithms, specifically through methods that influence the data processing pipeline by regularizing and reducing network complexity during training, directly impacting how data is processed and utilized in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11976",
      "abstract": "Conformance checking is a sub-discipline of process mining, which compares observed process traces with a process model to analyze whether the process execution conforms with or deviates from the process design. Organizations can leverage this analysis, for example to check whether their processes comply with internal or external regulations or to identify potential improvements. Gaining these insights requires suitable visualizations, which make complex results accessible and actionable. So far, however, the development of conformance checking visualizations has largely been left to tool vendors. As a result, current tools offer a wide variety of visual representations for conformance checking, but the analytical purposes they serve often remain unclear. However, without a systematic understanding of these purposes, it is difficult to evaluate the visualizations' usefulness. Such an evaluation hence requires a deeper understanding of conformance checking as an analysis domain. To this end, we propose a task taxonomy, which categorizes the tasks that can occur when conducting conformance checking analyses. This taxonomy supports researchers in determining the purpose of visualizations, specifying relevant conformance checking tasks in terms of their goal, means, constraint type, data characteristics, data target, and data cardinality. Combining concepts from process mining and visual analytics, we address researchers from both disciplines to enable and support closer collaborations.",
      "authors": [
        "Jana-Rebecca Rehse",
        "Michael Grohs",
        "Finn Klessascheck",
        "Lisa-Marie Klein",
        "Tatiana von Landesberger",
        "Luise Pufahl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:18:29+00:00",
          "link": "https://arxiv.org/abs/2507.11976v1",
          "size": "2231kb",
          "version": "v1"
        }
      ],
      "title": "A Task Taxonomy for Conformance Checking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11976",
        "HTML": "https://arxiv.org/html/2507.11976v1",
        "PDF": "https://arxiv.org/pdf/2507.11976"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on conformance checking in process mining and does not involve reinforcement learning or relevant data processing aspects therein."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11978",
      "abstract": "The emergence of deep learning domain-specific languages (DSLs) has substantially reduced the obstacles in developing high-performance, cross-platform compute kernels. However, current DSLs, such as Triton, still demand that developers possess expertise in parallel programming and expose them to many low-level details. This requirement complicates the development process and adds to the difficulty of maintaining compute kernels. Consequently, developing a new programming model that supports serial programming for deep learning workloads is crucial.\n  This paper introduces NineToothed, a domain-specific language that offers serial semantics for machine learning programming. Through the automatic transformation of serial code into parallel code, NineToothed significantly streamlines the development process while causing minimal performance degradation. NineToothed encompasses (1) a language with tensor-oriented metaprogramming (TOM) that adopts the arrange-and-apply paradigm, enabling the expression of tiled computations without the need to manage low-level details and (2) a code generator for generating high-performance parallel code. Our evaluation results indicate that NineToothed can greatly simplify compute kernel development while maintaining performance comparable to that of Triton.",
      "authors": [
        "Jiacheng Huang",
        "Zimin Li",
        "Yinghui Li",
        "Haojie Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:20:06+00:00",
          "link": "https://arxiv.org/abs/2507.11978v1",
          "size": "381kb",
          "version": "v1"
        }
      ],
      "title": "NineToothed: A Triton-Based High-Level Domain-Specific Language for Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11978",
        "PDF": "https://arxiv.org/pdf/2507.11978"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a domain-specific language for machine learning but does not provide contributions to data processing within the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11979",
      "abstract": "Large language models (LLMs) have emerged as powerful tools for simulating complex social phenomena using human-like agents with specific traits. In human societies, value similarity is important for building trust and close relationships; however, it remains unexplored whether this principle holds true in artificial societies comprising LLM agents. Therefore, this study investigates the influence of value similarity on relationship-building among LLM agents through two experiments. First, in a preliminary experiment, we evaluated the controllability of values in LLMs to identify the most effective model and prompt design for controlling the values. Subsequently, in the main experiment, we generated pairs of LLM agents imbued with specific values and analyzed their mutual evaluations of trust and interpersonal closeness following a dialogue. The experiments were conducted in English and Japanese to investigate language dependence. The results confirmed that pairs of agents with higher value similarity exhibited greater mutual trust and interpersonal closeness. Our findings demonstrate that the LLM agent simulation serves as a valid testbed for social science theories, contributes to elucidating the mechanisms by which values influence relationship building, and provides a foundation for inspiring new theories and insights into the social sciences.",
      "authors": [
        "Yuki Sakamoto",
        "Takahisa Uchida",
        "Hiroshi Ishiguro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:21:59+00:00",
          "link": "https://arxiv.org/abs/2507.11979v1",
          "size": "341kb",
          "version": "v1"
        }
      ],
      "title": "Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11979",
        "HTML": "https://arxiv.org/html/2507.11979v1",
        "PDF": "https://arxiv.org/pdf/2507.11979"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses simulating social phenomena using LLM agents, focusing on trust and interpersonal closeness, without addressing any data processing in reinforcement learning such as data collection, preprocessing, or dataset curation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11980",
      "abstract": "Diffusion Models have shown remarkable proficiency in image and video synthesis. As model size and latency increase limit user experience, hybrid edge-cloud collaborative framework was recently proposed to realize fast inference and high-quality generation, where the cloud model initiates high-quality semantic planning and the edge model expedites later-stage refinement. However, excessive cloud denoising prolongs inference time, while insufficient steps cause semantic ambiguity, leading to inconsistency in edge model output. To address these challenges, we propose EC-Diff that accelerates cloud inference through gradient-based noise estimation while identifying the optimal point for cloud-edge handoff to maintain generation quality. Specifically, we design a K-step noise approximation strategy to reduce cloud inference frequency by using noise gradients between steps and applying cloud inference periodically to adjust errors. Then we design a two-stage greedy search algorithm to efficiently find the optimal parameters for noise approximation and edge model switching. Extensive experiments demonstrate that our method significantly enhances generation quality compared to edge inference, while achieving up to an average $2\\times$ speedup in inference compared to cloud inference. Video samples and source code are available at https://ec-diff.github.io/.",
      "authors": [
        "Jiajian Xie",
        "Shengyu Zhang",
        "Zhou Zhao",
        "Fan Wu",
        "Fei Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:23:14+00:00",
          "link": "https://arxiv.org/abs/2507.11980v1",
          "size": "9022kb",
          "version": "v1"
        }
      ],
      "title": "EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11980",
        "HTML": "https://arxiv.org/html/2507.11980v1",
        "PDF": "https://arxiv.org/pdf/2507.11980"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel edge-cloud collaborative inference framework for diffusion models, with an emphasis on improving inference speed and output quality, without covering any topics related to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11981",
      "abstract": "Large Language Models (LLMs) can provide accurate word definitions and explanations for any context. However, the scope of the definition changes for different target groups, like children or language learners. This is especially relevant for homonyms, words with multiple meanings, where oversimplification might risk information loss by omitting key senses, potentially misleading users who trust LLM outputs. We investigate how simplification impacts homonym definition quality across three target groups: Normal, Simple, and ELI5. Using two novel evaluation datasets spanning multiple languages, we test DeepSeek v3, Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge and human annotations. Our results show that simplification drastically degrades definition completeness by neglecting polysemy, increasing the risk of misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization substantially improves homonym response quality across all prompt types. These findings highlight the need to balance simplicity and completeness in educational NLP to ensure reliable, context-aware definitions for all learners.",
      "authors": [
        "Lukas Ellinger",
        "Miriam Ansch\\\"utz",
        "Georg Groh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:25:27+00:00",
          "link": "https://arxiv.org/abs/2507.11981v1",
          "size": "333kb",
          "version": "v1"
        }
      ],
      "title": "Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11981",
        "HTML": "https://arxiv.org/html/2507.11981v1",
        "PDF": "https://arxiv.org/pdf/2507.11981"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper investigates the impact of language simplification on word sense awareness in LLMs, focusing on educational NLP applications, but does not address data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11984",
      "abstract": "Selecting the appropriate dimensionality reduction (DR) technique and determining its optimal hyperparameter settings that maximize the accuracy of the output projections typically involves extensive trial and error, often resulting in unnecessary computational overhead. To address this challenge, we propose a dataset-adaptive approach to DR optimization guided by structural complexity metrics. These metrics quantify the intrinsic complexity of a dataset, predicting whether higher-dimensional spaces are necessary to represent it accurately. Since complex datasets are often inaccurately represented in two-dimensional projections, leveraging these metrics enables us to predict the maximum achievable accuracy of DR techniques for a given dataset, eliminating redundant trials in optimizing DR. We introduce the design and theoretical foundations of these structural complexity metrics. We quantitatively verify that our metrics effectively approximate the ground truth complexity of datasets and confirm their suitability for guiding dataset-adaptive DR workflow. Finally, we empirically show that our dataset-adaptive workflow significantly enhances the efficiency of DR optimization without compromising accuracy.",
      "authors": [
        "Hyeon Jeon",
        "Jeongin Park",
        "Soohyun Lee",
        "Dae Hyun Kim",
        "Sungbok Shin",
        "Jinwook Seo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:32:08+00:00",
          "link": "https://arxiv.org/abs/2507.11984v1",
          "size": "1564kb",
          "version": "v1"
        }
      ],
      "title": "Dataset-Adaptive Dimensionality Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11984",
        "HTML": "https://arxiv.org/html/2507.11984v1",
        "PDF": "https://arxiv.org/pdf/2507.11984"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper proposes a dataset-adaptive dimensionality reduction technique, focused on optimizing dimensionality reduction processes using complexity metrics, without any relation to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11985",
      "abstract": "Part-level features are crucial for image understanding, but few studies focus on them because of the lack of fine-grained labels. Although unsupervised part discovery can eliminate the reliance on labels, most of them cannot maintain robustness across various categories and scenarios, which restricts their application range. To overcome this limitation, we present a more effective paradigm for unsupervised part discovery, named Masked Part Autoencoder (MPAE). It first learns part descriptors as well as a feature map from the inputs and produces patch features from a masked version of the original images. Then, the masked regions are filled with the learned part descriptors based on the similarity between the local features and descriptors. By restoring these masked patches using the part descriptors, they become better aligned with their part shapes, guided by appearance features from unmasked patches. Finally, MPAE robustly discovers meaningful parts that closely match the actual object shapes, even in complex scenarios. Moreover, several looser yet more effective constraints are proposed to enable MPAE to identify the presence of parts across various scenarios and categories in an unsupervised manner. This provides the foundation for addressing challenges posed by occlusion and for exploring part similarity across multiple categories. Extensive experiments demonstrate that our method robustly discovers meaningful parts across various categories and scenarios. The code is available at the project https://github.com/Jiahao-UTS/MPAE.",
      "authors": [
        "Jiahao Xia",
        "Yike Wu",
        "Wenjian Huang",
        "Jianguo Zhang",
        "Jian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:33:14+00:00",
          "link": "https://arxiv.org/abs/2507.11985v1",
          "size": "13608kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11985",
        "HTML": "https://arxiv.org/html/2507.11985v1",
        "PDF": "https://arxiv.org/pdf/2507.11985"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work presents a method for unsupervised part discovery in images via masked image restoration, but it does not discuss data processing within the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11986",
      "abstract": "Diffusion-based text-to-image models have achieved remarkable results in synthesizing diverse images from text prompts and can capture specific artistic styles via style personalization. However, their entangled latent space and lack of smooth interpolation make it difficult to apply distinct painting techniques in a controlled, regional manner, often causing one style to dominate. To overcome this, we propose a zero-shot diffusion pipeline that naturally blends multiple styles by performing style composition on the denoised latents predicted during the flow-matching denoising process of separately trained, style-specialized models. We leverage the fact that lower-noise latents carry stronger stylistic information and fuse them across heterogeneous diffusion pipelines using spatial masks, enabling precise, region-specific style control. This mechanism preserves the fidelity of each individual style while allowing user-guided mixing. Furthermore, to ensure structural coherence across different models, we incorporate depth-map conditioning via ControlNet into the diffusion framework. Qualitative and quantitative experiments demonstrate that our method successfully achieves region-specific style mixing according to the given masks.",
      "authors": [
        "Jaehyun Lee",
        "Wonhark Park",
        "Wonsik Shin",
        "Hyunho Lee",
        "Hyoung Min Na",
        "Nojun Kwak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:36:07+00:00",
          "link": "https://arxiv.org/abs/2507.11986v1",
          "size": "17041kb",
          "version": "v1"
        }
      ],
      "title": "Style Composition within Distinct LoRA modules for Traditional Art",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11986",
        "HTML": "https://arxiv.org/html/2507.11986v1",
        "PDF": "https://arxiv.org/pdf/2507.11986"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a diffusion-based text-to-image model focusing on artistic style synthesis and control, without any mention of reinforcement learning or data processing in RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11987",
      "abstract": "Neural certificates have emerged as a powerful tool in cyber-physical systems control, providing witnesses of correctness. These certificates, such as barrier functions, often learned alongside control policies, once verified, serve as mathematical proofs of system safety. However, traditional formal verification of their defining conditions typically faces scalability challenges due to exhaustive state-space exploration. To address this challenge, we propose a lightweight runtime monitoring framework that integrates real-time verification and does not require access to the underlying control policy. Our monitor observes the system during deployment and performs on-the-fly verification of the certificate over a lookahead region to ensure safety within a finite prediction horizon. We instantiate this framework for ReLU-based control barrier functions and demonstrate its practical effectiveness in a case study. Our approach enables timely detection of safety violations and incorrect certificates with minimal overhead, providing an effective but lightweight alternative to the static verification of the certificates.",
      "authors": [
        "Thomas A. Henzinger",
        "Konstantin Kueffner",
        "Emily Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:37:23+00:00",
          "link": "https://arxiv.org/abs/2507.11987v1",
          "size": "241kb",
          "version": "v1"
        }
      ],
      "title": "Formal Verification of Neural Certificates Done Dynamically",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11987",
        "HTML": "https://arxiv.org/html/2507.11987v1",
        "PDF": "https://arxiv.org/pdf/2507.11987"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses neural certificates and formal verification within the control systems domain, with no direct connection to reinforcement learning or RL-specific data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11988",
      "abstract": "Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are emerging as a powerful paradigm for solving complex, multifaceted problems. However, the potential of these systems is often constrained by the prevalent plan-and-execute framework, which suffers from critical limitations: rigid plan execution, static agent capabilities, and inefficient communication. These weaknesses hinder their adaptability and robustness in dynamic environments. This paper introduces Aime, a novel multi-agent framework designed to overcome these challenges through dynamic, reactive planning and execution. Aime replaces the conventional static workflow with a fluid and adaptive architecture. Its core innovations include: (1) a Dynamic Planner that continuously refines the overall strategy based on real-time execution feedback; (2) an Actor Factory that implements Dynamic Actor instantiation, assembling specialized agents on-demand with tailored tools and knowledge; and (3) a centralized Progress Management Module that serves as a single source of truth for coherent, system-wide state awareness. We empirically evaluated Aime on a diverse suite of benchmarks spanning general reasoning (GAIA), software engineering (SWE-bench Verified), and live web navigation (WebVoyager). The results demonstrate that Aime consistently outperforms even highly specialized state-of-the-art agents in their respective domains. Its superior adaptability and task success rate establish Aime as a more resilient and effective foundation for multi-agent collaboration.",
      "authors": [
        "Yexuan Shi",
        "Mingyu Wang",
        "Yunxiang Cao",
        "Hongjie Lai",
        "Junjian Lan",
        "Xin Han",
        "Yu Wang",
        "Jie Geng",
        "Zhenan Li",
        "Zihao Xia",
        "Xiang Chen",
        "Chen Li",
        "Jian Xu",
        "Wenbo Duan",
        "Yuanshuo Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:38:28+00:00",
          "link": "https://arxiv.org/abs/2507.11988v1",
          "size": "329kb",
          "version": "v1"
        }
      ],
      "title": "Aime: Towards Fully-Autonomous Multi-Agent Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11988",
        "HTML": "https://arxiv.org/html/2507.11988v1",
        "PDF": "https://arxiv.org/pdf/2507.11988"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a multi-agent framework for LLMs named Aime, focusing on dynamic planning and execution, without discussing data processing aspects related to reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11990",
      "abstract": "Recently, personalized portrait generation with a text-to-image diffusion model has significantly advanced with Textual Inversion, emerging as a promising approach for creating high-fidelity personalized images. Despite its potential, current Textual Inversion methods struggle to maintain consistent facial identity due to semantic misalignments between textual and visual embedding spaces regarding identity. We introduce ID-EA, a novel framework that guides text embeddings to align with visual identity embeddings, thereby improving identity preservation in a personalized generation. ID-EA comprises two key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned Adapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings with a textual ID anchor, refining visual identity embeddings derived from a face recognition model using representative text embeddings. Then, the ID-Adapter leverages the identity-enhanced embedding to adapt the text condition, ensuring identity preservation by adjusting the cross-attention module in the pre-trained UNet model. This process encourages the text features to find the most related visual clues across the foreground snippets. Extensive quantitative and qualitative evaluations demonstrate that ID-EA substantially outperforms state-of-the-art methods in identity preservation metrics while achieving remarkable computational efficiency, generating personalized portraits approximately 15 times faster than existing approaches.",
      "authors": [
        "Hyun-Jun Jin",
        "Young-Eun Kim",
        "and Seong-Whan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:42:02+00:00",
          "link": "https://arxiv.org/abs/2507.11990v1",
          "size": "4043kb",
          "version": "v1"
        }
      ],
      "title": "ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11990",
        "HTML": "https://arxiv.org/html/2507.11990v1",
        "PDF": "https://arxiv.org/pdf/2507.11990"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a text-to-image generation model that enhances identity preservation, with no relation to reinforcement learning or data processing within the RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11991",
      "abstract": "High-risk traffic zones such as intersections are a major cause of collisions. This study leverages deep generative models to enhance the safety of autonomous vehicles in an intersection context. We train a 1000-step denoising diffusion probabilistic model to generate collision-causing sensor noise sequences for an autonomous vehicle navigating a four-way intersection based on the current relative position and velocity of an intruder. Using the generative adversarial architecture, the 1000-step model is distilled into a single-step denoising diffusion model which demonstrates fast inference speed while maintaining similar sampling quality. We demonstrate one possible application of the single-step model in building a robust planner for the autonomous vehicle. The planner uses the single-step model to efficiently sample potential failure cases based on the currently measured traffic state to inform its decision-making. Through simulation experiments, the robust planner demonstrates significantly lower failure rate and delay rate compared with the baseline Intelligent Driver Model controller.",
      "authors": [
        "Juanran Wang",
        "Marc R. Schlichting",
        "Mykel J. Kochenderfer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:43:55+00:00",
          "link": "https://arxiv.org/abs/2507.11991v1",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "title": "Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11991",
        "HTML": "https://arxiv.org/html/2507.11991v1",
        "PDF": "https://arxiv.org/pdf/2507.11991"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper proposes a diffusion-based model used to generate sensor noise sequences for autonomous vehicles, which can be considered a form of data augmentation. It mentions the use of these generated scenarios for robust planning, but does not directly focus on RL data processing methods. The connection to RL data processing is indirect, as it involves generating test cases for planning which could be applicable in RL training environments for autonomous vehicles."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11992",
      "abstract": "Bio-inspired design is often used in autonomous UAV navigation due to the capacity of biological systems for flight and obstacle avoidance despite limited sensory and computational capabilities. In particular, honeybees mainly use the sensory input of optic flow, the apparent motion of objects in their visual field, to navigate cluttered environments. In our work, we train a Reinforcement Learning agent to navigate a tunnel with obstacles using only optic flow as sensory input. We inspect the attention patterns of trained agents to determine the regions of optic flow on which they primarily base their motor decisions. We find that agents trained in this way pay most attention to regions of discontinuity in optic flow, as well as regions with large optic flow magnitude. The trained agents appear to navigate a cluttered tunnel by avoiding the obstacles that produce large optic flow, while maintaining a centered position in their environment, which resembles the behavior seen in flying insects. This pattern persists across independently trained agents, which suggests that this could be a good strategy for developing a simple explicit control law for physical UAVs.",
      "authors": [
        "Pranav Rajbhandari",
        "Abhi Veda",
        "Matthew Garratt",
        "Mandayam Srinivasan",
        "Sridhar Ravi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.11992v1",
          "size": "4292kb",
          "version": "v1"
        }
      ],
      "title": "Understanding visual attention beehind bee-inspired UAV navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11992",
        "HTML": "https://arxiv.org/html/2507.11992v1",
        "PDF": "https://arxiv.org/pdf/2507.11992"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper trains a reinforcement learning agent to navigate using optic flow as sensory input, which involves data processing of visual input for the RL agent. However, the focus is more on the RL application rather than novel data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11994",
      "abstract": "Public remote sensing datasets often face limitations in universality due to resolution variability and inconsistent land cover category definitions. To harness the vast pool of unlabeled remote sensing data, we propose SAMST, a semi-supervised semantic segmentation method. SAMST leverages the strengths of the Segment Anything Model (SAM) in zero-shot generalization and boundary detection. SAMST iteratively refines pseudo-labels through two main components: supervised model self-training using both labeled and pseudo-labeled data, and a SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three modules: a Threshold Filter Module for preprocessing, a Prompt Generation Module for extracting connected regions and generating prompts for SAM, and a Label Refinement Module for final label stitching. By integrating the generalization power of large models with the training efficiency of small models, SAMST improves pseudo-label accuracy, thereby enhancing overall model performance. Experiments on the Potsdam dataset validate the effectiveness and feasibility of SAMST, demonstrating its potential to address the challenges posed by limited labeled data in remote sensing semantic segmentation.",
      "authors": [
        "Jun Yin",
        "Fei Wu",
        "Yupeng Ren",
        "Jisheng Huang",
        "Qiankun Li",
        "Heng jin",
        "Jianhai Fu",
        "Chanjie Cui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:47:49+00:00",
          "link": "https://arxiv.org/abs/2507.11994v1",
          "size": "1076kb",
          "version": "v1"
        }
      ],
      "title": "SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11994",
        "HTML": "https://arxiv.org/html/2507.11994v1",
        "PDF": "https://arxiv.org/pdf/2507.11994"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with semi-supervised semantic segmentation in remote sensing and does not discuss reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11997",
      "abstract": "Graph fraud detection has garnered significant attention as Graph Neural Networks (GNNs) have proven effective in modeling complex relationships within multimodal data. However, existing graph fraud detection methods typically use preprocessed node embeddings and predefined graph structures to reveal fraudsters, which ignore the rich semantic cues contained in raw textual information. Although Large Language Models (LLMs) exhibit powerful capabilities in processing textual information, it remains a significant challenge to perform multimodal fusion of processed textual embeddings with graph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM \\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In MLED, we utilize LLMs to extract external knowledge from textual information to enhance graph fraud detection methods. To integrate LLMs with graph structure information and enhance the ability to distinguish fraudsters, we design a multi-level LLM enhanced framework including type-level enhancer and relation-level enhancer. One is to enhance the difference between the fraudsters and the benign entities, the other is to enhance the importance of the fraudsters in different relations. The experiments on four real-world datasets show that MLED achieves state-of-the-art performance in graph fraud detection as a generalized framework that can be applied to existing methods.",
      "authors": [
        "Tairan Huang",
        "Yili Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:50:43+00:00",
          "link": "https://arxiv.org/abs/2507.11997v1",
          "size": "3272kb",
          "version": "v1"
        }
      ],
      "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11997",
        "HTML": "https://arxiv.org/html/2507.11997v1",
        "PDF": "https://arxiv.org/pdf/2507.11997"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is about graph fraud detection using large language models and does not address reinforcement learning or data processing in the context of RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11999",
      "abstract": "Graph querying is the process of retrieving information from graph data using specialized languages (e.g., Cypher), often requiring programming expertise. Visual Graph Querying (VGQ) streamlines this process by enabling users to construct and execute queries via an interactive interface without resorting to complex coding. However, current VGQ tools only allow users to construct simple and specific query graphs, limiting users' ability to interactively express their query intent, especially for underspecified query intent. To address these limitations, we propose Envisage, an interactive visual graph querying system to enhance the expressiveness of VGQ in complex query scenarios by supporting intuitive graph structure construction and flexible parameterized rule specification. Specifically, Envisage comprises four stages: Query Expression allows users to interactively construct graph queries through intuitive operations; Query Verification enables the validation of constructed queries via rule verification and query instantiation; Progressive Query Execution can progressively execute queries to ensure meaningful querying results; and Result Analysis facilitates result exploration and interpretation. To evaluate Envisage, we conducted two case studies and in-depth user interviews with 14 graph analysts. The results demonstrate its effectiveness and usability in constructing, verifying, and executing complex graph queries.",
      "authors": [
        "Xiaolin Wen",
        "Qishuang Fu",
        "Shuangyue Han",
        "Yichen Guo",
        "Joseph K. Liu",
        "Yong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:54:37+00:00",
          "link": "https://arxiv.org/abs/2507.11999v1",
          "size": "5643kb",
          "version": "v1"
        }
      ],
      "title": "Envisage: Towards Expressive Visual Graph Querying",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11999",
        "HTML": "https://arxiv.org/html/2507.11999v1",
        "PDF": "https://arxiv.org/pdf/2507.11999"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visual graph querying, which does not involve reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12001",
      "abstract": "While 3D facial animation has made impressive progress, challenges still exist in realizing fine-grained stylized 3D facial expression manipulation due to the lack of appropriate datasets. In this paper, we introduce the AUBlendSet, a 3D facial dataset based on AU-Blendshape representation for fine-grained facial expression manipulation across identities. AUBlendSet is a blendshape data collection based on 32 standard facial action units (AUs) across 500 identities, along with an additional set of facial postures annotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to learn AU-Blendshape basis vectors for different character styles. AUBlendNet predicts, in parallel, the AU-Blendshape basis vectors of the corresponding style for a given identity mesh, thereby achieving stylized 3D emotional facial manipulation. We comprehensively validate the effectiveness of AUBlendSet and AUBlendNet through tasks such as stylized facial expression manipulation, speech-driven emotional facial animation, and emotion recognition data augmentation. Through a series of qualitative and quantitative experiments, we demonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D facial animation tasks. To the best of our knowledge, AUBlendSet is the first dataset, and AUBlendNet is the first network for continuous 3D facial expression manipulation for any identity through facial AUs. Our source code is available at https://github.com/wslh852/AUBlendNet.git.",
      "authors": [
        "Hao Li",
        "Ju Dai",
        "Feng Zhou",
        "Kaida Ning",
        "Lei Li",
        "Junjun Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:56:25+00:00",
          "link": "https://arxiv.org/abs/2507.12001v1",
          "size": "2933kb",
          "version": "v1"
        }
      ],
      "title": "AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12001",
        "HTML": "https://arxiv.org/html/2507.12001v1",
        "PDF": "https://arxiv.org/pdf/2507.12001"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is about 3D facial expression manipulation and dataset creation for facial animation, unrelated to reinforcement learning or its data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12002",
      "abstract": "Social interactions play a crucial role in shaping human behavior, relationships, and societies. It encompasses various forms of communication, such as verbal conversation, non-verbal gestures, facial expressions, and body language. In this work, we develop a novel computational approach to detect a foundational aspect of human social interactions, in-person verbal conversations, by leveraging audio and inertial data captured with a commodity smartwatch in acoustically-challenging scenarios. To evaluate our approach, we conducted a lab study with 11 participants and a semi-naturalistic study with 24 participants. We analyzed machine learning and deep learning models with 3 different fusion methods, showing the advantages of fusing audio and inertial data to consider not only verbal cues but also non-verbal gestures in conversations. Furthermore, we perform a comprehensive set of evaluations across activities and sampling rates to demonstrate the benefits of multimodal sensing in specific contexts. Overall, our framework achieved 82.0$\\pm$3.0% macro F1-score when detecting conversations in the lab and 77.2$\\pm$1.8% in the semi-naturalistic setting.",
      "authors": [
        "Alice Zhang and Callihan Bertley and Dawei Liang and Edison Thomaz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:57:15+00:00",
          "link": "https://arxiv.org/abs/2507.12002v1",
          "size": "5835kb",
          "version": "v1"
        }
      ],
      "title": "Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12002",
        "HTML": "https://arxiv.org/html/2507.12002v1",
        "PDF": "https://arxiv.org/pdf/2507.12002"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on detecting in-person conversations using smartwatch sensors, relying on audio and inertial data fusion in human-computer interaction. There is no discussion or contribution relating to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12003",
      "abstract": "This article presents the current state of ML-security and of the documentation of ML-based systems, models and datasets in research and practice based on an extensive review of the existing literature. It shows a generally low awareness of security aspects among ML-practitioners and organizations and an often unstandardized approach to documentation, leading to overall low quality of ML-documentation. Existing standards are not regularly adopted in practice and IT-security aspects are often not included in documentation. Due to these factors, there is a clear need for improved security documentation in ML, as one step towards addressing the existing gaps in ML-security. To achieve this, we propose expanding existing documentation standards for ML-documentation to include a security section with specific security relevant information. Implementing this, a novel expanded method of documenting security requirements in ML-documentation is presented, based on the existing Model Cards and Datasheets for Datasets standards, but with the recommendation to adopt these findings in all ML-documentation.",
      "authors": [
        "Cara Ellen Appel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:57:57+00:00",
          "link": "https://arxiv.org/abs/2507.12003v1",
          "size": "84kb",
          "version": "v1"
        }
      ],
      "title": "Expanding ML-Documentation Standards For Better Security",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12003",
        "HTML": "https://arxiv.org/html/2507.12003v1",
        "PDF": "https://arxiv.org/pdf/2507.12003"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in ML documentation standards for security purposes and does not mention reinforcement learning or data processing related to RL. It focuses on security documentation rather than RL-specific data handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12004",
      "abstract": "This thesis addresses challenges related to data and parameter efficiency in neural language models, with a focus on representation analysis and the introduction of new optimization techniques. The first part examines the properties and dynamics of language representations within neural models, emphasizing their significance in enhancing robustness and generalization. It proposes innovative approaches based on representation smoothness, including regularization strategies that utilize Jacobian and Hessian matrices to stabilize training and mitigate sensitivity to input perturbations. The second part focuses on methods to significantly enhance data and parameter efficiency by integrating active learning strategies with parameter-efficient fine-tuning, guided by insights from representation smoothness analysis. It presents smoothness-informed early-stopping techniques designed to eliminate the need for labeled validation sets and proposes innovative combinations of active learning and parameter-efficient fine-tuning to reduce labeling efforts and computational resources. Extensive experimental evaluations across various NLP tasks demonstrate that these combined approaches substantially outperform traditional methods in terms of performance, stability, and efficiency. The third part explores weak supervision techniques enhanced by in-context learning to effectively utilize unlabeled data, further reducing dependence on extensive labeling. It shows that using in-context learning as a mechanism for weak supervision enables models to better generalize from limited labeled data by leveraging unlabeled examples more effectively during training. Comprehensive empirical evaluations confirm significant gains in model accuracy, adaptability, and robustness, especially in low-resource settings and dynamic data environments.",
      "authors": [
        "Josip Juki\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:58:20+00:00",
          "link": "https://arxiv.org/abs/2507.12004v1",
          "size": "8684kb",
          "version": "v1"
        }
      ],
      "title": "Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12004",
        "PDF": "https://arxiv.org/pdf/2507.12004"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "Although the focus is on data and parameter efficiency in language models through representation analysis, techniques like active learning and weak supervision indirectly relate to RL-like settings. However, the main contribution is not specific to RL data processing, making it only tangentially relevant."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12006",
      "abstract": "Vision Transformers (ViTs) have significantly advanced computer vision, demonstrating strong performance across various tasks. However, the attention mechanism in ViTs makes each layer function as a low-pass filter, and the stacked-layer architecture in existing transformers suffers from frequency vanishing. This leads to the loss of critical details and textures. We propose a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly modulates the overall frequency response of ViTs and consists of two techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling (FreqScale). Since circuit theory uses low-pass filters as fundamental elements, we introduce AttInv, a method that generates complementary high-pass filtering by inverting the low-pass filter in the attention matrix, and dynamically combining the two. We further design FreqScale to weight different frequency components for fine-grained adjustments to the target response function. Through feature similarity analysis and effective rank evaluation, we demonstrate that our approach avoids representation collapse, leading to consistent performance improvements across various models, including SegFormer, DeiT, and MaskDINO. These improvements are evident in tasks such as semantic segmentation, object detection, and instance segmentation. Additionally, we apply our method to remote sensing detection, achieving state-of-the-art results in single-scale settings. The code is available at \\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.",
      "authors": [
        "Linwei Chen",
        "Lin Gu",
        "Ying Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.12006v1",
          "size": "1421kb",
          "version": "v1"
        }
      ],
      "title": "Frequency-Dynamic Attention Modulation for Dense Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12006",
        "HTML": "https://arxiv.org/html/2507.12006v1",
        "PDF": "https://arxiv.org/pdf/2507.12006"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work introduces a method for frequency modulation in vision transformers, improving vision models for dense prediction tasks like semantic segmentation. It does not pertain to reinforcement learning or related data processing strategies in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12007",
      "abstract": "Predicting changes in consumer attention for cultural products, such as books, movies, and songs, is notoriously difficult. Past research on predicting the popularity of individual products suggests the existence of intrinsic prediction limits. However, little is known about the limits for predicting collective attention across cultural products. Here, we analyze four years of nationwide library loan data for approximately 2 million individuals, comprising over 100 million loans of more than 660,000 unique books. We find that culture, as measured by popularity distributions of loaned books, drifts continually from month to month at a near-constant rate, leading to a growing divergence over time, and that drifts vary between different book genres. By linking book loans to registry data, we investigate the influence of age, sex, educational level, and geographical area on cultural drift, finding heterogeneous effects from the different demographic groups. Our findings have important implications for market forecasting and developing robust recommender systems, highlighting the need to account for specific drift dynamics for different types of items and demographic groups.",
      "authors": [
        "Anders Weile Larsen",
        "Vedran Sekara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:03:52+00:00",
          "link": "https://arxiv.org/abs/2507.12007v1",
          "size": "12362kb",
          "version": "v1"
        }
      ],
      "title": "Predictable Drifts in Collective Cultural Attention: Evidence from Nation-Level Library Takeout Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12007",
        "HTML": "https://arxiv.org/html/2507.12007v1",
        "PDF": "https://arxiv.org/pdf/2507.12007"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on predicting changes in consumer attention for cultural products, using library loan data. It does not relate to reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12008",
      "abstract": "Recent works have correlated Masked Image Modeling (MIM) with consistency regularization in Unsupervised Domain Adaptation (UDA). However, they merely treat masking as a special form of deformation on the input images and neglect the theoretical analysis, which leads to a superficial understanding of masked reconstruction and insufficient exploitation of its potential in enhancing feature extraction and representation learning. In this paper, we reframe masked reconstruction as a sparse signal reconstruction problem and theoretically prove that the dual form of complementary masks possesses superior capabilities in extracting domain-agnostic image features. Based on this compelling insight, we propose MaskTwins, a simple yet effective UDA framework that integrates masked reconstruction directly into the main training pipeline. MaskTwins uncovers intrinsic structural patterns that persist across disparate domains by enforcing consistency between predictions of images masked in complementary ways, enabling domain generalization in an end-to-end manner. Extensive experiments verify the superiority of MaskTwins over baseline methods in natural and biological image segmentation. These results demonstrate the significant advantages of MaskTwins in extracting domain-invariant features without the need for separate pre-training, offering a new paradigm for domain-adaptive segmentation.",
      "authors": [
        "Jiawen Wang",
        "Yinda Chen",
        "Xiaoyu Liu",
        "Che Liu",
        "Dong Liu",
        "Jianqing Gao",
        "Zhiwei Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:05:22+00:00",
          "link": "https://arxiv.org/abs/2507.12008v1",
          "size": "13090kb",
          "version": "v1"
        }
      ],
      "title": "Dual form Complementary Masking for Domain-Adaptive Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12008",
        "PDF": "https://arxiv.org/pdf/2507.12008"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses a new framework for domain-adaptive image segmentation using masked image modeling. It does not involve reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12009",
      "abstract": "We propose an end-to-end deep neural encoder-decoder model to encode and decode brain activity in response to naturalistic stimuli using functional magnetic resonance imaging (fMRI) data. Leveraging temporally correlated input from consecutive film frames, we employ temporal convolutional layers in our architecture, which effectively allows to bridge the temporal resolution gap between natural movie stimuli and fMRI acquisitions. Our model predicts activity of voxels in and around the visual cortex and performs reconstruction of corresponding visual inputs from neural activity. Finally, we investigate brain regions contributing to visual decoding through saliency maps. We find that the most contributing regions are the middle occipital area, the fusiform area, and the calcarine, respectively employed in shape perception, complex recognition (in particular face perception), and basic visual features such as edges and contrasts. These functions being strongly solicited are in line with the decoder's capability to reconstruct edges, faces, and contrasts. All in all, this suggests the possibility to probe our understanding of visual processing in films using as a proxy the behaviour of deep learning models such as the one proposed in this paper.",
      "authors": [
        "Florian David",
        "Michael Chan",
        "Elenor Morgenroth",
        "Patrik Vuilleumier",
        "Dimitri Van De Ville"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:08:48+00:00",
          "link": "https://arxiv.org/abs/2507.12009v1",
          "size": "3352kb",
          "version": "v1"
        }
      ],
      "title": "Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12009",
        "HTML": "https://arxiv.org/html/2507.12009v1",
        "PDF": "https://arxiv.org/pdf/2507.12009"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a deep neural encoder-decoder model for brain activity related to naturalistic stimuli using fMRI data, without any relation to reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12011",
      "abstract": "Although deep neural networks have made remarkable achievements in the field of automatic modulation recognition (AMR), these models often require a large amount of labeled data for training. However, in many practical scenarios, the available target domain data is scarce and difficult to meet the needs of model training. The most direct way is to collect data manually and perform expert annotation, but the high time and labor costs are unbearable. Another common method is data augmentation. Although it can enrich training samples to a certain extent, it does not introduce new data and therefore cannot fundamentally solve the problem of data scarcity. To address these challenges, we introduce a data expansion framework called Dynamic Uncertainty-driven Sample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring function to filter out useful samples from relevant AMR datasets and employs an active learning strategy to continuously refine the scorer. Extensive experiments demonstrate that DUSE consistently outperforms 8 coreset selection baselines in both class-balance and class-imbalance settings. Besides, DUSE exhibits strong cross-architecture generalization for unseen models.",
      "authors": [
        "Yao Lu",
        "Hongyu Gao",
        "Zhuangzhi Chen",
        "Dongwei Xu",
        "Yun Lin",
        "Qi Xuan",
        "Guan Gui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:09:41+00:00",
          "link": "https://arxiv.org/abs/2507.12011v1",
          "size": "1614kb",
          "version": "v1"
        }
      ],
      "title": "DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12011",
        "HTML": "https://arxiv.org/html/2507.12011v1",
        "PDF": "https://arxiv.org/pdf/2507.12011"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a data expansion framework for automatic modulation recognition through active learning, but it does not involve reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12012",
      "abstract": "Quantifiable image patterns associated with disease progression and treatment response are critical tools for guiding individual treatment, and for developing novel therapies. Here, we show that unsupervised machine learning can identify a pattern vocabulary of liver tissue in magnetic resonance images that quantifies treatment response in diffuse liver disease. Deep clustering networks simultaneously encode and cluster patches of medical images into a low-dimensional latent space to establish a tissue vocabulary. The resulting tissue types capture differential tissue change and its location in the liver associated with treatment response. We demonstrate the utility of the vocabulary on a randomized controlled trial cohort of non-alcoholic steatohepatitis patients. First, we use the vocabulary to compare longitudinal liver change in a placebo and a treatment cohort. Results show that the method identifies specific liver tissue change pathways associated with treatment, and enables a better separation between treatment groups than established non-imaging measures. Moreover, we show that the vocabulary can predict biopsy derived features from non-invasive imaging data. We validate the method on a separate replication cohort to demonstrate the applicability of the proposed method.",
      "authors": [
        "Matthias Perkonigg",
        "Nina Bastati",
        "Ahmed Ba-Ssalamah",
        "Peter Mesenbrink",
        "Alexander Goehler",
        "Miljen Martic",
        "Xiaofei Zhou",
        "Michael Trauner and Georg Langs"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:11:48+00:00",
          "link": "https://arxiv.org/abs/2507.12012v1",
          "size": "802kb",
          "version": "v1"
        }
      ],
      "title": "Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12012",
        "HTML": "https://arxiv.org/html/2507.12012v1",
        "PDF": "https://arxiv.org/pdf/2507.12012"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with identifying image phenotypes for tracking treatment responses in liver disease using unsupervised learning, lacking any direct connection to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12015",
      "abstract": "In recent years, emotional Text-to-Speech (TTS) synthesis and emphasis-controllable speech synthesis have advanced significantly. However, their interaction remains underexplored. We propose Emphasis Meets Emotion TTS (EME-TTS), a novel framework designed to address two key research questions: (1) how to effectively utilize emphasis to enhance the expressiveness of emotional speech, and (2) how to maintain the perceptual clarity and stability of target emphasis across different emotions. EME-TTS employs weakly supervised learning with emphasis pseudo-labels and variance-based emphasis features. Additionally, the proposed Emphasis Perception Enhancement (EPE) block enhances the interaction between emotional signals and emphasis positions. Experimental results show that EME-TTS, when combined with large language models for emphasis position prediction, enables more natural emotional speech synthesis while preserving stable and distinguishable target emphasis across emotions. Synthesized samples are available on-line.",
      "authors": [
        "Haoxun Li",
        "Leyuan Qu",
        "Jiaxi Hu",
        "Taihao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:19:20+00:00",
          "link": "https://arxiv.org/abs/2507.12015v1",
          "size": "453kb",
          "version": "v1"
        }
      ],
      "title": "EME-TTS: Unlocking the Emphasis and Emotion Link in Speech Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12015",
        "HTML": "https://arxiv.org/html/2507.12015v1",
        "PDF": "https://arxiv.org/pdf/2507.12015"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on emotional TTS synthesis and does not discuss reinforcement learning or any aspect of data processing within the RL context, such as data collection, preprocessing, or dataset curation for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12017",
      "abstract": "Unsupervised domain adaptive object detection (UDAOD) from the visible domain to the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB domain as a unified domain and neglect the multiple subdomains within it, such as daytime, nighttime, and foggy scenes. We argue that decoupling the domain-invariant (DI) and domain-specific (DS) features across these multiple subdomains is beneficial for RGB-IR domain adaptation. To this end, this paper proposes a new SS-DC framework based on a decoupling-coupling strategy. In terms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID) module in the aspect of spectral decomposition. Due to the style and content information being highly embedded in different frequency bands, this module can decouple DI and DS components more accurately and interpretably. A novel filter bank-based spectral processing paradigm and a self-distillation-driven decoupling loss are proposed to improve the spectral domain decoupling. In terms of coupling, a new spatial-spectral coupling method is proposed, which realizes joint coupling through spatial and spectral DI feature pyramids. Meanwhile, this paper introduces DS from decoupling to reduce the domain bias. Extensive experiments demonstrate that our method can significantly improve the baseline performance and outperform existing UDAOD methods on multiple RGB-IR datasets, including a new experimental protocol proposed in this paper based on the FLIR-ADAS dataset.",
      "authors": [
        "Xiwei Zhang",
        "Chunjin Yang",
        "Yiming Xiao",
        "Runtong Zhang",
        "Fanman Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:21:41+00:00",
          "link": "https://arxiv.org/abs/2507.12017v1",
          "size": "2688kb",
          "version": "v1"
        }
      ],
      "title": "SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12017",
        "HTML": "https://arxiv.org/html/2507.12017v1",
        "PDF": "https://arxiv.org/pdf/2507.12017"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses domain adaptive object detection in the context of RGB-IR data but does not relate to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12019",
      "abstract": "We investigate the performance of a Bayesian statistician tasked with recovering a rank-\\(k\\) signal matrix \\(\\bS \\bS^{\\top} \\in \\mathbb{R}^{n \\times n}\\), corrupted by element-wise additive Gaussian noise. This problem lies at the core of numerous applications in machine learning, signal processing, and statistics. We derive an analytic expression for the asymptotic mean-square error (MSE) of the Bayesian estimator under mismatches in the assumed signal rank, signal power, and signal-to-noise ratio (SNR), considering both sphere and Gaussian signals. Additionally, we conduct a rigorous analysis of how rank mismatch influences the asymptotic MSE. Our primary technical tools include the spectrum of Gaussian orthogonal ensembles (GOE) with low-rank perturbations and asymptotic behavior of \\(k\\)-dimensional spherical integrals.",
      "authors": [
        "Panpan Niu",
        "Yuhao Liu",
        "Teng Fu",
        "Jie Fan",
        "Chaowen Deng and Zhongyi Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:24:44+00:00",
          "link": "https://arxiv.org/abs/2507.12019v1",
          "size": "142kb",
          "version": "v1"
        }
      ],
      "title": "The Role of Rank in Mismatched Low-Rank Symmetric Matrix Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12019",
        "HTML": "https://arxiv.org/html/2507.12019v1",
        "PDF": "https://arxiv.org/pdf/2507.12019"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on Bayesian estimation of low-rank symmetric matrices with Gaussian noise, which does not pertain to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12022",
      "abstract": "High-quality open-source datasets have emerged as a pivotal catalyst driving the swift advancement of deep learning, while facing the looming threat of potential exploitation. Protecting these datasets is of paramount importance for the interests of their owners. The verification of dataset ownership has evolved into a crucial approach in this domain; however, existing verification techniques are predominantly tailored to supervised models and contrastive pre-trained models, rendering them ill-suited for direct application to the increasingly prevalent masked models. In this work, we introduce the inaugural methodology addressing this critical, yet unresolved challenge, termed Dataset Ownership Verification for Masked Modeling (DOV4MM). The central objective is to ascertain whether a suspicious black-box model has been pre-trained on a particular unlabeled dataset, thereby assisting dataset owners in safeguarding their rights. DOV4MM is grounded in our empirical observation that when a model is pre-trained on the target dataset, the difficulty of reconstructing masked information within the embedding space exhibits a marked contrast to models not pre-trained on that dataset. We validated the efficacy of DOV4MM through ten masked image models on ImageNet-1K and four masked language models on WikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis, with a $p$-value considerably below 0.05, surpassing all prior approaches. Code is available at https://github.com/xieyc99/DOV4MM.",
      "authors": [
        "Yuechen Xie",
        "Jie Song",
        "Yicheng Shan",
        "Xiaoyan Zhang",
        "Yuanyu Wan",
        "Shengxuming Zhang",
        "Jiarui Duan",
        "Mingli Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:30:30+00:00",
          "link": "https://arxiv.org/abs/2507.12022v1",
          "size": "1340kb",
          "version": "v1"
        }
      ],
      "title": "Dataset Ownership Verification for Pre-trained Masked Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12022",
        "HTML": "https://arxiv.org/html/2507.12022v1",
        "PDF": "https://arxiv.org/pdf/2507.12022"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses dataset ownership verification for pre-trained masked models, which is not related to reinforcement learning or data processing methods within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12023",
      "abstract": "Air pollutants pose a significant threat to the environment and human health, thus forecasting accurate pollutant concentrations is essential for pollution warnings and policy-making. Existing studies predominantly focus on single-pollutant forecasting, neglecting the interactions among different pollutants and their diverse spatial responses. To address the practical needs of forecasting multivariate air pollutants, we propose MultiVariate AutoRegressive air pollutants forecasting model (MVAR), which reduces the dependency on long-time-window inputs and boosts the data utilization efficiency. We also design the Multivariate Autoregressive Training Paradigm, enabling MVAR to achieve 120-hour long-term sequential forecasting. Additionally, MVAR develops Meteorological Coupled Spatial Transformer block, enabling the flexible coupling of AI-based meteorological forecasts while learning the interactions among pollutants and their diverse spatial responses. As for the lack of standardized datasets in air pollutants forecasting, we construct a comprehensive dataset covering 6 major pollutants across 75 cities in North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0 forecast data. Experimental results demonstrate that the proposed model outperforms state-of-the-art methods and validate the effectiveness of the proposed architecture.",
      "authors": [
        "Xu Fan",
        "Zhihao Wang",
        "Yuetan Lin",
        "Yan Zhang",
        "Yang Xiang and Hao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:30:41+00:00",
          "link": "https://arxiv.org/abs/2507.12023v1",
          "size": "2701kb",
          "version": "v1"
        }
      ],
      "title": "MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12023",
        "HTML": "https://arxiv.org/html/2507.12023v1",
        "PDF": "https://arxiv.org/pdf/2507.12023"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a forecasting model for air pollutants using a multivariate autoregressive approach and does not discuss reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12026",
      "abstract": "With the growing need for diverse and scalable data in indoor scene tasks, such as question answering and dense captioning, we propose 3D-MoRe, a novel paradigm designed to generate large-scale 3D-language datasets by leveraging the strengths of foundational models. The framework integrates key components, including multi-modal embedding, cross-modal interaction, and a language model decoder, to process natural language instructions and 3D scene data. This approach facilitates enhanced reasoning and response generation in complex 3D environments. Using the ScanNet 3D scene dataset, along with text annotations from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs and 73,000 object descriptions across 1,513 scenes. We also employ various data augmentation techniques and implement semantic filtering to ensure high-quality data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms state-of-the-art baselines, with the CIDEr score improving by 2.15\\%. Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5 by 1.84\\%, highlighting its effectiveness in both tasks. Our code and generated datasets will be publicly released to benefit the community, and both can be accessed on the https://3D-MoRe.github.io.",
      "authors": [
        "Rongtao Xu",
        "Han Gao",
        "Mingming Yu",
        "Dong An",
        "Shunpeng Chen",
        "Changwei Wang",
        "Li Guo",
        "Xiaodan Liang and Shibiao Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:38:26+00:00",
          "link": "https://arxiv.org/abs/2507.12026v1",
          "size": "4633kb",
          "version": "v1"
        }
      ],
      "title": "3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12026",
        "HTML": "https://arxiv.org/html/2507.12026v1",
        "PDF": "https://arxiv.org/pdf/2507.12026"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper involves data augmentation and semantic filtering to generate high-quality datasets for 3D-language tasks. While data processing is mentioned, the primary focus is on enhancing reasoning and response generation rather than reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12027",
      "abstract": "We propose SGLoc, a novel localization system that directly regresses camera poses from 3D Gaussian Splatting (3DGS) representation by leveraging semantic information. Our method utilizes the semantic relationship between 2D image and 3D scene representation to estimate the 6DoF pose without prior pose information. In this system, we introduce a multi-level pose regression strategy that progressively estimates and refines the pose of query image from the global 3DGS map, without requiring initial pose priors. Moreover, we introduce a semantic-based global retrieval algorithm that establishes correspondences between 2D (image) and 3D (3DGS map). By matching the extracted scene semantic descriptors of 2D query image and 3DGS semantic representation, we align the image with the local region of the global 3DGS map, thereby obtaining a coarse pose estimation. Subsequently, we refine the coarse pose by iteratively optimizing the difference between the query image and the rendered image from 3DGS. Our SGLoc demonstrates superior performance over baselines on 12scenes and 7scenes datasets, showing excellent capabilities in global localization without initial pose prior. Code will be available at https://github.com/IRMVLab/SGLoc.",
      "authors": [
        "Beining Xu",
        "Siting Zhu",
        "Hesheng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:39:08+00:00",
          "link": "https://arxiv.org/abs/2507.12027v1",
          "size": "3013kb",
          "version": "v1"
        }
      ],
      "title": "SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12027",
        "HTML": "https://arxiv.org/html/2507.12027v1",
        "PDF": "https://arxiv.org/pdf/2507.12027"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a system for camera pose estimation using a 3D Gaussian Splatting representation and does not involve reinforcement learning or RL-specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12028",
      "abstract": "Task offloading in three-layer fog computing environments presents a critical challenge due to user equipment (UE) mobility, which frequently triggers costly service migrations and degrades overall system performance. This paper addresses this problem by proposing MOFCO, a novel Mobility- and Migration-aware Task Offloading algorithm for Fog Computing environments. The proposed method formulates task offloading and resource allocation as a Mixed-Integer Nonlinear Programming (MINLP) problem and employs a heuristic-aided evolutionary game theory approach to solve it efficiently. To evaluate MOFCO, we simulate mobile users using SUMO, providing realistic mobility patterns. Experimental results show that MOFCO reduces system cost, defined as a combination of latency and energy consumption, by an average of 19% and up to 43% in certain scenarios compared to state-of-the-art methods.",
      "authors": [
        "Soheil Mahdizadeh",
        "Elyas Oustad",
        "Mohsen Ansari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:42:32+00:00",
          "link": "https://arxiv.org/abs/2507.12028v1",
          "size": "3461kb",
          "version": "v1"
        }
      ],
      "title": "MOFCO: Mobility- and Migration-Aware Task Offloading in Three-Layer Fog Computing Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12028",
        "HTML": "https://arxiv.org/html/2507.12028v1",
        "PDF": "https://arxiv.org/pdf/2507.12028"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is about task offloading in fog computing environments and does not relate to reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12029",
      "abstract": "In this paper, we address the problem of novel class discovery (NCD), which aims to cluster novel classes by leveraging knowledge from disjoint known classes. While recent advances have made significant progress in this area, existing NCD methods face two major limitations. First, they primarily focus on single-view data (e.g., images), overlooking the increasingly common multi-view data, such as multi-omics datasets used in disease diagnosis. Second, their reliance on pseudo-labels to supervise novel class clustering often results in unstable performance, as pseudo-label quality is highly sensitive to factors such as data noise and feature dimensionality. To address these challenges, we propose a novel framework named Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery (IICMVNCD), which is the first attempt to explore NCD in multi-view setting so far. Specifically, at the intra-view level, leveraging the distributional similarity between known and novel classes, we employ matrix factorization to decompose features into view-specific shared base matrices and factor matrices. The base matrices capture distributional consistency among the two datasets, while the factor matrices model pairwise relationships between samples. At the inter-view level, we utilize view relationships among known classes to guide the clustering of novel classes. This includes generating predicted labels through the weighted fusion of factor matrices and dynamically adjusting view weights of known classes based on the supervision loss, which are then transferred to novel class learning. Experimental results validate the effectiveness of our proposed approach.",
      "authors": [
        "Xinhang Wan",
        "Jiyuan Liu",
        "Qian Qu",
        "Suyuan Liu",
        "Chuyu Zhang",
        "Fangdi Wang",
        "Xinwang Liu",
        "En Zhu",
        "Kunlun He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:42:52+00:00",
          "link": "https://arxiv.org/abs/2507.12029v1",
          "size": "349kb",
          "version": "v1"
        }
      ],
      "title": "Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12029",
        "HTML": "https://arxiv.org/html/2507.12029v1",
        "PDF": "https://arxiv.org/pdf/2507.12029"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses novel class discovery using multi-view data and does not involve reinforcement learning or data processing tailored to RL approaches."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12031",
      "abstract": "6G networks are composed of subnetworks expected to meet ultra-reliable low-latency communication (URLLC) requirements for mission-critical applications such as industrial control and automation. An often-ignored aspect in URLLC is consecutive packet outages, which can destabilize control loops and compromise safety in in-factory environments. Hence, the current work proposes a link adaptation framework to support extreme reliability requirements using the soft actor-critic (SAC)-based deep reinforcement learning (DRL) algorithm that jointly optimizes energy efficiency (EE) and reliability under dynamic channel and interference conditions. Unlike prior work focusing on average reliability, our method explicitly targets reducing burst/consecutive outages through adaptive control of transmit power and blocklength based solely on the observed signal-to-interference-plus-noise ratio (SINR). The joint optimization problem is formulated under finite blocklength and quality of service constraints, balancing reliability and EE. Simulation results show that the proposed method significantly outperforms the baseline algorithms, reducing outage bursts while consuming only 18\\% of the transmission cost required by a full/maximum resource allocation policy in the evaluated scenario. The framework also supports flexible trade-off tuning between EE and reliability by adjusting reward weights, making it adaptable to diverse industrial requirements.",
      "authors": [
        "Fateme Salehi",
        "Aamir Mahmood",
        "Sarder Fakhrul Abedin",
        "Kyi Thar",
        "Mikael Gidlund"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:43:30+00:00",
          "link": "https://arxiv.org/abs/2507.12031v1",
          "size": "825kb",
          "version": "v1"
        }
      ],
      "title": "Towards Ultra-Reliable 6G in-X Subnetworks: Dynamic Link Adaptation by Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12031",
        "HTML": "https://arxiv.org/html/2507.12031v1",
        "PDF": "https://arxiv.org/pdf/2507.12031"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses the use of a deep reinforcement learning algorithm (SAC) for link adaptation in 6G networks. While it focuses on RL, it does not specifically address data processing techniques but rather applies existing RL methods to a networking problem."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12032",
      "abstract": "Achieving sustainable, explainable, and maintainable automation for resource optimization is a core challenge across the edge-cloud continuum. Persistent overprovisioning and operational complexity often stem from heterogeneous platforms and layered abstractions, while systems lacking explainability and maintainability become fragile, impede safe recovery, and accumulate technical debt. Existing solutions are frequently reactive, limited to single abstraction layers, or require intrusive platform changes, leaving efficiency and maintainability gains unrealized.\n  This paper addresses safe, transparent, and low-effort resource optimization in dynamic, multi-tenant edge-cloud systems, without disrupting operator workflows or increasing technical debt. We introduce ARRC, a recommender system rooted in software engineering design principles, which delivers explainable, cross-layer resource recommendations directly into operator workflows (such as tickets and GitOps pull requests). ARRC encapsulates optimization logic in specialized, auditable agents coordinated via a shared interface, supporting maintainability and extensibility through transparency and the ability to inspect both recommendations and their rationale.\n  Empirical evaluation in a multi-region industrial deployment shows that ARRC reduces operator workload by over 50%, improves compute utilization by up to 7.7x, and maintains error rates below 5%, with most benefits achieved through incremental, operator-approved changes. This demonstrates that explainable, recommendation-based architectures can achieve sustainable efficiency and maintainability improvements at production scale.\n  ARRC provides an empirically evaluated framework for integrating explainable, workflow-driven automation into resource management, intended to advance best practices for robust, maintainable, and transparent edge-cloud continuum platforms.",
      "authors": [
        "Brian-Frederik Jahnke",
        "Ren\\'e Brinkhege",
        "Jan Peter Meyer",
        "Daniel Tebernum",
        "Falk Howar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:48:04+00:00",
          "link": "https://arxiv.org/abs/2507.12032v1",
          "size": "1478kb",
          "version": "v1"
        }
      ],
      "title": "ARRC: Explainable, Workflow-Integrated Recommender for Sustainable Resource Optimization Across the Edge-Cloud Continuum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12032",
        "HTML": "https://arxiv.org/html/2507.12032v1",
        "PDF": "https://arxiv.org/pdf/2507.12032"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with a recommender system for resource optimization across the edge-cloud continuum and does not involve reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12036",
      "abstract": "This article presents a detailed analysis of the Arrow-Hurwicz iteration applied to the solution of the incompressible Navier-Stokes equations, discretized by a divergence-free mixed virtual element method. Under a set of appropriate assumptions, it is rigorously demonstrated that the method exhibits geometric convergence, with a contraction factor that remains independent of the mesh sizes. A series of numerical experiments are conducted to validate the theoretical findings and to assess the computational performance of the proposed method.",
      "authors": [
        "Binbin Du",
        "Shenxiang Cheng",
        "Yue Yu and Chuanjun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:53:22+00:00",
          "link": "https://arxiv.org/abs/2507.12036v1",
          "size": "8764kb",
          "version": "v1"
        }
      ],
      "title": "The Arrow-Hurwicz iteration for virtual element discretizations of the incompressible Navier-Stokes equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12036",
        "HTML": "https://arxiv.org/html/2507.12036v1",
        "PDF": "https://arxiv.org/pdf/2507.12036"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper pertains to numerical methods for solving differential equations and does not relate to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12038",
      "abstract": "In this work we present a fast distributed algorithm for local potential problems: these are graph problems where the task is to find a locally optimal solution where no node can unilaterally improve the utility in its local neighborhood by changing its own label. A simple example of such a problem is the task of finding a locally optimal cut, i.e., a cut where for each node at least half of its incident edges are cut edges. The distributed round complexity of locally optimal cut has been wide open; the problem is known to require $\\Omega(\\log n)$ rounds in the deterministic LOCAL model and $\\Omega(\\log \\log n)$ rounds in the randomized LOCAL model, but the only known upper bound is the trivial brute-force solution of $O(n)$ rounds. Locally optimal cut in bounded-degree graphs is perhaps the simplest example of a locally checkable labeling problem for which there is still such a large gap between current upper and lower bounds. We show that in bounded-degree graphs, all local potential problems, including locally optimal cut, can be solved in $\\log^{O(1)} n$ rounds, both in the deterministic and randomized LOCAL models. In particular, the deterministic round complexity of the locally optimal cut problem is now settled to $\\log^{\\Theta(1)} n$.",
      "authors": [
        "Alkida Balliu",
        "Thomas Boudier",
        "Francesco d'Amore",
        "Dennis Olivetti",
        "Gustav Schmid",
        "Jukka Suomela"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.12038v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Algorithms for Potential Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12038",
        "HTML": "https://arxiv.org/html/2507.12038v1",
        "PDF": "https://arxiv.org/pdf/2507.12038"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on distributed algorithms for graph problems and does not discuss reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12039",
      "abstract": "The following paper introduces a general linguistic creativity test for humans and Large Language Models (LLMs). The test consists of various tasks aimed at assessing their ability to generate new original words and phrases based on word formation processes (derivation and compounding) and on metaphorical language use. We administered the test to 24 humans and to an equal number of LLMs, and we automatically evaluated their answers using OCSAI tool for three criteria: Originality, Elaboration, and Flexibility. The results show that LLMs not only outperformed humans in all the assessed criteria, but did better in six out of the eight test tasks. We then computed the uniqueness of the individual answers, which showed some minor differences between humans and LLMs. Finally, we performed a short manual analysis of the dataset, which revealed that humans are more inclined towards E(extending)-creativity, while LLMs favor F(ixed)-creativity.",
      "authors": [
        "Anca Dinu",
        "Andra-Maria Florescu and Alina Resceanu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:56:19+00:00",
          "link": "https://arxiv.org/abs/2507.12039v1",
          "size": "153kb",
          "version": "v1"
        }
      ],
      "title": "A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12039",
        "HTML": "https://arxiv.org/html/2507.12039v1",
        "PDF": "https://arxiv.org/pdf/2507.12039"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study assesses the linguistic creativity of large language models and humans without a connection to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12041",
      "abstract": "Human feedback is increasingly used across diverse applications like training AI models, developing recommender systems, and measuring public opinion -- with granular feedback often being preferred over binary feedback for its greater informativeness. While it is easy to accurately estimate a population's distribution of feedback given feedback from a large number of individuals, cost constraints typically necessitate using smaller groups. A simple method to approximate the population distribution is regularized averaging: compute the empirical distribution and regularize it toward a prior. Can we do better? As we will discuss, the answer to this question depends on feedback granularity.\n  Suppose one wants to predict a population's distribution of feedback using feedback from a limited number of individuals. We show that, as feedback granularity increases, one can substantially improve upon predictions of regularized averaging by combining individuals' feedback in ways more sophisticated than regularized averaging.\n  Our empirical analysis using questions on social attitudes confirms this pattern. In particular, with binary feedback, sophistication barely reduces the number of individuals required to attain a fixed level of performance. By contrast, with five-point feedback, sophisticated methods match the performance of regularized averaging with about half as many individuals.",
      "authors": [
        "Anmol Kagrecha",
        "Henrik Marklund",
        "Potsawee Manakul",
        "Richard Zeckhauser",
        "Benjamin Van Roy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:58:27+00:00",
          "link": "https://arxiv.org/abs/2507.12041v1",
          "size": "90kb",
          "version": "v1"
        }
      ],
      "title": "Granular feedback merits sophisticated aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12041",
        "HTML": "https://arxiv.org/html/2507.12041v1",
        "PDF": "https://arxiv.org/pdf/2507.12041"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for aggregating granular human feedback, which is not related to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12042",
      "abstract": "This paper presents the objective, dataset, baseline, and metrics of Task 3 of the DCASE2025 Challenge on sound event localization and detection (SELD). In previous editions, the challenge used four-channel audio formats of first-order Ambisonics (FOA) and microphone array. In contrast, this year's challenge investigates SELD with stereo audio data (termed stereo SELD). This change shifts the focus from more specialized 360{\\deg} audio and audiovisual scene analysis to more commonplace audio and media scenarios with limited field-of-view (FOV). Due to inherent angular ambiguities in stereo audio data, the task focuses on direction-of-arrival (DOA) estimation in the azimuth plane (left-right axis) along with distance estimation. The challenge remains divided into two tracks: audio-only and audiovisual, with the audiovisual track introducing a new sub-task of onscreen/offscreen event classification necessitated by the limited FOV. This challenge introduces the DCASE2025 Task3 Stereo SELD Dataset, whose stereo audio and perspective video clips are sampled and converted from the STARSS23 recordings. The baseline system is designed to process stereo audio and corresponding video frames as inputs. In addition to the typical SELD event classification and localization, it integrates onscreen/offscreen classification for the audiovisual track. The evaluation metrics have been modified to introduce an onscreen/offscreen accuracy metric, which assesses the models' ability to identify which sound sources are onscreen. In the experimental evaluation, the baseline system performs reasonably well with the stereo audio data.",
      "authors": [
        "Kazuki Shimada",
        "Archontis Politis",
        "Iran R. Roman",
        "Parthasaarathy Sudarsanam",
        "David Diaz-Guerra",
        "Ruchi Pandey",
        "Kengo Uchida",
        "Yuichiro Koyama",
        "Naoya Takahashi",
        "Takashi Shibuya",
        "Shusuke Takahashi",
        "Tuomas Virtanen",
        "Yuki Mitsufuji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:59:09+00:00",
          "link": "https://arxiv.org/abs/2507.12042v1",
          "size": "649kb",
          "version": "v1"
        }
      ],
      "title": "Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12042",
        "HTML": "https://arxiv.org/html/2507.12042v1",
        "PDF": "https://arxiv.org/pdf/2507.12042"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is about sound event localization and detection in stereo audio datasets within an audio challenge context, not related to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12043",
      "abstract": "Continual learning (CL) has emerged as a dominant paradigm for acquiring knowledge from sequential tasks while avoiding catastrophic forgetting. Although many CL methods have been proposed to show impressive empirical performance, the theoretical understanding of their generalization behavior remains limited, particularly for replay-based approaches. In this paper, we establish a unified theoretical framework for replay-based CL, deriving a series of information-theoretic bounds that explicitly characterize how the memory buffer interacts with the current task to affect generalization. Specifically, our hypothesis-based bounds reveal that utilizing the limited exemplars of previous tasks alongside the current task data, rather than exhaustive replay, facilitates improved generalization while effectively mitigating catastrophic forgetting. Furthermore, our prediction-based bounds yield tighter and computationally tractable upper bounds of the generalization gap through the use of low-dimensional variables. Our analysis is general and broadly applicable to a wide range of learning algorithms, exemplified by stochastic gradient Langevin dynamics (SGLD) as a representative method. Comprehensive experimental evaluations demonstrate the effectiveness of our derived bounds in capturing the generalization dynamics in replay-based CL settings.",
      "authors": [
        "Wen Wen",
        "Tieliang Gong",
        "Yunjiao Zhang",
        "Zeyu Gao",
        "Weizhan Zhang",
        "Yong-Jin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:00:57+00:00",
          "link": "https://arxiv.org/abs/2507.12043v1",
          "size": "433kb",
          "version": "v1"
        }
      ],
      "title": "Information-Theoretic Generalization Bounds of Replay-based Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12043",
        "HTML": "https://arxiv.org/html/2507.12043v1",
        "PDF": "https://arxiv.org/pdf/2507.12043"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper is about continual learning, which can be related to reinforcement learning, the focus is on theoretical generalization bounds rather than data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12047",
      "abstract": "In this paper, we study the problem of pathfinding on traversal-dependent graphs, i.e., graphs whose edges change depending on the previously visited vertices. In particular, we study \\emph{self-deleting graphs}, introduced by Carmesin et al. (Sarah Carmesin, David Woller, David Parker, Miroslav Kulich, and Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson problems with traversal-dependent edge deletion. J. Comput. Sci.), which consist of a graph $G=(V, E)$ and a function $f\\colon V\\rightarrow 2^E$, where $f(v)$ is the set of edges that will be deleted after visiting the vertex $v$. In the \\textsc{(Shortest) Self-Deleting $s$-$t$-path} problem we are given a self-deleting graph and its vertices $s$ and $t$, and we are asked to find a (shortest) path from $s$ to $t$, such that it does not traverse an edge in $f(v)$ after visiting $v$ for any vertex $v$.\n  We prove that \\textsc{Self-Deleting $s$-$t$-path} is NP-hard even if the given graph is outerplanar, bipartite, has maximum degree $3$, bandwidth $2$ and $|f(v)|\\leq 1$ for each vertex $v$. We show that \\textsc{Shortest Self-Deleting $s$-$t$-path} is W[1]-complete parameterized by the length of the sought path and that \\textsc{Self-Deleting $s$-$t$-path} is \\W{1}-complete parameterized by the vertex cover number, feedback vertex set number and treedepth. We also show that the problem becomes FPT when we parameterize by the maximum size of $f(v)$ and several structural parameters. Lastly, we show that the problem does not admit a polynomial kernel even for parameterization by the vertex cover number and the maximum size of $f(v)$ combined already on 2-outerplanar graphs.",
      "authors": [
        "Michal Dvo\\v{r}\\'ak",
        "Du\\v{s}an Knop",
        "Michal Opler",
        "Jan Pokorn\\'y",
        "Ond\\v{r}ej Such\\'y",
        "Krisztina Szil\\'agyi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:07:57+00:00",
          "link": "https://arxiv.org/abs/2507.12047v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "Pathfinding in Self-Deleting Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12047",
        "HTML": "https://arxiv.org/html/2507.12047v1",
        "PDF": "https://arxiv.org/pdf/2507.12047"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper studies pathfinding in self-deleting graphs, which is not relevant to reinforcement learning or any aspects of data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12049",
      "abstract": "VAD is a critical field in machine learning focused on identifying deviations from normal patterns in images, often challenged by the scarcity of anomalous data and the need for unsupervised training. To accelerate research and deployment in this domain, we introduce MoViAD, a comprehensive and highly modular library designed to provide fast and easy access to state-of-the-art VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array of scenarios, including continual, semi-supervised, few-shots, noisy, and many more. In addition, it addresses practical deployment challenges through dedicated Edge and IoT settings, offering optimized models and backbones, along with quantization and compression utilities for efficient on-device execution and distributed inference. MoViAD integrates a selection of backbones, robust evaluation VAD metrics (pixel-level and image-level) and useful profiling tools for efficiency analysis. The library is designed for fast, effortless deployment, enabling machine learning engineers to easily use it for their specific setup with custom models, datasets, and backbones. At the same time, it offers the flexibility and extensibility researchers need to develop and experiment with new methods.",
      "authors": [
        "Manuel Barusco and Francesco Borsatti and Arianna Stropeni and Davide Dalle Pezze and Gian Antonio Susto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:10:38+00:00",
          "link": "https://arxiv.org/abs/2507.12049v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "MoViAD: Modular Visual Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12049",
        "HTML": "https://arxiv.org/html/2507.12049v1",
        "PDF": "https://arxiv.org/pdf/2507.12049"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visual anomaly detection (VAD) and introduces MoViAD, a library for accessing VAD models and datasets. It does not discuss any aspects related to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12050",
      "abstract": "As face recognition systems (FRS) become more widely used, user privacy becomes more important. A key privacy issue in FRS is protecting the user's face template, as the characteristics of the user's face image can be recovered from the template. Although recent advances in cryptographic tools such as homomorphic encryption (HE) have provided opportunities for securing the FRS, HE cannot be used directly with FRS in an efficient plug-and-play manner. In particular, although HE is functionally complete for arbitrary programs, it is basically designed for algebraic operations on encrypted data of predetermined shape, such as a polynomial ring. Thus, a non-tailored combination of HE and the system can yield very inefficient performance, and many previous HE-based face template protection methods are hundreds of times slower than plain systems without protection. In this study, we propose IDFace, a new HE-based secure and efficient face identification method with template protection. IDFace is designed on the basis of two novel techniques for efficient searching on a (homomorphically encrypted) biometric database with an angular metric. The first technique is a template representation transformation that sharply reduces the unit cost for the matching test. The second is a space-efficient encoding that reduces wasted space from the encryption algorithm, thus saving the number of operations on encrypted templates. Through experiments, we show that IDFace can identify a face template from among a database of 1M encrypted templates in 126ms, showing only 2X overhead compared to the identification over plaintexts.",
      "authors": [
        "Sunpill Kim",
        "Seunghun Paik",
        "Chanwoo Hwang",
        "Dongsoo Kim",
        "Junbum Shin",
        "Jae Hong Seo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:10:40+00:00",
          "link": "https://arxiv.org/abs/2507.12050v1",
          "size": "4497kb",
          "version": "v1"
        }
      ],
      "title": "IDFace: Face Template Protection for Efficient and Secure Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12050",
        "HTML": "https://arxiv.org/html/2507.12050v1",
        "PDF": "https://arxiv.org/pdf/2507.12050"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "IDFace is about securing face templates in face recognition systems using homomorphic encryption. The paper does not address reinforcement learning or data processing related to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12052",
      "abstract": "This paper addresses the problem of distributed resilient state estimation and control for linear time-invariant systems in the presence of malicious false data injection sensor attacks and bounded noise. We consider a system operator (defender) capable of deploying cybersecurity measures to counteract the sensor compromises. Although such measures enhance resilience against adversarial attacks, they may incur substantial costs; hence, it is crucial to select countermeasures to balance resilience gains and cost efficiency strategically. We first demonstrate that the system's resilience against attacks is maximized through the appropriate implementation of security measures, implying that no attacker can execute undetectable sensor attacks. Building on this analysis, we propose an algorithm that identifies the optimal security measure. While determining this measure is NP-hard in general, we also derive sufficient conditions under which efficient computation is feasible. Furthermore, we develop a distributed resilient state estimation and control scheme informed by the optimal security measure and establish conditions that guarantee bounded estimation and control errors. Finally, we validate the efficacy of our approach via numerical simulations of a vehicle platooning scenario.",
      "authors": [
        "Takumi Shinohara",
        "Karl H. Johansson",
        "Henrik Sandberg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:11:09+00:00",
          "link": "https://arxiv.org/abs/2507.12052v1",
          "size": "1133kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Resilient State Estimation and Control with Strategically Implemented Security Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12052",
        "HTML": "https://arxiv.org/html/2507.12052v1",
        "PDF": "https://arxiv.org/pdf/2507.12052"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses security measures for distributed state estimation and control in systems facing sensor attacks. It does not cover reinforcement learning or its data processing needs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12053",
      "abstract": "The mobility patterns of people in cities evolve alongside changes in land use and population. This makes it crucial for urban planners to simulate and analyze human mobility patterns for purposes such as transportation optimization and sustainable urban development. Existing generative models borrowed from machine learning rely heavily on historical trajectories and often overlook evolving factors like changes in population density and land use. Mechanistic approaches incorporate population density and facility distribution but assume static scenarios, limiting their utility for future projections where historical data for calibration is unavailable. This study introduces a novel, data-driven approach for generating origin-destination mobility flows tailored to simulated urban scenarios. Our method leverages adaptive factors such as dynamic region sizes and land use archetypes, and it utilizes conditional generative adversarial networks (cGANs) to blend historical data with these adaptive parameters. The approach facilitates rapid mobility flow generation with adjustable spatial granularity based on regions of interest, without requiring extensive calibration data or complex behavior modeling. The promising performance of our approach is demonstrated by its application to mobile phone data from Singapore, and by its comparison with existing methods.",
      "authors": [
        "Seanglidet Yean",
        "Jiazu Zhou",
        "Bu-Sung Lee",
        "Markus Schl\\\"apfer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:12:38+00:00",
          "link": "https://arxiv.org/abs/2507.12053v1",
          "size": "1114kb",
          "version": "v1"
        }
      ],
      "title": "FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12053",
        "HTML": "https://arxiv.org/html/2507.12053v1",
        "PDF": "https://arxiv.org/pdf/2507.12053"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "FloGAN introduces a method for generating urban mobility flows using conditional GANs. It does not relate to reinforcement learning or its data processing, focusing instead on urban simulation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12054",
      "abstract": "This paper explores the economic interactions within modern crowdsourcing markets. In these markets, employers issue requests for tasks, platforms facilitate the recruitment of crowd workers, and workers complete tasks for monetary rewards. Recognizing that these roles serve distinct functions within the ecosystem, we introduce a three-party model that distinguishes among the principal (the requester), the intermediary (the platform), and the pool of agents (the workers). The principal, unable to directly engage with agents, relies on the intermediary to recruit and incentivize them. This interaction unfolds in two stages: first, the principal designs a profit-sharing contract with the intermediary; second, the intermediary implements a mechanism to select an agent to complete the delegated task.\n  We analyze the proposed model as an extensive-form Stackelberg game. Our contributions are fourfold: (1) We fully characterize the subgame perfect equilibrium. In particular, we reduce the principal's contract design problem to a novel auction-theoretic formulation we term virtual value pricing, and reveals that linear contracts are optimal even when the task have multiple outcomes and agents' cost distributions are asymmetric. (2) To quantify the principal's utility loss from delegation and information asymmetry, we introduce the price of double marginalization (PoDM) and the classical price of anarchy (PoA), and derive tight or nearly tight bounds on both ratios under regular and monotone hazard rate (MHR) distributions. (3) We further examine these two ratios in a natural setting where the intermediary is restricted to anonymous pricing mechanisms, and show that similar qualitative insights continue to hold. (4) Finally, we extend our results on both ratios to a robust framework that accommodates scenarios in which the principal lacks precise information about the market size.",
      "authors": [
        "Tian Bai",
        "Yiding Feng",
        "Yaohao Liu",
        "Mengfan Ma",
        "Mingyu Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:12:40+00:00",
          "link": "https://arxiv.org/abs/2507.12054v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Contracting with a Mechanism Designer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12054",
        "HTML": "https://arxiv.org/html/2507.12054v1",
        "PDF": "https://arxiv.org/pdf/2507.12054"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper examines economic interactions in crowdsourcing markets, focusing on contract design and mechanism selection. It does not involve reinforcement learning or relevant data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12059",
      "abstract": "We investigate the abilities of 28 Large language Models (LLMs) to reason about cardinal directions (CDs) using a benchmark generated from a set of templates, extensively testing an LLM's ability to determine the correct CD given a particular scenario. The templates allow for a number of degrees of variation such as means of locomotion of the agent involved, and whether set in the first, second or third person. Even the newer Large Reasoning Models are unable to reliably determine the correct CD for all questions. This paper summarises and extends earlier work presented at COSIT-24.",
      "authors": [
        "Anthony G Cohn and Robert E Blackwell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:16:36+00:00",
          "link": "https://arxiv.org/abs/2507.12059v1",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12059",
        "HTML": "https://arxiv.org/html/2507.12059v1",
        "PDF": "https://arxiv.org/pdf/2507.12059"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the reasoning abilities of large language models concerning cardinal directions, without addressing any aspects of data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12060",
      "abstract": "Face anti-spoofing (FAS) aims to construct a robust system that can withstand diverse attacks. While recent efforts have concentrated mainly on cross-domain generalization, two significant challenges persist: limited semantic understanding of attack types and training redundancy across domains. We address the first by integrating vision-language models (VLMs) to enhance the perception of visual input. For the second challenge, we employ a meta-domain strategy to learn a unified model that generalizes well across multiple domains. Our proposed InstructFLIP is a novel instruction-tuned framework that leverages VLMs to enhance generalization via textual guidance trained solely on a single domain. At its core, InstructFLIP explicitly decouples instructions into content and style components, where content-based instructions focus on the essential semantics of spoofing, and style-based instructions consider variations related to the environment and camera characteristics. Extensive experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA models in accuracy and substantially reducing training redundancy across diverse domains in FAS. Project website is available at https://kunkunlin1221.github.io/InstructFLIP.",
      "authors": [
        "Kun-Hsiang Lin and Yu-Wen Tseng and Kang-Yang Huang and Jhih-Ciang Wu and Wen-Huang Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:16:51+00:00",
          "link": "https://arxiv.org/abs/2507.12060v1",
          "size": "1968kb",
          "version": "v1"
        }
      ],
      "title": "InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12060",
        "HTML": "https://arxiv.org/html/2507.12060v1",
        "PDF": "https://arxiv.org/pdf/2507.12060"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper centers around face anti-spoofing using vision-language models and instruction tuning, which is unrelated to reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12061",
      "abstract": "Modern Security Orchestration, Automation, and Response (SOAR) platforms must rapidly adapt to continuously evolving cyber attacks. Intent-Based Networking has emerged as a promising paradigm for cyber attack mitigation through high-level declarative intents, which offer greater flexibility and persistency than procedural actions. In this paper, we bridge the gap between two active research directions: Intent-Based Cyber Defense and Autonomic Cyber Defense, by proposing a unified, ontology-driven security intent definition leveraging the MITRE-D3FEND cybersecurity ontology. We also propose a general two-tiered methodology for integrating such security intents into decision-theoretic Autonomic Cyber Defense systems, enabling hierarchical and context-aware automated response capabilities. The practicality of our approach is demonstrated through a concrete use case, showcasing its integration within next-generation Security Orchestration, Automation, and Response platforms.",
      "authors": [
        "Zequan Huang",
        "Jacques Robin",
        "Nicolas Herbaut",
        "Nourh\\`ene Ben Rabah and B\\'en\\'edicte Le Grand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:17:53+00:00",
          "link": "https://arxiv.org/abs/2507.12061v1",
          "size": "1410kb",
          "version": "v1"
        }
      ],
      "title": "Toward an Intent-Based and Ontology-Driven Autonomic Security Response in Security Orchestration Automation and Response",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12061",
        "PDF": "https://arxiv.org/pdf/2507.12061"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work is focused on cybersecurity and intent-based networking, without linking its contributions to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12062",
      "abstract": "Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint specific moments and assess clip-wise relevance based on the text query. While DETR-based joint frameworks have made significant strides, there remains untapped potential in harnessing the intricate relationships between temporal motion and spatial semantics within video content. In this paper, we propose the Motion-Semantics DETR (MS-DETR), a framework that captures rich motion-semantics features through unified learning for MR/HD tasks. The encoder first explicitly models disentangled intra-modal correlations within motion and semantics dimensions, guided by the given text queries. Subsequently, the decoder utilizes the task-wise correlation across temporal motion and spatial semantics dimensions to enable precise query-guided localization for MR and refined highlight boundary delineation for HD. Furthermore, we observe the inherent sparsity dilemma within the motion and semantics dimensions of MR/HD datasets. To address this issue, we enrich the corpus from both dimensions by generation strategies and propose contrastive denoising learning to ensure the above components learn robustly and effectively. Extensive experiments on four MR/HD benchmarks demonstrate that our method outperforms existing state-of-the-art models by a margin. Our code is available at https://github.com/snailma0229/MS-DETR.git.",
      "authors": [
        "Hongxu Ma",
        "Guanshuo Wang",
        "Fufu Yu",
        "Qiong Jia",
        "Shouhong Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:18:18+00:00",
          "link": "https://arxiv.org/abs/2507.12062v1",
          "size": "4774kb",
          "version": "v1"
        }
      ],
      "title": "MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12062",
        "HTML": "https://arxiv.org/html/2507.12062v1",
        "PDF": "https://arxiv.org/pdf/2507.12062"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses motion-semantics feature learning for video tasks and addresses data enrichment issues, which could marginally relate to RL data processing concepts through data augmentation strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12063",
      "abstract": "A wide variety of information is disseminated through social media, and content that spreads at scale can have tangible effects on the real world. To curb the spread of harmful content and promote the dissemination of reliable information, research on cascade graph mining has attracted increasing attention. A promising approach in this area is Contrastive Cascade Graph Learning (CCGL). One important task in cascade graph mining is cascade classification, which involves categorizing cascade graphs based on their structural characteristics. Although CCGL is expected to be effective for this task, its performance has not yet been thoroughly evaluated. This study aims to investigate the effectiveness of CCGL for cascade classification. Our findings demonstrate the strong performance of CCGL in capturing platform- and model-specific structural patterns in cascade graphs, highlighting its potential for a range of downstream information diffusion analysis tasks.",
      "authors": [
        "Naoki Shibao",
        "Sho Tsugawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:20:44+00:00",
          "link": "https://arxiv.org/abs/2507.12063v1",
          "size": "85kb",
          "version": "v1"
        }
      ],
      "title": "Contrastive Cascade Graph Learning for Classifying Real and Synthetic Information Diffusion Patterns",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12063",
        "PDF": "https://arxiv.org/pdf/2507.12063"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates information diffusion using cascade graph learning, which is not connected to reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12064",
      "abstract": "This submission to the binary AI detection task is based on a modular stylometric pipeline, where: public spaCy models are used for text preprocessing (including tokenisation, named entity recognition, dependency parsing, part-of-speech tagging, and morphology annotation) and extracting several thousand features (frequencies of n-grams of the above linguistic annotations); light-gradient boosting machines are used as the classifier. We collect a large corpus of more than 500 000 machine-generated texts for the classifier's training. We explore several parameter options to increase the classifier's capacity and take advantage of that training set. Our approach follows the non-neural, computationally inexpensive but explainable approach found effective previously.",
      "authors": [
        "Jeremi K. Ochab",
        "Mateusz Matias",
        "Tymoteusz Boba",
        "Tomasz Walkowiak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:21:20+00:00",
          "link": "https://arxiv.org/abs/2507.12064v1",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "title": "StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12064",
        "HTML": "https://arxiv.org/html/2507.12064v1",
        "PDF": "https://arxiv.org/pdf/2507.12064"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper describes a modular stylometric pipeline using gradient-boosted trees for AI detection. It focuses on text preprocessing and feature extraction unrelated to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12067",
      "abstract": "Sidewalk delivery robots are a promising solution for urban freight distribution, reducing congestion compared to trucks and providing a safer, higher-capacity alternative to drones. However, unreliable travel times on sidewalks due to pedestrian density, obstacles, and varying infrastructure conditions can significantly affect their efficiency. This study addresses the robust route planning problem for sidewalk robots, explicitly accounting for travel time uncertainty due to varying sidewalk conditions. Optimization is integrated with simulation to reproduce the effect of obstacles and pedestrian flows and generate realistic travel times. The study investigates three different approaches to derive uncertainty sets, including budgeted, ellipsoidal, and support vector clustering (SVC)-based methods, along with a distributionally robust method to solve the shortest path (SP) problem. A realistic case study reproducing pedestrian patterns in Stockholm's city center is used to evaluate the efficiency of robust routing across various robot designs and environmental conditions. The results show that, when compared to a conventional SP, robust routing significantly enhances operational reliability under variable sidewalk conditions. The Ellipsoidal and DRSP approaches outperform the other methods, yielding the most efficient paths in terms of average and worst-case delay. Sensitivity analyses reveal that robust approaches consistently outperform the conventional SP, particularly for sidewalk delivery robots that are wider, slower, and have more conservative navigation behaviors. These benefits are even more pronounced in adverse weather conditions and high pedestrian congestion scenarios.",
      "authors": [
        "Xing Tong and Michele D. Simoni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:24:19+00:00",
          "link": "https://arxiv.org/abs/2507.12067v1",
          "size": "11791kb",
          "version": "v1"
        }
      ],
      "title": "Robust Route Planning for Sidewalk Delivery Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12067",
        "HTML": "https://arxiv.org/html/2507.12067v1",
        "PDF": "https://arxiv.org/pdf/2507.12067"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with robust route planning for sidewalk delivery robots focusing on optimization under uncertainty, without any mention or contribution to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12070",
      "abstract": "This paper describes a novel methodology for determining representational alignment, developed upon the existing Spotlight Resonance method. Using this, it is found that algebraic symmetries of network primitives are a strong predictor for task-agnostic structure in representations. Particularly, this new tool is used to gain insight into how discrete representations can form and arrange in autoencoder models, through an ablation study where only the activation function is altered. Representations are found to tend to discretise when the activation functions are defined through a discrete algebraic permutation-equivariant symmetry. In contrast, they remain continuous under a continuous algebraic orthogonal-equivariant definition. These findings corroborate the hypothesis that functional form choices can carry unintended inductive biases which produce task-independent artefactual structures in representations, particularly that contemporary forms induce discretisation of otherwise continuous structure -- a quantisation effect. Moreover, this supports a general causal model for one mode in which discrete representations may form, and could constitute a prerequisite for downstream interpretability phenomena, including grandmother neurons, discrete coding schemes, general linear features and possibly Superposition. Hence, this tool and proposed mechanism for the influence of functional form on representations may provide several insights into emergent interpretability research. Finally, preliminary results indicate that quantisation of representations appears to correlate with a measurable increase in reconstruction error, reinforcing previous conjectures that this collapse can be detrimental.",
      "authors": [
        "George Bird"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:27:54+00:00",
          "link": "https://arxiv.org/abs/2507.12070v1",
          "size": "25970kb",
          "version": "v1"
        }
      ],
      "title": "Emergence of Quantised Representations Isolated to Anisotropic Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12070",
        "HTML": "https://arxiv.org/html/2507.12070v1",
        "PDF": "https://arxiv.org/pdf/2507.12070"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates the emergent properties of quantized representations in autoencoders by altering activation functions, which does not involve reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12073",
      "abstract": "Consider an ensemble of regular generalized LDPC (GLDPC) codes and assume that the same component code is associated with each parity check node. To decode a GLDPC code from the ensemble, we use the bit flipping bounded distance decoding algorithm, which is an extension of the bit flipping algorithm for LDPC codes. Previous work has shown conditions, under which, for a typical code in the ensemble with blocklength sufficiently large, a positive constant fraction of worst case errors can be corrected. In this work we first show that these requirements can be relaxed for ensembles with small left degrees. While previous work on GLDPC codes has considered expander graph arguments, our analysis formulates a necessary condition that the Tanner graph needs to satisfy for a failure event and then shows that the probability of this event vanishes for a sufficiently large blocklength. We then extend the analysis to random error correction and derive a lower bound on the fraction of random errors that can be corrected asymptotically. We discuss the extension of our results to non-binary GLDPC codes and present numerical examples.",
      "authors": [
        "David Burshtein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:30:48+00:00",
          "link": "https://arxiv.org/abs/2507.12073v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "On the error correction of iterative bounded distance decoding of generalized LDPC codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12073",
        "HTML": "https://arxiv.org/html/2507.12073v1",
        "PDF": "https://arxiv.org/pdf/2507.12073"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on error correction and decoding of generalized LDPC codes, with no mention or relevance to data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12075",
      "abstract": "Coreference Resolution systems are typically evaluated on benchmarks containing small- to medium-scale documents. When it comes to evaluating long texts, however, existing benchmarks, such as LitBank, remain limited in length and do not adequately assess system capabilities at the book scale, i.e., when co-referring mentions span hundreds of thousands of tokens. To fill this gap, we first put forward a novel automatic pipeline that produces high-quality Coreference Resolution annotations on full narrative texts. Then, we adopt this pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with an average document length of more than 200,000 tokens. We carry out a series of experiments showing the robustness of our automatic procedure and demonstrating the value of our resource, which enables current long-document coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full books. Moreover, we report on the new challenges introduced by this unprecedented book-scale setting, highlighting that current models fail to deliver the same performance they achieve on smaller documents. We release our data and code to encourage research and development of new book-scale Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.",
      "authors": [
        "Giuliano Martinelli",
        "Tommaso Bonomo",
        "Pere-Llu\\'is Huguet Cabot",
        "Roberto Navigli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:35:38+00:00",
          "link": "https://arxiv.org/abs/2507.12075v1",
          "size": "9346kb",
          "version": "v1"
        }
      ],
      "title": "BOOKCOREF: Coreference Resolution at Book Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12075",
        "HTML": "https://arxiv.org/html/2507.12075v1",
        "PDF": "https://arxiv.org/pdf/2507.12075"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a coreference resolution benchmark for long texts, with no connection to reinforcement learning or data processing within RL environments."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12079",
      "abstract": "This paper presents an intervention study on the effects of the combined methods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3) simplified gamification and (4) formative feedback on university students' Maths learning driven by large language models (LLMs). We call our approach Mathematics Explanations through Games by AI LLMs (MEGA). Some students struggle with Maths and as a result avoid Math-related discipline or subjects despite the importance of Maths across many fields, including signal processing. Oftentimes, students' Maths difficulties stem from suboptimal pedagogy. We compared the MEGA method to the traditional step-by-step (CoT) method to ascertain which is better by using a within-group design after randomly assigning questions for the participants, who are university students. Samples (n=60) were randomly drawn from each of the two test sets of the Grade School Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH) datasets, based on the error margin of 11%, the confidence level of 90%, and a manageable number of samples for the student evaluators. These samples were used to evaluate two capable LLMs at length (Generative Pretrained Transformer 4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for capability. The results showed that students agree in more instances that the MEGA method is experienced as better for learning for both datasets. It is even much better than the CoT (47.5% compared to 26.67%) in the more difficult MATH dataset, indicating that MEGA is better at explaining difficult Maths problems.",
      "authors": [
        "Tosin Adewumi",
        "Foteini Simistira Liwicki",
        "Marcus Liwicki",
        "Viktor Gardelli",
        "Lama Alkhaled and Hamam Mokayed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:39:56+00:00",
          "link": "https://arxiv.org/abs/2507.12079v1",
          "size": "1747kb",
          "version": "v1"
        }
      ],
      "title": "Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12079",
        "HTML": "https://arxiv.org/html/2507.12079v1",
        "PDF": "https://arxiv.org/pdf/2507.12079"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on educational methods using LLMs to improve math learning, not on reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12082",
      "abstract": "This paper proposes a simple and accurate monomial-like equation for estimating the inductance of Multilayer Rectangle-shaped Planar Windings (MLRPWs) for high-frequency, high-power applications. The equation consists of the power product of the geometrical dimensions, raised at individual power coefficients. The coefficients are generated via Multiple Linear Regression (MLR), based on a large set of approximately 6,000 simulated windings, with an 80/20 training/evaluation sample ratio. The resulting mean error value is 0%, with a standard deviation below 1.8%. The accuracy of the inductance estimation is confirmed on several experimental samples, with dimensions both within and outside the initial training dataset.",
      "authors": [
        "Theofilos Papadopoulos and Antonios Antonopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:42:13+00:00",
          "link": "https://arxiv.org/abs/2507.12082v1",
          "size": "6267kb",
          "version": "v1"
        }
      ],
      "title": "Inductance Estimation for High-Power Multilayer Rectangle Planar Windings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12082",
        "HTML": "https://arxiv.org/html/2507.12082v1",
        "PDF": "https://arxiv.org/pdf/2507.12082"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses inductance estimation for planar windings and does not relate to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12083",
      "abstract": "Motion forecasting for on-road traffic agents presents both a significant challenge and a critical necessity for ensuring safety in autonomous driving systems. In contrast to most existing data-driven approaches that directly predict future trajectories, we rethink this task from a planning perspective, advocating a \"First Reasoning, Then Forecasting\" strategy that explicitly incorporates behavior intentions as spatial guidance for trajectory prediction. To achieve this, we introduce an interpretable, reward-driven intention reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL) scheme. Our method first encodes traffic agents and scene elements into a unified vectorized representation, then aggregates contextual features through a query-centric paradigm. This enables the derivation of a reward distribution, a compact yet informative representation of the target agent's behavior within the given scene context via IRL. Guided by this reward heuristic, we perform policy rollouts to reason about multiple plausible intentions, providing valuable priors for subsequent trajectory generation. Finally, we develop a hierarchical DETR-like decoder integrated with bidirectional selective state space models to produce accurate future trajectories along with their associated probabilities. Extensive experiments on the large-scale Argoverse and nuScenes motion forecasting datasets demonstrate that our approach significantly enhances trajectory prediction confidence, achieving highly competitive performance relative to state-of-the-art methods.",
      "authors": [
        "Muleilan Pei",
        "Shaoshuai Shi",
        "Xuesong Chen",
        "Xu Liu",
        "Shaojie Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:46:17+00:00",
          "link": "https://arxiv.org/abs/2507.12083v1",
          "size": "471kb",
          "version": "v1"
        }
      ],
      "title": "Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12083",
        "HTML": "https://arxiv.org/html/2507.12083v1",
        "PDF": "https://arxiv.org/pdf/2507.12083"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper introduces a trajectory prediction method using inverse reinforcement learning (IRL), which involves encoding traffic data into a representation used for predicting trajectories. While RL techniques are used, the primary focus is not on data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12084",
      "abstract": "Smart contracts play a pivotal role in blockchain ecosystems, and fuzzing remains an important approach to securing smart contracts. Even though mutation scheduling is a key factor influencing fuzzing effectiveness, existing fuzzers have primarily explored seed scheduling and generation, while mutation scheduling has been rarely addressed by prior work. In this work, we propose a Large Language Models (LLMs)-based Multi-feedback Smart Contract Fuzzing framework (LLAMA) that integrates LLMs, evolutionary mutation strategies, and hybrid testing techniques. Key components of the proposed LLAMA include: (i) a hierarchical prompting strategy that guides LLMs to generate semantically valid initial seeds, coupled with a lightweight pre-fuzzing phase to select high-potential inputs; (ii) a multi-feedback optimization mechanism that simultaneously improves seed generation, seed selection, and mutation scheduling by leveraging runtime coverage and dependency feedback; and (iii) an evolutionary fuzzing engine that dynamically adjusts mutation operator probabilities based on effectiveness, while incorporating symbolic execution to escape stagnation and uncover deeper vulnerabilities. Our experiments demonstrate that LLAMA outperforms state-of-the-art fuzzers in both coverage and vulnerability detection. Specifically, it achieves 91% instruction coverage and 90% branch coverage, while detecting 132 out of 148 known vulnerabilities across diverse categories. These results highlight LLAMA's effectiveness, adaptability, and practicality in real-world smart contract security testing scenarios.",
      "authors": [
        "Keke Gai",
        "Haochen Liang",
        "Jing Yu",
        "Liehuang Zhu",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.12084v1",
          "size": "1666kb",
          "version": "v1"
        }
      ],
      "title": "LLAMA: Multi-Feedback Smart Contract Fuzzing Framework with LLM-Guided Seed Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12084",
        "HTML": "https://arxiv.org/html/2507.12084v1",
        "PDF": "https://arxiv.org/pdf/2507.12084"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses fuzzing frameworks for smart contracts using LLMs and evolutionary strategies, not reinforcement learning or related data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12087",
      "abstract": "Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned Aerial Vehicle (UAV) perspective is a highly challenging computer vision task. The difficulty stems from three main sources: the extreme scarcity of target appearance features, the complex motion entanglement caused by the combined dynamics of the camera and the targets themselves, and the frequent occlusions and identity ambiguity arising from dense flocking behavior. This paper details our championship-winning solution in the MVA 2025 \"Finding Birds\" Small Multi-Object Tracking Challenge (SMOT4SB), which adopts the tracking-by-detection paradigm with targeted innovations at both the detection and association levels. On the detection side, we propose a systematic training enhancement framework named \\textbf{SliceTrain}. This framework, through the synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic augmentation, effectively addresses the problem of insufficient learning for small objects in high-resolution image training. On the tracking side, we designed a robust tracker that is completely independent of appearance information. By integrating a \\textbf{motion direction maintenance (EMA)} mechanism and an \\textbf{adaptive similarity metric} combining \\textbf{bounding box expansion and distance penalty} into the OC-SORT framework, our tracker can stably handle irregular motion and maintain target identities. Our method achieves state-of-the-art performance on the SMOT4SB public test set, reaching an SO-HOTA score of \\textbf{55.205}, which fully validates the effectiveness and advancement of our framework in solving complex real-world SMOT problems. The source code will be made available at https://github.com/Salvatore-Love/YOLOv8-SMOT.",
      "authors": [
        "Xiang Yu and Xinyao Liu and Guang Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:51:19+00:00",
          "link": "https://arxiv.org/abs/2507.12087v1",
          "size": "362kb",
          "version": "v1"
        }
      ],
      "title": "YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12087",
        "HTML": "https://arxiv.org/html/2507.12087v1",
        "PDF": "https://arxiv.org/pdf/2507.12087"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on computer vision techniques, specifically improving real-time tracking of small objects from UAVs using innovations at the detection and association levels, but it does not address reinforcement learning or data processing in this context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12090",
      "abstract": "We propose MambaRate, which predicts Mean Opinion Scores (MOS) with limited bias regarding the sampling rate of the waveform under evaluation. It is designed for Track 3 of the AudioMOS Challenge 2025, which focuses on predicting MOS for speech in high sampling frequencies. Our model leverages self-supervised embeddings and selective state space modeling. The target ratings are encoded in a continuous representation via Gaussian radial basis functions (RBF). The results of the challenge were based on the system-level Spearman's Rank Correllation Coefficient (SRCC) metric. An initial MambaRate version (T16 system) outperformed the pre-trained baseline (B03) by ~14% in a few-shot setting without pre-training. T16 ranked fourth out of five in the challenge, differing by ~6% from the winning system. We present additional results on the BVCC dataset as well as ablations with different representations as input, which outperform the initial T16 version.",
      "authors": [
        "Panos Kakoulidis",
        "Iakovi Alexiou",
        "Junkwang Oh",
        "Gunu Jho",
        "Inchul Hwang",
        "Pirros Tsiakoulis",
        "Aimilios Chalamandaris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:53:29+00:00",
          "link": "https://arxiv.org/abs/2507.12090v1",
          "size": "249kb",
          "version": "v1"
        }
      ],
      "title": "MambaRate: Speech Quality Assessment Across Different Sampling Rates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12090",
        "HTML": "https://arxiv.org/html/2507.12090v1",
        "PDF": "https://arxiv.org/pdf/2507.12090"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with predicting speech quality without bias towards sampling rates using the MambaRate model for audio evaluation, which does not pertain to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12092",
      "abstract": "Cortical lesions (CLs) have emerged as valuable biomarkers in multiple sclerosis (MS), offering high diagnostic specificity and prognostic relevance. However, their routine clinical integration remains limited due to subtle magnetic resonance imaging (MRI) appearance, challenges in expert annotation, and a lack of standardized automated methods. We propose a comprehensive multi-centric benchmark of CL detection and segmentation in MRI. A total of 656 MRI scans, including clinical trial and research data from four institutions, were acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with expert-consensus annotations. We rely on the self-configuring nnU-Net framework, designed for medical imaging segmentation, and propose adaptations tailored to the improved CL detection. We evaluated model generalization through out-of-distribution testing, demonstrating strong lesion detection capabilities with an F1-score of 0.64 and 0.5 in and out of the domain, respectively. We also analyze internal model features and model errors for a better understanding of AI decision-making. Our study examines how data variability, lesion ambiguity, and protocol differences impact model performance, offering future recommendations to address these barriers to clinical adoption. To reinforce the reproducibility, the implementation and models will be publicly accessible and ready to use at https://github.com/Medical-Image-Analysis-Laboratory/ and https://doi.org/10.5281/zenodo.15911797.",
      "authors": [
        "Nataliia Molchanova",
        "Alessandro Cagol",
        "Mario Ocampo-Pineda",
        "Po-Jui Lu",
        "Matthias Weigel",
        "Xinjie Chen",
        "Erin Beck",
        "Charidimos Tsagkas",
        "Daniel Reich",
        "Colin Vanden Bulcke",
        "Anna Stolting",
        "Serena Borrelli",
        "Pietro Maggi",
        "Adrien Depeursinge",
        "Cristina Granziera",
        "Henning Mueller",
        "Pedro M. Gordaliza",
        "Meritxell Bach Cuadra"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:56:11+00:00",
          "link": "https://arxiv.org/abs/2507.12092v1",
          "size": "9164kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12092",
        "HTML": "https://arxiv.org/html/2507.12092v1",
        "PDF": "https://arxiv.org/pdf/2507.12092"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is related to medical imaging and segmentation tasks for cortical lesions using deep learning methods, which are outside the reinforcement learning scope and do not involve RL-specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12093",
      "abstract": "Accurate mapping of individual trees is an important component for precision agriculture in orchards, as it allows autonomous robots to perform tasks like targeted operations or individual tree monitoring. However, creating these maps is challenging because GPS signals are often unreliable under dense tree canopies. Furthermore, standard Simultaneous Localization and Mapping (SLAM) approaches struggle in orchards because the repetitive appearance of trees can confuse the system, leading to mapping errors. To address this, we introduce Tree-SLAM, a semantic SLAM approach tailored for creating maps of individual trees in orchards. Utilizing RGB-D images, our method detects tree trunks with an instance segmentation model, estimates their location and re-identifies them using a cascade-graph-based data association algorithm. These re-identified trunks serve as landmarks in a factor graph framework that integrates noisy GPS signals, odometry, and trunk observations. The system produces maps of individual trees with a geo-localization error as low as 18 cm, which is less than 20\\% of the planting distance. The proposed method was validated on diverse datasets from apple and pear orchards across different seasons, demonstrating high mapping accuracy and robustness in scenarios with unreliable GPS signals.",
      "authors": [
        "David Rapado-Rincon",
        "Gert Kootstra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:56:55+00:00",
          "link": "https://arxiv.org/abs/2507.12093v1",
          "size": "18308kb",
          "version": "v1"
        }
      ],
      "title": "Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12093",
        "HTML": "https://arxiv.org/html/2507.12093v1",
        "PDF": "https://arxiv.org/pdf/2507.12093"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses semantic mapping in orchards for precision agriculture using a SLAM approach, which although a type of learning and mapping method, does not pertain to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12094",
      "abstract": "In many applications, decision-makers must choose between multiple predictive models that may all be miscalibrated. Which model (i.e., predictor) is more \"useful\" in downstream decision tasks? To answer this, our first contribution introduces the notion of the informativeness gap between any two predictors, defined as the maximum normalized payoff advantage one predictor offers over the other across all decision-making tasks. Our framework strictly generalizes several existing notions: it subsumes U-Calibration [KLST-23] and Calibration Decision Loss [HW-24], which compare a miscalibrated predictor to its calibrated counterpart, and it recovers Blackwell informativeness [Bla-51, Bla-53] as a special case when both predictors are perfectly calibrated. Our second contribution is a dual characterization of the informativeness gap, which gives rise to a natural informativeness measure that can be viewed as a relaxed variant of the earth mover's distance (EMD) between two prediction distributions. We show that this measure satisfies natural desiderata: it is complete and sound, and it can be estimated sample-efficiently in the prediction-only access setting. Along the way, we also obtain novel combinatorial structural results when applying this measure to perfectly calibrated predictors.",
      "authors": [
        "Yiding Feng",
        "Wei Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:01:22+00:00",
          "link": "https://arxiv.org/abs/2507.12094v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Measuring Informativeness Gap of (Mis)Calibrated Predictors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12094",
        "HTML": "https://arxiv.org/html/2507.12094v1",
        "PDF": "https://arxiv.org/pdf/2507.12094"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the informativeness gap between predictors in decision-making tasks but does not involve reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12095",
      "abstract": "Accurate 3D reconstruction of vehicles is vital for applications such as vehicle inspection, predictive maintenance, and urban planning. Existing methods like Neural Radiance Fields and Gaussian Splatting have shown impressive results but remain limited by their reliance on dense input views, which hinders real-world applicability. This paper addresses the challenge of reconstructing vehicles from sparse-view inputs, leveraging depth maps and a robust pose estimation architecture to synthesize novel views and augment training data. Specifically, we enhance Gaussian Splatting by integrating a selective photometric loss, applied only to high-confidence pixels, and replacing standard Structure-from-Motion pipelines with the DUSt3R architecture to improve camera pose estimation. Furthermore, we present a novel dataset featuring both synthetic and real-world public transportation vehicles, enabling extensive evaluation of our approach. Experimental results demonstrate state-of-the-art performance across multiple benchmarks, showcasing the method's ability to achieve high-quality reconstructions even under constrained input conditions.",
      "authors": [
        "Davide Di Nucci",
        "Matteo Tomei",
        "Guido Borghi",
        "Luca Ciuffreda",
        "Roberto Vezzani",
        "Rita Cucchiara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:04:35+00:00",
          "link": "https://arxiv.org/abs/2507.12095v1",
          "size": "3223kb",
          "version": "v1"
        }
      ],
      "title": "BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12095",
        "HTML": "https://arxiv.org/html/2507.12095v1",
        "PDF": "https://arxiv.org/pdf/2507.12095"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "While the paper involves data processing for 3D vehicle reconstruction, it does not relate to reinforcement learning or data processing specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12096",
      "abstract": "The classic result by Fortune, Hopcroft, and Wyllie [TCS~'80] states that the directed disjoint paths problem is NP-complete even for two pairs of terminals. Extending this well-known result, we show that the directed disjoint paths problem is NP-complete for any constant congestion $c \\geq 1$ and~$k \\geq 3c-1$ pairs of terminals. This refutes a conjecture by Giannopoulou et al. [SODA~'22], which says that the directed disjoint paths problem with congestion two is polynomial-time solvable for any constant number $k$ of terminal pairs. We then consider the cases that are not covered by this hardness result. The first nontrivial case is $c=2$ and $k = 3$. Our second main result is to show that this case is polynomial-time solvable.",
      "authors": [
        "Matthias Bentert",
        "Dario Cavallaro",
        "Amelie Heindl",
        "Ken-ichi Kawarabayashi",
        "Stephan Kreutzer",
        "Johannes Schr\\\"oder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:05:11+00:00",
          "link": "https://arxiv.org/abs/2507.12096v1",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "title": "The Directed Disjoint Paths Problem with Congestion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12096",
        "HTML": "https://arxiv.org/html/2507.12096v1",
        "PDF": "https://arxiv.org/pdf/2507.12096"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores computational complexity in the context of the directed disjoint paths problem and does not pertain to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12098",
      "abstract": "To mitigate privacy leakage and performance issues in personalized advertising, this paper proposes a framework that integrates federated learning and differential privacy. The system combines distributed feature extraction, dynamic privacy budget allocation, and robust model aggregation to balance model accuracy, communication overhead, and privacy protection. Multi-party secure computing and anomaly detection mechanisms further enhance system resilience against malicious attacks. Experimental results demonstrate that the framework achieves dual optimization of recommendation accuracy and system efficiency while ensuring privacy, providing both a practical solution and a theoretical foundation for applying privacy protection technologies in advertisement recommendation.",
      "authors": [
        "Xiang Li",
        "Yifan Lin",
        "Yuanzhe Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:07:19+00:00",
          "link": "https://arxiv.org/abs/2507.12098v1",
          "size": "2787kb",
          "version": "v1"
        }
      ],
      "title": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12098",
        "PDF": "https://arxiv.org/pdf/2507.12098"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on privacy-preserving frameworks in advertising using federated learning and differential privacy, without any connection to reinforcement learning or RL-specific data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12102",
      "abstract": "In runtime verification, pattern matching, which searches for occurrences of a specific pattern within a word, provides more information than a simple violation detection of the monitored property, by locating concrete evidence of the violation. However, witnessing violations of some properties, particularly hyperproperties, requires evidence across multiple input words or different parts of the same word, which goes beyond the scope of conventional pattern matching. We propose here hyper pattern matching, a generalization of pattern matching over a set of words. Properties of interest include robustness and (non-)interference. As a formalism for patterns, we use nondeterministic asynchronous finite automata (NAAs). We first provide a naive algorithm for hyper pattern matching and then devise several heuristics for better efficiency. Although we prove the NP-completeness of the problem, our implementation HypPAu is able to address several case studies scalable in the length, number of words (or logs) and number of dimensions, suggesting the practical relevance of our approach.",
      "authors": [
        "Masaki Waga",
        "\\'Etienne Andr\\'e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:13:17+00:00",
          "link": "https://arxiv.org/abs/2507.12102v1",
          "size": "197kb",
          "version": "v1"
        }
      ],
      "title": "Hyper pattern matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12102",
        "PDF": "https://arxiv.org/pdf/2507.12102"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on runtime verification and pattern matching using nondeterministic asynchronous finite automata for hyperproperties. It does not involve reinforcement learning or address data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12103",
      "abstract": "Heatwaves pose a significant threat to public health, especially as global warming intensifies. However, current routing systems (e.g., online maps) fail to incorporate shade information due to the difficulty of estimating shades directly from noisy satellite imagery and the limited availability of training data for generative models. In this paper, we address these challenges through two main contributions. First, we build an extensive dataset covering diverse longitude-latitude regions, varying levels of building density, and different urban layouts. Leveraging Blender-based 3D simulations alongside building outlines, we capture building shadows under various solar zenith angles throughout the year and at different times of day. These simulated shadows are aligned with satellite images, providing a rich resource for learning shade patterns. Second, we propose the DeepShade, a diffusion-based model designed to learn and synthesize shade variations over time. It emphasizes the nuance of edge features by jointly considering RGB with the Canny edge layer, and incorporates contrastive learning to capture the temporal change rules of shade. Then, by conditioning on textual descriptions of known conditions (e.g., time of day, solar angles), our framework provides improved performance in generating shade images. We demonstrate the utility of our approach by using our shade predictions to calculate shade ratios for real-world route planning in Tempe, Arizona. We believe this work will benefit society by providing a reference for urban planning in extreme heat weather and its potential practical applications in the environment.",
      "authors": [
        "Longchao Da",
        "Xiangrui Liu",
        "Mithun Shivakoti",
        "Thirulogasankar Pranav Kutralingam",
        "Yezhou Yang",
        "Hua Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:19:12+00:00",
          "link": "https://arxiv.org/abs/2507.12103v1",
          "size": "1606kb",
          "version": "v1"
        }
      ],
      "title": "DeepShade: Enable Shade Simulation by Text-conditioned Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12103",
        "HTML": "https://arxiv.org/html/2507.12103v1",
        "PDF": "https://arxiv.org/pdf/2507.12103"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is about using text-conditioned image generation for simulating shades in urban planning applications. It does not relate to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12104",
      "abstract": "The SaaS paradigm has revolutionized software distribution by offering flexible pricing options to meet diverse customer needs. However, the rapid expansion of the SaaS market has introduced significant complexity for DevOps teams, who must manually manage and evolve pricing structures, an approach that is both time-consuming and prone to errors. The absence of automated tools for pricing analysis restricts the ability to efficiently evaluate, optimize, and scale these models. This paper proposes leveraging intelligent pricing (iPricing), dynamic, machine-readable pricing models, as a solution to these challenges. Intelligent pricing enables competitive analysis, streamlines operational decision-making, and supports continuous pricing evolution in response to market dynamics, leading to improved efficiency and accuracy. We present an LLM-driven approach that automates the transformation of static HTML pricing into iPricing, significantly improving efficiency and consistency while minimizing human error. Our implementation, AI4Pricing2Yaml, features a basic Information Extractor that uses web scraping and LLMs technologies to extract essential pricing components, plans, features, usage limits, and add-ons, from SaaS websites. Validation against a dataset of 30 distinct commercial SaaS, encompassing over 150 intelligent pricings, demonstrates the system's effectiveness in extracting the desired elements across all steps. However, challenges remain in addressing hallucinations, complex structures, and dynamic content. This work highlights the potential of automating intelligent pricing transformation to streamline SaaS pricing management, offering implications for improved consistency and scalability in an increasingly intricate pricing landscape. Future research will focus on refining extraction capabilities and enhancing the system's adaptability to a wider range of SaaS websites.",
      "authors": [
        "Francisco Javier Cavero",
        "Juan C. Alonso",
        "Antonio Ruiz-Cort\\'es"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:20:14+00:00",
          "link": "https://arxiv.org/abs/2507.12104v1",
          "size": "2496kb",
          "version": "v1"
        }
      ],
      "title": "From Static to Intelligent: Evolving SaaS Pricing with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12104",
        "HTML": "https://arxiv.org/html/2507.12104v1",
        "PDF": "https://arxiv.org/pdf/2507.12104"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses intelligent pricing transformation of SaaS using LLMs, which is unrelated to reinforcement learning or any data processing aspects of RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12105",
      "abstract": "Biomedical segmentation networks easily suffer from the unexpected misclassification between foreground and background objects when learning on limited and imperfect medical datasets. Inspired by the strong power of Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric framework, Med-OoD to address this issue by introducing OoD data supervision into fully-supervised biomedical segmentation with none of the following needs: (i) external data sources, (ii) feature regularization objectives, (iii) additional annotations. Our method can be seamlessly integrated into segmentation networks without any modification on the architectures. Extensive experiments show that Med-OoD largely prevents various segmentation networks from the pixel misclassification on medical images and achieves considerable performance improvements on Lizard dataset. We also present an emerging learning paradigm of training a medical segmentation network completely using OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU as test result. We hope this learning paradigm will attract people to rethink the roles of OoD data. Code is made available at https://github.com/StudioYG/Med-OoD.",
      "authors": [
        "Yiquan Gao",
        "Duohui Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:21:45+00:00",
          "link": "https://arxiv.org/abs/2507.12105v1",
          "size": "902kb",
          "version": "v1"
        }
      ],
      "title": "Out-of-distribution data supervision towards biomedical semantic segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12105",
        "PDF": "https://arxiv.org/pdf/2507.12105"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a data-centric framework for biomedical semantic segmentation using Out-of-Distribution (OoD) data supervision. It does not pertain to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12106",
      "abstract": "The efficient design and management of public green spaces is a key factor in promoting the health and well-being of urban population, as emphasized by the WHO, UNEP, and EEA. These areas serve as the \"green lungs\" of the urban ecosystem, playing a vital role in enhancing quality of life thanks to the provision of ecosystem services. In this context, the Smart Green City use case in Campobasso municipality, funded by the Italian Ministry of Enterprises (MIMIT), emerges as an innovative model for the sustainable management of green urban areas through the adoption of an advanced system of emerging technologies integrated and interoperable. The project integrates IoT systems and data-driven governance platforms, enabling real-time monitoring of the health status of trees and green areas via a Decision Support System (DSS). It also facilitates the collection and analysis of data from diverse sources, including weather conditions, air quality, soil moisture, pollution levels. The resulting cloud-based platform supports a holistic real time decision making for green urban managers, technical experts and operational staff. It enables intelligent control and management of urban green spaces using Tree Talker sensors, integrated with soil moisture and water potential monitoring systems. Thanks to predictive models based on machine learning algorithms and real time data provided by IoT sensors, irrigation of public parks can be optimized by providing suggestions on when and how much water to apply. Customized alerts layers are also activated warning users when monitored parameters, such as soil temperature, humidity, or water potential, exceed predefined thresholds. This Use Case demonstrates how digitalization, IoT sensors fusion and technological innovation can support sustainable urban governance, fostering environmental resilience and improving citizens quality of life.",
      "authors": [
        "Antonio Salis",
        "Gabriele Troina",
        "Gianluca Boanelli",
        "Marco Ottaviano",
        "Paola Fortini",
        "Soraya Versace"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:24:07+00:00",
          "link": "https://arxiv.org/abs/2507.12106v1",
          "size": "1194kb",
          "version": "v1"
        }
      ],
      "title": "Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12106",
        "PDF": "https://arxiv.org/pdf/2507.12106"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work involves IoT-driven management of urban green spaces and does not address reinforcement learning or any data processing aspects within the RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12107",
      "abstract": "Adversarial attacks on face recognition systems (FRSs) pose serious security and privacy threats, especially when these systems are used for identity verification. In this paper, we propose a novel method for generating adversarial faces-synthetic facial images that are visually distinct yet recognized as a target identity by the FRS. Unlike iterative optimization-based approaches (e.g., gradient descent or other iterative solvers), our method leverages the structural characteristics of the FRS feature space. We figure out that individuals sharing the same attribute (e.g., gender or race) form an attributed subsphere. By utilizing such subspheres, our method achieves both non-adaptiveness and a remarkably small number of queries. This eliminates the need for relying on transferability and open-source surrogate models, which have been a typical strategy when repeated adaptive queries to commercial FRSs are impossible. Despite requiring only a single non-adaptive query consisting of 100 face images, our method achieves a high success rate of over 93% against AWS's CompareFaces API at its default threshold. Furthermore, unlike many existing attacks that perturb a given image, our method can deliberately produce adversarial faces that impersonate the target identity while exhibiting high-level attributes chosen by the adversary.",
      "authors": [
        "Sunpill Kim",
        "Seunghun Paik",
        "Chanwoo Hwang",
        "Minsu Kim",
        "Jae Hong Seo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.12107v1",
          "size": "10854kb",
          "version": "v1"
        }
      ],
      "title": "Non-Adaptive Adversarial Face Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12107",
        "HTML": "https://arxiv.org/html/2507.12107v1",
        "PDF": "https://arxiv.org/pdf/2507.12107"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating adversarial face images for face recognition systems and does not address reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12108",
      "abstract": "Coordinated online behavior, which spans from beneficial collective actions to harmful manipulation such as disinformation campaigns, has become a key focus in digital ecosystem analysis. Traditional methods often rely on monomodal approaches, focusing on single types of interactions like co-retweets or co-hashtags, or consider multiple modalities independently of each other. However, these approaches may overlook the complex dynamics inherent in multimodal coordination. This study compares different ways of operationalizing the detection of multimodal coordinated behavior. It examines the trade-off between weakly and strongly integrated multimodal models, highlighting the balance between capturing broader coordination patterns and identifying tightly coordinated behavior. By comparing monomodal and multimodal approaches, we assess the unique contributions of different data modalities and explore how varying implementations of multimodality impact detection outcomes. Our findings reveal that not all the modalities provide distinct insights, but that with a multimodal approach we can get a more comprehensive understanding of coordination dynamics. This work enhances the ability to detect and analyze coordinated online behavior, offering new perspectives for safeguarding the integrity of digital platforms.",
      "authors": [
        "Lorenzo Mannocci",
        "Stefano Cresci",
        "Matteo Magnani",
        "Anna Monreale",
        "Maurizio Tesconi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:25:45+00:00",
          "link": "https://arxiv.org/abs/2507.12108v1",
          "size": "4418kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12108",
        "HTML": "https://arxiv.org/html/2507.12108v1",
        "PDF": "https://arxiv.org/pdf/2507.12108"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with multimodal coordinated online behavior and detection strategies, which do not pertain to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12110",
      "abstract": "The exploration-exploitation trade-off constitutes one of the fundamental challenges in reinforcement learning (RL), which is exacerbated in multi-agent reinforcement learning (MARL) due to the exponential growth of joint state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL) method for optimizing cooperative decision-making of connected and autonomous vehicles (CAVs) in mixed traffic. This work presents two primary contributions: First, we construct a game topology tensor for dynamic traffic flow, effectively compressing high-dimensional traffic state information and decrease the search space for MARL algorithms. Second, building upon the designed game topology tensor and using QMIX as the backbone RL algorithm, we establish a topology-enhanced MARL framework incorporating visit counts and agent mutual information. Extensive simulations across varying traffic densities and CAV penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations encompassing training dynamics, exploration patterns, macroscopic traffic performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL successfully balances exploration and exploitation. Consequently, it exhibits superior performance in terms of traffic efficiency, safety, decision smoothness, and task completion. Furthermore, the algorithm demonstrates decision-making rationality comparable to or exceeding that of human drivers in both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is available at \\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.",
      "authors": [
        "Ye Han",
        "Lijun Zhang",
        "Dejian Meng",
        "Zhuang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:27:36+00:00",
          "link": "https://arxiv.org/abs/2507.12110v1",
          "size": "13234kb",
          "version": "v1"
        }
      ],
      "title": "Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12110",
        "HTML": "https://arxiv.org/html/2507.12110v1",
        "PDF": "https://arxiv.org/pdf/2507.12110"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses a topology-enhanced MARL method by constructing a game topology tensor to optimize decision-making, indirectly touching upon data structuring and processing within RL, but data processing is not the core focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12114",
      "abstract": "Dynamic driving scene reconstruction is of great importance in fields like digital twin system and autonomous driving simulation. However, unacceptable degradation occurs when the view deviates from the input trajectory, leading to corrupted background and vehicle models. To improve reconstruction quality on novel trajectory, existing methods are subject to various limitations including inconsistency, deformation, and time consumption. This paper proposes LidarPainter, a one-step diffusion model that recovers consistent driving views from sparse LiDAR condition and artifact-corrupted renderings in real-time, enabling high-fidelity lane shifts in driving scene reconstruction. Extensive experiments show that LidarPainter outperforms state-of-the-art methods in speed, quality and resource efficiency, specifically 7 x faster than StreetCrafter with only one fifth of GPU memory required. LidarPainter also supports stylized generation using text prompts such as \"foggy\" and \"night\", allowing for a diverse expansion of the existing asset library.",
      "authors": [
        "Yuzhou Ji",
        "Ke Ma",
        "Hong Cai",
        "Anchun Zhang",
        "Lizhuang Ma",
        "Xin Tan"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:30:47+00:00",
          "link": "https://arxiv.org/abs/2507.12114v1",
          "size": "7606kb",
          "version": "v1"
        }
      ],
      "title": "LidarPainter: One-Step Away From Any Lidar View To Novel Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12114",
        "HTML": "https://arxiv.org/html/2507.12114v1",
        "PDF": "https://arxiv.org/pdf/2507.12114"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces LidarPainter for reconstructing dynamic driving scenes from LiDAR data, focusing on rendering quality rather than reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12118",
      "abstract": "In recent years, attention has increasingly focused on enhancing user satisfaction with user interfaces, spanning both mobile applications and websites. One fundamental aspect of human-machine interaction is the concept of web usability. In order to assess web usability, the A/B testing technique enables the comparison of data between two designs. Expanding the scope of tests to include the designs being evaluated, in conjunction with the involvement of both real and fictional users, presents a challenge for which few online tools offer support. We propose a methodology for web usability evaluation based on user-centered approaches such as design thinking and linguistic decision-making, named Linguistic Decision-Making for Web Usability Evaluation. This engages people in role-playing scenarios and conducts a number of usability tests, including the widely recognized System Usability Scale. We incorporate the methodology into a decision support system based on A/B testing. We use real users in a case study to assess three Moodle platforms at the University of Guadalajara, Mexico.",
      "authors": [
        "Noe Zerme\\~no",
        "Cristina Zuheros",
        "Lucas Daniel Del Rosso Calache",
        "Francisco Herrera",
        "Rosana Montes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:37:29+00:00",
          "link": "https://arxiv.org/abs/2507.12118v1",
          "size": "1486kb",
          "version": "v1"
        }
      ],
      "title": "An Online A/B Testing Decision Support System for Web Usability Assessment Based on a Linguistic Decision-making Methodology: Case of Study a Virtual Learning Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12118",
        "HTML": "https://arxiv.org/html/2507.12118v1",
        "PDF": "https://arxiv.org/pdf/2507.12118"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on web usability and A/B testing for user interface evaluation, which is not related to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12123",
      "abstract": "We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor environment over a Hierarchical Scene Graph derived from sequences of RGB-D frames utilizing a set of open-vocabulary foundation models and sensor data processing. The hierarchical representation explicitly models spatial relations across floors, rooms, locations, and objects. To effectively address complex queries involving spatial reference to other objects, we integrate the hierarchical scene graph with a Large Language Model for multistep reasoning. This integration leverages inter-layer (e.g., room-to-object) and intra-layer (e.g., object-to-object) connections, enhancing spatial contextual understanding. We investigate the semantic and geometry accuracy of hierarchical representation on Habitat Matterport 3D Semantic multi-floor scenes. Our approach demonstrates efficient scene comprehension and robust object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates strong potential for applications requiring spatial reasoning and understanding of indoor environments. Related materials can be found at https://github.com/linukc/OVIGo-3DHSG.",
      "authors": [
        "Sergey Linok",
        "Gleb Naumov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:47:12+00:00",
          "link": "https://arxiv.org/abs/2507.12123v1",
          "size": "11962kb",
          "version": "v1"
        }
      ],
      "title": "Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12123",
        "HTML": "https://arxiv.org/html/2507.12123v1",
        "PDF": "https://arxiv.org/pdf/2507.12123"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper involves indoor object grounding and spatial reasoning using a scene graph, without any mention of reinforcement learning or related data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12124",
      "abstract": "We show that for a randomly sampled unsatisfiable $O(\\log n)$-CNF over $n$ variables the randomized two-party communication cost of finding a clause falsified by the given variable assignment is linear in $n$.",
      "authors": [
        "Artur Riazanov",
        "Anastasia Sofronova",
        "Dmitry Sokolov",
        "Weiqiang Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:48:39+00:00",
          "link": "https://arxiv.org/abs/2507.12124v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Searching for Falsified Clause in Random (log n)-CNFs is Hard for Randomized Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12124",
        "HTML": "https://arxiv.org/html/2507.12124v1",
        "PDF": "https://arxiv.org/pdf/2507.12124"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses the complexity of finding falsified clauses in CNFs using communication complexity, which is unrelated to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12125",
      "abstract": "Vision Transformer (ViT) has achieved impressive results across various vision tasks, yet its high computational cost limits practical applications. Recent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning unimportant tokens. However, these techniques often sacrifice accuracy by independently pruning query (Q) and key (K) tokens, leading to performance degradation due to overlooked token interactions. To address this limitation, we introduce a novel {\\bf Block-based Symmetric Pruning and Fusion} for efficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly. Unlike previous methods that consider only a single direction, our approach evaluates each token and its neighbors to decide which tokens to retain by taking token interaction into account. The retained tokens are compressed through a similarity fusion step, preserving key information while reducing computational costs. The shared weights of Q/K tokens create a symmetric attention matrix, allowing pruning only the upper triangular part for speed up. BSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning levels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0% on DeiT-S, while reducing computational overhead by 50%. It achieves 40% speedup with improved accuracy across various ViTs.",
      "authors": [
        "Yi-Kuan Hsieh",
        "Jun-Wei Hsieh",
        "Xin Li",
        "Yu-Ming Chang",
        "Yu-Chee Tseng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:48:56+00:00",
          "link": "https://arxiv.org/abs/2507.12125v1",
          "size": "233kb",
          "version": "v1"
        }
      ],
      "title": "Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12125",
        "HTML": "https://arxiv.org/html/2507.12125v1",
        "PDF": "https://arxiv.org/pdf/2507.12125"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimization techniques for Vision Transformers, specifically token pruning for computational efficiency, without any connection to reinforcement learning or its data processing concerns."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12126",
      "abstract": "Text data augmentation is a widely used strategy for mitigating data sparsity in natural language processing (NLP), particularly in low-resource settings where limited samples hinder effective semantic modeling. While augmentation can improve input diversity and downstream interpretability, existing techniques often lack mechanisms to ensure semantic preservation during large-scale or iterative generation, leading to redundancy and instability. This work introduces a principled evaluation framework for large language model (LLM) based text augmentation, comprising two components: (1) Scalability Analysis, which measures semantic consistency as augmentation volume increases, and (2) Iterative Augmentation with Summarization Refinement (IASR), which evaluates semantic drift across recursive paraphrasing cycles. Empirical evaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the best balance of semantic fidelity, diversity, and generation efficiency. Applied to a real-world topic modeling task using BERTopic with GPT-enhanced few-shot labeling, the proposed approach results in a 400% increase in topic granularity and complete elimination of topic overlaps. These findings validated the utility of the proposed frameworks for structured evaluation of LLM-based augmentation in practical NLP pipelines.",
      "authors": [
        "Payal Bhattad",
        "Sai Manoj Pudukotai Dinakarrao and Anju Gupta"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:49:30+00:00",
          "link": "https://arxiv.org/abs/2507.12126v1",
          "size": "1733kb",
          "version": "v1"
        }
      ],
      "title": "Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12126",
        "PDF": "https://arxiv.org/pdf/2507.12126"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on text data augmentation in NLP, specifically evaluating semantic consistency and semantic drift for LLM-based augmentation, without any mention of reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12127",
      "abstract": "Advancements in wireless and mobile technologies, including 5G advanced and the envisioned 6G, are driving exponential growth in wireless devices. However, this rapid expansion exacerbates spectrum scarcity, posing a critical challenge. Dynamic spectrum allocation (DSA)--which relies on sensing and dynamically sharing spectrum--has emerged as an essential solution to address this issue. While machine learning (ML) models hold significant potential for improving spectrum sensing, their adoption in centralized ML-based DSA systems is limited by privacy concerns, bandwidth constraints, and regulatory challenges. To overcome these limitations, distributed ML-based approaches such as Federated Learning (FL) offer promising alternatives. This work addresses two key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of labeled data for training FL models in practical spectrum sensing scenarios is tackled with a semi-supervised FL approach, combined with energy detection, enabling model training on unlabeled datasets. Second, we examine the security vulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our analysis highlights the shortcomings of existing majority-based defenses in countering such attacks. To address these vulnerabilities, we propose a novel defense mechanism inspired by vaccination, which effectively mitigates data poisoning attacks without relying on majority-based assumptions. Extensive experiments on both synthetic and real-world datasets validate our solutions, demonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets and maintain Byzantine robustness against both targeted and untargeted data poisoning attacks, even when a significant proportion of participants are malicious.",
      "authors": [
        "Ngoc Duy Pham",
        "Thusitha Dayaratne",
        "Viet Vo",
        "Shangqi Lai",
        "Sharif Abuadbba",
        "Hajime Suzuki",
        "Xingliang Yuan",
        "Carsten Rudolph"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:53:19+00:00",
          "link": "https://arxiv.org/abs/2507.12127v1",
          "size": "2991kb",
          "version": "v1"
        }
      ],
      "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12127",
        "HTML": "https://arxiv.org/html/2507.12127v1",
        "PDF": "https://arxiv.org/pdf/2507.12127"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses federated learning for spectrum sensing in cellular networks, concentrating on labeled data scarcity and security in distributed learning, without addressing data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12130",
      "abstract": "The weighted $k$-server is a variant of the $k$-server problem, where the cost of moving a server is the server's weight times the distance through which it moves. The problem is famous for its intriguing properties and for evading standard techniques for designing and analyzing online algorithms. Even on uniform metric spaces with sufficiently many points, the deterministic competitive ratio of weighted $k$-server is known to increase doubly exponentially with respect to $k$, while the behavior of its randomized competitive ratio is not fully understood. Specifically, no upper bound better than doubly exponential is known, while the best known lower bound is singly exponential in $k$. In this paper, we close the exponential gap between these bounds by giving an $\\exp(O(k^2))$-competitive randomized online algorithm for the weighted $k$-server problem on uniform metrics, thus breaking the doubly exponential barrier for deterministic algorithms for the first time. This is achieved by a recursively defined notion of a phase which, on the one hand, forces a lower bound on the cost of any offline solution, while, on the other hand, also admits a randomized online algorithm with bounded expected cost. The algorithm is also recursive; it involves running several algorithms virtually and in parallel and following the decisions of one of them in a random order. We also show that our techniques can be lifted to construct an $\\exp(O(k^2))$-competitive randomized online algorithm for the generalized $k$-server problem on weighted uniform metrics.",
      "authors": [
        "Adithya Bijoy",
        "Ankit Mondal",
        "Ashish Chiplunkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:57:20+00:00",
          "link": "https://arxiv.org/abs/2507.12130v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "Weighted $k$-Server Admits an Exponentially Competitive Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12130",
        "HTML": "https://arxiv.org/html/2507.12130v1",
        "PDF": "https://arxiv.org/pdf/2507.12130"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper explores the weighted k-server problem and proposes a competitive algorithm for it, focusing on online algorithms rather than reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12133",
      "abstract": "Device recognition is vital for security in wireless communication systems, particularly for applications like access control. Radio Frequency Fingerprint Identification (RFFI) offers a non-cryptographic solution by exploiting hardware-induced signal distortions. This paper proposes HyDRA, a Hybrid Dual-mode RF Architecture that integrates an optimized Variational Mode Decomposition (VMD) with a novel architecture based on the fusion of Convolutional Neural Networks (CNNs), Transformers, and Mamba components, designed to support both closed-set and open-set classification tasks. The optimized VMD enhances preprocessing efficiency and classification accuracy by fixing center frequencies and using closed-form solutions. HyDRA employs the Transformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and the Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting to varying conditions. Evaluation on public datasets demonstrates state-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance in our proposed open-set classification method, effectively identifying unauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves millisecond-level inference speed with low power consumption, providing a practical solution for real-time wireless authentication in real-world environments.",
      "authors": [
        "Hanwen Liu",
        "Yuhe Huang",
        "Yifeng Gong",
        "Yanjie Zhai",
        "Jiaxuan Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:02:11+00:00",
          "link": "https://arxiv.org/abs/2507.12133v1",
          "size": "9060kb",
          "version": "v1"
        }
      ],
      "title": "HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12133",
        "HTML": "https://arxiv.org/html/2507.12133v1",
        "PDF": "https://arxiv.org/pdf/2507.12133"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on radio frequency fingerprint identification systems, using a hybrid network architecture to improve device recognition, without any relation to reinforcement learning or its data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12135",
      "abstract": "Deep learning-based bilateral grid processing has emerged as a promising solution for image enhancement, inherently encoding spatial and intensity information while enabling efficient full-resolution processing through slicing operations. However, existing approaches are limited to linear affine transformations, hindering their ability to model complex color relationships. Meanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings, traditional MLP-based methods employ globally shared parameters, which is hard to deal with localized variations. To overcome these dual challenges, we propose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM) framework. Our approach synergizes the spatial modeling of bilateral grids with the non-linear capabilities of MLPs. Specifically, we generate bilateral grids containing MLP parameters, where each pixel dynamically retrieves its unique transformation parameters and obtain a distinct MLP for color mapping based on spatial coordinates and intensity values. In addition, we propose a novel grid decomposition strategy that categorizes MLP parameters into distinct types stored in separate subgrids. Multi-channel guidance maps are used to extract category-specific parameters from corresponding subgrids, ensuring effective utilization of color information during slicing while guiding precise parameter generation. Extensive experiments on public datasets demonstrate that our method outperforms state-of-the-art methods in performance while maintaining real-time processing capabilities.",
      "authors": [
        "Junyu Lou",
        "Xiaorui Zhao",
        "Kexuan Shi",
        "Shuhang Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:09:39+00:00",
          "link": "https://arxiv.org/abs/2507.12135v1",
          "size": "7324kb",
          "version": "v1"
        }
      ],
      "title": "Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12135",
        "HTML": "https://arxiv.org/html/2507.12135v1",
        "PDF": "https://arxiv.org/pdf/2507.12135"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is focused on image enhancement using deep learning and does not address reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12136",
      "abstract": "The generation of room impulse responses (RIRs) using deep neural networks has attracted growing research interest due to its applications in virtual and augmented reality, audio postproduction, and related fields. Most existing approaches condition generative models on physical descriptions of a room, such as its size, shape, and surface materials. However, this reliance on geometric information limits their usability in scenarios where the room layout is unknown or when perceptual realism (how a space sounds to a listener) is more important than strict physical accuracy. In this study, we propose an alternative strategy: conditioning RIR generation directly on a set of RIR acoustic parameters. These parameters include various measures of reverberation time and direct sound to reverberation ratio, both broadband and bandwise. By specifying how the space should sound instead of how it should look, our method enables more flexible and perceptually driven RIR generation. We explore both autoregressive and non-autoregressive generative models operating in the Descript Audio Codec domain, using either discrete token sequences or continuous embeddings. Specifically, we have selected four models to evaluate: an autoregressive transformer, the MaskGIT model, a flow matching model, and a classifier-based approach. Objective and subjective evaluations are performed to compare these methods with state-of-the-art alternatives. Results show that the proposed models match or outperform state-of-the-art alternatives, with the MaskGIT model achieving the best performance.",
      "authors": [
        "Silvia Arellano and Chunghsin Yeh and Gautam Bhattacharya and Daniel Arteaga"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:09:50+00:00",
          "link": "https://arxiv.org/abs/2507.12136v1",
          "size": "406kb",
          "version": "v1"
        }
      ],
      "title": "Room Impulse Response Generation Conditioned on Acoustic Parameters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12136",
        "HTML": "https://arxiv.org/html/2507.12136v1",
        "PDF": "https://arxiv.org/pdf/2507.12136"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study discusses room impulse response generation using deep learning, which is unrelated to reinforcement learning or data processing therein."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12137",
      "abstract": "Modeling and rendering dynamic urban driving scenes is crucial for self-driving simulation. Current high-quality methods typically rely on costly manual object tracklet annotations, while self-supervised approaches fail to capture dynamic object motions accurately and decompose scenes properly, resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised framework for high-quality free-viewpoint rendering of driving scenes from a single log. At its core is a novel learnable motion model that integrates locality-aware B-spline curves with global-aware trigonometric functions, enabling flexible yet precise dynamic object modeling. Rather than requiring comprehensive semantic labeling, AD-GS automatically segments scenes into objects and background with the simplified pseudo 2D segmentation, representing objects using dynamic Gaussians and bidirectional temporal visibility masks. Further, our model incorporates visibility reasoning and physically rigid regularization to enhance robustness. Extensive evaluations demonstrate that our annotation-free model significantly outperforms current state-of-the-art annotation-free methods and is competitive with annotation-dependent approaches.",
      "authors": [
        "Jiawei Xu",
        "Kai Deng",
        "Zexin Fan",
        "Shenlong Wang",
        "Jin Xie",
        "Jian Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:10:57+00:00",
          "link": "https://arxiv.org/abs/2507.12137v1",
          "size": "18515kb",
          "version": "v1"
        }
      ],
      "title": "AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12137",
        "HTML": "https://arxiv.org/html/2507.12137v1",
        "PDF": "https://arxiv.org/pdf/2507.12137"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses autonomous driving with a self-supervised approach that involves free-viewpoint rendering of scenes. While it involves data processing for dynamic object modeling, it is not directly centered on reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12138",
      "abstract": "We introduce a principled, data-driven approach for modeling a neural prior over human body poses using normalizing flows. Unlike heuristic or low-expressivity alternatives, our method leverages RealNVP to learn a flexible density over poses represented in the 6D rotation format. We address the challenge of modeling distributions on the manifold of valid 6D rotations by inverting the Gram-Schmidt process during training, enabling stable learning while preserving downstream compatibility with rotation-based frameworks. Our architecture and training pipeline are framework-agnostic and easily reproducible. We demonstrate the effectiveness of the learned prior through both qualitative and quantitative evaluations, and we analyze its impact via ablation studies. This work provides a sound probabilistic foundation for integrating pose priors into human motion capture and reconstruction pipelines.",
      "authors": [
        "Michal Heker",
        "Sefy Kararlitsky",
        "David Tolpin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:11:18+00:00",
          "link": "https://arxiv.org/abs/2507.12138v1",
          "size": "3437kb",
          "version": "v1"
        }
      ],
      "title": "Neural Human Pose Prior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12138",
        "HTML": "https://arxiv.org/html/2507.12138v1",
        "PDF": "https://arxiv.org/pdf/2507.12138"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work is about modeling a prior over human body poses using normalizing flows and does not involve reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12140",
      "abstract": "In this work we propose and analyze a new Hybrid High-Order method for the Brinkman problem for fluids with power-law viscosity. The proposed method supports general meshes and arbitrary approximation orders and is robust in all regimes, from pure (power-law) Stokes to pure Darcy. Robustness is reflected by error estimates that distinguish the contributions from Stokes- and Darcy-dominated elements as identified by an appropriate dimensionless number, and that additionally account for pre-asymptotic orders of convergence. Theoretical results are illustrated by a complete panel of numerical experiments.",
      "authors": [
        "Daniel Casta\\~n\\'on Quiroz",
        "Daniele A. Di Pietro",
        "J\\'er\\^ome Droniou",
        "Marwa Salah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:15:32+00:00",
          "link": "https://arxiv.org/abs/2507.12140v1",
          "size": "985kb",
          "version": "v1"
        }
      ],
      "title": "A Hybrid High-Order method for the power-law Brinkman problem robust in all regimes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12140",
        "PDF": "https://arxiv.org/pdf/2507.12140"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a new method for solving the Brinkman problem in fluid dynamics, which does not pertain to reinforcement learning or related data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12142",
      "abstract": "Low-Rank Adaptation (LoRA) has become a widely adopted standard for parameter-efficient fine-tuning of large language models (LLMs), significantly reducing memory and computational demands. However, challenges remain, including finding optimal initialization strategies or mitigating overparametrization in low-rank matrix factorization. In this work, we propose a novel approach that addresses both of the challenges simultaneously within a unified framework. Our method treats a set of fixed-rank LoRA matrices as a smooth manifold. Considering adapters as elements on this manifold removes overparametrization, while determining the direction of the fastest loss decrease along the manifold provides initialization. Special care is taken to obtain numerically stable and computationally efficient implementation of our method, using best practices from numerical linear algebra and Riemannian optimization. Experimental results on LLM and diffusion model architectures demonstrate that RiemannLoRA consistently improves both convergence speed and final performance over standard LoRA and its state-of-the-art modifications.",
      "authors": [
        "Vladimir Bogachev",
        "Vladimir Aletov",
        "Alexander Molozhavenko",
        "Denis Bobkov",
        "Vera Soboleva",
        "Aibek Alanov",
        "Maxim Rakhuba"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Numerical Analysis (cs.NA)",
        "Differential Geometry (math.DG)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:17:12+00:00",
          "link": "https://arxiv.org/abs/2507.12142v1",
          "size": "9089kb",
          "version": "v1"
        }
      ],
      "title": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12142",
        "HTML": "https://arxiv.org/html/2507.12142v1",
        "PDF": "https://arxiv.org/pdf/2507.12142"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on optimizing low-rank adaptation (LoRA) for large language models using numerical linear algebra and Riemannian optimization. It does not discuss reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12143",
      "abstract": "ELOQUENT is a set of shared tasks that aims to create easily testable high-level criteria for evaluating generative language models. Sensemaking is one such shared task.\n  In Sensemaking, we try to assess how well generative models ``make sense out of a given text'' in three steps inspired by exams in a classroom setting: (1) Teacher systems should prepare a set of questions, (2) Student systems should answer these questions, and (3) Evaluator systems should score these answers, all adhering rather strictly to a given set of input materials.\n  We report on the 2025 edition of Sensemaking, where we had 7 sources of test materials (fact-checking analyses of statements, textbooks, transcribed recordings of a lecture, and educational videos) spanning English, German, Ukrainian, and Czech languages.\n  This year, 4 teams participated, providing us with 2 Teacher submissions, 2 Student submissions, and 2 Evaluator submissions. We added baselines for Teacher and Student using commercial large language model systems. We devised a fully automatic evaluation procedure, which we compare to a minimalistic manual evaluation.\n  We were able to make some interesting observations. For the first task, the creation of questions, better evaluation strategies will still have to be devised because it is difficult to discern the quality of the various candidate question sets. In the second task, question answering, the LLMs examined overall perform acceptably, but restricting their answers to the given input texts remains problematic. In the third task, evaluation of question answers, our adversarial tests reveal that systems using the LLM-as-a-Judge paradigm erroneously rate both garbled question-answer pairs and answers to mixed-up questions as acceptable.",
      "authors": [
        "Pavel \\v{S}indel\\'a\\v{r} and Ond\\v{r}ej Bojar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:19:28+00:00",
          "link": "https://arxiv.org/abs/2507.12143v1",
          "size": "59kb",
          "version": "v1"
        }
      ],
      "title": "Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12143",
        "HTML": "https://arxiv.org/html/2507.12143v1",
        "PDF": "https://arxiv.org/pdf/2507.12143"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on evaluating the capabilities of generative language models to make sense of text through shared tasks. It does not involve reinforcement learning or any data processing techniques related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12144",
      "abstract": "FourCastNet 3 advances global weather modeling by implementing a scalable, geometric machine learning (ML) approach to probabilistic ensemble forecasting. The approach is designed to respect spherical geometry and to accurately model the spatially correlated probabilistic nature of the problem, resulting in stable spectra and realistic dynamics across multiple scales. FourCastNet 3 delivers forecasting accuracy that surpasses leading conventional ensemble models and rivals the best diffusion-based methods, while producing forecasts 8 to 60 times faster than these approaches. In contrast to other ML approaches, FourCastNet 3 demonstrates excellent probabilistic calibration and retains realistic spectra, even at extended lead times of up to 60 days. All of these advances are realized using a purely convolutional neural network architecture tailored for spherical geometry. Scalable and efficient large-scale training on 1024 GPUs and more is enabled by a novel training paradigm for combined model- and data-parallelism, inspired by domain decomposition methods in classical numerical models. Additionally, FourCastNet 3 enables rapid inference on a single GPU, producing a 90-day global forecast at 0.25{\\deg}, 6-hourly resolution in under 20 seconds. Its computational efficiency, medium-range probabilistic skill, spectral fidelity, and rollout stability at subseasonal timescales make it a strong candidate for improving meteorological forecasting and early warning systems through large ensemble predictions.",
      "authors": [
        "Boris Bonev",
        "Thorsten Kurth",
        "Ankur Mahesh",
        "Mauro Bisson",
        "Jean Kossaifi",
        "Karthik Kashinath",
        "Anima Anandkumar",
        "William D. Collins",
        "Michael S. Pritchard",
        "Alexander Keller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:22:18+00:00",
          "link": "https://arxiv.org/abs/2507.12144v1",
          "size": "32340kb",
          "version": "v1"
        }
      ],
      "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12144",
        "HTML": "https://arxiv.org/html/2507.12144v1",
        "PDF": "https://arxiv.org/pdf/2507.12144"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "FourCastNet 3 is centered on weather forecasting using machine learning techniques tailored for spherical geometry. It does not address reinforcement learning or any RL-specific data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12145",
      "abstract": "Foundation models (FMs) have achieved remarkable success across a wide range of applications, from image classification to natural langurage processing, but pose significant challenges for deployment at edge. This has sparked growing interest in developing practical and efficient strategies for bringing foundation models to edge environments. In this work, we propose PRISM, a communication-efficient and compute-aware strategy for distributed Transformer inference on edge devices. Our method leverages a Segment Means representation to approximate intermediate output features, drastically reducing inter-device communication. Additionally, we restructure the self-attention mechanism to eliminate redundant computations caused by per-device Key/Value calculation in position-wise partitioning and design a partition-aware causal masking scheme tailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2 across diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and CBT. Our results demonstrate substantial reductions in communication overhead (up to 99.2% for BERT at compression rate CR = 128) and per-device computation (51.24% for BERT at the same setting), with only minor accuracy degradation. This method offers a scalable and practical solution for deploying foundation models in distributed resource-constrained environments.",
      "authors": [
        "Muhammad Azlan Qazi",
        "Alexandros Iosifidis",
        "Qi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:25:03+00:00",
          "link": "https://arxiv.org/abs/2507.12145v1",
          "size": "577kb",
          "version": "v1"
        }
      ],
      "title": "PRISM: Distributed Inference for Foundation Models at Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12145",
        "HTML": "https://arxiv.org/html/2507.12145v1",
        "PDF": "https://arxiv.org/pdf/2507.12145"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on communication-efficient distributed inference for foundation models on edge devices. It does not address any aspects of data processing within the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12148",
      "abstract": "Walkability is a key component of sustainable urban development, while collecting detailed data on its related features remains challenging due to the high costs and limited scalability of traditional methods. Sidewalk delivery robots, increasingly deployed in urban environments, offer a promising solution to these limitations. This paper explores how these robots can serve as mobile data collection platforms, capturing sidewalk-level features related to walkability in a scalable, automated, and real-time manner. A sensor-equipped robot was deployed on a sidewalk network at KTH in Stockholm, completing 101 trips covering 900 segments. From the collected data, different typologies of features are derived, including robot trip characteristics (e.g., speed, duration), sidewalk conditions (e.g., width, surface unevenness), and sidewalk utilization (e.g., pedestrian density). Their walkability-related implications were investigated with a series of analyses. The results demonstrate that pedestrian movement patterns are strongly influenced by sidewalk characteristics, with higher density, reduced width, and surface irregularity associated with slower and more variable trajectories. Notably, robot speed closely mirrors pedestrian behavior, highlighting its potential as a proxy for assessing pedestrian dynamics. The proposed framework enables continuous monitoring of sidewalk conditions and pedestrian behavior, contributing to the development of more walkable, inclusive, and responsive urban environments.",
      "authors": [
        "Xing Tong",
        "Michele D. Simoni",
        "Kaj Munhoz Arfvidsson",
        "Jonas M{\\aa}rtensson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:28:56+00:00",
          "link": "https://arxiv.org/abs/2507.12148v1",
          "size": "11966kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Sidewalk Robots for Walkability-Related Analyses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12148",
        "HTML": "https://arxiv.org/html/2507.12148v1",
        "PDF": "https://arxiv.org/pdf/2507.12148"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses mobile data collection using sidewalk robots for urban walkability analysis, which is not related to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12155",
      "abstract": "Stall patterns are known to cause an error floor in hard decision decoding of the OFEC code. We propose a novel stall pattern removal algorithm that lowers the error floor of state-of-the-art algorithms by an order of magnitude",
      "authors": [
        "Jasper Lagendijk",
        "Yunus Can G\\\"ultekin",
        "Alexios Balatsoukas-Stimming",
        "Gabriele Liga",
        "Alex Alvarado"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:34:15+00:00",
          "link": "https://arxiv.org/abs/2507.12155v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "Lowering Error Floors for Hard Decision Decoding of OFEC Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12155",
        "PDF": "https://arxiv.org/pdf/2507.12155"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel stall pattern removal algorithm for hard decision decoding of OFEC code, which does not pertain to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12156",
      "abstract": "Reconstructing dynamic fluids from sparse views is a long-standing and challenging problem, due to the severe lack of 3D information from insufficient view coverage. While several pioneering approaches have attempted to address this issue using differentiable rendering or novel view synthesis, they are often limited by time-consuming optimization and refinement processes under ill-posed conditions. To tackle above challenges, we propose SmokeSVD, an efficient and effective framework to progressively generate and reconstruct dynamic smoke from a single video by integrating both the powerful generative capabilities from diffusion models and physically guided consistency optimization towards realistic appearance and dynamic evolution. Specifically, we first propose a physically guided side-view synthesizer based on diffusion models, which explicitly incorporates divergence and gradient guidance of velocity fields to generate visually realistic and spatio-temporally consistent side-view images frame by frame, significantly alleviating the ill-posedness of single-view reconstruction without imposing additional constraints. Subsequently, we determine a rough estimation of density field from the pair of front-view input and side-view synthetic image, and further refine 2D blurry novel-view images and 3D coarse-grained density field through an iterative process that progressively renders and enhances the images from increasing novel viewing angles, generating high-quality multi-view image sequences. Finally, we reconstruct and estimate the fine-grained density field, velocity field, and smoke source via differentiable advection by leveraging the Navier-Stokes equations. Extensive quantitative and qualitative experiments show that our approach achieves high-quality reconstruction and outperforms previous state-of-the-art techniques.",
      "authors": [
        "Chen Li",
        "Shanshan Dong",
        "Sheng Qiu",
        "Jianmin Han",
        "Zan Gao",
        "Kemeng Huang",
        "Taku Komura"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:37:04+00:00",
          "link": "https://arxiv.org/abs/2507.12156v1",
          "size": "35562kb",
          "version": "v1"
        }
      ],
      "title": "SmokeSVD: Smoke Reconstruction from A Single View via Progressive Novel View Synthesis and Refinement with Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12156",
        "HTML": "https://arxiv.org/html/2507.12156v1",
        "PDF": "https://arxiv.org/pdf/2507.12156"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a smoke reconstruction framework using diffusion models and novel view synthesis, which does not relate to reinforcement learning or its data processing requirements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12157",
      "abstract": "Fine-grained image recognition (FGIR) aims to distinguish visually similar sub-categories within a broader class, such as identifying bird species. While most existing FGIR methods rely on backbones pretrained on large-scale datasets like ImageNet, this dependence limits adaptability to resource-constrained environments and hinders the development of task-specific architectures tailored to the unique challenges of FGIR.\n  In this work, we challenge the conventional reliance on pretrained models by demonstrating that high-performance FGIR systems can be trained entirely from scratch. We introduce a novel training framework, TGDA, that integrates data-aware augmentation with weak supervision via a fine-grained-aware teacher model, implemented through knowledge distillation. This framework unlocks the design of task-specific and hardware-aware architectures, including LRNets for low-resolution FGIR and ViTFS, a family of Vision Transformers optimized for efficient inference.\n  Extensive experiments across three FGIR benchmarks over diverse settings involving low-resolution and high-resolution inputs show that our method consistently matches or surpasses state-of-the-art pretrained counterparts. In particular, in the low-resolution setting, LRNets trained with TGDA improve accuracy by up to 23\\% over prior methods while requiring up to 20.6x less parameters, lower FLOPs, and significantly less training data. Similarly, ViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k while using 15.3x fewer trainable parameters and requiring orders of magnitudes less data. These results highlight TGDA's potential as an adaptable alternative to pretraining, paving the way for more efficient fine-grained vision systems.",
      "authors": [
        "Edwin Arkel Rios",
        "Fernando Mikael",
        "Oswin Gosal",
        "Femiloye Oyerinde",
        "Hao-Chun Liang",
        "Bo-Cheng Lai",
        "Min-Chun Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:37:33+00:00",
          "link": "https://arxiv.org/abs/2507.12157v1",
          "size": "611kb",
          "version": "v1"
        }
      ],
      "title": "Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12157",
        "HTML": "https://arxiv.org/html/2507.12157v1",
        "PDF": "https://arxiv.org/pdf/2507.12157"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a fine-grained image recognition method using data augmentation and knowledge distillation, but does not focus on reinforcement learning or associated data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12158",
      "abstract": "As industrial autonomous ground vehicles are increasingly deployed in safety-critical environments, ensuring their safe operation under diverse conditions is paramount. This paper presents a novel approach for their safety verification based on systematic situation extraction, probabilistic modelling and verification. We build upon the concept of a situation coverage grid, which exhaustively enumerates environmental configurations relevant to the vehicle's operation. This grid is augmented with quantitative probabilistic data collected from situation-based system testing, capturing probabilistic transitions between situations. We then generate a probabilistic model that encodes the dynamics of both normal and unsafe system behaviour. Safety properties extracted from hazard analysis and formalised in temporal logic are verified through probabilistic model checking against this model. The results demonstrate that our approach effectively identifies high-risk situations, provides quantitative safety guarantees, and supports compliance with regulatory standards, thereby contributing to the robust deployment of autonomous systems.",
      "authors": [
        "Nawshin Mannan Proma",
        "Gricel V\\'azquez",
        "Sepeedeh Shahbeigi",
        "Arjun Badyal",
        "Victoria Hodge"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:37:37+00:00",
          "link": "https://arxiv.org/abs/2507.12158v1",
          "size": "2924kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Safety Verification for an Autonomous Ground Vehicle: A Situation Coverage Grid Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12158",
        "HTML": "https://arxiv.org/html/2507.12158v1",
        "PDF": "https://arxiv.org/pdf/2507.12158"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a safety verification method for autonomous vehicles using probabilistic modeling, which is not directly related to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12162",
      "abstract": "Measuring online behavioural student engagement often relies on simple count indicators or retrospective, predictive methods, which present challenges for real-time application. To address these limitations, we reconceptualise an existing course-wide engagement metric to create a chapter-based version that aligns with the weekly structure of online courses. Derived directly from virtual learning environment log data, the new metric allows for cumulative, real-time tracking of student activity without requiring outcome data or model training. We evaluate the approach across three undergraduate statistics modules over two academic years, comparing it to the course-wide formulation to assess how the reconceptualisation influences what is measured. Results indicate strong alignment from as early as week 3, along with comparable or improved predictive validity for final grades in structured, lecture-based contexts. By the course midpoint, the weekly metric identifies as many low-performing students as are identifiable by the end of the course. While performance varies across modules, the chapter-based formulation offers a scalable and interpretable method for early engagement monitoring and student support.",
      "authors": [
        "Laura J. Johnston",
        "Jim E. Griffin",
        "Ioanna Manolopoulou and Takoua Jendoubi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:44:13+00:00",
          "link": "https://arxiv.org/abs/2507.12162v1",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "title": "A real-time metric of online engagement monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12162",
        "HTML": "https://arxiv.org/html/2507.12162v1",
        "PDF": "https://arxiv.org/pdf/2507.12162"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on measuring online behavioral student engagement using virtual learning environment log data, which is unrelated to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12163",
      "abstract": "Energy Harvesting technologies will play a fundamental role in the development of the next generation of electronic systems as well as in advancing the development of sustainable infrastructure. One of the critical challenges in EH is utilizing ambient vibrations to harvest energy. Piezo Energy Harvesting, which uses ambient vibrations, is a promising technology in energy harvesting and a self-powered technology. However, it suffers from several practical challenges. Some of these challenges include narrow bandwidth, non-linearity, and impedance mismatch, among others. This paper presents a novel, simulated Piezo Energy Harvesting (PEH) framework that addresses some of these challenges. The proposed model is designed to be adaptive and effective against the inherent non-linearity of PEH. This detailed model covers a non-linear piezo, Synchronous Electric Charge Extraction (SECE), Hybrid Maximum Power Point Tracking (MPPT) and a Switched Capacitor Array (SCA). The SECE extracts the maximum charge accumulated on the piezo every time the piezo reaches the mechanical extremum. The Bouc-Wen model has been used to establish nonlinearity in the system. The hybrid MPPT exhibits significant improvement over conventional P&O, while the SCA-tuned system demonstrates resilience against variable frequency input.",
      "authors": [
        "Pramit Karmakar",
        "Siddharth B",
        "Chinmay Murlidhar Kadnur Rao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.12163v1",
          "size": "5214kb",
          "version": "v1"
        }
      ],
      "title": "Integrated Switched Capacitor Array and Synchronous Charge Extraction with Adaptive Hybrid MPPT for Piezoelectric Harvesters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12163",
        "HTML": "https://arxiv.org/html/2507.12163v1",
        "PDF": "https://arxiv.org/pdf/2507.12163"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses energy harvesting technologies, specifically Piezo Energy Harvesting, which does not relate to reinforcement learning or data processing within this context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12165",
      "abstract": "Multi-component datasets with intricate dependencies, like industrial assemblies or multi-modal imaging, challenge current generative modeling techniques. Existing Multi-component Variational AutoEncoders typically rely on simplified aggregation strategies, neglecting critical nuances and consequently compromising structural coherence across generated components. To explicitly address this gap, we introduce the Gaussian Markov Random Field Multi-Component Variational AutoEncoder , a novel generative framework embedding Gaussian Markov Random Fields into both prior and posterior distributions. This design choice explicitly models cross-component relationships, enabling richer representation and faithful reproduction of complex interactions. Empirically, our GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula dataset specifically constructed to evaluate intricate component relationships, demonstrates competitive results on the PolyMNIST benchmark, and significantly enhances structural coherence on the real-world BIKED dataset. Our results indicate that the GMRF MCVAE is especially suited for practical applications demanding robust and realistic modeling of multi-component coherence",
      "authors": [
        "Fouad Oubari",
        "Mohamed El-Baha",
        "Raphael Meunier",
        "Rodrigue D\\'ecatoire",
        "Mathilde Mougeot"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:53:08+00:00",
          "link": "https://arxiv.org/abs/2507.12165v1",
          "size": "963kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Component VAE with Gaussian Markov Random Field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12165",
        "HTML": "https://arxiv.org/html/2507.12165v1",
        "PDF": "https://arxiv.org/pdf/2507.12165"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a Gaussian Markov Random Field for multi-component datasets, focusing on generative modeling rather than reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12166",
      "abstract": "Radio maps (RMs) serve as a critical foundation for enabling environment-aware wireless communication, as they provide the spatial distribution of wireless channel characteristics. Despite recent progress in RM construction using data-driven approaches, most existing methods focus solely on pathloss prediction in a fixed 2D plane, neglecting key parameters such as direction of arrival (DoA), time of arrival (ToA), and vertical spatial variations. Such a limitation is primarily due to the reliance on static learning paradigms, which hinder generalization beyond the training data distribution. To address these challenges, we propose UrbanRadio3D, a large-scale, high-resolution 3D RM dataset constructed via ray tracing in realistic urban environments. UrbanRadio3D is over 37$\\times$3 larger than previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA, forming a novel 3D$\\times$33D dataset with 7$\\times$3 more height layers than prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet with 3D convolutional operators is proposed. Moreover, we further introduce RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D convolutional architecture. RadioDiff-3D supports both radiation-aware scenarios with known transmitter locations and radiation-unaware settings based on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate that RadioDiff-3D achieves superior performance in constructing rich, high-dimensional radio maps under diverse environmental dynamics. This work provides a foundational dataset and benchmark for future research in 3D environment-aware communication. The dataset is available at https://github.com/UNIC-Lab/UrbanRadio3D.",
      "authors": [
        "Xiucheng Wang and Qiming Zhang and Nan Cheng and Junting Chen and Zezhong Zhang and Zan Li and Shuguang Cui and Xuemin Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:54:08+00:00",
          "link": "https://arxiv.org/abs/2507.12166v1",
          "size": "6043kb",
          "version": "v1"
        }
      ],
      "title": "RadioDiff-3D: A 3D$\\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12166",
        "HTML": "https://arxiv.org/html/2507.12166v1",
        "PDF": "https://arxiv.org/pdf/2507.12166"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a 3D radio map dataset and a diffusion model-based benchmark for wireless communication. It does not address reinforcement learning or data processing within reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12168",
      "abstract": "It is demanding to author an existing hairstyle for novel characters in games and VR applications. However, it is a non-trivial task for artists due to the complicated hair geometries and spatial interactions to preserve. In this paper, we present an automatic shape adaptation method to retarget 3D hairstyles. We formulate the adaptation process as a constrained optimization problem, where all the shape properties and spatial relationships are converted into individual objectives and constraints. To make such an optimization on high-resolution hairstyles tractable, we adopt a multi-scale strategy to compute the target positions of the hair strands in a coarse-to-fine manner. The global solving for the inter-strands coupling is restricted to the coarse level, and the solving for fine details is made local and parallel. In addition, we present a novel hairline edit tool to allow for user customization during retargeting. We achieve it by solving physics-based deformations of an embedded membrane to redistribute the hair roots with minimal distortion. We demonstrate the efficacy of our method through quantitative and qualitative experiments on various hairstyles and characters.",
      "authors": [
        "Lu Yu",
        "Zhong Ren",
        "Youyi Zheng",
        "Xiang Chen",
        "Kun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:55:11+00:00",
          "link": "https://arxiv.org/abs/2507.12168v1",
          "size": "11531kb",
          "version": "v1"
        }
      ],
      "title": "Shape Adaptation for 3D Hairstyle Retargeting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12168",
        "HTML": "https://arxiv.org/html/2507.12168v1",
        "PDF": "https://arxiv.org/pdf/2507.12168"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for 3D hairstyle retargeting through shape adaptation, which is not relevant to reinforcement learning or data processing within that domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12174",
      "abstract": "Trajectory planning involving multi-agent interactions has been a long-standing challenge in the field of robotics, primarily burdened by the inherent yet intricate interactions among agents. While game-theoretic methods are widely acknowledged for their effectiveness in managing multi-agent interactions, significant impediments persist when it comes to accommodating the intentional uncertainties of agents. In the context of intentional uncertainties, the heavy computational burdens associated with existing game-theoretic methods are induced, leading to inefficiencies and poor scalability. In this paper, we propose a novel game-theoretic interactive trajectory planning method to effectively address the intentional uncertainties of agents, and it demonstrates both high efficiency and enhanced scalability. As the underpinning basis, we model the interactions between agents under intentional uncertainties as a general Bayesian game, and we show that its agent-form equivalence can be represented as a potential game under certain minor assumptions. The existence and attainability of the optimal interactive trajectories are illustrated, as the corresponding Bayesian Nash equilibrium can be attained by optimizing a unified optimization problem. Additionally, we present a distributed algorithm based on the dual consensus alternating direction method of multipliers (ADMM) tailored to the parallel solving of the problem, thereby significantly improving the scalability. The attendant outcomes from simulations and experiments demonstrate that the proposed method is effective across a range of scenarios characterized by general forms of intentional uncertainties. Its scalability surpasses that of existing centralized and decentralized baselines, allowing for real-time interactive trajectory planning in uncertain game settings.",
      "authors": [
        "Zhenmin Huang",
        "Yusen Xie",
        "Benshan Ma",
        "Shaojie Shen",
        "Jun Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:12:25+00:00",
          "link": "https://arxiv.org/abs/2507.12174v1",
          "size": "9286kb",
          "version": "v1"
        }
      ],
      "title": "Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12174",
        "HTML": "https://arxiv.org/html/2507.12174v1",
        "PDF": "https://arxiv.org/pdf/2507.12174"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on game-theoretic trajectory planning involving multi-agent interactions and intentional uncertainties in robotics, and does not address data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12175",
      "abstract": "This study introduces RUMAA, a transformer-based framework for music performance analysis that unifies score-to-performance alignment, score-informed transcription, and mistake detection in a near end-to-end manner. Unlike prior methods addressing these tasks separately, RUMAA integrates them using pre-trained score and audio encoders and a novel tri-stream decoder capturing task interdependencies through proxy tasks. It aligns human-readable MusicXML scores with repeat symbols to full-length performance audio, overcoming traditional MIDI-based methods that rely on manually unfolded score-MIDI data with pre-specified repeat structures. RUMAA matches state-of-the-art alignment methods on non-repeated scores and outperforms them on scores with repeats in a public piano music dataset, while also delivering promising transcription and mistake detection results.",
      "authors": [
        "Sungkyun Chang",
        "Simon Dixon and Emmanouil Benetos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:13:13+00:00",
          "link": "https://arxiv.org/abs/2507.12175v1",
          "size": "223kb",
          "version": "v1"
        }
      ],
      "title": "RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12175",
        "HTML": "https://arxiv.org/html/2507.12175v1",
        "PDF": "https://arxiv.org/pdf/2507.12175"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents RUMAA, a framework for music performance analysis, focusing on tasks like score-performance alignment, transcription, and mistake detection, without a relation to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12177",
      "abstract": "Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable tool for detecting tumors due to its capability to produce detailed images that reveal their presence. However, the accuracy of diagnosis can be compromised when human specialists evaluate these images. Factors such as fatigue, limited expertise, and insufficient image detail can lead to errors. For example, small tumors might go unnoticed, or overlap with healthy brain regions could result in misidentification. To address these challenges and enhance diagnostic precision, this study proposes a novel double ensembling framework, consisting of ensembled pre-trained deep learning (DL) models for feature extraction and ensembled fine-tuned hyperparameter machine learning (ML) models to efficiently classify brain tumors. Specifically, our method includes extensive preprocessing and augmentation, transfer learning concepts by utilizing various pre-trained deep convolutional neural networks and vision transformer networks to extract deep features from brain MRI, and fine-tune hyperparameters of ML classifiers. Our experiments utilized three different publicly available Kaggle MRI brain tumor datasets to evaluate the pre-trained DL feature extractor models, ML classifiers, and the effectiveness of an ensemble of deep features along with an ensemble of ML classifiers for brain tumor classification. Our results indicate that the proposed feature fusion and classifier fusion improve upon the state of the art, with hyperparameter fine-tuning providing a significant enhancement over the ensemble method. Additionally, we present an ablation study to illustrate how each component contributes to accurate brain tumor classification.",
      "authors": [
        "Zahid Ullah",
        "Dragan Pamucar",
        "Jihie Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:22:11+00:00",
          "link": "https://arxiv.org/abs/2507.12177v1",
          "size": "13552kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12177",
        "HTML": "https://arxiv.org/html/2507.12177v1",
        "PDF": "https://arxiv.org/pdf/2507.12177"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study proposes a double ensembling framework for MRI-based brain tumor classification, which involves image preprocessing and deep learning, but it is not related to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12185",
      "abstract": "The advent of advanced Generative AI (GenAI) models such as DeepSeek and ChatGPT has significantly reshaped the cybersecurity landscape, introducing both promising opportunities and critical risks. This study investigates how GenAI powered chatbot services can be exploited via jailbreaking techniques to bypass ethical safeguards, enabling the generation of phishing content, recommendation of hacking tools, and orchestration of phishing campaigns. In ethically controlled experiments, we used ChatGPT 4o Mini selected for its accessibility and status as the latest publicly available model at the time of experimentation, as a representative GenAI system. Our findings reveal that the model could successfully guide novice users in executing phishing attacks across various vectors, including web, email, SMS (smishing), and voice (vishing). Unlike automated phishing campaigns that typically follow detectable patterns, these human-guided, AI assisted attacks are capable of evading traditional anti phishing mechanisms, thereby posing a growing security threat. We focused on DeepSeek and ChatGPT due to their widespread adoption and technical relevance in 2025. The study further examines common jailbreaking techniques and the specific vulnerabilities exploited in these models. Finally, we evaluate a range of mitigation strategies such as user education, advanced authentication mechanisms, and regulatory policy measures and discuss emerging trends in GenAI facilitated phishing, outlining future research directions to strengthen cybersecurity defenses in the age of artificial intelligence.",
      "authors": [
        "Rina Mishra",
        "Gaurav Varshney"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:32:46+00:00",
          "link": "https://arxiv.org/abs/2507.12185v1",
          "size": "4219kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Jailbreaking Vulnerabilities in Generative AI to Bypass Ethical Safeguards for Facilitating Phishing Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12185",
        "PDF": "https://arxiv.org/pdf/2507.12185"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the vulnerabilities of GenAI models in facilitating phishing attacks and does not relate to data processing or reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12186",
      "abstract": "This paper proposes Partially Observable Reference Policy Programming, a novel anytime online approximate POMDP solver which samples meaningful future histories very deeply while simultaneously forcing a gradual policy update. We provide theoretical guarantees for the algorithm's underlying scheme which say that the performance loss is bounded by the average of the sampling approximation errors rather than the usual maximum, a crucial requirement given the sampling sparsity of online planning. Empirical evaluations on two large-scale problems with dynamically evolving environments -- including a helicopter emergency scenario in the Corsica region requiring approximately 150 planning steps -- corroborate the theoretical results and indicate that our solver considerably outperforms current online benchmarks.",
      "authors": [
        "Edward Kim and Hanna Kurniawati"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:33:32+00:00",
          "link": "https://arxiv.org/abs/2507.12186v1",
          "size": "1945kb",
          "version": "v1"
        }
      ],
      "title": "Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12186",
        "HTML": "https://arxiv.org/html/2507.12186v1",
        "PDF": "https://arxiv.org/pdf/2507.12186"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper proposes a novel POMDP solver that involves sampling strategies, which are a part of reinforcement learning data processing, but these strategies are not the central focus or a direct contribution to data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12187",
      "abstract": "This article addresses the challenge of adapting data-based models over time. We propose a novel two-fold modelling architecture designed to correct plant-model mismatch caused by two types of uncertainty. Out-of-domain uncertainty arises when the system operates under conditions not represented in the initial training dataset, while in-domain uncertainty results from real-world variability and flaws in the model structure or training process. To handle out-of-domain uncertainty, a slow learning component, inspired by the human brain's slow thinking process, learns system dynamics under unexplored operating conditions, and it is activated only when a monitoring strategy deems it necessary. This component consists of an ensemble of models, featuring (i) a combination rule that weights individual models based on the statistical proximity between their training data and the current operating condition, and (ii) a monitoring algorithm based on statistical control charts that supervises the ensemble's reliability and triggers the offline training and integration of a new model when a new operating condition is detected. To address in-domain uncertainty, a fast learning component, inspired by the human brain's fast thinking process, continuously compensates in real time for the mismatch of the slow learning model. This component is implemented as a Gaussian process (GP) model, trained online at each iteration using recent data while discarding older samples. The proposed methodology is tested on a benchmark energy system referenced in the literature, demonstrating that the combined use of slow and fast learning components improves model accuracy compared to standard adaptation approaches.",
      "authors": [
        "Laura Boca de Giuli",
        "Alessio La Bella",
        "Riccardo Scattolini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:34:17+00:00",
          "link": "https://arxiv.org/abs/2507.12187v1",
          "size": "808kb",
          "version": "v1"
        }
      ],
      "title": "Learning, fast and slow: a two-fold algorithm for data-based model adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12187",
        "HTML": "https://arxiv.org/html/2507.12187v1",
        "PDF": "https://arxiv.org/pdf/2507.12187"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses a two-fold algorithm for model adaptation, which includes a Gaussian process (GP) model trained online with recent data while discarding older samples. This is related to data processing in that it involves ongoing data collection and preprocessing strategies, but it's not the core focus as the paper primarily discusses model adaptation strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12188",
      "abstract": "Low-light images suffer from complex degradation, and existing enhancement methods often encode all degradation factors within a single latent space. This leads to highly entangled features and strong black-box characteristics, making the model prone to shortcut learning. To mitigate the above issues, this paper proposes a wavelet-based low-light stereo image enhancement method with feature space decoupling. Our insight comes from the following findings: (1) Wavelet transform enables the independent processing of low-frequency and high-frequency information. (2) Illumination adjustment can be achieved by adjusting the low-frequency component of a low-light image, extracted through multi-level wavelet decomposition. Thus, by using wavelet transform the feature space is decomposed into a low-frequency branch for illumination adjustment and multiple high-frequency branches for texture enhancement. Additionally, stereo low-light image enhancement can extract useful cues from another view to improve enhancement. To this end, we propose a novel high-frequency guided cross-view interaction module (HF-CIM) that operates within high-frequency branches rather than across the entire feature space, effectively extracting valuable image details from the other view. Furthermore, to enhance the high-frequency information, a detail and texture enhancement module (DTEM) is proposed based on cross-attention mechanism. The model is trained on a dataset consisting of images with uniform illumination and images with non-uniform illumination. Experimental results on both real and synthetic images indicate that our algorithm offers significant advantages in light adjustment while effectively recovering high-frequency information. The code and dataset are publicly available at: https://github.com/Cherisherr/WDCI-Net.git.",
      "authors": [
        "Shuangli Du",
        "Siming Yan",
        "Zhenghao Shi",
        "Zhenzhen You",
        "Lu Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:42:27+00:00",
          "link": "https://arxiv.org/abs/2507.12188v1",
          "size": "8382kb",
          "version": "v1"
        }
      ],
      "title": "Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12188",
        "HTML": "https://arxiv.org/html/2507.12188v1",
        "PDF": "https://arxiv.org/pdf/2507.12188"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses low-light stereo image enhancement using a wavelet-based framework for feature space decoupling and does not mention reinforcement learning or related data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12192",
      "abstract": "Unsupervised classification is a fundamental machine learning problem. Real-world data often contain imperfections, characterized by uncertainty and imprecision, which are not well handled by traditional methods. Evidential clustering, based on Dempster-Shafer theory, addresses these challenges. This paper explores the underexplored problem of explaining evidential clustering results, which is crucial for high-stakes domains such as healthcare. Our analysis shows that, in the general case, representativity is a necessary and sufficient condition for decision trees to serve as abductive explainers. Building on the concept of representativity, we generalize this idea to accommodate partial labeling through utility functions. These functions enable the representation of \"tolerable\" mistakes, leading to the definition of evidential mistakeness as explanation cost and the construction of explainers tailored to evidential classifiers. Finally, we propose the Iterative Evidential Mistake Minimization (IEMM) algorithm, which provides interpretable and cautious decision tree explanations for evidential clustering functions. We validate the proposed algorithm on synthetic and real-world data. Taking into account the decision-maker's preferences, we were able to provide an explanation that was satisfactory up to 93% of the time.",
      "authors": [
        "Victor F. Lopes de Souza and Karima Bakhti and Sofiane Ramdani and Denis Mottet and Abdelhak Imoussaten"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.12192v1",
          "size": "1144kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Evidential Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12192",
        "HTML": "https://arxiv.org/html/2507.12192v1",
        "PDF": "https://arxiv.org/pdf/2507.12192"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on explainable evidential clustering using decision trees and Dempster-Shafer theory. It does not relate to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12194",
      "abstract": "Existing LGL methods typically consider only partial information (e.g., geometric features) from LiDAR observations or are designed for homogeneous LiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL method is proposed, termed UniLGL, which simultaneously achieves spatial and material uniformity, as well as sensor-type uniformity. The key idea of the proposed method is to encode the complete point cloud, which contains both geometric and material information, into a pair of BEV images (i.e., a spatial BEV image and an intensity BEV image). An end-to-end multi-BEV fusion network is designed to extract uniform features, equipping UniLGL with spatial and material uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a viewpoint invariance hypothesis is introduced, which replaces the conventional translation equivariance assumption commonly used in existing LPR networks and supervises UniLGL to achieve sensor-type uniformity in both global descriptors and local feature representations. Finally, based on the mapping between local features on the 2D BEV image and the point cloud, a robust global pose estimator is derived that determines the global minimum of the global pose on SE(3) without requiring additional registration. To validate the effectiveness of the proposed uniform LGL, extensive benchmarks are conducted in real-world environments, and the results show that the proposed UniLGL is demonstratively competitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL has been deployed on diverse platforms, including full-size trucks and agile Micro Aerial Vehicles (MAVs), to enable high-precision localization and mapping as well as multi-MAV collaborative exploration in port and forest environments, demonstrating the applicability of UniLGL in industrial and field scenarios.",
      "authors": [
        "Hongming Shen",
        "Xun Chen",
        "Yulin Hui",
        "Zhenyu Wu",
        "Wei Wang",
        "Qiyang Lyu",
        "Tianchen Deng",
        "and Danwei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:45:56+00:00",
          "link": "https://arxiv.org/abs/2507.12194v1",
          "size": "46969kb",
          "version": "v1"
        }
      ],
      "title": "UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12194",
        "HTML": "https://arxiv.org/html/2507.12194v1",
        "PDF": "https://arxiv.org/pdf/2507.12194"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a uniform LiDAR global localization method for LiDAR-based systems and does not involve reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12195",
      "abstract": "Modern digitised approaches have dramatically changed the preservation and restoration of cultural treasures, integrating computer scientists into multidisciplinary projects with ease. Machine learning, deep learning, and computer vision techniques have revolutionised developing sectors like 3D reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and image processing with the integration of computer scientists into multidisciplinary initiatives. We suggest three cutting-edge techniques in recognition of the special qualities of Indian monuments, which are famous for their architectural skill and aesthetic appeal. First is the Fractal Convolution methodology, a segmentation method based on image processing that successfully reveals subtle architectural patterns within these irreplaceable cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling (SSTF) method created especially for West Bengal's mesmerising Bankura Terracotta Temples with a brand-new data augmentation method called MosaicSlice on the third. Furthermore, we delve deeper into the Super Resolution strategy to upscale the images without losing significant amount of quality. Our methods allow for the development of seamless region-filling and highly detailed tiles while maintaining authenticity using a novel data augmentation strategy within affordable costs introducing automation. By providing effective solutions that preserve the delicate balance between tradition and innovation, this study improves the subject and eventually ensures unrivalled efficiency and aesthetic excellence in cultural heritage protection. The suggested approaches advance the field into an era of unmatched efficiency and aesthetic quality while carefully upholding the delicate equilibrium between tradition and innovation.",
      "authors": [
        "Arkaprabha Basu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:46:04+00:00",
          "link": "https://arxiv.org/abs/2507.12195v1",
          "size": "48762kb",
          "version": "v1"
        }
      ],
      "title": "Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12195",
        "HTML": "https://arxiv.org/html/2507.12195v1",
        "PDF": "https://arxiv.org/pdf/2507.12195"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on digital reconstruction of historical artifacts using computer vision, image processing, and data augmentation techniques. There is no exploration or mention of reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12196",
      "abstract": "Quantization is a process that reduces the precision of deep neural network models to lower model size and computational demands, often at the cost of accuracy. However, fully quantized models may exhibit sub-optimal performance below acceptable levels and face deployment challenges on low-end hardware accelerators due to practical constraints. To address these issues, quantization can be selectively applied to only a subset of layers, but selecting which layers to exclude is non-trivial. To this direction, we propose TuneQn, a suite enabling selective quantization, deployment and execution of ONNX models across various CPU and GPU devices, combined with profiling and multi-objective optimization. TuneQn generates selectively quantized ONNX models, deploys them on different hardware, measures performance on metrics like accuracy and size, performs Pareto Front minimization to identify the best model candidate and visualizes the results. To demonstrate the effectiveness of TuneQn, we evaluated TuneQn on four ONNX models with two quantization settings across CPU and GPU devices. As a result, we demonstrated that our utility effectively performs selective quantization and tuning, selecting ONNX model candidates with up to a $54.14$% reduction in accuracy loss compared to the fully quantized model, and up to a $72.9$% model size reduction compared to the original model.",
      "authors": [
        "Nikolaos Louloudakis and Ajitha Rajan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:46:04+00:00",
          "link": "https://arxiv.org/abs/2507.12196v1",
          "size": "1567kb",
          "version": "v1"
        }
      ],
      "title": "Selective Quantization Tuning for ONNX Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12196",
        "HTML": "https://arxiv.org/html/2507.12196v1",
        "PDF": "https://arxiv.org/pdf/2507.12196"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses selective quantization for ONNX models, focusing on deep neural network optimization for deployment. It does not involve reinforcement learning or data processing within the context of RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12197",
      "abstract": "Text-to-speech (TTS) synthesis has seen renewed progress under the discrete modeling paradigm. Existing autoregressive approaches often rely on single-codebook representations, which suffer from significant information loss. Even with post-hoc refinement techniques such as flow matching, these methods fail to recover fine-grained details (e.g., prosodic nuances, speaker-specific timbres), especially in challenging scenarios like singing voice or music synthesis. We propose QTTS, a novel TTS framework built upon our new audio codec, QDAC. The core innovation of QDAC lies in its end-to-end training of an ASR-based auto-regressive network with a GAN, which achieves superior semantic feature disentanglement for scalable, near-lossless compression. QTTS models these discrete codes using two innovative strategies: the Hierarchical Parallel architecture, which uses a dual-AR structure to model inter-codebook dependencies for higher-quality synthesis, and the Delay Multihead approach, which employs parallelized prediction with a fixed delay to accelerate inference speed. Our experiments demonstrate that the proposed framework achieves higher synthesis quality and better preserves expressive content compared to baseline. This suggests that scaling up compression via multi-codebook modeling is a promising direction for high-fidelity, general-purpose speech and audio generation.",
      "authors": [
        "Yichen Han",
        "Xiaoyang Hao",
        "Keming Chen",
        "Weibo Xiong",
        "Jun He",
        "Ruonan Zhang",
        "Junjie Cao",
        "Yue Liu",
        "Bowen Li",
        "Dongrui Zhang",
        "Hui Xia",
        "Huilei Fu",
        "Kai Jia",
        "Kaixuan Guo",
        "Mingli Jin",
        "Qingyun Meng",
        "Ruidong Ma",
        "Ruiqian Fang",
        "Shaotong Guo",
        "Xuhui Li",
        "Yang Xiang",
        "Ying Zhang",
        "Yulong Liu",
        "Yunfeng Li",
        "Yuyi Zhang",
        "Yuze Zhou",
        "Zhen Wang",
        "Zhaowen Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:47:09+00:00",
          "link": "https://arxiv.org/abs/2507.12197v1",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "title": "Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12197",
        "HTML": "https://arxiv.org/html/2507.12197v1",
        "PDF": "https://arxiv.org/pdf/2507.12197"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a new text-to-speech synthesis framework focusing on audio coding and compression. It does not discuss reinforcement learning or data processing pertinent to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12201",
      "abstract": "Diffusion models have achieved state-of-the-art performance in generative modeling, yet their sampling procedures remain vulnerable to hallucinations, often stemming from inaccuracies in score approximation. In this work, we reinterpret diffusion sampling through the lens of optimization and introduce RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that detects and corrects high-risk sampling steps using geometric cues from the loss landscape. RODS enforces smoother sampling trajectories and adaptively adjusts perturbations, reducing hallucinations without retraining and at minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands demonstrate that RODS improves both sampling fidelity and robustness, detecting over 70% of hallucinated samples and correcting more than 25%, all while avoiding the introduction of new artifacts.",
      "authors": [
        "Yiqi Tian",
        "Pengfei Jin",
        "Mingze Yuan",
        "Na Li",
        "Bo Zeng",
        "Quanzheng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:55:58+00:00",
          "link": "https://arxiv.org/abs/2507.12201v1",
          "size": "44788kb",
          "version": "v1"
        }
      ],
      "title": "RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12201",
        "HTML": "https://arxiv.org/html/2507.12201v1",
        "PDF": "https://arxiv.org/pdf/2507.12201"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses issue hitching diffusion sampling in generative models, focusing on hallucination reduction in generative models. It does not cover reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12202",
      "abstract": "Many current state-of-the-art models for sequential recommendations are based on transformer architectures. Interpretation and explanation of such black box models is an important research question, as a better understanding of their internals can help understand, influence, and control their behavior, which is very important in a variety of real-world applications. Recently sparse autoencoders (SAE) have been shown to be a promising unsupervised approach for extracting interpretable features from language models. These autoencoders learn to reconstruct hidden states of the transformer's internal layers from sparse linear combinations of directions in their activation space.\n  This paper is focused on the application of SAE to the sequential recommendation domain. We show that this approach can be successfully applied to the transformer trained on a sequential recommendation task: learned directions turn out to be more interpretable and monosemantic than the original hidden state dimensions. Moreover, we demonstrate that the features learned by SAE can be used to effectively and flexibly control the model's behavior, providing end-users with a straightforward method to adjust their recommendations to different custom scenarios and contexts.",
      "authors": [
        "Anton Klenitskiy",
        "Konstantin Polev",
        "Daria Denisova",
        "Alexey Vasilev",
        "Dmitry Simakov",
        "Gleb Gusev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:57:43+00:00",
          "link": "https://arxiv.org/abs/2507.12202v1",
          "size": "3020kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12202",
        "HTML": "https://arxiv.org/html/2507.12202v1",
        "PDF": "https://arxiv.org/pdf/2507.12202"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores sequential recommendation models using sparse autoencoders for interpretable features extraction. However, it does not discuss reinforcement learning or relevant data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12204",
      "abstract": "Adolescents' mobile technology use is often regulated through rigid control mechanisms that fail to account for their autonomy and natural usage patterns. Drawing on Taoist philosophy, particularly Wu Wei, Yin-Yang, and Zi Ran, this position paper proposes Tao-Technology, a self-organizing, adaptive regulatory framework. Integrating insights from Reflective Informatics and Information Ecologies, we explore how mobile technology can dynamically adjust to context while fostering self-reflection and meaning-making. This approach shifts from external restrictions to dynamic co-adaptative regulation, ensuring technology governance remains flexible yet structured, supporting adolescents in cultivating a balanced and intentional relationship with digital technology.",
      "authors": [
        "Pengyu Zhu and Janghee Cho"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:03:24+00:00",
          "link": "https://arxiv.org/abs/2507.12204v1",
          "size": "208kb",
          "version": "v1"
        }
      ],
      "title": "Tao-Technology for Teen Mobile Use: Harmonizing Adaptation, Autonomy, and Reflection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12204",
        "HTML": "https://arxiv.org/html/2507.12204v1",
        "PDF": "https://arxiv.org/pdf/2507.12204"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for mobile technology use regulation in adolescents based on Taoist philosophy and does not address any aspects of RL or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12205",
      "abstract": "Sparse Matrix-Vector Multiplication (SpMV) has become a critical performance bottleneck in the local deployment of sparse Large Language Models (LLMs), where inference predominantly operates on workloads during the decoder phase with a batch size of one. Existing SpMV kernels and sparse matrix formats, originally designed for scientific computing, fail to exploit the unique structure patterns inherent in sparse LLMs, resulting in suboptimal performance and excessive storage overhead. This paper presents EC-SpMV, a GPU-optimized SpMV approach for accelerating sparse LLM inference. EC-SpMV introduces (1) a hierarchical block extraction algorithm that captures multiple granularities of block structures within sparse LLMs, and (2) a novel compressed sparse format (EC-CSR) that employs delta indexing to reduce storage overhead and enhance memory access efficiency. Evaluated on real sparse weight matrices from LLaMA and OPT models, EC-SpMV achieves up to 6.44x speedup over state-of-the-art SpMV libraries and reduces storage overhead by up to 55.4% compared to CSR.",
      "authors": [
        "Junqing Lin",
        "Jingwei Sun",
        "Mingge Lu",
        "Guangzhong Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:04:06+00:00",
          "link": "https://arxiv.org/abs/2507.12205v1",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "title": "Toward Efficient SpMV in Sparse LLMs via Block Extraction and Compressed Storage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12205",
        "HTML": "https://arxiv.org/html/2507.12205v1",
        "PDF": "https://arxiv.org/pdf/2507.12205"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing Sparse Matrix-Vector Multiplication for Large Language Models and does not discuss reinforcement learning or data processing in that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12207",
      "abstract": "Accurate building energy forecasting is essential, yet traditional heuristics often lack precision, while advanced models can be opaque and struggle with generalization by neglecting physical principles. This paper introduces BuildEvo, a novel framework that uses Large Language Models (LLMs) to automatically design effective and interpretable energy prediction heuristics. Within an evolutionary process, BuildEvo guides LLMs to construct and enhance heuristics by systematically incorporating physical insights from building characteristics and operational data (e.g., from the Building Data Genome Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on benchmarks, offering improved generalization and transparent prediction logic. This work advances the automated design of robust, physically grounded heuristics, promoting trustworthy models for complex energy systems.",
      "authors": [
        "Subin Lin",
        "Chuanbo Hua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:07:24+00:00",
          "link": "https://arxiv.org/abs/2507.12207v1",
          "size": "1320kb",
          "version": "v1"
        }
      ],
      "title": "BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12207",
        "HTML": "https://arxiv.org/html/2507.12207v1",
        "PDF": "https://arxiv.org/pdf/2507.12207"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for designing energy consumption forecasting heuristics driven by LLMs, lacking any discussion related to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12208",
      "abstract": "The paper introduces a Behavioural Translation Style Space (BTSS) that describes possible behavioural translation patterns. The suggested BTSS is organized as a hierarchical structure that entails various embedded processing layers. We posit that observable translation behaviour - i.e., eye and finger movements - is fundamental when executing the physical act of translation but it is caused and shaped by higher-order cognitive processes and affective translation states. We analyse records of keystrokes and gaze data as indicators of the hidden mental processing structure and organize the behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the basis for a computational translation agent to simulate the temporal dynamics of affect, automatized behaviour and cognition during human translation production.",
      "authors": [
        "Michael Carl",
        "Takanori Mizowaki",
        "Aishvarya Ray",
        "Masaru Yamada",
        "Devi Sri Bandaru",
        "Xinyue Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:10:10+00:00",
          "link": "https://arxiv.org/abs/2507.12208v1",
          "size": "1002kb",
          "version": "v1"
        }
      ],
      "title": "Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12208",
        "PDF": "https://arxiv.org/pdf/2507.12208"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a Behavioural Translation Style Space for simulating translation production dynamics and does not involve reinforcement learning or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12212",
      "abstract": "Generative AI does not only replicate human creativity but also reproduces deep-seated cultural biases, making it crucial to critically examine how concepts like ugliness are understood and expressed by these tools. This study investigates how four different generative AI models understand and express ugliness through text and image and explores the biases embedded within these representations. We extracted 13 adjectives associated with ugliness through iterative prompting of a large language model and generated 624 images across four AI models and three prompts. Demographic and socioeconomic attributes within the images were independently coded and thematically analyzed. Our findings show that AI models disproportionately associate ugliness with old white male figures, reflecting entrenched social biases as well as paradoxical biases, where efforts to avoid stereotypical depictions of marginalized groups inadvertently result in the disproportionate projection of negative attributes onto majority groups. Qualitative analysis further reveals that, despite supposed attempts to frame ugliness within social contexts, conventional physical markers such as asymmetry and aging persist as central visual motifs. These findings demonstrate that despite attempts to create more equal representations, generative AI continues to perpetuate inherited and paradoxical biases, underscoring the critical work being done to create ethical AI training paradigms and advance methodologies for more inclusive AI development.",
      "authors": [
        "Garyoung Kim",
        "Huisung Kwon",
        "Seoju Yun",
        "Yu-Won Youn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:16:56+00:00",
          "link": "https://arxiv.org/abs/2507.12212v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "Draw an Ugly Person An Exploration of Generative AIs Perceptions of Ugliness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12212",
        "HTML": "https://arxiv.org/html/2507.12212v1",
        "PDF": "https://arxiv.org/pdf/2507.12212"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study examines generative AI models' perceptions of ugliness and associated biases, with no relation to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12215",
      "abstract": "Game playing has long served as a fundamental benchmark for evaluating Artificial General Intelligence (AGI). While Large Language Models (LLMs) have demonstrated impressive capabilities in general reasoning, their effectiveness in spatial strategic reasoning, which is critical for complex and fully observable board games, remains insufficiently explored. In this work, we adopt Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate rules and spatial complexity. To advance LLMs' strategic competence in such environments, we propose a training framework tailored to Xiangqi, built upon a large-scale dataset of five million board-move pairs enhanced with expert annotations and engine evaluations. Building on this foundation, we introduce Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning for legal move prediction to capture basic spatial rules, (2) incorporating strategic annotations to improve decision-making, and (3) applying reinforcement learning via Group Relative Policy Optimization (GRPO) with multi-dimensional reward signals to enhance reasoning stability. Our Experimental results indicate that, despite their size and power, general-purpose LLMs struggle to achieve satisfactory performance in these tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an 18% rise in move legality and a 22% boost in analysis accuracy. Our results point to a promising path for creating general strategic intelligence in spatially complex areas.",
      "authors": [
        "Yuhao Chen",
        "Shuochen Liu",
        "Yuanjie Lyu",
        "Chao Zhang",
        "Jiayao Shi",
        "Tong Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:19:46+00:00",
          "link": "https://arxiv.org/abs/2507.12215v1",
          "size": "1262kb",
          "version": "v1"
        }
      ],
      "title": "Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12215",
        "HTML": "https://arxiv.org/html/2507.12215v1",
        "PDF": "https://arxiv.org/pdf/2507.12215"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper introduces a reinforcement learning framework for training a model in the context of Chinese Chess using a large-scale dataset of board-move pairs, strategic annotations, and multi-dimensional reward signals. The work emphasizes data collection and processing, making significant contributions to data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12217",
      "abstract": "We explore an ASR-free method for isolated word reading assessment in low-resource settings. Our few-shot approach compares input child speech to a small set of adult-provided reference templates. Inputs and templates are encoded using intermediate layers from large self-supervised learned (SSL) models. Using an Afrikaans child speech benchmark, we investigate design options such as discretising SSL features and barycentre averaging of the templates. Idealised experiments show reasonable performance for adults, but a substantial drop for child speech input, even with child templates. Despite the success of employing SSL representations in low-resource speech tasks, our work highlights the limitations of SSL representations for processing child data when used in a few-shot classification system.",
      "authors": [
        "Reuben Smit",
        "Retief Louw and Herman Kamper"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:20:32+00:00",
          "link": "https://arxiv.org/abs/2507.12217v1",
          "size": "309kb",
          "version": "v1"
        }
      ],
      "title": "Towards few-shot isolated word reading assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12217",
        "HTML": "https://arxiv.org/html/2507.12217v1",
        "PDF": "https://arxiv.org/pdf/2507.12217"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores an ASR-free method for word reading assessment and does not discuss reinforcement learning or data processing related to RL in its methodology or objectives."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12218",
      "abstract": "Many physical systems are described by partial differential equations (PDEs), and solving these equations and estimating their coefficients or boundary conditions (BCs) from observational data play a crucial role in understanding the associated phenomena. Recently, a machine learning approach known as physics-informed neural network, which solves PDEs using neural networks by minimizing the sum of residuals from the PDEs, BCs, and data, has gained significant attention in the scientific community. In this study, we investigate a physics-informed linear model (PILM) that uses linear combinations of basis functions to represent solutions, thereby enabling an analytical representation of optimal solutions. The PILM was formulated and verified for illustrative forward and inverse problems including cases with uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain rates using geodetic data. Specifically, physical regularization that enforces elastic equilibrium on the velocity fields was compared with mathematical regularization that imposes smoothness constraints. From a Bayesian perspective, mathematical regularization exhibited superior performance. The PILM provides an analytically solvable framework applicable to linear forward and inverse problems, underdetermined systems, and physical regularization.",
      "authors": [
        "Tomohisa Okazaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Geophysics (physics.geo-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:23:39+00:00",
          "link": "https://arxiv.org/abs/2507.12218v1",
          "size": "1971kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12218",
        "PDF": "https://arxiv.org/pdf/2507.12218"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a physics-informed linear model for estimating crustal strain rates using geodetic data, which is unrelated to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12224",
      "abstract": "Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not guarantee convergence to a unique global minimum of the loss when using optimizers relying only on local information, such as SGD. Indeed, this was a primary source of skepticism regarding the feasibility of DNNs in the early days of the field. The past decades of progress in deep learning have revealed this skepticism to be misplaced, and a large body of empirical evidence shows that sufficiently large DNNs following standard training protocols exhibit well-behaved optimization dynamics that converge to performant solutions. This success has biased the community to use convex optimization as a mental model for learning, leading to a focus on training efficiency, either in terms of required iteration, FLOPs or wall-clock time, when improving optimizers. We argue that, while this perspective has proven extremely fruitful, another perspective specific to DNNs has received considerably less attention: the optimizer not only influences the rate of convergence, but also the qualitative properties of the learned solutions. Restated, the optimizer can and will encode inductive biases and change the effective expressivity of a given class of models. Furthermore, we believe the optimizer can be an effective way of encoding desiderata in the learning process. We contend that the community should aim at understanding the biases of already existing methods, as well as aim to build new optimizers with the explicit intent of inducing certain properties of the solution, rather than solely judging them based on their convergence rates. We hope our arguments will inspire research to improve our understanding of how the learning process can impact the type of solution we converge to, and lead to a greater recognition of optimizers design as a critical lever that complements the roles of architecture and data in shaping model outcomes.",
      "authors": [
        "Razvan Pascanu",
        "Clare Lyle",
        "Ionut-Vlad Modoranu",
        "Naima Elosegui Borras",
        "Dan Alistarh",
        "Petar Velickovic",
        "Sarath Chandar",
        "Soham De",
        "James Martens"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:33:31+00:00",
          "link": "https://arxiv.org/abs/2507.12224v1",
          "size": "738kb",
          "version": "v1"
        }
      ],
      "title": "Optimizers Qualitatively Alter Solutions And We Should Leverage This",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12224",
        "HTML": "https://arxiv.org/html/2507.12224v1",
        "PDF": "https://arxiv.org/pdf/2507.12224"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the role of optimizers in influencing the properties of deep neural network solutions, but it does not address reinforcement learning or data processing aspects specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12226",
      "abstract": "In this paper, we study a generalized finite element method for solving second-order elliptic partial differential equations with rough coefficients. The method uses local approximation spaces computed by solving eigenvalue problems on rings around the boundary of local subdomains. Compared to the corresponding method that solves eigenvalue problems on the whole subdomains, the problem size and the bandwidth of the resulting system matrices are substantially reduced, resulting in faster spectral computations. We prove a nearly exponential a priori decay result for the local approximation errors of the proposed method, which implies the nearly exponential decay of the overall approximation error of the method. The proposed method can also be used as a preconditioner, and only a slight adaptation of our theory is necessary to prove the optimal convergence of the preconditioned iteration. Numerical experiments are presented to support the effectiveness of the proposed method and to investigate its coefficient robustness.",
      "authors": [
        "Christian Alber",
        "Peter Bastian",
        "Moritz Hauck",
        "Robert Scheichl"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:36:27+00:00",
          "link": "https://arxiv.org/abs/2507.12226v1",
          "size": "563kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Spectral Approximation in the Overlaps for Generalized Finite Element Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12226",
        "HTML": "https://arxiv.org/html/2507.12226v1",
        "PDF": "https://arxiv.org/pdf/2507.12226"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study discusses a generalized finite element method for solving PDEs, which does not involve reinforcement learning or data processing in the context of RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12232",
      "abstract": "Recent studies have utilized visual large language models (VLMs) to answer not only \"Is this face a forgery?\" but also \"Why is the face a forgery?\" These studies introduced forgery-related attributes, such as forgery location and type, to construct deepfake VQA datasets and train VLMs, achieving high accuracy while providing human-understandable explanatory text descriptions. However, these methods still have limitations. For example, they do not fully leverage face quality-related attributes, which are often abnormal in forged faces, and they lack effective training strategies for forgery-aware VLMs. In this paper, we extend the VQA dataset to create DD-VQA+, which features a richer set of attributes and a more diverse range of samples. Furthermore, we introduce a novel forgery detection framework, MGFFD-VLM, which integrates an Attribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual Large Language Models (VLMs). Additionally, our framework incorporates Multi-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By transforming classification and forgery segmentation results into prompts, our method not only improves forgery classification but also enhances interpretability. To further boost detection performance, we design multiple forgery-related auxiliary losses. Experimental results demonstrate that our approach surpasses existing methods in both text-based forgery judgment and analysis, achieving superior accuracy.",
      "authors": [
        "Tao Chen",
        "Jingyi Zhang",
        "Decheng Liu",
        "Chunlei Peng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:47:13+00:00",
          "link": "https://arxiv.org/abs/2507.12232v1",
          "size": "1849kb",
          "version": "v1"
        }
      ],
      "title": "MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12232",
        "HTML": "https://arxiv.org/html/2507.12232v1",
        "PDF": "https://arxiv.org/pdf/2507.12232"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses face forgery detection using visual large language models and does not address data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12233",
      "abstract": "\\noindent Solving cell problems in homogenization is hard, and available deep-learning frameworks fail to match the speed and generality of traditional computational frameworks. More to the point, it is generally unclear what to expect of machine-learning approaches, let alone single out which approaches are promising. In the work at hand, we advocate Fourier Neural Operators (FNOs) for micromechanics, empowering them by insights from computational micromechanics methods based on the fast Fourier transform (FFT). We construct an FNO surrogate mimicking the basic scheme foundational for FFT-based methods and show that the resulting operator predicts solutions to cell problems with \\emph{arbitrary} stiffness distribution only subject to a material-contrast constraint up to a desired accuracy. In particular, there are no restrictions on the material symmetry like isotropy, on the number of phases and on the geometry of the interfaces between materials. Also, the provided fidelity is sharp and uniform, providing explicit guarantees leveraging our physical empowerment of FNOs. To show the desired universal approximation property, we construct an FNO explicitly that requires no training to begin with. Still, the obtained neural operator complies with the same memory requirements as the basic scheme and comes with runtimes proportional to classical FFT solvers. In particular, large-scale problems with more than 100 million voxels are readily handled. The goal of this work is to underline the potential of FNOs for solving micromechanical problems, linking FFT-based methods to FNOs. This connection is expected to provide a fruitful exchange between both worlds.",
      "authors": [
        "Binh Huy Nguyen and Matti Schneider"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:47:20+00:00",
          "link": "https://arxiv.org/abs/2507.12233v1",
          "size": "2929kb",
          "version": "v1"
        }
      ],
      "title": "Universal Fourier Neural Operators for Micromechanics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12233",
        "PDF": "https://arxiv.org/pdf/2507.12233"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores Fourier Neural Operators for micromechanics and does not relate to reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12236",
      "abstract": "Phrase grounding, i.e., mapping natural language phrases to specific image regions, holds significant potential for disease localization in medical imaging through clinical reports. While current state-of-the-art methods rely on discriminative, self-supervised contrastive models, we demonstrate that generative text-to-image diffusion models, leveraging cross-attention maps, can achieve superior zero-shot phrase grounding performance. Contrary to prior assumptions, we show that fine-tuning diffusion models with a frozen, domain-specific language model, such as CXR-BERT, substantially outperforms domain-agnostic counterparts. This setup achieves remarkable improvements, with mIoU scores doubling those of current discriminative methods. These findings highlight the underexplored potential of generative models for phrase grounding tasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM), a novel post-processing technique that aligns text and image biases to identify regions of high certainty. BBM refines cross-attention maps, achieving even greater localization accuracy. Our results establish generative approaches as a more effective paradigm for phrase grounding in the medical imaging domain, paving the way for more robust and interpretable applications in clinical practice. The source code and model weights are available at https://github.com/Felix-012/generate_to_ground.",
      "authors": [
        "Felix N\\\"utzel",
        "Mischa Dombrowski",
        "Bernhard Kainz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:48:32+00:00",
          "link": "https://arxiv.org/abs/2507.12236v1",
          "size": "5157kb",
          "version": "v1"
        }
      ],
      "title": "Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12236",
        "HTML": "https://arxiv.org/html/2507.12236v1",
        "PDF": "https://arxiv.org/pdf/2507.12236"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on phrase grounding in medical vision-language models using generative models and does not involve data processing within reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12240",
      "abstract": "Recent research has focused extensively on constructing binary self-orthogonal (SO) linear codes due to their applications in quantum information theory, lattice design, and related areas. Despite significant activity, the fundamental characterization remains unchanged: binary SO codes are necessarily even (all codeword weights even), while doubly-even codes (weights divisible by $4$) are automatically SO.\n  This paper advances the theory by addressing the understudied case of singly-even (even but not doubly-even) SO codes. We first provide a complete characterization of binary SO linear codes, and a necessary and sufficient condition for binary SO singly-even linear codes is given. Moreover, we give a general approach to generating many binary SO linear codes from two known SO linear codes, yielding three infinite classes of binary SO singly-even linear codes with few weights. Note that these new codes are also minimal and violate the Aschikhmin-Barg condition. Their weight distributions are determined. Furthermore, we give a necessary and sufficient condition for a Boolean function $f$ such that the linear code proposed from $f$ via a well-known generic construction is SO singly-even, and a general approach to constructing Boolean functions satisfying this condition is provided, yielding several infinite classes of binary SO singly-even minimal linear codes with few weights. Finally, we would like to emphasize that using the methods in this paper, we can construct more binary linear codes that are SO, singly-even, minimal, violating the AB condition, and with few weights at the same time.",
      "authors": [
        "Kangquan Li and Hao Chen and Wengang Jin and Longjiang Qu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:50:20+00:00",
          "link": "https://arxiv.org/abs/2507.12240v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Characterization and constructions of binary self-orthogonal singly-even linear codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12240",
        "HTML": "https://arxiv.org/html/2507.12240v1",
        "PDF": "https://arxiv.org/pdf/2507.12240"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper delves into the construction of binary self-orthogonal linear codes and does not pertain to reinforcement learning or data processing within its scope."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12242",
      "abstract": "Recommender systems can be found everywhere today, shaping our everyday experience whenever we're consuming content, ordering food, buying groceries online, or even just reading the news. Let's imagine we're in the process of building a recommender system to make content suggestions to users on social media. When thinking about fairness, it becomes clear there are several perspectives to consider: the users asking for tailored suggestions, the content creators hoping for some limelight, and society at large, navigating the repercussions of algorithmic recommendations. A shared fairness concern across all three is the emergence of filter bubbles, a side-effect that takes place when recommender systems are almost \"too good\", making recommendations so tailored that users become inadvertently confined to a narrow set of opinions/themes and isolated from alternative ideas. From the user's perspective, this is akin to manipulation. From the small content creator's perspective, this is an obstacle preventing them access to a whole range of potential fans. From society's perspective, the potential consequences are far-reaching, influencing collective opinions, social behavior and political decisions. How can our recommender system be fine-tuned to avoid the creation of filter bubbles, and ensure a more inclusive and diverse content landscape? Approaching this problem involves defining one (or more) performance metric to represent diversity, and tweaking our recommender system's performance through the lens of fairness. By incorporating this metric into our evaluation framework, we aim to strike a balance between personalized recommendations and the broader societal goal of fostering rich and varied cultures and points of view.",
      "authors": [
        "C\\'ecile Log\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:53:02+00:00",
          "link": "https://arxiv.org/abs/2507.12242v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Looking for Fairness in Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12242",
        "HTML": "https://arxiv.org/html/2507.12242v1",
        "PDF": "https://arxiv.org/pdf/2507.12242"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses fairness in recommender systems and does not involve reinforcement learning or its associated data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12244",
      "abstract": "For a fixed graph H, the function #IndSub(H,*) maps graphs G to the count of induced H-copies in G; this function obviously \"counts something\" in that it has a combinatorial interpretation. Linear combinations of such functions are called graph motif parameters and have recently received significant attention in counting complexity after a seminal paper by Curticapean, Dell and Marx (STOC'17). We show that, among linear combinations of functions #IndSub(H,*) involving only graphs H without isolated vertices, precisely those with positive integer coefficients maintain a combinatorial interpretation. It is important to note that graph motif parameters can be nonnegative for all inputs G, even when some coefficients are negative.\n  Formally, we show that evaluating any graph motif parameter with a negative coefficient is impossible in an oracle variant of #P, where an implicit graph is accessed by oracle queries. Our proof follows the classification of the relativizing closure properties of #P by Hertrampf, Vollmer, and Wagner (SCT'95) and the framework developed by Ikenmeyer and Pak (STOC'22), but our application of the required Ramsey theorem turns out to be more subtle, as graphs do not have the required Ramsey property.\n  Our techniques generalize from graphs to relational structures, including colored graphs. Vastly generalizing this, we introduce motif parameters over categories that count occurrences of sub-objects in the category. We then prove a general dichotomy theorem that characterizes which such parameters have a combinatorial interpretation. Using known results in Ramsey theory for categories, we obtain a dichotomy for motif parameters of finite vector spaces as well as parameter sets.",
      "authors": [
        "Markus Bl\\\"aser",
        "Radu Curticapean",
        "Julian D\\\"orfler",
        "Christian Ikenmeyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:55:16+00:00",
          "link": "https://arxiv.org/abs/2507.12244v1",
          "size": "61kb",
          "version": "v1"
        }
      ],
      "title": "Which graph motif parameters count?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12244",
        "PDF": "https://arxiv.org/pdf/2507.12244"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph motif parameters and their combinatorial interpretations, with no connection to reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12245",
      "abstract": "Calisthenics is a fast-growing bodyweight discipline that consists of different categories, one of which is focused on skills. Skills in calisthenics encompass both static and dynamic elements performed by athletes. The evaluation of static skills is based on their difficulty level and the duration of the hold. Automated tools able to recognize isometric skills from a video by segmenting them to estimate their duration would be desirable to assist athletes in their training and judges during competitions. Although the video understanding literature on action recognition through body pose analysis is rich, no previous work has specifically addressed the problem of calisthenics skill temporal video segmentation. This study aims to provide an initial step towards the implementation of automated tools within the field of Calisthenics. To advance knowledge in this context, we propose a dataset of video footage of static calisthenics skills performed by athletes. Each video is annotated with a temporal segmentation which determines the extent of each skill. We hence report the results of a baseline approach to address the problem of skill temporal segmentation on the proposed dataset. The results highlight the feasibility of the proposed problem, while there is still room for improvement.",
      "authors": [
        "Antonio Finocchiaro",
        "Giovanni Maria Farinella",
        "Antonino Furnari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:55:27+00:00",
          "link": "https://arxiv.org/abs/2507.12245v1",
          "size": "1804kb",
          "version": "v1"
        }
      ],
      "title": "Calisthenics Skills Temporal Video Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12245",
        "HTML": "https://arxiv.org/html/2507.12245v1",
        "PDF": "https://arxiv.org/pdf/2507.12245"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses temporal video segmentation for calisthenics skills and proposes a specialized dataset, but it does not discuss reinforcement learning or any data processing techniques related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12248",
      "abstract": "Deep learning has significantly advanced the field of medical image classification, particularly with the adoption of Convolutional Neural Networks (CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer unique advantages in model development and deployment. However, their comparative performance in medical imaging tasks remains underexplored. This study presents a comprehensive analysis of CNN implementations across these frameworks, using the PathMNIST dataset as a benchmark. We evaluate training efficiency, classification accuracy and inference speed to assess their suitability for real-world applications. Our findings highlight the trade-offs between computational speed and model accuracy, offering valuable insights for researchers and practitioners in medical image analysis.",
      "authors": [
        "Anida Nezovi\\'c",
        "Jalal Romano",
        "Nada Mari\\'c",
        "Medina Kapo",
        "Amila Akagi\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:57:50+00:00",
          "link": "https://arxiv.org/abs/2507.12248v1",
          "size": "270kb",
          "version": "v1"
        }
      ],
      "title": "Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12248",
        "PDF": "https://arxiv.org/pdf/2507.12248"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is a comparative analysis of CNN performance across different frameworks for medical image classification and does not relate to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12252",
      "abstract": "While end-to-end Automatic Speech Recognition (ASR) models have shown impressive performance in transcribing general speech, they often struggle to accurately recognize contextually relevant keywords, such as proper nouns or user-specific entities.\n  Previous approaches have explored leveraging keyword dictionaries in the textual modality to improve keyword recognition, either through token-level fusion that guides token-by-token generation or phrase-level fusion that enables direct copying of keyword phrases.\n  However, these methods operate at different granularities and have their own limitations.\n  In this paper, we propose a novel multi-grained fusion approach that jointly leverages the strengths of both token-level and phrase-level fusion with Large Language Models (LLMs).\n  Our approach incorporates a late-fusion strategy that elegantly combines ASR's acoustic information with LLM's rich contextual knowledge, balancing fine-grained token precision with holistic phrase-level understanding.\n  Experiments on Chinese and English datasets demonstrate that our approach achieves state-of-the-art performance on keyword-related metrics while preserving high accuracy on non-keyword text.\n  Ablation studies further confirm that the token-level and phrase-level components both contribute significantly to the performance gains, complementing each other in our joint multi-grained framework.\n  The code and models will be publicly available at https://github.com/.",
      "authors": [
        "Shilin Zhou",
        "Zhenghua Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:59:32+00:00",
          "link": "https://arxiv.org/abs/2507.12252v1",
          "size": "208kb",
          "version": "v1"
        }
      ],
      "title": "Improving Contextual ASR via Multi-grained Fusion with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12252",
        "HTML": "https://arxiv.org/html/2507.12252v1",
        "PDF": "https://arxiv.org/pdf/2507.12252"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper proposes a multi-grained fusion approach for improving ASR using large language models, which is unrelated to reinforcement learning or data processing within the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12255",
      "abstract": "Team science dominates scientific knowledge production, but what makes academic teams successful? Using temporal data on 25.2 million publications and 31.8 million authors, we propose a novel network-driven approach to identify and study the success of persistent teams. Challenging the idea that persistence alone drives success, we find that team freshness - new collaborations built on prior experience - is key to success. High impact research tends to emerge early in a team's lifespan. Analyzing complex team overlap, we find that teams open to new collaborative ties consistently produce better science. Specifically, team re-combinations that introduce new freshness impulses sustain success, while persistence impulses from experienced teams are linked to earlier impact. Together, freshness and persistence shape team success across collaboration stages.",
      "authors": [
        "Hanjo D. Boekhout",
        "Eelke M. Heemskerk",
        "Nicol\\`o Pisani",
        "Frank W. Takes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:00:51+00:00",
          "link": "https://arxiv.org/abs/2507.12255v1",
          "size": "617kb",
          "version": "v1"
        }
      ],
      "title": "Freshness, Persistence and Success of Scientific Teams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12255",
        "HTML": "https://arxiv.org/html/2507.12255v1",
        "PDF": "https://arxiv.org/pdf/2507.12255"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates the success factors of scientific teams using network-driven approaches, without any mention of reinforcement learning or data processing techniques applicable to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12257",
      "abstract": "Exploring causal relationships in stochastic time series is a challenging yet crucial task with a vast range of applications, including finance, economics, neuroscience, and climate science. Many algorithms for Causal Discovery (CD) have been proposed, but they often exhibit a high sensitivity to noise, resulting in misleading causal inferences when applied to real data. In this paper, we observe that the frequency spectra of typical real-world time series follow a power-law distribution, notably due to an inherent self-organizing behavior. Leveraging this insight, we build a robust CD method based on the extraction of power -law spectral features that amplify genuine causal signals. Our method consistently outperforms state-of-the-art alternatives on both synthetic benchmarks and real-world datasets with known causal structures, demonstrating its robustness and practical relevance.",
      "authors": [
        "Matteo Tusoni",
        "Giuseppe Masi",
        "Andrea Coletta",
        "Aldo Glielmo",
        "Viviana Arrigoni",
        "Novella Bartolini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (stat.ML)",
        "Other Statistics (stat.OT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:02:21+00:00",
          "link": "https://arxiv.org/abs/2507.12257v1",
          "size": "971kb",
          "version": "v1"
        }
      ],
      "title": "Robust Causal Discovery in Real-World Time Series with Power-Laws",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12257",
        "PDF": "https://arxiv.org/pdf/2507.12257"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with causal discovery in time series data using power-law spectral features. It does not mention reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12259",
      "abstract": "We propose a novel unsupervised learning framework for solving nonlinear optimal control problems (OCPs) with input constraints in real-time. In this framework, a neural network (NN) learns to predict the optimal co-state trajectory that minimizes the control Hamiltonian for a given system, at any system's state, based on the Pontryagin's Minimum Principle (PMP). Specifically, the NN is trained to find the norm-optimal co-state solution that simultaneously satisfies the nonlinear system dynamics and minimizes a quadratic regulation cost. The control input is then extracted from the predicted optimal co-state trajectory by solving a quadratic program (QP) to satisfy input constraints and optimality conditions. We coin the term neural co-state regulator (NCR) to describe the combination of the co-state NN and control input QP solver. To demonstrate the effectiveness of the NCR, we compare its feedback control performance with that of an expert nonlinear model predictive control (MPC) solver on a unicycle model. Because the NCR's training does not rely on expert nonlinear control solvers which are often suboptimal, the NCR is able to produce solutions that outperform the nonlinear MPC solver in terms of convergence error and input trajectory smoothness even for system conditions that are outside its original training domain. At the same time, the NCR offers two orders of magnitude less computational time than the nonlinear MPC.",
      "authors": [
        "Lihan Lian",
        "Yuxin Tong",
        "Uduak Inyang-Udoh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:04:23+00:00",
          "link": "https://arxiv.org/abs/2507.12259v1",
          "size": "1728kb",
          "version": "v1"
        }
      ],
      "title": "Neural Co-state Regulator: A Data-Driven Paradigm for Real-time Optimal Control with Input Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12259",
        "HTML": "https://arxiv.org/html/2507.12259v1",
        "PDF": "https://arxiv.org/pdf/2507.12259"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper introduces a data-driven framework for optimal control problems, which is relevant to learning control policies as in RL, it does not make a direct contribution to data processing for RL, focusing instead on unsupervised learning methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12260",
      "abstract": "In this paper, we propose the first quantitative measure for translationese -- the translationese-index (T-index) for graded and generalizable measurement of translationese, computed from the likelihood ratios of two contrastively fine-tuned language models (LMs). We use a synthesized dataset and a dataset with translations in the wild to evaluate T-index's generalizability in cross-domain settings and its validity against human judgments. Our results show that T-index is both robust and efficient. T-index scored by two 0.5B LMs fine-tuned on only 1-5k pairs of synthetic data can well capture translationese in the wild. We find that the relative differences in T-indices between translations can well predict pairwise translationese annotations obtained from human annotators; and the absolute values of T-indices correlate well with human ratings of degrees of translationese (Pearson's $r = 0.568$). Additionally, the correlation between T-index and existing machine translation (MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting that T-index is not covered by these metrics and can serve as a complementary metric in MT QE.",
      "authors": [
        "Yikang Liu",
        "Wanyang Zhang",
        "Yiming Wang",
        "Jialong Tang",
        "Pei Zhang",
        "Baosong Yang",
        "Fei Huang",
        "Rui Wang",
        "Hai Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:06:05+00:00",
          "link": "https://arxiv.org/abs/2507.12260v1",
          "size": "417kb",
          "version": "v1"
        }
      ],
      "title": "Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12260",
        "HTML": "https://arxiv.org/html/2507.12260v1",
        "PDF": "https://arxiv.org/pdf/2507.12260"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with measuring translationese using likelihood ratios and language models in the context of machine translation, with no relevance to reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12261",
      "abstract": "For clinical data integration and healthcare services, the HL7 FHIR standard has established itself as a desirable format for interoperability between complex health data. Previous attempts at automating the translation from free-form clinical notes into structured FHIR resources rely on modular, rule-based systems or LLMs with instruction tuning and constrained decoding. Since they frequently suffer from limited generalizability and structural inconformity, we propose an end-to-end framework powered by LLM agents, code execution, and healthcare terminology database tools to address these issues. Our solution, called Infherno, is designed to adhere to the FHIR document schema and competes well with a human baseline in predicting FHIR resources from unstructured text. The implementation features a front end for custom and synthetic data and both local and proprietary models, supporting clinical data integration processes and interoperability across institutions.",
      "authors": [
        "Johann Frei",
        "Nils Feldhus",
        "Lisa Raithel",
        "Roland Roller",
        "Alexander Meyer",
        "Frank Kramer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:06:51+00:00",
          "link": "https://arxiv.org/abs/2507.12261v1",
          "size": "6492kb",
          "version": "v1"
        }
      ],
      "title": "Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12261",
        "HTML": "https://arxiv.org/html/2507.12261v1",
        "PDF": "https://arxiv.org/pdf/2507.12261"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This research addresses clinical data integration via the FHIR standards and free-form clinical notes, without any mention of reinforcement learning or data processing relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12262",
      "abstract": "Gaussian processes have become a popular tool for nonparametric regression because of their flexibility and uncertainty quantification. However, they often use stationary kernels, which limit the expressiveness of the model and may be unsuitable for many datasets. We propose a framework that uses nonstationary kernels whose parameters vary across the feature space, modeling these parameters as the output of a neural network that takes the features as input. The neural network and Gaussian process are trained jointly using the chain rule to calculate derivatives. Our method clearly describes the behavior of the nonstationary parameters and is compatible with approximation methods for scaling to large datasets. It is flexible and easily adapts to different nonstationary kernels without needing to redesign the optimization procedure. Our methods are implemented with the GPyTorch library and can be readily modified. We test a nonstationary variance and noise variant of our method on several machine learning datasets and find that it achieves better accuracy and log-score than both a stationary model and a hierarchical model approximated with variational inference. Similar results are observed for a model with only nonstationary variance. We also demonstrate our approach's ability to recover the nonstationary parameters of a spatial dataset.",
      "authors": [
        "Zachary James",
        "Joseph Guinness"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:09:49+00:00",
          "link": "https://arxiv.org/abs/2507.12262v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "A Framework for Nonstationary Gaussian Processes with Neural Network Parameters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12262",
        "HTML": "https://arxiv.org/html/2507.12262v1",
        "PDF": "https://arxiv.org/pdf/2507.12262"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for nonstationary Gaussian processes with neural network parameters and does not address reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12265",
      "abstract": "Ever since Clos topologies were used in datacenter networks (DCNs), a practical centralized scheduling algorithm that supports dynamic scheduling has been absent. The introduction of optical switches in DCNs as a future-proof solution exacerbates this problem due to several properties of optical switches, such as the fact that they are generally bufferless and therefore rely on centralized scheduling, and that they have long switching times and therefore require the number of rearrangements to be minimized.\n  In this paper, we propose a centralized scheduling algorithm that achieves theoretical maximum throughput even in one-rate bidirectional Clos networks, while producing schemes with near-minimal numbers of rearrangements. It is the only algorithm that directly supports bidirectional Clos networks and has a time efficiency high enough to support dynamic scheduling to date. For static minimal rewiring, its running time ranges from a fraction to a few hundredths of other algorithms, and the number of rearrangements has also been steadily improved, allowing for more frequent adjustments and less impact on ongoing communications. In addition, the algorithm is very flexible and can support various functional requirements in real-world environments. We achieve this result through the replacement chain concept and bitset optimization.",
      "authors": [
        "Zihan Zhu",
        "Dongchao Wu",
        "Zhanbang Zhang",
        "Jian Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:12:00+00:00",
          "link": "https://arxiv.org/abs/2507.12265v1",
          "size": "787kb",
          "version": "v1"
        }
      ],
      "title": "FastReChain: Highly Responsive and Low-Overhead Centralized Route Scheduling in Clos Datacenter Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12265",
        "HTML": "https://arxiv.org/html/2507.12265v1",
        "PDF": "https://arxiv.org/pdf/2507.12265"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is centered on a centralized route scheduling algorithm for datacenter networks and does not mention reinforcement learning or any RL-related data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12269",
      "abstract": "Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of extremely low birth weight infants. Defined by oxygen dependence at 36 weeks postmenstrual age, it causes lifelong respiratory complications. However, preventive interventions carry severe risks, including neurodevelopmental impairment, ventilator-induced lung injury, and systemic complications. Therefore, early BPD prognosis and prediction of BPD outcome is crucial to avoid unnecessary toxicity in low risk infants. Admission radiographs of extremely preterm infants are routinely acquired within 24h of life and could serve as a non-invasive prognostic tool. In this work, we developed and investigated a deep learning approach using chest X-rays from 163 extremely low-birth-weight infants ($\\leq$32 weeks gestation, 401-999g) obtained within 24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult chest radiographs, employing progressive layer freezing with discriminative learning rates to prevent overfitting and evaluated a CutMix augmentation and linear probing. For moderate/severe BPD outcome prediction, our best performing model with progressive freezing, linear probing and CutMix achieved an AUROC of 0.78 $\\pm$ 0.10, balanced accuracy of 0.69 $\\pm$ 0.10, and an F1-score of 0.67 $\\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet initialization (p = 0.031) which confirms domain-specific pretraining to be important for BPD outcome prediction. Routine IRDS grades showed limited prognostic value (AUROC 0.57 $\\pm$ 0.11), confirming the need of learned markers. Our approach demonstrates that domain-specific pretraining enables accurate BPD prediction from routine day-1 radiographs. Through progressive freezing and linear probing, the method remains computationally feasible for site-level implementation and future federated learning deployments.",
      "authors": [
        "Sybelle Goedicke-Fritz (1)",
        "Michelle Bous (1)",
        "Annika Engel (2)",
        "Matthias Flotho (2 and 5)",
        "Pascal Hirsch (2)",
        "Hannah Wittig (1)",
        "Dino Milanovic (2)",
        "Dominik Mohr (1)",
        "Mathias Kaspar (6)",
        "Sogand Nemat (3)",
        "Dorothea Kerner (3)",
        "Arno B\\\"ucker (3)",
        "Andreas Keller (2 and 5 and 7)",
        "Sascha Meyer (4)",
        "Michael Zemlin (1)",
        "Philipp Flotho (2 and 5) ((1) Department of General Pediatrics and Neonatology",
        "Saarland University",
        "Campus Homburg",
        "Homburg/Saar",
        "Germany",
        "(2) Chair for Clinical Bioinformatics",
        "Saarland Informatics Campus",
        "Saarland University",
        "Saarbr\\\"ucken",
        "Germany",
        "(3) Department of Radiology",
        "and Interventional Radiology",
        "University Hospital of Saarland",
        "Homburg",
        "Germany",
        "(4) Clinical Centre Karlsruhe",
        "Franz-Lust Clinic for Paediatrics",
        "Karlsruhe",
        "Germany",
        "(5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS)",
        "Saarland University Campus",
        "Germany",
        "(6) Digital Medicine",
        "University Hospital of Augsburg",
        "Augsburg",
        "Germany",
        "(7) Pharma Science Hub (PSH)",
        "Saarland University Campus",
        "Germany)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:19:44+00:00",
          "link": "https://arxiv.org/abs/2507.12269v1",
          "size": "483kb",
          "version": "v1"
        }
      ],
      "title": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12269",
        "PDF": "https://arxiv.org/pdf/2507.12269"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study explores a deep learning approach to predict bronchopulmonary dysplasia using chest radiographs, focusing on medical image processing without discussing reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12273",
      "abstract": "Autonomous robots are increasingly being tested into public spaces to enhance user experiences, particularly in cultural and educational settings. This paper presents the design, implementation, and evaluation of the autonomous museum guide robot Alter-Ego equipped with advanced navigation and interactive capabilities. The robot leverages state-of-the-art Large Language Models (LLMs) to provide real-time, context aware question-and-answer (Q&A) interactions, allowing visitors to engage in conversations about exhibits. It also employs robust simultaneous localization and mapping (SLAM) techniques, enabling seamless navigation through museum spaces and route adaptation based on user requests. The system was tested in a real museum environment with 34 participants, combining qualitative analysis of visitor-robot conversations and quantitative analysis of pre and post interaction surveys. Results showed that the robot was generally well-received and contributed to an engaging museum experience, despite some limitations in comprehension and responsiveness. This study sheds light on HRI in cultural spaces, highlighting not only the potential of AI-driven robotics to support accessibility and knowledge acquisition, but also the current limitations and challenges of deploying such technologies in complex, real-world environments.",
      "authors": [
        "Luca Garello",
        "Francesca Cocchella",
        "Alessandra Sciutti",
        "Manuel Catalano",
        "Francesco Rea"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:22:00+00:00",
          "link": "https://arxiv.org/abs/2507.12273v1",
          "size": "7115kb",
          "version": "v1"
        }
      ],
      "title": "Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12273",
        "PDF": "https://arxiv.org/pdf/2507.12273"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper details an autonomous robot system for museums focusing on visitor interaction and navigation, without any mention of reinforcement learning or RL data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12283",
      "abstract": "Diffusion models have demonstrated remarkable image generation capabilities, but also pose risks in privacy and fairness by memorizing sensitive concepts or perpetuating biases. We propose a novel \\textbf{concept erasure} method for text-to-image diffusion models, designed to remove specified concepts (e.g., a private individual or a harmful stereotype) from the model's generative repertoire. Our method, termed \\textbf{FADE} (Fair Adversarial Diffusion Erasure), combines a trajectory-aware fine-tuning strategy with an adversarial objective to ensure the concept is reliably removed while preserving overall model fidelity. Theoretically, we prove a formal guarantee that our approach minimizes the mutual information between the erased concept and the model's outputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable Diffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity, explicit content, and style erasure tasks from MACE). FADE achieves state-of-the-art concept removal performance, surpassing recent baselines like ESD, UCE, MACE, and ANT in terms of removal efficacy and image quality. Notably, FADE improves the harmonic mean of concept removal and fidelity by 5--10\\% over the best prior method. We also conduct an ablation study to validate each component of FADE, confirming that our adversarial and trajectory-preserving objectives each contribute to its superior performance. Our work sets a new standard for safe and fair generative modeling by unlearning specified concepts without retraining from scratch.",
      "authors": [
        "Zixuan Fu",
        "Yan Ren",
        "Finn Carter",
        "Chenyue Wang",
        "Ze Niu",
        "Dacheng Yu",
        "Emily Davis",
        "Bo Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:31:21+00:00",
          "link": "https://arxiv.org/abs/2507.12283v1",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "title": "FADE: Adversarial Concept Erasure in Flow Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12283",
        "HTML": "https://arxiv.org/html/2507.12283v1",
        "PDF": "https://arxiv.org/pdf/2507.12283"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on concept erasure in diffusion models for privacy and fairness, involving image generation but does not involve reinforcement learning or any related data processing elements in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12284",
      "abstract": "Advancements in LLMs have enhanced task automation in software engineering; however, current evaluations primarily focus on natural language tasks, overlooking code quality. Most benchmarks prioritize high-level reasoning over executable code and real-world performance, leaving gaps in understanding true capabilities and risks associated with these models in production. To address this issue, we propose MERA Code, a new addition to the MERA benchmark family, specifically focused on evaluating code for the latest code generation LLMs in Russian. This benchmark includes 11 evaluation tasks that span 8 programming languages. Our proposed evaluation methodology features a taxonomy that outlines the practical coding skills necessary for models to complete these tasks. The benchmark comprises an open-source codebase for users to conduct MERA assessments, a scoring system compatible with various programming environments, and a platform featuring a leaderboard and submission system. We evaluate open LLMs and frontier API models, analyzing their limitations in terms of practical coding tasks in non-English languages. We are publicly releasing MERA to guide future research, anticipate groundbreaking features in model development, and standardize evaluation procedures.",
      "authors": [
        "Artem Chervyakov",
        "Alexander Kharitonov",
        "Pavel Zadorozhny",
        "Adamenko Pavel",
        "Rodion Levichev",
        "Dmitrii Vorobev",
        "Dmitrii Salikhov",
        "Aidar Valeev",
        "Alena Pestova",
        "Maria Dziuba",
        "Ilseyar Alimova",
        "Artem Zavgorodnev",
        "Aleksandr Medvedev",
        "Stanislav Moiseev",
        "Elena Bruches",
        "Daniil Grebenkin",
        "Roman Derunets",
        "Vikulov Vladimir",
        "Anton Emelyanov",
        "Dmitrii Babaev",
        "Vladimir V. Ivanov",
        "Valentin Malykh",
        "Alena Fenogenova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:31:33+00:00",
          "link": "https://arxiv.org/abs/2507.12284v1",
          "size": "307kb",
          "version": "v1"
        }
      ],
      "title": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12284",
        "HTML": "https://arxiv.org/html/2507.12284v1",
        "PDF": "https://arxiv.org/pdf/2507.12284"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the evaluation of code generation models and does not discuss any aspects related to data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12286",
      "abstract": "SHACL and OWL are two prominent W3C standards for managing RDF data. These languages share many features, but they have one fundamental difference: OWL, designed for inferring facts from incomplete data, makes the open-world assumption, whereas SHACL is a constraint language that treats the data as complete and must be validated under the closed-world assumption. The combination of both formalisms is very appealing and has been called for, but their semantic gap is a major challenge, semantically and computationally. In this paper, we advocate a semantics for SHACL validation in the presence of ontologies based on core universal models. We provide a technique for constructing these models for ontologies in the rich data-tractable description logic Horn-ALCHIQ. Furthermore, we use a finite representation of this model to develop a rewriting technique that reduces SHACL validation in the presence of ontologies to standard validation. Finally, we study the complexity of SHACL validation in the presence of ontologies, and show that even very simple ontologies make the problem EXPTIME-complete, and PTIME-complete in data complexity.",
      "authors": [
        "Anouk Oudshoorn",
        "Magdalena Ortiz",
        "Mantas Simkus"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:38:27+00:00",
          "link": "https://arxiv.org/abs/2507.12286v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12286",
        "HTML": "https://arxiv.org/html/2507.12286v1",
        "PDF": "https://arxiv.org/pdf/2507.12286"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper involves SHACL validation and ontologies, which are unrelated to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12292",
      "abstract": "Calisthenics skill classification is the computer vision task of inferring the skill performed by an athlete from images, enabling automatic performance assessment and personalized analytics. Traditional methods for calisthenics skill recognition are based on pose estimation methods to determine the position of skeletal data from images, which is later fed to a classification algorithm to infer the performed skill. Despite the progress in human pose estimation algorithms, they still involve high computational costs, long inference times, and complex setups, which limit the applicability of such approaches in real-time applications or mobile devices. This work proposes a direct approach to calisthenics skill recognition, which leverages depth estimation and athlete patch retrieval to avoid the computationally expensive human pose estimation module. Using Depth Anything V2 for depth estimation and YOLOv10 for athlete localization, we segment the subject from the background rather than relying on traditional pose estimation techniques. This strategy increases efficiency, reduces inference time, and improves classification accuracy. Our approach significantly outperforms skeleton-based methods, achieving 38.3x faster inference with RGB image patches and improved classification accuracy with depth patches (0.837 vs. 0.815). Beyond these performance gains, the modular design of our pipeline allows for flexible replacement of components, enabling future enhancements and adaptation to real-world applications.",
      "authors": [
        "Antonio Finocchiaro",
        "Giovanni Maria Farinella",
        "Antonino Furnari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:44:29+00:00",
          "link": "https://arxiv.org/abs/2507.12292v1",
          "size": "5241kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12292",
        "HTML": "https://arxiv.org/html/2507.12292v1",
        "PDF": "https://arxiv.org/pdf/2507.12292"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses data processing techniques in computer vision for skill classification, it does not relate to reinforcement learning or data processing within RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12295",
      "abstract": "Text anomaly detection is a critical task in natural language processing (NLP), with applications spanning fraud detection, misinformation identification, spam detection and content moderation, etc. Despite significant advances in large language models (LLMs) and anomaly detection algorithms, the absence of standardized and comprehensive benchmarks for evaluating the existing anomaly detection methods on text data limits rigorous comparison and development of innovative approaches. This work performs a comprehensive empirical study and introduces a benchmark for text anomaly detection, leveraging embeddings from diverse pre-trained language models across a wide array of text datasets. Our work systematically evaluates the effectiveness of embedding-based text anomaly detection by incorporating (1) early language models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI (small, ada, large)); (3) multi-domain text datasets (news, social media, scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC). Our experiments reveal a critical empirical insight: embedding quality significantly governs anomaly detection efficacy, and deep learning-based approaches demonstrate no performance advantage over conventional shallow algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived embeddings.In addition, we observe strongly low-rank characteristics in cross-model performance matrices, which enables an efficient strategy for rapid model evaluation (or embedding evaluation) and selection in practical applications. Furthermore, by open-sourcing our benchmark toolkit that includes all embeddings from different models and code at https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work provides a foundation for future research in robust and scalable text anomaly detection systems.",
      "authors": [
        "Feng Xiao",
        "Jicong Fan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:47:41+00:00",
          "link": "https://arxiv.org/abs/2507.12295v1",
          "size": "464kb",
          "version": "v1"
        }
      ],
      "title": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12295",
        "HTML": "https://arxiv.org/html/2507.12295v1",
        "PDF": "https://arxiv.org/pdf/2507.12295"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for text anomaly detection and discusses NLP tasks, without addressing reinforcement learning or data processing specifically relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12296",
      "abstract": "Despite widespread debunking, many psychological myths remain deeply entrenched. This paper investigates whether Large Language Models (LLMs) mimic human behaviour of myth belief and explores methods to mitigate such tendencies. Using 50 popular psychological myths, we evaluate myth belief across multiple LLMs under different prompting strategies, including retrieval-augmented generation and swaying prompts. Results show that LLMs exhibit significantly lower myth belief rates than humans, though user prompting can influence responses. RAG proves effective in reducing myth belief and reveals latent debiasing potential within LLMs. Our findings contribute to the emerging field of Machine Psychology and highlight how cognitive science methods can inform the evaluation and development of LLM-based systems.",
      "authors": [
        "Bevan Koopman and Guido Zuccon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:49:45+00:00",
          "link": "https://arxiv.org/abs/2507.12296v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "Humans are more gullible than LLMs in believing common psychological myths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12296",
        "HTML": "https://arxiv.org/html/2507.12296v1",
        "PDF": "https://arxiv.org/pdf/2507.12296"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper investigates myth belief across large language models and human participants but does not address reinforcement learning or data processing concerns relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12297",
      "abstract": "To address the performance limitations of the Segment Anything Model (SAM) in specific domains, existing works primarily adopt adapter-based one-step adaptation paradigms. However, some of these methods are specific developed for specific domains. If used on other domains may lead to performance degradation. This issue of catastrophic forgetting severely limits the model's scalability. To address this issue, this paper proposes RegCL, a novel non-replay continual learning (CL) framework designed for efficient multi-domain knowledge integration through model merging. Specifically, RegCL incorporates the model merging algorithm into the continual learning paradigm by merging the parameters of SAM's adaptation modules (e.g., LoRA modules) trained on different domains. The merging process is guided by weight optimization, which minimizes prediction discrepancies between the merged model and each of the domain-specific models. RegCL effectively consolidates multi-domain knowledge while maintaining parameter efficiency, i.e., the model size remains constant regardless of the number of tasks, and no historical data storage is required. Experimental results demonstrate that RegCL achieves favorable continual learning performance across multiple downstream datasets, validating its effectiveness in dynamic scenarios.",
      "authors": [
        "Yuan-Chen Shu",
        "Zhiwei Lin",
        "Yongtao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:51:37+00:00",
          "link": "https://arxiv.org/abs/2507.12297v1",
          "size": "1444kb",
          "version": "v1"
        }
      ],
      "title": "RegCL: Continual Adaptation of Segment Anything Model via Model Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12297",
        "HTML": "https://arxiv.org/html/2507.12297v1",
        "PDF": "https://arxiv.org/pdf/2507.12297"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a continual learning framework for the Segment Anything Model, specifically addressing model merging and multi-domain knowledge integration, with no mention of reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12298",
      "abstract": "Eligibility criteria play a critical role in clinical trials by determining the target patient population, which significantly influences the outcomes of medical interventions. However, current approaches for designing eligibility criteria have limitations to support interactive exploration of the large space of eligibility criteria. They also ignore incorporating detailed characteristics from the original electronic health record (EHR) data for criteria refinement. To address these limitations, we proposed TrialCompass, a visual analytics system integrating a novel workflow, which can empower clinicians to iteratively explore the vast space of eligibility criteria through knowledge-driven and outcome-driven approaches. TrialCompass supports history-tracking to help clinicians trace the evolution of their adjustments and decisions when exploring various forms of data (i.e., eligibility criteria, outcome metrics, and detailed characteristics of original EHR data) through these two approaches. This feature can help clinicians comprehend the impact of eligibility criteria on outcome metrics and patient characteristics, which facilitates systematic refinement of eligibility criteria. Using a real-world dataset, we demonstrated the effectiveness of TrialCompass in providing insights into designing eligibility criteria for septic shock and sepsis-associated acute kidney injury. We also discussed the research prospects of applying visual analytics to clinical trials.",
      "authors": [
        "Rui Sheng",
        "Xingbo Wang",
        "Jiachen Wang",
        "Xiaofu Jin",
        "Zhonghua Sheng",
        "Zhenxing Xu",
        "Suraj Rajendran",
        "Huamin Qu",
        "and Fei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:54:16+00:00",
          "link": "https://arxiv.org/abs/2507.12298v1",
          "size": "1869kb",
          "version": "v1"
        }
      ],
      "title": "TrialCompass: Visual Analytics for Enhancing the Eligibility Criteria Design of Clinical Trials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12298",
        "HTML": "https://arxiv.org/html/2507.12298v1",
        "PDF": "https://arxiv.org/pdf/2507.12298"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper centers around a visual analytics system for refining eligibility criteria in clinical trials, which does not relate to reinforcement learning or any aspect of data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12304",
      "abstract": "The $k$-opt algorithm is one of the simplest and most widely used heuristics for solving the traveling salesman problem. Starting from an arbitrary tour, the $k$-opt algorithm improves the current tour in each iteration by exchanging up to $k$ edges. The algorithm continues until no further improvement of this kind is possible. For a long time, it remained an open question how many iterations the $k$-opt algorithm might require for small values of $k$, assuming the use of an optimal pivot rule. In this paper, we resolve this question for the cases $k = 3$ and $k = 4$ by proving that in both these cases an exponential number of iterations may be needed even if an optimal pivot rule is used. Combined with a recent result from Heimann, Hoang, and Hougardy (ICALP 2024), this provides a complete answer for all $k \\geq 3$ regarding the number of iterations the $k$-opt algorithm may require under an optimal pivot rule. In addition we establish an analogous exponential lower bound for the 2.5-opt algorithm, a variant that generalizes 2-opt and is a restricted version of 3-opt. All our results hold for both the general and the metric traveling salesman problem.",
      "authors": [
        "Sophia Heimann",
        "Hung P. Hoang",
        "Stefan Hougardy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:04:26+00:00",
          "link": "https://arxiv.org/abs/2507.12304v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "A near-complete resolution of the exponential-time complexity of k-opt for the traveling salesman problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12304",
        "PDF": "https://arxiv.org/pdf/2507.12304"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with the exponential-time complexity of the k-opt algorithm for the traveling salesman problem and does not involve reinforcement learning or data processing within the RL scope."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12305",
      "abstract": "The data privacy constraint in online continual learning (OCL), where the data can be seen only once, complicates the catastrophic forgetting problem in streaming data. A common approach applied by the current SOTAs in OCL is with the use of memory saving exemplars or features from previous classes to be replayed in the current task. On the other hand, the prompt-based approach performs excellently in continual learning but with the cost of a growing number of trainable parameters. The first approach may not be applicable in practice due to data openness policy, while the second approach has the issue of throughput associated with the streaming data. In this study, we propose a novel prompt-based method for online continual learning that includes 4 main components: (1) single light-weight prompt generator as a general knowledge, (2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model (PTM) generalization preserving, and (4) hard-soft updates mechanism. Our proposed method achieves significantly higher performance than the current SOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity analysis shows that our method requires a relatively smaller number of parameters and achieves moderate training time, inference time, and throughput. For further study, the source code of our method is available at https://github.com/anwarmaxsum/PROL.",
      "authors": [
        "M. Anwar Ma'sum",
        "Mahardhika Pratama",
        "Savitha Ramasamy",
        "Lin Liu",
        "Habibullah Habibullah",
        "and Ryszard Kowalczyk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:04:46+00:00",
          "link": "https://arxiv.org/abs/2507.12305v1",
          "size": "832kb",
          "version": "v1"
        }
      ],
      "title": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12305",
        "HTML": "https://arxiv.org/html/2507.12305v1",
        "PDF": "https://arxiv.org/pdf/2507.12305"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is focused on continual learning and prompt-based learning methods for online continual learning, aimed at enhancing performance across various datasets like CIFAR100. It doesn't directly discuss data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12307",
      "abstract": "The Golub-Kahan-Tikhonov method is a popular solution technique for large linear discrete ill-posed problems. This method first applies partial Golub-Kahan bidiagonalization to reduce the size of the given problem and then uses Tikhonov regularization to compute a meaningful approximate solution of the reduced problem. It is well known that iterated variants of this method often yield approximate solutions of higher quality than the standard non-iterated method. Moreover, it produces more accurate computed solutions than the Arnoldi method when the matrix that defines the linear discrete ill-posed problem is far from symmetric.\n  This paper starts with an ill-posed operator equation in infinite-dimensional Hilbert space, discretizes the equation, and then applies the iterated Golub-Kahan-Tikhonov method to the solution of the latter problem. An error analysis that addresses all discretization and approximation errors is provided. Additionally, a new approach for choosing the regularization parameter is described. This solution scheme produces more accurate approximate solutions than the standard (non-iterated) Golub-Kahan-Tikhonov method and the iterated Arnoldi-Tikhonov method.",
      "authors": [
        "Davide Bianchi",
        "Marco Donatelli",
        "Davide Furch\\`i",
        "Lothar Reichel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:05:15+00:00",
          "link": "https://arxiv.org/abs/2507.12307v1",
          "size": "1008kb",
          "version": "v1"
        }
      ],
      "title": "The iterated Golub-Kahan-Tikhonov method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12307",
        "HTML": "https://arxiv.org/html/2507.12307v1",
        "PDF": "https://arxiv.org/pdf/2507.12307"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on an iterative method for solving large linear discrete ill-posed problems, which does not pertain to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12308",
      "abstract": "Large Language Models (LLMs) have become widely used across diverse NLP tasks and domains, demonstrating their adaptability and effectiveness. In the realm of Electronic Design Automation (EDA), LLMs show promise for tasks like Register-Transfer Level (RTL) code generation and summarization. However, despite the proliferation of LLMs for general code-related tasks, there's a dearth of research focused on evaluating and refining these models for hardware description languages (HDLs), notably VHDL. In this study, we evaluate the performance of existing code LLMs for VHDL code generation and summarization using various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter, an in-house dataset, aims to gauge LLMs' understanding of functionally equivalent code. Our findings reveal consistent underperformance of these models across different metrics, underscoring a significant gap in their suitability for this domain. To address this challenge, we propose Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of LLMs for VHDL code generation and summarization tasks. CoDes involves generating a series of intermediate descriptive steps based on: (i) the problem statement for code generation, and (ii) the VHDL code for summarization. These steps are then integrated with the original input prompt (problem statement or code) and provided as input to the LLMs to generate the final output. Our experiments demonstrate that the CoDes approach significantly surpasses the standard prompting strategy across various metrics on both datasets. This method not only improves the quality of VHDL code generation and summarization but also serves as a framework for future research aimed at enhancing code LLMs for VHDL.",
      "authors": [
        "Prashanth Vijayaraghavan",
        "Apoorva Nitsure",
        "Charles Mackin",
        "Luyao Shi",
        "Stefano Ambrogio",
        "Arvind Haran",
        "Viresh Paruthi",
        "Ali Elzein",
        "Dan Coops",
        "David Beymer",
        "Tyler Baldwin",
        "Ehsan Degan"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:05:30+00:00",
          "link": "https://arxiv.org/abs/2507.12308v1",
          "size": "518kb",
          "version": "v1"
        }
      ],
      "title": "Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12308",
        "HTML": "https://arxiv.org/html/2507.12308v1",
        "PDF": "https://arxiv.org/pdf/2507.12308"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study centers on improving code language models for VHDL code generation and summarization. It does not address data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12311",
      "abstract": "Ontology interoperability is one of the complicated issues that restricts the use of ontologies in knowledge graphs (KGs). Different ontologies with conflicting and overlapping concepts make it difficult to design, develop, and deploy an interoperable ontology for downstream tasks. We propose an ecosystem for ontology interoperability. The ecosystem employs three state-of-the-art semantic techniques in different phases of the ontology engineering life cycle: ontology design patterns (ODPs) in the design phase, ontology matching and versioning (OM\\&OV) in the develop phase, and ontology-compliant knowledge graphs (OCKGs) in the deploy phase, to achieve better ontology interoperability in real-world applications. A case study in the building domain validates the usefulness of the proposed ecosystem.",
      "authors": [
        "Zhangcheng Qiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:06:29+00:00",
          "link": "https://arxiv.org/abs/2507.12311v1",
          "size": "1158kb",
          "version": "v1"
        }
      ],
      "title": "An Ecosystem for Ontology Interoperability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12311",
        "HTML": "https://arxiv.org/html/2507.12311v1",
        "PDF": "https://arxiv.org/pdf/2507.12311"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper explores ontology interoperability within knowledge graphs, which is unrelated to reinforcement learning or data processing specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12314",
      "abstract": "While reinforcement learning-trained Large Reasoning Models (LRMs, e.g., Deepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large Language Models (LLMs) domain, their susceptibility to security threats remains a critical vulnerability. This weakness is particularly evident in Chain-of-Thought (CoT) generation processes, where adversarial methods like backdoor prompt attacks can systematically subvert the model's core reasoning mechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this vulnerability through exploiting prompt controllability, simultaneously degrading both CoT safety and task performance with low-cost interventions. To address this compounded security-performance vulnerability, we propose Thought Purity (TP): a defense paradigm that systematically strengthens resistance to malicious content while preserving operational efficacy. Our solution achieves this through three synergistic components: (1) a safety-optimized data processing pipeline (2) reinforcement learning-enhanced rule constraints (3) adaptive monitoring metrics. Our approach establishes the first comprehensive defense mechanism against CoTA vulnerabilities in reinforcement learning-aligned reasoning systems, significantly advancing the security-functionality equilibrium for next-generation AI architectures.",
      "authors": [
        "Zihao Xue and Zhen Bi and Long Ma and Zhenlin Hu and Yan Wang and Zhenfang Liu and Qing Sheng and Jie Xiao and Jungang Lou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:09:13+00:00",
          "link": "https://arxiv.org/abs/2507.12314v1",
          "size": "1249kb",
          "version": "v1"
        }
      ],
      "title": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12314",
        "HTML": "https://arxiv.org/html/2507.12314v1",
        "PDF": "https://arxiv.org/pdf/2507.12314"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper specifically discusses a safety-optimized data processing pipeline as a part of the Thought Purity defense paradigm for reinforcement learning-aligned reasoning systems, directly contributing to data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12318",
      "abstract": "We argue that diffusion models' success in modeling complex distributions is, for the most part, coming from their input conditioning. This paper investigates the representation used to condition diffusion models from the perspective that ideal representations should improve sample fidelity, be easy to generate, and be compositional to allow out-of-training samples generation. We introduce Discrete Latent Code (DLC), an image representation derived from Simplicial Embeddings trained with a self-supervised learning objective. DLCs are sequences of discrete tokens, as opposed to the standard continuous image embeddings. They are easy to generate and their compositionality enables sampling of novel images beyond the training distribution. Diffusion models trained with DLCs have improved generation fidelity, establishing a new state-of-the-art for unconditional image generation on ImageNet. Additionally, we show that composing DLCs allows the image generator to produce out-of-distribution samples that coherently combine the semantics of images in diverse ways. Finally, we showcase how DLCs can enable text-to-image generation by leveraging large-scale pretrained language models. We efficiently finetune a text diffusion language model to generate DLCs that produce novel samples outside of the image generator training distribution.",
      "authors": [
        "Samuel Lavoie",
        "Michael Noukhovitch",
        "Aaron Courville"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:12:17+00:00",
          "link": "https://arxiv.org/abs/2507.12318v1",
          "size": "18400kb",
          "version": "v1"
        }
      ],
      "title": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12318",
        "HTML": "https://arxiv.org/html/2507.12318v1",
        "PDF": "https://arxiv.org/pdf/2507.12318"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on diffusion models and discrete latent codes for image generation, without any mention of reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12327",
      "abstract": "With the increasing energy demand and the growing integration of renewable sources of energy, power systems face operational challenges such as overloads, losses, and stability concerns, particularly as networks operate near their capacity limits. Flexible alternating current transmission system (FACTS) devices are essential to ensure reliable grid operations and enable the efficient integration of renewable energy. This work introduces a mixed-integer second-order cone programming (MISOCP) model for the multi-period scheduling of key FACTS devices in electric transmission systems. The proposed model integrates four key control mechanisms: (i) on-load tap changers (OLTCs) for voltage regulation via discrete taps; (ii) static synchronous compensators (STATCOMs) and (iii) shunt reactors for reactive power compensation; and (iv) thyristor-controlled series capacitors (TCSCs) for adjustable impedance and flow control. The objective is to minimize active power losses using a limited number of control actions while meeting physical and operational constraints at all times throughout the defined time horizon. To ensure tractability, the model employs a second-order cone relaxation of the power flow. Device-specific constraints are handled via binary expansion and linearization: OLTCs and shunt reactors are modelled with discrete variables, STATCOMs through reactive power bounds, and TCSCs using a reformulation-linearization technique (RLT). A multi-period formulation captures the sequential nature of decision making, ensuring consistency across time steps. The model is evaluated on the IEEE 9-bus, 30-bus, and RTS96 test systems, demonstrating its ability to reduce losses, with potential applicability to larger-scale grids.",
      "authors": [
        "Mohamad Charara (Polytechnique Montr\\'eal",
        "GERAD & MILA",
        "Canada)",
        "Martin De Montigny (Hydro-Qu\\'ebec",
        "Canada)",
        "Nivine Abou Daher (Hydro-Qu\\'ebec",
        "Canada)",
        "Hanane Dagdougui (Polytechnique Montr\\'eal",
        "GERAD & MILA",
        "Canada)",
        "Antoine Lesage-Landry (Polytechnique Montr\\'eal",
        "GERAD & MILA",
        "Canada)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:21:11+00:00",
          "link": "https://arxiv.org/abs/2507.12327v1",
          "size": "195kb",
          "version": "v1"
        }
      ],
      "title": "Mixed-integer Second-Order Cone Programming for Multi-period Scheduling of Flexible AC Transmission System Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12327",
        "HTML": "https://arxiv.org/html/2507.12327v1",
        "PDF": "https://arxiv.org/pdf/2507.12327"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is related to power systems and scheduling of transmission system devices, with no relevance to reinforcement learning or data processing in the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12329",
      "abstract": "This paper introduces a neural polar decoder (NPD) for deletion channels with a constant deletion rate. Existing polar decoders for deletion channels exhibit high computational complexity of $O(N^4)$, where $N$ is the block length. This limits the application of polar codes for deletion channels to short-to-moderate block lengths. In this work, we demonstrate that employing NPDs for deletion channels can reduce the computational complexity. First, we extend the architecture of the NPD to support deletion channels. Specifically, the NPD architecture consists of four neural networks (NNs), each replicating fundamental successive cancellation (SC) decoder operations. To support deletion channels, we change the architecture of only one. The computational complexity of the NPD is $O(AN\\log N)$, where the parameter $A$ represents a computational budget determined by the user and is independent of the channel. We evaluate the new extended NPD for deletion channels with deletion rates $\\delta\\in\\{0.01, 0.1\\}$ and we verify the NPD with the ground truth given by the trellis decoder by Tal et al. We further show that due to the reduced complexity of the NPD, we are able to incorporate list decoding and further improve performance. We believe that the extended NPD presented here could have applications in future technologies like DNA storage.",
      "authors": [
        "Ziv Aharoni and Henry D. Pfister"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:22:34+00:00",
          "link": "https://arxiv.org/abs/2507.12329v1",
          "size": "500kb",
          "version": "v1"
        }
      ],
      "title": "Neural Polar Decoders for Deletion Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12329",
        "PDF": "https://arxiv.org/pdf/2507.12329"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses neural polar decoders for deletion channels, focusing on error correction and computational complexity, unrelated to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12334",
      "abstract": "Text is an integral but understudied component of visualization design. Although recent studies have examined how text elements (e.g., titles and annotations) influence comprehension, preferences, and predictions, many questions remain about textual design and use in practice. This paper introduces a framework for understanding text functions in information visualizations, building on and filling gaps in prior classifications and taxonomies. Through an analysis of 120 real-world visualizations and 804 text elements, we identified ten distinct text functions, ranging from identifying data mappings to presenting valenced subtext. We further identify patterns in text usage and conduct a factor analysis, revealing four overarching text-informed design strategies: Attribution and Variables, Annotation-Centric Design, Visual Embellishments, and Narrative Framing. In addition to these factors, we explore features of title rhetoric and text multifunctionality, while also uncovering previously unexamined text functions, such as text replacing visual elements. Our findings highlight the flexibility of text, demonstrating how different text elements in a given design can combine to communicate, synthesize, and frame visual information. This framework adds important nuance and detail to existing frameworks that analyze the diverse roles of text in visualization.",
      "authors": [
        "Chase Stokes",
        "Anjana Arunkumar",
        "Marti A. Hearst",
        "and Lace Padilla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:25:26+00:00",
          "link": "https://arxiv.org/abs/2507.12334v1",
          "size": "2361kb",
          "version": "v1"
        }
      ],
      "title": "An Analysis of Text Functions in Information Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12334",
        "HTML": "https://arxiv.org/html/2507.12334v1",
        "PDF": "https://arxiv.org/pdf/2507.12334"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper provides an analysis of text functions in information visualization and does not address any aspects of reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12336",
      "abstract": "This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D keypoints estimation that accurately predicts 3D keypoints from a single image. While previous methods rely on manual annotations or calibrated multi-view images, both of which are expensive to collect, our method enables monocular 3D keypoints estimation using only a collection of single-view images. To achieve this, we leverage powerful geometric priors embedded in a pretrained multi-view diffusion model. In our framework, this model generates multi-view images from a single image, serving as a supervision signal to provide 3D geometric cues to our model. We also use the diffusion model as a powerful 2D multi-view feature extractor and construct 3D feature volumes from its intermediate representations. This transforms implicit 3D priors learned by the diffusion model into explicit 3D features. Beyond accurate keypoints estimation, we further introduce a pipeline that enables manipulation of 3D objects generated by the diffusion model. Experimental results on diverse aspects and datasets, including Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain datasets, highlight the effectiveness of our method in terms of accuracy, generalization, and its ability to enable manipulation of 3D objects generated by the diffusion model from a single image.",
      "authors": [
        "Subin Jeon",
        "In Cho",
        "Junyoung Hong",
        "Seon Joo Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:29:07+00:00",
          "link": "https://arxiv.org/abs/2507.12336v1",
          "size": "5225kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12336",
        "HTML": "https://arxiv.org/html/2507.12336v1",
        "PDF": "https://arxiv.org/pdf/2507.12336"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D keypoint estimation using diffusion models and does not mention reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12337",
      "abstract": "Acquiring medical expertise is a critical component of medical education and professional development. While existing studies focus primarily on constructing medical knowledge bases or developing learning tools based on the structured, private healthcare data, they often lack methods for extracting expertise from unstructured medical texts. These texts constitute a significant portion of medical literature and offer greater flexibility and detail compared to structured data formats. Furthermore, many studies fail to provide explicit analytical and learning pathways in this context.\n  This paper introduces MExplore, an interactive visual analytics system designed to support the acquisition of medical expertise. To address the challenges of the inconsistencies and confidentiality concerns inherent in unstructured medical texts, we propose a workflow that employs a fine-tuned BERT-based model to extract medical entities (MEs) from them. We then present a novel multilevel visual analysis framework that integrates multiple coordinated visualizations, enabling a progressive and interactive exploration of medical knowledge.\n  To assess the effectiveness of MExplore, we conducted three case studies, a user study, and interviews with domain experts. The results indicate that the system significantly enhances the medical expertise acquisition process, providing an effective interactive approach for acquiring and retaining knowledge from medical texts.",
      "authors": [
        "Xiao Pang",
        "Yan Huang",
        "Chang Liu",
        "JiYuan Liu",
        "MingYou Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:29:56+00:00",
          "link": "https://arxiv.org/abs/2507.12337v1",
          "size": "3030kb",
          "version": "v1"
        }
      ],
      "title": "MExplore: an entity-based visual analytics approach for medical expertise acquisition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12337",
        "HTML": "https://arxiv.org/html/2507.12337v1",
        "PDF": "https://arxiv.org/pdf/2507.12337"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a visual analytics system for medical expertise acquisition without any reference to reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12338",
      "abstract": "We propose a locally conservative enriched Galerkin scheme that respects the discrete maximum principle of an elliptic problem. To this end, we use a substantial over-penalization of the discrete solution's jumps to obtain optimal convergence. To avoid the ill-conditioning issues that arise in over-penalized schemes, we introduce an involved splitting approach that separates the system of equations for the discontinuous solution part from the system of equations for the continuous solution part, yielding well-behaved subproblems. We prove the existence of discrete solutions and optimal error estimates, which are validated numerically.",
      "authors": [
        "Gabriel R. Barrenechea and Philip L. Lederer and Andreas Rupp"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:32:40+00:00",
          "link": "https://arxiv.org/abs/2507.12338v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "A bound-preserving and conservative enriched Galerkin method for elliptic problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12338",
        "HTML": "https://arxiv.org/html/2507.12338v1",
        "PDF": "https://arxiv.org/pdf/2507.12338"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research discusses an enriched Galerkin method for elliptic problems, unrelated to reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12339",
      "abstract": "This paper addresses the challenge of ensuring robustness in the presence of system perturbations for symbolic control techniques. Given a discrete-time control system that is related to its symbolic model by an alternating simulation relation. In this paper, we focus on computing the maximum robustness margin under which the symbolic model remains valid for a perturbed-version of the discrete-time control system. We first show that symbolic models are inherently equipped with a certain free robustness margins. We then provide constructive procedures to compute uniform and non-uniform (state and input dependent) robustness margins. We also show that the tightness of the robustness margin depends on the tightness of the reachability technique used to compute the symbolic model. We then explain how the computed robustness margin can be used for the sake of controller synthesis. Finally, we present two illustrative examples to demonstrate the effectiveness of our approach.",
      "authors": [
        "Youssef Ait Si",
        "Antoine Girard",
        "Adnane Saoud"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:34:49+00:00",
          "link": "https://arxiv.org/abs/2507.12339v1",
          "size": "382kb",
          "version": "v1"
        }
      ],
      "title": "Symbolic Control: Unveiling Free Robustness Margins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12339",
        "HTML": "https://arxiv.org/html/2507.12339v1",
        "PDF": "https://arxiv.org/pdf/2507.12339"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with robustness in symbolic control systems, focusing on robustness margins and control synthesis, but does not address reinforcement learning or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12341",
      "abstract": "Ensuring that neural models used in real-world applications cannot infer sensitive information, such as demographic attributes like gender or race, from text representations is a critical challenge when fairness is a concern. We address this issue through concept erasure, a process that removes information related to a specific concept from distributed representations while preserving as much of the remaining semantic information as possible. Our approach involves learning an orthogonal projection in the embedding space, designed to make the class-conditional feature distributions of the discrete concept to erase indistinguishable after projection. By adjusting the rank of the projector, we control the extent of information removal, while its orthogonality ensures strict preservation of the local structure of the embeddings. Our method, termed $\\overline{\\mathrm{L}}$EOPARD, achieves state-of-the-art performance in nonlinear erasure of a discrete attribute on classic natural language processing benchmarks. Furthermore, we demonstrate that $\\overline{\\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear classifiers, thereby promoting fairness.",
      "authors": [
        "Antoine Saillenfest",
        "Pirmin Lemberger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.12341v1",
          "size": "6315kb",
          "version": "v1"
        }
      ],
      "title": "Nonlinear Concept Erasure: a Density Matching Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12341",
        "HTML": "https://arxiv.org/html/2507.12341v1",
        "PDF": "https://arxiv.org/pdf/2507.12341"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on concept erasure to ensure fairness in neural models and does not touch upon reinforcement learning or the data processing aspects associated with it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12344",
      "abstract": "Weed detection is a critical component of precision agriculture, facilitating targeted herbicide application and reducing environmental impact. However, deploying accurate object detection models on resource-limited platforms remains challenging, particularly when differentiating visually similar weed species commonly encountered in plant phenotyping applications. In this work, we investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative Distillation (MGD) to enhance the performance of lightweight models for real-time smart spraying systems. Utilizing YOLO11x as the teacher model and YOLO11n as both reference and student, both CWD and MGD effectively transfer knowledge from the teacher to the student model. Our experiments, conducted on a real-world dataset comprising sugar beet crops and four weed types (Cirsium, Convolvulus, Fallopia, and Echinochloa), consistently show increased AP50 across all classes. The distilled CWD student model achieves a notable improvement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without increasing model complexity. Additionally, we validate real-time deployment feasibility by evaluating the student YOLO11n model on Jetson Orin Nano and Raspberry Pi 5 embedded devices, performing five independent runs to evaluate performance stability across random seeds. These findings confirm CWD and MGD as an effective, efficient, and practical approach for improving deep learning-based weed detection accuracy in precision agriculture and plant phenotyping scenarios.",
      "authors": [
        "Ahmet O\\u{g}uz Salt{\\i}k",
        "Max Voigt",
        "Sourav Modak",
        "Mike Beckworth",
        "Anthony Stein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:38:07+00:00",
          "link": "https://arxiv.org/abs/2507.12344v1",
          "size": "10760kb",
          "version": "v1"
        }
      ],
      "title": "Improving Lightweight Weed Detection via Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12344",
        "HTML": "https://arxiv.org/html/2507.12344v1",
        "PDF": "https://arxiv.org/pdf/2507.12344"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on knowledge distillation for lightweight weed detection in precision agriculture, which does not relate to reinforcement learning or data processing for RL agents."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12345",
      "abstract": "Control Flow Attestation (CFA) allows remote verification of run-time software integrity in embedded systems. However, CFA is limited by the storage/transmission costs of generated control flow logs (CFlog). Recent work has proposed application-specific optimizations by speculating on likely sub-paths in CFlog and replacing them with reserved symbols at runtime. Albeit effective, prior approaches do not consider the representation of addresses in a control flow path for speculation. This work proposes RESPEC-CFA, an architectural extension for CFA allowing for speculation on (1) the locality of control flows and (2) their Huffman encoding. Alone, RESPEC-CFA reduces CFlog sizes by up to 90.1%. Combined with prior methods, RESPEC-CFA yields reductions of up to 99.7%, representing a significant step toward practical CFA.",
      "authors": [
        "Liam Tyler",
        "Adam Caulfield",
        "Ivan De Oliveira Nunes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:38:58+00:00",
          "link": "https://arxiv.org/abs/2507.12345v1",
          "size": "795kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Control Flow Attestation by Speculating on Control Flow Path Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12345",
        "HTML": "https://arxiv.org/html/2507.12345v1",
        "PDF": "https://arxiv.org/pdf/2507.12345"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research revolves around control flow attestation in the context of embedded systems, and does not pertain to reinforcement learning or the associated data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12356",
      "abstract": "Gender bias has been widely observed in speech perception tasks, influenced by the fundamental voicing differences between genders. This study reveals a gender bias in the perception of Alzheimer's Disease (AD) speech. In a perception experiment involving 16 Chinese listeners evaluating both Chinese and Greek speech, we identified that male speech was more frequently identified as AD, with this bias being particularly pronounced in Chinese speech. Acoustic analysis showed that shimmer values in male speech were significantly associated with AD perception, while speech portion exhibited a significant negative correlation with AD identification. Although language did not have a significant impact on AD perception, our findings underscore the critical role of gender bias in AD speech perception. This work highlights the necessity of addressing gender bias when developing AD detection models and calls for further research to validate model performance across different linguistic contexts.",
      "authors": [
        "Liu He and Yuanchao Li and Rui Feng and XinRan Han and Yin-Long Liu and Yuwei Yang and Zude Zhu and Jiahong Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:56:09+00:00",
          "link": "https://arxiv.org/abs/2507.12356v1",
          "size": "2611kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12356",
        "HTML": "https://arxiv.org/html/2507.12356v1",
        "PDF": "https://arxiv.org/pdf/2507.12356"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses gender bias in speech perception for Alzheimer's Disease detection, without involving reinforcement learning or RL data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12357",
      "abstract": "We consider the algorithmic challenge that is faced by blockchains that have multidimensional block constraints and serve quasi-patient bidders. We provide online approximation algorithms for this problem, thus solving open problems left by [Babaioff and Nisan, EC 2025].",
      "authors": [
        "Ariel Ben Eliezer",
        "Noam Nisan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:56:16+00:00",
          "link": "https://arxiv.org/abs/2507.12357v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "Online Block Packing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12357",
        "HTML": "https://arxiv.org/html/2507.12357v1",
        "PDF": "https://arxiv.org/pdf/2507.12357"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study addresses online block packing algorithms concerning blockchains, which is unrelated to reinforcement learning or data processing tasks specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12359",
      "abstract": "We introduce Cluster Contrast (CueCo), a novel approach to unsupervised visual representation learning that effectively combines the strengths of contrastive learning and clustering methods. Inspired by recent advancements, CueCo is designed to simultaneously scatter and align feature representations within the feature space. This method utilizes two neural networks, a query and a key, where the key network is updated through a slow-moving average of the query outputs. CueCo employs a contrastive loss to push dissimilar features apart, enhancing inter-class separation, and a clustering objective to pull together features of the same cluster, promoting intra-class compactness. Our method achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on CIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18 backbone. By integrating contrastive learning with clustering, CueCo sets a new direction for advancing unsupervised visual representation learning.",
      "authors": [
        "Nikolaos Giakoumoglou",
        "Tania Stathaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:59:43+00:00",
          "link": "https://arxiv.org/abs/2507.12359v1",
          "size": "130kb",
          "version": "v1"
        }
      ],
      "title": "Cluster Contrast for Unsupervised Visual Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12359",
        "HTML": "https://arxiv.org/html/2507.12359v1",
        "PDF": "https://arxiv.org/pdf/2507.12359"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for unsupervised visual representation learning and does not incorporate reinforcement learning or address data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12364",
      "abstract": "Securing sensitive cloud workloads requires composing confidential virtual machines (CVMs) with nested enclaves or sandboxes. Unfortunately, each new isolation boundary adds ad-hoc access control mechanisms, hardware extensions, and trusted software. This escalating complexity bloats the TCB, complicates end-to-end attestation, and leads to fragmentation across platforms and cloud service providers (CSPs).\n  We introduce a unified isolation model that delegates enforceable, composable, and attestable isolation to a single trusted security monitor: Tyche. Tyche provides an API for partitioning, sharing, attesting, and reclaiming resources through its core abstraction, trust domains (TDs). To provide fine-grain isolation, TDs can recursively create and manage sub-TDs. Tyche captures these relationships in attestations, allowing cloud tenants to reason about end-to-end security. TDs serve as the building blocks for constructing composable enclaves, sandboxes, and CVMs.\n  Tyche runs on commodity x86_64 without hardware security extensions and can maintain backward compatibility with existing software. We provide an SDK to run and compose unmodified workloads as sandboxes, enclaves, and CVMs with minimal overhead compared to native Linux execution. Tyche supports complex cloud scenarios, such as confidential inference with mutually distrustful users, model owners, and CSPs. An additional RISC-V prototype demonstrates Tyche's portability across platforms.",
      "authors": [
        "Adrien Ghosn",
        "Charly Castes",
        "Neelu S. Kalani",
        "Yuchen Qian",
        "Marios Kogias",
        "Edouard Bugnion"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:08:24+00:00",
          "link": "https://arxiv.org/abs/2507.12364v1",
          "size": "307kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking the confidential cloud through a unified low-level abstraction for composable isolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12364",
        "HTML": "https://arxiv.org/html/2507.12364v1",
        "PDF": "https://arxiv.org/pdf/2507.12364"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cloud security and isolation mechanisms, specifically discussing the implementation of Tyche for secure cloud workloads. It does not address reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12366",
      "abstract": "Neuro-symbolic artificial intelligence (neuro-symbolic AI) excels in logical analysis and reasoning. Hyperdimensional Computing (HDC), a promising brain-inspired computational model, is integral to neuro-symbolic AI. Various HDC models have been proposed to represent class-instance and class-class relations, but when representing the more complex class-subclass relation, where multiple objects associate different levels of classes and subclasses, they face challenges for factorization, a crucial task for neuro-symbolic AI systems. In this article, we propose FactorHD, a novel HDC model capable of representing and factorizing the complex class-subclass relation efficiently. FactorHD features a symbolic encoding method that embeds an extra memorization clause, preserving more information for multiple objects. In addition, it employs an efficient factorization algorithm that selectively eliminates redundant classes by identifying the memorization clause of the target class. Such model significantly enhances computing efficiency and accuracy in representing and factorizing multiple objects with class-subclass relation, overcoming limitations of existing HDC models such as \"superposition catastrophe\" and \"the problem of 2\". Evaluations show that FactorHD achieves approximately 5667x speedup at a representation size of 10^9 compared to existing HDC models. When integrated with the ResNet-18 neural network, FactorHD achieves 92.48% factorization accuracy on the Cifar-10 dataset.",
      "authors": [
        "Yifei Zhou",
        "Xuchu Huang",
        "Chenyu Ni",
        "Min Zhou",
        "Zheyu Yan",
        "Xunzhao Yin",
        "Cheng Zhuo"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:09:51+00:00",
          "link": "https://arxiv.org/abs/2507.12366v1",
          "size": "2271kb",
          "version": "v1"
        }
      ],
      "title": "FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12366",
        "HTML": "https://arxiv.org/html/2507.12366v1",
        "PDF": "https://arxiv.org/pdf/2507.12366"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a novel hyperdimensional computing model for neuro-symbolic AI, focusing on class-subclass relations and factorization. It does not involve reinforcement learning or data processing in the context of RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12367",
      "abstract": "The rapid evolution of software libraries poses a considerable hurdle for code generation, necessitating continuous adaptation to frequent version updates while preserving backward compatibility. While existing code evolution benchmarks provide valuable insights, they typically lack execution-based evaluation for generating code compliant with specific library versions. To address this, we introduce GitChameleon, a novel, meticulously curated dataset comprising 328 Python code completion problems, each conditioned on specific library versions and accompanied by executable unit tests. GitChameleon rigorously evaluates the capacity of contemporary large language models (LLMs), LLM-powered agents, code assistants, and RAG systems to perform version-conditioned code generation that demonstrates functional accuracy through execution. Our extensive evaluations indicate that state-of-the-art systems encounter significant challenges with this task; enterprise models achieving baseline success rates in the 48-51\\% range, underscoring the intricacy of the problem. By offering an execution-based benchmark emphasizing the dynamic nature of code libraries, GitChameleon enables a clearer understanding of this challenge and helps guide the development of more adaptable and dependable AI code generation methods. We make the dataset and evaluation code publicly available at https://github.com/mrcabbage972/GitChameleonBenchmark.",
      "authors": [
        "Diganta Misra",
        "Nizar Islah",
        "Victor May",
        "Brice Rauby",
        "Zihan Wang",
        "Justine Gehring",
        "Antonio Orvieto",
        "Muawiz Chaudhary",
        "Eilif B. Muller",
        "Irina Rish",
        "Samira Ebrahimi Kahou",
        "Massimo Caccia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:10:42+00:00",
          "link": "https://arxiv.org/abs/2507.12367v1",
          "size": "754kb",
          "version": "v1"
        }
      ],
      "title": "GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12367",
        "HTML": "https://arxiv.org/html/2507.12367v1",
        "PDF": "https://arxiv.org/pdf/2507.12367"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces GitChameleon, a dataset aimed at evaluating AI in the context of Python library version incompatibilities. It focuses on code generation and does not pertain to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12368",
      "abstract": "We consider a rare event monitoring system consisting of a set of devices and a base station, where devices transmit information about rare events to the base station using a random multiple access scheme. We introduce a model in which the presence of noise in the multiple access channel can cause message loss even in the absence of transmission collisions. The occurrence of events is modeled by a family of independent two-state Markov chains (with states 0 and 1). We analyze how repeated transmissions affect system performance. Two efficiency criteria are proposed and studied: the maximum probability that a message about an event from a fixed device is successfully delivered to the base station and the maximum frequency at which the base station successfully receives updates about the entire system. For each criterion, we determine the optimal number of retransmissions as a function of the system parameters.",
      "authors": [
        "Sergey Foss",
        "Dmitriy Kim",
        "Andrey Turlikov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:11:36+00:00",
          "link": "https://arxiv.org/abs/2507.12368v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Remote Monitoring through Noisy Random Access with Retransmissions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12368",
        "HTML": "https://arxiv.org/html/2507.12368v1",
        "PDF": "https://arxiv.org/pdf/2507.12368"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with efficient remote monitoring through noisy random access and retransmissions in a communication system. It does not relate to reinforcement learning or RL data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12370",
      "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities in understanding and generating human language, contributing to more natural interactions with complex systems. However, they face challenges such as ambiguity in user requests processed by LLMs. To address these challenges, this paper introduces and evaluates a multi-agent debate framework designed to enhance detection and resolution capabilities beyond single models. The framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and Mistral-7B variants) and a dataset with diverse ambiguities. The debate framework markedly enhanced the performance of Llama3-8B and Mistral-7B variants over their individual baselines, with Mistral-7B-led debates achieving a notable 76.7% success rate and proving particularly effective for complex ambiguities and efficient consensus. While acknowledging varying model responses to collaborative strategies, these findings underscore the debate framework's value as a targeted method for augmenting LLM capabilities. This work offers important insights for developing more robust and adaptive language understanding systems by showing how structured debates can lead to improved clarity in interactive systems.",
      "authors": [
        "Ana Davila",
        "Jacinto Colan",
        "Yasuhisa Hasegawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:15:25+00:00",
          "link": "https://arxiv.org/abs/2507.12370v1",
          "size": "1227kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12370",
        "HTML": "https://arxiv.org/html/2507.12370v1",
        "PDF": "https://arxiv.org/pdf/2507.12370"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses using a debate framework to enhance LLMs' ability to detect and resolve ambiguities in requests. It does not relate to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12372",
      "abstract": "Large language models (LLMs) have traditionally relied on static training data, limiting their knowledge to fixed snapshots. Recent advancements, however, have equipped LLMs with web browsing capabilities, enabling real time information retrieval and multi step reasoning over live web content. While prior studies have demonstrated LLMs ability to access and analyze websites, their capacity to directly retrieve and analyze social media data remains unexplored. Here, we evaluate whether web browsing LLMs can infer demographic attributes of social media users given only their usernames. Using a synthetic dataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international participants, we show that these models can access social media content and predict user demographics with reasonable accuracy. Analysis of the synthetic dataset further reveals how LLMs parse and interpret social media profiles, which may introduce gender and political biases against accounts with minimal activity. While this capability holds promise for computational social science in the post API era, it also raises risks of misuse particularly in information operations and targeted advertising underscoring the need for safeguards. We recommend that LLM providers restrict this capability in public facing applications, while preserving controlled access for verified research purposes.",
      "authors": [
        "Meysam Alizadeh",
        "Fabrizio Gilardi",
        "Zeynab Samei",
        "and Mohsen Mosleh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:21:01+00:00",
          "link": "https://arxiv.org/abs/2507.12372v1",
          "size": "3978kb",
          "version": "v1"
        }
      ],
      "title": "Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12372",
        "HTML": "https://arxiv.org/html/2507.12372v1",
        "PDF": "https://arxiv.org/pdf/2507.12372"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLMs' ability to infer demographics from social media profiles, which is not related to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12373",
      "abstract": "The energy sector is experiencing rapid transformation due to increasing renewable energy integration, decentralisation of power systems, and a heightened focus on efficiency and sustainability. With energy demand becoming increasingly dynamic and generation sources more variable, advanced forecasting and optimisation strategies are crucial for maintaining grid stability, cost-effectiveness, and environmental sustainability. This paper explores emerging paradigms in energy forecasting and management, emphasizing four critical domains: Energy Demand Forecasting integrated with Weather Data, Building Energy Optimisation, Heat Network Optimisation, and Energy Management System (EMS) Optimisation within a System of Systems (SoS) framework. Leveraging machine learning techniques and Model Predictive Control (MPC), the study demonstrates substantial enhancements in energy efficiency across scales -- from individual buildings to complex interconnected energy networks. Weather-informed demand forecasting significantly improves grid resilience and resource allocation strategies. Smart building optimisation integrates predictive analytics to substantially reduce energy consumption without compromising occupant comfort. Optimising CHP-based heat networks achieves cost and carbon savings while adhering to operational and asset constraints. At the systems level, sophisticated EMS optimisation ensures coordinated control of distributed resources, storage solutions, and demand-side flexibility. Through real-world case studies we highlight the potential of AI-driven automation and integrated control solutions in facilitating a resilient, efficient, and sustainable energy future.",
      "authors": [
        "Dariush Pourkeramati",
        "Gareth Wadge",
        "Rachel Hassall",
        "Charlotte Mitchell",
        "Anish Khadka",
        "Shiwang Jaiswal",
        "Andrew Duncan",
        "Rossella Arcucci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:21:07+00:00",
          "link": "https://arxiv.org/abs/2507.12373v1",
          "size": "589kb",
          "version": "v1"
        }
      ],
      "title": "Emerging Paradigms in the Energy Sector: Forecasting and System Control Optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12373",
        "HTML": "https://arxiv.org/html/2507.12373v1",
        "PDF": "https://arxiv.org/pdf/2507.12373"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses machine learning and optimization strategies in the energy sector, but it does not address reinforcement learning or data processing for RL agents."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12377",
      "abstract": "We conduct a deconstructive reading of a qualitative interview study with 17 visual data journalists from newsrooms across the globe. We borrow a deconstruction approach from literary critique to explore the instability of meaning in language and reveal implicit beliefs in words and ideas. Through our analysis we surface two sets of opposing implicit beliefs in visual data journalism: objectivity/subjectivity and humanism/mechanism. We contextualize these beliefs through a genealogical analysis, which brings deconstruction theory into practice by providing a historic backdrop for these opposing perspectives. Our analysis shows that these beliefs held within visual data journalism are not self-enclosed but rather a product of external societal forces and paradigm shifts over time. Through this work, we demonstrate how thinking with critical theories such as deconstruction and genealogy can reframe \"success\" in visual data storytelling and diversify visualization research outcomes. These efforts push the ways in which we as researchers produce domain knowledge to examine the sociotechnical issues of today's values towards datafication and data visualization.",
      "authors": [
        "Ke Er Amy Zhang",
        "Jodie Jenkinson",
        "Laura Garrison"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:26:44+00:00",
          "link": "https://arxiv.org/abs/2507.12377v1",
          "size": "8945kb",
          "version": "v1"
        }
      ],
      "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12377",
        "HTML": "https://arxiv.org/html/2507.12377v1",
        "PDF": "https://arxiv.org/pdf/2507.12377"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on visual data journalism and explores implicit beliefs in data narratives without any mention of reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12378",
      "abstract": "Traditional information extraction systems face challenges with text only language models as it does not consider infographics (visual elements of information) such as tables, charts, images etc. often used to convey complex information to readers. Multimodal LLM (MLLM) face challenges of finding needle in the haystack problem i.e., either longer context length or substantial number of documents as search space. Late interaction mechanism over visual language models has shown state of the art performance in retrieval-based vision augmented Q&A tasks. There are yet few challenges using it for RAG based multi-modal Q&A. Firstly, many popular and widely adopted vector databases do not support native multi-vector retrieval. Secondly, late interaction requires computation which inflates space footprint and can hinder enterprise adoption. Lastly, the current state of late interaction mechanism does not leverage the approximate neighbor search indexing methods for large speed ups in retrieval process. This paper explores a pragmatic approach to make vision retrieval process scalable and efficient without compromising on performance quality. We propose multi-step custom implementation utilizing widely adopted hybrid search (metadata & embedding) and state of the art late interaction re-ranker to retrieve best matching pages. Finally, MLLM are prompted as reader to generate answers from contextualized best matching pages. Through experiments, we observe that the proposed design is scalable (significant speed up) and stable (without degrading performance quality), hence can be used as production systems at enterprises.",
      "authors": [
        "Rachna Saxena",
        "Abhijeet Kumar",
        "Suresh Shanmugam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:27:05+00:00",
          "link": "https://arxiv.org/abs/2507.12378v1",
          "size": "332kb",
          "version": "v1"
        }
      ],
      "title": "Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12378",
        "PDF": "https://arxiv.org/pdf/2507.12378"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores a vision augmented Q&A system, focusing on retrieval and multimodal language models, but does not relate to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12379",
      "abstract": "We investigate whether internal activations in language models can be used to detect arithmetic errors. Starting with a controlled setting of 3-digit addition, we show that simple probes can accurately decode both the model's predicted output and the correct answer from hidden states, regardless of whether the model's output is correct. Building on this, we train lightweight error detectors that predict model correctness with over 90% accuracy. We then extend our analysis to structured chain-of-thought traces on addition-only GSM8K problems and find that probes trained on simple arithmetic generalize well to this more complex setting, revealing consistent internal representations. Finally, we demonstrate that these probes can guide selective re-prompting of erroneous reasoning steps, improving task accuracy with minimal disruption to correct outputs. Our findings suggest that arithmetic errors can be anticipated from internal activations alone, and that simple probes offer a viable path toward lightweight model self-correction.",
      "authors": [
        "Yucheng Sun",
        "Alessandro Stolfo",
        "Mrinmaya Sachan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:27:50+00:00",
          "link": "https://arxiv.org/abs/2507.12379v1",
          "size": "895kb",
          "version": "v1"
        }
      ],
      "title": "Probing for Arithmetic Errors in Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12379",
        "HTML": "https://arxiv.org/html/2507.12379v1",
        "PDF": "https://arxiv.org/pdf/2507.12379"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates arithmetic error detection in language models, which does not involve reinforcement learning or data processing related to RL tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12380",
      "abstract": "Topological neural networks have emerged as powerful successors of graph neural networks. However, they typically involve higher-order message passing, which incurs significant computational expense. We circumvent this issue with a novel topological framework that introduces a Laplacian operator on combinatorial complexes (CCs), enabling efficient computation of heat kernels that serve as node descriptors. Our approach captures multiscale information and enables permutation-equivariant representations, allowing easy integration into modern transformer-based architectures.\n  Theoretically, the proposed method is maximally expressive because it can distinguish arbitrary non-isomorphic CCs. Empirically, it significantly outperforms existing topological methods in terms of computational efficiency. Besides demonstrating competitive performance with the state-of-the-art descriptors on standard molecular datasets, it exhibits superior capability in distinguishing complex topological structures and avoiding blind spots on topological benchmarks. Overall, this work advances topological deep learning by providing expressive yet scalable representations, thereby opening up exciting avenues for molecular classification and property prediction tasks.",
      "authors": [
        "Maximilian Krahn",
        "Vikas Garg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:28:10+00:00",
          "link": "https://arxiv.org/abs/2507.12380v1",
          "size": "985kb",
          "version": "v1"
        }
      ],
      "title": "Heat Kernel Goes Topological",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12380",
        "HTML": "https://arxiv.org/html/2507.12380v1",
        "PDF": "https://arxiv.org/pdf/2507.12380"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on topological neural networks and graph neural networks, with no mention of reinforcement learning or data processing techniques applicable to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12382",
      "abstract": "Semi-supervised medical image segmentation is a crucial technique for alleviating the high cost of data annotation. When labeled data is limited, textual information can provide additional context to enhance visual semantic understanding. However, research exploring the use of textual data to enhance visual semantic embeddings in 3D medical imaging tasks remains scarce. In this paper, we propose a novel text-driven multiplanar visual interaction framework for semi-supervised medical image segmentation (termed Text-SemiSeg), which consists of three main modules: Text-enhanced Multiplanar Representation (TMR), Category-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation (DCA). Specifically, TMR facilitates text-visual interaction through planar mapping, thereby enhancing the category awareness of visual features. CSA performs cross-modal semantic alignment between the text features with introduced learnable variables and the intermediate layer of visual features. DCA reduces the distribution discrepancy between labeled and unlabeled data through their interaction, thus improving the model's robustness. Finally, experiments on three public datasets demonstrate that our model effectively enhances visual features with textual information and outperforms other methods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.",
      "authors": [
        "Kaiwen Huang",
        "Yi Zhou",
        "Huazhu Fu",
        "Yizhe Zhang",
        "Chen Gong",
        "Tao Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:29:30+00:00",
          "link": "https://arxiv.org/abs/2507.12382v1",
          "size": "918kb",
          "version": "v1"
        }
      ],
      "title": "Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12382",
        "HTML": "https://arxiv.org/html/2507.12382v1",
        "PDF": "https://arxiv.org/pdf/2507.12382"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with semi-supervised medical image segmentation, utilizing textual data to enhance visual semantic understanding, and does not involve reinforcement learning or related data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12383",
      "abstract": "In this study, we derive Probably Approximately Correct (PAC) bounds on the asymptotic sample-complexity for RL within the infinite-horizon Markov Decision Process (MDP) setting that are sharper than those in existing literature. The premise of our study is twofold: firstly, the further two states are from each other, transition-wise, the less relevant the value of the first state is when learning the $\\epsilon$-optimal value of the second; secondly, the amount of 'effort', sample-complexity-wise, expended in learning the $\\epsilon$-optimal value of a state is independent of the number of samples required to learn the $\\epsilon$-optimal value of a second state that is a sufficient number of transitions away from the first. Inversely, states within each other's vicinity have values that are dependent on each other and will require a similar number of samples to learn. By approximating the original MDP using smaller MDPs constructed using subsets of the original's state-space, we are able to reduce the sample-complexity by a logarithmic factor to $O(SA \\log A)$ timesteps, where $S$ and $A$ are the state and action space sizes. We are able to extend these results to an infinite-horizon, model-free setting by constructing a PAC-MDP algorithm with the aforementioned sample-complexity. We conclude with showing how significant the improvement is by comparing our algorithm against prior work in an experimental setting.",
      "authors": [
        "Mohit Prashant",
        "Arvind Easwaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:31:17+00:00",
          "link": "https://arxiv.org/abs/2507.12383v1",
          "size": "166kb",
          "version": "v1"
        }
      ],
      "title": "Improving Reinforcement Learning Sample-Efficiency using Local Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12383",
        "HTML": "https://arxiv.org/html/2507.12383v1",
        "PDF": "https://arxiv.org/pdf/2507.12383"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "This paper is relevant as it addresses reinforcement learning by proposing a method that reduces the sample-complexity for RL tasks, specifically through approximating MDPs and improving sample-efficiency, directly impacting data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12384",
      "abstract": "The rapid advancement of artificial intelligence has raised concerns regarding its trustworthiness, especially in terms of interpretability and robustness. Tree-based models like Random Forest and XGBoost excel in interpretability and accuracy for tabular data, but scaling them remains computationally expensive due to poor data locality and high data dependence. Previous efforts to accelerate these models with analog content addressable memory (CAM) have struggled, due to the fact that the difficult-to-implement sharp decision boundaries are highly susceptible to device variations, which leads to poor hardware performance and vulnerability to adversarial attacks. This work presents a novel hardware-software co-design approach using $MoS_2$ Flash-based analog CAM with inherent soft boundaries, enabling efficient inference with soft tree-based models. Our soft tree model inference experiments on $MoS_2$ analog CAM arrays show this method achieves exceptional robustness against device variation and adversarial attacks while achieving state-of-the-art accuracy. Specifically, our fabricated analog CAM arrays achieve $96\\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database, while maintaining decision explainability. Our experimentally calibrated model validated only a $0.6\\%$ accuracy drop on the MNIST dataset under $10\\%$ device threshold variation, compared to a $45.3\\%$ drop for traditional decision trees. This work paves the way for specialized hardware that enhances AI's trustworthiness and efficiency.",
      "authors": [
        "Bo Wen",
        "Guoyun Gao",
        "Zhicheng Xu",
        "Ruibin Mao",
        "Xiaojuan Qi",
        "X. Sharon Hu",
        "Xunzhao Yin",
        "and Can Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:31:20+00:00",
          "link": "https://arxiv.org/abs/2507.12384v1",
          "size": "33561kb",
          "version": "v1"
        }
      ],
      "title": "Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12384",
        "HTML": "https://arxiv.org/html/2507.12384v1",
        "PDF": "https://arxiv.org/pdf/2507.12384"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper centers on tree-based machine learning models and enhancing their performance using novel hardware, without touching on reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12391",
      "abstract": "Large Language Models (LLMs) show potential for enhancing robotic path planning. This paper assesses visual input's utility for multimodal LLMs in such tasks via a comprehensive benchmark. We evaluated 15 multimodal LLMs on generating valid and optimal paths in 2D grid environments, simulating simplified robotic planning, comparing text-only versus text-plus-visual inputs across varying model sizes and grid complexities. Our results indicate moderate success rates on simpler small grids, where visual input or few-shot text prompting offered some benefits. However, performance significantly degraded on larger grids, highlighting a scalability challenge. While larger models generally achieved higher average success, the visual modality was not universally dominant over well-structured text for these multimodal systems, and successful paths on simpler grids were generally of high quality. These results indicate current limitations in robust spatial reasoning, constraint adherence, and scalable multimodal integration, identifying areas for future LLM development in robotic path planning.",
      "authors": [
        "Jacinto Colan",
        "Ana Davila",
        "Yasuhisa Hasegawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:37:13+00:00",
          "link": "https://arxiv.org/abs/2507.12391v1",
          "size": "272kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12391",
        "HTML": "https://arxiv.org/html/2507.12391v1",
        "PDF": "https://arxiv.org/pdf/2507.12391"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper investigates the use of visual inputs for multimodal LLMs in robotic path planning, which might involve some RL environment components, the focus is not primarily on data processing techniques particular to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12396",
      "abstract": "Realistic human surveillance datasets are crucial for training and evaluating computer vision models under real-world conditions, facilitating the development of robust algorithms for human and human-interacting object detection in complex environments. These datasets need to offer diverse and challenging data to enable a comprehensive assessment of model performance and the creation of more reliable surveillance systems for public safety. To this end, we present two visual object detection benchmarks named OD-VIRAT Large and OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance imagery. The video sequences in both benchmarks cover 10 different scenes of human surveillance recorded from significant height and distance. The proposed benchmarks offer rich annotations of bounding boxes and categories, where OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also focuses on benchmarking state-of-the-art object detection architectures, including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object detection-specific variant of VIRAT dataset. To the best of our knowledge, it is the first work to examine the performance of these recently published state-of-the-art object detection architectures on realistic surveillance imagery under challenging conditions such as complex backgrounds, occluded objects, and small-scale objects. The proposed benchmarking and experimental settings will help in providing insights concerning the performance of selected object detection models and set the base for developing more efficient and robust object detection architectures.",
      "authors": [
        "Hayat Ullah",
        "Abbas Khan",
        "Arslan Munir",
        "and Hari Kalva"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:41:47+00:00",
          "link": "https://arxiv.org/abs/2507.12396v1",
          "size": "17899kb",
          "version": "v1"
        }
      ],
      "title": "OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12396",
        "HTML": "https://arxiv.org/html/2507.12396v1",
        "PDF": "https://arxiv.org/pdf/2507.12396"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a benchmark for object detection in surveillance environments and focuses on dataset creation for computer vision, not reinforcement learning, thus unrelated to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12399",
      "abstract": "Test-time scaling aims to improve language model performance by leveraging additional compute during inference. While many works have empirically studied techniques like Best-of-N (BoN) and rejection sampling that make use of a verifier to enable test-time scaling, there is little theoretical understanding of how verifier imperfection affects performance. In this work, we address this gap. Specifically, we prove how instance-level accuracy of these methods is precisely characterized by the geometry of the verifier's ROC curve. Interestingly, while scaling is determined by the local geometry of the ROC curve for rejection sampling, it depends on global properties of the ROC curve for BoN. As a consequence when the ROC curve is unknown, it is impossible to extrapolate the performance of rejection sampling based on the low-compute regime. Furthermore, while rejection sampling outperforms BoN for fixed compute, in the infinite-compute limit both methods converge to the same level of accuracy, determined by the slope of the ROC curve near the origin. Our theoretical results are confirmed by experiments on GSM8K using different versions of Llama and Qwen to generate and verify solutions.",
      "authors": [
        "Florian E. Dorner",
        "Yatong Chen",
        "Andr\\'e F. Cruz",
        "Fanny Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:44:29+00:00",
          "link": "https://arxiv.org/abs/2507.12399v1",
          "size": "3950kb",
          "version": "v1"
        }
      ],
      "title": "ROC-n-reroll: How verifier imperfection affects test-time scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12399",
        "HTML": "https://arxiv.org/html/2507.12399v1",
        "PDF": "https://arxiv.org/pdf/2507.12399"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses test-time scaling for language models using techniques like Best-of-N and rejection sampling, without any mention of reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12400",
      "abstract": "Deploying motile nanosized particles, also known as ``nanobots'', in the human body promises to improve selectivity in drug delivery and reduce side effects. We consider a swarm of nanobots locating a single cancerous region and treating it by releasing an onboard payload of drugs at the site. At nanoscale, the computation, communication, sensing, and locomotion capabilities of individual agents are extremely limited, noisy, and/or nonexistent.\n  We present a general model to formally describe the individual and collective behavior of agents in a colloidal environment, such as the bloodstream, for cancer detection and treatment by nanobots. This includes a feasible and precise model of agent locomotion, inspired by actual nanoparticles that, in the presence of an external chemical gradient, move towards areas of higher concentration by means of self-propulsion. We present two variants of our general model: The first assumes an endogenous chemical gradient that is fixed over time and centered at the targeted cancer site; the second is a more speculative and dynamic variant in which agents themselves create and amplify a chemical gradient centered at the cancer site. In both settings, agents can sense the gradient and ascend it noisily, locating the cancer site more quickly than via simple Brownian motion.\n  For the first variant of the model, we present simulation results to show the behavior of agents under our locomotion model, as well as {analytical results} to bound the time it takes for the agents to reach the cancer site. For the second variant, simulation results highlight the collective benefit in having agents issue their own chemical signal. While arguably more speculative in its agent capability assumptions, this variant shows a significant improvement in runtime performance over the first variant, resulting from its chemical signal amplification mechanism.",
      "authors": [
        "Noble Harasha",
        "Cristina Gava",
        "Nancy Lynch",
        "Claudia Contini and Frederik Mallmann-Trenn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:44:50+00:00",
          "link": "https://arxiv.org/abs/2507.12400v1",
          "size": "2541kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Feasible Locomotion of Nanobots for Cancer Detection and Treatment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12400",
        "HTML": "https://arxiv.org/html/2507.12400v1",
        "PDF": "https://arxiv.org/pdf/2507.12400"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with nanobots in a medical context, focusing on modeling and locomotion in cancer detection/treatment, without any connection to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12406",
      "abstract": "The Sinc convolution is an approximate formula for indefinite convolutions proposed by F. Stenger. The formula was derived based on the Sinc indefinite integration formula combined with the single-exponential transformation. Although its efficiency has been confirmed in variety of areas, there remain some open problems in its theory. The first contribution of this study is to resolve those problems by refinement of the theory of the Sinc convolution. This contribution includes a partial resolution of Stenger's conjecture. The second contribution of this study is to improve the convergence rate by replacement of the single-exponential transformation with the double-exponential transformation. In both theoretical and numerical ways, this study also shows that the convergence rate of the new formula is improved compared to Stenger's formula.",
      "authors": [
        "Tomoaki Okayama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:52:02+00:00",
          "link": "https://arxiv.org/abs/2507.12406v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "Refinement of the theory and convergence of the Sinc convolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12406",
        "PDF": "https://arxiv.org/pdf/2507.12406"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study addresses the mathematical theory and convergence of Sinc convolution in numerical analysis, with no relevance to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12407",
      "abstract": "We consider manipulation problems in constrained and cluttered settings, which require several regrasps at unknown locations. We propose to inform an optimization-based task and motion planning (TAMP) solver with possible regrasp areas and grasp sequences to speed up the search. Our main idea is to use a state space abstraction, a regrasp map, capturing the combinations of available grasps in different parts of the configuration space, and allowing us to provide the solver with guesses for the mode switches and additional constraints for the object placements. By interleaving the creation of regrasp maps, their adaptation based on failed refinements, and solving TAMP (sub)problems, we are able to provide a robust search method for challenging regrasp manipulation problems.",
      "authors": [
        "Svetlana Levit and Marc Toussaint"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:53:07+00:00",
          "link": "https://arxiv.org/abs/2507.12407v1",
          "size": "1295kb",
          "version": "v1"
        }
      ],
      "title": "Regrasp Maps for Sequential Manipulation Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12407",
        "HTML": "https://arxiv.org/html/2507.12407v1",
        "PDF": "https://arxiv.org/pdf/2507.12407"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on manipulation planning using regrasp maps in cluttered environments, which is related to optimization and motion planning, but it does not directly address data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12412",
      "abstract": "In many critical applications, resource constraints limit the amount of information that can be gathered to make predictions. For example, in healthcare, patient data often spans diverse features ranging from lab tests to imaging studies. Each feature may carry different information and must be acquired at a respective cost of time, money, or risk to the patient. Moreover, temporal prediction tasks, where both instance features and labels evolve over time, introduce additional complexity in deciding when or what information is important. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff Acquisition method that sequentially acquires the most informative features at inference time while accounting for both temporal dynamics and acquisition cost. We first introduce a cohesive estimation target for our NOCTA setting, and then develop two complementary estimators: 1) a non-parametric method based on nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric method that directly predicts the utility of potential acquisitions (NOCTA-P). Experiments on synthetic and real-world medical datasets demonstrate that both NOCTA variants outperform existing baselines.",
      "authors": [
        "Dzung Dinh",
        "Boqi Chen",
        "Marc Niethammer",
        "Junier Oliva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:00:41+00:00",
          "link": "https://arxiv.org/abs/2507.12412v1",
          "size": "607kb",
          "version": "v1"
        }
      ],
      "title": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12412",
        "HTML": "https://arxiv.org/html/2507.12412v1",
        "PDF": "https://arxiv.org/pdf/2507.12412"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents NOCTA for optimizing feature acquisition in temporal prediction tasks, such as healthcare, rather than dealing with data processing issues in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12414",
      "abstract": "Training of autonomous driving systems requires extensive datasets with precise annotations to attain robust performance. Human annotations suffer from imperfections, and multiple iterations are often needed to produce high-quality datasets. However, manually reviewing large datasets is laborious and expensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning) framework and investigate the utilization of Vision-Language Models (VLMs) to automatically identify erroneous annotations in vision datasets, thereby enabling users to eliminate these errors and enhance data quality. We validate our approach using the KITTI and nuImages datasets, which contain object detection benchmarks for autonomous driving. To test the effectiveness of AutoVDC, we create dataset variants with intentionally injected erroneous annotations and observe the error detection rate of our approach. Additionally, we compare the detection rates using different VLMs and explore the impact of VLM fine-tuning on our pipeline. The results demonstrate our method's high performance in error detection and data cleaning experiments, indicating its potential to significantly improve the reliability and accuracy of large-scale production datasets in autonomous driving.",
      "authors": [
        "Santosh Vasa",
        "Aditi Ramadwar",
        "Jnana Rama Krishna Darabattula",
        "Md Zafar Anwar",
        "Stanislaw Antol",
        "Andrei Vatavu",
        "Thomas Monninger",
        "Sihao Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:04:49+00:00",
          "link": "https://arxiv.org/abs/2507.12414v1",
          "size": "830kb",
          "version": "v1"
        }
      ],
      "title": "AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12414",
        "HTML": "https://arxiv.org/html/2507.12414v1",
        "PDF": "https://arxiv.org/pdf/2507.12414"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the AutoVDC framework for cleaning vision datasets using vision-language models, which is focused on data quality in autonomous driving datasets and not on reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12415",
      "abstract": "Code performance optimization is paramount in real-world software engineering and critical for production-level systems. While Large Language Models (LLMs) have demonstrated impressive capabilities in code generation and bug fixing, their proficiency in enhancing code performance at the repository level remains largely unexplored. To address this gap, we introduce SWE-Perf, the first benchmark specifically designed to systematically evaluate LLMs on code performance optimization tasks within authentic repository contexts. SWE-Perf comprises 140 carefully curated instances, each derived from performance-improving pull requests from popular GitHub repositories. Each benchmark instance includes the relevant codebase, target functions, performance-related tests, expert-authored patches, and executable environments. Through a comprehensive evaluation of representative methods that span file-level and repo-level approaches (e.g., Agentless and OpenHands), we reveal a substantial capability gap between existing LLMs and expert-level optimization performance, highlighting critical research opportunities in this emerging field.",
      "authors": [
        "Xinyi He",
        "Qian Liu",
        "Mingzhe Du",
        "Lin Yan",
        "Zhijie Fan",
        "Yiming Huang",
        "Zejian Yuan",
        "Zejun Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:05:17+00:00",
          "link": "https://arxiv.org/abs/2507.12415v1",
          "size": "3420kb",
          "version": "v1"
        }
      ],
      "title": "SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12415",
        "HTML": "https://arxiv.org/html/2507.12415v1",
        "PDF": "https://arxiv.org/pdf/2507.12415"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on code performance optimization benchmarks for LLMs, with no direct mention of reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12416",
      "abstract": "Composed Image Retrieval (CIR) retrieves relevant images based on a reference image and accompanying text describing desired modifications. However, existing CIR methods only focus on retrieving the target image and disregard the relevance of other images. This limitation arises because most methods employing contrastive learning-which treats the target image as positive and all other images in the batch as negatives-can inadvertently include false negatives. This may result in retrieving irrelevant images, reducing user satisfaction even when the target image is retrieved. To address this issue, we propose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which optimizes a reward model objective to reduce false negatives. Additionally, we introduce a hard negative sampling strategy that selects images positioned between two steep drops in relevance scores following the target image, to effectively filter false negatives. In order to evaluate CIR models on their alignment with human satisfaction, we create Human-Preference FashionIQ (HP-FashionIQ), a new dataset that explicitly captures user preferences beyond target retrieval. Extensive experiments demonstrate that QuRe achieves state-of-the-art performance on FashionIQ and CIRR datasets while exhibiting the strongest alignment with human preferences on the HP-FashionIQ dataset. The source code is available at https://github.com/jackwaky/QuRe.",
      "authors": [
        "Jaehyun Kwak",
        "Ramahdani Muhammad Izaaz Inhar",
        "Se-Young Yun",
        "Sung-Ju Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:06:33+00:00",
          "link": "https://arxiv.org/abs/2507.12416v1",
          "size": "5685kb",
          "version": "v1"
        }
      ],
      "title": "QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12416",
        "HTML": "https://arxiv.org/html/2507.12416v1",
        "PDF": "https://arxiv.org/pdf/2507.12416"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper proposes a hard negative sampling strategy to improve composed image retrieval, which involves optimizing a reward model objective. While this is related to RL concepts, the main focus is not on data processing or reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12418",
      "abstract": "The Number Theoretic Transform (NTT) is a fundamental operation in privacy-preserving technologies, particularly within fully homomorphic encryption (FHE). The efficiency of NTT computation directly impacts the overall performance of FHE, making hardware acceleration a critical technology that will enable realistic FHE applications. Custom accelerators, in FPGAs or ASICs, offer significant performance advantages due to their ability to exploit massive parallelism and specialized optimizations. However, the operation of NTT over large moduli requires large word-length modulo arithmetic that limits achievable clock frequencies in hardware and increases hardware area costs. To overcome such deficits, digit-serial arithmetic has been explored for modular multiplication and addition independently. The goal of this work is to leverage digit-serial modulo arithmetic combined with appropriate redundant data representation to design modular pipelined NTT accelerators that operate uniformly on arbitrary small digits, without the need for intermediate (de)serialization. The proposed architecture enables high clock frequencies through regular pipelining while maintaining parallelism. Experimental results demonstrate that the proposed approach outperforms state-of-the-art implementations and reduces hardware complexity under equal performance and input-output bandwidth constraints.",
      "authors": [
        "George Alexakis",
        "Dimitrios Schoinianakis and Giorgos Dimitrakopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:08:36+00:00",
          "link": "https://arxiv.org/abs/2507.12418v1",
          "size": "4855kb",
          "version": "v1"
        }
      ],
      "title": "High-Performance Pipelined NTT Accelerators with Homogeneous Digit-Serial Modulo Arithmetic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12418",
        "HTML": "https://arxiv.org/html/2507.12418v1",
        "PDF": "https://arxiv.org/pdf/2507.12418"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with hardware acceleration for cryptographic operations, specifically the Number Theoretic Transform (NTT), without any association with reinforcement learning or its data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12419",
      "abstract": "We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts (MoE) architecture which can dynamically select sequences of experts, producing computational graphs of variable width and depth. Existing MoE architectures generally require a fixed amount of computation for a given sample. Our approach, in contrast, yields predictions with increasing accuracy as the computation cycles through the experts' sequence. We train our model by iteratively sampling from a set of candidate experts, unfolding the sequence akin to how Recurrent Neural Networks are trained. Our method does not require load-balancing mechanisms, and preliminary experiments show a reduction in training epochs of 10\\% to 40\\% with a comparable/higher accuracy. These results point to new research directions in the field of MoEs, allowing the design of potentially faster and more expressive models. The code is available at https://github.com/nutig/RayTracing",
      "authors": [
        "Andrea Perin",
        "Giacomo Lagomarsini",
        "Claudio Gallicchio",
        "Giuseppe Nuti"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:08:46+00:00",
          "link": "https://arxiv.org/abs/2507.12419v1",
          "size": "1749kb",
          "version": "v1"
        }
      ],
      "title": "Mixture of Raytraced Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12419",
        "HTML": "https://arxiv.org/html/2507.12419v1",
        "PDF": "https://arxiv.org/pdf/2507.12419"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is a Mixture of Experts architecture for raytracing, which does not involve reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12420",
      "abstract": "Bounding box regression (BBR) is fundamental to object detection, where the regression loss is crucial for accurate localization. Existing IoU-based losses often incorporate handcrafted geometric penalties to address IoU's non-differentiability in non-overlapping cases and enhance BBR performance. However, these penalties are sensitive to box shape, size, and distribution, often leading to suboptimal optimization for small objects and undesired behaviors such as bounding box enlargement due to misalignment with the IoU objective. To address these limitations, we propose InterpIoU, a novel loss function that replaces handcrafted geometric penalties with a term based on the IoU between interpolated boxes and the target. By using interpolated boxes to bridge the gap between predictions and ground truth, InterpIoU provides meaningful gradients in non-overlapping cases and inherently avoids the box enlargement issue caused by misaligned penalties. Simulation results further show that IoU itself serves as an ideal regression target, while existing geometric penalties are both unnecessary and suboptimal. Building on InterpIoU, we introduce Dynamic InterpIoU, which dynamically adjusts interpolation coefficients based on IoU values, enhancing adaptability to scenarios with diverse object distributions. Experiments on COCO, VisDrone, and PASCAL VOC show that our methods consistently outperform state-of-the-art IoU-based losses across various detection frameworks, with particularly notable improvements in small object detection, confirming their effectiveness.",
      "authors": [
        "Haoyuan Liu",
        "Hiroshi Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:09:04+00:00",
          "link": "https://arxiv.org/abs/2507.12420v1",
          "size": "7476kb",
          "version": "v1"
        }
      ],
      "title": "InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12420",
        "HTML": "https://arxiv.org/html/2507.12420v1",
        "PDF": "https://arxiv.org/pdf/2507.12420"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improvements to bounding box regression for object detection. There is no mention of reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12425",
      "abstract": "Organizations increasingly rely on proprietary enterprise data, including HR records, structured reports, and tabular documents, for critical decision-making. While Large Language Models (LLMs) have strong generative capabilities, they are limited by static pretraining, short context windows, and challenges in processing heterogeneous data formats. Conventional Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but often struggle with structured and semi-structured data.\n  This work proposes an advanced RAG framework that combines hybrid retrieval strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by metadata-aware filtering with SpaCy NER and cross-encoder reranking. The framework applies semantic chunking to maintain textual coherence and retains tabular data structures to preserve row-column integrity. Quantized indexing optimizes retrieval efficiency, while human-in-the-loop feedback and conversation memory improve adaptability.\n  Experiments on enterprise datasets show notable improvements: Precision@5 increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74), and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness (4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale. These results demonstrate the framework's effectiveness in delivering accurate, comprehensive, and contextually relevant responses for enterprise tasks. Future work includes extending to multimodal data and integrating agent-based retrieval. The source code will be released at https://github.com/CheerlaChandana/Enterprise-Chatbot",
      "authors": [
        "Chandana Cheerla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:13:06+00:00",
          "link": "https://arxiv.org/abs/2507.12425v1",
          "size": "226kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12425",
        "HTML": "https://arxiv.org/html/2507.12425v1",
        "PDF": "https://arxiv.org/pdf/2507.12425"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper is dedicated to retrieval-augmented generation for enterprise data, without any discussion on reinforcement learning or related data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12426",
      "abstract": "The landscape of video recognition has evolved significantly, shifting from traditional Convolutional Neural Networks (CNNs) to Transformer-based architectures for improved accuracy. While 3D CNNs have been effective at capturing spatiotemporal dynamics, recent Transformer models leverage self-attention to model long-range spatial and temporal dependencies. Despite achieving state-of-the-art performance on major benchmarks, Transformers remain computationally expensive, particularly with dense video data. To address this, we propose a lightweight Video Focal Modulation Network, DVFL-Net, which distills spatiotemporal knowledge from a large pre-trained teacher into a compact nano student model, enabling efficient on-device deployment. DVFL-Net utilizes knowledge distillation and spatial-temporal feature modulation to significantly reduce computation while preserving high recognition performance. We employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal focal modulation to effectively transfer both local and global context from the Video-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate DVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it against recent state-of-the-art methods in Human Action Recognition (HAR). Additionally, we conduct a detailed ablation study analyzing the impact of forward KL divergence. The results confirm the superiority of DVFL-Net in achieving an optimal balance between performance and efficiency, demonstrating lower memory usage, reduced GFLOPs, and strong accuracy, making it a practical solution for real-time HAR applications.",
      "authors": [
        "Hayat Ullah",
        "Muhammad Ali Shafique",
        "Abbas Khan",
        "and Arslan Munir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:15:06+00:00",
          "link": "https://arxiv.org/abs/2507.12426v1",
          "size": "20568kb",
          "version": "v1"
        }
      ],
      "title": "DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12426",
        "HTML": "https://arxiv.org/html/2507.12426v1",
        "PDF": "https://arxiv.org/pdf/2507.12426"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper proposes a lightweight network for action recognition in videos but does not relate to reinforcement learning or its data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12428",
      "abstract": "Open-weights reasoning language models generate long chains-of-thought (CoTs) before producing a final response, which improves performance but introduces additional alignment risks, with harmful content often appearing in both the CoTs and the final outputs. In this work, we investigate if we can use CoTs to predict final response misalignment. We evaluate a range of monitoring approaches, including humans, highly-capable large language models, and text classifiers, using either CoT text or activations. First, we find that a simple linear probe trained on CoT activations can significantly outperform all text-based methods in predicting whether a final response will be safe or unsafe. CoT texts are often unfaithful and can mislead humans and classifiers, while model latents (i.e., CoT activations) offer a more reliable predictive signal. Second, the probe makes accurate predictions before reasoning completes, achieving strong performance even when applied to early CoT segments. These findings generalize across model sizes, families, and safety benchmarks, suggesting that lightweight probes could enable real-time safety monitoring and early intervention during generation.",
      "authors": [
        "Yik Siu Chan",
        "Zheng-Xin Yong",
        "Stephen H. Bach"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:16:03+00:00",
          "link": "https://arxiv.org/abs/2507.12428v1",
          "size": "314kb",
          "version": "v1"
        }
      ],
      "title": "Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12428",
        "HTML": "https://arxiv.org/html/2507.12428v1",
        "PDF": "https://arxiv.org/pdf/2507.12428"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the prediction of model alignment in reasoning language models, which is not related to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12431",
      "abstract": "The Automated Contact Angle Tester (ACAT) is a fully integrated robotic work cell developed to automate the measurement of surface wettability on 3D-printed materials. Designed for precision, repeatability, and safety, ACAT addresses the limitations of manual contact angle testing by combining programmable robotics, precise liquid dispensing, and a modular software-hardware architecture. The system is composed of three core subsystems: (1) an electrical system including power, control, and safety circuits compliant with industrial standards such as NEC 70, NFPA 79, and UL 508A; (2) a software control system based on a Raspberry Pi and Python, featuring fault detection, GPIO logic, and operator interfaces; and (3) a mechanical system that includes a 3-axis Cartesian robot, pneumatic actuation, and a precision liquid dispenser enclosed within a safety-certified frame. The ACAT enables high-throughput, automated surface characterization and provides a robust platform for future integration into smart manufacturing and materials discovery workflows. This paper details the design methodology, implementation strategies, and system integration required to develop the ACAT platform.",
      "authors": [
        "Connor Burgess",
        "Kyle Douin",
        "Amir Kordijazi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:20:10+00:00",
          "link": "https://arxiv.org/abs/2507.12431v1",
          "size": "1974kb",
          "version": "v1"
        }
      ],
      "title": "Design and Development of an Automated Contact Angle Tester (ACAT) for Surface Wettability Measurement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12431",
        "PDF": "https://arxiv.org/pdf/2507.12431"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the design and development of an automated system for surface wettability measurement, which is unrelated to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12433",
      "abstract": "Accurate pedestrian intention estimation is crucial for the safe navigation of autonomous vehicles (AVs) and hence attracts a lot of research attention. However, current models often fail to adequately consider dynamic traffic signals and contextual scene information, which are critical for real-world applications. This paper presents a Traffic-Aware Spatio-Temporal Graph Convolutional Network (TA-STGCN) that integrates traffic signs and their states (Red, Yellow, Green) into pedestrian intention prediction. Our approach introduces the integration of dynamic traffic signal states and bounding box size as key features, allowing the model to capture both spatial and temporal dependencies in complex urban environments. The model surpasses existing methods in accuracy. Specifically, TA-STGCN achieves a 4.75% higher accuracy compared to the baseline model on the PIE dataset, demonstrating its effectiveness in improving pedestrian intention prediction.",
      "authors": [
        "Fahimeh Orvati Nia and Hai Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:20:36+00:00",
          "link": "https://arxiv.org/abs/2507.12433v1",
          "size": "1246kb",
          "version": "v1"
        }
      ],
      "title": "Traffic-Aware Pedestrian Intention Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12433",
        "HTML": "https://arxiv.org/html/2507.12433v1",
        "PDF": "https://arxiv.org/pdf/2507.12433"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a spatio-temporal graph convolutional network for pedestrian intention prediction, with no mention or relation to reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12435",
      "abstract": "Modern deep neural networks are powerful predictive tools yet often lack valid inference for causal parameters, such as treatment effects or entire survival curves. While frameworks like Double Machine Learning (DML) and Targeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits, existing neural implementations either rely on \"targeted losses\" that do not guarantee solving the efficient influence function equation or computationally expensive post-hoc \"fluctuations\" for multi-parameter settings. We propose Targeted Deep Architectures (TDA), a new framework that embeds TMLE directly into the network's parameter space with no restrictions on the backbone architecture. Specifically, TDA partitions model parameters - freezing all but a small \"targeting\" subset - and iteratively updates them along a targeting gradient, derived from projecting the influence functions onto the span of the gradients of the loss with respect to weights. This procedure yields plug-in estimates that remove first-order bias and produce asymptotically valid confidence intervals. Crucially, TDA easily extends to multi-dimensional causal estimands (e.g., entire survival curves) by merging separate targeting gradients into a single universal targeting update. Theoretically, TDA inherits classical TMLE properties, including double robustness and semiparametric efficiency. Empirically, on the benchmark IHDP dataset (average treatment effects) and simulated survival data with informative censoring, TDA reduces bias and improves coverage relative to both standard neural-network estimators and prior post-hoc approaches. In doing so, TDA establishes a direct, scalable pathway toward rigorous causal inference within modern deep architectures for complex multi-parameter targets.",
      "authors": [
        "Yi Li",
        "David Mccoy",
        "Nolan Gunter",
        "Kaitlyn Lee",
        "Alejandro Schuler",
        "Mark van der Laan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:24:06+00:00",
          "link": "https://arxiv.org/abs/2507.12435v1",
          "size": "584kb",
          "version": "v1"
        }
      ],
      "title": "Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12435",
        "HTML": "https://arxiv.org/html/2507.12435v1",
        "PDF": "https://arxiv.org/pdf/2507.12435"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for robust causal inference in neural networks, focusing on causal parameters and survival curves, without discussing reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12439",
      "abstract": "Federated learning (FL) enables collaborative model training across decentralized clients while preserving data privacy. However, its open-participation nature exposes it to data-poisoning attacks, in which malicious actors submit corrupted model updates to degrade the global model. Existing defenses are often reactive, relying on statistical aggregation rules that can be computationally expensive and that typically assume an honest majority. This paper introduces a proactive, economic defense: a lightweight Bayesian incentive mechanism that makes malicious behavior economically irrational. Each training round is modeled as a Bayesian game of incomplete information in which the server, acting as the principal, uses a small, private validation dataset to verify update quality before issuing payments. The design satisfies Individual Rationality (IR) for benevolent clients, ensuring their participation is profitable, and Incentive Compatibility (IC), making poisoning an economically dominated strategy. Extensive experiments on non-IID partitions of MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping adversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3 percentage points lower than in a scenario with 30% label-flipping adversaries. This outcome is 51.7 percentage points better than standard FedAvg, which collapses under the same 50% attack. The mechanism is computationally light, budget-bounded, and readily integrates into existing FL frameworks, offering a practical route to economically robust and sustainable FL ecosystems.",
      "authors": [
        "Daniel Commey",
        "Rebecca A. Sarpong",
        "Griffith S. Klogo",
        "Winful Bagyl-Bac",
        "and Garth V. Crosby"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:27:25+00:00",
          "link": "https://arxiv.org/abs/2507.12439v1",
          "size": "140kb",
          "version": "v1"
        }
      ],
      "title": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12439",
        "HTML": "https://arxiv.org/html/2507.12439v1",
        "PDF": "https://arxiv.org/pdf/2507.12439"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study discusses a Bayesian incentive mechanism for federated learning to combat data-poisoning attacks and does not involve reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12440",
      "abstract": "Real robot data collection for imitation learning has led to significant advancements in robotic manipulation. However, the requirement for robot hardware in the process fundamentally constrains the scale of the data. In this paper, we explore training Vision-Language-Action (VLA) models using egocentric human videos. The benefit of using human videos is not only for their scale but more importantly for the richness of scenes and tasks. With a VLA trained on human video that predicts human wrist and hand actions, we can perform Inverse Kinematics and retargeting to convert the human actions to robot actions. We fine-tune the model using a few robot manipulation demonstrations to obtain the robot policy, namely EgoVLA. We propose a simulation benchmark called Isaac Humanoid Manipulation Benchmark, where we design diverse bimanual manipulation tasks with demonstrations. We fine-tune and evaluate EgoVLA with Isaac Humanoid Manipulation Benchmark and show significant improvements over baselines and ablate the importance of human data. Videos can be found on our website: https://rchalyang.github.io/EgoVLA",
      "authors": [
        "Ruihan Yang",
        "Qinxi Yu",
        "Yecheng Wu",
        "Rui Yan",
        "Borui Li",
        "An-Chieh Cheng",
        "Xueyan Zou",
        "Yunhao Fang",
        "Hongxu Yin",
        "Sifei Liu",
        "Song Han",
        "Yao Lu",
        "Xiaolong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:27:44+00:00",
          "link": "https://arxiv.org/abs/2507.12440v1",
          "size": "45829kb",
          "version": "v1"
        }
      ],
      "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12440",
        "HTML": "https://arxiv.org/html/2507.12440v1",
        "PDF": "https://arxiv.org/pdf/2507.12440"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper discusses using egocentric human videos to train Vision-Language-Action models, which includes processing and translating human actions into robot actions for imitation learning, a core aspect of data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12441",
      "abstract": "Recent progress has been made in region-aware vision-language modeling, particularly with the emergence of the Describe Anything Model (DAM). DAM is capable of generating detailed descriptions of any specific image areas or objects without the need for additional localized image-text alignment supervision. We hypothesize that such region-level descriptive capability is beneficial for the task of Visual Question Answering (VQA), especially in challenging scenarios involving images with dense text. In such settings, the fine-grained extraction of textual information is crucial to producing correct answers. Motivated by this, we introduce DAM-QA, a framework with a tailored evaluation protocol, developed to investigate and harness the region-aware capabilities from DAM for the text-rich VQA problem that requires reasoning over text-based information within images. DAM-QA incorporates a mechanism that aggregates answers from multiple regional views of image content, enabling more effective identification of evidence that may be tied to text-related elements. Experiments on six VQA benchmarks show that our approach consistently outperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA also achieves the best overall performance among region-aware models with fewer parameters, significantly narrowing the gap with strong generalist VLMs. These results highlight the potential of DAM-like models for text-rich and broader VQA tasks when paired with efficient usage and integration strategies. Our code is publicly available at https://github.com/Linvyl/DAM-QA.git.",
      "authors": [
        "Yen-Linh Vu",
        "Dinh-Thang Duong",
        "Truong-Binh Duong",
        "Anh-Khoi Nguyen",
        "Thanh-Huy Nguyen",
        "Le Thien Phuc Nguyen",
        "Jianhua Xing",
        "Xingjian Li",
        "Tianyang Wang",
        "Ulas Bagci",
        "Min Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:28:19+00:00",
          "link": "https://arxiv.org/abs/2507.12441v1",
          "size": "4474kb",
          "version": "v1"
        }
      ],
      "title": "Describe Anything Model for Visual Question Answering on Text-rich Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12441",
        "HTML": "https://arxiv.org/html/2507.12441v1",
        "PDF": "https://arxiv.org/pdf/2507.12441"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visual question answering (VQA) with a model for handling text-rich images. It does not address data processing within the reinforcement learning (RL) context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12442",
      "abstract": "The demand for machine intelligence capable of processing continuous, long-context inputs on local devices is growing rapidly. However, the quadratic complexity and memory requirements of traditional Transformer architectures make them inefficient and often unusable for these tasks. This has spurred a paradigm shift towards new architectures like State Space Models (SSMs) and hybrids, which promise near-linear scaling. While most current research focuses on the accuracy and theoretical throughput of these models, a systematic performance characterization on practical consumer hardware is critically needed to guide system-level optimization and unlock new applications.\n  To address this gap, we present a comprehensive, comparative benchmarking of carefully selected Transformer, SSM, and hybrid models specifically for long-context inference on consumer and embedded GPUs. Our analysis reveals that SSMs are not only viable but superior for this domain, capable of processing sequences up to 220K tokens on a 24GB consumer GPU-approximately 4x longer than comparable Transformers. While Transformers may be up to 1.8x faster at short sequences, SSMs demonstrate a dramatic performance inversion, becoming up to 4x faster at very long contexts (~57K tokens). Our operator-level analysis reveals that custom, hardware-aware SSM kernels dominate the inference runtime, accounting for over 55% of latency on edge platforms, identifying them as a primary target for future hardware acceleration. We also provide detailed, device-specific characterization results to guide system co-design for the edge. To foster further research, we will open-source our characterization framework.",
      "authors": [
        "Saptarshi Mitra",
        "Rachid Karami",
        "Haocheng Xu",
        "Sitao Huang",
        "Hyoukjun Kwon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:28:40+00:00",
          "link": "https://arxiv.org/abs/2507.12442v1",
          "size": "9235kb",
          "version": "v1"
        }
      ],
      "title": "Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12442",
        "HTML": "https://arxiv.org/html/2507.12442v1",
        "PDF": "https://arxiv.org/pdf/2507.12442"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses the performance of State Space Models (SSMs) and SSM-Transformer hybrids for long-context processing but does not mention reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12443",
      "abstract": "Beyond hallucinations, another problem in program synthesis using LLMs is ambiguity in user intent. We illustrate the ambiguity problem in a networking context for LLM-based incremental configuration synthesis of route-maps and ACLs. These structures frequently overlap in header space, making the relative priority of actions impossible for the LLM to infer without user interaction. Measurements in a large cloud identify complex ACLs with 100's of overlaps, showing ambiguity is a real problem. We propose a prototype system, Clarify, which uses an LLM augmented with a new module called a Disambiguator that helps elicit user intent. On a small synthetic workload, Clarify incrementally synthesizes routing policies after disambiguation and then verifies them. Our treatment of ambiguities is useful more generally when the intent of updates can be correctly synthesized by LLMs, but their integration is ambiguous and can lead to different global behaviors.",
      "authors": [
        "Rajdeep Mondal",
        "Nikolaj Bjorner",
        "Todd Millstein",
        "Alan Tang",
        "George Varghese"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:29:15+00:00",
          "link": "https://arxiv.org/abs/2507.12443v1",
          "size": "211kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Based Config Synthesis requires Disambiguation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12443",
        "HTML": "https://arxiv.org/html/2507.12443v1",
        "PDF": "https://arxiv.org/pdf/2507.12443"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses LLM-based configuration synthesis with a focus on disambiguation of user intent, unrelated to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12444",
      "abstract": "Bit-serial computation facilitates bit-wise sequential data processing, offering numerous benefits, such as a reduced area footprint and dynamically-adaptive computational precision. It has emerged as a prominent approach, particularly in leveraging bit-level sparsity in Deep Neural Networks (DNNs). However, existing bit-serial accelerators exploit bit-level sparsity to reduce computations by skipping zero bits, but they suffer from inefficient memory accesses due to the irregular indices of the non-zero bits.\n  As memory accesses typically are the dominant contributor to DNN accelerator performance, this paper introduces a novel computing approach called \"bit-column-serial\" and a compatible architecture design named \"BitWave.\" BitWave harnesses the advantages of the \"bit-column-serial\" approach, leveraging structured bit-level sparsity in combination with dynamic dataflow techniques. This achieves a reduction in computations and memory footprints through redundant computation skipping and weight compression. BitWave is able to mitigate the performance drop or the need for retraining that is typically associated with sparsity-enhancing techniques using a post-training optimization involving selected weight bit-flips. Empirical studies conducted on four deep-learning benchmarks demonstrate the achievements of BitWave: (1) Maximally realize 13.25x higher speedup, 7.71x efficiency compared to state-of-the-art sparsity-aware accelerators. (2) Occupying 1.138 mm2 area and consuming 17.56 mW power in 16nm FinFet process node.",
      "authors": [
        "Man Shi",
        "Vikram Jain",
        "Antony Joseph",
        "Maurice Meijer",
        "Marian Verhelst"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:29:42+00:00",
          "link": "https://arxiv.org/abs/2507.12444v1",
          "size": "9397kb",
          "version": "v1"
        }
      ],
      "title": "BitWave: Exploiting Column-Based Bit-Level Sparsity for Deep Learning Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12444",
        "HTML": "https://arxiv.org/html/2507.12444v1",
        "PDF": "https://arxiv.org/pdf/2507.12444"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "BitWave focuses on bit-level sparsity in deep learning accelerators, specifically for DNNs, and does not pertain to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12445",
      "abstract": "Reducing latency in the Internet of Things (IoT) is a critical concern. While cloud computing facilitates communication, it falls short of meeting real-time requirements reliably. Edge and fog computing have emerged as viable solutions by positioning computing nodes closer to end users, offering lower latency and increased processing power. An edge-fog framework comprises various components, including edge and fog nodes, whose strategic placement is crucial as it directly impacts latency and system cost. This paper presents an effective and tunable node placement strategy based on a genetic algorithm to address the optimization problem of deploying edge and fog nodes. The main objective is to minimize latency and cost through optimal node placement. Simulation results demonstrate that the proposed framework achieves up to 2.77% latency and 31.15% cost reduction.",
      "authors": [
        "Soheil Mahdizadeh",
        "Amir Mahdi Rasouli",
        "Mohammad Pourashory",
        "Sadra Galavani",
        "Mohsen Ansari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:29:52+00:00",
          "link": "https://arxiv.org/abs/2507.12445v1",
          "size": "5065kb",
          "version": "v1"
        }
      ],
      "title": "CRAFT: Latency and Cost-Aware Genetic-Based Framework for Node Placement in Edge-Fog Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12445",
        "HTML": "https://arxiv.org/html/2507.12445v1",
        "PDF": "https://arxiv.org/pdf/2507.12445"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a genetic algorithm for node placement in edge-fog computing environments, with no connection to data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12449",
      "abstract": "Obstacle avoidance is essential for ensuring the safety of autonomous vehicles. Accurate perception and motion planning are crucial to enabling vehicles to navigate complex environments while avoiding collisions. In this paper, we propose an efficient obstacle avoidance pipeline that leverages a camera-only perception module and a Frenet-Pure Pursuit-based planning strategy. By integrating advancements in computer vision, the system utilizes YOLOv11 for object detection and state-of-the-art monocular depth estimation models, such as Depth Anything V2, to estimate object distances. A comparative analysis of these models provides valuable insights into their accuracy, efficiency, and robustness in real-world conditions. The system is evaluated in diverse scenarios on a university campus, demonstrating its effectiveness in handling various obstacles and enhancing autonomous navigation. The video presenting the results of the obstacle avoidance experiments is available at: https://www.youtube.com/watch?v=FoXiO5S_tA8",
      "authors": [
        "Van-Hoang-Anh Phan",
        "Chi-Tam Nguyen",
        "Doan-Trung Au",
        "Thanh-Danh Phan",
        "Minh-Thien Duong",
        "My-Ha Le"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:41:14+00:00",
          "link": "https://arxiv.org/abs/2507.12449v1",
          "size": "1702kb",
          "version": "v1"
        }
      ],
      "title": "Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12449",
        "HTML": "https://arxiv.org/html/2507.12449v1",
        "PDF": "https://arxiv.org/pdf/2507.12449"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on obstacle avoidance and perception for autonomous vehicles using camera-based systems. It does not discuss reinforcement learning or any related data processing aspects within the RL context explicitly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12451",
      "abstract": "Modeling latent representations in a hyperspherical space has proven effective for capturing directional similarities in high-dimensional text data, benefiting topic modeling. Variational autoencoder-based neural topic models (VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical structure. However, VAE-NTMs often suffer from posterior collapse, where the KL divergence term in the objective function highly diminishes, leading to ineffective latent representations. To mitigate this issue while modeling hyperspherical structure in the latent space, we propose the Spherical Sliced Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior distribution supported on the unit hypersphere and leverages the Spherical Sliced-Wasserstein distance to align the aggregated posterior distribution with the prior. Experimental results demonstrate that S2WTM outperforms state-of-the-art topic models, generating more coherent and diverse topics while improving performance on downstream tasks.",
      "authors": [
        "Suman Adhya",
        "Debarshi Kumar Sanyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:47:45+00:00",
          "link": "https://arxiv.org/abs/2507.12451v1",
          "size": "260kb",
          "version": "v1"
        }
      ],
      "title": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12451",
        "HTML": "https://arxiv.org/html/2507.12451v1",
        "PDF": "https://arxiv.org/pdf/2507.12451"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a topic modeling approach using a spherical sliced-Wasserstein autoencoder. It does not relate to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12453",
      "abstract": "In automated machine learning, scientific discovery, and other applications of Bayesian optimization, deciding when to stop evaluating expensive black-box functions is an important practical consideration. While several adaptive stopping rules have been proposed, in the cost-aware setting they lack guarantees ensuring they stop before incurring excessive function evaluation costs. We propose a cost-aware stopping rule for Bayesian optimization that adapts to varying evaluation costs and is free of heuristic tuning. Our rule is grounded in a theoretical connection to state-of-the-art cost-aware acquisition functions, namely the Pandora's Box Gittins Index (PBGI) and log expected improvement per cost. We prove a theoretical guarantee bounding the expected cumulative evaluation cost incurred by our stopping rule when paired with these two acquisition functions. In experiments on synthetic and empirical tasks, including hyperparameter optimization and neural architecture size search, we show that combining our stopping rule with the PBGI acquisition function consistently matches or outperforms other acquisition-function--stopping-rule pairs in terms of cost-adjusted simple regret, a metric capturing trade-offs between solution quality and cumulative evaluation cost.",
      "authors": [
        "Qian Xie",
        "Linda Cai",
        "Alexander Terenin",
        "Peter I. Frazier",
        "Ziv Scully"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:54:14+00:00",
          "link": "https://arxiv.org/abs/2507.12453v1",
          "size": "3008kb",
          "version": "v1"
        }
      ],
      "title": "Cost-aware Stopping for Bayesian Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12453",
        "HTML": "https://arxiv.org/html/2507.12453v1",
        "PDF": "https://arxiv.org/pdf/2507.12453"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a cost-aware stopping rule for Bayesian Optimization, which, while related to automated machine learning, does not directly address data processing within reinforcement learning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12455",
      "abstract": "Multimodal large language models (MLLMs) have revolutionized cross-modal understanding but continue to struggle with hallucinations - fabricated content contradicting visual inputs. Existing hallucination mitigation methods either incur prohibitive computational costs or introduce distribution mismatches between training data and model outputs. We identify a critical insight: hallucinations predominantly emerge at the early stages of text generation and propagate through subsequent outputs. To address this, we propose **SENTINEL** (**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain pr**E**ference **L**earning), a framework that eliminates dependency on human annotations. Specifically, we first bootstrap high-quality in-domain preference pairs by iteratively sampling model outputs, validating object existence through cross-checking with two open-vocabulary detectors, and classifying sentences into hallucinated/non-hallucinated categories. Subsequently, we use context-coherent positive samples and hallucinated negative samples to build context-aware preference data iteratively. Finally, we train models using a context-aware preference loss (C-DPO) that emphasizes discriminative learning at the sentence level where hallucinations initially manifest. Experimental results show that SENTINEL can reduce hallucinations by over 90\\% compared to the original model and outperforms the previous state-of-the-art method on both hallucination benchmarks and general capabilities benchmarks, demonstrating its superiority and generalization ability. The models, datasets, and code are available at https://github.com/pspdada/SENTINEL.",
      "authors": [
        "Shangpin Peng and Senqiao Yang and Li Jiang and Zhuotao Tian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:55:43+00:00",
          "link": "https://arxiv.org/abs/2507.12455v1",
          "size": "6061kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Object Hallucinations via Sentence-Level Early Intervention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12455",
        "HTML": "https://arxiv.org/html/2507.12455v1",
        "PDF": "https://arxiv.org/pdf/2507.12455"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with hallucination mitigation in multimodal large language models. It does not mention reinforcement learning or related data processing techniques within an RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12456",
      "abstract": "One-shot signatures (OSS) were defined by Amos, Georgiou, Kiayias, and Zhandry (STOC'20). These allow for signing exactly one message, after which the signing key self-destructs, preventing a second message from ever being signed. While such an object is impossible classically, Amos et al observe that OSS may be possible using quantum signing keys by leveraging the no-cloning principle. OSS has since become an important conceptual tool with many applications in decentralized settings and for quantum cryptography with classical communication. OSS are also closely related to separations between classical-binding and collapse-binding for post-quantum hashing and commitments. Unfortunately, the only known OSS construction due to Amos et al. was only justified in a classical oracle model, and moreover their justification was ultimately found to contain a fatal bug. Thus, the existence of OSS, even in a classical idealized model, has remained open.\n  We give the first standard-model OSS, with provable security assuming (sub-exponential) indistinguishability obfuscation (iO) and LWE. This also gives the first standard-model separation between classical and collapse-binding post-quantum commitments/hashing, solving a decade-old open problem. Along the way, we also give the first construction with unconditional security relative to a classical oracle. To achieve our standard-model construction, we develop a notion of permutable pseudorandom permutations (permutable PRPs), and show how they are useful for translating oracle proofs involving random permutations into obfuscation-based proofs. In particular, obfuscating permutable PRPs gives a trapdoor one-way permutation that is \\emph{full-domain}, solving another decade-old-problem of constructing this object from (sub-exponential) iO and one-way functions.",
      "authors": [
        "Omri Shmueli and Mark Zhandry"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:56:08+00:00",
          "link": "https://arxiv.org/abs/2507.12456v1",
          "size": "2559kb",
          "version": "v1"
        }
      ],
      "title": "On One-Shot Signatures, Quantum vs Classical Binding, and Obfuscating Permutations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12456",
        "HTML": "https://arxiv.org/html/2507.12456v1",
        "PDF": "https://arxiv.org/pdf/2507.12456"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cryptographic concepts like one-shot signatures and obfuscating permutations. It does not pertain to reinforcement learning or data processing within this context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12461",
      "abstract": "Radiologists rely on eye movements to navigate and interpret medical images. A trained radiologist possesses knowledge about the potential diseases that may be present in the images and, when searching, follows a mental checklist to locate them using their gaze. This is a key observation, yet existing models fail to capture the underlying intent behind each fixation. In this paper, we introduce a deep learning-based approach, RadGazeIntent, designed to model this behavior: having an intention to find something and actively searching for it. Our transformer-based architecture processes both the temporal and spatial dimensions of gaze data, transforming fine-grained fixation features into coarse, meaningful representations of diagnostic intent to interpret radiologists' goals. To capture the nuances of radiologists' varied intention-driven behaviors, we process existing medical eye-tracking datasets to create three intention-labeled subsets: RadSeq (Systematic Sequential Search), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid Pattern). Experimental results demonstrate RadGazeIntent's ability to predict which findings radiologists are examining at specific moments, outperforming baseline methods across all intention-labeled datasets.",
      "authors": [
        "Trong-Thang Pham",
        "Anh Nguyen",
        "Zhigang Deng",
        "Carol C. Wu",
        "Hien Van Nguyen",
        "Ngan Le"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:58:35+00:00",
          "link": "https://arxiv.org/abs/2507.12461v1",
          "size": "14541kb",
          "version": "v1"
        }
      ],
      "title": "Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12461",
        "HTML": "https://arxiv.org/html/2507.12461v1",
        "PDF": "https://arxiv.org/pdf/2507.12461"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with interpreting radiologist intention through eye movements in medical imaging using deep learning. It does not relate to reinforcement learning or data processing in this area."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12462",
      "abstract": "We present SpatialTrackerV2, a feed-forward 3D point tracking method for monocular videos. Going beyond modular pipelines built on off-the-shelf components for 3D tracking, our approach unifies the intrinsic connections between point tracking, monocular depth, and camera pose estimation into a high-performing and feedforward 3D point tracker. It decomposes world-space 3D motion into scene geometry, camera ego-motion, and pixel-wise object motion, with a fully differentiable and end-to-end architecture, allowing scalable training across a wide range of datasets, including synthetic sequences, posed RGB-D videos, and unlabeled in-the-wild footage. By learning geometry and motion jointly from such heterogeneous data, SpatialTrackerV2 outperforms existing 3D tracking methods by 30%, and matches the accuracy of leading dynamic 3D reconstruction approaches while running 50$\\times$ faster.",
      "authors": [
        "Yuxi Xiao",
        "Jianyuan Wang",
        "Nan Xue",
        "Nikita Karaev",
        "Yuri Makarov",
        "Bingyi Kang",
        "Xing Zhu",
        "Hujun Bao",
        "Yujun Shen",
        "Xiaowei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:03+00:00",
          "link": "https://arxiv.org/abs/2507.12462v1",
          "size": "13458kb",
          "version": "v1"
        }
      ],
      "title": "SpatialTrackerV2: 3D Point Tracking Made Easy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12462",
        "HTML": "https://arxiv.org/html/2507.12462v1",
        "PDF": "https://arxiv.org/pdf/2507.12462"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on 3D point tracking for monocular videos, including monocular depth and camera pose estimation. It does not address reinforcement learning or data processing relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12463",
      "abstract": "Humans are integral components of the transportation ecosystem, and understanding their behaviors is crucial to facilitating the development of safe driving systems. Although recent progress has explored various aspects of human behavior$\\unicode{x2014}$such as motion, trajectories, and intention$\\unicode{x2014}$a comprehensive benchmark for evaluating human behavior understanding in autonomous driving remains unavailable. In this work, we propose $\\textbf{MMHU}$, a large-scale benchmark for human behavior analysis featuring rich annotations, such as human motion and trajectories, text description for human motions, human intention, and critical behavior labels relevant to driving safety. Our dataset encompasses 57k human motion clips and 1.73M frames gathered from diverse sources, including established driving datasets such as Waymo, in-the-wild videos from YouTube, and self-collected data. A human-in-the-loop annotation pipeline is developed to generate rich behavior captions. We provide a thorough dataset analysis and benchmark multiple tasks$\\unicode{x2014}$ranging from motion prediction to motion generation and human behavior question answering$\\unicode{x2014}$thereby offering a broad evaluation suite. Project page : https://MMHU-Benchmark.github.io.",
      "authors": [
        "Renjie Li",
        "Ruijie Ye",
        "Mingyang Wu",
        "Hao Frank Yang",
        "Zhiwen Fan",
        "Hezhen Hu",
        "Zhengzhong Tu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:30+00:00",
          "link": "https://arxiv.org/abs/2507.12463v1",
          "size": "22370kb",
          "version": "v1"
        }
      ],
      "title": "MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12463",
        "HTML": "https://arxiv.org/html/2507.12463v1",
        "PDF": "https://arxiv.org/pdf/2507.12463"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for human behavior analysis in autonomous driving contexts. Despite the dataset focus, it does not tie into reinforcement learning or data processing for RL agents."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12464",
      "abstract": "Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic interpretability of transformer-based foundation models. Very recently, SAEs were also adopted for the visual domain, enabling the discovery of visual concepts and their patch-wise attribution to tokens in the transformer model. While a growing number of foundation models emerged for medical imaging, tools for explaining their inferences are still lacking. In this work, we show the applicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder which is trained on over 40,000 peripheral blood single-cell images. CytoSAE generalizes to diverse and out-of-domain datasets, including bone marrow cytology, where it identifies morphologically relevant concepts which we validated with medical experts. Furthermore, we demonstrate scenarios in which CytoSAE can generate patient-specific and disease-specific concepts, enabling the detection of pathognomonic cells and localized cellular abnormalities at the patch level. We quantified the effect of concepts on a patient-level AML subtype classification task and show that CytoSAE concepts reach performance comparable to the state-of-the-art, while offering explainability on the sub-cellular level. Source code and model weights are available at https://github.com/dynamical-inference/cytosae.",
      "authors": [
        "Muhammed Furkan Dasdelen",
        "Hyesu Lim",
        "Michele Buck",
        "Katharina S. G\\\"otze",
        "Carsten Marr and Steffen Schneider"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:32+00:00",
          "link": "https://arxiv.org/abs/2507.12464v1",
          "size": "7030kb",
          "version": "v1"
        }
      ],
      "title": "CytoSAE: Interpretable Cell Embeddings for Hematology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12464",
        "HTML": "https://arxiv.org/html/2507.12464v1",
        "PDF": "https://arxiv.org/pdf/2507.12464"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "CytoSAE, presented in the paper, is a sparse autoencoder for interpretability in hematology images. The research does not involve reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12465",
      "abstract": "3D modeling is moving from virtual to physical. Existing 3D generation primarily emphasizes geometries and textures while neglecting physical-grounded modeling. Consequently, despite the rapid development of 3D generative models, the synthesized 3D assets often overlook rich and important physical properties, hampering their real-world application in physical domains like simulation and embodied AI. As an initial attempt to address this challenge, we propose \\textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we present PhysXNet - the first physics-grounded 3D dataset systematically annotated across five foundational dimensions: absolute scale, material, affordance, kinematics, and function description. In particular, we devise a scalable human-in-the-loop annotation pipeline based on vision-language models, which enables efficient creation of physics-first assets from raw 3D assets.2) Furthermore, we propose \\textbf{PhysXGen}, a feed-forward framework for physics-grounded image-to-3D asset generation, injecting physical knowledge into the pre-trained 3D structural space. Specifically, PhysXGen employs a dual-branch architecture to explicitly model the latent correlations between 3D structures and physical properties, thereby producing 3D assets with plausible physical predictions while preserving the native geometry quality. Extensive experiments validate the superior performance and promising generalization capability of our framework. All the code, data, and models will be released to facilitate future research in generative physical AI.",
      "authors": [
        "Ziang Cao",
        "Zhaoxi Chen",
        "Linag Pan",
        "Ziwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:35+00:00",
          "link": "https://arxiv.org/abs/2507.12465v1",
          "size": "3895kb",
          "version": "v1"
        }
      ],
      "title": "PhysX: Physical-Grounded 3D Asset Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12465",
        "HTML": "https://arxiv.org/html/2507.12465v1",
        "PDF": "https://arxiv.org/pdf/2507.12465"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D asset generation with physical properties but does not discuss reinforcement learning or any aspects related to data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12466",
      "abstract": "Every data selection method inherently has a target. In practice, these targets often emerge implicitly through benchmark-driven iteration: researchers develop selection strategies, train models, measure benchmark performance, then refine accordingly. This raises a natural question: what happens when we make this optimization explicit? To explore this, we propose benchmark-targeted ranking (BETR), a simple method that selects pretraining documents based on similarity to benchmark training examples. BETR embeds benchmark examples and a sample of pretraining documents in a shared space, scores this sample by similarity to benchmarks, then trains a lightweight classifier to predict these scores for the full corpus. We compare data selection methods by training over 500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to them. From this, we find that simply aligning pretraining data to evaluation benchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline (4.7x over unfiltered data) and improves performance on 9 out of 10 tasks across all scales. BETR also generalizes well: when targeting a diverse set of benchmarks disjoint from our evaluation suite, it still matches or outperforms baselines. Our scaling analysis further reveals a clear trend: larger models require less aggressive filtering. Overall, our findings show that directly matching pretraining data to target tasks precisely shapes model capabilities and highlight that optimal selection strategies must adapt to model scale.",
      "authors": [
        "David Mizrahi",
        "Anders Boesen Lindbo Larsen",
        "Jesse Allardice",
        "Suzie Petryk",
        "Yuri Gorokhov",
        "Jeffrey Li",
        "Alex Fang",
        "Josh Gardner",
        "Tom Gunter",
        "Afshin Dehghan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:45+00:00",
          "link": "https://arxiv.org/abs/2507.12466v1",
          "size": "18097kb",
          "version": "v1"
        }
      ],
      "title": "Language Models Improve When Pretraining Data Matches Target Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12466",
        "HTML": "https://arxiv.org/html/2507.12466v1",
        "PDF": "https://arxiv.org/pdf/2507.12466"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores the effects of aligning pretraining data with target tasks for language models. It does not mention reinforcement learning or any specific data processing techniques related to the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2304.12063",
      "abstract": "In automated driving, risk describes potential harm to passengers of an autonomous vehicle (AV) and other road users. Recent studies suggest that human-like driving behavior emerges from embedding risk in AV motion planning algorithms. Additionally, providing evidence that risk is minimized during the AV operation is essential to vehicle safety certification. However, there has yet to be a consensus on how to define and operationalize risk in motion planning or how to bound or minimize it during operation. In this paper, we define a stochastic risk measure and introduce it as a constraint into both robust and stochastic nonlinear model predictive path-following controllers (RMPC and SMPC respectively). We compare the vehicle's behavior arising from employing SMPC and RMPC with respect to safety and path-following performance. Further, the implementation of an automated driving example is provided, showcasing the effects of different risk tolerances and uncertainty growths in predictions of other road users for both cases. We find that the RMPC is significantly more conservative than the SMPC, while also displaying greater following errors towards references. Further, the RMPCs behavior cannot be considered as human-like. Moreover, unlike SMPC, the RMPC cannot account for different risk tolerances. The RMPC generates undesired driving behavior for even moderate uncertainties, which are handled better by the SMPC.",
      "authors": [
        "Leon Tolksdorf",
        "Arturo Tejada",
        "Nathan van de Wouw",
        "Christian Birkner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-24T13:00:01+00:00",
          "link": "https://arxiv.org/abs/2304.12063v1",
          "size": "307kb",
          "version": "v1"
        }
      ],
      "title": "Risk in Stochastic and Robust Model Predictive Path-Following Control for Vehicular Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.12063",
        "PDF": "https://arxiv.org/pdf/2304.12063"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "While the paper involves control strategies for vehicular motion planning in autonomous vehicles, it does not specifically address reinforcement learning processes or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11551",
      "abstract": "Radiographic images are a cornerstone of medical diagnostics in orthopaedics, with anatomical landmark detection serving as a crucial intermediate step for information extraction. General-purpose foundational segmentation models, such as SAM (Segment Anything Model), do not support landmark segmentation out of the box and require prompts to function. However, in medical imaging, the prompts for landmarks are highly specific. Since SAM has not been trained to recognize such landmarks, it cannot generate accurate landmark segmentations for diagnostic purposes. Even MedSAM, a medically adapted variant of SAM, has been trained to identify larger anatomical structures, such as organs and their parts, and lacks the fine-grained precision required for orthopaedic pelvic landmarks. To address this limitation, we propose leveraging another general-purpose, non-foundational model: YOLO. YOLO excels in object detection and can provide bounding boxes that serve as input prompts for SAM. While YOLO is efficient at detection, it is significantly outperformed by SAM in segmenting complex structures. In combination, these two models form a reliable pipeline capable of segmenting not only a small pilot set of eight anatomical landmarks but also an expanded set of 72 landmarks and 16 regions with complex outlines, such as the femoral cortical bone and the pelvic inlet. By using YOLO-generated bounding boxes to guide SAM, we trained the hybrid model to accurately segment orthopaedic pelvic radiographs. Our results show that the proposed combination of YOLO and SAM yields excellent performance in detecting anatomical landmarks and intricate outlines in orthopaedic pelvic radiographs.",
      "authors": [
        "Ekaterina Stansfield",
        "Jennifer A. Mitterer",
        "Abdulrahman Altahhan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T07:17:53+00:00",
          "link": "https://arxiv.org/abs/2507.11551v1",
          "size": "2693kb",
          "version": "v1"
        }
      ],
      "title": "Landmark Detection for Medical Images using a General-purpose Segmentation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11551",
        "HTML": "https://arxiv.org/html/2507.11551v1",
        "PDF": "https://arxiv.org/pdf/2507.11551"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses landmark detection in medical images using segmentation models, with no connections to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11557",
      "abstract": "Magnetic Resonance (MR) imaging plays an essential role in contemporary clinical diagnostics. It is increasingly integrated into advanced therapeutic workflows, such as hybrid Positron Emission Tomography/Magnetic Resonance (PET/MR) imaging and MR-only radiation therapy. These integrated approaches are critically dependent on accurate estimation of radiation attenuation, which is typically facilitated by synthesizing Computed Tomography (CT) images from MR scans to generate attenuation maps. However, existing MR-to-CT synthesis methods for whole-body imaging often suffer from poor spatial alignment between the generated CT and input MR images, and insufficient image quality for reliable use in downstream clinical tasks. In this paper, we present a novel 3D Wavelet Latent Diffusion Model (3D-WLDM) that addresses these limitations by performing modality translation in a learned latent space. By incorporating a Wavelet Residual Module into the encoder-decoder architecture, we enhance the capture and reconstruction of fine-scale features across image and latent spaces. To preserve anatomical integrity during the diffusion process, we disentangle structural and modality-specific characteristics and anchor the structural component to prevent warping. We also introduce a Dual Skip Connection Attention mechanism within the diffusion model, enabling the generation of high-resolution CT images with improved representation of bony structures and soft-tissue contrast.",
      "authors": [
        "Jiaxu Zheng",
        "Meiman He",
        "Xuhui Tang",
        "Xiong Wang",
        "Tuoyu Cao",
        "Tianyi Zeng",
        "Lichi Zhang",
        "and Chenyu You"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:17:05+00:00",
          "link": "https://arxiv.org/abs/2507.11557v1",
          "size": "26793kb",
          "version": "v1"
        }
      ],
      "title": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11557",
        "HTML": "https://arxiv.org/html/2507.11557v1",
        "PDF": "https://arxiv.org/pdf/2507.11557"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work focuses on the translation between MR and CT images using a 3D Wavelet Latent Diffusion Model. It does not relate to reinforcement learning or data processing within that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11561",
      "abstract": "Pulmonary hypertension (PH) in newborns is a critical condition characterized by elevated pressure in the pulmonary arteries, leading to right ventricular strain and heart failure. While right heart catheterization (RHC) is the diagnostic gold standard, echocardiography is preferred due to its non-invasive nature, safety, and accessibility. However, its accuracy highly depends on the operator, making PH assessment subjective. While automated detection methods have been explored, most models focus on adults and rely on single-view echocardiographic frames, limiting their performance in diagnosing PH in newborns. While multi-view echocardiography has shown promise in improving PH assessment, existing models struggle with generalizability. In this work, we employ a multi-view variational autoencoder (VAE) for PH prediction using echocardiographic videos. By leveraging the VAE framework, our model captures complex latent representations, improving feature extraction and robustness. We compare its performance against single-view and supervised learning approaches. Our results show improved generalization and classification accuracy, highlighting the effectiveness of multi-view learning for robust PH assessment in newborns.",
      "authors": [
        "Lucas Erlacher",
        "Samuel Ruip\\'erez-Campillo",
        "Holger Michel",
        "Sven Wellmann",
        "Thomas M. Sutter",
        "Ece Ozkan",
        "Julia E. Vogt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:46:38+00:00",
          "link": "https://arxiv.org/abs/2507.11561v1",
          "size": "1298kb",
          "version": "v1"
        }
      ],
      "title": "Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11561",
        "HTML": "https://arxiv.org/html/2507.11561v1",
        "PDF": "https://arxiv.org/pdf/2507.11561"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using multi-view VAE for pulmonary hypertension prediction, which involves medical imaging and does not relate to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11568",
      "abstract": "Humanity's unprecedented technological capacity and concurrent existential risks reveal a critical lacuna in the philosophical tradition: the absence of a systematic framework for the long-term future. This article argues that formulating such a framework is the central ethical imperative of our era. To defend this thesis, it synthesizes the normative ethics of Hans Jonas and Derek Parfit with the analytical framework of Nick Bostrom's work on existential risk and longtermism. The analysis further addresses the ontological challenge posed by posthumanism to the human 'subject' and explores the functional role of a secular cosmic purpose in motivating long-term action. The paper's main contribution is the articulation of a synthetic research agenda for a prospective philosophy, one that integrates axiology, risk management, and ontology to guide humanity through its perilous technological adolescence.",
      "authors": [
        "Santos E. Moreta Reyes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computers and Society (cs.CY)",
        "History and Philosophy of Physics (physics.hist-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:41:09+00:00",
          "link": "https://arxiv.org/abs/2507.11568v1",
          "size": "166kb",
          "version": "v1"
        }
      ],
      "title": "La \\'Ultima Frontera de La Filosof\\'ia: Hacia una S\\'intesis de La \\'Etica del Futuro a Largo Plazo, el Riesgo Existencial y la Ontolog\\'ia Posthumana",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11568",
        "PDF": "https://arxiv.org/pdf/2507.11568"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is focused on philosophical concepts such as existential risk, longtermism, and posthumanism, without any mention or engagement with reinforcement learning or data processing within that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11569",
      "abstract": "Foundation models, pre-trained on large image datasets and capable of capturing rich feature representations, have recently shown potential for zero-shot image registration. However, their performance has mostly been tested in the context of rigid or less complex structures, such as the brain or abdominal organs, and it remains unclear whether these models can handle more challenging, deformable anatomy. Breast MRI registration is particularly difficult due to significant anatomical variation between patients, deformation caused by patient positioning, and the presence of thin and complex internal structure of fibroglandular tissue, where accurate alignment is crucial. Whether foundation model-based registration algorithms can address this level of complexity remains an open question. In this study, we provide a comprehensive evaluation of foundation model-based registration algorithms for breast MRI. We assess five pre-trained encoders, including DINO-v2, SAM, MedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks that capture variations in different years and dates, sequences, modalities, and patient disease status (lesion versus no lesion). Our results show that foundation model-based algorithms such as SAM outperform traditional registration baselines for overall breast alignment, especially under large domain shifts, but struggle with capturing fine details of fibroglandular tissue. Interestingly, additional pre-training or fine-tuning on medical or breast-specific images in MedSAM and SSLSAM, does not improve registration performance and may even decrease it in some cases. Further work is needed to understand how domain-specific training influences registration and to explore targeted strategies that improve both global alignment and fine structure accuracy. We also publicly release our code at \\href{https://github.com/mazurowski-lab/Foundation-based-reg}{Github}.",
      "authors": [
        "Hanxue Gu",
        "Yaqian Chen",
        "Nicholas Konz",
        "Qihang Li",
        "Maciej A. Mazurowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:17:14+00:00",
          "link": "https://arxiv.org/abs/2507.11569v1",
          "size": "6845kb",
          "version": "v1"
        }
      ],
      "title": "Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11569",
        "HTML": "https://arxiv.org/html/2507.11569v1",
        "PDF": "https://arxiv.org/pdf/2507.11569"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper evaluates foundation model-based algorithms for medical image registration, specifically breast MRI. It does not relate to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11588",
      "abstract": "Spatial Transcriptomics (ST) technologies provide biologists with rich insights into single-cell biology by preserving spatial context of cells. Building foundational models for ST can significantly enhance the analysis of vast and complex data sources, unlocking new perspectives on the intricacies of biological tissues. However, modeling ST data is inherently challenging due to the need to extract multi-scale information from tissue slices containing vast numbers of cells. This process requires integrating macro-scale tissue morphology, micro-scale cellular microenvironment, and gene-scale gene expression profile. To address this challenge, we propose SToFM, a multi-scale Spatial Transcriptomics Foundation Model. SToFM first performs multi-scale information extraction on each ST slice, to construct a set of ST sub-slices that aggregate macro-, micro- and gene-scale information. Then an SE(2) Transformer is used to obtain high-quality cell representations from the sub-slices. Additionally, we construct \\textbf{SToCorpus-88M}, the largest high-resolution spatial transcriptomics corpus for pretraining. SToFM achieves outstanding performance on a variety of downstream tasks, such as tissue region semantic segmentation and cell type annotation, demonstrating its comprehensive understanding of ST data",
      "authors": [
        "Suyuan Zhao",
        "Yizhen Luo",
        "Ganbo Yang",
        "Yan Zhong",
        "Hao Zhou",
        "Zaiqing Nie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Genomics (q-bio.GN)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:47:01+00:00",
          "link": "https://arxiv.org/abs/2507.11588v1",
          "size": "926kb",
          "version": "v1"
        }
      ],
      "title": "SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11588",
        "HTML": "https://arxiv.org/html/2507.11588v1",
        "PDF": "https://arxiv.org/pdf/2507.11588"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a model for Spatial Transcriptomics data analysis and does not pertain to reinforcement learning or RL-specific data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11636",
      "abstract": "Speech quality assessment (SQA) is often used to learn a mapping from a high-dimensional input space to a scalar that represents the mean opinion score (MOS) of the perceptual speech quality. Learning such a mapping is challenging for many reasons, but largely because MOS exhibits high levels of inherent variance due to perceptual and experimental-design differences. Many solutions have been proposed, but many approaches do not properly incorporate perceptual factors into their learning algorithms (beyond the MOS label), which could lead to unsatisfactory results. To this end, we propose JSQA, a two-stage framework that pretrains an audio encoder using perceptually-guided contrastive learning on just noticeable difference (JND) pairs, followed by fine-tuning for MOS prediction. We first generate pairs of audio data within JND levels, which are then used to pretrain an encoder to leverage perceptual quality similarity information and map it into an embedding space. The JND pairs come from clean LibriSpeech utterances that are mixed with background noise from CHiME-3, at different signal-to-noise ratios (SNRs). The encoder is later fine-tuned with audio samples from the NISQA dataset for MOS prediction. Experimental results suggest that perceptually-inspired contrastive pretraining significantly improves the model performance evaluated by various metrics when compared against the same network trained from scratch without pretraining. These findings suggest that incorporating perceptual factors into pretraining greatly contributes to the improvement in performance for SQA.",
      "authors": [
        "Junyi Fan",
        "Donald Williamson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:16:46+00:00",
          "link": "https://arxiv.org/abs/2507.11636v1",
          "size": "763kb",
          "version": "v1"
        }
      ],
      "title": "JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11636",
        "HTML": "https://arxiv.org/html/2507.11636v1",
        "PDF": "https://arxiv.org/pdf/2507.11636"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces JSQA for speech quality assessment, focusing on perceptual factors and contrastive pretraining. It does not address reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11686",
      "abstract": "For a graph $G = (V,E)$ and a subset $R \\subseteq V$, we say that $R$ is \\textit{multiset resolving} for $G$ if for every pair of vertices $v,w$, the \\textit{multisets} $\\{d(v,r): r \\in R\\}$ and $\\{d(w,r):r \\in R\\}$ are distinct, where $d(x,y)$ is the graph distance between vertices $x$ and $y$. The \\textit{multiset metric dimension} of $G$ is the size of a smallest set $R \\subseteq V$ that is multiset resolving (or $\\infty$ if no such set exists). This graph parameter was introduced by Simanjuntak, Siagian, and Vitr\\'{i}k in 2017~\\cite{simanjuntak2017multiset}, and has since been studied for a variety of graph families. We prove bounds which hold with high probability for the multiset metric dimension of the binomial random graph $G(n,p)$ in the regime $d = (n-1)p = \\Theta(n^{x})$ for fixed $x \\in (0,1)$.",
      "authors": [
        "Austin Eide",
        "Pawel Pralat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:41:23+00:00",
          "link": "https://arxiv.org/abs/2507.11686v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "Multiset Metric Dimension of Binomial Random Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11686",
        "HTML": "https://arxiv.org/html/2507.11686v1",
        "PDF": "https://arxiv.org/pdf/2507.11686"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper studies the multiset metric dimension of binomial random graphs, which is unrelated to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11692",
      "abstract": "Modern digital sky surveys have been acquiring images of billions of galaxies. While these images often provide sufficient details to analyze the shape of the galaxies, accurate analysis of such high volumes of images requires effective automation. Current solutions often rely on machine learning annotation of the galaxy images based on a set of pre-defined classes. Here we introduce a new approach to galaxy image analysis that is based on generative AI. The method simplifies the galaxy images and automatically converts them into a ``skeletonized\" form. The simplified images allow accurate measurements of the galaxy shapes and analysis that is not limited to a certain pre-defined set of classes. We demonstrate the method by applying it to galaxy images acquired by the DESI Legacy Survey. The code and data are publicly available. The method was applied to 125,000 DESI Legacy Survey images, and the catalog of the simplified images is publicly available.",
      "authors": [
        "Sai Teja Erukude",
        "Lior Shamir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Astrophysics of Galaxies (astro-ph.GA)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:48:09+00:00",
          "link": "https://arxiv.org/abs/2507.11692v1",
          "size": "797kb",
          "version": "v1"
        }
      ],
      "title": "Galaxy image simplification using Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11692",
        "HTML": "https://arxiv.org/html/2507.11692v1",
        "PDF": "https://arxiv.org/pdf/2507.11692"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a generative AI approach for simplifying galaxy images, which does not involve reinforcement learning or data processing techniques within RL frameworks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11711",
      "abstract": "We explore the use of Swin Transformer V2, a pre-trained vision Transformer, for photometric classification in a multi-survey setting by leveraging light curves from the Zwicky Transient Facility (ZTF) and the Asteroid Terrestrial-impact Last Alert System (ATLAS). We evaluate different strategies for integrating data from these surveys and find that a multi-survey architecture which processes them jointly achieves the best performance. These results highlight the importance of modeling survey-specific characteristics and cross-survey interactions, and provide guidance for building scalable classifiers for future time-domain astronomy.",
      "authors": [
        "Daniel Moreno-Cartagena",
        "Guillermo Cabrera-Vives",
        "Alejandra M. Mu\\~noz Arancibia",
        "Pavlos Protopapas",
        "Francisco F\\\"orster",
        "M\\'arcio Catelan",
        "A. Bayo",
        "Pablo A. Est\\'evez",
        "P. S\\'anchez-S\\'aez",
        "Franz E. Bauer",
        "M. Pavez-Herrera",
        "L. Hern\\'andez-Garc\\'ia",
        "and Gonzalo Rojas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:30:21+00:00",
          "link": "https://arxiv.org/abs/2507.11711v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "Image-Based Multi-Survey Classification of Light Curves with a Pre-Trained Vision Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11711",
        "HTML": "https://arxiv.org/html/2507.11711v1",
        "PDF": "https://arxiv.org/pdf/2507.11711"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates the use of a vision transformer for classifying light curves in astronomy, focusing on integrating multi-survey data. It is not related to reinforcement learning or any data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11768",
      "abstract": "Large language models demonstrate remarkable in-context learning capabilities, adapting to new tasks without parameter updates. While this phenomenon has been successfully modeled as implicit Bayesian inference, recent empirical findings reveal a fundamental contradiction: transformers systematically violate the martingale property, a cornerstone requirement of Bayesian updating on exchangeable data. This violation challenges the theoretical foundations underlying uncertainty quantification in critical applications.\n  Our theoretical analysis establishes four key results: (1) positional encodings induce martingale violations of order $\\Theta(\\log n / n)$; (2) transformers achieve information-theoretic optimality with excess risk $O(n^{-1/2})$ in expectation over orderings; (3) the implicit posterior representation converges to the true Bayesian posterior in the space of sufficient statistics; and (4) we derive the optimal chain-of-thought length as $k^* = \\Theta(\\sqrt{n}\\log(1/\\varepsilon))$ with explicit constants, providing a principled approach to reduce inference costs while maintaining performance. Empirical validation on GPT-3 confirms predictions (1)-(3), with transformers reaching 99\\% of theoretical entropy limits within 20 examples. Our framework provides practical methods for extracting calibrated uncertainty estimates from position-aware architectures and optimizing computational efficiency in deployment.",
      "authors": [
        "Leon Chlon",
        "Sarah Rashidi",
        "Zein Khamis",
        "and MarcAntonio M. Awada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:20:11+00:00",
          "link": "https://arxiv.org/abs/2507.11768v1",
          "size": "1500kb",
          "version": "v1"
        }
      ],
      "title": "LLMs are Bayesian, in Expectation, not in Realization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11768",
        "HTML": "https://arxiv.org/html/2507.11768v1",
        "PDF": "https://arxiv.org/pdf/2507.11768"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the Bayesian modeling of large language models and their in-context learning capabilities, with no discussion of data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11779",
      "abstract": "We consider a class of multi-agent distributed synchronization systems, which are modeled as $n$ particles moving on the real line. This class generalizes the model of a multi-server queueing system, considered in [15], employing so-called cancel-on-completion (c.o.c.) redundancy mechanism, but is motivated by other applications as well. The model in [15] is a particle system, regulated at the left boundary point. The more general model of this paper is such that we allow regulation boundaries on either side, or both sides, or no regulation at all. We consider the mean-field asymptotic regime, when the number of particles $n$ and the job arrival rates go to infinity, while the job arrival rates per particle remain constant. The results include: the existence/uniqueness of fixed points of mean-field limits (ML), which describe the limiting dynamics of the system; conditions for the steady-state asymptotic independence (concentration, as $n \\to\\infty$, of the stationary distribution on a single state, which is necessarily an ML fixed point); the limits, as $n \\to\\infty$, of the average velocity at which unregulated (free) particle system advances. In particular, our results for the left-regulated system unify and generalize the corresponding results in [15]. Our technical development is such that the systems with different types of regulation are analyzed within a unified framework. In particular, these systems are used as tools for analysis of each other.",
      "authors": [
        "Alexander Stolyar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:36:59+00:00",
          "link": "https://arxiv.org/abs/2507.11779v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Large-scale distributed synchronization systems, using a cancel-on-completion redundancy mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11779",
        "HTML": "https://arxiv.org/html/2507.11779v1",
        "PDF": "https://arxiv.org/pdf/2507.11779"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses distributed synchronization systems and queueing models with a focus on theoretical properties and particle systems, without any mention of reinforcement learning or data processing in that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11780",
      "abstract": "Constructing confidence intervals for the value of an optimal treatment policy is an important problem in causal inference. Insight into the optimal policy value can guide the development of reward-maximizing, individualized treatment regimes. However, because the functional that defines the optimal value is non-differentiable, standard semi-parametric approaches for performing inference fail to be directly applicable. Existing approaches for handling this non-differentiability fall roughly into two camps. In one camp are estimators based on constructing smooth approximations of the optimal value. These approaches are computationally lightweight, but typically place unrealistic parametric assumptions on outcome regressions. In another camp are approaches that directly de-bias the non-smooth objective. These approaches don't place parametric assumptions on nuisance functions, but they either require the computation of intractably-many nuisance estimates, assume unrealistic $L^\\infty$ nuisance convergence rates, or make strong margin assumptions that prohibit non-response to a treatment. In this paper, we revisit the problem of constructing smooth approximations of non-differentiable functionals. By carefully controlling first-order bias and second-order remainders, we show that a softmax smoothing-based estimator can be used to estimate parameters that are specified as a maximum of scores involving nuisance components. In particular, this includes the value of the optimal treatment policy as a special case. Our estimator obtains $\\sqrt{n}$ convergence rates, avoids parametric restrictions/unrealistic margin assumptions, and is often statistically efficient.",
      "authors": [
        "Justin Whitehouse",
        "Morgane Austern",
        "Vasilis Syrgkanis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Econometrics (econ.EM)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:38:39+00:00",
          "link": "https://arxiv.org/abs/2507.11780v1",
          "size": "357kb",
          "version": "v1"
        }
      ],
      "title": "Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11780",
        "HTML": "https://arxiv.org/html/2507.11780v1",
        "PDF": "https://arxiv.org/pdf/2507.11780"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper proposes a smoothing-based estimator for optimal policy values which is relevant to RL, particularly in treatment policy optimization. However, the main focus is on statistical inference rather than data processing per se in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11783",
      "abstract": "Patterns of electrical brain activity recorded via electroencephalography (EEG) offer immense value for scientific and clinical investigations. The inability of supervised EEG encoders to learn robust EEG patterns and their over-reliance on expensive signal annotations have sparked a transition towards general-purpose self-supervised EEG encoders, i.e., EEG foundation models (EEG-FMs), for robust and scalable EEG feature extraction. However, the real-world readiness of early EEG-FMs and the rubric for long-term research progress remain unclear. A systematic and comprehensive review of first-generation EEG-FMs is therefore necessary to understand the current state-of-the-art and identify key directions for future EEG-FMs. To that end, this study reviews 10 early EEG-FMs and presents a critical synthesis of their methodology, empirical findings, and outstanding research gaps. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. We believe that developing benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may further advance the translational utility and real-world adoption of EEG-FMs.",
      "authors": [
        "Gayal Kuruppu",
        "Neeraj Wagh",
        "Yogatheesan Varatharajah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:52:44+00:00",
          "link": "https://arxiv.org/abs/2507.11783v1",
          "size": "1309kb",
          "version": "v1"
        }
      ],
      "title": "Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11783",
        "HTML": "https://arxiv.org/html/2507.11783v1",
        "PDF": "https://arxiv.org/pdf/2507.11783"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This review paper focuses on EEG foundation models and self-supervised learning for brain signals, without any specific discussion on reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11799",
      "abstract": "This paper presents a neural network (NN)-based solver for an integro-differential equation that models shrinkage-induced fragmentation. The proposed method directly maps input parameters to the corresponding probability density function without numerically solving the governing equation, thereby significantly reducing computational costs. Specifically, it enables efficient evaluation of the density function in Monte Carlo simulations while maintaining accuracy comparable to or even exceeding that of conventional finite difference schemes. Validatation on synthetic data demonstrates both the method's computational efficiency and predictive reliability. This study establishes a foundation for the data-driven inverse analysis of fragmentation and suggests the potential for extending the framework beyond pre-specified model structures.",
      "authors": [
        "Shin-ichi Ito"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:33:05+00:00",
          "link": "https://arxiv.org/abs/2507.11799v1",
          "size": "1548kb",
          "version": "v1"
        }
      ],
      "title": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11799",
        "HTML": "https://arxiv.org/html/2507.11799v1",
        "PDF": "https://arxiv.org/pdf/2507.11799"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a neural network-based solver for integro-differential equations related to shrinkage-induced fragmentation. It focuses on computational efficiency and density estimation, with no connection to reinforcement learning or data processing within that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11806",
      "abstract": "Universal machine learning interatomic potentials (uMLIPs) have emerged as powerful tools for accelerating atomistic simulations, offering scalable and efficient modeling with accuracy close to quantum calculations. However, their reliability and effectiveness in practical, real-world applications remain an open question. Metal-organic frameworks (MOFs) and related nanoporous materials are highly porous crystals with critical relevance in carbon capture, energy storage, and catalysis applications. Modeling nanoporous materials presents distinct challenges for uMLIPs due to their diverse chemistry, structural complexity, including porosity and coordination bonds, and the absence from existing training datasets. Here, we introduce MOFSimBench, a benchmark to evaluate uMLIPs on key materials modeling tasks for nanoporous materials, including structural optimization, molecular dynamics (MD) stability, the prediction of bulk properties, such as bulk modulus and heat capacity, and guest-host interactions. Evaluating over 20 models from various architectures on a chemically and structurally diverse materials set, we find that top-performing uMLIPs consistently outperform classical force fields and fine-tuned machine learning potentials across all tasks, demonstrating their readiness for deployment in nanoporous materials modeling. Our analysis highlights that data quality, particularly the diversity of training sets and inclusion of out-of-equilibrium conformations, plays a more critical role than model architecture in determining performance across all evaluated uMLIPs. We release our modular and extendable benchmarking framework at https://github.com/AI4ChemS/mofsim-bench, providing an open resource to guide the adoption for nanoporous materials modeling and further development of uMLIPs.",
      "authors": [
        "Hendrik Kra{\\ss} and Ju Huang and Seyed Mohamad Moosavi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:00:55+00:00",
          "link": "https://arxiv.org/abs/2507.11806v1",
          "size": "9711kb",
          "version": "v1"
        }
      ],
      "title": "MOFSimBench: Evaluating Universal Machine Learning Interatomic Potentials In Metal--Organic Framework Molecular Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11806",
        "HTML": "https://arxiv.org/html/2507.11806v1",
        "PDF": "https://arxiv.org/pdf/2507.11806"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on evaluating machine learning interatomic potentials for materials modeling, specifically in metal-organic frameworks. It does not relate to reinforcement learning or data processing within that domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11814",
      "abstract": "Cycle rank is one of the depth parameters for digraphs introduced by Eggan in 1963. We show that there exists a function $f:\\mathbb{N}\\to \\mathbb{N}$ such that every digraph of cycle rank at least $f(k)$ contains a directed cycle chain, a directed ladder, or a directed tree chain of order $k$ as a butterfly minor. We also investigate a new connection between cycle rank and a directed analogue of the weak coloring number of graphs.",
      "authors": [
        "Meike Hatzel",
        "O-joung Kwon",
        "Myounghwan Lee",
        "Sebastian Wiederrecht"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T00:24:53+00:00",
          "link": "https://arxiv.org/abs/2507.11814v1",
          "size": "633kb",
          "version": "v1"
        }
      ],
      "title": "Unavoidable butterfly minors in digraphs of large cycle rank",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11814",
        "HTML": "https://arxiv.org/html/2507.11814v1",
        "PDF": "https://arxiv.org/pdf/2507.11814"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is about digraphs and cycle rank, with no connection to reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11825",
      "abstract": "This study examines a fundamental yet overlooked function of peer review: its role in exposing reviewers to new and unexpected ideas. Leveraging a natural experiment involving over half a million peer review invitations covering both accepted and rejected manuscripts, and integrating high-scale bibliographic and editorial records for 37,279 submitting authors, we find that exposure to a manuscript's core ideas significantly influences the future referencing behavior and knowledge of reviewer invitees who decline the review invite. Specifically, declining reviewer invitees who could view concise summaries of the manuscript's core ideas not only increase their citations to the manuscript itself but also demonstrate expanded breadth, depth, diversity, and prominence of citations to the submitting author's broader body of work. Overall, these results suggest peer review substantially influences the spread of scientific knowledge. Ironically, while the massive scale of peer review, entailing millions of reviews annually, often drives policy debates about its costs and burdens, our findings demonstrate that precisely because of this scale, peer review serves as a powerful yet previously unrecognized engine for idea diffusion, which is central to scientific advances and scholarly communication.",
      "authors": [
        "Binglu Wang",
        "Zhengnan Ma",
        "Dashun Wang",
        "Brian Uzzi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:02:51+00:00",
          "link": "https://arxiv.org/abs/2507.11825v1",
          "size": "3819kb",
          "version": "v1"
        }
      ],
      "title": "Peer Review and the Diffusion of Ideas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11825",
        "PDF": "https://arxiv.org/pdf/2507.11825"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study analyzes the role of peer review in idea diffusion, not related to data processing tasks in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11842",
      "abstract": "Generative machine learning models have been demonstrated to be able to learn low dimensional representations of data that preserve information required for downstream tasks. In this work, we demonstrate that flow matching based generative models can learn compact, semantically rich latent representations of field level cold dark matter (CDM) simulation data without supervision. Our model, CosmoFlow, learns representations 32x smaller than the raw field data, usable for field level reconstruction, synthetic data generation, and parameter inference. Our model also learns interpretable representations, in which different latent channels correspond to features at different cosmological scales.",
      "authors": [
        "Sidharth Kannan",
        "Tian Qiu",
        "Carolina Cuesta-Lazaro",
        "Haewon Jeong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:15:31+00:00",
          "link": "https://arxiv.org/abs/2507.11842v1",
          "size": "3678kb",
          "version": "v1"
        }
      ],
      "title": "CosmoFlow: Scale-Aware Representation Learning for Cosmology with Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11842",
        "HTML": "https://arxiv.org/html/2507.11842v1",
        "PDF": "https://arxiv.org/pdf/2507.11842"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study focuses on representation learning for cosmology using generative models, which does not involve reinforcement learning or data processing specific to RL scenarios."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11853",
      "abstract": "The development of advanced packaging is essential in the semiconductor manufacturing industry. However, non-destructive testing (NDT) of advanced packaging becomes increasingly challenging due to the depth and complexity of the layers involved. In such a scenario, Magnetic field imaging (MFI) enables the imaging of magnetic fields generated by currents. For MFI to be effective in NDT, the magnetic fields must be converted into current density. This conversion has typically relied solely on a Fast Fourier Transform (FFT) for magnetic field inversion; however, the existing approach does not consider eddy current effects or image misalignment in the test setup. In this paper, we present a spatial-physics informed model (SPIM) designed for a 3D spiral sample scanned using Superconducting QUantum Interference Device (SQUID) microscopy. The SPIM encompasses three key components: i) magnetic image enhancement by aligning all the \"sharp\" wire field signals to mitigate the eddy current effect using both in-phase (I-channel) and quadrature-phase (Q-channel) images; (ii) magnetic image alignment that addresses skew effects caused by any misalignment of the scanning SQUID microscope relative to the wire segments; and (iii) an inversion method for converting magnetic fields to magnetic currents by integrating the Biot-Savart Law with FFT. The results show that the SPIM improves I-channel sharpness by 0.3% and reduces Q-channel sharpness by 25%. Also, we were able to remove rotational and skew misalignments of 0.30 in a real image. Overall, SPIM highlights the potential of combining spatial analysis with physics-driven models in practical applications.",
      "authors": [
        "J. Senthilnath",
        "Jayasanker Jayabalan",
        "Zhuoyi Lin",
        "Aye Phyu Phyu Aung",
        "Chen Hao",
        "Kaixin Xu",
        "Yeow Kheng Lim",
        "F. C. Wellstood"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Detectors (physics.ins-det)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:34:33+00:00",
          "link": "https://arxiv.org/abs/2507.11853v1",
          "size": "692kb",
          "version": "v1"
        }
      ],
      "title": "A Spatial-Physics Informed Model for 3D Spiral Sample Scanned by SQUID Microscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11853",
        "PDF": "https://arxiv.org/pdf/2507.11853"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a spatial-physics informed model for SQUID microscopy, and does not involve reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11891",
      "abstract": "We study A/B experiments that are designed to compare the performance of two recommendation algorithms. Prior work has shown that the standard difference-in-means estimator is biased in estimating the global treatment effect (GTE) due to a particular form of interference between experimental units. Specifically, units under the treatment and control algorithms contribute to a shared pool of data that subsequently train both algorithms, resulting in interference between the two groups. The bias arising from this type of data sharing is known as \"symbiosis bias\". In this paper, we highlight that, for decision-making purposes, the sign of the GTE often matters more than its precise magnitude when selecting the better algorithm. We formalize this insight under a multi-armed bandit framework and theoretically characterize when the sign of the expected GTE estimate under data sharing aligns with or contradicts the sign of the true GTE. Our analysis identifies the level of exploration versus exploitation as a key determinant of how symbiosis bias impacts algorithm selection.",
      "authors": [
        "Shuangning Li",
        "Chonghuan Wang",
        "Jingyan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:14:52+00:00",
          "link": "https://arxiv.org/abs/2507.11891v1",
          "size": "1439kb",
          "version": "v1"
        }
      ],
      "title": "Choosing the Better Bandit Algorithm under Data Sharing: When Do A/B Experiments Work?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11891",
        "HTML": "https://arxiv.org/html/2507.11891v1",
        "PDF": "https://arxiv.org/pdf/2507.11891"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper analyzes A/B experiments and symbiosis bias in multi-armed bandit settings, indirectly touching upon data sharing impacting RL algorithms, but data processing is not the main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11895",
      "abstract": "The increasing complexity of machine learning (ML) and artificial intelligence (AI) models has created a pressing need for tools that help scientists, engineers, and policymakers interpret and refine model decisions and predictions. Influence functions, originating from robust statistics, have emerged as a popular approach for this purpose.\n  However, the heuristic foundations of influence functions rely on low-dimensional assumptions where the number of parameters $p$ is much smaller than the number of observations $n$. In contrast, modern AI models often operate in high-dimensional regimes with large $p$, challenging these assumptions.\n  In this paper, we examine the accuracy of influence functions in high-dimensional settings. Our theoretical and empirical analyses reveal that influence functions cannot reliably fulfill their intended purpose. We then introduce an alternative approximation, called Newfluence, that maintains similar computational efficiency while offering significantly improved accuracy.\n  Newfluence is expected to provide more accurate insights than many existing methods for interpreting complex AI models and diagnosing their issues. Moreover, the high-dimensional framework we develop in this paper can also be applied to analyze other popular techniques, such as Shapley values.",
      "authors": [
        "Haolin Zou",
        "Arnab Auddy",
        "Yongchan Kwon",
        "Kamiar Rahnama Rad",
        "Arian Maleki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:22:16+00:00",
          "link": "https://arxiv.org/abs/2507.11895v1",
          "size": "119kb",
          "version": "v1"
        }
      ],
      "title": "Newfluence: Boosting Model interpretability and Understanding in High Dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11895",
        "HTML": "https://arxiv.org/html/2507.11895v1",
        "PDF": "https://arxiv.org/pdf/2507.11895"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on improving interpretability of machine learning models in high-dimensional settings using influence functions. There is no mention of reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11950",
      "abstract": "Functional annotation of microbial genomes is often biased toward protein-coding genes, leaving a vast, unexplored landscape of non-coding RNAs (ncRNAs) that are critical for regulating bacterial and archaeal physiology, stress response and metabolism. Identifying ncRNAs directly from genomic sequence is a paramount challenge in bioinformatics and biology, essential for understanding the complete regulatory potential of an organism. This paper presents RNAMunin, a machine learning (ML) model that is capable of finding ncRNAs using genomic sequence alone. It is also computationally viable for large sequence datasets such as long read metagenomic assemblies with contigs totaling multiple Gbp. RNAMunin is trained on Rfam sequences extracted from approximately 60 Gbp of long read metagenomes from 16 San Francisco Estuary samples. We know of no other model that can detect ncRNAs based solely on genomic sequence at this scale. Since RNAMunin only requires genomic sequence as input, we do not need for an ncRNA to be transcribed to find it, i.e., we do not need transcriptomics data. We wrote this manuscript in a narrative style in order to best convey how RNAMunin was developed and how it works in detail. Unlike almost all current ML models, at approximately 1M parameters, RNAMunin is very small and very fast.",
      "authors": [
        "Lauren Lui and Torben Nielsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Genomics (q-bio.GN)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:33:50+00:00",
          "link": "https://arxiv.org/abs/2507.11950v1",
          "size": "526kb",
          "version": "v1"
        }
      ],
      "title": "RNAMunin: A Deep Machine Learning Model for Non-coding RNA Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11950",
        "PDF": "https://arxiv.org/pdf/2507.11950"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a machine learning model for non-coding RNA discovery based on genomic sequences. It does not mention reinforcement learning or any data processing tasks associated with RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11970",
      "abstract": "Program obfuscation aims to hide the inner workings of a program while preserving its functionality. In the quantum setting, recent works have obtained obfuscation schemes for specialized classes of quantum circuits. For instance, Bartusek, Brakerski, and Vaikuntanathan (STOC 2024) constructed a quantum state obfuscation scheme, which supports the obfuscation of quantum programs represented as quantum states for pseudo-deterministic quantum programs with classical inputs and outputs in the classical oracle model.\n  In this work, we improve upon existing results by constructing the first quantum state obfuscation scheme for unitary (or approximately unitary) quantum programs supporting quantum inputs and outputs in the classical oracle model. At the core of our obfuscation scheme are two novel ingredients: a functional quantum authentication scheme that allows key holders to learn specific functions of the authenticated quantum state with simulation-based security, and a compiler that represents an arbitrary quantum circuit as a projective linear-plus-measurement quantum program described by a sequence of non-adaptive Clifford gates interleaved with adaptive and compatible measurements.",
      "authors": [
        "Mi-Ying Huang",
        "Er-Cheng Tang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:07:52+00:00",
          "link": "https://arxiv.org/abs/2507.11970v1",
          "size": "70kb",
          "version": "v1"
        }
      ],
      "title": "Obfuscation of Unitary Quantum Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11970",
        "PDF": "https://arxiv.org/pdf/2507.11970"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work addresses quantum program obfuscation and constructs a state obfuscation scheme, which is unrelated to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11977",
      "abstract": "The study of boosted Higgs bosons at the LHC provides a unique window to probe Higgs boson couplings at high energy scales and search for signs of physics beyond the standard model. In these proceedings, we present recent results on boosted Higgs boson searches at the CMS experiment, highlighting innovative reconstruction and tagging techniques that enhance sensitivity in this challenging regime.",
      "authors": [
        "Farouk Mokhtar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Experiment (hep-ex)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:18:51+00:00",
          "link": "https://arxiv.org/abs/2507.11977v1",
          "size": "637kb",
          "version": "v1"
        }
      ],
      "title": "Recent results on searches with boosted Higgs bosons at CMS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11977",
        "HTML": "https://arxiv.org/html/2507.11977v1",
        "PDF": "https://arxiv.org/pdf/2507.11977"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper relates to high-energy physics and boosted Higgs boson searches, which are not connected to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12005",
      "abstract": "For a fixed graph $H$, in the List $H$-Coloring problem, we are given a graph $G$ along with list $L(v) \\subseteq V(H)$ for every $v \\in V(G)$, and we have to determine if there exists a list homomorphism $\\varphi$ from $(G,L)$ to $H$, i.e., an edge preserving mapping $\\varphi: V(G)\\to V(H)$ that satisfies $\\varphi(v)\\in L(v)$ for every $v\\in V(G)$. Note that if $H$ is the complete graph on $q$ vertices, the problem is equivalent to List $q$-Coloring. We investigate the kernelization properties of List $H$-Coloring parameterized by the vertex cover number of $G$: given an instance $(G,L)$ and a vertex cover of $G$ of size $k$, can we reduce $(G,L)$ to an equivalent instance $(G',L')$ of List $H$-Coloring where the size of $G'$ is bounded by a low-degree polynomial $p(k)$ in $k$? This question has been investigated previously by Jansen and Pieterse [Algorithmica 2019], who provided an upper bound, which turns out to be optimal if $H$ is a complete graph, i.e., for List $q$-Coloring. This result was one of the first applications of the method of kernelization via bounded-degree polynomials. We define two new integral graph invariants, $c^*(H)$ and $d^*(H)$, with $d^*(H) \\leq c^*(H) \\leq d^*(H)+1$, and show that for every graph $H$, List $H$-Coloring\n  -- has a kernel with $\\mathcal{O}(k^{c^*(H)})$ vertices,\n  -- admits no kernel of size $\\mathcal{O}(k^{d^*(H)-\\varepsilon})$ for any $\\varepsilon > 0$, unless the polynomial hierarchy collapses.\n  -- Furthermore, if $c^*(H) > d^*(H)$, then there is a kernel with $\\mathcal{O}(k^{c^*(H)-\\varepsilon})$ vertices where $\\varepsilon \\geq 2^{1-c^*(H)}$.\n  Additionally, we show that for some classes of graphs, including powers of cycles and graphs $H$ where $\\Delta(H) \\leq c^*(H)$ (which in particular includes cliques), the bound $d^*(H)$ is tight, using the polynomial method. We conjecture that this holds in general.",
      "authors": [
        "Marta Piecyk",
        "Astrid Pieterse",
        "Pawe{\\l} Rz\\k{a}\\.zewski",
        "Magnus Wahlstr\\\"om"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:59:20+00:00",
          "link": "https://arxiv.org/abs/2507.12005v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "Kernelization for list $H$-coloring for graphs with small vertex cover",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12005",
        "HTML": "https://arxiv.org/html/2507.12005v1",
        "PDF": "https://arxiv.org/pdf/2507.12005"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper centers on graph coloring and kernelization techniques in a computational graph theory context, with no mention or applicability to reinforcement learning data processing. It is unrelated to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12021",
      "abstract": "Archetypal Analysis (AA) is an unsupervised learning method that represents data as convex combinations of extreme patterns called archetypes. While AA provides interpretable and low-dimensional representations, it can inadvertently encode sensitive attributes, leading to fairness concerns. In this work, we propose Fair Archetypal Analysis (FairAA), a modified formulation that explicitly reduces the influence of sensitive group information in the learned projections. We also introduce FairKernelAA, a nonlinear extension that addresses fairness in more complex data distributions. Our approach incorporates a fairness regularization term while preserving the structure and interpretability of the archetypes. We evaluate FairAA and FairKernelAA on synthetic datasets, including linear, nonlinear, and multi-group scenarios, demonstrating their ability to reduce group separability -- as measured by mean maximum discrepancy and linear separability -- without substantially compromising explained variance. We further validate our methods on the real-world ANSUR I dataset, confirming their robustness and practical utility. The results show that FairAA achieves a favorable trade-off between utility and fairness, making it a promising tool for responsible representation learning in sensitive applications.",
      "authors": [
        "Aleix Alcacer and Irene Epifanio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:28:01+00:00",
          "link": "https://arxiv.org/abs/2507.12021v1",
          "size": "403kb",
          "version": "v1"
        }
      ],
      "title": "Incorporating Fairness Constraints into Archetypal Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12021",
        "HTML": "https://arxiv.org/html/2507.12021v1",
        "PDF": "https://arxiv.org/pdf/2507.12021"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a fairness-aware extension to archetypal analysis, which is an unsupervised learning technique unrelated to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12040",
      "abstract": "In this paper, we study a class of convex composite optimization problems. We begin by characterizing the equivalence between the primal/dual strong second-order sufficient condition and the dual/primal nondegeneracy condition. Building on this foundation, we derive a specific set of equivalent conditions for the perturbation analysis of the problem. Furthermore, we employ the augmented Lagrangian method (ALM) to solve the problem and provide theoretical guarantees for its performance. Specifically, we establish the equivalence between the primal/dual second-order sufficient condition and the dual/primal strict Robinson constraint qualification, as well as the equivalence between the dual nondegeneracy condition and the nonsingularity of Clarke's generalized Jacobian for the ALM subproblem. These theoretical results form a solid foundation for designing efficient algorithms. Finally, we apply the ALM to the von Neumann entropy optimization problem and present numerical experiments to demonstrate the algorithm's effectiveness.",
      "authors": [
        "Chengjing Wang",
        "Peipei Tang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:58:05+00:00",
          "link": "https://arxiv.org/abs/2507.12040v1",
          "size": "91kb",
          "version": "v1"
        }
      ],
      "title": "An augmented Lagrangian method for strongly regular minimizers in a class of convex composite optimization problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12040",
        "HTML": "https://arxiv.org/html/2507.12040v1",
        "PDF": "https://arxiv.org/pdf/2507.12040"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on convex composite optimization problems and the augmented Lagrangian method, with no mention of reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12077",
      "abstract": "We prove that every finite poset has a directed cut with at least one half of the poset's pairwise order relations. The bound is tight. Also, the largest directed cut in a poset can be found in linear time.",
      "authors": [
        "Nati Linial",
        "Ori Shoshani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:38:12+00:00",
          "link": "https://arxiv.org/abs/2507.12077v1",
          "size": "6kb",
          "version": "v1"
        }
      ],
      "title": "Every Poset has a Large Cut",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12077",
        "HTML": "https://arxiv.org/html/2507.12077v1",
        "PDF": "https://arxiv.org/pdf/2507.12077"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses mathematical properties of posets and does not discuss reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12091",
      "abstract": "In this paper, we present enhanced analysis for sign-based optimization algorithms with momentum updates. Traditional sign-based methods, under the separable smoothness assumption, guarantee a convergence rate of $\\mathcal{O}(T^{-1/4})$, but they either require large batch sizes or assume unimodal symmetric stochastic noise. To address these limitations, we demonstrate that signSGD with momentum can achieve the same convergence rate using constant batch sizes without additional assumptions. Our analysis, under the standard $l_2$-smoothness condition, improves upon the result of the prior momentum-based signSGD method by a factor of $\\mathcal{O}(d^{1/2})$, where $d$ is the problem dimension. Furthermore, we explore sign-based methods with majority vote in distributed settings and show that the proposed momentum-based method yields convergence rates of $\\mathcal{O}\\left( d^{1/2}T^{-1/2} + dn^{-1/2} \\right)$ and $\\mathcal{O}\\left( \\max \\{ d^{1/4}T^{-1/4}, d^{1/10}T^{-1/5} \\} \\right)$, which outperform the previous results of $\\mathcal{O}\\left( dT^{-1/4} + dn^{-1/2} \\right)$ and $\\mathcal{O}\\left( d^{3/8}T^{-1/8} \\right)$, respectively. Numerical experiments further validate the effectiveness of the proposed methods.",
      "authors": [
        "Wei Jiang",
        "Dingzhi Yu",
        "Sifan Yang",
        "Wenhao Yang",
        "Lijun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:54:08+00:00",
          "link": "https://arxiv.org/abs/2507.12091v1",
          "size": "383kb",
          "version": "v1"
        }
      ],
      "title": "Improved Analysis for Sign-based Methods with Momentum Updates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12091",
        "HTML": "https://arxiv.org/html/2507.12091v1",
        "PDF": "https://arxiv.org/pdf/2507.12091"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on optimization methods in machine learning, particularly improvements in sign-based algorithms with momentum updates, rather than any aspect of reinforcement learning or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12100",
      "abstract": "We show that if the ground set of a matroid can be partitioned into $k\\ge 2$ bases, then for any given subset $S$ of the ground set, there is a partition into $k$ bases such that the sizes of the intersections of the bases with $S$ may differ by at most one. This settles the matroid equitability conjecture by Fekete and Szab\\'o (Electron.~J.~Comb.~2011) in the affirmative. We also investigate equitable splittings of two disjoint sets $S_1$ and $S_2$, and show that there is a partition into $k$ bases such that the sizes of the intersections with $S_1$ may differ by at most one and the sizes of the intersections with $S_2$ may differ by at most two; this is the best possible one can hope for arbitrary matroids.\n  We also derive applications of this result into matroid constrained fair division problems. We show that there exists a matroid-constrained fair division that is envy-free up to 1 item if the valuations are identical and tri-valued additive. We also show that for bi-valued additive valuations, there exists a matroid-constrained allocation that provides everyone their maximin share.",
      "authors": [
        "Hannaneh Akrami",
        "Roshan Raj",
        "L\\'aszl\\'o A. V\\'egh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:09:09+00:00",
          "link": "https://arxiv.org/abs/2507.12100v1",
          "size": "533kb",
          "version": "v1"
        }
      ],
      "title": "Matroids are Equitable",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12100",
        "PDF": "https://arxiv.org/pdf/2507.12100"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The content revolves around matroid theory and equitable partitions, lacking any mention of reinforcement learning or data processing within the RL sphere."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12117",
      "abstract": "Quantum machine learning (QML) seeks to exploit the intrinsic properties of quantum mechanical systems, including superposition, coherence, and quantum entanglement for classical data processing. However, due to the exponential growth of the Hilbert space, QML faces practical limits in classical simulations with the state-vector representation of quantum system. On the other hand, phase-space methods offer an alternative by encoding quantum states as quasi-probability functions. Building on prior work in qubit phase-space and the Stratonovich-Weyl (SW) correspondence, we construct a closed, composable dynamical formalism for one- and many-qubit systems in phase-space. This formalism replaces the operator algebra of the Pauli group with function dynamics on symplectic manifolds, and recasts the curse of dimensionality in terms of harmonic support on a domain that scales linearly with the number of qubits. It opens a new route for QML based on variational modelling over phase-space.",
      "authors": [
        "Timothy Heightman",
        "Edward Jiang",
        "Ruth Mora-Soto",
        "Maciej Lewenstein",
        "Marcin P{\\l}odzie\\'n"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:37:16+00:00",
          "link": "https://arxiv.org/abs/2507.12117v1",
          "size": "1021kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12117",
        "HTML": "https://arxiv.org/html/2507.12117v1",
        "PDF": "https://arxiv.org/pdf/2507.12117"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores quantum machine learning in qubit phase-space and does not involve reinforcement learning or any data processing techniques related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12122",
      "abstract": "Recent advances in spatially selective active noise control (SSANC) using multiple microphones have enabled hearables to suppress undesired noise while preserving desired speech from a specific direction. Aiming to achieve minimal speech distortion, a hard constraint has been used in previous work in the optimization problem to compute the control filter. In this work, we propose a soft-constrained SSANC system that uses a frequency-independent parameter to trade off between speech distortion and noise reduction. We derive both time- and frequency-domain formulations, and show that conventional active noise control and hard-constrained SSANC represent two limiting cases of the proposed design. We evaluate the system through simulations using a pair of open-fitting hearables in an anechoic environment with one speech source and two noise sources. The simulation results validate the theoretical derivations and demonstrate that for a broad range of the trade-off parameter, the signal-to-noise ratio and the speech quality and intelligibility in terms of PESQ and ESTOI can be substantially improved compared to the hard-constrained design.",
      "authors": [
        "Tong Xiao",
        "Reinhild Roden",
        "Matthias Blau",
        "Simon Doclo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:47:05+00:00",
          "link": "https://arxiv.org/abs/2507.12122v1",
          "size": "2225kb",
          "version": "v1"
        }
      ],
      "title": "Soft-Constrained Spatially Selective Active Noise Control for Open-fitting Hearables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12122",
        "PDF": "https://arxiv.org/pdf/2507.12122"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses active noise control in hearables and does not address reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12132",
      "abstract": "Wi-Fi Channel State Information (CSI) has gained increasing interest for remote sensing applications. Recent studies show that Doppler velocity projections extracted from CSI can enable human activity recognition (HAR) that is robust to environmental changes and generalizes to new users. However, despite these advances, generalizability still remains insufficient for practical deployment. Inspired by neural radiance fields (NeRF), which learn a volumetric representation of a 3D scene from 2D images, this work proposes a novel approach to reconstruct an informative 3D latent motion representation from one-dimensional Doppler velocity projections extracted from Wi-Fi CSI. The resulting latent representation is then used to construct a uniform Doppler radiance field (DoRF) of the motion, providing a comprehensive view of the performed activity and improving the robustness to environmental variability. The results show that the proposed approach noticeably enhances the generalization accuracy of Wi-Fi-based HAR, highlighting the strong potential of DoRFs for practical sensing applications.",
      "authors": [
        "Navid Hasanzadeh and Shahrokh Valaee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:00:46+00:00",
          "link": "https://arxiv.org/abs/2507.12132v1",
          "size": "458kb",
          "version": "v1"
        }
      ],
      "title": "DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12132",
        "HTML": "https://arxiv.org/html/2507.12132v1",
        "PDF": "https://arxiv.org/pdf/2507.12132"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on using Wi-Fi CSI for human activity recognition, drawing parallels with neural radiance fields for improved generalization. It does not pertain to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12146",
      "abstract": "In MIMO systems, the presence of phase noise is a significant factor that can degrade performance. For MIMO testbeds build from SDR devices, phase noise cannot be ignored, particular in applications that require phase synchronization. This is especially relevant in MIMO systems that employ digital beamforming, where precise phase alignment is crucial. Accordingly, accurate phase noise modelling of SDR devices is essential. However, the information provided in data sheets for different SDR models varies widely and is often insufficient for comprehensive characterization of their phase noise performance. While numerical simulations of PLL phase noise behavior are documented in the literature, there is a lack of extensive measurements supported by appropriate system modelling. In this work, we present a practical phase noise modeling methodology applied to an SDR from the USRP X310 series. Based on measurement data, we derive estimates of key PLL performance indicators such as cycle-to-cycle jitter, oscillator constants, and PLL bandwidth. Furthermore, we propose a parametric model for the phase noise PSD of the PLL circuit and provide corresponding parameter estimates. This model can be used for further investigation into the impact of phase noise on MIMO system performance implemented by similar SDR devices.",
      "authors": [
        "Carl Collmann",
        "Bitan Banerjee",
        "Ahmad Nimr",
        "Gerhard Fettweis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:26:11+00:00",
          "link": "https://arxiv.org/abs/2507.12146v1",
          "size": "3017kb",
          "version": "v1"
        }
      ],
      "title": "A Practical Analysis: Understanding Phase Noise Modelling in Time and Frequency Domain for Phase-Locked Loops",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12146",
        "HTML": "https://arxiv.org/html/2507.12146v1",
        "PDF": "https://arxiv.org/pdf/2507.12146"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study deals with phase noise modeling in MIMO systems, with no mention of reinforcement learning or related data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12189",
      "abstract": "We introduce BenchRL-QAS, a unified benchmarking framework for systematically evaluating reinforcement learning (RL) algorithms in quantum architecture search (QAS) across diverse variational quantum algorithm tasks and system sizes ranging from 2- to 8-qubit. Our study benchmarks nine RL agents including both value-based and policy-gradient methods on representative quantum problems such as variational quantum eigensolver, variational quantum state diagonalization, quantum classification, and state preparation, spanning both noiseless and realistic noisy regimes. We propose a weighted ranking metric that balances accuracy, circuit depth, gate count, and computational efficiency, enabling fair and comprehensive comparison. Our results first reveal that RL-based quantum classifier outperforms baseline variational classifiers. Then we conclude that no single RL algorithm is universally optimal when considering a set of QAS tasks; algorithmic performance is highly context-dependent, varying with task structure, qubit count, and noise. This empirical finding provides strong evidence for the \"no free lunch\" principle in RL-based quantum circuit design and highlights the necessity of tailored algorithm selection and systematic benchmarking for advancing quantum circuit synthesis. This work represents the most comprehensive RL-QAS benchmarking effort to date, and BenchRL-QAS along with all experimental data are made publicly available to support reproducibility and future research https://github.com/azhar-ikhtiarudin/bench-rlqas.",
      "authors": [
        "Azhar Ikhtiarudin",
        "Aditi Das",
        "Param Thakkar",
        "Akash Kundu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:43:25+00:00",
          "link": "https://arxiv.org/abs/2507.12189v1",
          "size": "364kb",
          "version": "v1"
        }
      ],
      "title": "BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12189",
        "PDF": "https://arxiv.org/pdf/2507.12189"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper focuses on a benchmarking framework, BenchRL-QAS, for RL algorithms in quantum architecture search, making all experimental data publicly available. This directly involves processing and curating datasets for evaluating RL algorithms, thereby making a significant technical contribution to data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12256",
      "abstract": "Direct numerical simulation of turbulent flows at high Reynolds numbers remains a major challenge for traditional computational fluid dynamics (CFD) tools running on classical computer hardware. This has motivated growing interest in quantum algorithms for CFD to enable flow simulations on quantum computers. The reason being that these computers are expected to deliver potential speed-ups for certain problems. One promising quantum CFD approach is a fully quantum implementation of the lattice Boltzmann method called QLBM. Although efficient quantum routines are now available for the streaming step, implementing the nonlinear, irreversible collision step with a low depth circuit that avoids additional ancilla qubits, probabilistic post-selection and repeated executions remains a significant challenge. In this study, we address this challenge by introducing a framework for learning a surrogate quantum circuit (SQC) that approximates the full Bhatnagar Gross Krook (BGK) collision operator for the D2Q9 lattice. The four qubit circuit is trained to respect the physical properties of the BGK collision operator, including mass and momentum conservation, D8 equivariance and scale equivariance. When compiled to the gate set used by IBM Heron processor under the assumption of full qubit connectivity, the 15 block SQC requires only 2,430 native gates and uses neither ancilla qubits nor post-selection or repeated executions. Moreover, its depth is independent of the grid resolution, as collision is a local operation that can exploit quantum parallelism to its full extent. We validate the SQC on two benchmark flows, the Taylor Green vortex decay and the lid driven cavity, demonstrating that it accurately captures vortex dissipation and flow recirculation.",
      "authors": [
        "Monica L\\u{a}c\\u{a}tu\\c{s}",
        "Matthias M\\\"oller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:02:01+00:00",
          "link": "https://arxiv.org/abs/2507.12256v1",
          "size": "7175kb",
          "version": "v1"
        }
      ],
      "title": "Surrogate Quantum Circuit Design for the Lattice Boltzmann Collision Operator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12256",
        "HTML": "https://arxiv.org/html/2507.12256v1",
        "PDF": "https://arxiv.org/pdf/2507.12256"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a quantum computing approach to computational fluid dynamics, specifically the lattice Boltzmann method, with no mention of reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12299",
      "abstract": "Optimizing multimode waveguide performance depends on modal analysis; however, current approaches focus predominantly on modal power distribution and, limited by experimental hardware and conditions, exhibit low accuracy, poor adaptability, and high computational cost. In this work, under a power-normalization constraint, we employ the AdaMax optimizer with a large-step-size strategy to perform modal analysis of multimode waveguides from far-field amplitude measurements. Our method retrieves both the modal power distribution and the modal relative-phase distribution, and we elucidate how twin-image ambiguity limits the capability to analyze modal relative-phase distributions. Experimental results demonstrate that the proposed method performs well for both rectangular and circular waveguides, maintaining high accuracy and robustness under noise with signal-to-noise ratios (SNRs) ranging from 20 to 120 dB, and achieving substantial improvements in accuracy and computational cost over comparable methods. This method provides a novel solution for modal analysis with broad application potential.",
      "authors": [
        "Jingtong Li",
        "Dongting Huang",
        "Minhui Xiong",
        "Mingzhi Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Sound (cs.SD)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:56:03+00:00",
          "link": "https://arxiv.org/abs/2507.12299v1",
          "size": "10688kb",
          "version": "v1"
        }
      ],
      "title": "Modal Analysis of Multimode Waveguides Based on Large Step Size AdaMax from Far-Field Amplitudes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12299",
        "HTML": "https://arxiv.org/html/2507.12299v1",
        "PDF": "https://arxiv.org/pdf/2507.12299"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study discusses a method for modal analysis of multimode waveguides, focusing on optimizing computational techniques rather than reinforcement learning or data processing within RL frameworks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12301",
      "abstract": "Deep learning-based implicit channel state information (CSI) feedback has been introduced to enhance spectral efficiency in massive MIMO systems. Existing methods often show performance degradation in ultra-low-rate scenarios and inadaptability across diverse environments. In this paper, we propose Dual-ImRUNet, an efficient uplink-assisted deep implicit CSI feedback framework incorporating two novel plug-in preprocessing modules to achieve ultra-low feedback rates while maintaining high environmental robustness. First, a novel bi-directional correlation enhancement module is proposed to strengthen the correlation between uplink and downlink CSI eigenvector matrices. This module projects highly correlated uplink and downlink channel matrices into their respective eigenspaces, effectively reducing redundancy for ultra-low-rate feedback. Second, an innovative input format alignment module is designed to maintain consistent data distributions at both encoder and decoder sides without extra transmission overhead, thereby enhancing robustness against environmental variations. Finally, we develop an efficient transformer-based implicit CSI feedback network to exploit angular-delay domain sparsity and bi-directional correlation for ultra-low-rate CSI compression. Simulation results demonstrate successful reduction of the feedback overhead by 85% compared with the state-of-the-art method and robustness against unseen environments.",
      "authors": [
        "Zhenyu Liu",
        "Yi Ma",
        "Rahim Tafazolli",
        "Zhi Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:00:39+00:00",
          "link": "https://arxiv.org/abs/2507.12301v1",
          "size": "620kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Bi-Directional Channel Reciprocity for Robust Ultra-Low-Rate Implicit CSI Feedback with Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12301",
        "HTML": "https://arxiv.org/html/2507.12301v1",
        "PDF": "https://arxiv.org/pdf/2507.12301"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a deep learning-based CSI feedback framework for massive MIMO systems, which does not pertain to reinforcement learning or data processing within the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12306",
      "abstract": "We present Mass-Conserving Evolution (MaCE), a general method for implementing mass conservation in Cellular Automata (CA). MaCE is a simple evolution rule that can be easily 'attached' to existing CAs to make them mass-conserving, which tends to produce interesting behaviours more often, as patterns can no longer explode or die out. We first show that MaCE is numerically stable and admits a simple continuous limit. We then test MaCE on Lenia, and through several experiments, we demonstrate that it produces a wide variety of interesting behaviours, starting from the variety and abundance of solitons up to hints of intrinsic evolution in resource-constrained environments. Finally, we showcase the versatility of MaCE by applying it to Neural-CAs and discrete CAs, and discuss promising research directions opened up by this scheme.",
      "authors": [
        "Vassilis Papadopoulos and Etienne Guichard"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cellular Automata and Lattice Gases (nlin.CG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Adaptation and Self-Organizing Systems (nlin.AO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:04:52+00:00",
          "link": "https://arxiv.org/abs/2507.12306v1",
          "size": "11052kb",
          "version": "v1"
        }
      ],
      "title": "MaCE: General Mass Conserving Dynamics for Cellular Automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12306",
        "HTML": "https://arxiv.org/html/2507.12306v1",
        "PDF": "https://arxiv.org/pdf/2507.12306"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses Mass-Conserving Evolution (MaCE) for Cellular Automata, which is not related to reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12404",
      "abstract": "Understanding and predicting the activity of oxide perovskite catalysts for the oxygen evolution reaction (OER) requires descriptors that are both accurate and physically interpretable. While symbolic regression (SR) offers a path to discover such formulas, its performance degrades with high-dimensional inputs and small datasets. We present a two-phase framework that combines neural networks (NN), feature importance analysis, and symbolic regression (SR) to discover interpretable descriptors for OER activity in oxide perovskites. In Phase I, using a small dataset and seven structural features, we reproduce and improve the known {\\mu}/t descriptor by engineering composite features and applying symbolic regression, achieving training and validation MAEs of 22.8 and 20.8 meV, respectively. In Phase II, we expand to 164 features, reduce dimensionality, and identify LUMO energy as a key electronic descriptor. A final formula using {\\mu}/t, {\\mu}/RA, and LUMO energy achieves improved accuracy (training and validation MAEs of 22.1 and 20.6 meV) with strong physical interpretability. Our results demonstrate that NN-guided symbolic regression enables accurate, interpretable, and physically meaningful descriptor discovery in data-scarce regimes, indicating interpretability need not sacrifice accuracy for materials informatics.",
      "authors": [
        "Yeming Xian",
        "Xiaoming Wang",
        "Yanfa Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:47:38+00:00",
          "link": "https://arxiv.org/abs/2507.12404v1",
          "size": "1999kb",
          "version": "v1"
        }
      ],
      "title": "Neural Network-Guided Symbolic Regression for Interpretable Descriptor Discovery in Perovskite Catalysts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12404",
        "PDF": "https://arxiv.org/pdf/2507.12404"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses symbolic regression for discovering descriptors in perovskite catalysts, focusing on materials informatics rather than reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12408",
      "abstract": "Non-local games are a powerful tool to distinguish between correlations possible in classical and quantum worlds. Kalai et al. (STOC'23) proposed a compiler that converts multipartite non-local games into interactive protocols with a single prover, relying on cryptographic tools to remove the assumption of physical separation of the players. While quantum completeness and classical soundness of the construction have been established for all multipartite games, quantum soundness is known only in the special case of bipartite games.\n  In this paper, we prove that the Kalai et al.'s compiler indeed achieves quantum soundness for all multipartite compiled non-local games, by showing that any correlations that can be generated in the asymptotic case correspond to quantum commuting strategies.\n  Our proof uses techniques from the theory of operator algebras, and relies on a characterisation of sequential operationally no-signalling strategies as quantum commuting operator strategies in the multipartite case, thereby generalising several previous results. On the way, we construct universal C*-algebras of sequential PVMs and prove a new chain rule for Radon-Nikodym derivatives of completely positive maps on C*-algebras which may be of independent interest.",
      "authors": [
        "Matilde Baroni",
        "Dominik Leichtle",
        "Sini\\v{s}a Jankovi\\'c",
        "Ivan \\v{S}upi\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:58:39+00:00",
          "link": "https://arxiv.org/abs/2507.12408v1",
          "size": "63kb",
          "version": "v1"
        }
      ],
      "title": "Bounding the asymptotic quantum value of all multipartite compiled non-local games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12408",
        "HTML": "https://arxiv.org/html/2507.12408v1",
        "PDF": "https://arxiv.org/pdf/2507.12408"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with quantum soundness in non-local games and does not pertain to reinforcement learning or any specific data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12411",
      "abstract": "We study the feedback stabilization of the McKean-Vlasov PDE on the torus. Our goal is to steer the dynamics toward a prescribed stationary distribution or accelerate convergence to it using a time-dependent control potential. We reformulate the controlled PDE in a weighted-projected space and apply the ground-state transform to obtain a Schrodinger-type operator. The resulting operator framework enables spectral analysis, verification of the infinite-dimensional Hautus test, and the construction of Riccati-based feedback laws. We rigorously prove local exponential stabilization via maximal regularity arguments and nonlinear estimates. Numerical experiments on well-studied models (the noisy Kuramoto model for synchronization, the O(2) spin model in a magnetic field, and the Gaussian/von Mises attractive interaction potential) showcase the effectiveness of our control strategy, demonstrating convergence speed-ups and stabilization of otherwise unstable equilibria.",
      "authors": [
        "Dante Kalise",
        "Lucas M. Moschen",
        "Grigorios A. Pavliotis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:59:49+00:00",
          "link": "https://arxiv.org/abs/2507.12411v1",
          "size": "1705kb",
          "version": "v1"
        }
      ],
      "title": "Linearization-Based Feedback Stabilization of McKean-Vlasov PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12411",
        "HTML": "https://arxiv.org/html/2507.12411v1",
        "PDF": "https://arxiv.org/pdf/2507.12411"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with feedback stabilization of PDEs and does not address topics related to reinforcement learning or data processing within an RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12417",
      "abstract": "Humans possess a remarkable capacity for spatial cognition, allowing for self-localization even in novel or unfamiliar environments. While hippocampal neurons encoding position and orientation are well documented, the large-scale neural dynamics supporting spatial representation, particularly during naturalistic, passive experience, remain poorly understood. Here, we demonstrate for the first time that non-invasive brain-computer interfaces (BCIs) based on electroencephalography (EEG) can decode spontaneous, fine-grained egocentric 6D pose, comprising three-dimensional position and orientation, during passive viewing of egocentric video. Despite EEG's limited spatial resolution and high signal noise, we find that spatially coherent visual input (i.e., continuous and structured motion) reliably evokes decodable spatial representations, aligning with participants' subjective sense of spatial engagement. Decoding performance further improves when visual input is presented at a frame rate of 100 ms per image, suggesting alignment with intrinsic neural temporal dynamics. Using gradient-based backpropagation through a neural decoding model, we identify distinct EEG channels contributing to position -- and orientation specific -- components, revealing a distributed yet complementary neural encoding scheme. These findings indicate that the brain's spatial systems operate spontaneously and continuously, even under passive conditions, challenging traditional distinctions between active and passive spatial cognition. Our results offer a non-invasive window into the automatic construction of egocentric spatial maps and advance our understanding of how the human mind transforms everyday sensory experience into structured internal representations.",
      "authors": [
        "Weichen Dai",
        "Yuxuan Huang",
        "Li Zhu",
        "Dongjun Liu",
        "Yu Zhang",
        "Qibin Zhao",
        "Andrzej Cichocki",
        "Fabio Babiloni",
        "Ke Li",
        "Jianyu Qiu",
        "Gangyong Jia",
        "Wanzeng Kong",
        "Qing Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:07:57+00:00",
          "link": "https://arxiv.org/abs/2507.12417v1",
          "size": "15862kb",
          "version": "v1"
        }
      ],
      "title": "Spontaneous Spatial Cognition Emerges during Egocentric Video Viewing through Non-invasive BCI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12417",
        "HTML": "https://arxiv.org/html/2507.12417v1",
        "PDF": "https://arxiv.org/pdf/2507.12417"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study discusses spatial cognition and neural decoding using BCIs, focusing on EEG data interpretation rather than reinforcement learning or related data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12427",
      "abstract": "We propose UTS, a unit-based tissue segmentation framework for histopathology that classifies each fixed-size 32 * 32 tile, rather than each pixel, as the segmentation unit. This approach reduces annotation effort and improves computational efficiency without compromising accuracy. To implement this approach, we introduce a Multi-Level Vision Transformer (L-ViT), which benefits the multi-level feature representation to capture both fine-grained morphology and global tissue context. Trained to segment breast tissue into three categories (infiltrating tumor, non-neoplastic stroma, and fat), UTS supports clinically relevant tasks such as tumor-stroma quantification and surgical margin assessment. Evaluated on 386,371 tiles from 459 H&E-stained regions, it outperforms U-Net variants and transformer-based baselines. Code and Dataset will be available at GitHub.",
      "authors": [
        "Ashkan Shakarami",
        "Azade Farshad",
        "Yousef Yeganeh",
        "Lorenzo Nicole",
        "Peter Schuffler",
        "Stefano Ghidoni",
        "Nassir Navab"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:15:18+00:00",
          "link": "https://arxiv.org/abs/2507.12427v1",
          "size": "2766kb",
          "version": "v1"
        }
      ],
      "title": "Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12427",
        "HTML": "https://arxiv.org/html/2507.12427v1",
        "PDF": "https://arxiv.org/pdf/2507.12427"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Here, the focus is on tissue segmentation using histopathology images with no mention of reinforcement learning or data processing relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12452",
      "abstract": "Energy-efficient high-bandwidth interconnects play a key role in computing systems. Advances in silicon photonic electro-optic modulators and wavelength selective components have enabled the utilization of wavelength-division-multiplexing (WDM) in integrated optical transceivers, offering a high data-rate operation while achieving enhanced energy efficiency, bandwidth density, scalability, and the reach required for data-centers. Here, we report the demonstration of a single chip optical WDM PAM4 receiver, where by co-integration of a 32-channel optical demultiplexer (O-DeMux) with autonomous wavelength tuning and locking at a near-zero power consumption and a 32-channel ultra-low power concurrent electrical detection system, a record chip energy efficiency of under 0.38 pJ/bit is measured. The implemented 32 channel monolithic WDM optical receiver chip achieves an end-to-end latency of under 100 ps and a bit-error-rate of less than 10-12 with no equalization, pre-distortion, or digital-signal-processing, while operating at 1.024 Tb/s aggregate data-rate on a single input fiber, the largest reported data-rate for a WDM PAM4 receiver chip to date. The receiver bandwidth density of more than 3.55 Tb/s/mm2 corresponds to more than an order-of-magnitude larger bandwidth density-energy efficiency product compared to the state-of-the-art optical PAM4 receivers for beyond 100Gb/s links. The chip, integrated using GlobalFoundries 45CLO CMOS-photonic process, can be used for implementation of energy-efficient high data-rate optical links for AI applications.",
      "authors": [
        "Ali Pirmoradi",
        "Han Hao",
        "Kaisarbek Omirzakhov",
        "Alexander J. Geers and Firooz Aflatouni"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:52:14+00:00",
          "link": "https://arxiv.org/abs/2507.12452v1",
          "size": "2530kb",
          "version": "v1"
        }
      ],
      "title": "A single chip 1.024 Tb/s silicon photonics PAM4 receiver",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12452",
        "PDF": "https://arxiv.org/pdf/2507.12452"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work is about a silicon photonics receiver for high-bandwidth interconnects and does not involve reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2111.09290",
      "abstract": "We show how to round any half-integral solution to the subtour-elimination relaxation for the TSP, while losing a less-than-1.5 factor. Such a rounding algorithm was recently given by Karlin, Klein, and Oveis Gharan based on sampling from max-entropy distributions. We build on an approach of Haddadan and Newman to show how sampling from the matroid intersection polytope, and a new use of max-entropy sampling, can give better guarantees.",
      "authors": [
        "Anupam Gupta",
        "Euiwoong Lee",
        "Jason Li",
        "Marcin Mucha",
        "Heather Newman",
        "Sherry Sarkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-17T18:42:54+00:00",
          "link": "https://arxiv.org/abs/2111.09290v1",
          "size": "603kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T20:32:52+00:00",
          "link": "https://arxiv.org/abs/2111.09290v2",
          "size": "515kb",
          "version": "v2"
        }
      ],
      "title": "Matroid-Based TSP Rounding for Half-Integral Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.09290",
        "HTML": "https://arxiv.org/html/2111.09290v2",
        "PDF": "https://arxiv.org/pdf/2111.09290"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper covers matroid-based rounding for the Traveling Salesman Problem and does not involve reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2212.14494",
      "abstract": "We introduce monoidal streams. Monoidal streams are a generalization of causal stream functions, which can be defined in cartesian monoidal categories, to arbitrary symmetric monoidal categories. In the same way that streams provide semantics to dataflow programming with pure functions, monoidal streams provide semantics to dataflow programming with theories of processes represented by a symmetric monoidal category. Monoidal streams also form a feedback monoidal category. In the same way that we can use a coinductive stream calculus to reason about signal flow graphs, we can use coinductive string diagrams to reason about feedback monoidal categories. As an example, we study syntax for a stochastic dataflow language, with semantics in stochastic monoidal streams.",
      "authors": [
        "Elena Di Lavore",
        "Giovanni de Felice",
        "Mario Rom\\'an"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-30T00:25:12+00:00",
          "link": "https://arxiv.org/abs/2212.14494v1",
          "size": "124kb",
          "version": "v1"
        },
        {
          "date": "2024-05-21T21:10:58+00:00",
          "link": "https://arxiv.org/abs/2212.14494v2",
          "size": "129kb",
          "version": "v2"
        },
        {
          "date": "2025-04-18T11:42:55+00:00",
          "link": "https://arxiv.org/abs/2212.14494v3",
          "size": "128kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T14:43:30+00:00",
          "link": "https://arxiv.org/abs/2212.14494v4",
          "size": "126kb",
          "version": "v4"
        }
      ],
      "title": "Coinductive Streams in Monoidal Categories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.14494",
        "PDF": "https://arxiv.org/pdf/2212.14494"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses monoidal streams and coinductive streams in the context of dataflow programming with symmetric monoidal categories and does not relate to reinforcement learning or data processing within RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.00646",
      "abstract": "We introduce EPIC-SOUNDS, a large-scale dataset of audio annotations capturing temporal extents and class labels within the audio stream of the egocentric videos. We propose an annotation pipeline where annotators temporally label distinguishable audio segments and describe the action that could have caused this sound. We identify actions that can be discriminated purely from audio, through grouping these free-form descriptions of audio into classes. For actions that involve objects colliding, we collect human annotations of the materials of these objects (e.g. a glass object being placed on a wooden surface), which we verify from video, discarding ambiguities. Overall, EPIC-SOUNDS includes 78.4k categorised segments of audible events and actions, distributed across 44 classes as well as 39.2k non-categorised segments. We train and evaluate state-of-the-art audio recognition and detection models on our dataset, for both audio-only and audio-visual methods. We also conduct analysis on: the temporal overlap between audio events, the temporal and label correlations between audio and visual modalities, the ambiguities in annotating materials from audio-only input, the importance of audio-only labels and the limitations of current models to understand actions that sound.",
      "authors": [
        "Jaesung Huh",
        "Jacob Chalk",
        "Evangelos Kazakos",
        "Dima Damen",
        "Andrew Zisserman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-01T18:19:37+00:00",
          "link": "https://arxiv.org/abs/2302.00646v1",
          "size": "6817kb",
          "version": "v1"
        },
        {
          "date": "2024-09-28T13:35:40+00:00",
          "link": "https://arxiv.org/abs/2302.00646v2",
          "size": "13165kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T04:37:59+00:00",
          "link": "https://arxiv.org/abs/2302.00646v3",
          "size": "13239kb",
          "version": "v3"
        }
      ],
      "title": "Epic-Sounds: A Large-scale Dataset of Actions That Sound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.00646",
        "HTML": "https://arxiv.org/html/2302.00646v3",
        "PDF": "https://arxiv.org/pdf/2302.00646"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces the EPIC-SOUNDS dataset focusing on audio annotations from egocentric videos. It is centered on audio recognition and detection, not reinforcement learning or RL data processing."
      },
      "tasks": [
        "Action Recognition",
        "Sound Classification"
      ],
      "repo_urls": [
        "https://github.com/epic-kitchens/epic-sounds-annotations"
      ],
      "source": "arXiv"
    },
    {
      "id": "2306.04473",
      "abstract": "Many integral equation-based methods are available for problems of time-harmonic electromagnetic scattering from perfect electric conductors. Among the many challenges that arise in such calculations are the avoidance of spurious resonances, robustness of the method to scatterers of non-trivial topology or multiscale features, stability under mesh refinement, ease of implementation with high-order basis functions, and behavior in the static limit. Since three-dimensional scattering is a challenging, large-scale problem, many of these issues have been historically difficult to investigate. It is only with the advent of fast algorithms for matrix-vector multiplies coupled with modern iterative methods that a careful study of these issues can be carried out effectively. Our focus here is on comparing the behavior of several integral equation formulations with regard to the issues noted above, namely: the well-known, standard electric, magnetic, and combined field integral equations with standard RWG basis functions, and the more modern non-resonant charge-current and decoupled potential integral equation. Numerical results are provided to demonstrate the behavior of each of these schemes. Furthermore, we provide some analytical properties and comparisons with the electric charge-current integral equation and the augmented regularized combined source integral equation.",
      "authors": [
        "Felipe Vico and Leslie Greengard and Michael O'Neil and Manas Rachh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-07T14:44:42+00:00",
          "link": "https://arxiv.org/abs/2306.04473v1",
          "size": "2243kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:49:54+00:00",
          "link": "https://arxiv.org/abs/2306.04473v2",
          "size": "2713kb",
          "version": "v2"
        }
      ],
      "title": "Fast adaptive high-order integral equation methods for electromagnetic scattering from smooth perfect electric conductors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.04473",
        "HTML": "https://arxiv.org/html/2306.04473v2",
        "PDF": "https://arxiv.org/pdf/2306.04473"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integral equation methods for electromagnetic scattering, which does not align with reinforcement learning or data processing aspects within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.06974",
      "abstract": "A computational theory for clustering and a semi-supervised clustering algorithm is presented. Clustering is defined to be the obtainment of groupings of data such that each group contains no anomalies with respect to a chosen grouping principle and measure; all other examples are considered to be fringe points, isolated anomalies, anomalous clusters or unknown clusters. More precisely, after appropriate modelling under the assumption of uniform random distribution, any example whose expectation of occurrence is <1 with respect to a group is considered an anomaly; otherwise it is assigned a membership of that group. Thus, clustering is conceived as the dual of anomaly detection. The representation of data is taken to be the Euclidean distance of a point to a cluster median. This is due to the robustness properties of the median to outliers, its approximate location of centrality and so that decision boundaries are general purpose. The kernel of the clustering method is the perception anomaly detection algorithm, resulting in a parameter-free, fast, and efficient clustering algorithm. Acknowledging that clustering is an interactive and iterative process, the algorithm relies on a small fraction of known relationships between examples. These relationships serve as seeds to define the user's objectives and guide the clustering process. The method then expands the clusters accordingly, leaving the remaining examples for exploration and subsequent iterations. Results are presented on synthetic and realworld data sets, demonstrating the advantages over the most popular unsupervised and semi-supervised clustering methods.",
      "authors": [
        "Nassir Mohammad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-12T09:15:58+00:00",
          "link": "https://arxiv.org/abs/2306.06974v1",
          "size": "1751kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:53:15+00:00",
          "link": "https://arxiv.org/abs/2306.06974v2",
          "size": "2317kb",
          "version": "v2"
        }
      ],
      "title": "A Computational Theory and Semi-Supervised Algorithm for Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.06974",
        "HTML": "https://arxiv.org/html/2306.06974v2",
        "PDF": "https://arxiv.org/pdf/2306.06974"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a semi-supervised clustering algorithm and computational theory for clustering, without any specific discussion or contribution related to data processing in reinforcement learning."
      },
      "tasks": [
        "Anomaly Detection",
        "Clustering"
      ],
      "repo_urls": [
        "https://github.com/m-nassir/clustering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.10527",
      "abstract": "Annotating 3D LiDAR point clouds for perception tasks is fundamental for many applications e.g., autonomous driving, yet it still remains notoriously labor-intensive. Pretraining-finetuning approach can alleviate the labeling burden by fine-tuning a pre-trained backbone across various downstream datasets as well as tasks. In this paper, we propose SPOT, namely Scalable Pre-training via Occupancy prediction for learning Transferable 3D representations under such a label-efficient fine-tuning paradigm. SPOT achieves effectiveness on various public datasets with different downstream tasks, showcasing its general representation power, cross-domain robustness and data scalability which are three key factors for real-world application. Specifically, we both theoretically and empirically show, for the first time, that general representations learning can be achieved through the task of occupancy prediction. Then, to address the domain gap caused by different LiDAR sensors and annotation methods, we develop a beam re-sampling technique for point cloud augmentation combined with class-balancing strategy. Furthermore, scalable pre-training is observed, that is, the downstream performance across all the experiments gets better with more pre-training data. Additionally, such pre-training strategy also remains compatible with unlabeled data. The hope is that our findings will facilitate the understanding of LiDAR points and pave the way for future advancements in LiDAR pre-training.",
      "authors": [
        "Xiangchao Yan",
        "Runjian Chen",
        "Bo Zhang",
        "Hancheng Ye",
        "Renqiu Xia",
        "Jiakang Yuan",
        "Hongbin Zhou",
        "Xinyu Cai",
        "Botian Shi",
        "Wenqi Shao",
        "Ping Luo",
        "Yu Qiao",
        "Tao Chen",
        "and Junchi Yan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-19T11:13:01+00:00",
          "link": "https://arxiv.org/abs/2309.10527v1",
          "size": "6925kb",
          "version": "v1"
        },
        {
          "date": "2023-09-25T06:41:30+00:00",
          "link": "https://arxiv.org/abs/2309.10527v2",
          "size": "6925kb",
          "version": "v2"
        },
        {
          "date": "2024-07-25T11:26:49+00:00",
          "link": "https://arxiv.org/abs/2309.10527v3",
          "size": "25047kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T08:17:09+00:00",
          "link": "https://arxiv.org/abs/2309.10527v4",
          "size": "8062kb",
          "version": "v4"
        }
      ],
      "title": "SPOT: Scalable 3D Pre-training via Occupancy Prediction for Learning Transferable 3D Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.10527",
        "HTML": "https://arxiv.org/html/2309.10527v4",
        "PDF": "https://arxiv.org/pdf/2309.10527"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for 3D representation learning through pre-training on LiDAR point clouds, but does not involve reinforcement learning or data processing for RL agents."
      },
      "tasks": [
        "3D Object Detection",
        "Autonomous Driving",
        "LIDAR Semantic Segmentation",
        "object-detection",
        "Object Detection",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/pjlab-adg/3dtrans"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.02718",
      "abstract": "Pan-sharpening algorithms utilize a panchromatic image and a multispectral image to generate a high spatial and high spectral image. However, the optimizations of the algorithms are designed with different standards. We employ a simple matrix equation to describe the Pan-sharpening problem. The conditions for the existence of a solution and the acquisition of spectral and spatial resolution are discussed. A down-sampling enhancement method is introduced to improve the estimation of spatial and spectral down-sample matrices.\n  Using generalized inverse theory, we discovered two kinds of solution spaces of generalized inverse matrix formulations, which correspond to the two prominent classes of Pan-sharpening methods: component substitution and multi-resolution analysis. Specifically, the Gram-Schmidt adaptive method is demonstrated to align with the generalized inverse matrix formulation of component substitution. A model prior of the generalized inverse matrix of the spectral function is rendered. Theoretical errors are analyzed. The diffusion prior is naturally embedded with the help of general solution spaces of the generalized inverse form, enabling the acquisition of refined Pan-sharpening results.\n  Extensive experiments, including comparative, synthetic, real-data ablation and diffusion-related tests are conducted. The proposed methods produce qualitatively sharper and superior results in both synthetic and real experiments. The down-sampling enhancement method demonstrates quantitatively and qualitatively better outcomes in real-data experiments. The diffusion prior can significantly improve the performance of our methods across almost all evaluation measures.\n  The generalized inverse matrix theory helps deepen the understanding of Pan-sharpening mechanisms.",
      "authors": [
        "Shiqi Liu",
        "Yihua Tan",
        "Yutong Bai",
        "Alan Yuille"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-04T10:41:21+00:00",
          "link": "https://arxiv.org/abs/2310.02718v1",
          "size": "2537kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T08:52:35+00:00",
          "link": "https://arxiv.org/abs/2310.02718v2",
          "size": "22535kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T02:17:08+00:00",
          "link": "https://arxiv.org/abs/2310.02718v3",
          "size": "22537kb",
          "version": "v3"
        }
      ],
      "title": "Understanding Pan-Sharpening via Generalized Inverse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.02718",
        "HTML": "https://arxiv.org/html/2310.02718v3",
        "PDF": "https://arxiv.org/pdf/2310.02718"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses the pan-sharpening problem using generalized inverses, which is unrelated to reinforcement learning or data processing in that field."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2310.20360",
      "abstract": "This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning.",
      "authors": [
        "Arnulf Jentzen",
        "Benno Kuckuck",
        "Philippe von Wurstemberger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-31T11:01:23+00:00",
          "link": "https://arxiv.org/abs/2310.20360v1",
          "size": "2327kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T21:17:16+00:00",
          "link": "https://arxiv.org/abs/2310.20360v2",
          "size": "2356kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T18:49:51+00:00",
          "link": "https://arxiv.org/abs/2310.20360v3",
          "size": "2379kb",
          "version": "v3"
        }
      ],
      "title": "Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.20360",
        "PDF": "https://arxiv.org/pdf/2310.20360"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mathematical methods and theories related to deep learning, specifically covering artificial neural networks and optimization algorithms. It does not address data processing or reinforcement learning."
      },
      "tasks": [
        "Deep Learning"
      ],
      "repo_urls": [
        "https://github.com/introdeeplearning/book"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.05128",
      "abstract": "This research project investigated the correlation between a 10 Hz time series of thermocouple temperatures and turbulent kinetic energy (TKE) computed from wind speeds collected from a small experimental prescribed burn at the Silas Little Experimental Forest in New Jersey, USA. The primary objective of this project was to explore the potential for using thermocouple temperatures as predictors for estimating the TKE produced by a wildland fire. Machine learning models, including Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and Gaussian Process Regressor, are employed to assess the potential for thermocouple temperature perturbations to predict TKE values. Data visualization and correlation analyses reveal patterns and relationships between thermocouple temperatures and TKE, providing insight into the underlying dynamics. The project achieves high accuracy in predicting TKE by employing various machine learning models despite a weak correlation between the predictors and the target variable. The results demonstrate significant success, particularly from regression models, in accurately estimating the TKE. The research findings contribute to fire behavior and smoke modeling science, emphasizing the importance of incorporating machine learning approaches and identifying complex relationships between fine-scale fire behavior and turbulence. Accurate TKE estimation using thermocouple temperatures allows for the refinement of models that can inform decision-making in fire management strategies, facilitate effective risk mitigation, and optimize fire management efforts. This project highlights the valuable role of machine learning techniques in analyzing wildland fire data, showcasing their potential to advance fire research and management practices.",
      "authors": [
        "Dipak Dulal",
        "Joseph J. Charney",
        "Michael Gallagher",
        "Carmeliza Navasca",
        "and Nicholas Skowronski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-09T03:47:49+00:00",
          "link": "https://arxiv.org/abs/2311.05128v1",
          "size": "7314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:04:34+00:00",
          "link": "https://arxiv.org/abs/2311.05128v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Exploring and Analyzing Wildland Fire Data Via Machine Learning Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.05128",
        "PDF": "https://arxiv.org/pdf/2311.05128"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper employs machine learning models to analyze wildland fire data, primarily to predict turbulent kinetic energy. There is no mention of reinforcement learning or data processing within an RL context."
      },
      "tasks": [
        "Data Visualization",
        "Decision Making",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.05968",
      "abstract": "Consensus amongst researchers and industry points to a lack of large, representative annotated datasets as the biggest obstacle to progress in the field of surgical data science. Advances in Self-Supervised Learning (SSL) represent a solution, reducing the dependence on large labeled datasets by providing task-agnostic initializations. However, the robustness of current self-supervised learning methods to domain shifts remains unclear, limiting our understanding of its utility for leveraging diverse sources of surgical data. Shifting the focus from methods to data, we demonstrate that the downstream value of SSL-based initializations is intricately intertwined with the composition of pre-training datasets. These results underscore an important gap that needs to be filled as we scale self-supervised approaches toward building general-purpose \"foundation models\" that enable diverse use-cases within the surgical domain. Through several stages of controlled experimentation, we develop recommendations for pretraining dataset composition evidenced through over 300 experiments spanning 20 pre-training datasets, 9 surgical procedures, 7 centers (hospitals), 3 labeled-data settings, 3 downstream tasks, and multiple runs. Using the approaches here described, we outperform state-of-the-art pre-trainings on two public benchmarks for phase recognition: up to 2.2% on Cholec80 and 5.1% on AutoLaparo.",
      "authors": [
        "Deepak Alapatt",
        "Aditya Murali",
        "Vinkle Srivastav",
        "Pietro Mascagni",
        "AI4SafeChole Consortium",
        "Nicolas Padoy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-10T18:54:16+00:00",
          "link": "https://arxiv.org/abs/2312.05968v1",
          "size": "7856kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:42:47+00:00",
          "link": "https://arxiv.org/abs/2312.05968v2",
          "size": "460kb",
          "version": "v2"
        }
      ],
      "title": "Jumpstarting Surgical Computer Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.05968",
        "HTML": "https://arxiv.org/html/2312.05968v2",
        "PDF": "https://arxiv.org/pdf/2312.05968"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with self-supervised learning for surgical computer vision and discusses dataset composition for pre-training models. It does not relate to data processing specifically in the context of reinforcement learning."
      },
      "tasks": [
        "Self-Supervised Learning",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.06875",
      "abstract": "Model-based testing (MBT), whereby a model of the system under test is analyzed to generate high-coverage test cases, has been used to test protocol implementations. A key barrier to the use of MBT is the need for users to understand protocol RFCs in detail to create a compliant model. Our new approach to MBT uses LLMs to automatically build rich models of intended protocol behavior from knowledge embedded in RFCs, blogs, and other natural language sources. Our approach addresses key challenges with using LLMs, including hallucinations and their inability to monolithically generate complex protocol models. We realize our approach through a novel protocol testing framework Eywa,and demonstrate its effectiveness through extensive case studies of DNS and BGP and a smaller study of SMTP. Despite minimal user effort, applying Eywa enabled the discovery of 32 unique bugs across widely used DNS, BGP, and SMTP implementations, 15 of which were previously undiscovered despite extensive prior testing with manually crafted models.",
      "authors": [
        "Rajdeep Mondal",
        "Rathin Singha",
        "Todd Millstein",
        "George Varghese",
        "Ryan Beckett",
        "Siva Kesava Reddy Kakarla"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-11T22:51:15+00:00",
          "link": "https://arxiv.org/abs/2312.06875v1",
          "size": "128kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T01:15:36+00:00",
          "link": "https://arxiv.org/abs/2312.06875v2",
          "size": "439kb",
          "version": "v2"
        }
      ],
      "title": "Eywa: Automating Model Based Testing using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.06875",
        "PDF": "https://arxiv.org/pdf/2312.06875"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model-based testing framework using LLMs, focused on automatic model generation from protocol documentation. There is no discussion of reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.07003",
      "abstract": "This paper introduces RACER, the Rational Artificial Intelligence Car-following model Enhanced by Reality, a cutting-edge deep learning car-following model, that satisfies partial derivative constraints, designed to predict Adaptive Cruise Control (ACC) driving behavior while staying theoretically feasible. Unlike conventional models, RACER effectively integrates Rational Driving Constraints (RDCs), crucial tenets of actual driving, resulting in strikingly accurate and realistic predictions. Against established models like the Optimal Velocity Relative Velocity (OVRV), a car-following Neural Network (NN), and a car-following Physics-Informed Neural Network (PINN), RACER excels across key metrics, such as acceleration, velocity, and spacing. Notably, it displays a perfect adherence to the RDCs, registering zero violations, in stark contrast to other models. This study highlights the immense value of incorporating physical constraints within AI models, especially for augmenting safety measures in transportation. It also paves the way for future research to test these models against human driving data, with the potential to guide safer and more rational driving behavior. The versatility of the proposed model, including its potential to incorporate additional derivative constraints and broader architectural applications, enhances its appeal and broadens its impact within the scientific community.",
      "authors": [
        "Tianyi Li",
        "Alexander Halatsis",
        "Raphael Stern"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-12T06:21:30+00:00",
          "link": "https://arxiv.org/abs/2312.07003v1",
          "size": "6665kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:47:03+00:00",
          "link": "https://arxiv.org/abs/2312.07003v2",
          "size": "4793kb",
          "version": "v2"
        }
      ],
      "title": "RACER: Rational Artificial Intelligence Car-following-model Enhanced by Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.07003",
        "HTML": "https://arxiv.org/html/2312.07003v2",
        "PDF": "https://arxiv.org/pdf/2312.07003"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study proposes a deep learning car-following model incorporating physical constraints for adaptive cruise control prediction without referencing reinforcement learning or data processing specific to RL."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2312.12216",
      "abstract": "Data sharing is a necessity for innovative progress in many domains, especially in healthcare. However, the ability to share data is hindered by regulations protecting the privacy of natural persons. Synthetic tabular data provide a promising solution to address data sharing difficulties but does not inherently guarantee privacy. Still, there is a lack of agreement on appropriate methods for assessing the privacy-preserving capabilities of synthetic data, making it difficult to compare results across studies. To the best of our knowledge, this is the first work to identify properties that constitute good universal privacy evaluation metrics for synthetic tabular data. The goal of universally applicable metrics is to enable comparability across studies and to allow non-technical stakeholders to understand how privacy is protected. We identify four principles for the assessment of metrics: Comparability, Applicability, Interpretability, and Representativeness (CAIR). To quantify and rank the degree to which evaluation metrics conform to the CAIR principles, we design a rubric using a scale of 1-4. Each of the four properties is scored on four parameters, yielding 16 total dimensions. We study the applicability and usefulness of the CAIR principles and rubric by assessing a selection of metrics popular in other studies. The results provide granular insights into the strengths and weaknesses of existing metrics that not only rank the metrics but highlight areas of potential improvements. We expect that the CAIR principles will foster agreement among researchers and organizations on which universal privacy evaluation metrics are appropriate for synthetic tabular data.",
      "authors": [
        "Tobias Hyrup",
        "Anton Danholt Lautrup",
        "Arthur Zimek",
        "Peter Schneider-Kamp"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-19T15:05:52+00:00",
          "link": "https://arxiv.org/abs/2312.12216v1",
          "size": "140kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:10:49+00:00",
          "link": "https://arxiv.org/abs/2312.12216v2",
          "size": "869kb",
          "version": "v2"
        }
      ],
      "title": "Sharing is CAIRing: Characterizing Principles and Assessing Properties of Universal Privacy Evaluation for Synthetic Tabular Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.12216",
        "HTML": "https://arxiv.org/html/2312.12216v2",
        "PDF": "https://arxiv.org/pdf/2312.12216"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy evaluation metrics for synthetic tabular data and does not address any aspects related to data processing in reinforcement learning."
      },
      "tasks": [
        "Privacy Preserving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.14628",
      "abstract": "In light of emerging legal requirements and policies focused on privacy protection, there is a growing trend of companies across various industries adopting Federated Learning (FL). This decentralized approach involves multiple clients or silos, collaboratively training a global model under the coordination of a central server while utilizing their private local data. Unlike traditional methods that necessitate data sharing and transmission, Cross-Silo FL allows clients to share model updates rather than raw data, thereby enhancing privacy. Despite its growing adoption, the carbon impact associated with Cross-Silo FL remains poorly understood due to the limited research in this area. This study seeks to bridge this gap by evaluating the sustainability of Cross-Silo FL throughout the entire AI product lifecycle, extending the analysis beyond the model training phase alone. We systematically compare this decentralized method with traditional centralized approaches and present a robust quantitative framework for assessing the costs and CO2 emissions in real-world Cross-Silo FL environments. Our findings indicate that the energy consumption and costs of model training are comparable between Cross-Silo Federated Learning and Centralized Learning. However, the additional data transfer and storage requirements inherent in Centralized Learning can result in significant, often overlooked CO2 emissions. Moreover, we introduce an innovative data and application management system that integrates Cross-Silo FL and analytics, aiming at improving the sustainability and economic efficiency of IT enterprises.",
      "authors": [
        "Hongliu Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-22T11:58:53+00:00",
          "link": "https://arxiv.org/abs/2312.14628v1",
          "size": "1568kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T06:58:38+00:00",
          "link": "https://arxiv.org/abs/2312.14628v2",
          "size": "2047kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T13:35:12+00:00",
          "link": "https://arxiv.org/abs/2312.14628v3",
          "size": "1552kb",
          "version": "v3"
        }
      ],
      "title": "Holistic analysis on the sustainability of Federated Learning across AI product lifecycle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.14628",
        "HTML": "https://arxiv.org/html/2312.14628v3",
        "PDF": "https://arxiv.org/pdf/2312.14628"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the sustainability of Federated Learning and how Cross-Silo Federated Learning affects CO2 emissions, without addressing any reinforcement learning data processing aspects."
      },
      "tasks": [
        "Federated Learning",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.11212",
      "abstract": "Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calculus (XC), a core functional language based on neighbouring values (maps from neighbours to values) where state and interaction is handled through a single primitive, exchange, and provide a corresponding implementation in the FCPP language. Then, we exercise distributed collective processes using two case studies: multi-hop message propagation and distributed monitoring of spatial properties. Finally, we discuss the features of the abstraction and its suitability for different kinds of distributed computing applications.",
      "authors": [
        "Giorgio Audrito",
        "Roberto Casadei",
        "Ferruccio Damiani",
        "Gianluca Torta",
        "Mirko Viroli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-20T11:37:44+00:00",
          "link": "https://arxiv.org/abs/2401.11212v1",
          "size": "336kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T18:26:31+00:00",
          "link": "https://arxiv.org/abs/2401.11212v2",
          "size": "519kb",
          "version": "v2"
        },
        {
          "date": "2025-04-04T15:23:08+00:00",
          "link": "https://arxiv.org/abs/2401.11212v3",
          "size": "519kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T08:38:23+00:00",
          "link": "https://arxiv.org/abs/2401.11212v4",
          "size": "520kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T14:15:06+00:00",
          "link": "https://arxiv.org/abs/2401.11212v5",
          "size": "518kb",
          "version": "v5"
        }
      ],
      "title": "Programming Distributed Collective Processes in the eXchange Calculus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.11212",
        "PDF": "https://arxiv.org/pdf/2401.11212"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper elaborates on programming distributed collective processes in computational ecosystems, with no explicit discussion of reinforcement learning or data processing related to RL contexts."
      },
      "tasks": [
        "Distributed Computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.05102",
      "abstract": "REST APIs are prevalent among web service implementations, easing interoperability through the HTTP protocol. API testers and users exploit the widely adopted OpenAPI Specification (OAS), a machine-readable standard to document REST APIs. However, documenting APIs is a time-consuming and error-prone task, and existing documentation is not always complete, publicly accessible, or up-to-date. This situation limits the efficiency of testing tools and hinders human comprehension. Large Language Models (LLMs) offer the potential to automatically infer API documentation, using their colossal training data. In this paper, we present RESTSpecIT, the first automated approach that infers documentation and performs black-box testing of REST APIs by leveraging LLMs. Our approach requires minimal user input compared to state-of-the-art tools; Given an API name and an LLM access key, RESTSpecIT generates API request seeds and mutates them with data returned by the LLM. The tool then analyzes API responses for documentation inference and testing purposes. RESTSpecIT utilizes an in-context prompt masking strategy, requiring no prior model fine-tuning. We evaluate the quality of our tool with three state-of-the-art LLMs: DeepSeek V3, GPT-4.1, and GPT-3.5. Our evaluation demonstrates that RESTSpecIT can (1) infer documentation with 88.62% of routes and 89.25% of query parameters found on average, (2) discover undocumented API data, (3) operate efficiently (in terms of model costs, requests sent, runtime), and (4) assist REST API testing by uncovering server errors and generating valid OpenAPI Specification inputs for testing tools.",
      "authors": [
        "Alix Decrop",
        "Xavier Devroey",
        "Mike Papadakis",
        "Pierre-Yves Schobbens",
        "Gilles Perrouin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T18:55:41+00:00",
          "link": "https://arxiv.org/abs/2402.05102v1",
          "size": "170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T19:25:43+00:00",
          "link": "https://arxiv.org/abs/2402.05102v2",
          "size": "721kb",
          "version": "v2"
        }
      ],
      "title": "You Can REST Now: Automated REST API Documentation and Testing via LLM-Assisted Request Mutations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.05102",
        "HTML": "https://arxiv.org/html/2402.05102v2",
        "PDF": "https://arxiv.org/pdf/2402.05102"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on automated REST API documentation and testing via LLMs and lacks any direct connection to reinforcement learning or RL data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.11662",
      "abstract": "Motion detection is a primary task required for robotic systems to perceive and navigate in their environment. Proposed in the literature bioinspired neuromorphic Time-Difference Encoder (TDE-2) combines event-based sensors and processors with spiking neural networks to provide real-time and energy-efficient motion detection through extracting temporal correlations between two points in space. However, on the algorithmic level, this design leads to loss of direction-selectivity of individual TDEs in textured environments. Here we propose an augmented 3-point TDE (TDE-3) with additional inhibitory input that makes TDE-3 direction-selectivity robust in textured environments. We developed a procedure to train the new TDE-3 using backpropagation through time and surrogate gradients to linearly map input velocities into an output spike count or an Inter-Spike Interval (ISI). Our work is the first instance of training a spiking neuron to have a specific ISI. Using synthetic data we compared training and inference with spike count and ISI with respect to changes in stimuli dynamic range, spatial frequency, and level of noise. ISI turns out to be more robust towards variation in spatial frequency, whereas the spike count is a more reliable training signal in the presence of noise. We performed the first in-depth quantitative investigation of optical flow coding with TDE and compared TDE-2 vs TDE-3 in terms of energy-efficiency and coding precision. Results show that on the network level both detectors show similar precision (20 degree angular error, 88% correlation with ground truth). Yet, due to the more robust direction-selectivity of individual TDEs, TDE-3 based network spike less and hence is more energy-efficient. Reported precision is on par with model-based methods but the spike-based processing of the TDEs provides allows more energy-efficient inference with neuromorphic hardware.",
      "authors": [
        "Matthew Yedutenko",
        "Federico Paredes-Valles",
        "Lyes Khacef and Guido C.H.E. De Croon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-18T17:42:19+00:00",
          "link": "https://arxiv.org/abs/2402.11662v1",
          "size": "6205kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:12:09+00:00",
          "link": "https://arxiv.org/abs/2402.11662v2",
          "size": "4856kb",
          "version": "v2"
        }
      ],
      "title": "TDE-3: An improved prior for optical flow computation in spiking neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.11662",
        "HTML": "https://arxiv.org/html/2402.11662v2",
        "PDF": "https://arxiv.org/pdf/2402.11662"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses motion detection in robotic systems using spiking neural networks, without any mention of reinforcement learning or data processing in an RL context."
      },
      "tasks": [
        "Motion Detection",
        "Navigate",
        "Optical Flow Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.13357",
      "abstract": "In this work we revisit the elementary scheduling problem $1||\\sum p_j U_j$. The goal is to select, among $n$ jobs with processing times and due dates, a subset of jobs with maximum total processing time that can be scheduled in sequence without violating their due dates. This problem is NP-hard, but a classical algorithm by Lawler and Moore from the 60s solves this problem in pseudo-polynomial time $O(nP)$, where $P$ is the total processing time of all jobs. With the aim to develop best-possible pseudo-polynomial-time algorithms, a recent wave of results has improved Lawler and Moore's algorithm for $1||\\sum p_j U_j$: First to time $\\tilde O(P^{7/4})$ [Bringmann, Fischer, Hermelin, Shabtay, Wellnitz; ICALP'20], then to time $\\tilde O(P^{5/3})$ [Klein, Polak, Rohwedder; SODA'23], and finally to time $\\tilde O(P^{7/5})$ [Schieber, Sitaraman; WADS'23]. It remained an exciting open question whether these works can be improved further.\n  In this work we develop an algorithm in near-linear time $\\tilde O(P)$ for the $1||\\sum p_j U_j$ problem. This running time not only significantly improves upon the previous results, but also matches conditional lower bounds based on the Strong Exponential Time Hypothesis or the Set Cover Hypothesis and is therefore likely optimal (up to subpolynomial factors). Our new algorithm also extends to the case of $m$ machines in time $\\tilde O(P^m)$. In contrast to the previous improvements, we take a different, more direct approach inspired by the recent reductions from Modular Subset Sum to dynamic string problems. We thereby arrive at a satisfyingly simple algorithm.",
      "authors": [
        "Nick Fischer and Leo Wennmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-20T20:19:33+00:00",
          "link": "https://arxiv.org/abs/2402.13357v1",
          "size": "225kb",
          "version": "v1"
        },
        {
          "date": "2024-08-14T13:54:31+00:00",
          "link": "https://arxiv.org/abs/2402.13357v2",
          "size": "230kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T09:21:37+00:00",
          "link": "https://arxiv.org/abs/2402.13357v3",
          "size": "59kb",
          "version": "v3"
        }
      ],
      "title": "Minimizing Tardy Processing Time on a Single Machine in Near-Linear Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13357",
        "HTML": "https://arxiv.org/html/2402.13357v3",
        "PDF": "https://arxiv.org/pdf/2402.13357"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses scheduling problems and algorithmic improvements unrelated to reinforcement learning or any data processing within the RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.01234",
      "abstract": "As vast databases of chemical identities become increasingly available, the challenge shifts to how we effectively explore and leverage these resources to study molecular properties. This paper presents an active learning approach for molecular discovery using Deep Kernel Learning (DKL), demonstrated on the QM9 dataset. DKL links structural embeddings directly to properties, creating organized latent spaces that prioritize relevant property information. By iteratively recalculating embedding vectors in alignment with target properties, DKL uncovers concentrated maxima representing key molecular properties and reveals unexplored regions with potential for innovation. This approach underscores DKL's potential in advancing molecular research and discovery.",
      "authors": [
        "Ayana Ghosh",
        "Maxim Ziatdinov and Sergei V. Kalinin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Chemical Physics (physics.chem-ph)",
        "Computational Physics (physics.comp-ph)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-02T15:34:31+00:00",
          "link": "https://arxiv.org/abs/2403.01234v1",
          "size": "3918kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:38:41+00:00",
          "link": "https://arxiv.org/abs/2403.01234v2",
          "size": "1254kb",
          "version": "v2"
        }
      ],
      "title": "Active Deep Kernel Learning of Molecular Properties: Realizing Dynamic Structural Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.01234",
        "PDF": "https://arxiv.org/pdf/2403.01234"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents an active learning approach for molecular discovery using Deep Kernel Learning without involving reinforcement learning or data processing in RL."
      },
      "tasks": [
        "Active Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.02004",
      "abstract": "We prove non-asymptotic error bounds for particle gradient descent (PGD, Kuntz et al., 2023), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that the flow converges exponentially fast to the free energy's minimizers for models satisfying a condition that generalizes both the log-Sobolev and the Polyak--{\\L}ojasiewicz inequalities (LSI and P{\\L}I, respectively). We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the P{\\L}I implies the so-called quadratic growth condition), and applying the extension to our new setting. We also generalize the Bakry--\\'Emery Theorem and show that the LSI/P{\\L}I extension holds for models with strongly concave log-likelihoods. For such models, we further control PGD's discretization error and obtain the non-asymptotic error bounds. While we are motivated by the study of PGD, we believe that the inequalities and results we extend may be of independent interest.",
      "authors": [
        "Rocco Caprio",
        "Juan Kuntz",
        "Samuel Power and Adam M. Johansen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Functional Analysis (math.FA)",
        "Optimization and Control (math.OC)",
        "Computation (stat.CO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-04T12:57:26+00:00",
          "link": "https://arxiv.org/abs/2403.02004v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2024-04-11T07:54:55+00:00",
          "link": "https://arxiv.org/abs/2403.02004v2",
          "size": "40kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T13:30:45+00:00",
          "link": "https://arxiv.org/abs/2403.02004v3",
          "size": "42kb",
          "version": "v3"
        }
      ],
      "title": "Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.02004",
        "HTML": "https://arxiv.org/html/2403.02004v3",
        "PDF": "https://arxiv.org/pdf/2403.02004"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus is on error bounds for particle gradient descent and related inequalities; there is no direct connection to reinforcement learning or RL data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.05192",
      "abstract": "Remaining a dominant force in Internet traffic, video streaming captivates end users, service providers, and researchers. This paper takes a pragmatic approach to reviewing recent advances in the field by focusing on the prevalent streaming paradigm that involves delivering long-form two-dimensional videos over the best-effort Internet with client-side adaptive bitrate (ABR) algorithms and assistance from content delivery networks (CDNs). To enhance accessibility, we supplement the survey with tutorial material. Unlike existing surveys that offer fragmented views, our work provides a holistic perspective on the entire end-to-end streaming pipeline, from video capture by a camera-equipped device to playback by the end user. Our novel perspective covers the ingestion, processing, and distribution stages of the pipeline and addresses key challenges such as video compression, upload, transcoding, ABR algorithms, CDN support, and quality of experience. We review over 200 papers and classify streaming designs by their problem-solving methodology, whether based on intuition (simple heuristics), theory (formal optimization), or machine learning (generalizable data patterns). The survey further refines these methodology-based categories and characterizes each design by additional traits such as compatible codecs and use of super resolution. We connect the reviewed research to real-world applications by discussing the practices of commercial streaming platforms. Finally, the survey highlights prominent current trends and outlines future directions in video streaming.",
      "authors": [
        "Leonardo Peroni",
        "Sergey Gorinsky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-08T10:14:32+00:00",
          "link": "https://arxiv.org/abs/2403.05192v1",
          "size": "1673kb",
          "version": "v1"
        },
        {
          "date": "2024-09-12T11:46:32+00:00",
          "link": "https://arxiv.org/abs/2403.05192v2",
          "size": "1646kb",
          "version": "v2"
        },
        {
          "date": "2025-02-07T14:34:28+00:00",
          "link": "https://arxiv.org/abs/2403.05192v3",
          "size": "1990kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T18:32:35+00:00",
          "link": "https://arxiv.org/abs/2403.05192v4",
          "size": "3591kb",
          "version": "v4"
        }
      ],
      "title": "An End-to-End Pipeline Perspective on Video Streaming in Best-Effort Networks: A Survey and Tutorial",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.05192",
        "HTML": "https://arxiv.org/html/2403.05192v4",
        "PDF": "https://arxiv.org/pdf/2403.05192"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper provides a comprehensive survey on video streaming technologies but does not focus on reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.06403",
      "abstract": "Recent success of vision foundation models have shown promising performance for the 2D perception tasks. However, it is difficult to train a 3D foundation network directly due to the limited dataset and it remains under explored whether existing foundation models can be lifted to 3D space seamlessly. In this paper, we present PointSeg, a novel training-free paradigm that leverages off-the-shelf vision foundation models to address 3D scene perception tasks. PointSeg can segment anything in 3D scene by acquiring accurate 3D prompts to align their corresponding pixels across frames. Concretely, we design a two-branch prompts learning structure to construct the 3D point-box prompts pairs, combining with the bidirectional matching strategy for accurate point and proposal prompts generation. Then, we perform the iterative post-refinement adaptively when cooperated with different vision foundation models. Moreover, we design a affinity-aware merging algorithm to improve the final ensemble masks. PointSeg demonstrates impressive segmentation performance across various datasets, all without training. Specifically, our approach significantly surpasses the state-of-the-art specialist training-free model by 14.1$\\%$, 12.3$\\%$, and 12.6$\\%$ mAP on ScanNet, ScanNet++, and KITTI-360 datasets, respectively. On top of that, PointSeg can incorporate with various foundation models and even surpasses the specialist training-based methods by 3.4$\\%$-5.4$\\%$ mAP across various datasets, serving as an effective generalist model.",
      "authors": [
        "Qingdong He",
        "Jinlong Peng",
        "Zhengkai Jiang",
        "Xiaobin Hu",
        "Jiangning Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-11T03:28:20+00:00",
          "link": "https://arxiv.org/abs/2403.06403v1",
          "size": "1278kb",
          "version": "v1"
        },
        {
          "date": "2024-07-17T11:31:23+00:00",
          "link": "https://arxiv.org/abs/2403.06403v2",
          "size": "31417kb",
          "version": "v2"
        },
        {
          "date": "2024-07-18T02:09:10+00:00",
          "link": "https://arxiv.org/abs/2403.06403v3",
          "size": "31439kb",
          "version": "v3"
        },
        {
          "date": "2024-10-21T06:44:01+00:00",
          "link": "https://arxiv.org/abs/2403.06403v4",
          "size": "1077kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T11:30:47+00:00",
          "link": "https://arxiv.org/abs/2403.06403v5",
          "size": "1061kb",
          "version": "v5"
        }
      ],
      "title": "PointSeg: A Training-Free Paradigm for 3D Scene Segmentation via Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06403",
        "HTML": "https://arxiv.org/html/2403.06403v5",
        "PDF": "https://arxiv.org/pdf/2403.06403"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a training-free 3D segmentation paradigm leveraging vision foundation models, with no mention of reinforcement learning or data processing within RL frameworks."
      },
      "tasks": [
        "Scene Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.08269",
      "abstract": "This paper explores the residual based a posteriori error estimations for the generalized Burgers-Huxley equation (GBHE) featuring weakly singular kernels. Initially, we present a reliable and efficient error estimator for both the stationary GBHE and the semi-discrete GBHE with memory, utilizing the discontinuous Galerkin finite element method (DGFEM) in spatial dimensions. Additionally, employing backward Euler and Crank Nicolson discretization in the temporal domain and DGFEM in spatial dimensions, we introduce an estimator for the fully discrete GBHE, taking into account the influence of past history. The paper also establishes optimal $L^2$ error estimates for both the stationary GBHE and GBHE. Ultimately, we validate the effectiveness of the proposed error estimator through numerical results, demonstrating its efficacy in an adaptive refinement strategy.",
      "authors": [
        "Sumit Mahajan and Arbaz Khan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-13T05:46:23+00:00",
          "link": "https://arxiv.org/abs/2403.08269v1",
          "size": "2970kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:55:31+00:00",
          "link": "https://arxiv.org/abs/2403.08269v2",
          "size": "1581kb",
          "version": "v2"
        }
      ],
      "title": "A posteriori error estimates for the Generalized Burgers-Huxley equation with weakly singular kernels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08269",
        "HTML": "https://arxiv.org/html/2403.08269v2",
        "PDF": "https://arxiv.org/pdf/2403.08269"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on error estimation for the Generalized Burgers-Huxley equation using numerical methods, with no connection to reinforcement learning or RL data processing concerns."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.08802",
      "abstract": "Generative Artificial Intelligence (GenAI), specifically large language models(LLMs) like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debates on GenAI's transformative nature and regulatory measures, limited research addresses organizational governance, encompassing technical and business perspectives. Although numerous frameworks for governance of AI exist, it is not clear to what extent they apply to GenAI. Our review paper fills this gap by surveying recent works with the purpose of better understanding fundamental characteristics of GenAI and adjusting prior frameworks specifically towards GenAI governance within companies. To do so, it extends Nickerson's framework development processes to include prior conceptualizations. Our framework outlines the scope, objectives, and governance mechanisms tailored to harness business opportunities as well as mitigate risks associated with GenAI integration. Our research contributes a focused approach to GenAI governance, offering practical insights for companies navigating the challenges of GenAI adoption and highlighting research gaps.",
      "authors": [
        "Johannes Schneider and Pauline Kuss and Rene Abraham and Christian Meske"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-05T14:20:19+00:00",
          "link": "https://arxiv.org/abs/2403.08802v1",
          "size": "482kb",
          "version": "v1"
        },
        {
          "date": "2024-06-09T19:48:05+00:00",
          "link": "https://arxiv.org/abs/2403.08802v2",
          "size": "494kb",
          "version": "v2"
        },
        {
          "date": "2024-12-03T09:39:57+00:00",
          "link": "https://arxiv.org/abs/2403.08802v3",
          "size": "602kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T12:09:34+00:00",
          "link": "https://arxiv.org/abs/2403.08802v4",
          "size": "630kb",
          "version": "v4"
        }
      ],
      "title": "Governance of Generative Artificial Intelligence for Companies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08802",
        "PDF": "https://arxiv.org/pdf/2403.08802"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on governance frameworks for generative AI within organizations, which does not involve reinforcement learning or data processing for RL agents."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.09040",
      "abstract": "Retrieval-augmented generation (RAG) enhances language models by integrating external knowledge, but its effectiveness is highly dependent on system configuration. Improper retrieval settings can degrade performance, making RAG less reliable than closed-book generation. In this work, we introduce RAGGED, a framework for systematically evaluating RAG systems across diverse retriever-reader configurations, retrieval depths, and datasets. Our analysis reveals that reader robustness to noise is the key determinant of RAG stability and scalability. Some readers benefit from increased retrieval depth, while others degrade due to their sensitivity to distracting content. Through large-scale experiments on open-domain, multi-hop, and specialized-domain datasets, we show that retrievers, rerankers, and prompts influence performance but do not fundamentally alter these reader-driven trends. By providing a principled framework and new metrics to assess RAG stability and scalability, RAGGED enables systematic evaluation of retrieval-augmented generation systems, guiding future research on optimizing retrieval depth and model robustness.",
      "authors": [
        "Jennifer Hsia",
        "Afreen Shaikh",
        "Zhiruo Wang",
        "Graham Neubig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-14T02:26:31+00:00",
          "link": "https://arxiv.org/abs/2403.09040v1",
          "size": "606kb",
          "version": "v1"
        },
        {
          "date": "2024-08-12T17:12:04+00:00",
          "link": "https://arxiv.org/abs/2403.09040v2",
          "size": "1851kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T09:39:02+00:00",
          "link": "https://arxiv.org/abs/2403.09040v3",
          "size": "1697kb",
          "version": "v3"
        }
      ],
      "title": "RAGGED: Towards Informed Design of Scalable and Stable RAG Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.09040",
        "HTML": "https://arxiv.org/html/2403.09040v3",
        "PDF": "https://arxiv.org/pdf/2403.09040"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work discusses the design of retrieval-augmented generation systems without addressing reinforcement learning or any aspects related to data processing within the RL context."
      },
      "tasks": [
        "Decoder",
        "Question Answering",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/neulab/ragged"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.09567",
      "abstract": "The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of generating natural language explanations by harnessing the capabilities of Large Language Models (LLMs) over the data contained within the previously mentioned black box. The study evaluates the performance of our solution in three different scenarios, each involving autonomous agent navigation functionalities. This evaluation includes a thorough examination of accountability and explainability metrics, demonstrating the effectiveness of our approach in using accountable data from robot actions to obtain coherent, accurate and understandable explanations, even when facing challenges inherent in the use of autonomous agents in real-world scenarios.",
      "authors": [
        "Laura Fern\\'andez-Becerra",
        "Miguel \\'Angel Gonz\\'alez-Santamarta",
        "\\'Angel Manuel Guerrero-Higueras",
        "Francisco Javier Rodr\\'iguez-Lera and Vicente Matell\\'an Olivera"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-14T16:57:18+00:00",
          "link": "https://arxiv.org/abs/2403.09567v1",
          "size": "1680kb",
          "version": "v1"
        },
        {
          "date": "2024-04-23T16:35:36+00:00",
          "link": "https://arxiv.org/abs/2403.09567v2",
          "size": "1686kb",
          "version": "v2"
        },
        {
          "date": "2024-12-19T19:08:29+00:00",
          "link": "https://arxiv.org/abs/2403.09567v3",
          "size": "4199kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T18:49:29+00:00",
          "link": "https://arxiv.org/abs/2403.09567v4",
          "size": "5530kb",
          "version": "v4"
        }
      ],
      "title": "Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.09567",
        "HTML": "https://arxiv.org/html/2403.09567v4",
        "PDF": "https://arxiv.org/pdf/2403.09567"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing accountability and explainability for autonomous agents using blockchain and large language models. It does not address data processing for reinforcement learning, as its emphasis is on security and communication between agents and users."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.14559",
      "abstract": "Localizing predefined 3D keypoints in a 2D image is an effective way to establish 3D-2D correspondences for instance-level 6DoF object pose estimation. However, unreliable localization results of invisible keypoints degrade the quality of correspondences. In this paper, we address this issue by localizing the important keypoints in terms of visibility. Since keypoint visibility information is currently missing in the dataset collection process, we propose an efficient way to generate binary visibility labels from available object-level annotations, for keypoints of both asymmetric objects and symmetric objects. We further derive real-valued visibility-aware importance from binary labels based on the PageRank algorithm. Taking advantage of the flexibility of our visibility-aware importance, we construct VAPO (Visibility-Aware POse estimator) by integrating the visibility-aware importance with a state-of-the-art pose estimation algorithm, along with additional positional encoding. VAPO can work in both CAD-based and CAD-free settings. Extensive experiments are conducted on popular pose estimation benchmarks including Linemod, Linemod-Occlusion, and YCB-V, demonstrating that VAPO clearly achieves state-of-the-art performances. Project page: https://github.com/RuyiLian/VAPO.",
      "authors": [
        "Ruyi Lian",
        "Yuewei Lin",
        "Longin Jan Latecki",
        "Haibin Ling"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-21T16:59:45+00:00",
          "link": "https://arxiv.org/abs/2403.14559v1",
          "size": "16949kb",
          "version": "v1"
        },
        {
          "date": "2025-01-01T20:36:45+00:00",
          "link": "https://arxiv.org/abs/2403.14559v2",
          "size": "17284kb",
          "version": "v2"
        },
        {
          "date": "2025-02-18T21:16:27+00:00",
          "link": "https://arxiv.org/abs/2403.14559v3",
          "size": "17377kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T20:41:43+00:00",
          "link": "https://arxiv.org/abs/2403.14559v4",
          "size": "708kb",
          "version": "v4"
        }
      ],
      "title": "VAPO: Visibility-Aware Keypoint Localization for Efficient 6DoF Object Pose Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.14559",
        "HTML": "https://arxiv.org/html/2403.14559v4",
        "PDF": "https://arxiv.org/pdf/2403.14559"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses visibility-aware keypoint localization for object pose estimation, focusing on 3D-2D correspondences and efficiency in pose estimation. It does not pertain to reinforcement learning or data processing within the RL context."
      },
      "tasks": [
        "Object",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.15740",
      "abstract": "A primary concern regarding training large language models (LLMs) is whether they abuse copyrighted online text. With the increasing training data scale and the prevalence of LLMs in daily lives, two problems arise: \\textbf{1)} false positive membership inference results misled by similar examples; \\textbf{2)} membership inference methods are usually too complex for end users to understand and use. To address these issues, we propose an alternative \\textit{insert-and-detect} methodology, advocating that web users and content platforms employ \\textbf{\\textit{unique identifiers}} for reliable and independent membership inference. Users and platforms can create their identifiers, embed them in copyrighted text, and independently detect them in future LLMs. As an initial demonstration, we introduce \\textit{\\textbf{ghost sentences}} and a user-friendly last-$k$ words test, allowing end users to chat with LLMs for membership inference. Ghost sentences consist primarily of unique passphrases of random natural words, which can come with customized elements to bypass possible filter rules. The last-$k$ words test requires a significant repetition time of ghost sentences~($\\ge10$). For cases with fewer repetitions, we designed an extra perplexity test, as LLMs exhibit high perplexity when encountering unnatural passphrases. We also conduct a comprehensive study on the memorization and membership inference of ghost sentences, examining factors such as training data scales, model sizes, repetition times, insertion positions, wordlist of passphrases, alignment, \\textit{etc}. Our study shows the possibility of applying ghost sentences in real scenarios and provides instructions for the potential application.",
      "authors": [
        "Shuai Zhao",
        "Linchao Zhu",
        "Ruijie Quan",
        "Yi Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-23T06:36:32+00:00",
          "link": "https://arxiv.org/abs/2403.15740v1",
          "size": "3242kb",
          "version": "v1"
        },
        {
          "date": "2024-08-12T08:21:32+00:00",
          "link": "https://arxiv.org/abs/2403.15740v2",
          "size": "1939kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T11:45:02+00:00",
          "link": "https://arxiv.org/abs/2403.15740v3",
          "size": "1936kb",
          "version": "v3"
        }
      ],
      "title": "Protecting Copyrighted Material with Unique Identifiers in Large Language Model Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.15740",
        "HTML": "https://arxiv.org/html/2403.15740v3",
        "PDF": "https://arxiv.org/pdf/2403.15740"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses copyright protection in large language models through unique identifiers and does not involve reinforcement learning or data processing related to RL, as its focus is on membership inference and copyright concerns."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Memorization",
        "Sentence"
      ],
      "repo_urls": [
        "https://github.com/mzhaoshuai/slimclr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.01007",
      "abstract": "Analyzing singular patterns in vector fields is a fundamental problem in theoretical and practical domains due to the ability of such patterns to detect the intrinsic characteristics of vector fields. In this study, we propose an approach for analyzing singular patterns from discrete planar vector fields. Our method involves converting the planar discrete vector field into a specialized digraph and computing its one-dimensional persistent path homology. By analyzing the persistence diagram, we can determine the location of singularities, and the variations of singular patterns can also be analyzed. The experimental results demonstrate the effectiveness of our method in analyzing the singular patterns of noisy real-world vector fields and measuring the variations between different vector fields.",
      "authors": [
        "Yu Chen",
        "Hongwei Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Algebraic Topology (math.AT)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-01T09:23:38+00:00",
          "link": "https://arxiv.org/abs/2404.01007v1",
          "size": "4154kb",
          "version": "v1"
        },
        {
          "date": "2024-06-09T06:22:44+00:00",
          "link": "https://arxiv.org/abs/2404.01007v2",
          "size": "17855kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T03:34:44+00:00",
          "link": "https://arxiv.org/abs/2404.01007v3",
          "size": "13927kb",
          "version": "v3"
        }
      ],
      "title": "Analyzing Singular Patterns in Discrete Planar Vector Fields via Persistent Path Homology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01007",
        "HTML": "https://arxiv.org/html/2404.01007v3",
        "PDF": "https://arxiv.org/pdf/2404.01007"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper analyzes singular patterns in discrete vector fields using persistent path homology, which is unrelated to reinforcement learning or any aspect of data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.06050",
      "abstract": "Dense scene reconstruction for photo-realistic view synthesis has various applications, such as VR/AR, autonomous vehicles. However, most existing methods have difficulties in large-scale scenes due to three core challenges: \\textit{(a) inaccurate depth input.} Accurate depth input is impossible to get in real-world large-scale scenes. \\textit{(b) inaccurate pose estimation.} Most existing approaches rely on accurate pre-estimated camera poses. \\textit{(c) insufficient scene representation capability.} A single global radiance field lacks the capacity to effectively scale to large-scale scenes. To this end, we propose an incremental joint learning framework, which can achieve accurate depth, pose estimation, and large-scale scene reconstruction. A vision transformer-based network is adopted as the backbone to enhance performance in scale information estimation. For pose estimation, a feature-metric bundle adjustment (FBA) method is designed for accurate and robust camera tracking in large-scale scenes. In terms of implicit scene representation, we propose an incremental scene representation method to construct the entire large-scale scene as multiple local radiance fields to enhance the scalability of 3D scene representation. Extended experiments have been conducted to demonstrate the effectiveness and accuracy of our method in depth estimation, pose estimation, and large-scale scene reconstruction.",
      "authors": [
        "Tianchen Deng",
        "Nailin Wang",
        "Chongdi Wang",
        "Shenghai Yuan",
        "Jingchuan Wang",
        "Hesheng Wang",
        "Danwei Wang",
        "Weidong Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-09T06:27:35+00:00",
          "link": "https://arxiv.org/abs/2404.06050v1",
          "size": "9657kb",
          "version": "v1"
        },
        {
          "date": "2024-10-22T13:15:20+00:00",
          "link": "https://arxiv.org/abs/2404.06050v2",
          "size": "21526kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T10:33:15+00:00",
          "link": "https://arxiv.org/abs/2404.06050v3",
          "size": "18765kb",
          "version": "v3"
        }
      ],
      "title": "Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.06050",
        "HTML": "https://arxiv.org/html/2404.06050v3",
        "PDF": "https://arxiv.org/pdf/2404.06050"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on depth estimation, pose estimation, and scene reconstruction using a monocular camera, and does not discuss data processing in the reinforcement learning context."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Depth Estimation",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.09158",
      "abstract": "In this paper, we introduce StreakNet-Arch, a real-time, end-to-end binary-classification framework based on our self-developed Underwater Carrier LiDAR-Radar (UCLR) that embeds Self-Attention and our novel Double Branch Cross Attention (DBC-Attention) to enhance scatter suppression. Under controlled water tank validation conditions, StreakNet-Arch with Self-Attention or DBC-Attention outperforms traditional bandpass filtering and achieves higher $F_1$ scores than learning-based MP networks and CNNs at comparable model size and complexity. Real-time benchmarks on an NVIDIA RTX 3060 show a constant Average Imaging Time (54 to 84 ms) regardless of frame count, versus a linear increase (58 to 1,257 ms) for conventional methods. To facilitate further research, we contribute a publicly available streak-tube camera image dataset contains 2,695,168 real-world underwater 3D point cloud data. More importantly, we validate our UCLR system in a South China Sea trial, reaching an error of 46mm for 3D target at 1,000 m depth and 20 m range. Source code and data are available at https://github.com/BestAnHongjun/StreakNet .",
      "authors": [
        "Xuelong Li",
        "Hongjun An",
        "Haofei Zhao",
        "Guangying Li",
        "Bo Liu",
        "Xing Wang",
        "Guanghua Cheng",
        "Guojun Wu",
        "and Zhe Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-14T06:19:46+00:00",
          "link": "https://arxiv.org/abs/2404.09158v1",
          "size": "12052kb",
          "version": "v1"
        },
        {
          "date": "2024-04-23T11:45:29+00:00",
          "link": "https://arxiv.org/abs/2404.09158v2",
          "size": "12052kb",
          "version": "v2"
        },
        {
          "date": "2025-07-01T14:19:46+00:00",
          "link": "https://arxiv.org/abs/2404.09158v3",
          "size": "11053kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T04:00:55+00:00",
          "link": "https://arxiv.org/abs/2404.09158v4",
          "size": "11053kb",
          "version": "v4"
        }
      ],
      "title": "StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.09158",
        "HTML": "https://arxiv.org/html/2404.09158v4",
        "PDF": "https://arxiv.org/pdf/2404.09158"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces an architecture for LiDAR-Radar imaging and provides a related dataset. It does not address any aspect of data processing for reinforcement learning."
      },
      "models": [
        {
          "model_path": "Coder-AN/StreakNet-Models",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Coder-AN/StreakNet-Models"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Coder-AN/StreakNet-Dataset",
          "downloads": "197",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Coder-AN/StreakNet-Dataset"
        }
      ],
      "tasks": [
        "Binary Classification"
      ],
      "repo_urls": [
        "https://github.com/bestanhongjun/streaknet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.17789",
      "abstract": "We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We provide a theoretical analysis that justifies our approach. Through extensive experiments over multiple PDE systems, we demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to the soft PDE constraints in many existing methods.",
      "authors": [
        "Ray Zirui Zhang",
        "Christopher E. Miles",
        "Xiaohui Xie",
        "John S. Lowengrub"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-27T06:06:41+00:00",
          "link": "https://arxiv.org/abs/2404.17789v1",
          "size": "1713kb",
          "version": "v1"
        },
        {
          "date": "2024-06-17T20:49:42+00:00",
          "link": "https://arxiv.org/abs/2404.17789v2",
          "size": "2159kb",
          "version": "v2"
        },
        {
          "date": "2024-08-16T02:19:23+00:00",
          "link": "https://arxiv.org/abs/2404.17789v3",
          "size": "2159kb",
          "version": "v3"
        },
        {
          "date": "2025-02-04T07:14:11+00:00",
          "link": "https://arxiv.org/abs/2404.17789v4",
          "size": "3916kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T00:58:56+00:00",
          "link": "https://arxiv.org/abs/2404.17789v5",
          "size": "5725kb",
          "version": "v5"
        }
      ],
      "title": "BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part I: PDE-Constrained Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.17789",
        "HTML": "https://arxiv.org/html/2404.17789v5",
        "PDF": "https://arxiv.org/pdf/2404.17789"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for solving inverse problems for PDEs via bilevel optimization, which does not pertain to data processing in reinforcement learning."
      },
      "tasks": [
        "Bilevel Optimization",
        "Operator learning"
      ],
      "repo_urls": [
        "https://github.com/Rayzhangzirui/BILO"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.08379",
      "abstract": "We address the challenge of unsupervised mistake detection in egocentric video of skilled human activities through the analysis of gaze signals. While traditional methods rely on manually labeled mistakes, our approach does not require mistake annotations, hence overcoming the need of domain-specific labeled data. Based on the observation that eye movements closely follow object manipulation activities, we assess to what extent eye-gaze signals can support mistake detection, proposing to identify deviations in attention patterns measured through a gaze tracker with respect to those estimated by a gaze prediction model. Since predicting gaze in video is characterized by high uncertainty, we propose a novel gaze completion task, where eye fixations are predicted from visual observations and partial gaze trajectories, and contribute a novel gaze completion approach which explicitly models correlations between gaze information and local visual tokens. Inconsistencies between predicted and observed gaze trajectories act as an indicator to identify mistakes. Experiments highlight the effectiveness of the proposed approach in different settings, with relative gains up to +14%, +11%, and +5% in EPIC-Tent, HoloAssist and IndustReal respectively, remarkably matching results of supervised approaches without seeing any labels. We further show that gaze-based analysis is particularly useful in the presence of skilled actions, low action execution confidence, and actions requiring hand-eye coordination and object manipulation skills. Our method is ranked first on the HoloAssist Mistake Detection challenge.",
      "authors": [
        "Michele Mazzamuto",
        "Antonino Furnari",
        "Yoichi Sato",
        "Giovanni Maria Farinella"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-12T16:29:45+00:00",
          "link": "https://arxiv.org/abs/2406.08379v1",
          "size": "7493kb",
          "version": "v1"
        },
        {
          "date": "2024-06-17T11:09:00+00:00",
          "link": "https://arxiv.org/abs/2406.08379v2",
          "size": "7493kb",
          "version": "v2"
        },
        {
          "date": "2024-07-30T09:32:17+00:00",
          "link": "https://arxiv.org/abs/2406.08379v3",
          "size": "18310kb",
          "version": "v3"
        },
        {
          "date": "2024-11-25T09:19:38+00:00",
          "link": "https://arxiv.org/abs/2406.08379v4",
          "size": "44021kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T09:17:10+00:00",
          "link": "https://arxiv.org/abs/2406.08379v5",
          "size": "11695kb",
          "version": "v5"
        }
      ],
      "title": "Gazing Into Missteps: Leveraging Eye-Gaze for Unsupervised Mistake Detection in Egocentric Videos of Skilled Human Activities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.08379",
        "HTML": "https://arxiv.org/html/2406.08379v5",
        "PDF": "https://arxiv.org/pdf/2406.08379"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mistake detection using eye-gaze analysis in egocentric videos, which is unrelated to reinforcement learning or data processing within an RL context."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Mazzamuto_Gazing_Into_Missteps_Leveraging_Eye-Gaze_for_Unsupervised_Mistake_Detection_in_CVPR_2025_paper.html",
      "tasks": [
        "Gaze Prediction",
        "Mistake Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.08788",
      "abstract": "State-of-the-art link prediction (LP) models demonstrate impressive benchmark results. However, popular benchmark datasets often assume that training, validation, and testing samples are representative of the overall dataset distribution. In real-world situations, this assumption is often incorrect; uncontrolled factors lead new dataset samples to come from a different distribution than training samples. Additionally, the majority of recent work with graph dataset shift focuses on node- and graph-level tasks, largely ignoring link-level tasks. To bridge this gap, we introduce a novel splitting strategy, known as LPShift, which utilizes structural properties to induce a controlled distribution shift. We verify LPShift's effect through empirical evaluation of SOTA LP models on 16 LPShift variants of original dataset splits, with results indicating drastic changes to model performance. Additional experiments demonstrate graph structure has a strong influence on the success of current generalization methods. Source Code Available Here: https://github.com/revolins/LPShift",
      "authors": [
        "Jay Revolinsky",
        "Harry Shomer",
        "Jiliang Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-13T03:47:12+00:00",
          "link": "https://arxiv.org/abs/2406.08788v1",
          "size": "1160kb",
          "version": "v1"
        },
        {
          "date": "2025-03-11T19:49:55+00:00",
          "link": "https://arxiv.org/abs/2406.08788v2",
          "size": "2610kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T16:14:48+00:00",
          "link": "https://arxiv.org/abs/2406.08788v3",
          "size": "701kb",
          "version": "v3"
        }
      ],
      "title": "Towards Understanding Link Predictor Generalizability Under Distribution Shifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.08788",
        "HTML": "https://arxiv.org/html/2406.08788v3",
        "PDF": "https://arxiv.org/pdf/2406.08788"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses link prediction models under distribution shifts in graph data, which does not pertain to data processing for reinforcement learning."
      },
      "tasks": [
        "Link Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.14335",
      "abstract": "Despite their success, Large-Language Models (LLMs) still face criticism due to their lack of interpretability. Traditional post-hoc interpretation methods, based on attention and gradient-based analysis, offer limited insights as they only approximate the model's decision-making processes and have been proved to be unreliable. For this reason, Concept-Bottleneck Models (CBMs) have been lately proposed in the textual field to provide interpretable predictions based on human-understandable concepts. However, CBMs still exhibit several limitations due to their architectural constraints limiting their expressivity, to the absence of task-interpretability when employing non-linear task predictors and for requiring extensive annotations that are impractical for real-world text data. In this paper, we address these challenges by proposing a novel Linearly Interpretable Concept Embedding Model (LICEM) going beyond the current accuracy-interpretability trade-off. LICEMs classification accuracy is better than existing interpretable models and matches black-box ones. We show that the explanations provided by our models are more interveneable and causally consistent with respect to existing solutions. Finally, we show that LICEMs can be trained without requiring any concept supervision, as concepts can be automatically predicted when using an LLM backbone.",
      "authors": [
        "Francesco De Santis",
        "Philippe Bich",
        "Gabriele Ciravegna",
        "Pietro Barbiero",
        "Danilo Giordano",
        "Tania Cerquitelli"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-20T14:04:53+00:00",
          "link": "https://arxiv.org/abs/2406.14335v1",
          "size": "849kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:35:17+00:00",
          "link": "https://arxiv.org/abs/2406.14335v2",
          "size": "3842kb",
          "version": "v2"
        }
      ],
      "title": "Linearly-Interpretable Concept Embedding Models for Text Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.14335",
        "HTML": "https://arxiv.org/html/2406.14335v2",
        "PDF": "https://arxiv.org/pdf/2406.14335"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses interpretability in concept embedding models for text analysis and does not relate to data processing in reinforcement learning."
      },
      "tasks": [
        "Decision Making",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.17241",
      "abstract": "Recent advances in language model interpretability have identified circuits, critical subnetworks that replicate model behaviors, yet how knowledge is structured within these crucial subnetworks remains opaque. To gain an understanding toward the knowledge in the circuits, we conduct systematic knowledge editing experiments on the circuits of the GPT-2 language model. Our analysis reveals intriguing patterns in how circuits respond to editing attempts, the extent of knowledge distribution across network components, and the architectural composition of knowledge-bearing circuits. These findings offer insights into the complex relationship between model circuits and knowledge representation, deepening the understanding of how information is organized within language models. Our findings offer novel insights into the ``meanings'' of the circuits, and introduce directions for further interpretability and safety research of language models.",
      "authors": [
        "Huaizhi Ge",
        "Frank Rudzicz",
        "Zining Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T03:09:53+00:00",
          "link": "https://arxiv.org/abs/2406.17241v1",
          "size": "389kb",
          "version": "v1"
        },
        {
          "date": "2024-09-19T20:41:18+00:00",
          "link": "https://arxiv.org/abs/2406.17241v2",
          "size": "421kb",
          "version": "v2"
        },
        {
          "date": "2024-12-16T18:54:05+00:00",
          "link": "https://arxiv.org/abs/2406.17241v3",
          "size": "423kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T22:13:30+00:00",
          "link": "https://arxiv.org/abs/2406.17241v4",
          "size": "412kb",
          "version": "v4"
        }
      ],
      "title": "Understanding Language Model Circuits through Knowledge Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17241",
        "HTML": "https://arxiv.org/html/2406.17241v4",
        "PDF": "https://arxiv.org/pdf/2406.17241"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus is on language model circuits and knowledge editing in GPT-2, without relevance to reinforcement learning or its data processing aspects."
      },
      "tasks": [
        "knowledge editing",
        "Language Modeling",
        "Language Modelling",
        "model",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.17253",
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but updating their knowledge post-training remains a critical challenge. While recent model editing techniques like Rank-One Model Editing (ROME) show promise, their effectiveness may vary based on the nature of the knowledge being edited. We introduce the concept of ``perplexingness'': the degree to which new knowledge conflicts with an LLM's learned conceptual hierarchies and categorical relationships. For instance, editing ``British Shorthair is a kind of cat'' to ``British Shorthair is a kind of dog'' represents a low-perplexingness edit within the same taxonomic level, while editing ``A cat is a kind of animal'' to ``A cat is a kind of plant'' represents a high-perplexingness edit that violates fundamental categorical boundaries. To systematically investigate this phenomenon, we introduce HierarchyData, a carefully curated dataset of 99 hyponym-hypernym pairs across diverse categories. Through controlled experiments across three models and four editing methods, we demonstrate a strong negative correlation between the perplexingness of new knowledge and the effectiveness of knowledge editing. Our analysis reveals that edits involving more abstract concepts (hypernyms) generally exhibit higher perplexingness and are more resistant to modification than their specific counterparts (hyponyms). These findings highlight a fundamental challenge in LLM knowledge editing: the more a new fact contradicts an LLM's learned conceptual hierarchies, the harder it becomes to reliably encode that knowledge.",
      "authors": [
        "Huaizhi Ge",
        "Frank Rudzicz",
        "Zining Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T03:41:02+00:00",
          "link": "https://arxiv.org/abs/2406.17253v1",
          "size": "1547kb",
          "version": "v1"
        },
        {
          "date": "2024-12-16T19:47:29+00:00",
          "link": "https://arxiv.org/abs/2406.17253v2",
          "size": "4995kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T22:18:40+00:00",
          "link": "https://arxiv.org/abs/2406.17253v3",
          "size": "4987kb",
          "version": "v3"
        }
      ],
      "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17253",
        "HTML": "https://arxiv.org/html/2406.17253v3",
        "PDF": "https://arxiv.org/pdf/2406.17253"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper examines knowledge editing in large language models, with no connection to reinforcement learning or data processing for RL."
      },
      "tasks": [
        "knowledge editing",
        "Model Editing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.00765",
      "abstract": "In this work, we propose a balanced multi-component and multi-layer neural network (MMNN) structure to accurately and efficiently approximate functions with complex features, in terms of both degrees of freedom and computational cost. The main idea is inspired by a multi-component approach, in which each component can be effectively approximated by a single-layer network, combined with a multi-layer decomposition strategy to capture the complexity of the target function. Although MMNNs can be viewed as a simple modification of fully connected neural networks (FCNNs) or multi-layer perceptrons (MLPs) by introducing balanced multi-component structures, they achieve a significant reduction in training parameters, a much more efficient training process, and improved accuracy compared to FCNNs or MLPs. Extensive numerical experiments demonstrate the effectiveness of MMNNs in approximating highly oscillatory functions and their ability to automatically adapt to localized features.",
      "authors": [
        "Shijun Zhang",
        "Hongkai Zhao",
        "Yimin Zhong",
        "Haomin Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-30T17:00:42+00:00",
          "link": "https://arxiv.org/abs/2407.00765v1",
          "size": "14750kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T16:46:38+00:00",
          "link": "https://arxiv.org/abs/2407.00765v2",
          "size": "12213kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T14:12:38+00:00",
          "link": "https://arxiv.org/abs/2407.00765v3",
          "size": "12383kb",
          "version": "v3"
        }
      ],
      "title": "Structured and Balanced Multi-Component and Multi-Layer Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.00765",
        "HTML": "https://arxiv.org/html/2407.00765v3",
        "PDF": "https://arxiv.org/pdf/2407.00765"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses a new neural network structure for function approximation, without any mention of reinforcement learning or data processing related to RL."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/shijunzhangmath/mmnn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.09357",
      "abstract": "Generating novel molecules is challenging, with most representations leading to generative models producing many invalid molecules. Spanning Tree-based Graph Generation (STGG) is a promising approach to ensure the generation of valid molecules, outperforming state-of-the-art SMILES and graph diffusion models for unconditional generation. In the real world, we want to be able to generate molecules conditional on one or multiple desired properties rather than unconditionally. Thus, in this work, we extend STGG to multi-property-conditional generation. Our approach, STGG+, incorporates a modern Transformer architecture, random masking of properties during training (enabling conditioning on any subset of properties and classifier-free guidance), an auxiliary property-prediction loss (allowing the model to self-criticize molecules and select the best ones), and other improvements. We show that STGG+ achieves state-of-the-art performance on in-distribution and out-of-distribution conditional generation, and reward maximization.",
      "authors": [
        "Alexia Jolicoeur-Martineau",
        "Aristide Baratin",
        "Kisoo Kwon",
        "Boris Knyazev",
        "Yan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-12T15:32:44+00:00",
          "link": "https://arxiv.org/abs/2407.09357v1",
          "size": "1875kb",
          "version": "v1"
        },
        {
          "date": "2024-07-15T14:10:13+00:00",
          "link": "https://arxiv.org/abs/2407.09357v2",
          "size": "1875kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T19:51:11+00:00",
          "link": "https://arxiv.org/abs/2407.09357v3",
          "size": "1187kb",
          "version": "v3"
        }
      ],
      "title": "Any-Property-Conditional Molecule Generation with Self-Criticism using Spanning Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09357",
        "HTML": "https://arxiv.org/html/2407.09357v3",
        "PDF": "https://arxiv.org/pdf/2407.09357"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This research aims at molecule generation using a spanning tree approach with conditional properties but does not involve reinforcement learning or the processing of RL data."
      },
      "tasks": [
        "Graph Generation",
        "Property Prediction",
        "valid"
      ],
      "repo_urls": [
        "https://github.com/samsungsailmontreal/stgg-al",
        "https://github.com/samsungsailmontreal/anymolgencritic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.20814",
      "abstract": "As consumer flexibility becomes expected, it is important that the market mechanisms which attain that flexibility are perceived as fair. We set out fairness issues in energy markets today, and propose a market design to address them. Consumption is categorised as either essential or flexible with different prices and reliability levels for each. Prices are generated by an Automatic Market Maker (AMM) based on instantaneous scarcity and resource is allocated using a novel Fair Play algorithm. We empirically show the performance of the system over 1 year for 101 UK households and benchmark its performance against more classical approaches.",
      "authors": [
        "Shaun Sweeney",
        "Chris King",
        "Mark O'Malley",
        "Robert Shorten"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Computer Science and Game Theory (cs.GT)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-30T13:26:06+00:00",
          "link": "https://arxiv.org/abs/2407.20814v1",
          "size": "680kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T10:16:52+00:00",
          "link": "https://arxiv.org/abs/2407.20814v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Embracing Fairness in Consumer Electricity Markets using an Automatic Market Maker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.20814",
        "PDF": "https://arxiv.org/pdf/2407.20814"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fairness in consumer electricity markets through an Automatic Market Maker and Fair Play algorithm, without discussing reinforcement learning or data processing for RL."
      },
      "tasks": [
        "Fairness"
      ],
      "repo_urls": [
        "https://github.com/sweeneys/consumption-characteriser",
        "https://github.com/sweeneys/fair-flexible-energy-market"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.02426",
      "abstract": "The success of large-scale pre-trained models has established fine-tuning as a standard method for achieving significant improvements in downstream tasks. However, fine-tuning the entire parameter set of a pre-trained model is costly. Parameter-efficient transfer learning (PETL) has recently emerged as a cost-effective alternative for adapting pre-trained models to downstream tasks. Despite its advantages, the increasing model size and input resolution present challenges for PETL, as the training memory consumption is not reduced as effectively as the parameter usage. In this paper, we introduce Fine-grained Prompt Tuning plus (FPT+), a PETL method designed for high-resolution medical image classification, which significantly reduces the training memory consumption compared to other PETL methods. FPT+ performs transfer learning by training a lightweight side network and accessing pre-trained knowledge from a large pre-trained model (LPM) through fine-grained prompts and fusion modules. Specifically, we freeze the LPM of interest and construct a learnable lightweight side network. The frozen LPM processes high-resolution images to extract fine-grained features, while the side network employs corresponding down-sampled low-resolution images to minimize the memory usage. To enable the side network to leverage pre-trained knowledge, we propose fine-grained prompts and fusion modules, which collaborate to summarize information through the LPM's intermediate activations. We evaluate FPT+ on eight medical image datasets of varying sizes, modalities, and complexities. Experimental results demonstrate that FPT+ outperforms other PETL methods, using only 1.03% of the learnable parameters and 3.18% of the memory required for fine-tuning an entire ViT-B model. Our code is available on https://github.com/YijinHuang/FPT.",
      "authors": [
        "Yijin Huang",
        "Pujin Cheng",
        "Roger Tam",
        "Xiaoying Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-05T12:33:07+00:00",
          "link": "https://arxiv.org/abs/2408.02426v1",
          "size": "960kb",
          "version": "v1"
        },
        {
          "date": "2025-01-02T15:25:43+00:00",
          "link": "https://arxiv.org/abs/2408.02426v2",
          "size": "552kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T00:34:01+00:00",
          "link": "https://arxiv.org/abs/2408.02426v3",
          "size": "1132kb",
          "version": "v3"
        }
      ],
      "title": "Boosting Memory Efficiency in Transfer Learning for High-Resolution Medical Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.02426",
        "HTML": "https://arxiv.org/html/2408.02426v3",
        "PDF": "https://arxiv.org/pdf/2408.02426"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for boosting memory efficiency in transfer learning for high-resolution medical image classification, not related to reinforcement learning or data processing within the RL context."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Medical Image Classification",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/yijinhuang/fpt"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.00979",
      "abstract": "Gaussian process upper confidence bound (GP-UCB) is a theoretically established algorithm for Bayesian optimization (BO), where we assume the objective function $f$ follows a GP. One notable drawback of GP-UCB is that the theoretical confidence parameter $\\beta$ increases along with the iterations and is too large. To alleviate this drawback, this paper analyzes the randomized variant of GP-UCB called improved randomized GP-UCB (IRGP-UCB), which uses the confidence parameter generated from the shifted exponential distribution. We analyze the expected regret and conditional expected regret, where the expectation and the probability are taken respectively with $f$ and noise and with the randomness of the BO algorithm. In both regret analyses, IRGP-UCB achieves a sub-linear regret upper bound without increasing the confidence parameter if the input domain is finite. Furthermore, we show that randomization plays a key role in avoiding an increase in confidence parameter by showing that GP-UCB using a constant confidence parameter can incur linearly growing expected cumulative regret. Finally, we show numerical experiments using synthetic and benchmark functions and real-world emulators.",
      "authors": [
        "Shion Takeno",
        "Yu Inatsu",
        "Masayuki Karasuyama"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T06:49:29+00:00",
          "link": "https://arxiv.org/abs/2409.00979v1",
          "size": "282kb",
          "version": "v1"
        },
        {
          "date": "2024-09-16T06:46:32+00:00",
          "link": "https://arxiv.org/abs/2409.00979v2",
          "size": "278kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T01:06:52+00:00",
          "link": "https://arxiv.org/abs/2409.00979v3",
          "size": "268kb",
          "version": "v3"
        }
      ],
      "title": "Regret Analysis for Randomized Gaussian Process Upper Confidence Bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00979",
        "HTML": "https://arxiv.org/html/2409.00979v3",
        "PDF": "https://arxiv.org/pdf/2409.00979"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper analyzes a modified GP-UCB algorithm for Bayesian optimization, which is related to reinforcement learning, but it primarily focuses on regret analysis and theoretical improvements rather than data processing techniques or strategies."
      },
      "tasks": [
        "Bayesian Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.15590",
      "abstract": "Exploration is a critical challenge in robotics, centered on understanding unknown environments. In this work, we focus on robots exploring structured indoor environments which are often predictable and composed of repeating patterns. Most existing approaches, such as conventional frontier approaches, have difficulty leveraging the predictability and explore with simple heuristics such as `closest first'. Recent works use deep learning techniques to predict unknown regions of the map, using these predictions for information gain calculation. However, these approaches are often sensitive to the predicted map quality or do not reason over sensor coverage. To overcome these issues, our key insight is to jointly reason over what the robot can observe and its uncertainty to calculate probabilistic information gain. We introduce MapEx, a new exploration framework that uses predicted maps to form probabilistic sensor model for information gain estimation. MapEx generates multiple predicted maps based on observed information, and takes into consideration both the computed variances of predicted maps and estimated visible area to estimate the information gain of a given viewpoint. Experiments on the real-world KTH dataset showed on average 12.4% improvement than representative map-prediction based exploration and 25.4% improvement than nearest frontier approach. Website: mapex-explorer.github.io",
      "authors": [
        "Cherie Ho",
        "Seungchan Kim",
        "Brady Moon",
        "Aditya Parandekar",
        "Narek Harutyunyan",
        "Chen Wang",
        "Katia Sycara",
        "Graeme Best",
        "Sebastian Scherer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T22:48:04+00:00",
          "link": "https://arxiv.org/abs/2409.15590v1",
          "size": "2298kb",
          "version": "v1"
        },
        {
          "date": "2024-11-03T23:51:33+00:00",
          "link": "https://arxiv.org/abs/2409.15590v2",
          "size": "2298kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T00:28:14+00:00",
          "link": "https://arxiv.org/abs/2409.15590v3",
          "size": "2297kb",
          "version": "v3"
        }
      ],
      "title": "MapEx: Indoor Structure Exploration with Probabilistic Information Gain from Global Map Predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15590",
        "HTML": "https://arxiv.org/html/2409.15590v3",
        "PDF": "https://arxiv.org/pdf/2409.15590"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper addresses exploration in robotics with probabilistic information gain, which may have tangential connections to RL data processing through environment interactions but is not the main focus."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.15615",
      "abstract": "While global point cloud registration systems have advanced significantly in all aspects, many studies have focused on specific components, such as feature extraction, graph-theoretic pruning, or pose solvers. In this paper, we take a holistic view on the registration problem and develop an open-source and versatile C++ library for point cloud registration, called KISS-Matcher. KISS-Matcher combines a novel feature detector, Faster-PFH, that improves over the classical fast point feature histogram (FPFH). Moreover, it adopts a $k$-core-based graph-theoretic pruning to reduce the time complexity of rejecting outlier correspondences. Finally, it combines these modules in a complete, user-friendly, and ready-to-use pipeline. As verified by extensive experiments, KISS-Matcher has superior scalability and broad applicability, achieving a substantial speed-up compared to state-of-the-art outlier-robust registration pipelines while preserving accuracy. Our code will be available at https://github.com/MIT-SPARK/KISS-Matcher.",
      "authors": [
        "Hyungtae Lim and Daebeom Kim and Gunhee Shin and Jingnan Shi and Ignacio Vizzo and Hyun Myung and Jaesik Park and Luca Carlone"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T23:39:03+00:00",
          "link": "https://arxiv.org/abs/2409.15615v1",
          "size": "14951kb",
          "version": "v1"
        },
        {
          "date": "2024-10-06T21:08:01+00:00",
          "link": "https://arxiv.org/abs/2409.15615v2",
          "size": "14951kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T00:45:39+00:00",
          "link": "https://arxiv.org/abs/2409.15615v3",
          "size": "8726kb",
          "version": "v3"
        }
      ],
      "title": "KISS-Matcher: Fast and Robust Point Cloud Registration Revisited",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15615",
        "HTML": "https://arxiv.org/html/2409.15615v3",
        "PDF": "https://arxiv.org/pdf/2409.15615"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses point cloud registration and does not address reinforcement learning or data processing within the RL context."
      },
      "tasks": [
        "Point Cloud Registration"
      ],
      "repo_urls": [
        "https://github.com/mit-spark/kiss-matcher"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.00603",
      "abstract": "Large Language Models (LLMs) are increasingly being explored for their potential in software engineering, particularly in static analysis tasks. In this study, we investigate the potential of current LLMs to enhance call-graph analysis and type inference for Python and JavaScript programs. We empirically evaluated 24 LLMs, including OpenAI's GPT series and open-source models like LLaMA and Mistral, using existing and newly developed benchmarks. Specifically, we enhanced TypeEvalPy, a micro-benchmarking framework for type inference in Python, with auto-generation capabilities, expanding its scope from 860 to 77,268 type annotations for Python. Additionally, we introduced SWARM-CG and SWARM-JS, comprehensive benchmarking suites for evaluating call-graph construction tools across multiple programming languages.\n  Our findings reveal a contrasting performance of LLMs in static analysis tasks. For call-graph generation, traditional static analysis tools such as PyCG for Python and Jelly for JavaScript consistently outperform LLMs. While advanced models like mistral-large-it-2407-123b and gpt-4o show promise, they still struggle with completeness and soundness in call-graph analysis across both languages. In contrast, LLMs demonstrate a clear advantage in type inference for Python, surpassing traditional tools like HeaderGen and hybrid approaches such as HiTyper. These results suggest that, while LLMs hold promise in type inference, their limitations in call-graph analysis highlight the need for further research. Our study provides a foundation for integrating LLMs into static analysis workflows, offering insights into their strengths and current limitations.",
      "authors": [
        "Ashwin Prasad Shivarpatna Venkatesh and Rose Sunil and Samkutty Sabu and Amir M. Mir and Sofia Reis and Eric Bodden"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-01T11:44:29+00:00",
          "link": "https://arxiv.org/abs/2410.00603v1",
          "size": "676kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:28:57+00:00",
          "link": "https://arxiv.org/abs/2410.00603v2",
          "size": "81kb",
          "version": "v2"
        }
      ],
      "title": "An Empirical Study of Large Language Models for Type and Call Graph Analysis in Python and JavaScript",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00603",
        "PDF": "https://arxiv.org/pdf/2410.00603"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper empirically examines large language models for static analysis tasks, which is not related to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.01349",
      "abstract": "Living beings are able to solve a wide variety of problems that they encounter rarely or only once. Without the benefit of extensive and repeated experience with these problems, they can solve them in an ad-hoc manner. We call this capacity to always find a solution to a physically solvable problem $hyperadaptability$. To explain how hyperadaptability can be achieved, we propose a theory that frames behavior as the physical manifestation of a self-modifying search procedure. Rather than exploring randomly, our system achieves robust problem-solving by dynamically ordering an infinite set of continuous behaviors according to simplicity and effectiveness. Behaviors are sampled from paths over cognitive graphs, their order determined by a tight behavior-execution/graph-modification feedback loop. We implement cognitive graphs using Hebbian-learning and a novel harmonic neural representation supporting flexible information storage. We validate our approach through simulation experiments showing rapid achievement of highly-robust navigation ability in complex mazes, as well as high reward on difficult extensions of classic reinforcement learning problems. This framework offers a new theoretical model for developmental learning and paves the way for robots that can autonomously master complex skills and handle exceptional circumstances.",
      "authors": [
        "Alex Baranski",
        "Jun Tani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T09:06:54+00:00",
          "link": "https://arxiv.org/abs/2410.01349v1",
          "size": "640kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:40:25+00:00",
          "link": "https://arxiv.org/abs/2410.01349v2",
          "size": "3668kb",
          "version": "v2"
        }
      ],
      "title": "Life, uh, Finds a Way: Hyperadaptability by Behavioral Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01349",
        "PDF": "https://arxiv.org/pdf/2410.01349"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper proposes a framework for hyperadaptability, showcasing RL applications in complex mazes, but it does not make a direct and significant contribution to data processing in RL."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Developmental Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.01590",
      "abstract": "We study monoidal transducers, transition systems arising as deterministic automata whose transitions also produce outputs in an arbitrary monoid, for instance allowing outputs to commute or to cancel out. We use the categorical framework for minimization and learning of Colcombet, Petri\\c{s}an and Stabile to recover the notion of minimal transducer recognizing a language, and give necessary and sufficient conditions on the output monoid for this minimal transducer to exist and be unique (up to isomorphism). The categorical framework then provides an abstract algorithm for learning it using membership and equivalence queries, and we discuss practical aspects of this algorithm's implementation.",
      "authors": [
        "Quentin Aristote (Universit\\'e Paris Cit\\'e",
        "CNRS",
        "Inria",
        "IRIF",
        "Paris",
        "France)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T14:24:04+00:00",
          "link": "https://arxiv.org/abs/2410.01590v1",
          "size": "148kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T15:05:16+00:00",
          "link": "https://arxiv.org/abs/2410.01590v2",
          "size": "200kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T08:06:20+00:00",
          "link": "https://arxiv.org/abs/2410.01590v3",
          "size": "221kb",
          "version": "v3"
        }
      ],
      "title": "Active Learning of Deterministic Transducers with Outputs in Arbitrary Monoids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01590",
        "HTML": "https://arxiv.org/html/2410.01590v3",
        "PDF": "https://arxiv.org/pdf/2410.01590"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study revolves around learning deterministic transducers with outputs in arbitrary monoids using categorical frameworks, which is unrelated to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.03103",
      "abstract": "Fill-in-the-Middle (FIM), or infilling, has become integral to code language models, enabling generation of missing code given both left and right contexts. However, the current FIM training paradigm which performs next-token prediction (NTP) over reordered sequence often leads to models struggling to generate content that aligns well with the surrounding context. We hypothesize that NTP alone is insufficient for models to learn effective planning conditioned on the distant right context, a critical factor for successful code infilling. To overcome this, we propose Horizon-Length Prediction (HLP), a novel training objective that teaches models to predict the number of remaining middle tokens at each step. HLP advances FIM with lookahead planning, enabling models to inherently learn infilling boundaries for arbitrary left and right contexts without relying on dataset-specific post-processing. Our evaluation across different model families and sizes shows that HLP significantly improves FIM performance by up to 24% relatively on diverse benchmarks, across file-level and repository-level. Furthermore, the enhanced planning capability gained through HLP boosts model performance on code reasoning. Importantly, HLP incurs negligible training overhead and no additional inference cost, ensuring its practicality for real-world scenarios.",
      "authors": [
        "Yifeng Ding",
        "Hantian Ding",
        "Shiqi Wang",
        "Qing Sun",
        "Varun Kumar",
        "Zijian Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-04T02:53:52+00:00",
          "link": "https://arxiv.org/abs/2410.03103v1",
          "size": "358kb",
          "version": "v1"
        },
        {
          "date": "2024-12-24T01:37:23+00:00",
          "link": "https://arxiv.org/abs/2410.03103v2",
          "size": "360kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T15:44:04+00:00",
          "link": "https://arxiv.org/abs/2410.03103v3",
          "size": "384kb",
          "version": "v3"
        }
      ],
      "title": "Planning-Aware Code Infilling via Horizon-Length Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03103",
        "HTML": "https://arxiv.org/html/2410.03103v3",
        "PDF": "https://arxiv.org/pdf/2410.03103"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new training objective for code infilling tasks in language models, with no explicit link to reinforcement learning or data processing techniques in the RL framework."
      },
      "tasks": [
        "Code Completion",
        "Code Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06405",
      "abstract": "The Abstraction and Reasoning Corpus (ARC) is a popular benchmark focused on visual reasoning in the evaluation of Artificial Intelligence systems. In its original framing, an ARC task requires solving a program synthesis problem over small 2D images using a few input-output training pairs. In this work, we adopt the recently popular data-driven approach to the ARC and ask whether a Vision Transformer (ViT) can learn the implicit mapping, from input image to output image, that underlies the task. We show that a ViT -- otherwise a state-of-the-art model for images -- fails dramatically on most ARC tasks even when trained on one million examples per task. This points to an inherent representational deficiency of the ViT architecture that makes it incapable of uncovering the simple structured mappings underlying the ARC tasks. Building on these insights, we propose ViTARC, a ViT-style architecture that unlocks some of the visual reasoning capabilities required by the ARC. Specifically, we use a pixel-level input representation, design a spatially-aware tokenization scheme, and introduce a novel object-based positional encoding that leverages automatic segmentation, among other enhancements. Our task-specific ViTARC models achieve a test solve rate close to 100% on more than half of the 400 public ARC tasks strictly through supervised learning from input-output grids. This calls attention to the importance of imbuing the powerful (Vision) Transformer with the correct inductive biases for abstract visual reasoning that are critical even when the training data is plentiful and the mapping is noise-free. Hence, ViTARC provides a strong foundation for future research in visual reasoning using transformer-based architectures.",
      "authors": [
        "Wenhao Li",
        "Yudong Xu",
        "Scott Sanner",
        "Elias Boutros Khalil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T22:25:34+00:00",
          "link": "https://arxiv.org/abs/2410.06405v1",
          "size": "1314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T23:13:43+00:00",
          "link": "https://arxiv.org/abs/2410.06405v2",
          "size": "3389kb",
          "version": "v2"
        }
      ],
      "title": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06405",
        "HTML": "https://arxiv.org/html/2410.06405v2",
        "PDF": "https://arxiv.org/pdf/2410.06405"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Even though the paper involves learning visual reasoning tasks, it does not engage with reinforcement learning or features related to data processing in an RL setting."
      },
      "tasks": [
        "ARC",
        "Program Synthesis",
        "Visual Reasoning"
      ],
      "repo_urls": [
        "https://github.com/khalil-research/ViTARC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08355",
      "abstract": "Predicting the biophysical and functional properties of proteins is essential for in silico protein design. Machine learning has emerged as a promising technique for such prediction tasks. However, the relative scarcity of in vitro annotations means that these models often have little, or no, specific data on the desired fitness prediction task. As a result of limited data, protein language models (PLMs) are typically trained on general protein sequence modeling tasks, and then fine-tuned, or applied zero-shot, to protein fitness prediction. When no task data is available, the models make strong assumptions about the correlation between the protein sequence likelihood and fitness scores. In contrast, we propose meta-learning over a distribution of standard fitness prediction tasks, and demonstrate positive transfer to unseen fitness prediction tasks. Our method, called Metalic (Meta-Learning In-Context), uses in-context learning and fine-tuning, when data is available, to adapt to new tasks. Crucially, fine-tuning enables considerable generalization, even though it is not accounted for during meta-training. Our fine-tuned models achieve strong results with 18 times fewer parameters than state-of-the-art models. Moreover, our method sets a new state-of-the-art in low-data settings on ProteinGym, an established fitness-prediction benchmark. Due to data scarcity, we believe meta-learning will play a pivotal role in advancing protein engineering.",
      "authors": [
        "Jacob Beck",
        "Shikha Surana",
        "Manus McAuliffe",
        "Oliver Bent",
        "Thomas D. Barrett",
        "Juan Jose Garau Luis",
        "Paul Duckworth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T20:19:35+00:00",
          "link": "https://arxiv.org/abs/2410.08355v1",
          "size": "913kb",
          "version": "v1"
        },
        {
          "date": "2025-01-31T15:41:43+00:00",
          "link": "https://arxiv.org/abs/2410.08355v2",
          "size": "14183kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T22:56:19+00:00",
          "link": "https://arxiv.org/abs/2410.08355v3",
          "size": "14183kb",
          "version": "v3"
        }
      ],
      "title": "Metalic: Meta-Learning In-Context with Protein Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08355",
        "HTML": "https://arxiv.org/html/2410.08355v3",
        "PDF": "https://arxiv.org/pdf/2410.08355"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research is about meta-learning for protein language models focused on fitness predictions, without any reference to reinforcement learning or associated data processing methodologies."
      },
      "tasks": [
        "In-Context Learning",
        "Meta-Learning",
        "Prediction",
        "Protein Design"
      ],
      "repo_urls": [
        "https://github.com/instadeepai/metalic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.09474",
      "abstract": "Knowledge distillation (KD) has been widely used to transfer knowledge from large, accurate models (teachers) to smaller, efficient ones (students). Recent methods have explored enforcing consistency by incorporating causal interpretations to distill invariant representations. In this work, we extend this line of research by introducing a dual augmentation strategy to promote invariant feature learning in both teacher and student models. Our approach leverages different augmentations applied to both models during distillation, pushing the student to capture robust, transferable features. This dual augmentation strategy complements invariant causal distillation by ensuring that the learned representations remain stable across a wider range of data variations and transformations. Extensive experiments on CIFAR-100 demonstrate the effectiveness of this approach, achieving competitive results in same-architecture KD.",
      "authors": [
        "Nikolaos Giakoumoglou",
        "Tania Stathaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-12T10:27:23+00:00",
          "link": "https://arxiv.org/abs/2410.09474v1",
          "size": "190kb",
          "version": "v1"
        },
        {
          "date": "2024-11-03T22:31:31+00:00",
          "link": "https://arxiv.org/abs/2410.09474v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2024-12-20T22:10:44+00:00",
          "link": "https://arxiv.org/abs/2410.09474v3",
          "size": "0kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T16:01:02+00:00",
          "link": "https://arxiv.org/abs/2410.09474v4",
          "size": "0kb",
          "version": "v4"
        }
      ],
      "title": "Distilling Invariant Representations with Dual Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09474",
        "PDF": "https://arxiv.org/pdf/2410.09474"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on knowledge distillation and invariant representation learning using dual augmentation but does not address reinforcement learning or data processing in an RL context."
      },
      "tasks": [
        "Knowledge Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11647",
      "abstract": "Large language models (LLMs) have become integral tool for users from various backgrounds. LLMs, trained on vast corpora, reflect the linguistic and cultural nuances embedded in their pre-training data. However, the values and perspectives inherent in this data can influence the behavior of LLMs, leading to potential biases. As a result, the use of LLMs in contexts involving spiritual or moral values necessitates careful consideration of these underlying biases. Our work starts with verification of our hypothesis by testing the spiritual values of popular LLMs. Experimental results show that LLMs' spiritual values are quite diverse, as opposed to the stereotype of atheists or secularists. We then investigate how different spiritual values affect LLMs in social-fairness scenarios e.g., hate speech identification). Our findings reveal that different spiritual values indeed lead to different sensitivity to different hate target groups. Furthermore, we propose to continue pre-training LLMs on spiritual texts, and empirical results demonstrate the effectiveness of this approach in mitigating spiritual bias.",
      "authors": [
        "Songyuan Liu",
        "Ziyang Zhang",
        "Runze Yan",
        "Wei Wu",
        "Carl Yang",
        "Jiaying Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T14:33:23+00:00",
          "link": "https://arxiv.org/abs/2410.11647v1",
          "size": "844kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:16:47+00:00",
          "link": "https://arxiv.org/abs/2410.11647v2",
          "size": "252kb",
          "version": "v2"
        }
      ],
      "title": "Measuring Spiritual Values and Bias of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11647",
        "HTML": "https://arxiv.org/html/2410.11647v2",
        "PDF": "https://arxiv.org/pdf/2410.11647"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with biases in large language models, particularly those related to spiritual values, and does not discuss reinforcement learning or any aspect of RL data processing."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.14987",
      "abstract": "We introduce SeaS, a unified industrial generative model for automatically creating diverse anomalies, authentic normal products, and precise anomaly masks. While extensive research exists, most efforts either focus on specific tasks, i.e., anomalies or normal products only, or require separate models for each anomaly type. Consequently, prior methods either offer limited generative capability or depend on a vast array of anomaly-specific models. We demonstrate that U-Net's differentiated learning ability captures the distinct visual traits of slightly-varied normal products and diverse anomalies, enabling us to construct a unified model for all tasks. Specifically, we first introduce an Unbalanced Abnormal (UA) Text Prompt, comprising one normal token and multiple anomaly tokens. More importantly, our Decoupled Anomaly Alignment (DA) loss decouples anomaly attributes and binds them to distinct anomaly tokens of UA, enabling SeaS to create unseen anomalies by recombining these attributes. Furthermore, our Normal-image Alignment (NA) loss aligns the normal token to normal patterns, making generated normal products globally consistent and locally varied. Finally, SeaS produces accurate anomaly masks by fusing discriminative U-Net features with high-resolution VAE features. SeaS sets a new benchmark for industrial generation, significantly enhancing downstream applications, with average improvements of $+8.66\\%$ pixel-level AP for synthesis-based AD approaches, $+1.10\\%$ image-level AP for unsupervised AD methods, and $+12.79\\%$ IoU for supervised segmentation models. Code is available at \\href{https://github.com/HUST-SLOW/SeaS}{https://github.com/HUST-SLOW/SeaS}.",
      "authors": [
        "Zhewei Dai",
        "Shilei Zeng",
        "Haotian Liu",
        "Xurui Li",
        "Feng Xue",
        "Yu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-19T05:37:11+00:00",
          "link": "https://arxiv.org/abs/2410.14987v1",
          "size": "25767kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:29:27+00:00",
          "link": "https://arxiv.org/abs/2410.14987v2",
          "size": "25327kb",
          "version": "v2"
        }
      ],
      "title": "SeaS: Few-shot Industrial Anomaly Image Generation with Separation and Sharing Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.14987",
        "HTML": "https://arxiv.org/html/2410.14987v2",
        "PDF": "https://arxiv.org/pdf/2410.14987"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper describes a generative model for industrial anomaly image generation and does not relate to reinforcement learning or data processing within an RL framework."
      },
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/HUST-SLOW/SeaS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.15460",
      "abstract": "As large language models (LLMs) become increasingly prevalent, concerns about their reliability, particularly due to hallucinations - factually inaccurate or irrelevant outputs - have grown. Our research investigates the relationship between the uncertainty in training dynamics and the emergence of hallucinations. Using models from the Pythia suite and several hallucination detection metrics, we analyze hallucination trends and identify significant variance during training. To address this, we propose \\textbf{Sensitivity Dropout (SenD)}, a novel training protocol designed to reduce hallucination variance during training by deterministically dropping embedding indices with significant variability. In addition, we develop an unsupervised hallucination detection metric, Efficient EigenScore (EES), which approximates the traditional EigenScore in 2x speed. This metric is integrated into our training protocol, allowing SenD to be both computationally scalable and effective at reducing hallucination variance. SenD improves test-time reliability of Pythia and Meta's Llama models by up to 17\\% and enhances factual accuracy in Wikipedia, Medical, Legal, and Coding domains without affecting downstream task performance.",
      "authors": [
        "Shahrad Mohammadzadeh",
        "Juan David Guerra",
        "Marco Bonizzato",
        "Reihaneh Rabbany",
        "Golnoosh Farnadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Spectral Theory (math.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-20T18:18:23+00:00",
          "link": "https://arxiv.org/abs/2410.15460v1",
          "size": "3742kb",
          "version": "v1"
        },
        {
          "date": "2024-12-08T18:42:11+00:00",
          "link": "https://arxiv.org/abs/2410.15460v2",
          "size": "4783kb",
          "version": "v2"
        },
        {
          "date": "2025-01-07T14:56:42+00:00",
          "link": "https://arxiv.org/abs/2410.15460v3",
          "size": "4783kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T14:04:55+00:00",
          "link": "https://arxiv.org/abs/2410.15460v4",
          "size": "6665kb",
          "version": "v4"
        }
      ],
      "title": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15460",
        "HTML": "https://arxiv.org/html/2410.15460v4",
        "PDF": "https://arxiv.org/pdf/2410.15460"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses methods for reducing hallucinations in large language models, it does not pertain to reinforcement learning or data processing activities specific to RL."
      },
      "tasks": [
        "Hallucination",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.15607",
      "abstract": "Reinforcement learning (RL) faces challenges in trajectory planning for urban automated driving due to the poor convergence of RL and the difficulty in designing reward functions. Consequently, few RL-based trajectory planning methods can achieve performance comparable to that of imitation learning-based methods. The convergence problem is alleviated by combining RL with supervised learning. However, most existing approaches only reason one step ahead and lack the capability to plan for multiple future steps. Besides, although inverse reinforcement learning holds promise for solving the reward function design issue, existing methods for automated driving impose a linear structure assumption on reward functions, making them difficult to apply to urban automated driving. In light of these challenges, this paper proposes a novel RL-based trajectory planning method that integrates RL with imitation learning to enable multi-step planning. Furthermore, a transformer-based Bayesian reward function is developed, providing effective reward signals for RL in urban scenarios. Moreover, a hybrid-driven trajectory planning framework is proposed to enhance safety and interpretability. The proposed methods were validated on the large-scale real-world urban automated driving nuPlan dataset. Evaluated using closed-loop metrics, the results demonstrated that the proposed method significantly outperformed the baseline employing the identical policy model structure and achieved competitive performance compared to the state-of-the-art method. The code is available at https://github.com/Zigned/nuplan_zigned.",
      "authors": [
        "Di Zeng",
        "Ling Zheng",
        "Xiantong Yang",
        "Yinong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T03:04:29+00:00",
          "link": "https://arxiv.org/abs/2410.15607v1",
          "size": "22441kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:38:09+00:00",
          "link": "https://arxiv.org/abs/2410.15607v2",
          "size": "16944kb",
          "version": "v2"
        }
      ],
      "title": "Reinforced Imitative Trajectory Planning for Urban Automated Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15607",
        "HTML": "https://arxiv.org/html/2410.15607v2",
        "PDF": "https://arxiv.org/pdf/2410.15607"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper proposes a novel RL-based trajectory planning method integrating RL with imitation learning and introduces a transformer-based Bayesian reward function. It uses the nuPlan dataset, highlighting a significant contribution to data processing and curation for RL in urban driving contexts."
      },
      "tasks": [
        "Imitation Learning",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)",
        "Trajectory Planning"
      ],
      "repo_urls": [
        "https://github.com/zigned/nuplan_zigned"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.16069",
      "abstract": "Human processing of idioms relies on understanding the contextual sentences in which idioms occur, as well as language-intrinsic features such as frequency and speaker-intrinsic factors like familiarity. While LLMs have shown high performance on idiomaticity detection tasks, this success may be attributed to reasoning shortcuts in existing datasets. To this end, we construct a novel, controlled contrastive dataset designed to test whether LLMs can effectively use context to disambiguate idiomatic meaning. Additionally, we explore how collocational frequency and sentence probability influence model performance. Our findings reveal that LLMs often fail to resolve idiomaticity when it is required to attend to the surrounding context, and that models perform better on sentences that have higher likelihood. The collocational frequency of expressions also impacts performance. We make our code and dataset publicly available.",
      "authors": [
        "Maggie Mi",
        "Aline Villavicencio",
        "Nafise Sadat Moosavi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T14:47:37+00:00",
          "link": "https://arxiv.org/abs/2410.16069v1",
          "size": "9443kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T18:29:52+00:00",
          "link": "https://arxiv.org/abs/2410.16069v2",
          "size": "9266kb",
          "version": "v2"
        }
      ],
      "title": "Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16069",
        "HTML": "https://arxiv.org/html/2410.16069v2",
        "PDF": "https://arxiv.org/pdf/2410.16069"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on LLMs' ability to interpret idiomatic language using contextual data, rather than any reinforcement learning techniques or data processing specific to RL contexts."
      },
      "tasks": [
        "Sentence"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.00265",
      "abstract": "Trustworthiness in neural networks is crucial for their deployment in critical applications, where reliability, confidence, and uncertainty play pivotal roles in decision-making. Traditional performance metrics such as accuracy and precision fail to capture these aspects, particularly in cases where models exhibit overconfidence. To address these limitations, this paper introduces a novel framework for quantifying the trustworthiness of neural networks by incorporating subjective logic into the evaluation of Expected Calibration Error (ECE). This method provides a comprehensive measure of trust, disbelief, and uncertainty by clustering predicted probabilities and fusing opinions using appropriate fusion operators. We demonstrate the effectiveness of this approach through experiments on MNIST and CIFAR-10 datasets, where post-calibration results indicate improved trustworthiness. The proposed framework offers a more interpretable and nuanced assessment of AI models, with potential applications in sensitive domains such as healthcare and autonomous systems.",
      "authors": [
        "Koffi Ismael Ouattara"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T23:54:21+00:00",
          "link": "https://arxiv.org/abs/2411.00265v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:16:27+00:00",
          "link": "https://arxiv.org/abs/2411.00265v2",
          "size": "134kb",
          "version": "v2"
        }
      ],
      "title": "Quantifying calibration error in modern neural networks through evidence based theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00265",
        "HTML": "https://arxiv.org/html/2411.00265v2",
        "PDF": "https://arxiv.org/pdf/2411.00265"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This framework aims at assessing neural network calibration using subjective logic, without any mention of reinforcement learning or data processing within RL contexts."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.00355",
      "abstract": "In this paper, we propose TextDestroyer, the first training- and annotation-free method for scene text destruction using a pre-trained diffusion model. Existing scene text removal models require complex annotation and retraining, and may leave faint yet recognizable text information, compromising privacy protection and content concealment. TextDestroyer addresses these issues by employing a three-stage hierarchical process to obtain accurate text masks. Our method scrambles text areas in the latent start code using a Gaussian distribution before reconstruction. During the diffusion denoising process, self-attention key and value are referenced from the original latent to restore the compromised background. Latent codes saved at each inversion step are used for replacement during reconstruction, ensuring perfect background restoration. The advantages of TextDestroyer include: (1) it eliminates labor-intensive data annotation and resource-intensive training; (2) it achieves more thorough text destruction, preventing recognizable traces; and (3) it demonstrates better generalization capabilities, performing well on both real-world scenes and generated images.",
      "authors": [
        "Mengcheng Li",
        "Fei Chao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-01T04:41:00+00:00",
          "link": "https://arxiv.org/abs/2411.00355v1",
          "size": "44859kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T11:08:07+00:00",
          "link": "https://arxiv.org/abs/2411.00355v2",
          "size": "24016kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T05:32:21+00:00",
          "link": "https://arxiv.org/abs/2411.00355v3",
          "size": "24016kb",
          "version": "v3"
        }
      ],
      "title": "TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00355",
        "HTML": "https://arxiv.org/html/2411.00355v3",
        "PDF": "https://arxiv.org/pdf/2411.00355"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper proposes TextDestroyer, a scene text destruction method for images using diffusion models. It does not relate to reinforcement learning or data processing within RL contexts."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.01482",
      "abstract": "Halfspace (or Tukey) depth is a fundamental and robust measure of centrality of data points in multivariate datasets. Computing the depth of a point with respect to the uniform distribution on an open convex body in $\\mathbb{R}^d$ is a natural algorithmic problem. While the coarser task of testing membership in convex bodies has been extensively studied, the refined problem of evaluating depth has received comparatively little attention in the literature.\n  In this work, we present an algorithm for approximating the halfspace depth of a point in an open convex body $K \\subset \\mathbb{R}^d.$ To the best of our knowledge, this is the first deterministic algorithm for this problem. As part of our approach, we design an algorithm for answering approximate membership queries for the depth-trimmed regions of $K$ (i.e., the superlevel sets of the depth function). Our data structure is inspired by recent work of Abdelkader and Mount [SOSA 2024], wherein approximate membership queries for $K$ are answered using geometric structures derived from the Hilbert metric on $K.$ A key component underlying our data structure is a novel quantitative comparison between the depth-trimmed regions and the Hilbert metric balls of $K$.\n  Lastly, to highlight the computational expense of the problem, we present an algorithm for determining the exact depth of a point in an open planar convex polygon presented as the intersection of finitely many halfplanes.",
      "authors": [
        "Purvi Gupta",
        "Anant Narayanan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Metric Geometry (math.MG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-03T08:44:30+00:00",
          "link": "https://arxiv.org/abs/2411.01482v1",
          "size": "309kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:06:35+00:00",
          "link": "https://arxiv.org/abs/2411.01482v2",
          "size": "219kb",
          "version": "v2"
        }
      ],
      "title": "A (Hilbert) geometric algorithm for approximating the halfspace depth of a point in a convex body",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01482",
        "HTML": "https://arxiv.org/html/2411.01482v2",
        "PDF": "https://arxiv.org/pdf/2411.01482"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a geometric algorithm for approximating the halfspace depth of a point in a convex body, a mathematical computation problem unrelated to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.02179",
      "abstract": "High-quality environment lighting is essential for creating immersive mobile augmented reality (AR) experiences. However, achieving visually coherent estimation for mobile AR is challenging due to several key limitations in AR device sensing capabilities, including low camera FoV and limited pixel dynamic ranges. Recent advancements in generative AI, which can generate high-quality images from different types of prompts, including texts and images, present a potential solution for high-quality lighting estimation. Still, to effectively use generative image diffusion models, we must address two key limitations of content quality and slow inference. In this work, we design and implement a generative lighting estimation system called CleAR that can produce high-quality, diverse environment maps in the format of 360{\\deg} HDR images. Specifically, we design a two-step generation pipeline guided by AR environment context data to ensure the output aligns with the physical environment's visual context and color appearance. To improve the estimation robustness under different lighting conditions, we design a real-time refinement component to adjust lighting estimation results on AR devices. Through a combination of quantitative and qualitative evaluations, we show that CleAR outperforms state-of-the-art lighting estimation methods on both estimation accuracy, latency, and robustness, and is rated by 31 participants as producing better renderings for most virtual objects. For example, CleAR achieves 51% to 56% accuracy improvement on virtual object renderings across objects of three distinctive types of materials and reflective properties. CleAR produces lighting estimates of comparable or better quality in just 3.2 seconds -- over 110X faster than state-of-the-art methods.",
      "authors": [
        "Yiqin Zhao",
        "Mallesham Dasari",
        "Tian Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T15:37:18+00:00",
          "link": "https://arxiv.org/abs/2411.02179v1",
          "size": "14752kb",
          "version": "v1"
        },
        {
          "date": "2025-05-05T19:58:02+00:00",
          "link": "https://arxiv.org/abs/2411.02179v2",
          "size": "16061kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T16:15:30+00:00",
          "link": "https://arxiv.org/abs/2411.02179v3",
          "size": "2816kb",
          "version": "v3"
        }
      ],
      "title": "CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02179",
        "HTML": "https://arxiv.org/html/2411.02179v3",
        "PDF": "https://arxiv.org/pdf/2411.02179"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses augmented reality lighting estimation using generative AI, not involving reinforcement learning or data processing within an RL framework."
      },
      "tasks": [
        "Hallucination",
        "Lighting Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02572",
      "abstract": "Large-scale cell microscopy screens are used in drug discovery and molecular biology research to study the effects of millions of chemical and genetic perturbations on cells. To use these images in downstream analysis, we need models that can map each image into a feature space that represents diverse biological phenotypes consistently, in the sense that perturbations with similar biological effects have similar representations. In this work, we present the largest foundation model for cell microscopy data to date, a new 1.9 billion-parameter ViT-G/8 MAE trained on over 8 billion microscopy image crops. Compared to a previous published ViT-L/8 MAE, our new model achieves a 60% improvement in linear separability of genetic perturbations and obtains the best overall performance on whole-genome biological relationship recall and replicate consistency benchmarks. Beyond scaling, we developed two key methods that improve performance: (1) training on a curated and diverse dataset; and, (2) using biologically motivated linear probing tasks to search across each transformer block for the best candidate representation of whole-genome screens. We find that many self-supervised vision transformers, pretrained on either natural or microscopy images, yield significantly more biologically meaningful representations of microscopy images in their intermediate blocks than in their typically used final blocks. More broadly, our approach and results provide insights toward a general strategy for successfully building foundation models for large-scale biological data.",
      "authors": [
        "Kian Kenyon-Dean",
        "Zitong Jerry Wang",
        "John Urbanik",
        "Konstantin Donhauser",
        "Jason Hartford",
        "Saber Saberian",
        "Nil Sahin",
        "Ihab Bendidi",
        "Safiye Celik",
        "Marta Fay",
        "Juan Sebastian Rodriguez Vera",
        "Imran S Haque",
        "Oren Kraus"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T20:09:51+00:00",
          "link": "https://arxiv.org/abs/2411.02572v1",
          "size": "2970kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:52:58+00:00",
          "link": "https://arxiv.org/abs/2411.02572v2",
          "size": "2321kb",
          "version": "v2"
        }
      ],
      "title": "ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02572",
        "HTML": "https://arxiv.org/html/2411.02572v2",
        "PDF": "https://arxiv.org/pdf/2411.02572"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses scaling biological representation learning using large-scale microscopy data and improves model performance, unconnected to reinforcement learning or RL data processing."
      },
      "tasks": [
        "Drug Discovery",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02813",
      "abstract": "Continual learning methods based on pre-trained models (PTM) have recently gained attention which adapt to successive downstream tasks without catastrophic forgetting. These methods typically refrain from updating the pre-trained parameters and instead employ additional adapters, prompts, and classifiers. In this paper, we from a novel perspective investigate the benefit of sparse orthogonal parameters for continual learning. We found that merging sparse orthogonality of models learned from multiple streaming tasks has great potential in addressing catastrophic forgetting. Leveraging this insight, we propose a novel yet effective method called SoTU (Sparse Orthogonal Parameters TUning). We hypothesize that the effectiveness of SoTU lies in the transformation of knowledge learned from multiple domains into the fusion of orthogonal delta parameters. Experimental evaluations on diverse CL benchmarks demonstrate the effectiveness of the proposed approach. Notably, SoTU achieves optimal feature representation for streaming data without necessitating complex classifier designs, making it a Plug-and-Play solution.",
      "authors": [
        "Hai-Jian Ke",
        "Kun-Peng Ning",
        "Yu-Yang Liu",
        "Jia-Yu Yao",
        "Yong-Hong Tian",
        "Li Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T05:19:09+00:00",
          "link": "https://arxiv.org/abs/2411.02813v1",
          "size": "12552kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:39:50+00:00",
          "link": "https://arxiv.org/abs/2411.02813v2",
          "size": "2536kb",
          "version": "v2"
        }
      ],
      "title": "Sparse Orthogonal Parameters Tuning for Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02813",
        "HTML": "https://arxiv.org/html/2411.02813v2",
        "PDF": "https://arxiv.org/pdf/2411.02813"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates continual learning with sparse orthogonal parameters, focusing on pre-trained models and catastrophic forgetting, without mentioning reinforcement learning or data processing in RL."
      },
      "tasks": [
        "Continual Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.04202",
      "abstract": "This paper studies the problem of optimal placement of water quality (WQ) sensors in water distribution networks (WDNs), with a focus on chlorine transport, decay, and reaction models. Such models are traditionally used as suitable proxies for WQ. The literature on this topic is inveterate, but has a key limitation: it utilizes simplified single-species decay and reaction models that do not capture WQ transients for nonlinear, multi-species interactions. This results in sensor placements (SP) that do not account for nonlinear WQ dynamics. Furthermore, as WQ simulations are parameterized by hydraulic profiles and demand patterns, the placement of sensors are often hydraulics-dependent. This study produces a greedy algorithm that addresses the two aforementioned limitations. The algorithm is grounded in nonlinear dynamic systems and observability theory, and yields SPs that are submodular and robust to hydraulic changes. Case studies on benchmark water networks are provided. The key findings provide practical recommendations for WDN operators.",
      "authors": [
        "Mohamad H. Kazma",
        "Salma M. Elsherif",
        "Ahmad F. Taha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T19:02:16+00:00",
          "link": "https://arxiv.org/abs/2411.04202v1",
          "size": "1825kb",
          "version": "v1"
        },
        {
          "date": "2024-11-26T21:14:46+00:00",
          "link": "https://arxiv.org/abs/2411.04202v2",
          "size": "1870kb",
          "version": "v2"
        },
        {
          "date": "2025-06-25T23:06:43+00:00",
          "link": "https://arxiv.org/abs/2411.04202v3",
          "size": "1003kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T18:08:16+00:00",
          "link": "https://arxiv.org/abs/2411.04202v4",
          "size": "1003kb",
          "version": "v4"
        }
      ],
      "title": "Observability and Generalized Sensor Placement for Nonlinear Quality Models in Drinking Water Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04202",
        "HTML": "https://arxiv.org/html/2411.04202v4",
        "PDF": "https://arxiv.org/pdf/2411.04202"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sensor placement and water quality modeling in water distribution networks. It does not discuss reinforcement learning or data processing within an RL context."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.05813",
      "abstract": "The detection and clearance of explosive ordnance (EO) continues to be a predominantly manual and high-risk process that can benefit from advances in technology to improve its efficiency and effectiveness. Research on artificial intelligence (AI) for EO detection in clearance operations has grown significantly in recent years. However, this research spans a wide range of fields, making it difficult to gain a comprehensive understanding of current trends and developments. Therefore, this article provides a literature review of academic research on AI for EO detection in clearance operations. It finds that research can be grouped into two main streams: AI for EO object detection and AI for EO risk prediction, with the latter being much less studied than the former. From the literature review, we develop three opportunities for future research. These include a call for renewed efforts in the use of AI for EO risk prediction, the combination of different AI systems and data sources, and novel approaches to improve EO risk prediction performance, such as pattern-based predictions. Finally, we provide a perspective on the future of AI for EO detection in clearance operations. We emphasize the role of traditional machine learning (ML) for this task, the need to dynamically incorporate expert knowledge into the models, and the importance of effectively integrating AI systems with real-world operations.",
      "authors": [
        "Bj\\\"orn Kischelewski",
        "Gregory Cathcart",
        "David Wahl and Benjamin Guedj"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T11:50:29+00:00",
          "link": "https://arxiv.org/abs/2411.05813v1",
          "size": "645kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T19:37:44+00:00",
          "link": "https://arxiv.org/abs/2411.05813v2",
          "size": "752kb",
          "version": "v2"
        }
      ],
      "title": "AI for Explosive Ordnance Detection in Clearance Operations: The State of Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05813",
        "PDF": "https://arxiv.org/pdf/2411.05813"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is a literature review on AI for explosive ordnance detection, focusing on object detection and risk prediction. It does not involve reinforcement learning or data processing specifically within the RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09127",
      "abstract": "We propose a novel algorithm for combined unit and layer pruning of deep neural networks that functions during training and without requiring a pre-trained network to apply. Our algorithm optimally trades-off learning accuracy and pruning levels while balancing layer vs. unit pruning and computational vs. parameter complexity using only three user-defined parameters, which are easy to interpret and tune. We formulate a stochastic optimization problem over the network weights and the parameters of variational Bernoulli distributions for binary Random Variables taking values either 0 or 1 and scaling the units and layers of the network. Optimal network structures are found as the solution to this optimization problem. Pruning occurs when a variational parameter converges to 0 rendering the corresponding structure permanently inactive, thus saving computations both during training and prediction. A key contribution of our approach is to define a cost function that combines the objectives of prediction accuracy and network pruning in a computational/parameter complexity-aware manner and the automatic selection of the many regularization parameters. We show that the proposed algorithm converges to solutions of the optimization problem corresponding to deterministic networks. We analyze the ODE system that underlies our stochastic optimization algorithm and establish domains of attraction for the dynamics of the network parameters. These theoretical results lead to practical pruning conditions avoiding the premature pruning of units and layers during training. We evaluate our method on the CIFAR-10/100 and ImageNet datasets using ResNet architectures and demonstrate that it gives improved results with respect to pruning ratios and test accuracy over layer-only or unit-only pruning and favorably competes with combined unit and layer pruning algorithms requiring pre-trained networks.",
      "authors": [
        "Valentin Frank Ingmar Guenter and Athanasios Sideris"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T02:00:22+00:00",
          "link": "https://arxiv.org/abs/2411.09127v1",
          "size": "163kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:39:10+00:00",
          "link": "https://arxiv.org/abs/2411.09127v2",
          "size": "191kb",
          "version": "v2"
        }
      ],
      "title": "Complexity-Aware Training of Deep Neural Networks for Optimal Structure Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09127",
        "HTML": "https://arxiv.org/html/2411.09127v2",
        "PDF": "https://arxiv.org/pdf/2411.09127"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a pruning algorithm for deep neural networks focused on optimizing computational complexity. It is not related to reinforcement learning or data processing in the RL context."
      },
      "tasks": [
        "Network Pruning",
        "Stochastic Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.10438",
      "abstract": "Training deep neural networks--and more recently, large models demands efficient and scalable optimizers. Adaptive gradient algorithms like Adam, AdamW, and their variants have been central to this task. Despite the development of numerous variance reduction algorithms in the past decade aimed at accelerating stochastic optimization in both convex and nonconvex settings, variance reduction has not found widespread success in training deep neural networks or large language models. Consequently, it has remained a less favored approach in modern AI. In this paper, to unleash the power of variance reduction for efficient training of large models, we propose a unified optimization framework, MARS (Make vAriance Reduction Shine), which reconciles preconditioned gradient methods with variance reduction via a scaled stochastic recursive momentum technique. Within our framework, we introduce three instances of MARS that leverage preconditioned gradient updates based on AdamW, Lion, and Shampoo, respectively. We also draw a connection between our algorithms and existing optimizers. Experimental results on training GPT-2 models indicate that MARS consistently outperforms AdamW by a large margin. The implementation of MARS is available at https://github.com/AGI-Arena/MARS.",
      "authors": [
        "Huizhuo Yuan",
        "Yifeng Liu",
        "Shuang Wu",
        "Xun Zhou",
        "Quanquan Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T18:57:39+00:00",
          "link": "https://arxiv.org/abs/2411.10438v1",
          "size": "597kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T11:23:11+00:00",
          "link": "https://arxiv.org/abs/2411.10438v2",
          "size": "2574kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T17:48:35+00:00",
          "link": "https://arxiv.org/abs/2411.10438v3",
          "size": "2687kb",
          "version": "v3"
        }
      ],
      "title": "MARS: Unleashing the Power of Variance Reduction for Training Large Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10438",
        "HTML": "https://arxiv.org/html/2411.10438v3",
        "PDF": "https://arxiv.org/pdf/2411.10438"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a unified optimization framework, MARS, using variance reduction for large models. It discusses optimization methods but does not specifically relate to reinforcement learning or RL data processing."
      },
      "models": [
        {
          "model_path": "rwightman/timm-optim-caution",
          "downloads": "0",
          "likes": "9",
          "trending_score": "0.0",
          "link": "https://huggingface.co/rwightman/timm-optim-caution"
        }
      ],
      "tasks": [
        "Stochastic Optimization"
      ],
      "repo_urls": [
        "https://github.com/AGI-Arena/MARS",
        "https://github.com/huggingface/pytorch-image-models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.10745",
      "abstract": "In zero-shot skeleton-based action recognition (ZSAR), aligning skeleton features with the text features of action labels is essential for accurately predicting unseen actions. ZSAR faces a fundamental challenge in bridging the modality gap between the two-kind features, which severely limits generalization to unseen actions. Previous methods focus on direct alignment between skeleton and text latent spaces, but the modality gaps between these spaces hinder robust generalization learning. Motivated by the success of diffusion models in multi-modal alignment (e.g., text-to-image, text-to-video), we firstly present a diffusion-based skeleton-text alignment framework for ZSAR. Our approach, Triplet Diffusion for Skeleton-Text Matching (TDSM), focuses on cross-alignment power of diffusion models rather than their generative capability. Specifically, TDSM aligns skeleton features with text prompts by incorporating text features into the reverse diffusion process, where skeleton features are denoised under text guidance, forming a unified skeleton-text latent space for robust matching. To enhance discriminative power, we introduce a triplet diffusion (TD) loss that encourages our TDSM to correct skeleton-text matches while pushing them apart for different action classes. Our TDSM significantly outperforms very recent state-of-the-art methods with significantly large margins of 2.36%-point to 13.05%-point, demonstrating superior accuracy and scalability in zero-shot settings through effective skeleton-text matching.",
      "authors": [
        "Jeonghyeok Do",
        "Munchurl Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-16T08:55:18+00:00",
          "link": "https://arxiv.org/abs/2411.10745v1",
          "size": "636kb",
          "version": "v1"
        },
        {
          "date": "2024-11-22T15:49:47+00:00",
          "link": "https://arxiv.org/abs/2411.10745v2",
          "size": "683kb",
          "version": "v2"
        },
        {
          "date": "2025-03-10T04:40:07+00:00",
          "link": "https://arxiv.org/abs/2411.10745v3",
          "size": "635kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T11:28:48+00:00",
          "link": "https://arxiv.org/abs/2411.10745v4",
          "size": "707kb",
          "version": "v4"
        }
      ],
      "title": "Bridging the Skeleton-Text Modality Gap: Diffusion-Powered Modality Alignment for Zero-shot Skeleton-based Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10745",
        "HTML": "https://arxiv.org/html/2411.10745v4",
        "PDF": "https://arxiv.org/pdf/2411.10745"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a diffusion-based framework for zero-shot skeleton-based action recognition. It focuses on modality alignment and does not involve reinforcement learning or data processing within an RL framework."
      },
      "tasks": [
        "Action Recognition",
        "Skeleton Based Action Recognition",
        "Text Matching",
        "Triplet",
        "Zero-Shot Action Recognition",
        "Zero-Shot Learning",
        "Zero Shot Skeletal Action Recognition"
      ],
      "repo_urls": [
        "https://github.com/KAIST-VICLab/TDSM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.11192",
      "abstract": "Biological lifeforms can heal, grow, adapt, and reproduce -- abilities essential for sustained survival and development. In contrast, robots today are primarily monolithic machines with limited ability to self-repair, physically develop, or incorporate material from their environments. While robot minds rapidly evolve new behaviors through AI, their bodies remain closed systems, unable to systematically integrate material to grow or heal. We argue that open-ended physical adaptation is only possible when robots are designed using a small repertoire of simple modules. This allows machines to mechanically adapt by consuming parts from other machines or their surroundings and shed broken components. We demonstrate this principle on a truss modular robot platform. We show how robots can grow bigger, faster, and more capable by consuming materials from their environment and other robots. We suggest that machine metabolic processes like those demonstrated here will be an essential part of any sustained future robot ecology.",
      "authors": [
        "Philippe Martin Wyder",
        "Riyaan Bakhda",
        "Meiqi Zhao",
        "Quinn A. Booth",
        "Matthew E. Modi",
        "Andrew Song",
        "Simon Kang",
        "Jiahao Wu",
        "Priya Patel",
        "Robert T. Kasumi",
        "David Yi",
        "Nihar Niraj Garg",
        "Pranav Jhunjhunwala",
        "Siddharth Bhutoria",
        "Evan H. Tong",
        "Yuhang Hu",
        "Judah Goldfeder",
        "Omer Mustel",
        "Donghan Kim and Hod Lipson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-17T22:54:53+00:00",
          "link": "https://arxiv.org/abs/2411.11192v1",
          "size": "7346kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:28:40+00:00",
          "link": "https://arxiv.org/abs/2411.11192v2",
          "size": "4489kb",
          "version": "v2"
        }
      ],
      "title": "Robot Metabolism: Towards machines that can grow by consuming other machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11192",
        "PDF": "https://arxiv.org/pdf/2411.11192"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robots' ability to physically adapt and grow by integrating material from their environments, without any mention of reinforcement learning or data processing in that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.13140",
      "abstract": "The PID controller remains the most widely adopted control architecture, with groundbreaking success across extensive implications. However, optimal parameter tuning for PID controller remains a critical challenge. Existing theories predominantly focus on linear time-invariant systems and Single-Input Single-Output (SISO) scenarios, leaving a research gap in addressing complex PID control problems for Multi-Input Multi-Output (MIMO) nonlinear systems with disturbances. This study enhances controller robustness by leveraging insights into the velocity form of nonlinear systems. It establishes a quantitative metric to evaluate the robustness of MIMO-PI controller, clarifies key theories on how robustness influences exponential error stabilization. Guided by these theories, an optimal robust MIMO-PI controller is developed without oversimplifying assumptions. Experimental results demonstrate that the controller achieves effective exponential stabilization and exhibits exceptional robustness under the guidance of the proposed robust indicator. Notably, the robust convergence indicator can also effectively assess comprehensive performance.",
      "authors": [
        "Zimao Sheng",
        "Hongan Yang",
        "Jiakang Wang",
        "Tong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-20T09:13:31+00:00",
          "link": "https://arxiv.org/abs/2411.13140v1",
          "size": "4942kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:56:36+00:00",
          "link": "https://arxiv.org/abs/2411.13140v2",
          "size": "3352kb",
          "version": "v2"
        }
      ],
      "title": "Robust Convergency Indicator using MIMO-PI Controller in the presence of disturbances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13140",
        "HTML": "https://arxiv.org/html/2411.13140v2",
        "PDF": "https://arxiv.org/pdf/2411.13140"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper centers around MIMO-PI controller robustness in control systems while optimizing PID controller parameters, without relating to reinforcement learning or its data processing aspects."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.13789",
      "abstract": "Display advertising provides significant value to advertisers, publishers, and users. Traditional display advertising systems utilize a multi-stage architecture consisting of retrieval, coarse ranking, and final ranking. However, conventional retrieval methods rely on ID-based learning to rank mechanisms and fail to adequately utilize the content information of ads, which hampers their ability to provide diverse recommendation lists.\n  To address this limitation, we propose leveraging the extensive world knowledge of LLMs. However, three key challenges arise when attempting to maximize the effectiveness of LLMs: \"How to capture user interests\", \"How to bridge the knowledge gap between LLMs and advertising system\", and \"How to efficiently deploy LLMs\". To overcome these challenges, we introduce a novel LLM-based framework called LLM Empowered Display ADvertisement REcommender system (LEADRE). LEADRE consists of three core modules: (1) The Intent-Aware Prompt Engineering introduces multi-faceted knowledge and designs intent-aware <Prompt, Response> pairs that fine-tune LLMs to generate ads tailored to users' personal interests. (2) The Advertising-Specific Knowledge Alignment incorporates auxiliary fine-tuning tasks and Direct Preference Optimization (DPO) to align LLMs with ad semantic and business value. (3) The Efficient System Deployment deploys LEADRE in an online environment by integrating both latency-tolerant and latency-sensitive service. Extensive offline experiments demonstrate the effectiveness of LEADRE and validate the contributions of individual modules. Online A/B test shows that LEADRE leads to a 1.57% and 1.17% GMV lift for serviced users on WeChat Channels and Moments separately. LEADRE has been deployed on both platforms, serving tens of billions of requests each day.",
      "authors": [
        "Fengxin Li",
        "Yi Li",
        "Yue Liu",
        "Chao Zhou",
        "Yuan Wang",
        "Xiaoxiang Deng",
        "Wei Xue",
        "Dapeng Liu",
        "Lei Xiao",
        "Haijie Gu",
        "Jie Jiang",
        "Hongyan Liu",
        "Biao Qin",
        "Jun He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T02:22:35+00:00",
          "link": "https://arxiv.org/abs/2411.13789v1",
          "size": "1527kb",
          "version": "v1"
        },
        {
          "date": "2024-11-26T02:54:07+00:00",
          "link": "https://arxiv.org/abs/2411.13789v2",
          "size": "1527kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T07:09:05+00:00",
          "link": "https://arxiv.org/abs/2411.13789v3",
          "size": "781kb",
          "version": "v3"
        }
      ],
      "title": "LEADRE: Multi-Faceted Knowledge Enhanced LLM Empowered Display Advertisement Recommender System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13789",
        "HTML": "https://arxiv.org/html/2411.13789v3",
        "PDF": "https://arxiv.org/pdf/2411.13789"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a display advertisement recommender system using LLMs to enhance ad recommendation, with focus on model fine-tuning and deployment, but does not address reinforcement learning or related data processing techniques."
      },
      "tasks": [
        "Learning-To-Rank",
        "Prompt Engineering",
        "Recommendation Systems",
        "Retrieval",
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.14995",
      "abstract": "Learning STRIPS action models from action traces alone is a challenging problem as it involves learning the domain predicates as well. In this work, a novel approach is introduced which, like the well-known LOCM systems, is scalable, but like SAT approaches, is sound and complete. Furthermore, the approach is general and imposes no restrictions on the hidden domain or the number or arity of the predicates. The new learning method is based on an \\emph{efficient, novel test} that checks whether the assumption that a predicate is affected by a set of action patterns, namely, actions with specific argument positions, is consistent with the traces. The predicates and action patterns that pass the test provide the basis for the learned domain that is then easily completed with preconditions and static predicates. The new method is studied theoretically and experimentally. For the latter, the method is evaluated on traces and graphs obtained from standard classical domains like the 8-puzzle, which involve hundreds of thousands of states and transitions. The learned representations are then verified on larger instances.",
      "authors": [
        "Jonas G\\\"osgens",
        "Niklas Jansen",
        "Hector Geffner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T15:09:50+00:00",
          "link": "https://arxiv.org/abs/2411.14995v1",
          "size": "86kb",
          "version": "v1"
        },
        {
          "date": "2025-05-02T14:12:10+00:00",
          "link": "https://arxiv.org/abs/2411.14995v2",
          "size": "78kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T15:43:01+00:00",
          "link": "https://arxiv.org/abs/2411.14995v3",
          "size": "78kb",
          "version": "v3"
        }
      ],
      "title": "Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General, and Scalable Solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14995",
        "HTML": "https://arxiv.org/html/2411.14995v3",
        "PDF": "https://arxiv.org/pdf/2411.14995"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The work explores learning STRIPS models from action traces in AI planning, not addressing reinforcement learning or data processing within that context."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.17240",
      "abstract": "In this paper, we present DM-Calib, a diffusion-based approach for estimating pinhole camera intrinsic parameters from a single input image. Monocular camera calibration is essential for many 3D vision tasks. However, most existing methods depend on handcrafted assumptions or are constrained by limited training data, resulting in poor generalization across diverse real-world images. Recent advancements in stable diffusion models, trained on massive data, have shown the ability to generate high-quality images with varied characteristics. Emerging evidence indicates that these models implicitly capture the relationship between camera focal length and image content. Building on this insight, we explore how to leverage the powerful priors of diffusion models for monocular pinhole camera calibration. Specifically, we introduce a new image-based representation, termed Camera Image, which losslessly encodes the numerical camera intrinsics and integrates seamlessly with the diffusion framework. Using this representation, we reformulate the problem of estimating camera intrinsics as the generation of a dense Camera Image conditioned on an input image. By fine-tuning a stable diffusion model to generate a Camera Image from a single RGB input, we can extract camera intrinsics via a RANSAC operation. We further demonstrate that our monocular calibration method enhances performance across various 3D tasks, including zero-shot metric depth estimation, 3D metrology, pose estimation and sparse-view reconstruction. Extensive experiments on multiple public datasets show that our approach significantly outperforms baselines and provides broad benefits to 3D vision tasks.",
      "authors": [
        "Junyuan Deng",
        "Wei Yin",
        "Xiaoyang Guo",
        "Qian Zhang",
        "Xiaotao Hu",
        "Weiqiang Ren",
        "Xiaoxiao-Long",
        "Ping Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-26T09:04:37+00:00",
          "link": "https://arxiv.org/abs/2411.17240v1",
          "size": "48221kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:51:26+00:00",
          "link": "https://arxiv.org/abs/2411.17240v2",
          "size": "45640kb",
          "version": "v2"
        }
      ],
      "title": "Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17240",
        "HTML": "https://arxiv.org/html/2411.17240v2",
        "PDF": "https://arxiv.org/pdf/2411.17240"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a diffusion-based approach for monocular camera calibration and does not engage with reinforcement learning or its data processing aspects."
      },
      "tasks": [
        "3D Reconstruction",
        "Camera Calibration",
        "Depth Estimation",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/junyuandeng/dm-calib"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.05737",
      "abstract": "Blockchain enables novel, trustworthy Process-Aware Information Systems (PAISs) by enforcing the security, robustness, and traceability of operations. In particular, transparency ensures that all information exchanges are openly accessible, fostering trust within the system. Although this is a desirable property to enable notarization and auditing activities, it also represents a limitation for such cases where confidentiality is a requirement since interactions involve sensitive data. Current solutions rely on obfuscation techniques or private infrastructures, hindering the enforcement capabilities of smart contracts and the public verifiability of transactions. Against this background, we propose CONFETTY, an architecture for blockchain-based PAISs to preserve confidentiality and transparency. Smart contracts enact, enforce and store public interactions, while attribute-based encryption techniques are adopted to specify access grants to confidential information. We assess the security of our solution through a systematic threat model analysis and evaluate its practical feasibility by gauging the performance of our implemented prototype in different scenarios from the literature.",
      "authors": [
        "Alessandro Marcelletti and Edoardo Marangone and Michele Kryston and Claudio Di Ciccio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-07T20:18:36+00:00",
          "link": "https://arxiv.org/abs/2412.05737v1",
          "size": "1511kb",
          "version": "v1"
        },
        {
          "date": "2024-12-13T15:55:31+00:00",
          "link": "https://arxiv.org/abs/2412.05737v2",
          "size": "1511kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T09:18:34+00:00",
          "link": "https://arxiv.org/abs/2412.05737v3",
          "size": "536kb",
          "version": "v3"
        }
      ],
      "title": "Balancing Confidentiality and Transparency for Blockchain-based Process-Aware Information Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05737",
        "HTML": "https://arxiv.org/html/2412.05737v3",
        "PDF": "https://arxiv.org/pdf/2412.05737"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The work elaborates on blockchain-based process-aware systems and confidentiality, with no connection to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.06771",
      "abstract": "User prompts for generative AI models are often underspecified, leading to a misalignment between the user intent and models' understanding. As a result, users commonly have to painstakingly refine their prompts. We study this alignment problem in text-to-image (T2I) generation and propose a prototype for proactive T2I agents equipped with an interface to (1) actively ask clarification questions when uncertain, and (2) present their uncertainty about user intent as an understandable and editable belief graph. We build simple prototypes for such agents and propose a new scalable and automated evaluation approach using two agents, one with a ground truth intent (an image) while the other tries to ask as few questions as possible to align with the ground truth. We experiment over three image-text datasets: ImageInWords (Garg et al., 2024), COCO (Lin et al., 2014) and DesignBench, a benchmark we curated with strong artistic and design elements. Experiments over the three datasets demonstrate the proposed T2I agents' ability to ask informative questions and elicit crucial information to achieve successful alignment with at least 2 times higher VQAScore (Lin et al., 2024) than the standard T2I generation. Moreover, we conducted human studies and observed that at least 90% of human subjects found these agents and their belief graphs helpful for their T2I workflow, highlighting the effectiveness of our approach. Code and DesignBench can be found at https://github.com/google-deepmind/proactive_t2i_agents.",
      "authors": [
        "Meera Hahn",
        "Wenjun Zeng",
        "Nithish Kannen",
        "Rich Galt",
        "Kartikeya Badola",
        "Been Kim",
        "Zi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-09T18:56:32+00:00",
          "link": "https://arxiv.org/abs/2412.06771v1",
          "size": "17877kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:08:22+00:00",
          "link": "https://arxiv.org/abs/2412.06771v2",
          "size": "17371kb",
          "version": "v2"
        }
      ],
      "title": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06771",
        "HTML": "https://arxiv.org/html/2412.06771v2",
        "PDF": "https://arxiv.org/pdf/2412.06771"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces proactive agents for text-to-image generation involving user prompt clarification, which does not involve reinforcement learning or RL data processing aspects."
      },
      "tasks": [
        "Image Generation",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "repo_urls": [
        "https://github.com/google-deepmind/proactive_t2i_agents"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.07682",
      "abstract": "The inference cost of Large Language Models (LLMs) is a significant challenge due to their computational demands, specially on tasks requiring long outputs. However, natural language often contains redundancy, which presents an opportunity for optimization. We have observed that LLMs can generate distilled language-concise outputs that retain essential meaning, when prompted appropriately. We propose TRIM, a pipeline for saving computational cost in which a shorter distilled output from the LLM is reconstructed into a full narrative by a smaller model with lower inference costs. Our experiments show promising results, particularly in general knowledge domains with 20.58% saved tokens on average with tiny decrease in evaluation metrics, hinting that this approach can effectively balance efficiency and accuracy in language processing tasks.",
      "authors": [
        "Alfredo Garrach\\'on Ruiz and Tom\\'as de la Rosa and Daniel Borrajo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-10T17:13:35+00:00",
          "link": "https://arxiv.org/abs/2412.07682v1",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "2024-12-16T12:06:25+00:00",
          "link": "https://arxiv.org/abs/2412.07682v2",
          "size": "262kb",
          "version": "v2"
        },
        {
          "date": "2024-12-18T13:39:47+00:00",
          "link": "https://arxiv.org/abs/2412.07682v3",
          "size": "262kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T12:27:40+00:00",
          "link": "https://arxiv.org/abs/2412.07682v4",
          "size": "328kb",
          "version": "v4"
        }
      ],
      "title": "TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.07682",
        "HTML": "https://arxiv.org/html/2412.07682v4",
        "PDF": "https://arxiv.org/pdf/2412.07682"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a token reduction and inference modeling technique for language generation efficiency, absent of any reinforcement learning or data processing within such a context."
      },
      "tasks": [
        "General Knowledge",
        "Text Generation",
        "Token Reduction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.09869",
      "abstract": "In this paper, we present a Hoare-style logic for reasoning about quantum programs with classical variables. Our approach offers several improvements over previous work:\n  (1) Enhanced expressivity of the programming language: Our logic applies to quantum programs with classical variables that incorporate quantum arrays and parameterised quantum gates, which have not been addressed in previous research on quantum Hoare logic, either with or without classical variables.\n  (2) Intuitive correctness specifications: In our logic, preconditions and postconditions for quantum programs with classical variables are specified as a pair consisting of a classical first-order logical formula and a quantum predicate formula (possibly parameterised by classical variables). These specifications offer greater clarity and align more closely with the programmer's intuitive understanding of quantum and classical interactions.\n  (3) Simplified proof system: By introducing a novel idea in formulating a proof rule for reasoning about quantum measurements, along with (2), we develop a proof system for quantum programs that requires only minimal modifications to classical Hoare logic. Furthermore, this proof system can be effectively and conveniently combined with classical first-order logic to verify quantum programs with classical variables.\n  As a result, the learning curve for quantum program verification techniques is significantly reduced for those already familiar with classical program verification techniques, and existing tools for verifying classical programs can be more easily adapted for quantum program verification.",
      "authors": [
        "Mingsheng Ying"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T05:28:19+00:00",
          "link": "https://arxiv.org/abs/2412.09869v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T23:41:38+00:00",
          "link": "https://arxiv.org/abs/2412.09869v2",
          "size": "42kb",
          "version": "v2"
        }
      ],
      "title": "A Practical Quantum Hoare Logic with Classical Variables, I",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09869",
        "PDF": "https://arxiv.org/pdf/2412.09869"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum Hoare logic for reasoning about quantum programs with classical variables, and does not address data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.10543",
      "abstract": "RAG (Retrieval Augmented Generation) allows LLMs (large language models) to generate better responses with external knowledge, but using more external knowledge often improves generation quality at the expense of response delay. Prior work either reduces the response delay (through better scheduling of RAG queries) or strives to maximize quality (which involves tuning the RAG workflow), but they fall short in optimizing the tradeoff between the delay and quality of RAG responses. This paper presents METIS, the first RAG system that jointly schedules queries and adapts the key RAG configurations of each query, such as the number of retrieved text chunks and synthesis methods, in order to balance quality optimization and response delay reduction. Using 4 popular RAG-QA datasets, we show that compared with the state-of-the-art RAG optimization schemes, METIS reduces the generation latency by $1.64-2.54\\times$ without sacrificing generation quality.",
      "authors": [
        "Siddhant Ray",
        "Rui Pan",
        "Zhuohan Gu",
        "Kuntai Du",
        "Shaoting Feng",
        "Ganesh Ananthanarayanan",
        "Ravi Netravali",
        "Junchen Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T20:39:30+00:00",
          "link": "https://arxiv.org/abs/2412.10543v1",
          "size": "2192kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:02:57+00:00",
          "link": "https://arxiv.org/abs/2412.10543v2",
          "size": "963kb",
          "version": "v2"
        }
      ],
      "title": "METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10543",
        "HTML": "https://arxiv.org/html/2412.10543v2",
        "PDF": "https://arxiv.org/pdf/2412.10543"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimization in Retrieval Augmented Generation (RAG) systems for processing queries in large language models, which is not related to reinforcement learning data processing or curation."
      },
      "tasks": [
        "RAG",
        "Retrieval-augmented Generation",
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.18375",
      "abstract": "This article addresses theory in evolutionary many-objective optimization and focuses on the role of crossover operators. The advantages of using crossover are hardly understood and rigorous runtime analyses with crossover are lagging far behind its use in practice, specifically in the case of more than two objectives. We present two many-objective problems $RR_{\\text{RO}}$ and $uRR_{\\text{RO}}$ together with a theoretical runtime analysis of the GSEMO and the widely used NSGA-III algorithm to demonstrate that one point crossover on $RR_{\\text{RO}}$, as well as uniform crossover on $uRR_{\\text{RO}}$, can yield an exponential speedup in the runtime. In particular, when the number of objectives is constant, this algorithms can find the Pareto set of both problems in expected polynomial time when using crossover while without crossover they require exponential time to even find a single Pareto-optimal point. For both problems, we also demonstrate a significant performance gap in certain superconstant parameter regimes for the number of objectives. To the best of our knowledge, this is one of the first rigorous runtime analysis in many-objective optimization which demonstrates an exponential performance gap when using crossover for more than two objectives. Additionally, it is the first runtime analysis involving crossover in many-objective optimization where the number of objectives is not necessarily constant.",
      "authors": [
        "Andre Opris"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T12:00:37+00:00",
          "link": "https://arxiv.org/abs/2412.18375v1",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T22:04:08+00:00",
          "link": "https://arxiv.org/abs/2412.18375v2",
          "size": "221kb",
          "version": "v2"
        }
      ],
      "title": "Many Objective Problems Where Crossover is Provably Essential",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18375",
        "HTML": "https://arxiv.org/html/2412.18375v2",
        "PDF": "https://arxiv.org/pdf/2412.18375"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses theoretical aspects of evolutionary many-objective optimization involving crossover operations, without any reference or technical contribution to data processing in reinforcement learning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.19819",
      "abstract": "Recent advancements in large language models (LLMs) have expanded their application across various domains, including chip design, where domain-adapted chip models like ChipNeMo have emerged. However, these models often struggle with instruction alignment, a crucial capability for LLMs that involves following explicit human directives. This limitation impedes the practical application of chip LLMs, including serving as assistant chatbots for hardware design engineers. In this work, we introduce ChipAlign, a novel approach that utilizes a training-free model merging strategy, combining the strengths of a general instruction-aligned LLM with a chip-specific LLM. By considering the underlying manifold in the weight space, ChipAlign employs geodesic interpolation to effectively fuse the weights of input LLMs, producing a merged model that inherits strong instruction alignment and chip expertise from the respective instruction and chip LLMs. Our results demonstrate that ChipAlign significantly enhances instruction-following capabilities of existing chip LLMs, achieving up to a 26.6% improvement on the IFEval benchmark, while maintaining comparable expertise in the chip domain. This improvement in instruction alignment also translates to notable gains in instruction-involved QA tasks, delivering performance enhancements of 3.9% on the OpenROAD QA benchmark and 8.25% on production-level chip QA benchmarks, surpassing state-of-the-art baselines.",
      "authors": [
        "Chenhui Deng",
        "Yunsheng Bai",
        "Haoxing Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-15T04:21:24+00:00",
          "link": "https://arxiv.org/abs/2412.19819v1",
          "size": "15136kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T21:47:40+00:00",
          "link": "https://arxiv.org/abs/2412.19819v2",
          "size": "1559kb",
          "version": "v2"
        }
      ],
      "title": "ChipAlign: Instruction Alignment in Large Language Models for Chip Design via Geodesic Interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19819",
        "HTML": "https://arxiv.org/html/2412.19819v2",
        "PDF": "https://arxiv.org/pdf/2412.19819"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on instruction alignment in large language models for chip design, using a model merging strategy and geodesic interpolation. It does not address any aspects of data processing in reinforcement learning."
      },
      "tasks": [
        "Instruction Following"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.00226",
      "abstract": "Large Language Models (LLMs) have demonstrated a remarkable ability to capture extensive world knowledge, yet how this is achieved without direct sensorimotor experience remains a fundamental puzzle. This study proposes a novel theoretical solution by introducing the Collective World Model hypothesis. We argue that an LLM does not learn a world model from scratch; instead, it learns a statistical approximation of a collective world model that is already implicitly encoded in human language through a society-wide process of embodied, interactive sense-making. To formalize this process, we introduce generative emergent communication (Generative EmCom), a framework built on the Collective Predictive Coding (CPC). This framework models the emergence of language as a process of decentralized Bayesian inference over the internal states of multiple agents. We argue that this process effectively creates an encoder-decoder structure at a societal scale: human society collectively encodes its grounded, internal representations into language, and an LLM subsequently decodes these symbols to reconstruct a latent space that mirrors the structure of the original collective representations. This perspective provides a principled, mathematical explanation for how LLMs acquire their capabilities. The main contributions of this paper are: 1) the formalization of the Generative EmCom framework, clarifying its connection to world models and multi-agent reinforcement learning, and 2) its application to interpret LLMs, explaining phenomena such as distributional semantics as a natural consequence of representation reconstruction. This work provides a unified theory that bridges individual cognitive development, collective language evolution, and the foundations of large-scale AI.",
      "authors": [
        "Tadahiro Taniguchi",
        "Ryo Ueda",
        "Tomoaki Nakamura",
        "Masahiro Suzuki",
        "Akira Taniguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-31T02:23:10+00:00",
          "link": "https://arxiv.org/abs/2501.00226v1",
          "size": "2194kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T04:59:12+00:00",
          "link": "https://arxiv.org/abs/2501.00226v2",
          "size": "1977kb",
          "version": "v2"
        }
      ],
      "title": "Generative Emergent Communication: Large Language Model is a Collective World Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00226",
        "HTML": "https://arxiv.org/html/2501.00226v2",
        "PDF": "https://arxiv.org/pdf/2501.00226"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper introduces a framework related to world models and multi-agent reinforcement learning, providing a theoretical perspective on how language models acquire capabilities. While it touches on RL-related topics, it does not focus on data processing in RL."
      },
      "tasks": [
        "Bayesian Inference",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "model",
        "Multi-agent Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.00691",
      "abstract": "Large language models (LLMs) have revolutionised many fields, with LLM-as-a-service (LLMSaaS) offering accessible, general-purpose solutions without costly task-specific training. In contrast to the widely studied prompt engineering for directly solving tasks (in vivo), this paper explores LLMs' potential for in-vitro applications: using LLM-generated labels to improve supervised training of mainstream models. We examine two strategies - (1) noisy label correction and (2) training data augmentation - in empathy computing, an emerging task to predict psychology-based questionnaire outcomes from inputs like textual narratives. Crowdsourced datasets in this domain often suffer from noisy labels that misrepresent underlying empathy. We show that replacing or supplementing these crowdsourced labels with LLM-generated labels, developed using psychology-based scale-aware prompts, achieves statistically significant accuracy improvements. Notably, the RoBERTa pre-trained language model (PLM) trained with noise-reduced labels yields a state-of-the-art Pearson correlation coefficient of 0.648 on the public NewsEmp benchmarks. This paper further analyses evaluation metric selection and demographic biases to help guide the future development of more equitable empathy computing models. Code and LLM-generated labels are available at https://github.com/hasan-rakibul/LLMPathy.",
      "authors": [
        "Md Rakibul Hasan",
        "Yue Yao",
        "Md Zakir Hossain",
        "Aneesh Krishna",
        "Imre Rudas",
        "Shafin Rahman",
        "Tom Gedeon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-01T01:06:58+00:00",
          "link": "https://arxiv.org/abs/2501.00691v1",
          "size": "3247kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:55:10+00:00",
          "link": "https://arxiv.org/abs/2501.00691v2",
          "size": "3316kb",
          "version": "v2"
        }
      ],
      "title": "Labels Generated by Large Language Models Help Measure People's Empathy in Vitro",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00691",
        "HTML": "https://arxiv.org/html/2501.00691v2",
        "PDF": "https://arxiv.org/pdf/2501.00691"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses using language models to generate labels for empathy prediction tasks. It explores data processing in the context of label generation and training data augmentation, but it does not relate to reinforcement learning."
      },
      "tasks": [
        "Data Augmentation",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Prompt Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01038",
      "abstract": "Integrated sensing and communication (ISAC) is emerging as a key enabler for vehicle-to-everything (V2X) systems. However, designing efficient beamforming schemes for ISAC signals to achieve accurate sensing and enhance communication performance in the dynamic and uncertain environments of V2X networks presents significant challenges. While artificial intelligence technologies offer promising solutions, the energy-intensive nature of neural networks imposes substantial burdens on communication infrastructures. To address these challenges, this work proposes an energy-efficient and intelligent ISAC system for V2X networks. Specifically, we first leverage a Markov Decision Process framework to model the dynamic and uncertain nature of V2X networks. This framework allows the roadside unit to develop beamforming schemes relying solely on its current sensing information, eliminating the need for numerous pilot signals and extensive CSI acquisition. We then introduce an advanced deep reinforcement learning (DRL) algorithm, enabling the joint optimization of beamforming and power allocation to guarantee both communication rate and sensing accuracy in dynamic and uncertain V2X scenario. To alleviate the energy demands of neural networks, we integrate spiking neural networks (SNNs) into the DRL algorithm. The event-driven, sparse spike-based processing of SNNs significantly improves energy efficiency while maintaining strong performance. Extensive simulation results validate the effectiveness of the proposed scheme with lower energy consumption, superior communication performance, and improved sensing accuracy.",
      "authors": [
        "Chen Shang",
        "Jiadong Yu",
        "Dinh Thai Hoang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T03:39:50+00:00",
          "link": "https://arxiv.org/abs/2501.01038v1",
          "size": "814kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:14:54+00:00",
          "link": "https://arxiv.org/abs/2501.01038v2",
          "size": "818kb",
          "version": "v2"
        }
      ],
      "title": "Energy-Efficient and Intelligent ISAC in V2X Networks with Spiking Neural Networks-Driven DRL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01038",
        "HTML": "https://arxiv.org/html/2501.01038v2",
        "PDF": "https://arxiv.org/pdf/2501.01038"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper proposes a deep reinforcement learning (DRL) algorithm integrated with spiking neural networks for beamforming and power allocation in V2X networks. It directly addresses data processing by using a Markov Decision Process framework to model data collection and preprocessing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03629",
      "abstract": "Medical image segmentation plays an important role in computer-aided diagnosis. Existing methods mainly utilize spatial attention to highlight the region of interest. However, due to limitations of medical imaging devices, medical images exhibit significant heterogeneity, posing challenges for segmentation. Ultrasound images, for instance, often suffer from speckle noise, low resolution, and poor contrast between target tissues and background, which may lead to inaccurate boundary delineation. To address these challenges caused by heterogeneous image quality, we propose a hybrid CNN-Transformer model,called CFFormer, which leverages effective channel feature extraction to enhance the model' s ability to accurately identify tissue regions by capturing rich contextual information. The proposed architecture contains two key components: the Cross Feature Channel Attention (CFCA) module and the X-Spatial Feature Fusion (XFF) module. The model incorporates dual encoders, with the CNN encoder focusing on capturing local features and the Transformer encoder modeling global features. The CFCA module filters and facilitates interactions between the channel features from the two encoders, while the XFF module effectively reduces the significant semantic information differences in spatial features, enabling a smooth and cohesive spatial feature fusion. We evaluate our model across eight datasets covering five modalities to test its generalization capability. Experimental results demonstrate that our model outperforms current state-of-the-art methods and maintains accurate tissue region segmentation across heterogeneous medical image datasets. The code is available at https://github.com/JiaxuanFelix/CFFormer.",
      "authors": [
        "Jiaxuan Li",
        "Qing Xu",
        "Xiangjian He",
        "Ziyu Liu",
        "Daokun Zhang",
        "Ruili Wang",
        "Rong Qu",
        "Guoping Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T08:59:20+00:00",
          "link": "https://arxiv.org/abs/2501.03629v1",
          "size": "10262kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T09:02:47+00:00",
          "link": "https://arxiv.org/abs/2501.03629v2",
          "size": "6652kb",
          "version": "v2"
        }
      ],
      "title": "CFFormer: Cross CNN-Transformer Channel Attention and Spatial Feature Fusion for Improved Segmentation of Heterogeneous Medical Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03629",
        "HTML": "https://arxiv.org/html/2501.03629v2",
        "PDF": "https://arxiv.org/pdf/2501.03629"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a hybrid CNN-Transformer model for medical image segmentation, focusing on feature extraction and fusion, without any reference to reinforcement learning or data processing within RL."
      },
      "tasks": [
        "Image Segmentation",
        "Medical Image Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.13916",
      "abstract": "We present Poisson Binomial Mechanism Vertical Federated Learning (PBM-VFL), a communication-efficient Vertical Federated Learning algorithm with Differential Privacy guarantees. PBM-VFL combines Secure Multi-Party Computation with the recently introduced Poisson Binomial Mechanism to protect parties' private datasets during model training. We define the novel concept of feature privacy and analyze end-to-end feature and sample privacy of our algorithm. We compare sample privacy loss in VFL with privacy loss in HFL. We also provide the first theoretical characterization of the relationship between privacy budget, convergence error, and communication cost in differentially-private VFL. Finally, we empirically show that our model performs well with high levels of privacy.",
      "authors": [
        "Linh Tran",
        "Timothy Castiglia",
        "Stacy Patterson",
        "Ana Milanova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T18:53:43+00:00",
          "link": "https://arxiv.org/abs/2501.13916v1",
          "size": "2576kb",
          "version": "v1"
        },
        {
          "date": "2025-01-27T19:50:52+00:00",
          "link": "https://arxiv.org/abs/2501.13916v2",
          "size": "2576kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T17:27:54+00:00",
          "link": "https://arxiv.org/abs/2501.13916v3",
          "size": "2598kb",
          "version": "v3"
        }
      ],
      "title": "PBM-VFL: Vertical Federated Learning with Feature and Sample Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13916",
        "HTML": "https://arxiv.org/html/2501.13916v3",
        "PDF": "https://arxiv.org/pdf/2501.13916"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper covers Poisson Binomial Mechanism for vertical federated learning and privacy, without any mention of reinforcement learning or data processing within RL."
      },
      "tasks": [
        "Federated Learning",
        "Vertical Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.13959",
      "abstract": "Formalized mathematics has recently garnered significant attention for its ability to assist mathematicians across various fields. Premise retrieval, as a common step in mathematical formalization, has been a challenge, particularly for inexperienced users. Existing retrieval methods that facilitate natural language queries require a certain level of mathematical expertise from users, while approaches based on formal languages (e.g., Lean) typically struggle with the scarcity of training data, hindering the training of effective and generalizable retrieval models. In this work, we introduce a novel method that leverages data extracted from Mathlib to train a lightweight and effective premise retrieval model. In particular, the proposed model embeds queries (i.e., proof state provided by Lean) and premises in a latent space, featuring a tokenizer specifically trained on formal corpora. The model is learned in a contrastive learning framework, in which a fine-grained similarity calculation method and a re-ranking module are applied to enhance the retrieval performance. Experimental results demonstrate that our model outperforms existing baselines, achieving higher accuracy while maintaining a lower computational load. We have released an open-source search engine based on our retrieval model at https://premise-search.com/. The source code and the trained model can be found at https://github.com/ruc-ai4math/Premise-Retrieval.",
      "authors": [
        "Yicheng Tao",
        "Haotian Liu",
        "Shanwen Wang",
        "Hongteng Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T06:32:25+00:00",
          "link": "https://arxiv.org/abs/2501.13959v1",
          "size": "1852kb",
          "version": "v1"
        },
        {
          "date": "2025-03-06T13:51:24+00:00",
          "link": "https://arxiv.org/abs/2501.13959v2",
          "size": "1725kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T04:56:27+00:00",
          "link": "https://arxiv.org/abs/2501.13959v3",
          "size": "1084kb",
          "version": "v3"
        }
      ],
      "title": "Learning an Effective Premise Retrieval Model for Efficient Mathematical Formalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13959",
        "HTML": "https://arxiv.org/html/2501.13959v3",
        "PDF": "https://arxiv.org/pdf/2501.13959"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a premise retrieval model for mathematical formalization, which does not relate to reinforcement learning or data processing in the RL domain."
      },
      "models": [
        {
          "model_path": "ruc-ai4math/Lean_State_Search_Random",
          "downloads": "0",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ruc-ai4math/Lean_State_Search_Random"
        },
        {
          "model_path": "ruc-ai4math/LeanStateSearch2025.3",
          "downloads": "3",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ruc-ai4math/LeanStateSearch2025.3"
        }
      ],
      "datasets": [
        {
          "dataset_name": "ruc-ai4math/mathlib_handler_benchmark_410",
          "downloads": "155",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ruc-ai4math/mathlib_handler_benchmark_410"
        }
      ],
      "tasks": [
        "Contrastive Learning",
        "Re-Ranking",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/ruc-ai4math/premise-retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.15151",
      "abstract": "Spiking Neural Networks (SNNs) are the third generation of neural networks. They have gained widespread attention in object detection due to their low power consumption and biological interpretability. However, existing SNN-based object detection methods suffer from local firing saturation, where neurons in information-concentrated regions fire continuously throughout all time steps. This abnormal neuron firing pattern reduces the feature discrimination capability and detection accuracy, while also increasing the firing rates that prevent SNNs from achieving their potential energy efficiency. To address this problem, we propose SpikeDet, a novel spiking object detector that optimizes firing patterns for accurate and energy-efficient detection. Specifically, we design a spiking backbone network, MDSNet, which effectively adjusts the membrane synaptic input distribution at each layer, achieving better neuron firing patterns during spiking feature extraction. Additionally, to better utilize and preserve these high-quality backbone features, we introduce the Spiking Multi-direction Fusion Module (SMFM), which realizes multi-direction fusion of spiking features, enhancing the multi-scale detection capability of the model. Experimental results demonstrate that SpikeDet achieves superior performance. On the COCO 2017 dataset, it achieves 51.4% AP, outperforming previous SNN-based methods by 2.5% AP while requiring only half the power consumption. On object detection sub-tasks, including the GEN1 event-based dataset and the URPC 2019 underwater dataset, SpikeDet also achieves the best performance. Notably, on GEN1, our method achieves 47.6% AP, outperforming previous SNN-based methods by 7.2% AP with better energy efficiency.",
      "authors": [
        "Yimeng Fan",
        "Changsong Liu",
        "Mingyang Li",
        "Dongze Liu",
        "Yanyan Liu",
        "Wei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-25T09:24:14+00:00",
          "link": "https://arxiv.org/abs/2501.15151v1",
          "size": "5996kb",
          "version": "v1"
        },
        {
          "date": "2025-01-28T03:08:59+00:00",
          "link": "https://arxiv.org/abs/2501.15151v2",
          "size": "5996kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T10:09:55+00:00",
          "link": "https://arxiv.org/abs/2501.15151v3",
          "size": "9103kb",
          "version": "v3"
        }
      ],
      "title": "SpikeDet: Better Firing Patterns for Accurate and Energy-Efficient Object Detection with Spiking Neuron Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15151",
        "HTML": "https://arxiv.org/html/2501.15151v3",
        "PDF": "https://arxiv.org/pdf/2501.15151"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus is on Spiking Neural Networks for object detection, optimizing neuron firing patterns for energy efficiency. It does not relate to reinforcement learning or data processing in RL."
      },
      "tasks": [
        "object-detection",
        "Object Detection"
      ],
      "repo_urls": [
        "https://github.com/yimeng-fan/spikssd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.16605",
      "abstract": "Metadata management plays a critical role in data governance, resource discovery, and decision-making in the data-driven era. While traditional metadata approaches have primarily focused on organization, classification, and resource reuse, the integration of modern artificial intelligence (AI) technologies has significantly transformed these processes. This paper investigates both traditional and AI-driven metadata approaches by examining open-source solutions, commercial tools, and research initiatives. A comparative analysis of traditional and AI-driven metadata management methods is provided, highlighting existing challenges and their impact on next-generation datasets. The paper also presents an innovative AI-assisted metadata management framework designed to address these challenges. This framework leverages more advanced modern AI technologies to automate metadata generation, enhance governance, and improve the accessibility and usability of modern datasets. Finally, the paper outlines future directions for research and development, proposing opportunities to further advance metadata management in the context of AI-driven innovation and complex datasets.",
      "authors": [
        "Wenli Yang",
        "Rui Fu",
        "Muhammad Bilal Amin",
        "Byeong Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T00:44:38+00:00",
          "link": "https://arxiv.org/abs/2501.16605v1",
          "size": "823kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T00:44:19+00:00",
          "link": "https://arxiv.org/abs/2501.16605v2",
          "size": "1367kb",
          "version": "v2"
        }
      ],
      "title": "The Impact of Modern AI in Metadata Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16605",
        "PDF": "https://arxiv.org/pdf/2501.16605"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with metadata management using AI technologies, highlighting advances in data governance and usability. There is no mention of reinforcement learning or specific data processing techniques relevant to RL."
      },
      "tasks": [
        "Decision Making",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17965",
      "abstract": "Hyperbolic space naturally encodes hierarchical structures such as phylogenies (binary trees), where inward-bending geodesics reflect paths through least common ancestors, and the exponential growth of neighborhoods mirrors the super-exponential scaling of topologies. This scaling challenge limits the efficiency of Euclidean-based approximate inference methods. Motivated by the geometric connections between trees and hyperbolic space, we develop novel hyperbolic extensions of two sequential search algorithms: Combinatorial and Nested Combinatorial Sequential Monte Carlo (\\textsc{Csmc} and \\textsc{Ncsmc}). Our approach introduces consistent and unbiased estimators, along with variational inference methods (\\textsc{H-Vcsmc} and \\textsc{H-Vncsmc}), which outperform their Euclidean counterparts. Empirical results demonstrate improved speed, scalability and performance in high-dimensional phylogenetic inference tasks.",
      "authors": [
        "Alex Chen",
        "Philipe Chlenski",
        "Kenneth Munyuza",
        "Antonio Khalil Moretti",
        "Christian A. Naesseth",
        "Itsik Pe'er"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T20:02:16+00:00",
          "link": "https://arxiv.org/abs/2501.17965v1",
          "size": "576kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T20:00:09+00:00",
          "link": "https://arxiv.org/abs/2501.17965v2",
          "size": "1020kb",
          "version": "v2"
        }
      ],
      "title": "Variational Combinatorial Sequential Monte Carlo for Bayesian Phylogenetics in Hyperbolic Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17965",
        "HTML": "https://arxiv.org/html/2501.17965v2",
        "PDF": "https://arxiv.org/pdf/2501.17965"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with Bayesian phylogenetics in hyperbolic space using sequential Monte Carlo methods, which is outside the domain of reinforcement learning data processing."
      },
      "tasks": [
        "Variational Inference"
      ],
      "repo_urls": [
        "https://github.com/axchen7/vcsmc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.19034",
      "abstract": "Human Action Recognition (HAR) plays a crucial role in applications such as health monitoring, smart home automation, and human-computer interaction. While HAR has been extensively studied, action summarization using Wi-Fi and IMU signals in smart-home environments , which involves identifying and summarizing continuous actions, remains an emerging task. This paper introduces the novel XRF V2 dataset, designed for indoor daily activity Temporal Action Localization (TAL) and action summarization. XRF V2 integrates multimodal data from Wi-Fi signals, IMU sensors (smartphones, smartwatches, headphones, and smart glasses), and synchronized video recordings, offering a diverse collection of indoor activities from 16 volunteers across three distinct environments. To tackle TAL and action summarization, we propose the XRFMamba neural network, which excels at capturing long-term dependencies in untrimmed sensory sequences and achieves the best performance with an average mAP of 78.74, outperforming the recent WiFiTAD by 5.49 points in mAP@avg while using 35% fewer parameters. In action summarization, we introduce a new metric, Response Meaning Consistency (RMC), to evaluate action summarization performance. And it achieves an average Response Meaning Consistency (mRMC) of 0.802. We envision XRF V2 as a valuable resource for advancing research in human action localization, action forecasting, pose estimation, multimodal foundation models pre-training, synthetic data generation, and more. The data and code are available at https://github.com/aiotgroup/XRFV2.",
      "authors": [
        "Bo Lan",
        "Pei Li",
        "Jiaxi Yin",
        "Yunpeng Song",
        "Ge Wang",
        "Han Ding",
        "Jinsong Han",
        "Fei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T11:03:54+00:00",
          "link": "https://arxiv.org/abs/2501.19034v1",
          "size": "6945kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T04:20:58+00:00",
          "link": "https://arxiv.org/abs/2501.19034v2",
          "size": "5403kb",
          "version": "v2"
        }
      ],
      "title": "XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19034",
        "HTML": "https://arxiv.org/html/2501.19034v2",
        "PDF": "https://arxiv.org/pdf/2501.19034"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on human action recognition using a novel dataset and does not relate to data processing techniques specific to reinforcement learning."
      },
      "tasks": [
        "Action Localization",
        "Action Recognition",
        "Pose Estimation",
        "Synthetic Data Generation",
        "Temporal Action Localization"
      ],
      "repo_urls": [
        "https://github.com/aiotgroup/xrfv2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01912",
      "abstract": "The history of art has seen significant shifts in the manner in which artworks are created, making understanding of creative processes a central question in technical art history. In the Renaissance and Early Modern period, paintings were largely produced by master painters directing workshops of apprentices who often contributed to projects. The masters varied significantly in artistic and managerial styles, meaning different combinations of artists and implements might be seen both between masters and within workshops or even individual canvases. Information on how different workshops were managed and the processes by which artworks were created remains elusive. Machine learning methods have potential to unearth new information about artists' creative processes by extending the analysis of brushwork to a microscopic scale. Analysis of workshop paintings, however, presents a challenge in that documentation of the artists and materials involved is sparse, meaning external examples are not available to train networks to recognize their contributions. Here we present a novel machine learning approach we call pairwise assignment training for classifying heterogeneity (PATCH) that is capable of identifying individual artistic practice regimes with no external training data, or \"ground truth.\" The method achieves unsupervised results by supervised means, and outperforms both simple statistical procedures and unsupervised machine learning methods. We apply this method to two historical paintings by the Spanish Renaissance master, El Greco: The Baptism of Christ and Christ on the Cross with Landscape, and our findings regarding the former potentially challenge previous work that has assigned the painting to workshop members. Further, the results of our analyses create a measure of heterogeneity of artistic practice that can be used to characterize artworks across time and space.",
      "authors": [
        "Andrew Van Horn",
        "Lauryn Smith",
        "Mahamad Mahmoud",
        "Michael McMaster",
        "Clara Pinchbeck",
        "Ina Martin",
        "Andrew Lininger",
        "Anthony Ingrisano",
        "Adam Lowe",
        "Carlos Bayod",
        "Elizabeth Bolman",
        "Kenneth Singer",
        "Michael Hinczewski"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T01:05:12+00:00",
          "link": "https://arxiv.org/abs/2502.01912v1",
          "size": "17086kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T05:25:43+00:00",
          "link": "https://arxiv.org/abs/2502.01912v2",
          "size": "9923kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T06:59:50+00:00",
          "link": "https://arxiv.org/abs/2502.01912v3",
          "size": "9699kb",
          "version": "v3"
        }
      ],
      "title": "PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01912",
        "HTML": "https://arxiv.org/html/2502.01912v3",
        "PDF": "https://arxiv.org/pdf/2502.01912"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research addresses machine learning in the context of art history, applying unsupervised methods to analyze paintings, which is not relevant to reinforcement learning or data processing in RL."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.03132",
      "abstract": "This paper introduces the Safe Protective and Assistive Robot Kit (SPARK), a comprehensive benchmark designed to ensure safety in humanoid autonomy and teleoperation. Humanoid robots pose significant safety risks due to their physical capabilities of interacting with complex environments. The physical structures of humanoid robots further add complexity to the design of general safety solutions. To facilitate safe deployment of complex robot systems, SPARK can be used as a toolbox that comes with state-of-the-art safe control algorithms in a modular and composable robot control framework. Users can easily configure safety criteria and sensitivity levels to optimize the balance between safety and performance. To accelerate humanoid safety research and development, SPARK provides simulation benchmarks that compare safety approaches in a variety of environments, tasks, and robot models. Furthermore, SPARK allows quick deployment of synthesized safe controllers on real robots. For hardware deployment, SPARK supports Apple Vision Pro (AVP) or a Motion Capture System as external sensors, while offering interfaces for seamless integration with alternative hardware setups at the same time. This paper demonstrates SPARK's capability with both simulation experiments and case studies with a Unitree G1 humanoid robot. Leveraging these advantages of SPARK, users and researchers can significantly improve the safety of their humanoid systems as well as accelerate relevant research. The open source code is available at: https://github.com/intelligent-control-lab/spark.",
      "authors": [
        "Yifan Sun",
        "Rui Chen",
        "Kai S. Yun",
        "Yikuan Fang",
        "Sebin Jung",
        "Feihan Li",
        "Bowei Li",
        "Weiye Zhao",
        "and Changliu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T12:49:26+00:00",
          "link": "https://arxiv.org/abs/2502.03132v1",
          "size": "25997kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:15:36+00:00",
          "link": "https://arxiv.org/abs/2502.03132v2",
          "size": "20772kb",
          "version": "v2"
        }
      ],
      "title": "SPARK: A Modular Benchmark for Humanoid Robot Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03132",
        "PDF": "https://arxiv.org/pdf/2502.03132"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for humanoid robot safety, focusing on safe control algorithms and does not address data processing within the reinforcement learning context."
      },
      "repo_urls": [
        "https://github.com/intelligent-control-lab/spark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05111",
      "abstract": "Large Language Models (LLMs) are often asked to generate structured outputs that obey precise syntactic rules, such as code snippets or formatted data. Grammar-constrained decoding (GCD) can guarantee that LLM outputs matches such rules by masking out tokens that will provably lead to outputs that do not belong to a specified context-free grammar (CFG). To guarantee soundness, GCD algorithms have to compute how a given LLM subword tokenizer can align with the tokens used\n  by a given context-free grammar and compute token masks based on this information. Doing so efficiently is challenging and existing GCD algorithms require tens of minutes to preprocess common grammars. We present a new GCD algorithm together with an implementation that offers 17.71x faster offline preprocessing than existing approaches while preserving state-of-the-art efficiency in online mask computation.",
      "authors": [
        "Kanghee Park",
        "Timothy Zhou",
        "Loris D'Antoni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T17:35:17+00:00",
          "link": "https://arxiv.org/abs/2502.05111v1",
          "size": "121kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T21:10:27+00:00",
          "link": "https://arxiv.org/abs/2502.05111v2",
          "size": "126kb",
          "version": "v2"
        }
      ],
      "title": "Flexible and Efficient Grammar-Constrained Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05111",
        "HTML": "https://arxiv.org/html/2502.05111v2",
        "PDF": "https://arxiv.org/pdf/2502.05111"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents an optimized algorithm for grammar-constrained decoding in large language models, which does not pertain to any data processing aspects or applications within the field of reinforcement learning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.05668",
      "abstract": "We analyze the implicit bias of constant step stochastic subgradient descent (SGD). We consider the setting of binary classification with homogeneous neural networks - a large class of deep neural networks with ReLU-type activation functions such as MLPs and CNNs without biases. We interpret the dynamics of normalized SGD iterates as an Euler-like discretization of a conservative field flow that is naturally associated to the normalized classification margin. Owing to this interpretation, we show that normalized SGD iterates converge to the set of critical points of the normalized margin at late-stage training (i.e., assuming that the data is correctly classified with positive normalized margin). Up to our knowledge, this is the first extension of the analysis of Lyu and Li (2020) on the discrete dynamics of gradient descent to the nonsmooth and stochastic setting. Our main result applies to binary classification with exponential or logistic losses. We additionally discuss extensions to more general settings.",
      "authors": [
        "Sholom Schechtman and Nicolas Schreuder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T19:09:16+00:00",
          "link": "https://arxiv.org/abs/2502.05668v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T10:04:45+00:00",
          "link": "https://arxiv.org/abs/2502.05668v2",
          "size": "45kb",
          "version": "v2"
        }
      ],
      "title": "The late-stage training dynamics of (stochastic) subgradient descent on homogeneous neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05668",
        "HTML": "https://arxiv.org/html/2502.05668v2",
        "PDF": "https://arxiv.org/pdf/2502.05668"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research analyzes the dynamics of stochastic subgradient descent in neural networks for binary classification. It does not pertain to reinforcement learning or data processing within an RL context."
      },
      "tasks": [
        "Binary Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05843",
      "abstract": "Current object detectors excel at entity localization and classification, yet exhibit inherent limitations in event recognition capabilities. This deficiency arises from their architecture's emphasis on discrete object identification rather than modeling the compositional reasoning, inter-object correlations, and contextual semantics essential for comprehensive event understanding. To address this challenge, we present a novel framework that expands the capability of standard object detectors beyond mere object recognition to complex event understanding through LLM-guided symbolic reasoning. Our key innovation lies in bridging the semantic gap between object detection and event understanding without requiring expensive task-specific training. The proposed plug-and-play framework interfaces with any open-vocabulary detector while extending their inherent capabilities across architectures. At its core, our approach combines (i) a symbolic regression mechanism exploring relationship patterns among detected entities and (ii) a LLM-guided strategically guiding the search toward meaningful expressions. These discovered symbolic rules transform low-level visual perception into interpretable event understanding, providing a transparent reasoning path from objects to events with strong transferability across domains.We compared our training-free framework against specialized event recognition systems across diverse application domains. Experiments demonstrate that our framework enhances multiple object detector architectures to recognize complex events such as illegal fishing activities (75% AUROC, +8.36% improvement), construction safety violations (+15.77%), and abnormal crowd behaviors (+23.16%). Code is available at \\href{https://github.com/MAC-AutoML/SymbolicDet}{here}.",
      "authors": [
        "Yuhui Zeng",
        "Haoxiang Wu",
        "Wenjie Nie",
        "Xiawu Zheng",
        "Guangyao Chen",
        "Yunhang Shen",
        "Jun Peng",
        "Yonghong Tian",
        "Rongrong Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-09T10:30:54+00:00",
          "link": "https://arxiv.org/abs/2502.05843v1",
          "size": "1222kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T03:56:51+00:00",
          "link": "https://arxiv.org/abs/2502.05843v2",
          "size": "1222kb",
          "version": "v2"
        },
        {
          "date": "2025-03-24T12:22:37+00:00",
          "link": "https://arxiv.org/abs/2502.05843v3",
          "size": "1356kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T11:47:45+00:00",
          "link": "https://arxiv.org/abs/2502.05843v4",
          "size": "1290kb",
          "version": "v4"
        }
      ],
      "title": "From Objects to Events: Unlocking Complex Visual Understanding in Object Detectors via LLM-guided Symbolic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05843",
        "HTML": "https://arxiv.org/html/2502.05843v4",
        "PDF": "https://arxiv.org/pdf/2502.05843"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing the capabilities of object detectors using symbolic reasoning guided by large language models, without any direct mention or contribution related to data processing in reinforcement learning."
      },
      "tasks": [
        "object-detection",
        "Object Detection",
        "Symbolic Regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.09724",
      "abstract": "In many real-world applications of reinforcement learning (RL), deployed policies have varied impacts on different stakeholders, creating challenges in reaching consensus on how to effectively aggregate their preferences. Generalized $p$-means form a widely used class of social welfare functions for this purpose, with broad applications in fair resource allocation, AI alignment, and decision-making. This class includes well-known welfare functions such as Egalitarian, Nash, and Utilitarian welfare. However, selecting the appropriate social welfare function is challenging for decision-makers, as the structure and outcomes of optimal policies can be highly sensitive to the choice of $p$. To address this challenge, we study the concept of an $\\alpha$-approximate portfolio in RL, a set of policies that are approximately optimal across the family of generalized $p$-means for all $p \\in [-\\infty, 1]$. We propose algorithms to compute such portfolios and provide theoretical guarantees on the trade-offs among approximation factor, portfolio size, and computational efficiency. Experimental results on synthetic and real-world datasets demonstrate the effectiveness of our approach in summarizing the policy space induced by varying $p$ values, empowering decision-makers to navigate this landscape more effectively.",
      "authors": [
        "Cheol Woo Kim",
        "Jai Moondra",
        "Shresth Verma",
        "Madeleine Pollack",
        "Lingkai Kong",
        "Milind Tambe",
        "Swati Gupta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T19:13:55+00:00",
          "link": "https://arxiv.org/abs/2502.09724v1",
          "size": "1999kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:43:06+00:00",
          "link": "https://arxiv.org/abs/2502.09724v2",
          "size": "535kb",
          "version": "v2"
        }
      ],
      "title": "Navigating the Social Welfare Frontier: Portfolios for Multi-objective Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09724",
        "HTML": "https://arxiv.org/html/2502.09724v2",
        "PDF": "https://arxiv.org/pdf/2502.09724"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper proposes algorithms to compute $\\alpha$-approximate portfolios in reinforcement learning, involving the construction and optimization of policy portfolios, which directly impact how data is processed for multi-objective RL tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.10341",
      "abstract": "Modern language models are trained on large, unstructured datasets consisting of trillions of tokens and obtained by crawling the web. The unstructured nature makes it difficult to reason about their contents and develop systematic approaches to data curation. In this paper, we unpack monolithic web corpora by developing taxonomies of their contents and organizing them into domains. We introduce WebOrganizer, a framework for organizing web pages in terms of both their topic and format. Using these two complementary notions of domains, we automatically annotate pre-training data by distilling annotations from a large language model into efficient classifiers. This allows us to study how data from different domains should be mixed to improve models on downstream tasks, and we show that we can combine insights about effective topics and formats to further boost performance. We demonstrate that our domain mixing also improves existing methods that select data based on quality. Furthermore, we study and compare how quality-based methods will implicitly change the domain mixture. Overall, our work demonstrates that constructing and mixing domains provides a valuable complement to quality-based data curation methods, opening new avenues for effective and insightful pre-training data curation.",
      "authors": [
        "Alexander Wettig",
        "Kyle Lo",
        "Sewon Min",
        "Hannaneh Hajishirzi",
        "Danqi Chen",
        "Luca Soldaini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T18:02:37+00:00",
          "link": "https://arxiv.org/abs/2502.10341v1",
          "size": "282kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T23:09:12+00:00",
          "link": "https://arxiv.org/abs/2502.10341v2",
          "size": "307kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T07:09:29+00:00",
          "link": "https://arxiv.org/abs/2502.10341v3",
          "size": "307kb",
          "version": "v3"
        }
      ],
      "title": "Organize the Web: Constructing Domains Enhances Pre-Training Data Curation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10341",
        "HTML": "https://arxiv.org/html/2502.10341v3",
        "PDF": "https://arxiv.org/pdf/2502.10341"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper concentrates on organizing web corpora and enhancing language model pre-training via domain construction, unrelated to data processing in the context of reinforcement learning."
      },
      "models": [
        {
          "model_path": "WebOrganizer/TopicClassifier-NoURL",
          "downloads": "8396",
          "likes": "11",
          "trending_score": "1.0",
          "link": "https://huggingface.co/WebOrganizer/TopicClassifier-NoURL"
        },
        {
          "model_path": "WebOrganizer/TopicClassifier",
          "downloads": "29712",
          "likes": "13",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/TopicClassifier"
        },
        {
          "model_path": "WebOrganizer/FormatClassifier-NoURL",
          "downloads": "12570",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/FormatClassifier-NoURL"
        },
        {
          "model_path": "WebOrganizer/FormatClassifier",
          "downloads": "5229",
          "likes": "7",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/FormatClassifier"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Baseline",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Baseline"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_HellaSwag",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_HellaSwag",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_HellaSwag",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_HellaSwag",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU_and_HellaSwag",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU_and_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU_and_Hellaswag",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU_and_Hellaswag",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU_and_Hellaswag",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-FineWebEdu",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-FineWebEdu"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-FineWebEdu_over_Topics_x_Formats_for_MMLU_and_Hellaswag",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-FineWebEdu_over_Topics_x_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-DCLMFasttext",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-DCLMFasttext"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-DCLMFasttext_over_Topics_x_Formats_for_MMLU_and_Hellaswag",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-DCLMFasttext_over_Topics_x_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "davanstrien/ModernBERT-web-topics-1m",
          "downloads": "40",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/davanstrien/ModernBERT-web-topics-1m"
        },
        {
          "model_path": "wissamantoun/WebOrganizer-FormatClassifier",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wissamantoun/WebOrganizer-FormatClassifier"
        },
        {
          "model_path": "wissamantoun/WebOrganizer-FormatClassifier-ModernBERT",
          "downloads": "4",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wissamantoun/WebOrganizer-FormatClassifier-ModernBERT"
        },
        {
          "model_path": "wissamantoun/WebOrganizer-TopicClassifier-ModernBERT",
          "downloads": "2",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wissamantoun/WebOrganizer-TopicClassifier-ModernBERT"
        }
      ],
      "datasets": [
        {
          "dataset_name": "WebOrganizer/TopicAnnotations-Llama-3.1-8B",
          "downloads": "83",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/TopicAnnotations-Llama-3.1-8B"
        },
        {
          "dataset_name": "WebOrganizer/TopicAnnotations-Llama-3.1-405B-FP8",
          "downloads": "56",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/TopicAnnotations-Llama-3.1-405B-FP8"
        },
        {
          "dataset_name": "WebOrganizer/FormatAnnotations-Llama-3.1-8B",
          "downloads": "73",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/FormatAnnotations-Llama-3.1-8B"
        },
        {
          "dataset_name": "WebOrganizer/FormatAnnotations-Llama-3.1-405B-FP8",
          "downloads": "39",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/FormatAnnotations-Llama-3.1-405B-FP8"
        },
        {
          "dataset_name": "WebOrganizer/Corpus-200B",
          "downloads": "5349",
          "likes": "8",
          "link": "https://huggingface.co/datasets/WebOrganizer/Corpus-200B"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.11078",
      "abstract": "To advance personalized applications such as recommendation systems and user behavior prediction, recent research increasingly adopts large language models (LLMs) for human -readable persona modeling. In dynamic real -world scenarios, effective persona modeling necessitates leveraging streaming behavior data to continually optimize user personas. However, existing methods -whether regenerating personas or incrementally extending them with new behaviors -often fail to achieve sustained improvements in persona quality or future behavior prediction accuracy. To address this, we propose DEEPER, a novel approach for dynamic persona modeling that enables continual persona optimization. Specifically, we enhance the model's direction -search capability through an iterative reinforcement learning framework, allowing it to automatically identify effective update directions and optimize personas using discrepancies between user behaviors and model predictions. Extensive experiments on dynamic persona modeling involving 4800 users across 10 domains highlight the superior persona optimization capabilities of DEEPER, delivering an impressive 32.2% average reduction in user behavior prediction error over four update rounds -outperforming the best baseline by a remarkable 22.92%.",
      "authors": [
        "Aili Chen",
        "Chengyu Du",
        "Jiangjie Chen",
        "Jinghan Xu",
        "Yikai Zhang",
        "Siyu Yuan",
        "Zulong Chen",
        "Liangyue Li",
        "Yanghua Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-16T11:02:37+00:00",
          "link": "https://arxiv.org/abs/2502.11078v1",
          "size": "517kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:26:24+00:00",
          "link": "https://arxiv.org/abs/2502.11078v2",
          "size": "512kb",
          "version": "v2"
        }
      ],
      "title": "DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11078",
        "HTML": "https://arxiv.org/html/2502.11078v2",
        "PDF": "https://arxiv.org/pdf/2502.11078"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper focuses on dynamic persona modeling using reinforcement learning techniques to optimize user personas but does not primarily contribute to data processing in RL, as it is more about model optimization and prediction improvement."
      },
      "tasks": [
        "Prediction",
        "Recommendation Systems"
      ],
      "repo_urls": [
        "https://github.com/sheep333c/deeper"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12272",
      "abstract": "Reinforcement learning is now widely adopted as the final stage of large language model training, especially for reasoning-style tasks such as maths problems. Typically, models attempt each question many times during a single training step and attempt to learn from their successes and failures. However, we demonstrate that throughout training with two popular algorithms (PPO and VinePPO) on two widely used datasets, many questions are either solved by all attempts - meaning they are already learned - or by none - providing no meaningful training signal. To address this, we adapt a method from the reinforcement learning literature - sampling for learnability - and apply it to the reinforcement learning stage of LLM training. Our curriculum prioritises questions with high variance of success, i.e. those where the agent sometimes succeeds, but not always. Our findings demonstrate that this curriculum consistently boosts training performance across multiple algorithms and datasets, paving the way for more efficient and effective reinforcement learning with LLMs.",
      "authors": [
        "Thomas Foster",
        "Jakob Foerster"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T19:16:37+00:00",
          "link": "https://arxiv.org/abs/2502.12272v1",
          "size": "601kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T23:01:25+00:00",
          "link": "https://arxiv.org/abs/2502.12272v2",
          "size": "597kb",
          "version": "v2"
        },
        {
          "date": "2025-02-24T18:15:02+00:00",
          "link": "https://arxiv.org/abs/2502.12272v3",
          "size": "597kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T10:34:26+00:00",
          "link": "https://arxiv.org/abs/2502.12272v4",
          "size": "14030kb",
          "version": "v4"
        }
      ],
      "title": "Learning to Reason at the Frontier of Learnability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12272",
        "PDF": "https://arxiv.org/pdf/2502.12272"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper directly addresses data processing by adapting sampling strategies from RL literature to prioritize learning from questions with high success variance, improving data efficiency and effectiveness in the RL stage of language model training."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12567",
      "abstract": "Recently, the transfer application of diffusion models in super-resolu-tion tasks has faced the problem ofdecreased fidelity. Due to the inherent randomsampling characteristics ofdiffusion models, direct application in super-resolu-tion tasks can result in generated details deviating from the true distribution ofhigh-resolution images. To address this, we propose DeltaDiff, a novel frame.work that constrains the difusion process, its essence is to establish a determin-istic mapping path between HR and LR, rather than the random noise disturbanceprocess oftraditional difusion models. Theoretical analysis demonstrates a 25%reduction in diffusion entropy in the residual space compared to pixel-space diffiusion, effectively suppressing irrelevant noise interference. The experimentalresults show that our method surpasses state-of-the-art models and generates re-sults with better fidelity. This work establishes a new low-rank constrained par-adigm for applying diffusion models to image reconstruction tasks, balancingstochastic generation with structural fidelity. Our code and model are publiclyavailable at https://github.com/continueyang/DeltaDiff .",
      "authors": [
        "Chao Yang",
        "Yong Fan",
        "Qichao Zhang",
        "Cheng Lu and Zhijing Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T06:07:14+00:00",
          "link": "https://arxiv.org/abs/2502.12567v1",
          "size": "2671kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:33:10+00:00",
          "link": "https://arxiv.org/abs/2502.12567v2",
          "size": "3000kb",
          "version": "v2"
        }
      ],
      "title": "DeltaDiff: Reality-Driven Diffusion with AnchorResiduals for Faithful SR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12567",
        "PDF": "https://arxiv.org/pdf/2502.12567"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces DeltaDiff for enhancing fidelity in image super-resolution using diffusion models, with no discussion related to data processing in reinforcement learning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12937",
      "abstract": "Graph-based semi-supervised learning is a powerful paradigm in machine learning for modeling and exploiting the underlying graph structure that captures the relationship between labeled and unlabeled data. A large number of classical as well as modern deep learning based algorithms have been proposed for this problem, often having tunable hyperparameters. We initiate a formal study of tuning algorithm hyperparameters from parameterized algorithm families for this problem. We obtain novel $O(\\log n)$ pseudo-dimension upper bounds for hyperparameter selection in three classical label propagation-based algorithm families, where $n$ is the number of nodes, implying bounds on the amount of data needed for learning provably good parameters. We further provide matching $\\Omega(\\log n)$ pseudo-dimension lower bounds, thus asymptotically characterizing the learning-theoretic complexity of the parameter tuning problem. We extend our study to selecting architectural hyperparameters in modern graph neural networks. We bound the Rademacher complexity for tuning the self-loop weighting in recently proposed Simplified Graph Convolution (SGC) networks. We further propose a tunable architecture that interpolates graph convolutional neural networks (GCN) and graph attention networks (GAT) in every layer, and provide Rademacher complexity bounds for tuning the interpolation coefficient.",
      "authors": [
        "Ally Yalei Du",
        "Eric Huang",
        "Dravyansh Sharma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T15:16:23+00:00",
          "link": "https://arxiv.org/abs/2502.12937v1",
          "size": "428kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:42:07+00:00",
          "link": "https://arxiv.org/abs/2502.12937v2",
          "size": "431kb",
          "version": "v2"
        }
      ],
      "title": "Tuning Algorithmic and Architectural Hyperparameters in Graph-Based Semi-Supervised Learning with Provable Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12937",
        "HTML": "https://arxiv.org/html/2502.12937v2",
        "PDF": "https://arxiv.org/pdf/2502.12937"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with hyperparameter tuning in graph-based semi-supervised learning and does not address data processing in reinforcement learning specifically, focusing instead on hyperparameter selection complexity."
      },
      "tasks": [
        "Graph Attention"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13497",
      "abstract": "Generative large language models (LLMs) have demonstrated gaps in diverse cultural awareness across the globe. We investigate the effect of retrieval augmented generation and search-grounding techniques on LLMs' ability to display familiarity with various national cultures. Specifically, we compare the performance of standard LLMs, LLMs augmented with retrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs augmented with retrievals from a web search (i.e., search grounding) on multiple cultural awareness benchmarks. We find that search grounding significantly improves the LLM performance on multiple-choice benchmarks that test propositional knowledge (e.g., cultural norms, artifacts, and institutions), while KB grounding's effectiveness is limited by inadequate knowledge base coverage and a suboptimal retriever. However, search grounding also increases the risk of stereotypical judgments by language models and fails to improve evaluators' judgments of cultural familiarity in a human evaluation with adequate statistical power. These results highlight the distinction between propositional cultural knowledge and open-ended cultural fluency when it comes to evaluating LLMs' cultural awareness.",
      "authors": [
        "Piyawat Lertvittayakumjorn",
        "David Kinney",
        "Vinodkumar Prabhakaran",
        "Donald Martin Jr.",
        "Sunipa Dev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T07:29:58+00:00",
          "link": "https://arxiv.org/abs/2502.13497v1",
          "size": "7591kb",
          "version": "v1"
        },
        {
          "date": "2025-02-20T06:38:50+00:00",
          "link": "https://arxiv.org/abs/2502.13497v2",
          "size": "7229kb",
          "version": "v2"
        },
        {
          "date": "2025-06-16T20:58:21+00:00",
          "link": "https://arxiv.org/abs/2502.13497v3",
          "size": "7088kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T01:13:21+00:00",
          "link": "https://arxiv.org/abs/2502.13497v4",
          "size": "7088kb",
          "version": "v4"
        }
      ],
      "title": "Towards Geo-Culturally Grounded LLM Generations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13497",
        "HTML": "https://arxiv.org/html/2502.13497v4",
        "PDF": "https://arxiv.org/pdf/2502.13497"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLMs' cultural awareness using retrieval augmented generation and grounding techniques, which is not related to reinforcement learning or data processing within RL contexts."
      },
      "tasks": [
        "Multiple-choice",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14198",
      "abstract": "In this paper, we propose an integrated sensing and communication (ISAC) system enabled by movable antennas (MAs), which can dynamically adjust antenna positions to enhance both sensing and communication performance for future wireless networks. To characterize the benefits of MA-enabled ISAC systems, we first derive the Cram\\'er-Rao bound (CRB) for angle estimation error, which is then minimized for optimizing the antenna position vector (APV) and beamforming design, subject to a pre-defined signal-to-noise ratio (SNR) constraint to ensure the communication performance. In particular, for the case with receive MAs only, we provide a closed-form optimal antenna position solution, and show that employing MAs over conventional fixed-position antennas (FPAs) can achieve a sensing performance gain upper-bounded by 4.77 dB. On the other hand, for the case with transmit MAs only, we develop a boundary traversal breadth-first search (BT-BFS) algorithm to obtain the global optimal solution in the line-of-sight (LoS) channel scenario, along with a lower-complexity boundary traversal depth-first search (BT-DFS) algorithm to find a local optimal solution efficiently. While in the scenario with non-LoS (NLoS) channels, a majorization-minimization (MM) based Rosen's gradient projection (RGP) algorithm with an efficient initialization method is proposed to obtain stationary solutions for the considered problem, which can be extended to the general case with both transmit and receive MAs. Extensive numerical results are presented to verify the effectiveness of the proposed algorithms, and demonstrate the superiority of the considered MA-enabled ISAC system over conventional ISAC systems with FPAs in terms of sensing and communication performance trade-off.",
      "authors": [
        "Lebin Chen",
        "Ming-Min Zhao",
        "Min-Jian Zhao",
        "and Rui Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T02:05:23+00:00",
          "link": "https://arxiv.org/abs/2502.14198v1",
          "size": "573kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T02:49:08+00:00",
          "link": "https://arxiv.org/abs/2502.14198v2",
          "size": "19811kb",
          "version": "v2"
        }
      ],
      "title": "Antenna Position and Beamforming Optimization for Movable Antenna Enabled ISAC: Optimal Solutions and Efficient Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14198",
        "HTML": "https://arxiv.org/html/2502.14198v2",
        "PDF": "https://arxiv.org/pdf/2502.14198"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses antenna position and beamforming optimization for communication systems, specifically with ISAC, without any discussion of reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.15203",
      "abstract": "Integrating multiple personalized concepts into a single image has recently gained attention in text-to-image (T2I) generation. However, existing methods often suffer from performance degradation in complex scenes due to distortions in non-personalized regions and the need for additional fine-tuning, limiting their practicality. To address this issue, we propose FlipConcept, a novel approach that seamlessly integrates multiple personalized concepts into a single image without requiring additional tuning. We introduce guided appearance attention to enhance the visual fidelity of personalized concepts. Additionally, we introduce mask-guided noise mixing to protect non-personalized regions during concept integration. Lastly, we apply background dilution to minimize concept leakage, i.e., the undesired blending of personalized concepts with other objects in the image. In our experiments, we demonstrate that the proposed method, despite not requiring tuning, outperforms existing models in both single and multiple personalized concept inference. These results demonstrate the effectiveness and practicality of our approach for scalable, high-quality multi-concept personalization.",
      "authors": [
        "Young Beom Woo",
        "Sun Eung Kim",
        "Seong-Whan Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T04:37:18+00:00",
          "link": "https://arxiv.org/abs/2502.15203v1",
          "size": "35538kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T02:44:24+00:00",
          "link": "https://arxiv.org/abs/2502.15203v2",
          "size": "33263kb",
          "version": "v2"
        }
      ],
      "title": "FlipConcept: Tuning-Free Multi-Concept Personalization for Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15203",
        "HTML": "https://arxiv.org/html/2502.15203v2",
        "PDF": "https://arxiv.org/pdf/2502.15203"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with text-to-image generation and integration of personalized concepts without any relation to reinforcement learning or data processing in the context of RL."
      },
      "tasks": [
        "Attribute",
        "Image Generation",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15873",
      "abstract": "Policymakers increasingly use development cost and compute as proxies for AI capabilities and risks. Recent laws have introduced regulatory requirements that are contingent on specific thresholds. However, technical ambiguities in how to perform this accounting create loopholes that can undermine regulatory effectiveness. We propose seven principles for designing AI cost and compute accounting standards that (1) reduce opportunities for strategic gaming, (2) avoid disincentivizing responsible risk mitigation, and (3) enable consistent implementation across companies and jurisdictions.",
      "authors": [
        "Stephen Casper",
        "Luke Bailey",
        "Tim Schreier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T18:59:47+00:00",
          "link": "https://arxiv.org/abs/2502.15873v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:12:40+00:00",
          "link": "https://arxiv.org/abs/2502.15873v2",
          "size": "137kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T02:03:11+00:00",
          "link": "https://arxiv.org/abs/2502.15873v3",
          "size": "137kb",
          "version": "v3"
        }
      ],
      "title": "Practical Principles for AI Cost and Compute Accounting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15873",
        "HTML": "https://arxiv.org/html/2502.15873v3",
        "PDF": "https://arxiv.org/pdf/2502.15873"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses AI cost and compute accounting standards, which are not relevant to reinforcement learning or data processing for RL applications."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.16075",
      "abstract": "We establish the asymptotic implicit bias of gradient descent (GD) for generic non-homogeneous deep networks under exponential loss. Specifically, we characterize three key properties of GD iterates starting from a sufficiently small empirical risk, where the threshold is determined by a measure of the network's non-homogeneity. First, we show that a normalized margin induced by the GD iterates increases nearly monotonically. Second, we prove that while the norm of the GD iterates diverges to infinity, the iterates themselves converge in direction. Finally, we establish that this directional limit satisfies the Karush-Kuhn-Tucker (KKT) conditions of a margin maximization problem. Prior works on implicit bias have focused exclusively on homogeneous networks; in contrast, our results apply to a broad class of non-homogeneous networks satisfying a mild near-homogeneity condition. In particular, our results apply to networks with residual connections and non-homogeneous activation functions, thereby resolving an open problem posed by Ji and Telgarsky (2020).",
      "authors": [
        "Yuhang Cai",
        "Kangjie Zhou",
        "Jingfeng Wu",
        "Song Mei",
        "Michael Lindsey",
        "Peter L. Bartlett"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T04:40:45+00:00",
          "link": "https://arxiv.org/abs/2502.16075v1",
          "size": "109kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T22:56:02+00:00",
          "link": "https://arxiv.org/abs/2502.16075v2",
          "size": "126kb",
          "version": "v2"
        }
      ],
      "title": "Implicit Bias of Gradient Descent for Non-Homogeneous Deep Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16075",
        "PDF": "https://arxiv.org/pdf/2502.16075"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the implicit bias of gradient descent in non-homogeneous networks, without discussing any aspects related to data processing in reinforcement learning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.16994",
      "abstract": "Recent advances in mechanistic interpretability have highlighted the potential of automating interpretability pipelines in analyzing the latent representations within LLMs. While this may enhance our understanding of internal mechanisms, the field lacks standardized evaluation methods for assessing the validity of discovered features. We attempt to bridge this gap by introducing FADE: Feature Alignment to Description Evaluation, a scalable model-agnostic framework for automatically evaluating feature-to-description alignment. FADE evaluates alignment across four key metrics - Clarity, Responsiveness, Purity, and Faithfulness - and systematically quantifies the causes of the misalignment between features and their descriptions. We apply FADE to analyze existing open-source feature descriptions and assess key components of automated interpretability pipelines, aiming to enhance the quality of descriptions. Our findings highlight fundamental challenges in generating feature descriptions, particularly for SAEs compared to MLP neurons, providing insights into the limitations and future directions of automated interpretability. We release FADE as an open-source package at: https://github.com/brunibrun/FADE",
      "authors": [
        "Bruno Puri",
        "Aakriti Jain",
        "Elena Golimblevskaia",
        "Patrick Kahardipraja",
        "Thomas Wiegand",
        "Wojciech Samek",
        "Sebastian Lapuschkin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T09:28:35+00:00",
          "link": "https://arxiv.org/abs/2502.16994v1",
          "size": "8813kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:35:23+00:00",
          "link": "https://arxiv.org/abs/2502.16994v2",
          "size": "8889kb",
          "version": "v2"
        }
      ],
      "title": "FADE: Why Bad Descriptions Happen to Good Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16994",
        "HTML": "https://arxiv.org/html/2502.16994v2",
        "PDF": "https://arxiv.org/pdf/2502.16994"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses a framework called FADE for automating interpretability pipelines, with no mention of reinforcement learning or data processing in the RL context."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/brunibrun/fade"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17066",
      "abstract": "Significant efforts have been directed towards adapting self-supervised multimodal learning for Earth observation applications. However, most current methods produce coarse patch-sized embeddings, limiting their effectiveness and integration with other modalities like LiDAR. To close this gap, we present DUNIA, an approach to learn pixel-sized embeddings through cross-modal alignment between images and full-waveform LiDAR data. As the model is trained in a contrastive manner, the embeddings can be directly leveraged in the context of a variety of environmental monitoring tasks in a zero-shot setting. In our experiments, we demonstrate the effectiveness of the embeddings for seven such tasks: canopy height mapping, fractional canopy cover, land cover mapping, tree species identification, plant area index, crop type classification, and per-pixel waveform-based vertical structure mapping. The results show that the embeddings, along with zero-shot classifiers, often outperform specialized supervised models, even in low-data regimes. In the fine-tuning setting, we show strong performances near or better than the state-of-the-art on five out of six tasks.",
      "authors": [
        "Ibrahim Fayad",
        "Max Zimmer",
        "Martin Schwartz",
        "Fabian Gieseke",
        "Philippe Ciais",
        "Gabriel Belouze",
        "Sarah Brood",
        "Aurelien De Truchis",
        "Alexandre d'Aspremont"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T11:28:00+00:00",
          "link": "https://arxiv.org/abs/2502.17066v1",
          "size": "28050kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:16:15+00:00",
          "link": "https://arxiv.org/abs/2502.17066v2",
          "size": "19031kb",
          "version": "v2"
        }
      ],
      "title": "DUNIA: Pixel-Sized Embeddings via Cross-Modal Alignment for Earth Observation Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17066",
        "HTML": "https://arxiv.org/html/2502.17066v2",
        "PDF": "https://arxiv.org/pdf/2502.17066"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study presents DUNIA, a self-supervised learning method for Earth observation applications, focusing on cross-modal alignment and environmental monitoring, with no relevance to RL data processing."
      },
      "tasks": [
        "cross-modal alignment",
        "Earth Observation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17926",
      "abstract": "Traditional social media platforms, once envisioned as digital town squares, now face growing criticism over corporate control, content moderation, and privacy concerns. Events such as Twitter's acquisition (now X) and major policy changes have pushed users toward alternative platforms like Mastodon and Threads. However, this diversification has led to user dispersion and fragmented discussions across the walled gardens of social media platforms. To address these issues, federation protocols like ActivityPub have been adopted, with Mastodon leading efforts to build decentralized yet interconnected networks. In March 2024, Threads joined this federation by introducing its Fediverse Sharing service, which enables interactions such as posts, replies, and likes between Threads and Mastodon users as if on a unified platform. Building on this development, we study the interactions between 20,000+ Threads users and 20,000+ Mastodon users over a ten-month period. Our work lays the foundation for research on cross-platform interactions and federation-driven platform integration.",
      "authors": [
        "Ujun Jeong",
        "Alimohammad Beigi",
        "Anique Tahir",
        "Susan Xu Tang",
        "H. Russell Bernard",
        "and Huan Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T07:47:08+00:00",
          "link": "https://arxiv.org/abs/2502.17926v1",
          "size": "4454kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:35:38+00:00",
          "link": "https://arxiv.org/abs/2502.17926v2",
          "size": "2576kb",
          "version": "v2"
        }
      ],
      "title": "Fediverse Sharing: Cross-Platform Interaction Dynamics between Threads and Mastodon Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17926",
        "HTML": "https://arxiv.org/html/2502.17926v2",
        "PDF": "https://arxiv.org/pdf/2502.17926"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper examines user interactions across social media platforms like Threads and Mastodon, without any connection to reinforcement learning or data processing in RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.02445",
      "abstract": "Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions. To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce BRIDGE, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by up to 12% on MSE and 6% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.",
      "authors": [
        "Hao Li",
        "Yu-Hao Huang",
        "Chang Xu",
        "Viktor Schlegel",
        "Renhe Jiang",
        "Riza Batista-Navarro",
        "Goran Nenadic",
        "Jiang Bian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T09:40:00+00:00",
          "link": "https://arxiv.org/abs/2503.02445v1",
          "size": "9090kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T06:04:37+00:00",
          "link": "https://arxiv.org/abs/2503.02445v2",
          "size": "9090kb",
          "version": "v2"
        },
        {
          "date": "2025-05-06T16:32:17+00:00",
          "link": "https://arxiv.org/abs/2503.02445v3",
          "size": "9091kb",
          "version": "v3"
        },
        {
          "date": "2025-06-08T08:19:28+00:00",
          "link": "https://arxiv.org/abs/2503.02445v4",
          "size": "958kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T06:56:08+00:00",
          "link": "https://arxiv.org/abs/2503.02445v5",
          "size": "968kb",
          "version": "v5"
        }
      ],
      "title": "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02445",
        "HTML": "https://arxiv.org/html/2503.02445v5",
        "PDF": "https://arxiv.org/pdf/2503.02445"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses a framework for generating time-series data using text descriptions, which could have implications for data augmentation and synthetic data generation relevant to RL, but it doesn't directly address RL data processing."
      },
      "tasks": [
        "counterfactual",
        "Data Augmentation",
        "Time Series",
        "Time Series Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04695",
      "abstract": "This work presents a novel formulation and numerical strategy for the simulation of geometrically nonlinear structures. First, a non-canonical Hamiltonian (Poisson) formulation is introduced by including the dynamics of the stress tensor. This framework is developed for von-K\\'arm\\'an nonlinearities in beams and plates, as well as geometrically nonlinear elasticity with Saint-Venant material behavior. In the case of plates, both negligible and non-negligible membrane inertia are considered. For the former case the two-dimensional elasticity complex is leveraged to express the dynamics in terms of the Airy stress function. The finite element discretization employs a mixed approach, combining a conforming approximation for displacement and velocity fields with a discontinuous stress tensor representation. A staggered, linear implicit time integration scheme is proposed, establishing connections with existing explicit-implicit energy-preserving methods. The stress degrees of freedom are statically condensed, reducing the computational complexity to solving a system with a positive definite matrix. The integration strategy preserves energy and angular momentum exactly. The methodology is validated through numerical experiments on the Duffing oscillator, a von-K\\'arm\\'an beam, and a column undergoing finite deformations. Comparisons with fully implicit energy-preserving method and the leapfrog scheme demonstrate that the proposed approach achieves superior accuracy while maintaining energy stability. Additionally, it enables larger time steps compared to explicit schemes and exhibits computational efficiency comparable to the leapfrog method.",
      "authors": [
        "Andrea Brugnoli",
        "Denis Matignon",
        "and Joseph Morlier"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T18:40:11+00:00",
          "link": "https://arxiv.org/abs/2503.04695v1",
          "size": "3891kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T18:13:43+00:00",
          "link": "https://arxiv.org/abs/2503.04695v2",
          "size": "23035kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T12:09:17+00:00",
          "link": "https://arxiv.org/abs/2503.04695v3",
          "size": "23020kb",
          "version": "v3"
        }
      ],
      "title": "A linearly-implicit energy-momentum preserving scheme for geometrically nonlinear mechanics based on non-canonical Hamiltonian formulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04695",
        "PDF": "https://arxiv.org/pdf/2503.04695"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on energy-momentum preserving schemes for nonlinear mechanics and doesn't touch upon reinforcement learning or data processing within that context."
      },
      "repo_urls": [
        "https://github.com/a-brugnoli/hamiltonian-geometrically-nonlinear-elasticity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06138",
      "abstract": "This paper introduces the System 0/1/2/3 framework as an extension of dual-process theory, employing a quad-process model of cognition. Expanding upon System 1 (fast, intuitive thinking) and System 2 (slow, deliberative thinking), we incorporate System 0, which represents pre-cognitive embodied processes, and System 3, which encompasses collective intelligence and symbol emergence. We contextualize this model within Bergson's philosophy by adopting multi-scale time theory to unify the diverse temporal dynamics of cognition. System 0 emphasizes morphological computation and passive dynamics, illustrating how physical embodiment enables adaptive behavior without explicit neural processing. Systems 1 and 2 are explained from a constructive perspective, incorporating neurodynamical and AI viewpoints. In System 3, we introduce collective predictive coding to explain how societal-level adaptation and symbol emergence operate over extended timescales. This comprehensive framework ranges from rapid embodied reactions to slow-evolving collective intelligence, offering a unified perspective on cognition across multiple timescales, levels of abstraction, and forms of human intelligence. The System 0/1/2/3 model provides a novel theoretical foundation for understanding the interplay between adaptive and cognitive processes, thereby opening new avenues for research in cognitive science, AI, robotics, and collective intelligence.",
      "authors": [
        "Tadahiro Taniguchi",
        "Yasushi Hirai",
        "Masahiro Suzuki",
        "Shingo Murata",
        "Takato Horii",
        "Kazutoshi Tanaka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T09:31:53+00:00",
          "link": "https://arxiv.org/abs/2503.06138v1",
          "size": "4058kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T23:45:53+00:00",
          "link": "https://arxiv.org/abs/2503.06138v2",
          "size": "4057kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T03:48:35+00:00",
          "link": "https://arxiv.org/abs/2503.06138v3",
          "size": "4326kb",
          "version": "v3"
        }
      ],
      "title": "System 0/1/2/3: Quad-process theory for multi-timescale embodied collective cognitive systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06138",
        "HTML": "https://arxiv.org/html/2503.06138v3",
        "PDF": "https://arxiv.org/pdf/2503.06138"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a theoretical framework for cognitive systems without mentioning reinforcement learning or data processing within this field."
      },
      "tasks": [
        "Philosophy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08384",
      "abstract": "Multiple Instance Learning (MIL) methods have succeeded remarkably in histopathology whole slide image (WSI) analysis. However, most MIL models only offer attention-based explanations that do not faithfully capture the model's decision mechanism and do not allow human-model interaction. To address these limitations, we introduce ProtoMIL, an inherently interpretable MIL model for WSI analysis that offers user-friendly explanations and supports human intervention. Our approach employs a sparse autoencoder to discover human-interpretable concepts from the image feature space, which are then used to train ProtoMIL. The model represents predictions as linear combinations of concepts, making the decision process transparent. Furthermore, ProtoMIL allows users to perform model interventions by altering the input concepts. Experiments on two widely used pathology datasets demonstrate that ProtoMIL achieves a classification performance comparable to state-of-the-art MIL models while offering intuitively understandable explanations. Moreover, we demonstrate that our method can eliminate reliance on diagnostically irrelevant information via human intervention, guiding the model toward being right for the right reason. Code will be publicly available at https://github.com/ss-sun/ProtoMIL.",
      "authors": [
        "Susu Sun",
        "Dominique van Midden",
        "Geert Litjens",
        "Christian F. Baumgartner"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T12:44:03+00:00",
          "link": "https://arxiv.org/abs/2503.08384v1",
          "size": "43709kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T09:15:00+00:00",
          "link": "https://arxiv.org/abs/2503.08384v2",
          "size": "40641kb",
          "version": "v2"
        }
      ],
      "title": "Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08384",
        "HTML": "https://arxiv.org/html/2503.08384v2",
        "PDF": "https://arxiv.org/pdf/2503.08384"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a MIL model for whole slide image analysis in histopathology, with no connection to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08506",
      "abstract": "Academic paper review is a critical yet time-consuming task within the research community. With the increasing volume of academic publications, automating the review process has become a significant challenge. The primary issue lies in generating comprehensive, accurate, and reasoning-consistent review comments that align with human reviewers' judgments. In this paper, we address this challenge by proposing ReviewAgents, a framework that leverages large language models (LLMs) to generate academic paper reviews. We first introduce a novel dataset, Review-CoT, consisting of 142k review comments, designed for training LLM agents. This dataset emulates the structured reasoning process of human reviewers-summarizing the paper, referencing relevant works, identifying strengths and weaknesses, and generating a review conclusion. Building upon this, we train LLM reviewer agents capable of structured reasoning using a relevant-paper-aware training method. Furthermore, we construct ReviewAgents, a multi-role, multi-LLM agent review framework, to enhance the review comment generation process. Additionally, we propose ReviewBench, a benchmark for evaluating the review comments generated by LLMs. Our experimental results on ReviewBench demonstrate that while existing LLMs exhibit a certain degree of potential for automating the review process, there remains a gap when compared to human-generated reviews. Moreover, our ReviewAgents framework further narrows this gap, outperforming advanced LLMs in generating review comments.",
      "authors": [
        "Xian Gao",
        "Jiacheng Ruan",
        "Zongyun Zhang",
        "Jingsheng Gao",
        "Ting Liu and Yuzhuo Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T14:56:58+00:00",
          "link": "https://arxiv.org/abs/2503.08506v1",
          "size": "580kb",
          "version": "v1"
        },
        {
          "date": "2025-05-22T13:02:31+00:00",
          "link": "https://arxiv.org/abs/2503.08506v2",
          "size": "9740kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T08:29:02+00:00",
          "link": "https://arxiv.org/abs/2503.08506v3",
          "size": "9475kb",
          "version": "v3"
        }
      ],
      "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08506",
        "HTML": "https://arxiv.org/html/2503.08506v3",
        "PDF": "https://arxiv.org/pdf/2503.08506"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses the automation of academic paper reviews using large language models, lacking any relation to reinforcement learning or data processing for RL."
      },
      "tasks": [
        "Comment Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.09174",
      "abstract": "This paper examines the number of communication modes, that is, the degrees of freedom (DoF) in a wireless line-of-sight channel comprising a small continuous linear intelligent antenna array in the near field of a large one. The framework allows for any orientations between the arrays and any positions in a two-dimensional space assuming that the transmitting array is placed at the origin. Therefore, apart from the length of the two continuous arrays, four key parameters determine the DoF and are hence considered in the analysis: the Cartesian coordinates of the center of the receiving array and two angles that model the rotation of each array around its center. The paper starts with the calculation of the deterministic DoF for a generic geometric setting, which extends beyond the widely studied paraxial case. Subsequently, a stochastic geometry framework is proposed to study the statistical DoF, as a first step towards the investigation of the system-level performance in near field networks. Numerical results applied to millimeter wave networks reveal the large number of DoF provided by near-field communications and unveil key system-level insights. A comparison of the proposed method with the singular value decomposition-based method is illustrated to validate the model.",
      "authors": [
        "Athanasios G. Kanatas",
        "Harris K. Armeniakos",
        "Harpreet S. Dhillon and Marco Di Renzo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T09:01:10+00:00",
          "link": "https://arxiv.org/abs/2503.09174v1",
          "size": "1670kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:38:10+00:00",
          "link": "https://arxiv.org/abs/2503.09174v2",
          "size": "1999kb",
          "version": "v2"
        }
      ],
      "title": "Deterministic and Statistical Analysis of the DoF of Continuous Linear Arrays in the Near Field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09174",
        "HTML": "https://arxiv.org/html/2503.09174v2",
        "PDF": "https://arxiv.org/pdf/2503.09174"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the degrees of freedom in wireless communication channels, with no indication of involvement with reinforcement learning or related data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11167",
      "abstract": "Decoding visual stimuli from neural activity is essential for understanding the human brain. While fMRI methods have successfully reconstructed static images, fMRI-to-video reconstruction faces challenges due to the need for capturing spatiotemporal dynamics like motion and scene transitions. Recent approaches have improved semantic and perceptual alignment but struggle to integrate coarse fMRI data with detailed visual features. Inspired by the hierarchical organization of the visual system, we propose NEURONS, a novel framework that decouples learning into four correlated sub-tasks: key object segmentation, concept recognition, scene description, and blurry video reconstruction. This approach simulates the visual cortex's functional specialization, allowing the model to capture diverse video content. In the inference stage, NEURONS generates robust conditioning signals for a pre-trained text-to-video diffusion model to reconstruct the videos. Extensive experiments demonstrate that NEURONS outperforms state-of-the-art baselines, achieving solid improvements in video consistency (26.6%) and semantic-level accuracy (19.1%). Notably, NEURONS shows a strong functional correlation with the visual cortex, highlighting its potential for brain-computer interfaces and clinical applications. Code and model weights are available at: https://github.com/xmed-lab/NEURONS.",
      "authors": [
        "Haonan Wang",
        "Qixiang Zhang",
        "Lehan Wang",
        "Xuanqi Huang",
        "Xiaomeng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T08:12:28+00:00",
          "link": "https://arxiv.org/abs/2503.11167v1",
          "size": "9318kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T14:53:40+00:00",
          "link": "https://arxiv.org/abs/2503.11167v2",
          "size": "9324kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T08:58:13+00:00",
          "link": "https://arxiv.org/abs/2503.11167v3",
          "size": "8863kb",
          "version": "v3"
        }
      ],
      "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11167",
        "HTML": "https://arxiv.org/html/2503.11167v3",
        "PDF": "https://arxiv.org/pdf/2503.11167"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Focused on fMRI-to-video reconstruction using a neural framework, the paper does not pertain to reinforcement learning or its data processing aspects."
      },
      "tasks": [
        "Semantic Segmentation",
        "Video Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/xmed-lab/neurons"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11579",
      "abstract": "State-of-the-art transformer-based large multimodal models (LMMs) struggle to handle hour-long video inputs due to the quadratic complexity of the causal self-attention operations, leading to high computational costs during training and inference. Existing token compression-based methods reduce the number of video tokens but often incur information loss and remain inefficient for extremely long sequences. In this paper, we explore an orthogonal direction to build a hybrid Mamba-Transformer model (VAMBA) that employs Mamba-2 blocks to encode video tokens with linear complexity. Without any token reduction, VAMBA can encode more than 1024 frames (640$\\times$360) on a single GPU, while transformer-based models can only encode 256 frames. On long video input, VAMBA achieves at least 50% reduction in GPU memory usage during training and inference, and nearly doubles the speed per training step compared to transformer-based LMMs. Our experimental results demonstrate that VAMBA improves accuracy by 4.3% on the challenging hour-long video understanding benchmark LVBench over prior efficient video LMMs, and maintains strong performance on a broad spectrum of long and short video understanding tasks.",
      "authors": [
        "Weiming Ren",
        "Wentao Ma",
        "Huan Yang",
        "Cong Wei",
        "Ge Zhang",
        "Wenhu Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T16:45:23+00:00",
          "link": "https://arxiv.org/abs/2503.11579v1",
          "size": "21749kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:39:44+00:00",
          "link": "https://arxiv.org/abs/2503.11579v2",
          "size": "21750kb",
          "version": "v2"
        }
      ],
      "title": "Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11579",
        "HTML": "https://arxiv.org/html/2503.11579v2",
        "PDF": "https://arxiv.org/pdf/2503.11579"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a hybrid model for efficient long video processing, without mentioning reinforcement learning or related data processing within RL."
      },
      "models": [
        {
          "model_path": "TIGER-Lab/Vamba-Qwen2-VL-7B",
          "downloads": "975",
          "likes": "16",
          "trending_score": "0.0",
          "link": "https://huggingface.co/TIGER-Lab/Vamba-Qwen2-VL-7B"
        }
      ],
      "tasks": [
        "Mamba",
        "Token Reduction",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12335",
      "abstract": "Accurate geometric surface reconstruction, providing essential environmental information for navigation and manipulation tasks, is critical for enabling robotic self-exploration and interaction. Recently, 3D Gaussian Splatting (3DGS) has gained significant attention in the field of surface reconstruction due to its impressive geometric quality and computational efficiency. While recent relevant advancements in novel view synthesis under inconsistent illumination using 3DGS have shown promise, the challenge of robust surface reconstruction under such conditions is still being explored. To address this challenge, we propose a method called GS-3I. Specifically, to mitigate 3D Gaussian optimization bias caused by underexposed regions in single-view images, based on Convolutional Neural Network (CNN), a tone mapping correction framework is introduced. Furthermore, inconsistent lighting across multi-view images, resulting from variations in camera settings and complex scene illumination, often leads to geometric constraint mismatches and deviations in the reconstructed surface. To overcome this, we propose a normal compensation mechanism that integrates reference normals extracted from single-view image with normals computed from multi-view observations to effectively constrain geometric inconsistencies. Extensive experimental evaluations demonstrate that GS-3I can achieve robust and accurate surface reconstruction across complex illumination scenarios, highlighting its effectiveness and versatility in this critical challenge. https://github.com/TFwang-9527/GS-3I",
      "authors": [
        "Tengfei Wang",
        "Xin Wang",
        "Yongmao Hou",
        "Zhaoning Zhang",
        "Yiwei Xu",
        "and Zongqian Zhan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-16T03:08:54+00:00",
          "link": "https://arxiv.org/abs/2503.12335v1",
          "size": "3930kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T07:03:21+00:00",
          "link": "https://arxiv.org/abs/2503.12335v2",
          "size": "3930kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T12:01:40+00:00",
          "link": "https://arxiv.org/abs/2503.12335v3",
          "size": "6143kb",
          "version": "v3"
        }
      ],
      "title": "GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from Illumination-Inconsistent Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12335",
        "HTML": "https://arxiv.org/html/2503.12335v3",
        "PDF": "https://arxiv.org/pdf/2503.12335"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on geometric surface reconstruction using 3D Gaussian Splatting, relevant to fields like computer vision and robotics but does not involve any aspects of reinforcement learning or data processing in RL contexts."
      },
      "tasks": [
        "3DGS",
        "Computational Efficiency",
        "Novel View Synthesis",
        "Surface Reconstruction",
        "Tone Mapping"
      ],
      "repo_urls": [
        "https://github.com/tfwang-9527/gs-3i"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12955",
      "abstract": "We propose a new task to benchmark human-in-scene understanding for embodied agents: Human-In-Scene Question Answering (HIS-QA). Given a human motion within a 3D scene, HIS-QA requires the agent to comprehend human states and behaviors, reason about its surrounding environment, and answer human-related questions within the scene. To support this new task, we present HIS-Bench, a multimodal benchmark that systematically evaluates HIS understanding across a broad spectrum, from basic perception to commonsense reasoning and planning. Our evaluation of various vision-language models on HIS-Bench reveals significant limitations in their ability to handle HIS-QA tasks. To this end, we propose HIS-GPT, the first foundation model for HIS understanding. HIS-GPT integrates 3D scene context and human motion dynamics into large language models while incorporating specialized mechanisms to capture human-scene interactions. Extensive experiments demonstrate that HIS-GPT sets a new state-of-the-art on HIS-QA tasks. We hope this work inspires future research on human behavior analysis in 3D scenes, advancing embodied AI and world models. The codes and data: https://github.com/ZJHTerry18/HumanInScene.",
      "authors": [
        "Jiahe Zhao",
        "Ruibing Hou",
        "Zejie Tian",
        "Hong Chang and Shiguang Shan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T09:10:50+00:00",
          "link": "https://arxiv.org/abs/2503.12955v1",
          "size": "8499kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:39:29+00:00",
          "link": "https://arxiv.org/abs/2503.12955v2",
          "size": "7974kb",
          "version": "v2"
        }
      ],
      "title": "HIS-GPT: Towards 3D Human-In-Scene Multimodal Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12955",
        "HTML": "https://arxiv.org/html/2503.12955v2",
        "PDF": "https://arxiv.org/pdf/2503.12955"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper proposes a benchmark and model for Human-In-Scene understanding, primarily targeting embodied AI and world model tasks. It does not discuss reinforcement learning or data processing techniques for RL."
      },
      "tasks": [
        "Question Answering",
        "Scene Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13026",
      "abstract": "The remarkable performance of large multimodal models (LMMs) has attracted significant interest from the image segmentation community. To align with the next-token-prediction paradigm, current LMM-driven segmentation methods either use object boundary points to represent masks or introduce special segmentation tokens, whose hidden states are decoded by a segmentation model requiring the original image as input. However, these approaches often suffer from inadequate mask representation and complex architectures, limiting the potential of LMMs. In this work, we propose the Hierarchical Mask Tokenizer (HiMTok), which represents segmentation masks with up to 32 tokens and eliminates the need for the original image during mask de-tokenization. HiMTok allows for compact and coarse-to-fine mask representations, aligning well with the LLM next-token-prediction paradigm and facilitating the direct acquisition of segmentation capabilities. We develop a 3-stage training recipe for progressive learning of segmentation and visual capabilities, featuring a hierarchical mask loss for effective coarse-to-fine learning. Additionally, we enable bidirectional information flow, allowing conversion between bounding boxes and mask tokens to fully leverage multi-task training potential. Extensive experiments demonstrate that our method achieves state-of-the-art performance across various segmentation tasks,while also enhancing visual grounding and maintaining overall visual understanding.",
      "authors": [
        "Tao Wang",
        "Changxu Cheng",
        "Lingfeng Wang",
        "Senda Chen",
        "Wuyue Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T10:29:08+00:00",
          "link": "https://arxiv.org/abs/2503.13026v1",
          "size": "21104kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:31:29+00:00",
          "link": "https://arxiv.org/abs/2503.13026v2",
          "size": "21046kb",
          "version": "v2"
        }
      ],
      "title": "HiMTok: Learning Hierarchical Mask Tokens for Image Segmentation with Large Multimodal Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13026",
        "HTML": "https://arxiv.org/html/2503.13026v2",
        "PDF": "https://arxiv.org/pdf/2503.13026"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses image segmentation using large multimodal models, focusing on mask representation and segmentation capabilities. It does not involve reinforcement learning or address data processing in RL."
      },
      "models": [
        {
          "model_path": "yayafengzi/InternVL2_5-HiMTok-8B",
          "downloads": "58",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/yayafengzi/InternVL2_5-HiMTok-8B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "yayafengzi/Mask_Perception",
          "downloads": "13",
          "likes": "0",
          "link": "https://huggingface.co/datasets/yayafengzi/Mask_Perception"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15237",
      "abstract": "Different annotators often assign different labels to the same sample due to backgrounds or preferences, and such labeling patterns are referred to as tendency. In multi-annotator scenarios, we introduce a novel task called Multi-annotator Tendency Learning (MATL), which aims to capture each annotator tendency. Unlike traditional tasks that prioritize consensus-oriented learning, which averages out annotator differences and leads to tendency information loss, MATL emphasizes learning each annotator tendency, better preserves tendency information. To this end, we propose an efficient baseline method, Query-based Multi-annotator Tendency Learning (QuMATL), which uses lightweight query to represent each annotator for tendency modeling. It saves the costs of building separate conventional models for each annotator, leverages shared learnable queries to capture inter-annotator correlations as an additional hidden supervisory signal to enhance modeling performance. Meanwhile, we provide a new metric, Difference of Inter-annotator Consistency (DIC), to evaluate how effectively models preserve annotators tendency information. Additionally, we contribute two large-scale datasets, STREET and AMER, providing averages of 4300 and 3118 per-annotator labels, respectively. Extensive experiments verified the effectiveness of our QuMATL.",
      "authors": [
        "Liyun Zhang",
        "Zheng Lian",
        "Hong Liu",
        "Takanori Takebe",
        "Yuta Nakashima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T14:14:57+00:00",
          "link": "https://arxiv.org/abs/2503.15237v1",
          "size": "3167kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T18:09:44+00:00",
          "link": "https://arxiv.org/abs/2503.15237v2",
          "size": "3014kb",
          "version": "v2"
        }
      ],
      "title": "QuMATL: Query-based Multi-annotator Tendency Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15237",
        "HTML": "https://arxiv.org/html/2503.15237v2",
        "PDF": "https://arxiv.org/pdf/2503.15237"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method and task for modeling annotator tendencies in multi-annotator settings. It does not mention reinforcement learning or data processing techniques relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.15426",
      "abstract": "Although Multimodal Large Language Models (MLLMs) excel at various image-related tasks, they encounter challenges in precisely aligning coordinates with spatial information within images, particularly in position-aware tasks such as visual grounding. This limitation arises from two key factors. First, MLLMs lack explicit spatial references, making it difficult to associate textual descriptions with precise image locations. Second, their feature extraction processes prioritize global context over fine-grained spatial details, leading to weak localization capability. To address these issues, we introduce VPP-LLaVA, an MLLM enhanced with Visual Position Prompt (VPP) to improve its grounding capability. VPP-LLaVA integrates two complementary mechanisms: the global VPP overlays a learnable, axis-like tensor onto the input image to provide structured spatial cues, while the local VPP incorporates position-aware queries to support fine-grained localization.To effectively train our model with spatial guidance, we further introduce VPP-SFT, a curated dataset of 0.6M high-quality visual grounding samples. Designed in a compact format, it enables efficient training and is significantly smaller than datasets used by other MLLMs (e.g., ~21M samples in MiniGPT-v2), yet still provides a strong performance boost. The resulting model, VPP-LLaVA, not only achieves state-of-the-art results on standard visual grounding benchmarks but also demonstrates strong zero-shot generalization to challenging unseen datasets. The code and dataset are available at https://github.com/WayneTomas/VPP-LLaVA.",
      "authors": [
        "Wei Tang",
        "Yanpeng Sun",
        "Qinying Gu",
        "Zechao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T17:08:13+00:00",
          "link": "https://arxiv.org/abs/2503.15426v1",
          "size": "7636kb",
          "version": "v1"
        },
        {
          "date": "2025-03-24T16:34:55+00:00",
          "link": "https://arxiv.org/abs/2503.15426v2",
          "size": "7637kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T08:04:49+00:00",
          "link": "https://arxiv.org/abs/2503.15426v3",
          "size": "14749kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T13:53:05+00:00",
          "link": "https://arxiv.org/abs/2503.15426v4",
          "size": "9580kb",
          "version": "v4"
        }
      ],
      "title": "Visual Position Prompt for MLLM based Visual Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15426",
        "HTML": "https://arxiv.org/html/2503.15426v4",
        "PDF": "https://arxiv.org/pdf/2503.15426"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper introduces the Visual Position Prompt for MLLMs with a curated dataset called VPP-SFT, involving visual grounding. While not RL-centric, the dataset curation aspect may have indirect implications for pretraining models that can aid RL tasks."
      },
      "models": [
        {
          "model_path": "wayneicloud/VPP-LLaVA-7b",
          "downloads": "34",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wayneicloud/VPP-LLaVA-7b"
        },
        {
          "model_path": "wayneicloud/VPP-LLaVA-13b",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wayneicloud/VPP-LLaVA-13b"
        }
      ],
      "datasets": [
        {
          "dataset_name": "wayneicloud/VPP-SFT",
          "downloads": "58",
          "likes": "0",
          "link": "https://huggingface.co/datasets/wayneicloud/VPP-SFT"
        }
      ],
      "tasks": [
        "Position",
        "Visual Grounding"
      ],
      "repo_urls": [
        "https://github.com/waynetomas/vpp-llava"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17070",
      "abstract": "Federated learning (FL) allows collaborative machine learning (ML) model training among decentralized clients' information, ensuring data privacy. The decentralized nature of FL deals with non-independent and identically distributed (non-IID) data. This open problem has notable consequences, such as decreased model performance and more significant convergence times. Despite its importance, experimental studies systematically addressing all types of data heterogeneity (a.k.a. non-IIDness) remain scarce. We aim to fill this gap by assessing and quantifying the non-IID effect through a thorough empirical analysis. We use the Hellinger Distance (HD) to measure differences in distribution among clients. Our study benchmarks four state-of-the-art strategies for handling non-IID data, including label, feature, quantity, and spatiotemporal skewness, under realistic and controlled conditions. This is the first comprehensive analysis of the spatiotemporal skew effect in FL. Our findings highlight the significant impact of label and spatiotemporal skew non-IID types on FL model performance, with notable performance drops occurring at specific HD thresholds. Additionally, the FL performance is heavily affected mainly when the non-IIDness is extreme. Thus, we provide recommendations for FL research to tackle data heterogeneity effectively. Our work represents the most extensive examination of non-IIDness in FL, offering a robust foundation for future research.",
      "authors": [
        "Daniel M. Jimenez-Gutierrez",
        "Mehrdad Hassanzadeh",
        "Aris Anagnostopoulos",
        "Ioannis Chatzigiannakis",
        "Andrea Vitaletti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T11:53:36+00:00",
          "link": "https://arxiv.org/abs/2503.17070v1",
          "size": "6320kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:02:29+00:00",
          "link": "https://arxiv.org/abs/2503.17070v2",
          "size": "545kb",
          "version": "v2"
        }
      ],
      "title": "A Thorough Assessment of the Non-IID Data Impact in Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17070",
        "HTML": "https://arxiv.org/html/2503.17070v2",
        "PDF": "https://arxiv.org/pdf/2503.17070"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper centers on federated learning and non-IID data effects, with no mention of reinforcement learning or data processing within that context."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17483",
      "abstract": "Mixed integer set representations, and specifically hybrid zonotopes, have enabled new techniques for reachability and verification of nonlinear and hybrid systems. Mixed-integer sets which have the property that their convex relaxation is equal to their convex hull are said to be sharp. This property allows the convex hull to be computed with minimal overhead, and is known to be important for improving the convergence rates of mixed-integer optimization algorithms that rely on convex relaxations. This paper examines methods for formulating sharp hybrid zonotopes and provides sharpness-preserving methods for performing several key set operations. The paper then shows how the reformulation-linearization technique can be applied to create a sharp realization of a hybrid zonotope that is initially not sharp. A numerical example applies this technique to find the convex hull of a level set of a feedforward ReLU neural network.",
      "authors": [
        "Jonah J. Glunt",
        "Joshua A. Robbins",
        "Jacob A. Siefert",
        "Daniel Silvestre",
        "and Herschel C. Pangborn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T18:53:25+00:00",
          "link": "https://arxiv.org/abs/2503.17483v1",
          "size": "314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:05:39+00:00",
          "link": "https://arxiv.org/abs/2503.17483v2",
          "size": "279kb",
          "version": "v2"
        }
      ],
      "title": "Sharp Hybrid Zonotopes: Set Operations and the Reformulation-linearization Technique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17483",
        "HTML": "https://arxiv.org/html/2503.17483v2",
        "PDF": "https://arxiv.org/pdf/2503.17483"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus is on sharp hybrid zonotopes for optimization, not related to reinforcement learning or data processing in RL contexts."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.19609",
      "abstract": "Researchers aim to build secure compilation chains enforcing that if there is no attack a source context can mount against a source program then there is also no attack an adversarial target context can mount against the compiled program. Proving that these compilation chains are secure is, however, challenging, and involves a non-trivial back-translation step: for any attack a target context mounts against the compiled program one has to exhibit a source context mounting the same attack against the source program. We describe a novel back-translation technique, which results in simpler proofs that can be more easily mechanized in a proof assistant. Given a finite set of finite trace prefixes, capturing the interaction recorded during an attack between a target context and the compiled program, we build a call-return tree that we back-translate into a source context producing the same trace prefixes. We use state in the generated source context to record the current location in the call-return tree. The back-translation is done in several small steps, each adding to the tree new information describing how the location should change depending on how the context regains control. To prove this back-translation correct we give semantics to every intermediate call-return tree language, using ghost state to store information and explicitly enforce execution invariants. We prove several small forward simulations, basically seeing the back-translation as a verified nanopass compiler. Thanks to this modular structure, we are able to mechanize this complex back-translation and its correctness proof in the Rocq prover without too much effort.",
      "authors": [
        "J\\'er\\'emy Thibault",
        "Joseph Lenormand",
        "and Catalin Hritcu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T12:50:35+00:00",
          "link": "https://arxiv.org/abs/2503.19609v1",
          "size": "178kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T13:02:37+00:00",
          "link": "https://arxiv.org/abs/2503.19609v2",
          "size": "193kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T12:54:33+00:00",
          "link": "https://arxiv.org/abs/2503.19609v3",
          "size": "51kb",
          "version": "v3"
        }
      ],
      "title": "Nanopass Back-Translation of Call-Return Trees for Mechanized Secure Compilation Proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19609",
        "PDF": "https://arxiv.org/pdf/2503.19609"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with secure compilation proofs and back-translation techniques, unrelated to reinforcement learning or any associated data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.22526",
      "abstract": "We introduce the AnnoPage Dataset, a novel collection of 7,550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",
      "authors": [
        "Martin Ki\\v{s}\\v{s} and Michal Hradi\\v{s} and Martina Dvo\\v{r}\\'akov\\'a and V\\'aclav Jirou\\v{s}ek and Filip Kersch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T15:30:42+00:00",
          "link": "https://arxiv.org/abs/2503.22526v1",
          "size": "18098kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:15:26+00:00",
          "link": "https://arxiv.org/abs/2503.22526v2",
          "size": "5891kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T14:55:25+00:00",
          "link": "https://arxiv.org/abs/2503.22526v3",
          "size": "5891kb",
          "version": "v3"
        }
      ],
      "title": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22526",
        "HTML": "https://arxiv.org/html/2503.22526v3",
        "PDF": "https://arxiv.org/pdf/2503.22526"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The AnnoPage Dataset is aimed at document layout analysis rather than reinforcement learning or any data processing activities within an RL framework."
      },
      "tasks": [
        "Document Layout Analysis",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22913",
      "abstract": "Recent shifts in the space of large language model (LLM) research have shown an increasing focus on novel architectures to compete with prototypical Transformer-based models that have long dominated this space. Linear recurrent models have proven to be a viable competitor due to their computational efficiency. However, such models still demonstrate a sizable gap compared to Transformers in terms of in-context learning among other tasks that require recalling information from a context. In this work, we introduce Resona, a simple and scalable framework for augmenting linear recurrent models with retrieval. Resona augments models with the ability to integrate retrieved information from the provided input context, enabling tailored behavior to diverse task requirements. Experiments on a variety of linear recurrent models demonstrate that Resona-augmented models observe significant performance gains on a variety of synthetic as well as real-world natural language tasks, highlighting its ability to act as a general purpose method to improve the in-context learning and language modeling abilities of linear recurrent LLMs.",
      "authors": [
        "Xinyu Wang",
        "Linrui Ma",
        "Jerry Huang",
        "Peng Lu",
        "Prasanna Parthasarathi",
        "Xiao-Wen Chang",
        "Boxing Chen",
        "Yufei Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T23:43:33+00:00",
          "link": "https://arxiv.org/abs/2503.22913v1",
          "size": "412kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:54:34+00:00",
          "link": "https://arxiv.org/abs/2503.22913v2",
          "size": "381kb",
          "version": "v2"
        }
      ],
      "title": "Resona: Improving Context Copying in Linear Recurrence Models with Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22913",
        "HTML": "https://arxiv.org/html/2503.22913v2",
        "PDF": "https://arxiv.org/pdf/2503.22913"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing language models with retrieval capabilities and does not address data processing in reinforcement learning contexts."
      },
      "tasks": [
        "Computational Efficiency",
        "In-Context Learning",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23175",
      "abstract": "Several recent works have argued that Large Language Models (LLMs) can be used to tame the data deluge in the cybersecurity field, by improving the automation of Cyber Threat Intelligence (CTI) tasks. This work presents an evaluation methodology that other than allowing to test LLMs on CTI tasks when using zero-shot learning, few-shot learning and fine-tuning, also allows to quantify their consistency and their confidence level. We run experiments with three state-of-the-art LLMs and a dataset of 350 threat intelligence reports and present new evidence of potential security risks in relying on LLMs for CTI. We show how LLMs cannot guarantee sufficient performance on real-size reports while also being inconsistent and overconfident. Few-shot learning and fine-tuning only partially improve the results, thus posing doubts about the possibility of using LLMs for CTI scenarios, where labelled datasets are lacking and where confidence is a fundamental factor.",
      "authors": [
        "Emanuele Mezzi",
        "Fabio Massacci and Katja Tuma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T18:09:36+00:00",
          "link": "https://arxiv.org/abs/2503.23175v1",
          "size": "1202kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:49:21+00:00",
          "link": "https://arxiv.org/abs/2503.23175v2",
          "size": "1203kb",
          "version": "v2"
        }
      ],
      "title": "Large Language Models are Unreliable for Cyber Threat Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23175",
        "HTML": "https://arxiv.org/html/2503.23175v2",
        "PDF": "https://arxiv.org/pdf/2503.23175"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work evaluates the performance of large language models in cybersecurity tasks, specifically around Cyber Threat Intelligence, without involving reinforcement learning or data processing for RL."
      },
      "tasks": [
        "Few-Shot Learning",
        "Zero-Shot Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.24144",
      "abstract": "Local complementation of a graph $G$ on vertex $v$ is an operation that results in a new graph $G*v$, where the neighborhood of $v$ is complemented. This operation has been widely studied in graph theory and quantum computing.\n  This article introduces the Local Complementation Problem, a decision problem that captures the complexity of applying a sequence of local complementations. Given a graph $G$, a sequence of vertices $s$, and a pair of vertices $u,v$, the problem asks whether the edge $(u,v)$ is present in the graph obtained after applying local complementations according to $s$. The main contribution of this work is proving that this problem is $\\mathsf{P}$-complete, implying that computing a sequence of local complementation is unlikely to be efficiently parallelizable. The proof is based on a reduction from the Circuit Value Problem, a well-known $\\mathsf{P}$-complete problem, by simulating circuits through local complementations.\n  Additionally, the complexity of this problem is analyzed under different restrictions. In particular, it is shown that for complete and star graphs, the problem belongs to $\\mathsf{LOGSPACE}$. Finally, it is conjectured that the problem remains $\\mathsf{P}$-complete for the class of circle graphs.",
      "authors": [
        "Pablo Concha-Vega (Aix-Marseille Universit\\'e Toulon",
        "LIS",
        "CNRS UMR",
        "Marseille",
        "France)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T14:27:46+00:00",
          "link": "https://arxiv.org/abs/2503.24144v1",
          "size": "271kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T02:56:29+00:00",
          "link": "https://arxiv.org/abs/2503.24144v2",
          "size": "210kb",
          "version": "v2"
        }
      ],
      "title": "Graph Local Complementation is Inherently Sequential",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.24144",
        "HTML": "https://arxiv.org/html/2503.24144v2",
        "PDF": "https://arxiv.org/pdf/2503.24144"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study involves graph theory and computational complexity related to graph operations, which has no connection to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.00513",
      "abstract": "AI systems are gaining widespread adoption across various sectors and domains. Creating high-quality AI system requirements is crucial for aligning the AI system with business goals and consumer values and for social responsibility. However, with the uncertain nature of AI systems and the heavy reliance on sensitive data, more research is needed to address the elicitation and analysis of AI systems requirements. With the proprietary nature of many AI systems, there is a lack of open-source requirements artifacts and technical requirements documents for AI systems, limiting broader research and investigation. With Large Language Models (LLMs) emerging as a promising alternative to human-generated text, this paper investigates the potential use of LLMs to generate user stories for AI systems based on abstracts from scholarly papers. We conducted an empirical evaluation using three LLMs and generated $1260$ user stories from $42$ abstracts from $26$ domains. We assess their quality using the Quality User Story (QUS) framework. Moreover, we identify relevant non-functional requirements (NFRs) and ethical principles. Our analysis demonstrates that the investigated LLMs can generate user stories inspired by the needs of various stakeholders, offering a promising approach for generating user stories for research purposes and for aiding in the early requirements elicitation phase of AI systems. We have compiled and curated a collection of stories generated by various LLMs into a dataset (UStAI), which is now publicly available for use.",
      "authors": [
        "Asma Yamani",
        "Malak Baslyman",
        "Moataz Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T08:03:40+00:00",
          "link": "https://arxiv.org/abs/2504.00513v1",
          "size": "929kb",
          "version": "v1"
        },
        {
          "date": "2025-04-23T11:26:49+00:00",
          "link": "https://arxiv.org/abs/2504.00513v2",
          "size": "932kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T10:35:09+00:00",
          "link": "https://arxiv.org/abs/2504.00513v3",
          "size": "646kb",
          "version": "v3"
        }
      ],
      "title": "Leveraging LLMs for User Stories in AI Systems: UStAI Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00513",
        "HTML": "https://arxiv.org/html/2504.00513v3",
        "PDF": "https://arxiv.org/pdf/2504.00513"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with generating user stories using large language models and does not touch upon reinforcement learning or data processing issues related to RL."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/asmayamani/ethicsrequirementsdata"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00584",
      "abstract": "Negation plays an important role in various natural language processing tasks such as Natural Language Inference and Sentiment Analysis tasks. Numerous prior studies have found that contextual text embedding models such as BERT, ELMO, RoBERTa or XLNet face challenges in accurately understanding negation. Recent advancements in universal text embeddings have demonstrated superior performance over contextual text embeddings in various tasks. However, due to the bias in popular evaluation benchmarks, the negation awareness capacity of these models remains unclear. To bridge the gap in existing literature, an in-depth analysis is initiated in this work to study the negation awareness of cutting-edge universal text embedding models. Our findings reveal a significant lack of negation awareness in these models, often interpreting negated text pairs as semantically similar. To efficiently deal with the conflict that different tasks need different trade-offs between topic and negation information among other semantic information, a data-efficient and computational-efficient embedding re-weighting method is proposed without modifying the parameters of text embedding models. The proposed solution is able to improve text embedding models' negation awareness significantly on both simple negation understanding task and complex negation understanding task. Furthermore, the proposed solution can also significantly improve the negation awareness of Large Language Model based task-specific high dimensional universal text embeddings.",
      "authors": [
        "Hongliu Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T09:39:57+00:00",
          "link": "https://arxiv.org/abs/2504.00584v1",
          "size": "1217kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:33:08+00:00",
          "link": "https://arxiv.org/abs/2504.00584v2",
          "size": "451kb",
          "version": "v2"
        }
      ],
      "title": "Semantic Adapter for Universal Text Embeddings: Diagnosing and Mitigating Negation Blindness to Enhance Universality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00584",
        "HTML": "https://arxiv.org/html/2504.00584v2",
        "PDF": "https://arxiv.org/pdf/2504.00584"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This research addresses improvements to text embedding models in negation understanding, with no discussion on reinforcement learning or its data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.01048",
      "abstract": "Visual Language Models (VLMs) have become foundational models for document understanding tasks, widely used in the processing of complex multimodal documents across domains such as finance, law, and academia. However, documents often contain noise-like information, such as watermarks, which inevitably leads us to inquire: \\emph{Do watermarks degrade the performance of VLMs in document understanding?} To address this, we propose a novel evaluation framework to investigate the effect of visible watermarks on VLMs performance. We takes into account various factors, including different types of document data, the positions of watermarks within documents and variations in watermark content. Our experimental results reveal that VLMs performance can be significantly compromised by watermarks, with performance drop rates reaching up to 36\\%. We discover that \\emph{scattered} watermarks cause stronger interference than centralized ones, and that \\emph{semantic contents} in watermarks creates greater disruption than simple visual occlusion. Through attention mechanism analysis and embedding similarity examination, we find that the performance drops are mainly attributed to that watermarks 1) force widespread attention redistribution, and 2) alter semantic representation in the embedding space. Our research not only highlights significant challenges in deploying VLMs for document understanding, but also provides insights towards developing robust inference mechanisms on watermarked documents.",
      "authors": [
        "Chunxue Xu",
        "Yiwei Wang",
        "Bryan Hooi",
        "Yujun Cai",
        "Songze Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T05:57:01+00:00",
          "link": "https://arxiv.org/abs/2504.01048v1",
          "size": "6822kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:00:57+00:00",
          "link": "https://arxiv.org/abs/2504.01048v2",
          "size": "2806kb",
          "version": "v2"
        }
      ],
      "title": "How does Watermarking Affect Visual Language Models in Document Understanding?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01048",
        "HTML": "https://arxiv.org/html/2504.01048v2",
        "PDF": "https://arxiv.org/pdf/2504.01048"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the impact of watermarks on the performance of visual language models in document understanding. It does not relate to reinforcement learning or any data processing aspects within the RL context."
      },
      "tasks": [
        "document understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.02477",
      "abstract": "Robot vision has greatly benefited from advancements in multimodal fusion techniques and vision-language models (VLMs). We systematically review the applications of multimodal fusion in key robotic vision tasks, including semantic scene understanding, simultaneous localization and mapping (SLAM), 3D object detection, navigation and localization, and robot manipulation. We compare VLMs based on large language models (LLMs) with traditional multimodal fusion methods, analyzing their advantages, limitations, and synergies. Additionally, we conduct an in-depth analysis of commonly used datasets, evaluating their applicability and challenges in real-world robotic scenarios. Furthermore, we identify critical research challenges such as cross-modal alignment, efficient fusion strategies, real-time deployment, and domain adaptation, and propose future research directions, including self-supervised learning for robust multimodal representations, transformer-based fusion architectures, and scalable multimodal frameworks. Through a comprehensive review, comparative analysis, and forward-looking discussion, we provide a valuable reference for advancing multimodal perception and interaction in robotic vision. A comprehensive list of studies in this survey is available at https://github.com/Xiaofeng-Han-Res/MF-RV.",
      "authors": [
        "Xiaofeng Han",
        "Shunpeng Chen",
        "Zenghuang Fu",
        "Zhe Feng",
        "Lue Fan",
        "Dong An",
        "Changwei Wang",
        "Li Guo",
        "Weiliang Meng",
        "Xiaopeng Zhang",
        "Rongtao Xu",
        "Shibiao Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T10:53:07+00:00",
          "link": "https://arxiv.org/abs/2504.02477v1",
          "size": "2332kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T00:07:56+00:00",
          "link": "https://arxiv.org/abs/2504.02477v2",
          "size": "2014kb",
          "version": "v2"
        }
      ],
      "title": "Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02477",
        "HTML": "https://arxiv.org/html/2504.02477v2",
        "PDF": "https://arxiv.org/pdf/2504.02477"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This survey discusses advancements in multimodal fusion and vision-language models for robot vision, with no mention of reinforcement learning or data processing for RL."
      },
      "tasks": [
        "3D Object Detection",
        "cross-modal alignment",
        "Domain Adaptation",
        "object-detection",
        "Object Detection",
        "Robot Manipulation",
        "Scene Understanding",
        "Self-Supervised Learning",
        "Simultaneous Localization and Mapping"
      ],
      "repo_urls": [
        "https://github.com/xiaofeng-han-res/mf-rv"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03205",
      "abstract": "This application paper investigates the stability of hydrogen bonds (H-bonds), as characterized by the Quantum Theory of Atoms in Molecules (QTAIM). First, we contribute a database of 4544 electron densities associated to four isomers of water hexamers (the so-called Ring, Book, Cage and Prism), generated by distorting their equilibrium geometry under various structural perturbations, modeling the natural dynamic behavior of molecular systems. Second, we present a new stability measure, called bond occurrence rate, associating each bond path present at equilibrium with its rate of occurrence within the input ensemble. We also provide an algorithm, called BondMatcher, for its automatic computation, based on a tailored, geometry-aware partial isomorphism estimation between the extremum graphs of the considered electron densities. Our new stability measure allows for the automatic identification of densities lacking H-bond paths, enabling further visual inspections. Specifically, the topological analysis enabled by our framework corroborates experimental observations and provides refined geometrical criteria for characterizing the disappearance of H-bond paths. Our electron density database and our C++ implementation are available at this address: https://github.com/thom-dani/BondMatcher.",
      "authors": [
        "Thomas Daniel",
        "Malgorzata Olejniczak",
        "Julien Tierny"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T06:29:29+00:00",
          "link": "https://arxiv.org/abs/2504.03205v1",
          "size": "32573kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:36:00+00:00",
          "link": "https://arxiv.org/abs/2504.03205v2",
          "size": "32919kb",
          "version": "v2"
        }
      ],
      "title": "BondMatcher: H-Bond Stability Analysis in Molecular Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03205",
        "HTML": "https://arxiv.org/html/2504.03205v2",
        "PDF": "https://arxiv.org/pdf/2504.03205"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates hydrogen bond stability using electron densities and does not pertain to reinforcement learning or data processing within RL contexts."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/thom-dani/bondmatcher"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03865",
      "abstract": "Mapper graphs are a widely used tool in topological data analysis and visualization. They can be viewed as discrete approximations of Reeb graphs, offering insight into the shape and connectivity of complex data. Given a high-dimensional point cloud $\\mathbb{X}$ equipped with a function $f: \\mathbb{X} \\to \\mathbb{R}$, a mapper graph provides a summary of the topological structure of $\\mathbb{X}$ induced by $f$, where each node represents a local neighborhood, and edges connect nodes whose corresponding neighborhoods overlap. Our focus is the interleaving distance for mapper graphs, arising from a discretization of the version for Reeb graphs, which is NP-hard to compute. This distance quantifies the similarity between two mapper graphs by measuring the extent to which they must be ``stretched\" to become comparable. Recent work introduced a loss function that provides an upper bound on the interleaving distance for mapper graphs, which evaluates how far a given assignment is from being a true interleaving. Finding the loss is computationally tractable, offering a practical way to estimate the distance.\n  In this paper, we employ a categorical formulation of mapper graphs and develop the first framework for computing the associated loss function. Since the quality of the bound depends on the chosen assignment, we optimize this loss function by formulating the problem of finding the best assignment as an integer linear programming problem. To evaluate the effectiveness of our optimization, we apply it to small mapper graphs where the interleaving distance is known, demonstrating that the optimized upper bound successfully matches the interleaving distance in these cases. Additionally, we conduct an experiment on the MPEG-7 dataset, computing the pairwise optimal loss on a collection of mapper graphs derived from images and leveraging the distance bound for image classification.",
      "authors": [
        "Erin Wolf Chambers",
        "Ishika Ghosh",
        "Elizabeth Munch",
        "Sarah Percival",
        "Bei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T18:43:01+00:00",
          "link": "https://arxiv.org/abs/2504.03865v1",
          "size": "1279kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T18:28:47+00:00",
          "link": "https://arxiv.org/abs/2504.03865v2",
          "size": "1685kb",
          "version": "v2"
        }
      ],
      "title": "Towards an Optimal Bound for the Interleaving Distance on Mapper Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03865",
        "PDF": "https://arxiv.org/pdf/2504.03865"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with mapper graphs in topological data analysis, without addressing reinforcement learning or related data processing activities for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.07618",
      "abstract": "Accurate and concise governing equations are crucial for understanding system dynamics. Recently, data-driven methods such as sparse regression have been employed to automatically uncover governing equations from data, representing a significant shift from traditional first-principles modeling. However, most existing methods focus on scalar equations, limiting their applicability to simple, low-dimensional scenarios, and failing to ensure rotation and reflection invariance without incurring significant computational cost or requiring additional prior knowledge. This paper proposes a Cartesian tensor-based sparse regression (CTSR) technique to accurately and efficiently uncover complex, high-dimensional governing equations while ensuring invariance. Evaluations on two two-dimensional (2D) and two three-dimensional (3D) test cases demonstrate that the proposed method achieves superior accuracy and efficiency compared to the conventional technique.",
      "authors": [
        "Boqian Zhang",
        "Juanmian Lei",
        "Guoyou Sun",
        "Shuaibing Ding",
        "Jian Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T10:06:29+00:00",
          "link": "https://arxiv.org/abs/2504.07618v1",
          "size": "4256kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T02:19:59+00:00",
          "link": "https://arxiv.org/abs/2504.07618v2",
          "size": "3737kb",
          "version": "v2"
        }
      ],
      "title": "CTSR: Cartesian tensor-based sparse regression for data-driven discovery of high-dimensional invariant governing equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07618",
        "PDF": "https://arxiv.org/pdf/2504.07618"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cartesian tensor-based sparse regression to uncover governing equations, which is unrelated to reinforcement learning or data processing in RL."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.09037",
      "abstract": "Reasoning is a fundamental cognitive process that enables logical inference, problem-solving, and decision-making. With the rapid advancement of large language models (LLMs), reasoning has emerged as a key capability that distinguishes advanced AI systems from conventional models that empower chatbots. In this survey, we categorize existing methods along two orthogonal dimensions: (1) Regimes, which define the stage at which reasoning is achieved (either at inference time or through dedicated training); and (2) Architectures, which determine the components involved in the reasoning process, distinguishing between standalone LLMs and agentic compound systems that incorporate external tools, and multi-agent collaborations. Within each dimension, we analyze two key perspectives: (1) Input level, which focuses on techniques that construct high-quality prompts that the LLM condition on; and (2) Output level, which methods that refine multiple sampled candidates to enhance reasoning quality. This categorization provides a systematic understanding of the evolving landscape of LLM reasoning, highlighting emerging trends such as the shift from inference-scaling to learning-to-reason (e.g., DeepSeek-R1), and the transition to agentic workflows (e.g., OpenAI Deep Research, Manus Agent). Additionally, we cover a broad spectrum of learning algorithms, from supervised fine-tuning to reinforcement learning such as PPO and GRPO, and the training of reasoners and verifiers. We also examine key designs of agentic workflows, from established patterns like generator-evaluator and LLM debate to recent innovations. ...",
      "authors": [
        "Zixuan Ke",
        "Fangkai Jiao",
        "Yifei Ming",
        "Xuan-Phi Nguyen",
        "Austin Xu",
        "Do Xuan Long",
        "Minzhi Li",
        "Chengwei Qin",
        "Peifeng Wang",
        "Silvio Savarese",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-12T01:27:49+00:00",
          "link": "https://arxiv.org/abs/2504.09037v1",
          "size": "4585kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:33:35+00:00",
          "link": "https://arxiv.org/abs/2504.09037v2",
          "size": "1194kb",
          "version": "v2"
        }
      ],
      "title": "A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09037",
        "HTML": "https://arxiv.org/html/2504.09037v2",
        "PDF": "https://arxiv.org/pdf/2504.09037"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper primarily surveys reasoning in language models, it mentions reinforcement learning methods like PPO and GRPO, which may involve aspects of data processing but are not the primary focus of this survey."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.15079",
      "abstract": "The growth of low-altitude economy (LAE) has driven a rising demand for efficient and secure communication. However, conventional beamforming optimization techniques struggle in the complex LAE environments. In this context, generative artificial intelligence (GenAI) methods provide a promising solution. In this article, we first introduce the core concepts of LAE and the roles of beamforming in advanced communication technologies for LAE. We then examine their interrelation, followed by an analysis of the limitations of conventional beamforming methods. Next, we provide an overview of how GenAI methods enhance the process of beamforming, with a focus on its applications in LAE. Furthermore, we present a case study using a generative diffusion model (GDM)-based algorithm to enhance the performance of aerial collaborative beamforming-enabled remote secure communications in LAE and simulation results verified the effectiveness of the proposed algorithms. Finally, promising research opportunities are identified.",
      "authors": [
        "Geng Sun",
        "Jia Qi",
        "Chuang Zhang",
        "Xuejie Liu",
        "Jiacheng Wang",
        "Dusit Niyato",
        "Yuanwei Liu",
        "and Dong In Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T13:09:15+00:00",
          "link": "https://arxiv.org/abs/2504.15079v1",
          "size": "22558kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T09:23:20+00:00",
          "link": "https://arxiv.org/abs/2504.15079v2",
          "size": "6437kb",
          "version": "v2"
        }
      ],
      "title": "Generative Artificial Intelligence for Beamforming in Low-Altitude Economy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15079",
        "HTML": "https://arxiv.org/html/2504.15079v2",
        "PDF": "https://arxiv.org/pdf/2504.15079"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses generative AI for beamforming in low-altitude communication and does not address reinforcement learning or data processing specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.15110",
      "abstract": "Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold Networks (KANs) have recently emerged as an improved backbone for most deep learning frameworks, promising more adaptivity than their multilayer perception (MLP) predecessor by allowing for trainable spline-based activation functions. In this paper, we probe the theoretical foundations of the KAN architecture by showing that it can optimally approximate any Besov function in $B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain $\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect to any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$. We complement our approximation guarantee with a dimension-free estimate on the sample complexity of a residual KAN model when learning a function of Besov regularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates contemporary deep learning wisdom by leveraging residual/skip connections between layers.",
      "authors": [
        "Anastasis Kratsios",
        "Bum Jun Kim",
        "Takashi Furuya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Functional Analysis (math.FA)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T14:02:59+00:00",
          "link": "https://arxiv.org/abs/2504.15110v1",
          "size": "661kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T19:29:26+00:00",
          "link": "https://arxiv.org/abs/2504.15110v2",
          "size": "211kb",
          "version": "v2"
        }
      ],
      "title": "Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for Functions and their Derivatives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15110",
        "HTML": "https://arxiv.org/html/2504.15110v2",
        "PDF": "https://arxiv.org/pdf/2504.15110"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is focused on theoretical advancements in deep learning architectures, specifically Kolmogorov-Arnold Networks, and does not address data processing within reinforcement learning."
      },
      "tasks": [
        "Kolmogorov-Arnold Networks"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16946",
      "abstract": "Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices, rely heavily on static agent profiles leading to behavioral homogenization, and inherit prohibitive computational costs. To address these limitations, we present MobileCity, a lightweight simulation platform designed to model realistic urban mobility with high computational efficiency. We introduce a comprehensive transportation system with multiple transport modes, and collect questionnaire data from respondents to construct agent profiles. To enable scalable simulation, agents perform action selection within a pre-generated action space and uses local models for efficient agent memory generation. Through extensive micro and macro-level evaluations on 4,000 agents, we demonstrate that MobileCity generates more realistic urban behaviors than baselines while maintaining computational efficiency. We further explore practical applications such as predicting movement patterns and analyzing demographic trends in transportation preferences.",
      "authors": [
        "Xiaotong Ye",
        "Nicolas Bougie",
        "Toshihiko Yamasaki",
        "and Narimasa Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T07:01:05+00:00",
          "link": "https://arxiv.org/abs/2504.16946v1",
          "size": "7130kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T04:13:04+00:00",
          "link": "https://arxiv.org/abs/2504.16946v2",
          "size": "6751kb",
          "version": "v2"
        }
      ],
      "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16946",
        "PDF": "https://arxiv.org/pdf/2504.16946"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper describes the MobileCity framework for urban behavior simulation, which could theoretically be used for generating training data for RL agents, it does not specifically contribute to data processing in reinforcement learning directly."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.17080",
      "abstract": "In this paper, we present an impedance control framework on the SE(3) manifold, which enables force tracking while guaranteeing passivity. Building upon the unified force-impedance control (UFIC) and our previous work on geometric impedance control (GIC), we develop the geometric unified force impedance control (GUFIC) to account for the SE(3) manifold structure in the controller formulation using a differential geometric perspective. As in the case of the UFIC, the GUFIC utilizes energy tank augmentation for both force-tracking and impedance control to guarantee the manipulator's passivity relative to external forces. This ensures that the end effector maintains safe contact interaction with uncertain environments and tracks a desired interaction force. Moreover, we resolve a non-causal implementation problem in the UFIC formulation by introducing velocity and force fields. Due to its formulation on SE(3), the proposed GUFIC inherits the desirable SE(3) invariance and equivariance properties of the GIC, which helps increase sample efficiency in machine learning applications where a learning algorithm is incorporated into the control law. The proposed control law is validated in a simulation environment under scenarios requiring tracking an SE(3) trajectory, incorporating both position and orientation, while exerting a force on a surface. The codes are available at https://github.com/Joohwan-Seo/GUFIC_mujoco.",
      "authors": [
        "Joohwan Seo",
        "Nikhil Potu Surya Prakash",
        "Soomi Lee",
        "Arvind Kruthiventy",
        "Megan Teng",
        "Jongeun Choi",
        "and Roberto Horowitz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T20:06:09+00:00",
          "link": "https://arxiv.org/abs/2504.17080v1",
          "size": "778kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:24:00+00:00",
          "link": "https://arxiv.org/abs/2504.17080v2",
          "size": "495kb",
          "version": "v2"
        }
      ],
      "title": "Geometric Formulation of Unified Force-Impedance Control on SE(3) for Robotic Manipulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17080",
        "PDF": "https://arxiv.org/pdf/2504.17080"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses a control framework for robotic manipulators using impedance control on the SE(3) manifold, without any focus on data processing techniques in reinforcement learning."
      },
      "repo_urls": [
        "https://github.com/joohwan-seo/gufic_mujoco"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17791",
      "abstract": "Training diffusion models that work directly on lidar points at the scale of outdoor scenes is challenging due to the difficulty of generating fine-grained details from white noise over a broad field of view. The latest works addressing scene completion with diffusion models tackle this problem by reformulating the original DDPM as a local diffusion process. It contrasts with the common practice of operating at the level of objects, where vanilla DDPMs are currently used. In this work, we close the gap between these two lines of work. We identify approximations in the local diffusion formulation, show that they are not required to operate at the scene level, and that a vanilla DDPM with a well-chosen starting point is enough for completion. Finally, we demonstrate that our method, LiDPM, leads to better results in scene completion on SemanticKITTI. The project page is https://astra-vision.github.io/LiDPM .",
      "authors": [
        "Tetiana Martyniuk and Gilles Puy and Alexandre Boulch and Renaud Marlet and Raoul de Charette"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T17:59:59+00:00",
          "link": "https://arxiv.org/abs/2504.17791v1",
          "size": "11594kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:45:17+00:00",
          "link": "https://arxiv.org/abs/2504.17791v2",
          "size": "11595kb",
          "version": "v2"
        }
      ],
      "title": "LiDPM: Rethinking Point Diffusion for Lidar Scene Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17791",
        "HTML": "https://arxiv.org/html/2504.17791v2",
        "PDF": "https://arxiv.org/pdf/2504.17791"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with diffusion models for lidar scene completion and does not focus on data processing or data-centric methods within the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19982",
      "abstract": "Task-oriented dialogue (TOD) systems are experiencing a revolution driven by Large Language Models (LLMs), yet the evaluation methodologies for these systems remain insufficient for their growing sophistication. While traditional automatic metrics effectively assessed earlier modular systems, they focus solely on the dialogue level and cannot detect critical intermediate errors that can arise during user-agent interactions. In this paper, we introduce TD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework that unifies fine-grained turn-level analysis with holistic dialogue-level comparisons. At turn level, we evaluate each response along three TOD-specific dimensions: conversation cohesion, backend knowledge consistency, and policy compliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons to provide a measure of dialogue-level quality. Through experiments on MultiWOZ 2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the conversational errors that conventional metrics miss. Furthermore, TD-EVAL exhibits better alignment with human judgments than traditional and LLM-based metrics. These findings demonstrate that TD-EVAL introduces a new paradigm for TOD system evaluation, efficiently assessing both turn and system levels with a plug-and-play framework for future research.",
      "authors": [
        "Emre Can Acikgoz",
        "Carl Guo",
        "Suvodip Dey",
        "Akul Datta",
        "Takyoung Kim",
        "Gokhan Tur",
        "Dilek Hakkani-T\\\"ur"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T16:57:17+00:00",
          "link": "https://arxiv.org/abs/2504.19982v1",
          "size": "877kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:52:44+00:00",
          "link": "https://arxiv.org/abs/2504.19982v2",
          "size": "879kb",
          "version": "v2"
        }
      ],
      "title": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19982",
        "HTML": "https://arxiv.org/html/2504.19982v2",
        "PDF": "https://arxiv.org/pdf/2504.19982"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new evaluation framework for task-oriented dialogue systems, which does not address data processing issues within reinforcement learning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21042",
      "abstract": "The growing adoption of artificial intelligence (AI) has amplified concerns about trustworthiness, including integrity, privacy, robustness, and bias. To assess and attribute these threats, we propose ConceptLens, a generic framework that leverages pre-trained multimodal models to identify the root causes of integrity threats by analyzing Concept Shift in probing samples. ConceptLens demonstrates strong detection performance for vanilla data poisoning attacks and uncovers vulnerabilities to bias injection, such as the generation of covert advertisements through malicious concept shifts. It identifies privacy risks in unaltered but high-risk samples, filters them before training, and provides insights into model weaknesses arising from incomplete or imbalanced training data. Additionally, at the model level, it attributes concepts that the target model is overly dependent on, identifies misleading concepts, and explains how disrupting key concepts negatively impacts the model. Furthermore, it uncovers sociological biases in generative content, revealing disparities across sociological contexts. Strikingly, ConceptLens reveals how safe training and inference data can be unintentionally and easily exploited, potentially undermining safety alignment. Our study informs actionable insights to breed trust in AI systems, thereby speeding adoption and driving greater innovation.",
      "authors": [
        "Jiamin Chang and Haoyang Li and Hammond Pearce and Ruoxi Sun and Bo Li and Minhui Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T13:30:48+00:00",
          "link": "https://arxiv.org/abs/2504.21042v1",
          "size": "13451kb",
          "version": "v1"
        },
        {
          "date": "2025-05-17T04:44:18+00:00",
          "link": "https://arxiv.org/abs/2504.21042v2",
          "size": "13431kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T14:13:44+00:00",
          "link": "https://arxiv.org/abs/2504.21042v3",
          "size": "7230kb",
          "version": "v3"
        }
      ],
      "title": "What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21042",
        "HTML": "https://arxiv.org/html/2504.21042v3",
        "PDF": "https://arxiv.org/pdf/2504.21042"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrity and bias detection using Concept Shift analysis in AI, which does not relate to data processing in the context of reinforcement learning."
      },
      "tasks": [
        "Attribute",
        "Data Poisoning",
        "Safety Alignment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00512",
      "abstract": "Online localization of road intersections is beneficial for autonomous vehicle localization, mapping and motion planning. Intersections offer strong landmarks for correcting vehicle pose estimation, anchoring new sensor data in up-to-date maps, and guiding vehicle routing in road network graphs. Despite this importance, intersection localization has not been widely studied, with existing methods either ignoring the rich semantic information already computed onboard or relying on scarce, hand-labeled intersection datasets. To close this gap, we present a novel LiDAR-based method for online vehicle-centric intersection localization. We detect the intersection candidates in a bird's eye view (BEV) representation formed by concatenating a sequence of semantic road scans. We then refine these candidates by analyzing the intersecting road branches and adjusting the intersection center point in a least-squares formulation. For evaluation, we introduce an automated pipeline that pairs localized intersection points with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS ground-truth poses. Experiments on the SemanticKITTI dataset show that our method outperforms the latest learning-based baseline in accuracy and reliability. Sensitivity tests demonstrate the method's robustness to challenging segmentation errors, highlighting its applicability in the real world.",
      "authors": [
        "Nguyen Hoang Khoi Tran",
        "Julie Stephany Berrio",
        "Mao Shan",
        "Zhenxing Ming",
        "Stewart Worrall"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T13:30:28+00:00",
          "link": "https://arxiv.org/abs/2505.00512v1",
          "size": "2863kb",
          "version": "v1"
        },
        {
          "date": "2025-05-02T07:20:07+00:00",
          "link": "https://arxiv.org/abs/2505.00512v2",
          "size": "2202kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T05:37:01+00:00",
          "link": "https://arxiv.org/abs/2505.00512v3",
          "size": "2198kb",
          "version": "v3"
        }
      ],
      "title": "InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00512",
        "HTML": "https://arxiv.org/html/2505.00512v3",
        "PDF": "https://arxiv.org/pdf/2505.00512"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work presents a method for LiDAR-based localization and evaluation in autonomous vehicles, which is unrelated to reinforcement learning or data processing for RL."
      },
      "tasks": [
        "Benchmarking",
        "Motion Planning",
        "Pose Estimation",
        "Road Segmentation",
        "Vehicle Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00784",
      "abstract": "Legged machines are becoming increasingly agile and adaptive but they have so far lacked the morphological diversity of legged animals, which have been rearranged and reshaped to fill millions of niches. Unlike their biological counterparts, legged machines have largely converged over the past decade to canonical quadrupedal and bipedal architectures that cannot be easily reconfigured to meet new tasks or recover from injury. Here we introduce autonomous modular legs: agile yet minimal, single-degree-of-freedom jointed links that can learn complex dynamic behaviors and may be freely attached to form legged metamachines at the meter scale. This enables rapid repair, redesign, and recombination of highly-dynamic modular agents that move quickly and acrobatically (non-quasistatically) through unstructured environments. Because each module is itself a complete agent, legged metamachines are able to sustain deep structural damage that would completely disable other legged robots. We also show how to encode the vast space of possible body configurations into a compact latent design genome that can be efficiently explored, revealing a wide diversity of novel legged forms.",
      "authors": [
        "Chen Yu",
        "David Matthews",
        "Jingxian Wang",
        "Jing Gu",
        "Douglas Blackiston",
        "Michael Rubenstein",
        "Sam Kriegman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T18:28:09+00:00",
          "link": "https://arxiv.org/abs/2505.00784v1",
          "size": "35490kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:50:45+00:00",
          "link": "https://arxiv.org/abs/2505.00784v2",
          "size": "36082kb",
          "version": "v2"
        }
      ],
      "title": "Reconfigurable legged metamachines that run on autonomous modular legs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00784",
        "HTML": "https://arxiv.org/html/2505.00784v2",
        "PDF": "https://arxiv.org/pdf/2505.00784"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses modular legged machines and their dynamic behavior without any focus on reinforcement learning or related data processing issues."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00894",
      "abstract": "The power of adaptivity in algorithms has been intensively studied in diverse areas of theoretical computer science. In this paper, we obtain a number of sharp lower bound results which show that adaptivity provides a significant extra power in cryptanalytic time-space tradeoffs with (possibly unlimited) preprocessing time.\n  Most notably, we consider the discrete logarithm (DLOG) problem in a generic group of $N$ elements. The classical `baby-step giant-step' algorithm for the problem has time complexity $T=O(\\sqrt{N})$, uses $O(\\sqrt{N})$ bits of space (up to logarithmic factors in $N$) and achieves constant success probability.\n  We examine a generalized setting where an algorithm obtains an advice string of $S$ bits and is allowed to make $T$ arbitrary non-adaptive queries that depend on the advice string (but not on the challenge group element).\n  We show that in this setting, the $T=O(\\sqrt{N})$ online time complexity of the baby-step giant-step algorithm cannot be improved, unless the advice string is more than $\\Omega(\\sqrt{N})$ bits long. This lies in stark contrast with the classical adaptive Pollard's rho algorithm for DLOG, which can exploit preprocessing to obtain the tradeoff curve $ST^2=O(N)$. We obtain similar sharp lower bounds for several other cryptanalytic problems.\n  To obtain our results, we present a new model that allows analyzing non-adaptive preprocessing algorithms for a wide array of search and decision problems in a unified way. Since previous proof techniques inherently cannot distinguish between adaptive and non-adaptive algorithms for the problems in our model, they cannot be used to obtain our results. Consequently, our proof uses a variant of Shearer's lemma for this setting, due to Barthe, Cordero-Erausquin, Ledoux, and Maurey (2011). This seems to be the first time a variant of Shearer's lemma for permutations is used in an algorithmic context.",
      "authors": [
        "Itai Dinur",
        "Nathan Keller",
        "Avichai Marmor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T22:17:11+00:00",
          "link": "https://arxiv.org/abs/2505.00894v1",
          "size": "48kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:37:23+00:00",
          "link": "https://arxiv.org/abs/2505.00894v2",
          "size": "45kb",
          "version": "v2"
        }
      ],
      "title": "Non-Adaptive Cryptanalytic Time-Space Lower Bounds via a Shearer-like Inequality for Permutations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00894",
        "HTML": "https://arxiv.org/html/2505.00894v2",
        "PDF": "https://arxiv.org/pdf/2505.00894"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with non-adaptive time-space lower bounds in cryptanalysis, not addressing data processing or reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.02274",
      "abstract": "Scenario-based testing has emerged as a common method for autonomous vehicles (AVs) safety assessment, offering a more efficient alternative to mile-based testing by focusing on high-risk scenarios. However, fundamental questions persist regarding its stopping rules, residual risk estimation, debug effectiveness, and the impact of simulation fidelity on safety claims. This paper argues that a rigorous statistical foundation is essential to address these challenges and enable rigorous safety assurance. By drawing parallels between AV testing and established software testing methods, we identify shared research gaps and reusable solutions. We propose proof-of-concept models to quantify the probability of failure per scenario (\\textit{pfs}) and evaluate testing effectiveness under varying conditions. Our analysis reveals that neither scenario-based nor mile-based testing universally outperforms the other. Furthermore, we give an example of formal reasoning about alignment of synthetic and real-world testing outcomes, a first step towards supporting statistically defensible simulation-based safety claims.",
      "authors": [
        "Xingyu Zhao",
        "Robab Aghazadeh-Chakherlou",
        "Chih-Hong Cheng",
        "Peter Popov",
        "Lorenzo Strigini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T22:06:23+00:00",
          "link": "https://arxiv.org/abs/2505.02274v1",
          "size": "113kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T22:18:21+00:00",
          "link": "https://arxiv.org/abs/2505.02274v2",
          "size": "115kb",
          "version": "v2"
        }
      ],
      "title": "On the Need for a Statistical Foundation in Scenario-Based Testing of Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02274",
        "HTML": "https://arxiv.org/html/2505.02274v2",
        "PDF": "https://arxiv.org/pdf/2505.02274"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study argues for statistical foundations in autonomous vehicle testing scenarios, without any linkage to reinforcement learning or its data processing concerns."
      },
      "tasks": [
        "Autonomous Vehicles",
        "software testing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.04457",
      "abstract": "Training data cleaning is a new application for generative model-based speech restoration (SR). This paper introduces Miipher-2, an SR model designed for million-hour scale data, for training data cleaning for large-scale generative models like large language models. Key challenges addressed include generalization to unseen languages, operation without explicit conditioning (e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a frozen, pre-trained Universal Speech Model (USM), supporting over 300 languages, as a robust, conditioning-free feature extractor. To optimize efficiency and minimize memory, Miipher-2 incorporates parallel adapters for predicting clean USM features from noisy inputs and employs the WaveFit neural vocoder for waveform synthesis. These components were trained on 3,000 hours of multi-lingual, studio-quality recordings with augmented degradations, while USM parameters remained fixed. Experimental results demonstrate Miipher-2's superior or comparable performance to conventional SR models in word-error-rate, speaker similarity, and both objective and subjective sound quality scores across all tested languages. Miipher-2 operates efficiently on consumer-grade accelerators, achieving a real-time factor of 0.0078, enabling the processing of a million-hour speech dataset in approximately three days using only 100 such accelerators.",
      "authors": [
        "Shigeki Karita",
        "Yuma Koizumi",
        "Heiga Zen",
        "Haruko Ishikawa",
        "Robin Scheibler",
        "Michiel Bacchiani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T14:27:46+00:00",
          "link": "https://arxiv.org/abs/2505.04457v1",
          "size": "195kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T23:59:00+00:00",
          "link": "https://arxiv.org/abs/2505.04457v2",
          "size": "195kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T01:08:39+00:00",
          "link": "https://arxiv.org/abs/2505.04457v3",
          "size": "196kb",
          "version": "v3"
        }
      ],
      "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04457",
        "HTML": "https://arxiv.org/html/2505.04457v3",
        "PDF": "https://arxiv.org/pdf/2505.04457"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on speech restoration and data cleaning for generative models, primarily in the context of speech-related data. It does not mention reinforcement learning or data processing within an RL context."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/yukara-ikemiya/wavefit-pytorch"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05470",
      "abstract": "We propose Flow-GRPO, the first method integrating online reinforcement learning (RL) into flow matching models. Our approach uses two key strategies: (1) an ODE-to-SDE conversion that transforms a deterministic Ordinary Differential Equation (ODE) into an equivalent Stochastic Differential Equation (SDE) that matches the original model's marginal distribution at all timesteps, enabling statistical sampling for RL exploration; and (2) a Denoising Reduction strategy that reduces training denoising steps while retaining the original inference timestep number, significantly improving sampling efficiency without performance degradation. Empirically, Flow-GRPO is effective across multiple text-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly perfect object counts, spatial relations, and fine-grained attributes, boosting GenEval accuracy from 63% to 95%. In visual text rendering, its accuracy improves from 59% to 92%, significantly enhancing text generation. Flow-GRPO also achieves substantial gains in human preference alignment. Notably, very little reward hacking occurred, meaning rewards did not increase at the cost of appreciable image quality or diversity degradation.",
      "authors": [
        "Jie Liu",
        "Gongye Liu",
        "Jiajun Liang",
        "Yangguang Li",
        "Jiaheng Liu",
        "Xintao Wang",
        "Pengfei Wan",
        "Di Zhang",
        "Wanli Ouyang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T17:58:45+00:00",
          "link": "https://arxiv.org/abs/2505.05470v1",
          "size": "3182kb",
          "version": "v1"
        },
        {
          "date": "2025-05-11T14:44:28+00:00",
          "link": "https://arxiv.org/abs/2505.05470v2",
          "size": "4204kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T13:31:15+00:00",
          "link": "https://arxiv.org/abs/2505.05470v3",
          "size": "9483kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T17:37:02+00:00",
          "link": "https://arxiv.org/abs/2505.05470v4",
          "size": "8401kb",
          "version": "v4"
        }
      ],
      "title": "Flow-GRPO: Training Flow Matching Models via Online RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05470",
        "HTML": "https://arxiv.org/html/2505.05470v4",
        "PDF": "https://arxiv.org/pdf/2505.05470"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper describes integrating online reinforcement learning into flow matching models, which primarily applies to text-to-image tasks. While it involves RL and sampling strategies, it does not explicitly focus on RL data processing techniques like dataset curation or preprocessing."
      },
      "models": [
        {
          "model_path": "jieliu/SD3.5M-FlowGRPO-GenEval",
          "downloads": "1235",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/jieliu/SD3.5M-FlowGRPO-GenEval"
        },
        {
          "model_path": "jieliu/SD3.5M-FlowGRPO-PickScore",
          "downloads": "192",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/jieliu/SD3.5M-FlowGRPO-PickScore"
        },
        {
          "model_path": "jieliu/SD3.5M-FlowGRPO-Text",
          "downloads": "24",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/jieliu/SD3.5M-FlowGRPO-Text"
        },
        {
          "model_path": "ighoshsubho/lora-grpo-flux-dev",
          "downloads": "3",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ighoshsubho/lora-grpo-flux-dev"
        }
      ],
      "tasks": [
        "Denoising",
        "Diversity",
        "Reinforcement Learning (RL)",
        "Text Generation",
        "Text-to-Image Generation"
      ],
      "repo_urls": [
        "https://github.com/yifan123/flow_grpo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.07530",
      "abstract": "Synthetic face datasets are increasingly used to overcome the limitations of real-world biometric data, including privacy concerns, demographic imbalance, and high collection costs. However, many existing methods lack fine-grained control over identity attributes and fail to produce paired, identity-consistent images under structured capture conditions. We introduce FLUXSynID, a framework for generating high-resolution synthetic face datasets along with a dataset of 14,889 synthetic identities. We generate synthetic faces with user-defined identity attribute distributions, offering both document-style and trusted live capture images. The dataset generated using the FLUXSynID framework shows improved alignment with real-world identity distributions and greater inter-class diversity compared to prior work. Our work is publicly released to support biometric research, including face recognition and morphing attack detection.",
      "authors": [
        "Raul Ismayilov",
        "Dzemila Sero",
        "Luuk Spreeuwers"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T13:12:33+00:00",
          "link": "https://arxiv.org/abs/2505.07530v1",
          "size": "18789kb",
          "version": "v1"
        },
        {
          "date": "2025-05-13T08:21:53+00:00",
          "link": "https://arxiv.org/abs/2505.07530v2",
          "size": "18774kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T14:20:45+00:00",
          "link": "https://arxiv.org/abs/2505.07530v3",
          "size": "18739kb",
          "version": "v3"
        }
      ],
      "title": "FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07530",
        "HTML": "https://arxiv.org/html/2505.07530v3",
        "PDF": "https://arxiv.org/pdf/2505.07530"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses synthetic face dataset generation and identity attribute control, with no connection to reinforcement learning or its data processing needs."
      },
      "tasks": [
        "Diversity",
        "Face Generation",
        "Face Recognition"
      ],
      "repo_urls": [
        "https://github.com/Raul2718/FLUXSynID"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08140",
      "abstract": "Despite their many successes, transformer-based large language models (LLMs) continue to struggle with tasks that require complex reasoning over large parts of their input. We argue that these failures arise due to capacity limits on the accurate flow of information within LLMs. To formalize this issue, we introduce the bounded attention prefix oracle (BAPO) model, a new computational framework that models bandwidth constraints on attention heads, the mechanism for internal communication in LLMs. We show that several important reasoning problems like graph reachability require high communication bandwidth for BAPOs to solve; we call these problems BAPO-hard. Our experiments corroborate our theoretical predictions: GPT-4o, Claude, and Gemini succeed on BAPO-easy tasks and fail even on relatively small BAPO-hard tasks. BAPOs also reveal another benefit of chain of thought (CoT): we prove that breaking down a task using CoT can turn any BAPO-hard problem into a BAPO-easy one. Our results offer principled explanations for key LLM failures and suggest directions for architectures and inference methods that mitigate bandwidth limits.",
      "authors": [
        "Tobias Schnabel",
        "Kiran Tomlinson",
        "Adith Swaminathan",
        "Jennifer Neville"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T00:25:23+00:00",
          "link": "https://arxiv.org/abs/2505.08140v1",
          "size": "695kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T16:46:27+00:00",
          "link": "https://arxiv.org/abs/2505.08140v2",
          "size": "803kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T23:00:23+00:00",
          "link": "https://arxiv.org/abs/2505.08140v3",
          "size": "769kb",
          "version": "v3"
        }
      ],
      "title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08140",
        "PDF": "https://arxiv.org/pdf/2505.08140"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper explores reasoning challenges in large language models and does not pertain to reinforcement learning or any aspect of data processing involved in RL."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.09092",
      "abstract": "Lane Keeping Assist (LKA) is widely adopted in modern vehicles, yet its real-world performance remains underexplored due to proprietary systems and limited data access. This paper presents OpenLKA, the first open, large-scale dataset for LKA evaluation and improvement. It includes 400 hours of driving data from 62 production vehicle models, collected through extensive road testing in Tampa, Florida and global contributions from the Comma.ai driving community. The dataset spans a wide range of challenging scenarios, including complex road geometries, degraded lane markings, adverse weather, lighting conditions and surrounding traffic. The dataset is multimodal, comprising: i) full CAN bus streams, decoded using custom reverse-engineered DBC files to extract key LKA events (e.g., system disengagements, lane detection failures); ii) synchronized high-resolution dash-cam video; iii) real-time outputs from Openpilot, providing accurate estimates of road curvature and lane positioning; iv) enhanced scene annotations generated by Vision Language Models, describing lane visibility, pavement quality, weather, lighting, and traffic conditions. By integrating vehicle-internal signals with high-fidelity perception and rich semantic context, OpenLKA provides a comprehensive platform for benchmarking the real-world performance of production LKA systems, identifying safety-critical operational scenarios, and assessing the readiness of current road infrastructure for autonomous driving. The dataset is publicly available at: https://github.com/OpenLKA/OpenLKA.",
      "authors": [
        "Yuhang Wang",
        "Abdulaziz Alhuraish",
        "Shengming Yuan",
        "Hao Zhou"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T02:53:50+00:00",
          "link": "https://arxiv.org/abs/2505.09092v1",
          "size": "8837kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:28:54+00:00",
          "link": "https://arxiv.org/abs/2505.09092v2",
          "size": "9875kb",
          "version": "v2"
        }
      ],
      "title": "OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09092",
        "HTML": "https://arxiv.org/html/2505.09092v2",
        "PDF": "https://arxiv.org/pdf/2505.09092"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces OpenLKA, a dataset for evaluating lane-keeping assist systems, which is relevant to autonomous driving but does not pertain to data processing within the context of reinforcement learning."
      },
      "tasks": [
        "Autonomous Driving",
        "Benchmarking",
        "Lane Detection"
      ],
      "repo_urls": [
        "https://github.com/openlka/openlka"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09598",
      "abstract": "This paper introduces a novel infrastructure-aware benchmarking framework for quantifying the environmental footprint of LLM inference across 30 state-of-the-art models as deployed in commercial data centers. Our framework combines public API performance data with region-specific environmental multipliers and statistical inference of hardware configurations. We additionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank models by performance relative to environmental cost. Our results show that o3 and DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33 Wh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and that Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short GPT-4o query consumes 0.42 Wh, scaling this to 700 million queries/day results in substantial annual environmental impacts. These include electricity use comparable to 35,000 U.S. homes, freshwater evaporation matching the annual drinking needs of 1.2 million people, and carbon emissions requiring a Chicago-sized forest to offset. These findings illustrate a growing paradox: Although AI is becoming cheaper and faster, its global adoption drives disproportionate resource consumption. Our study provides a standardized, empirically grounded methodology for benchmarking the sustainability of LLM deployments, laying a foundation for future environmental accountability in AI development and sustainability standards.",
      "authors": [
        "Nidhal Jegham",
        "Marwan Abdelatti",
        "Lassad Elmoubarki",
        "Abdeltawab Hendawi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T17:47:00+00:00",
          "link": "https://arxiv.org/abs/2505.09598v1",
          "size": "4049kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T20:21:12+00:00",
          "link": "https://arxiv.org/abs/2505.09598v2",
          "size": "4049kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T18:07:27+00:00",
          "link": "https://arxiv.org/abs/2505.09598v3",
          "size": "4049kb",
          "version": "v3"
        }
      ],
      "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09598",
        "HTML": "https://arxiv.org/html/2505.09598v3",
        "PDF": "https://arxiv.org/pdf/2505.09598"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking the environmental impact of LLM inference, addressing sustainability in AI but not relating to data processing in reinforcement learning."
      },
      "tasks": [
        "Benchmarking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.10389",
      "abstract": "This paper explores the design of an aspect-based sentiment analysis system using large language models (LLMs) for real-world use. We focus on quadruple opinion extraction -- identifying aspect categories, sentiment polarity, targets, and opinion expressions from text data across different domains and languages. We investigate whether a single fine-tuned model can effectively handle multiple domain-specific taxonomies simultaneously. We demonstrate that a combined multi-domain model achieves performance comparable to specialized single-domain models while reducing operational complexity. We also share lessons learned for handling non-extractive predictions and evaluating various failure modes when developing LLM-based systems for structured prediction tasks.",
      "authors": [
        "Benjamin White",
        "Anastasia Shimorina"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T15:11:48+00:00",
          "link": "https://arxiv.org/abs/2505.10389v1",
          "size": "57kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T20:16:15+00:00",
          "link": "https://arxiv.org/abs/2505.10389v2",
          "size": "60kb",
          "version": "v2"
        }
      ],
      "title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10389",
        "HTML": "https://arxiv.org/html/2505.10389v2",
        "PDF": "https://arxiv.org/pdf/2505.10389"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses sentiment analysis using language models, focusing on opinion extraction from text data which does not relate to reinforcement learning or its data processing aspects."
      },
      "tasks": [
        "Aspect-Based Sentiment Analysis",
        "Sentiment Analysis",
        "Structured Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.11493",
      "abstract": "Editing images using natural language instructions has become a natural and expressive way to modify visual content; yet, evaluating the performance of such models remains challenging. Existing evaluation approaches often rely on image-text similarity metrics like CLIP, which lack precision. In this work, we introduce a new benchmark designed to evaluate text-guided image editing models in a more grounded manner, along two critical dimensions: (i) functional correctness, assessed via automatically generated multiple-choice questions that verify whether the intended change was successfully applied; and (ii) image content preservation, which ensures that non-targeted regions of the image remain visually consistent using an object-aware masking technique and preservation scoring. The benchmark includes over 1000 high-quality editing examples across 20 diverse content categories, each annotated with detailed editing instructions, evaluation questions, and spatial object masks. We conduct a large-scale study comparing GPT-Image-1, the latest flagship in the text-guided image editing space, against several state-of-the-art editing models, and validate our automatic metrics against human ratings. Results show that GPT-Image-1 leads in instruction-following accuracy, but often over-modifies irrelevant image regions, highlighting a key trade-off in the current model behavior. GIE-Bench provides a scalable, reproducible framework for advancing more accurate evaluation of text-guided image editing.",
      "authors": [
        "Yusu Qian",
        "Jiasen Lu",
        "Tsu-Jui Fu",
        "Xinze Wang",
        "Chen Chen",
        "Yinfei Yang",
        "Wenze Hu",
        "Zhe Gan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T17:55:54+00:00",
          "link": "https://arxiv.org/abs/2505.11493v1",
          "size": "35762kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T05:31:10+00:00",
          "link": "https://arxiv.org/abs/2505.11493v2",
          "size": "35762kb",
          "version": "v2"
        }
      ],
      "title": "GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11493",
        "HTML": "https://arxiv.org/html/2505.11493v2",
        "PDF": "https://arxiv.org/pdf/2505.11493"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents GIE-Bench for evaluating text-guided image editing models, which is focused on image editing evaluation rather than data processing for reinforcement learning."
      },
      "tasks": [
        "Instruction Following",
        "Multiple-choice",
        "text-guided-image-editing",
        "text similarity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.14635",
      "abstract": "We present the first theoretical framework that connects predictive coding (PC), a biologically inspired local learning rule, with the minimum description length (MDL) principle in deep networks. We prove that layerwise PC performs block-coordinate descent on the MDL two-part code objective, thereby jointly minimizing empirical risk and model complexity. Using Hoeffding's inequality and a prefix-code prior, we derive a novel generalization bound of the form $R(\\theta) \\le \\hat{R}(\\theta) + \\frac{L(\\theta)}{N}$, capturing the tradeoff between fit and compression. We further prove that each PC sweep monotonically decreases the empirical two-part codelength, yielding tighter high-probability risk bounds than unconstrained gradient descent. Finally, we show that repeated PC updates converge to a block-coordinate stationary point, providing an approximate MDL-optimal solution. To our knowledge, this is the first result offering formal generalization and convergence guarantees for PC-trained deep models, positioning PC as a theoretically grounded and biologically plausible alternative to backpropagation.",
      "authors": [
        "Benjamin Prada",
        "Shion Matsumoto",
        "Abdul Malik Zekri",
        "Ankur Mali"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T17:25:16+00:00",
          "link": "https://arxiv.org/abs/2505.14635v1",
          "size": "246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:00:09+00:00",
          "link": "https://arxiv.org/abs/2505.14635v2",
          "size": "246kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Predictive Coding and MDL: A Two-Part Code Framework for Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14635",
        "HTML": "https://arxiv.org/html/2505.14635v2",
        "PDF": "https://arxiv.org/pdf/2505.14635"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work discusses theoretical connections between predictive coding and MDL in deep learning. It does not address reinforcement learning or any data processing methods within the RL setting."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.15670",
      "abstract": "Spoken dialogue is an intuitive form of human-computer interaction, yet current speech language models often remain constrained to turn-based exchanges, lacking real-time adaptability such as user barge-in. We propose a novel duplex speech to speech (S2S) architecture featuring continuous user inputs and codec agent outputs with channel fusion that directly models simultaneous user and agent streams. Using a pretrained streaming encoder for user input enables the first duplex S2S model without requiring speech pretrain. Separate architectures for agent and user modeling facilitate codec fine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared to previous works. Experimental results show that the proposed model outperforms previous duplex models in reasoning, turn-taking, and barge-in abilities. The model requires significantly less speech data, as speech pretrain is skipped, which markedly simplifies the process of building a duplex S2S model from any LLMs. Finally, it is the first openly available duplex S2S model with training and inference code to foster reproducibility.",
      "authors": [
        "Ke Hu",
        "Ehsan Hosseini-Asl",
        "Chen Chen",
        "Edresson Casanova",
        "Subhankar Ghosh",
        "Piotr \\.Zelasko",
        "Zhehuai Chen",
        "Jason Li",
        "Jagadeesh Balam",
        "Boris Ginsburg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T15:48:30+00:00",
          "link": "https://arxiv.org/abs/2505.15670v1",
          "size": "795kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T13:56:54+00:00",
          "link": "https://arxiv.org/abs/2505.15670v2",
          "size": "679kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T18:10:44+00:00",
          "link": "https://arxiv.org/abs/2505.15670v3",
          "size": "679kb",
          "version": "v3"
        }
      ],
      "title": "Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15670",
        "HTML": "https://arxiv.org/html/2505.15670v3",
        "PDF": "https://arxiv.org/pdf/2505.15670"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper proposes a duplex S2S architecture for speech language models, focusing on speech-to-speech interactions, with no discussion of reinforcement learning or data processing specific to RL datasets or workflows."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18384",
      "abstract": "Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.",
      "authors": [
        "Boyi Wei",
        "Benedikt Stroebl",
        "Jiacen Xu",
        "Joie Zhang",
        "Zhou Li",
        "Peter Henderson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T21:18:59+00:00",
          "link": "https://arxiv.org/abs/2505.18384v1",
          "size": "858kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T22:28:12+00:00",
          "link": "https://arxiv.org/abs/2505.18384v2",
          "size": "605kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T17:51:06+00:00",
          "link": "https://arxiv.org/abs/2505.18384v3",
          "size": "605kb",
          "version": "v3"
        }
      ],
      "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18384",
        "HTML": "https://arxiv.org/html/2505.18384v3",
        "PDF": "https://arxiv.org/pdf/2505.18384"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study evaluates the cybersecurity risk of autonomous programming agents by adversaries in offensive operations but does not discuss reinforcement learning or relevant data processing techniques within the RL context."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/boyiwei/dynamic-risk-assessment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23836",
      "abstract": "If AI models can detect when they are being evaluated, the effectiveness of evaluations might be compromised. For example, models could have systematically different behavior during evaluations, leading to less reliable benchmarks for deployment and governance decisions. We investigate whether frontier language models can accurately classify transcripts based on whether they originate from evaluations or real-world deployment, a capability we call evaluation awareness. To achieve this, we construct a diverse benchmark of 1,000 prompts and transcripts from 61 distinct datasets. These span public benchmarks (e.g., MMLU, SWEBench), real-world deployment interactions, and agent trajectories from scaffolding frameworks (e.g., web-browsing agents). Frontier models clearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches an AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of $0.92$). Furthermore, both AI models and humans are better at identifying evaluations in agentic settings compared to chat settings. Additionally, we test whether models can identify the purpose of the evaluation. Under multiple-choice and open-ended questioning, AI models far outperform random chance in identifying what an evaluation is testing for. Our results indicate that frontier models already exhibit a substantial, though not yet superhuman, level of evaluation-awareness. We recommend tracking this capability in future models.",
      "authors": [
        "Joe Needham",
        "Giles Edkins",
        "Govind Pimpale",
        "Henning Bartsch",
        "Marius Hobbhahn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T12:03:09+00:00",
          "link": "https://arxiv.org/abs/2505.23836v1",
          "size": "1081kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T19:01:36+00:00",
          "link": "https://arxiv.org/abs/2505.23836v2",
          "size": "1081kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T11:25:40+00:00",
          "link": "https://arxiv.org/abs/2505.23836v3",
          "size": "1081kb",
          "version": "v3"
        }
      ],
      "title": "Large Language Models Often Know When They Are Being Evaluated",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23836",
        "HTML": "https://arxiv.org/html/2505.23836v3",
        "PDF": "https://arxiv.org/pdf/2505.23836"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the evaluation awareness of language models and their ability to recognize evaluation settings, without involving reinforcement learning or data processing considerations for RL."
      },
      "datasets": [
        {
          "dataset_name": "jjpn2/eval_awareness",
          "downloads": "53",
          "likes": "0",
          "link": "https://huggingface.co/datasets/jjpn2/eval_awareness"
        }
      ],
      "tasks": [
        "MMLU",
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00713",
      "abstract": "This paper presents a framework to convert argumentative texts into argument knowledge graphs (AKG). The proposed argumentative knowledge representation framework (AKReF) extends the theoretical foundation and enables the AKG to provide a graphical view of the argumentative structure that is easier to understand. Starting with basic annotations of argumentative components (ACs) and argumentative relations (ARs), we enrich the information by constructing a knowledge base (KB) graph with metadata attributes for nodes. Next, we apply modus ponens on premises and inference rules from the KB to form arguments. From these arguments, we create an AKG. The nodes and edges of the AKG have attributes capturing key argumentative features such as the type of premise (e.g., axiom, ordinary premise, assumption), the type of inference rule (e.g., strict, defeasible), preference order over defeasible rules, markers (e.g., \"therefore\", \"however\"), and the type of attack (e.g., undercut, rebuttal, undermining). We identify inference rules by locating a specific set of markers, called inference markers (IM). This, in turn, makes it possible to identify undercut attacks previously undetectable in existing datasets. AKG prepares the ground for reasoning tasks, including checking the coherence of arguments and identifying opportunities for revision. For this, it is essential to find indirect relations, many of which are implicit. Our proposed AKG format, with annotated inference rules and modus ponens, helps reasoning models learn the implicit, indirect relations that require inference over arguments and their interconnections. We use an essay from the AAEC dataset to illustrate the framework. We further show its application in complex analyses such as extracting a conflict-free set and a maximal set of admissible arguments.",
      "authors": [
        "Debarati Bhattacharjee",
        "Ashish Anand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T21:11:30+00:00",
          "link": "https://arxiv.org/abs/2506.00713v1",
          "size": "541kb",
          "version": "v1"
        },
        {
          "date": "2025-06-15T19:52:55+00:00",
          "link": "https://arxiv.org/abs/2506.00713v2",
          "size": "243kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T21:31:55+00:00",
          "link": "https://arxiv.org/abs/2506.00713v3",
          "size": "284kb",
          "version": "v3"
        }
      ],
      "title": "AKReF: An argumentative knowledge representation framework for structured argumentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00713",
        "HTML": "https://arxiv.org/html/2506.00713v3",
        "PDF": "https://arxiv.org/pdf/2506.00713"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for converting argumentative texts into knowledge graphs and does not discuss reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.00785",
      "abstract": "This paper introduces GeoChain, a large-scale benchmark for evaluating step-by-step geographic reasoning in multimodal large language models (MLLMs). Leveraging 1.46 million Mapillary street-level images, GeoChain pairs each image with a 21-step chain-of-thought (CoT) question sequence (over 30 million Q&A pairs). These sequences guide models from coarse attributes to fine-grained localization across four reasoning categories - visual, spatial, cultural, and precise geolocation - annotated by difficulty. Images are also enriched with semantic segmentation (150 classes) and a visual locatability score. Our benchmarking of contemporary MLLMs (GPT-4.1 variants, Claude 3.7, Gemini 2.5 variants) on a diverse 2,088-image subset reveals consistent challenges: models frequently exhibit weaknesses in visual grounding, display erratic reasoning, and struggle to achieve accurate localization, especially as the reasoning complexity escalates. GeoChain offers a robust diagnostic methodology, critical for fostering significant advancements in complex geographic reasoning within MLLMs.",
      "authors": [
        "Sahiti Yerramilli",
        "Nilay Pande",
        "Rynaa Grover",
        "Jayant Sravan Tamarapalli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-01T02:24:46+00:00",
          "link": "https://arxiv.org/abs/2506.00785v1",
          "size": "3486kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:41:55+00:00",
          "link": "https://arxiv.org/abs/2506.00785v2",
          "size": "3500kb",
          "version": "v2"
        }
      ],
      "title": "GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00785",
        "HTML": "https://arxiv.org/html/2506.00785v2",
        "PDF": "https://arxiv.org/pdf/2506.00785"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "GeoChain is a benchmarking tool for geographic reasoning in multimodal models. It does not address data processing in reinforcement learning."
      },
      "datasets": [
        {
          "dataset_name": "sahitiy51/geochain",
          "downloads": "320",
          "likes": "0",
          "link": "https://huggingface.co/datasets/sahitiy51/geochain"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01588",
      "abstract": "Temporal envelope morphing, the process of interpolating between the amplitude dynamics of two audio signals, is an emerging problem in generative audio systems that lacks sufficient perceptual grounding. Morphing of temporal envelopes in a perceptually intuitive manner should enable new methods for sound blending in creative media and for probing perceptual organization in psychoacoustics. However, existing audio morphing techniques often fail to produce intermediate temporal envelopes when input sounds have distinct temporal structures; many morphers effectively overlay both temporal structures, leading to perceptually unnatural results. In this paper, we introduce a novel workflow for learning envelope morphing with perceptual guidance: we first derive perceptually grounded morphing principles through human listening studies, then synthesize large-scale datasets encoding these principles, and finally train machine learning models to create perceptually intermediate morphs. Specifically, we present: (1) perceptual principles that guide envelope morphing, derived from our listening studies, (2) a supervised framework to learn these principles, (3) an autoencoder that learns to compress temporal envelope structures into latent representations, and (4) benchmarks for evaluating audio envelope morphs, using both synthetic and naturalistic data, and show that our approach outperforms existing methods in producing temporally intermediate morphs. All code, models, and datasets will be made publicly available upon publication.",
      "authors": [
        "Satvik Dixit",
        "Sungjoon Park",
        "Chris Donahue",
        "Laurie M. Heller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T12:20:51+00:00",
          "link": "https://arxiv.org/abs/2506.01588v1",
          "size": "2037kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T00:47:39+00:00",
          "link": "https://arxiv.org/abs/2506.01588v2",
          "size": "2038kb",
          "version": "v2"
        }
      ],
      "title": "Learning Perceptually Relevant Temporal Envelope Morphing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01588",
        "HTML": "https://arxiv.org/html/2506.01588v2",
        "PDF": "https://arxiv.org/pdf/2506.01588"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for audio envelope morphing in generative audio systems, which does not involve reinforcement learning or related data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03194",
      "abstract": "Multimodal Large Language Models (MLLMs) excel at high-level visual reasoning, but their performance on nuanced perceptual tasks remains surprisingly limited. We present HueManity, a benchmark designed to assess visual perception in MLLMs. The dataset comprises 83,850 images featuring two-character alphanumeric strings embedded in Ishihara test style dot patterns, challenging models on precise pattern recognition. Our evaluation of nine state-of-the-art MLLMs on HueManity demonstrates a significant performance deficit compared to human and traditional computer vision baselines. The best-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a striking 3% on the alphanumeric `hard' task. In contrast, human participants achieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model reached accuracies of 96.5% and 94.5%. These results highlight a critical gap in the visual capabilities of current MLLMs. Our analysis further explores potential architectural and training-paradigm factors contributing to this perceptual gap in MLLMs. We open-source HueManity dataset and code to foster further research in improving perceptual robustness of MLLMs.",
      "authors": [
        "Rynaa Grover",
        "Jayant Sravan Tamarapalli",
        "Sahiti Yerramilli",
        "Nilay Pande"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T22:59:48+00:00",
          "link": "https://arxiv.org/abs/2506.03194v1",
          "size": "1085kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:42:22+00:00",
          "link": "https://arxiv.org/abs/2506.03194v2",
          "size": "1100kb",
          "version": "v2"
        }
      ],
      "title": "HueManity: Probing Fine-Grained Visual Perception in MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03194",
        "HTML": "https://arxiv.org/html/2506.03194v2",
        "PDF": "https://arxiv.org/pdf/2506.03194"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "HueManity is a benchmark for assessing visual perception in multimodal large language models and does not address data processing in reinforcement learning."
      },
      "datasets": [
        {
          "dataset_name": "Jayant-Sravan/HueManity",
          "downloads": "201",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Jayant-Sravan/HueManity"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04135",
      "abstract": "Graphical User Interface (GUI) agents show promising capabilities for automating computer-use tasks and facilitating accessibility, but existing interactive benchmarks are mostly English-only, covering web-use or Windows, Linux, and Android environments, but not macOS. macOS is a major OS with distinctive GUI patterns and exclusive applications. To bridge the gaps, we present macOSWorld, the first comprehensive benchmark for evaluating GUI agents on macOS. macOSWorld features 202 multilingual interactive tasks across 30 applications (28 macOS-exclusive), with task instructions and OS interfaces offered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As GUI agents are shown to be vulnerable to deception attacks, macOSWorld also includes a dedicated safety benchmarking subset. Our evaluation on six GUI agents reveals a dramatic gap: proprietary computer-use agents lead at above 30% success rate, while open-source lightweight research models lag at below 5%, highlighting the need for macOS domain adaptation. Multilingual benchmarks also expose common weaknesses, especially in Arabic, with a 28.8% average degradation compared to English. Results from safety benchmarking also highlight that deception attacks are more general and demand immediate attention. macOSWorld is available at https://github.com/showlab/macosworld.",
      "authors": [
        "Pei Yang",
        "Hai Ci",
        "and Mike Zheng Shou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T16:26:56+00:00",
          "link": "https://arxiv.org/abs/2506.04135v1",
          "size": "8212kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T16:03:48+00:00",
          "link": "https://arxiv.org/abs/2506.04135v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T05:46:51+00:00",
          "link": "https://arxiv.org/abs/2506.04135v3",
          "size": "8906kb",
          "version": "v3"
        }
      ],
      "title": "macOSWorld: A Multilingual Interactive Benchmark for GUI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04135",
        "HTML": "https://arxiv.org/html/2506.04135v3",
        "PDF": "https://arxiv.org/pdf/2506.04135"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "macOSWorld is a benchmark for evaluating GUI agents in a macOS environment and does not relate to data processing in reinforcement learning."
      },
      "tasks": [
        "Benchmarking",
        "Domain Adaptation"
      ],
      "repo_urls": [
        "https://github.com/showlab/macosworld"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04602",
      "abstract": "The burgeoning growth of the esports and multiplayer online gaming community has highlighted the critical importance of evaluating the Most Valuable Player (MVP). The establishment of an explainable and practical MVP evaluation method is very challenging. In our study, we specifically focus on play-by-play data, which records related events during the game, such as assists and points. We aim to address the challenges by introducing a new MVP evaluation framework, denoted as \\oursys, which leverages Shapley values. This approach encompasses feature processing, win-loss model training, Shapley value allocation, and MVP ranking determination based on players' contributions. Additionally, we optimize our algorithm to align with expert voting results from the perspective of causality. Finally, we substantiated the efficacy of our method through validation using the NBA dataset and the Dunk City Dynasty dataset and implemented online deployment in the industry.",
      "authors": [
        "Haifeng Sun",
        "Yu Xiong",
        "Runze Wu",
        "Kai Wang",
        "Lan Zhang",
        "Changjie Fan",
        "Shaojie Tang",
        "Xiang-Yang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T03:40:22+00:00",
          "link": "https://arxiv.org/abs/2506.04602v1",
          "size": "3968kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:12:42+00:00",
          "link": "https://arxiv.org/abs/2506.04602v2",
          "size": "3968kb",
          "version": "v2"
        }
      ],
      "title": "MVP-Shapley: Feature-based Modeling for Evaluating the Most Valuable Player in Basketball",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04602",
        "HTML": "https://arxiv.org/html/2506.04602v2",
        "PDF": "https://arxiv.org/pdf/2506.04602"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the Most Valuable Player (MVP) in basketball using feature-based modeling and Shapley values, without any reference to reinforcement learning or data processing within the RL context."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.05566",
      "abstract": "Recent advances in large language models (LLMs) have enabled near-human performance on software coding benchmarks, but their effectiveness in RTL code generation remains limited due to the scarcity of high-quality training data. While prior efforts have fine-tuned LLMs for RTL tasks, they do not fundamentally overcome the data bottleneck and lack support for test-time scaling due to their non-reasoning nature. In this work, we introduce ScaleRTL, the first reasoning LLM for RTL coding that scales up both high-quality reasoning data and test-time compute. Specifically, we curate a diverse set of long chain-of-thought reasoning traces averaging 56K tokens each, resulting in a dataset of 3.5B tokens that captures rich RTL knowledge. Fine-tuning a general-purpose reasoning model on this corpus yields ScaleRTL that is capable of deep RTL reasoning. Subsequently, we further enhance the performance of ScaleRTL through a novel test-time scaling strategy that extends the reasoning process via iteratively reflecting on and self-correcting previous reasoning steps. Experimental results show that ScaleRTL achieves state-of-the-art performance on VerilogEval and RTLLM, outperforming 18 competitive baselines by up to 18.4% on VerilogEval and 12.7% on RTLLM.",
      "authors": [
        "Chenhui Deng",
        "Yun-Da Tsai",
        "Guan-Ting Liu",
        "Zhongzhi Yu",
        "Haoxing Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T20:24:58+00:00",
          "link": "https://arxiv.org/abs/2506.05566v1",
          "size": "2055kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T21:44:21+00:00",
          "link": "https://arxiv.org/abs/2506.05566v2",
          "size": "2012kb",
          "version": "v2"
        }
      ],
      "title": "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05566",
        "HTML": "https://arxiv.org/html/2506.05566v2",
        "PDF": "https://arxiv.org/pdf/2506.05566"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses curating reasoning data and scaling large model computations for RTL code generation, but does not mention reinforcement learning or RL-specific data processing techniques."
      },
      "tasks": [
        "Code Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05935",
      "abstract": "Intraoperative navigation relies heavily on precise 3D reconstruction to ensure accuracy and safety during surgical procedures. However, endoscopic scenarios present unique challenges, including sparse features and inconsistent lighting, which render many existing Structure-from-Motion (SfM)-based methods inadequate and prone to reconstruction failure. To mitigate these constraints, we propose SurGSplat, a novel paradigm designed to progressively refine 3D Gaussian Splatting (3DGS) through the integration of geometric constraints. By enabling the detailed reconstruction of vascular structures and other critical features, SurGSplat provides surgeons with enhanced visual clarity, facilitating precise intraoperative decision-making. Experimental evaluations demonstrate that SurGSplat achieves superior performance in both novel view synthesis (NVS) and pose estimation accuracy, establishing it as a high-fidelity and efficient solution for surgical scene reconstruction. More information and results can be found on the page https://surgsplat.github.io/.",
      "authors": [
        "Yuchao Zheng",
        "Jianing Zhang",
        "Guochen Ning",
        "Hongen Liao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T10:02:11+00:00",
          "link": "https://arxiv.org/abs/2506.05935v1",
          "size": "6133kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T10:02:27+00:00",
          "link": "https://arxiv.org/abs/2506.05935v2",
          "size": "6133kb",
          "version": "v2"
        }
      ],
      "title": "SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05935",
        "HTML": "https://arxiv.org/html/2506.05935v2",
        "PDF": "https://arxiv.org/pdf/2506.05935"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper describes a methodology for 3D reconstruction in surgical environments with Gaussian Splatting, and makes no mention of reinforcement learning or associated data processing in an RL context."
      },
      "tasks": [
        "3DGS",
        "3D Reconstruction",
        "Decision Making",
        "Novel View Synthesis",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.06852",
      "abstract": "Semantic segmentation of satellite imagery is crucial for Earth observation applications, but remains constrained by limited labelled training data. While self-supervised pretraining methods like Masked Autoencoders (MAE) have shown promise, they focus on reconstruction rather than localisation-a fundamental aspect of segmentation tasks. We propose adapting LOCA (Location-aware), a position prediction self-supervised learning method, for multimodal satellite imagery semantic segmentation. Our approach addresses the unique challenges of satellite data by extending SatMAE's channel grouping from multispectral to multimodal data, enabling effective handling of multiple modalities, and introducing same-group attention masking to encourage cross-modal interaction during pretraining. The method uses relative patch position prediction, encouraging spatial reasoning for localisation rather than reconstruction. We evaluate our approach on the Sen1Floods11 flood mapping dataset, where it significantly outperforms existing reconstruction-based self-supervised learning methods for satellite imagery. Our results demonstrate that position prediction tasks, when properly adapted for multimodal satellite imagery, learn representations more effective for satellite image semantic segmentation than reconstruction-based approaches.",
      "authors": [
        "John Waithaka and Moise Busogi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T16:16:29+00:00",
          "link": "https://arxiv.org/abs/2506.06852v1",
          "size": "1502kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:30:34+00:00",
          "link": "https://arxiv.org/abs/2506.06852v2",
          "size": "75kb",
          "version": "v2"
        }
      ],
      "title": "Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06852",
        "HTML": "https://arxiv.org/html/2506.06852v2",
        "PDF": "https://arxiv.org/pdf/2506.06852"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on semantic segmentation in satellite imagery using self-supervised learning, without any connection to reinforcement learning or RL data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10323",
      "abstract": "Generation-based fuzzing produces appropriate testing cases according to specifications of input grammars and semantic constraints to test systems and software. However, these specifications require significant manual efforts to construct. This paper proposes a new approach, ELFuzz (Evolution Through Large Language Models for Fuzzing), that automatically synthesizes generation-based fuzzers tailored to a system under test (SUT) via LLM-driven synthesis over fuzzer space. At a high level, it starts with minimal seed fuzzers and propels the synthesis by fully automated LLM-driven evolution with coverage guidance. Compared to previous approaches, ELFuzz can 1) seamlessly scale to SUTs of real-world sizes -- up to 1,791,104 lines of code in our evaluation -- and 2) synthesize efficient fuzzers that catch interesting grammatical structures and semantic constraints in a human-understandable way. Our evaluation compared ELFuzz with specifications manually written by domain experts and synthesized by state-of-the-art approaches. It shows that ELFuzz achieves up to 434.8% more coverage and triggers up to 174.0% more artificially injected bugs. We also used ELFuzz to conduct a real-world fuzzing campaign on the newest version of cvc5 for 14 days, and encouragingly, it found five 0-day bugs (three are exploitable). Moreover, we conducted an ablation study, which shows that the fuzzer space model, the key component of ELFuzz, contributes the most (up to 62.5%) to the effectiveness of ELFuzz. Further analysis of the fuzzers synthesized by ELFuzz confirms that they catch interesting grammatical structures and semantic constraints in a human-understandable way. The results present the promising potential of ELFuzz for more automated, efficient, and extensible input generation for fuzzing.",
      "authors": [
        "Chuyang Chen",
        "Brendan Dolan-Gavitt",
        "Zhiqiang Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T03:13:55+00:00",
          "link": "https://arxiv.org/abs/2506.10323v1",
          "size": "1388kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T23:40:44+00:00",
          "link": "https://arxiv.org/abs/2506.10323v2",
          "size": "1388kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T18:15:42+00:00",
          "link": "https://arxiv.org/abs/2506.10323v3",
          "size": "1388kb",
          "version": "v3"
        }
      ],
      "title": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10323",
        "HTML": "https://arxiv.org/html/2506.10323v3",
        "PDF": "https://arxiv.org/pdf/2506.10323"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces ELFuzz, a method for input generation in fuzz testing using LLM-driven synthesis. The focus is on automated synthesis and efficiency in fuzzing, without any discussion on reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10972",
      "abstract": "Training Large Language Models (LLMs) is prohibitively expensive, creating a critical scaling gap where insights from small-scale experiments often fail to transfer to resource-intensive production systems, thereby hindering efficient innovation. To bridge this, we introduce Farseer, a novel and refined scaling law offering enhanced predictive accuracy across scales. By systematically constructing a model loss surface $L(N,D)$, Farseer achieves a significantly better fit to empirical data than prior laws (e.g., Chinchilla's law). Our methodology yields accurate, robust, and highly generalizable predictions, demonstrating excellent extrapolation capabilities, improving upon Chinchilla's law by reducing extrapolation error by 433\\%. This allows for the reliable evaluation of competing training strategies across all $(N,D)$ settings, enabling conclusions from small-scale ablation studies to be confidently extrapolated to predict large-scale performance. Furthermore, Farseer provides new insights into optimal compute allocation, better reflecting the nuanced demands of modern LLM training. To validate our approach, we trained an extensive suite of approximately 1,000 LLMs across diverse scales and configurations, consuming roughly 3 million NVIDIA H100 GPU hours. We are comprehensively open-sourcing all models, data, results, and logs at https://github.com/Farseer-Scaling-Law/Farseer to foster further research.",
      "authors": [
        "Houyi Li",
        "Wenzhen Zheng",
        "Qiufeng Wang",
        "Zhenyu Ding",
        "Haoying Wang",
        "Zili Wang",
        "Shijie Xuyang",
        "Ning Ding",
        "Shuigeng Zhou",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T17:59:23+00:00",
          "link": "https://arxiv.org/abs/2506.10972v1",
          "size": "5367kb",
          "version": "v1"
        },
        {
          "date": "2025-06-14T06:44:54+00:00",
          "link": "https://arxiv.org/abs/2506.10972v2",
          "size": "5385kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T07:09:02+00:00",
          "link": "https://arxiv.org/abs/2506.10972v3",
          "size": "5385kb",
          "version": "v3"
        }
      ],
      "title": "Predictable Scale: Part II, Farseer: A Refined Scaling Law in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10972",
        "HTML": "https://arxiv.org/html/2506.10972v3",
        "PDF": "https://arxiv.org/pdf/2506.10972"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Farseer addresses scaling laws for Large Language Models to predict performance across scales, focusing on predictive accuracy and compute allocation in LLM training. It does not pertain to reinforcement learning or data processing within the RL context."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/farseer-scaling-law/farseer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13212",
      "abstract": "The computation of volumetric correspondences between 3D shapes is a prominent tool for medical and industrial applications. In this work, we pave the way for spectral volume mapping, extending for the first time the functional maps framework from the surface to the volumetric setting. We show that the eigenfunctions of the volumetric Laplace operator define a functional space that is suitable for high-quality signal transfer. We also experiment with various techniques that edit this functional space, porting them to volume domains. We validate our method on novel volumetric datasets and on tetrahedralizations of well established surface datasets, also showcasing practical applications involving both discrete and continuous signal mapping, for segmentation transfer, mesh connectivity transfer and solid texturing. Last but not least, we show that considering the volumetric spectrum greatly improves the accuracy for classical shape matching tasks among surfaces, consistently outperforming existing surface-only spectral methods.",
      "authors": [
        "Filippo Maggioli",
        "Simone Melzi",
        "Marco Livesu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T08:13:57+00:00",
          "link": "https://arxiv.org/abs/2506.13212v1",
          "size": "9092kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T18:30:33+00:00",
          "link": "https://arxiv.org/abs/2506.13212v2",
          "size": "10021kb",
          "version": "v2"
        }
      ],
      "title": "Volumetric Functional Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13212",
        "HTML": "https://arxiv.org/html/2506.13212v2",
        "PDF": "https://arxiv.org/pdf/2506.13212"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses volumetric correspondences for 3D shapes using functional maps, introducing applications primarily in medical and industrial sectors. It does not relate to reinforcement learning or involve data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14485",
      "abstract": "Constraint Handling Rules (CHR) is a rule-based programming language that rewrites collections of constraints. It is typically embedded into a general-purpose language. There exists a plethora of implementation for numerous host languages. However, the existing implementations often re-invent the method of embedding, which impedes maintenance and weakens assertions of correctness. To formalize and thereby standardize the embedding of a ground subset of CHR into arbitrary host languages, we introduced the framework FreeCHR and proved it to be a valid representation of classical CHR. For the sake of simplicity, abstract implementations of our framework did not yet include a concrete matching algorithm nor optimizations. In this paper, we introduce an improved execution and matching algorithm for FreeCHR. We also provide empirical evaluation of the algorithm.",
      "authors": [
        "Sascha Rechenberger and Thom Fr\\\"uhwirth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T13:07:30+00:00",
          "link": "https://arxiv.org/abs/2506.14485v1",
          "size": "81kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:17:34+00:00",
          "link": "https://arxiv.org/abs/2506.14485v2",
          "size": "81kb",
          "version": "v2"
        }
      ],
      "title": "Optimized Execution of FreeCHR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14485",
        "PDF": "https://arxiv.org/pdf/2506.14485"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in execution and matching algorithms for Constraint Handling Rules (CHR), which does not relate to reinforcement learning or data processing within RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15026",
      "abstract": "The rapid advancements in autonomous vehicle (AV) technology promise enhanced safety and operational efficiency. However, frequent lane changes and merging maneuvers continue to pose significant safety risks and disrupt traffic flow. This paper introduces the Minimizing Lane Change Algorithm (MLCA), a state-machine-based approach designed to reduce unnecessary lane changes, thereby enhancing both traffic safety and efficiency. The MLCA algorithm prioritizes maintaining lane stability unless safety-critical conditions necessitate a lane change. The algorithm's effectiveness was evaluated through simulations conducted on the SUMO platform, comparing its performance against established models, including LC2017 and MOBIL. Results demonstrate substantial reductions in lane changes and collisions, leading to smoother traffic flow and improved safety metrics. Additionally, the study highlights the MLCA's adaptability to various traffic densities and roadway configurations, showcasing its potential for wide-scale deployment in real-world AV systems. Future work aims to validate these findings in more complex scenarios using the CARLA simulator, which will enable the testing of the algorithm under more dynamic and high-fidelity conditions, such as urban traffic environments with diverse road users. Moreover, the integration of cybersecurity measures for vehicle-to-vehicle (V2V) communication will be explored to ensure robust and secure data exchange, further enhancing the reliability and safety of AV operations. This research contributes to the broader goal of developing intelligent traffic systems that optimize both individual vehicle performance and overall traffic network efficiency.",
      "authors": [
        "Seyed Moein Abtahi and Akramul Azim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T23:59:06+00:00",
          "link": "https://arxiv.org/abs/2506.15026v1",
          "size": "233kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:59:02+00:00",
          "link": "https://arxiv.org/abs/2506.15026v2",
          "size": "83kb",
          "version": "v2"
        }
      ],
      "title": "Algorithmic Approaches to Enhance Safety in Autonomous Vehicles: Minimizing Lane Changes and Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15026",
        "HTML": "https://arxiv.org/html/2506.15026v2",
        "PDF": "https://arxiv.org/pdf/2506.15026"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithms for minimizing lane changes in autonomous vehicles using simulations, but it does not discuss reinforcement learning or RL-related data processing techniques."
      },
      "tasks": [
        "Autonomous Vehicles"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18212",
      "abstract": "In this paper, we introduce Haptic-Informed ACT, an advanced robotic system for pseudo oocyte manipulation, integrating multimodal information and Action Chunking with Transformers (ACT). Traditional automation methods for oocyte transfer rely heavily on visual perception, often requiring human supervision due to biological variability and environmental disturbances. Haptic-Informed ACT enhances ACT by incorporating haptic feedback, enabling real-time grasp failure detection and adaptive correction. Additionally, we introduce a 3D-printed TPU soft gripper to facilitate delicate manipulations. Experimental results demonstrate that Haptic-Informed ACT improves the task success rate, robustness, and adaptability compared to conventional ACT, particularly in dynamic environments. These findings highlight the potential of multimodal learning in robotics for biomedical automation.",
      "authors": [
        "Pedro Miguel Uriguen Eljuri",
        "Hironobu Shibata",
        "Maeyama Katsuyoshi",
        "Yuanyuan Jia",
        "and Tadahiro Taniguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T00:18:40+00:00",
          "link": "https://arxiv.org/abs/2506.18212v1",
          "size": "6362kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:48:37+00:00",
          "link": "https://arxiv.org/abs/2506.18212v2",
          "size": "6362kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T02:02:27+00:00",
          "link": "https://arxiv.org/abs/2506.18212v3",
          "size": "6305kb",
          "version": "v3"
        }
      ],
      "title": "Haptic-Informed ACT with a Soft Gripper and Recovery-Informed Training for Pseudo Oocyte Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18212",
        "HTML": "https://arxiv.org/html/2506.18212v3",
        "PDF": "https://arxiv.org/pdf/2506.18212"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a robotic system for oocyte manipulation with haptic feedback, concentrating on task success and adaptability without any discussion on reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18296",
      "abstract": "We construct Japanese Idol Speech Corpus (JIS) to advance research in speech generation AI, including text-to-speech synthesis (TTS) and voice conversion (VC). JIS will facilitate more rigorous evaluations of speaker similarity in TTS and VC systems since all speakers in JIS belong to a highly specific category: \"young female live idols\" in Japan, and each speaker is identified by a stage name, enabling researchers to recruit listeners familiar with these idols for listening experiments. With its unique speaker attributes, JIS will foster compelling research, including generating voices tailored to listener preferences-an area not yet widely studied. JIS will be distributed free of charge to promote research in speech generation AI, with usage restricted to non-commercial, basic research. We describe the construction of JIS, provide an overview of Japanese live idol culture to support effective and ethical use of JIS, and offer a basic analysis to guide application of JIS.",
      "authors": [
        "Yuto Kondo",
        "Hirokazu Kameoka",
        "Kou Tanaka",
        "Takuhiro Kaneko"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T05:23:34+00:00",
          "link": "https://arxiv.org/abs/2506.18296v1",
          "size": "336kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T23:31:58+00:00",
          "link": "https://arxiv.org/abs/2506.18296v2",
          "size": "336kb",
          "version": "v2"
        }
      ],
      "title": "JIS: A Speech Corpus of Japanese Idol Speakers with Various Speaking Styles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18296",
        "HTML": "https://arxiv.org/html/2506.18296v2",
        "PDF": "https://arxiv.org/pdf/2506.18296"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses the construction of a speech corpus for research in speech generation AI but does not address any aspects related to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21030",
      "abstract": "The ability to perform reliable long-horizon task planning is crucial for deploying robots in real-world environments. However, directly employing Large Language Models (LLMs) as action sequence generators often results in low success rates due to their limited reasoning ability for long-horizon embodied tasks. In the STEP framework, we construct a subgoal tree through a pair of closed-loop models: a subgoal decomposition model and a leaf node termination model. Within this framework, we develop a hierarchical tree structure that spans from coarse to fine resolutions. The subgoal decomposition model leverages a foundation LLM to break down complex goals into manageable subgoals, thereby spanning the subgoal tree. The leaf node termination model provides real-time feedback based on environmental states, determining when to terminate the tree spanning and ensuring each leaf node can be directly converted into a primitive action. Experiments conducted in both the VirtualHome WAH-NL benchmark and on real robots demonstrate that STEP achieves long-horizon embodied task completion with success rates up to 34% (WAH-NL) and 25% (real robot) outperforming SOTA methods.",
      "authors": [
        "Tianxing Zhou",
        "Zhirui Wang",
        "Haojia Ao",
        "Guangyan Chen",
        "Boyang Xing",
        "Jingwen Cheng",
        "Yi Yang",
        "Yufeng Yue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T06:10:02+00:00",
          "link": "https://arxiv.org/abs/2506.21030v1",
          "size": "11815kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:41:36+00:00",
          "link": "https://arxiv.org/abs/2506.21030v2",
          "size": "11815kb",
          "version": "v2"
        }
      ],
      "title": "STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21030",
        "HTML": "https://arxiv.org/html/2506.21030v2",
        "PDF": "https://arxiv.org/pdf/2506.21030"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper outlines a framework for embodied task planning using subgoal trees, which involves processing environmental state data to terminate subgoal trees. This is related to processing data in RL but isn't a direct or novel contribution to RL data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21316",
      "abstract": "Visual grounding in text-rich document images is a critical yet underexplored challenge for Document Intelligence and Visual Question Answering (VQA) systems. We present DRISHTIKON, a multi-granular and multi-block visual grounding framework designed to enhance interpretability and trust in VQA for complex, multilingual documents. Our approach integrates multilingual OCR, large language models, and a novel region matching algorithm to localize answer spans at the block, line, word, and point levels. We introduce the Multi-Granular Visual Grounding (MGVG) benchmark, a curated test set of diverse circular notifications from various sectors, each manually annotated with fine-grained, human-verified labels across multiple granularities. Extensive experiments show that our method achieves state-of-the-art grounding accuracy, with line-level granularity providing the best balance between precision and recall. Ablation studies further highlight the benefits of multi-block and multi-line reasoning. Comparative evaluations reveal that leading vision-language models struggle with precise localization, underscoring the effectiveness of our structured, alignment-based approach. Our findings pave the way for more robust and interpretable document understanding systems in real-world, text-centric scenarios with multi-granular grounding support. Code and dataset are made available for future research.",
      "authors": [
        "Badri Vishal Kasuba",
        "Parag Chaudhuri",
        "Ganesh Ramakrishnan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:32:23+00:00",
          "link": "https://arxiv.org/abs/2506.21316v1",
          "size": "2721kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T01:55:35+00:00",
          "link": "https://arxiv.org/abs/2506.21316v2",
          "size": "4399kb",
          "version": "v2"
        }
      ],
      "title": "DRISHTIKON: Visual Grounding at Multiple Granularities in Documents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21316",
        "HTML": "https://arxiv.org/html/2506.21316v2",
        "PDF": "https://arxiv.org/pdf/2506.21316"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This research introduces a multi-granular visual grounding framework within document images for VQA systems, which is unrelated to reinforcement learning or its data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21444",
      "abstract": "Atypical mitosis marks a deviation in the cell division process that has been shown be an independent prognostic marker for tumor malignancy. However, atypical mitosis classification remains challenging due to low prevalence, at times subtle morphological differences from normal mitotic figures, low inter-rater agreement among pathologists, and class imbalance in datasets. Building on the Atypical Mitosis dataset for Breast Cancer (AMi-Br), this study presents a comprehensive benchmark comparing deep learning approaches for automated atypical mitotic figure (AMF) classification, including end-to-end trained deep learning models, foundation models with linear probing, and foundation models fine-tuned with low-rank adaptation (LoRA). For rigorous evaluation, we further introduce two new held-out AMF datasets - AtNorM-Br, a dataset of mitotic figures from the TCGA breast cancer cohort, and AtNorM-MD, a multi-domain dataset of mitotic figures from a subset of the MIDOG++ training set. We found average balanced accuracy values of up to 0.8135, 0.7788, and 0.7723 on the in-domain AMi-Br and the out-of-domain AtNorm-Br and AtNorM-MD datasets, respectively. Our work shows that atypical mitotic figure classification, while being a challenging problem, can be effectively addressed through the use of recent advances in transfer learning and model fine-tuning techniques. We make all code and data used in this paper available in this github repository: https://github.com/DeepMicroscopy/AMi-Br_Benchmark.",
      "authors": [
        "Sweta Banerjee",
        "Viktoria Weiss",
        "Taryn A. Donovan",
        "Rutger H.J. Fick",
        "Thomas Conrad",
        "Jonas Ammeling",
        "Nils Porsche",
        "Robert Klopfleisch",
        "Christopher Kaltenecker",
        "Katharina Breininger",
        "Marc Aubreville",
        "Christof A. Bertram"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:30:42+00:00",
          "link": "https://arxiv.org/abs/2506.21444v1",
          "size": "997kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:20:11+00:00",
          "link": "https://arxiv.org/abs/2506.21444v2",
          "size": "1456kb",
          "version": "v2"
        }
      ],
      "title": "Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21444",
        "HTML": "https://arxiv.org/html/2506.21444v2",
        "PDF": "https://arxiv.org/pdf/2506.21444"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper primarily benchmarks deep learning models for atypical versus normal mitosis classification, focusing on vision and deep learning models rather than reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22027",
      "abstract": "Detecting and tracking ground objects using earth observation imagery remains a significant challenge in the field of remote sensing. Continuous maritime ship tracking is crucial for applications such as maritime search and rescue, law enforcement, and shipping analysis. However, most current ship tracking methods rely on geostationary satellites or video satellites. The former offer low resolution and are susceptible to weather conditions, while the latter have short filming durations and limited coverage areas, making them less suitable for the real-world requirements of ship tracking. To address these limitations, we present the Hybrid Optical and Synthetic Aperture Radar (SAR) Ship Re-Identification Dataset (HOSS ReID dataset), designed to evaluate the effectiveness of ship tracking using low-Earth orbit constellations of optical and SAR sensors. This approach ensures shorter re-imaging cycles and enables all-weather tracking. HOSS ReID dataset includes images of the same ship captured over extended periods under diverse conditions, using different satellites of different modalities at varying times and angles. Furthermore, we propose a baseline method for cross-modal ship re-identification, TransOSS, which is built on the Vision Transformer architecture. It refines the patch embedding structure to better accommodate cross-modal tasks, incorporates additional embeddings to introduce more reference information, and employs contrastive learning to pre-train on large-scale optical-SAR image pairs, ensuring the model's ability to extract modality-invariant features. Our dataset and baseline method are publicly available on https://github.com/Alioth2000/Hoss-ReID.",
      "authors": [
        "Han Wang",
        "Shengyang Li",
        "Jian Yang",
        "Yuxuan Liu",
        "Yixuan Lv",
        "Zhuang Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2506.22027v1",
          "size": "1008kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:25:58+00:00",
          "link": "https://arxiv.org/abs/2506.22027v2",
          "size": "1342kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T02:40:11+00:00",
          "link": "https://arxiv.org/abs/2506.22027v3",
          "size": "1340kb",
          "version": "v3"
        }
      ],
      "title": "Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22027",
        "HTML": "https://arxiv.org/html/2506.22027v3",
        "PDF": "https://arxiv.org/pdf/2506.22027"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a dataset for ship re-identification using optical and SAR imagery and proposes a method based on Vision Transformer, without discussing reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22196",
      "abstract": "Lambek and Scott constructed a correspondence between simply-typed lambda calculi and Cartesian closed categories. Scott's Representation Theorem is a cousin to this result for untyped lambda calculi. It states that every untyped lambda calculus arises from a reflexive object in some category. We present a formalization of Scott's Representation Theorem in univalent foundations, in the (Rocq-)UniMath library. Specifically, we implement two proofs of that theorem, one by Scott and one by Hyland. We also explain the role of the Karoubi envelope -- a categorical construction -- in the proofs and the impact the chosen foundation has on this construction. Finally, we report on some automation we have implemented for the reduction of $\\lambda$-terms.",
      "authors": [
        "Arnoud van der Leer",
        "Kobe Wullaert",
        "and Benedikt Ahrens"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:04:36+00:00",
          "link": "https://arxiv.org/abs/2506.22196v1",
          "size": "121kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:00:43+00:00",
          "link": "https://arxiv.org/abs/2506.22196v2",
          "size": "121kb",
          "version": "v2"
        }
      ],
      "title": "Scott's Representation Theorem and the Univalent Karoubi Envelope",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22196",
        "HTML": "https://arxiv.org/html/2506.22196v2",
        "PDF": "https://arxiv.org/pdf/2506.22196"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with formalizing Scott's Representation Theorem in univalent foundations and does not mention reinforcement learning or RL-related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23210",
      "abstract": "Federated learning(FL) is used for distributed scenarios to train artificial intelligence(AI) models while ensuring users' privacy. In federated learning scenario, the server generally never knows about users' data. This type of concept makes the AI training process efficient in terms of data privacy. However, regarding model performance, federated AI models may not sufficiently satisfy AI users' expectations. Furthermore, AI users have a wide range of different needs. It is not easy to satisfy the whole users needs. These types of issues can be addressed through AI model optimization, fine-tuning, or personalization to achieve optimal model performance. To address model optimization challenges, we propose reference model-based federated learning for optimal fine-tuning, which overcomes catastrophic forgetting in each round. This method is derived from Bayesian parameter-efficient transfer learning, which includes an optimal proximal term and utilizes a reference model that incorporates previous model parameters. As a result, this method achieves both high model performance and clients' low computing cost.",
      "authors": [
        "Taehwan Yoon",
        "Bongjun Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:41:11+00:00",
          "link": "https://arxiv.org/abs/2506.23210v1",
          "size": "657kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:06:41+00:00",
          "link": "https://arxiv.org/abs/2506.23210v2",
          "size": "802kb",
          "version": "v2"
        }
      ],
      "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23210",
        "HTML": "https://arxiv.org/html/2506.23210v2",
        "PDF": "https://arxiv.org/pdf/2506.23210"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated learning and model optimization through reference-based fine-tuning. It doesn't discuss data processing within the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23234",
      "abstract": "Pre-trained models (PTMs) have gained widespread popularity and achieved remarkable success across various fields, driven by their groundbreaking performance and easy accessibility through hosting providers. However, the challenges faced by downstream developers in reusing PTMs in software systems are less explored. To bridge this knowledge gap, we qualitatively created and analyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub projects. We systematically developed a comprehensive taxonomy of PTM-related challenges that developers face in downstream projects. Our study identifies seven key categories of challenges that downstream developers face in reusing PTMs, such as model usage, model performance, and output quality. We also compared our findings with existing taxonomies. Additionally, we conducted a resolution time analysis and, based on statistical tests, found that PTM-related issues take significantly longer to be resolved than issues unrelated to PTMs, with significant variation across challenge categories. We discuss the implications of our findings for practitioners and possibilities for future research.",
      "authors": [
        "Peerachai Banyongrakkul",
        "Mansooreh Zahedi",
        "Patanamon Thongtanunam",
        "Christoph Treude and Haoyu Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:36:58+00:00",
          "link": "https://arxiv.org/abs/2506.23234v1",
          "size": "1707kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:04:59+00:00",
          "link": "https://arxiv.org/abs/2506.23234v2",
          "size": "1617kb",
          "version": "v2"
        }
      ],
      "title": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23234",
        "HTML": "https://arxiv.org/html/2506.23234v2",
        "PDF": "https://arxiv.org/pdf/2506.23234"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper analyzes challenges faced when reusing pre-trained models in downstream projects and explores PTM-related issues. It does not cover data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23603",
      "abstract": "As Large Language Models (LLMs) are increasingly deployed in sensitive domains, traditional data privacy measures prove inadequate for protecting information that is implicit, contextual, or inferable - what we define as semantic privacy. This Systematization of Knowledge (SoK) introduces a lifecycle-centric framework to analyze how semantic privacy risks emerge across input processing, pretraining, fine-tuning, and alignment stages of LLMs. We categorize key attack vectors and assess how current defenses, such as differential privacy, embedding encryption, edge computing, and unlearning, address these threats. Our analysis reveals critical gaps in semantic-level protection, especially against contextual inference and latent representation leakage. We conclude by outlining open challenges, including quantifying semantic leakage, protecting multimodal inputs, balancing de-identification with generation quality, and ensuring transparency in privacy enforcement. This work aims to inform future research on designing robust, semantically aware privacy-preserving techniques for LLMs.",
      "authors": [
        "Baihe Ma",
        "Yanna Jiang",
        "Xu Wang",
        "Guangsheng Yu",
        "Qin Wang",
        "Caijun Sun",
        "Chen Li",
        "Xuelei Qi",
        "Ying He",
        "Wei Ni",
        "Ren Ping Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:08:15+00:00",
          "link": "https://arxiv.org/abs/2506.23603v1",
          "size": "401kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:51:30+00:00",
          "link": "https://arxiv.org/abs/2506.23603v2",
          "size": "1685kb",
          "version": "v2"
        }
      ],
      "title": "SoK: Semantic Privacy in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23603",
        "HTML": "https://arxiv.org/html/2506.23603v2",
        "PDF": "https://arxiv.org/pdf/2506.23603"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses semantic privacy in large language models, including threats across various stages like pretraining and fine-tuning. It does not involve data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00406",
      "abstract": "Feedback is one of the most crucial components to facilitate effective learning. With the rise of large language models (LLMs) in recent years, research in programming education has increasingly focused on automated feedback generation to help teachers provide timely support to every student. However, prior studies often overlook key pedagogical principles, such as mastery and progress adaptation, that shape effective feedback strategies. This paper introduces a novel pedagogical framework for LLM-driven feedback generation derived from established feedback models and local insights from secondary school teachers. To evaluate this framework, we implemented a web-based application for Python programming with LLM-based feedback that follows the framework and conducted a mixed-method evaluation with eight secondary-school computer science teachers. Our findings suggest that teachers consider that, when aligned with the framework, LLMs can effectively support students and even outperform human teachers in certain scenarios through instant and precise feedback. However, we also found several limitations, such as its inability to adapt feedback to dynamic classroom contexts. Such a limitation highlights the need to complement LLM-generated feedback with human expertise to ensure effective student learning. This work demonstrates an effective way to use LLMs for feedback while adhering to pedagogical standards and highlights important considerations for future systems.",
      "authors": [
        "Niklas Scholz",
        "Manh Hung Nguyen",
        "Adish Singla and Tomohiro Nagashima"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T03:48:48+00:00",
          "link": "https://arxiv.org/abs/2507.00406v1",
          "size": "1553kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T04:02:40+00:00",
          "link": "https://arxiv.org/abs/2507.00406v2",
          "size": "1553kb",
          "version": "v2"
        }
      ],
      "title": "Partnering with AI: A Pedagogical Feedback System for LLM Integration into Programming Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00406",
        "HTML": "https://arxiv.org/html/2507.00406v2",
        "PDF": "https://arxiv.org/pdf/2507.00406"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a pedagogical feedback system for programming education using LLMs. It doesn't address data processing within the reinforcement learning framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03034",
      "abstract": "The (generative) artificial intelligence (AI) era has profoundly reshaped the meaning and value of data. No longer confined to static content, data now permeates every stage of the AI lifecycle from the training samples that shape model parameters to the prompts and outputs that drive real-world model deployment. This shift renders traditional notions of data protection insufficient, while the boundaries of what needs safeguarding remain poorly defined. Failing to safeguard data in AI systems can inflict societal and individual, underscoring the urgent need to clearly delineate the scope of and rigorously enforce data protection. In this perspective, we propose a four-level taxonomy, including non-usability, privacy preservation, traceability, and deletability, that captures the diverse protection needs arising in modern (generative) AI models and systems. Our framework offers a structured understanding of the trade-offs between data utility and control, spanning the entire AI pipeline, including training datasets, model weights, system prompts, and AI-generated content. We analyze representative technical approaches at each level and reveal regulatory blind spots that leave critical assets exposed. By offering a structured lens to align future AI technologies and governance with trustworthy data practices, we underscore the urgency of rethinking data protection for modern AI techniques and provide timely guidance for developers, researchers, and regulators alike.",
      "authors": [
        "Yiming Li",
        "Shuo Shao",
        "Yu He",
        "Junfeng Guo",
        "Tianwei Zhang",
        "Zhan Qin",
        "Pin-Yu Chen",
        "Michael Backes",
        "Philip Torr",
        "Dacheng Tao",
        "Kui Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:45:51+00:00",
          "link": "https://arxiv.org/abs/2507.03034v1",
          "size": "1387kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:52:55+00:00",
          "link": "https://arxiv.org/abs/2507.03034v2",
          "size": "1413kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Data Protection in the (Generative) Artificial Intelligence Era",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03034",
        "HTML": "https://arxiv.org/html/2507.03034v2",
        "PDF": "https://arxiv.org/pdf/2507.03034"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses data protection in the context of generative AI, but does not address reinforcement learning or data processing specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03220",
      "abstract": "Parameter-efficient fine-tuning (PEFT) allows model builders to capture the task specific parameters into adapters, which are a fraction of the size of the original base model. Popularity of PEFT technique for fine-tuning has led to creation of a large number of adapters for popular Large Language Models (LLMs). However, existing frameworks fall short in supporting inference or fine-tuning with multiple adapters in the following ways. 1) For fine-tuning, each job needs to deploy its dedicated base model instance, which results in excessive GPU memory consumption and poor GPU utilization. 2) While popular inference platforms can serve multiple PEFT adapters, they do not allow independent resource management or mixing of different PEFT methods. 3) They cannot share resources (such as base model instance) between inference and fine-tuning jobs. 4) They do not provide privacy to users who may not wish to expose their fine-tuned parameters to service providers. In Symbiosis, we address the above problems by enabling as-a-service deployment of base model. The base model layers can be shared across multiple inference or fine-tuning processes. Our split-execution technique decouples the execution of client-specific adapters and layers from the frozen base model layers offering them flexibility to manage their resources, to select their fine-tuning method, to achieve their performance goals. Our approach is transparent to models and works out-of-the-box for most models in the transformers library. Our evaluation on Llama2-13B shows the compared to baseline, Symbiosis can fine-tune 4X more adapters on the same set of GPUs in the same amount of time.",
      "authors": [
        "Saransh Gupta",
        "Umesh Deshpande",
        "Travis Janssen",
        "Swami Sundararaman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T23:25:59+00:00",
          "link": "https://arxiv.org/abs/2507.03220v1",
          "size": "6892kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T00:58:07+00:00",
          "link": "https://arxiv.org/abs/2507.03220v2",
          "size": "6863kb",
          "version": "v2"
        }
      ],
      "title": "Symbiosis: Multi-Adapter Inference and Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03220",
        "HTML": "https://arxiv.org/html/2507.03220v2",
        "PDF": "https://arxiv.org/pdf/2507.03220"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses parameter-efficient fine-tuning (PEFT) for large language models and lacks connections to reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03361",
      "abstract": "Sketches are a fundamental tool in data stream analytics. They are notable for supporting both approximate frequency queries and heavy hitter detection with bounded trade-offs for error and memory. Importantly, on streams that contain sensitive information, sketches can be easily privatized with the injection of a suitable amount of noise. This process is efficient in the single-release model, where the output is released only at the end of the stream. In this setting, it suffices to add noise to the sketch once.\n  In contrast, in the continual observation model, where the output is released at every time-step, noise needs to be added to the sketch before each release. This creates an additional computational overhead. To address this, we introduce Lazy Sketch, a novel differentially private sketching method, in the continual observation model, that employs lazy updates, perturbing and modifying only a small portion of the sketch at each step. Compared to prior work, we reduce the update complexity by a factor of $O(w)$, where $w$ is the width of the sketch. Experiments demonstrate that our method increases throughput by up to 250x over prior work, making continual observation differential privacy practical for high-speed streaming applications.\n  In addition, for heavy hitter detection, we present a new sketch-based algorithm that leverages lazy updates to achieve a per-update complexity of $O(d \\log T/w + \\log w)$, for sketches with dimension $d\\times w$ and streams of length $T$. This marks a significant improvement over prior approaches in the streaming continual observation model, which require recomputing frequency estimates for every item in the input domain at each time step.",
      "authors": [
        "Rayne Holland"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T07:49:00+00:00",
          "link": "https://arxiv.org/abs/2507.03361v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T09:23:14+00:00",
          "link": "https://arxiv.org/abs/2507.03361v2",
          "size": "176kb",
          "version": "v2"
        }
      ],
      "title": "Scalable Differentially Private Sketches under Continual Observation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03361",
        "HTML": "https://arxiv.org/html/2507.03361v2",
        "PDF": "https://arxiv.org/pdf/2507.03361"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on differential privacy in data stream analytics using sketches, but it does not address any aspects related to data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03556",
      "abstract": "This paper presents the first multistakeholder approach for translating diverse stakeholder values into an evaluation metric setup for Recommender Systems (RecSys) in digital archives. While commercial platforms mainly rely on engagement metrics, cultural heritage domains require frameworks that balance competing priorities among archivists, platform owners, researchers, and other stakeholders. To address this challenge, we conducted high-profile focus groups (5 groups x 5 persons) with upstream, provider, system, consumer, and downstream stakeholders, identifying value priorities across critical dimensions: visibility/representation, expertise adaptation, and transparency/trust. Our analysis shows that stakeholder concerns naturally align with four sequential research funnel stages: discovery, interaction, integration, and impact. The resulting evaluation setup addresses domain-specific challenges including collection representation imbalances, non-linear research patterns, and tensions between specialized expertise and broader accessibility. We propose directions for tailored metrics in each stage of this research journey, such as research path quality for discovery, contextual appropriateness for interaction, metadata-weighted relevance for integration, and cross-stakeholder value alignment for impact assessment. Our contributions extend beyond digital archives to the broader RecSys community, offering transferable evaluation approaches for domains where value emerges through sustained engagement rather than immediate consumption.",
      "authors": [
        "Florian Atzenhofer-Baumgartner",
        "Georg Vogeler",
        "Dominik Kowald"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T13:09:08+00:00",
          "link": "https://arxiv.org/abs/2507.03556v1",
          "size": "75kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:47:37+00:00",
          "link": "https://arxiv.org/abs/2507.03556v2",
          "size": "79kb",
          "version": "v2"
        }
      ],
      "title": "A Multistakeholder Approach to Value-Driven Co-Design of Recommender System Evaluation Metrics in Digital Archives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03556",
        "HTML": "https://arxiv.org/html/2507.03556v2",
        "PDF": "https://arxiv.org/pdf/2507.03556"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses the design of evaluation metrics for recommender systems in digital archives, with no discussion or contribution related to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03560",
      "abstract": "While kernel methods and Graph Neural Networks offer complementary strengths, integrating the two has posed challenges in efficiency and scalability. The Graph Neural Tangent Kernel provides a theoretical bridge by interpreting GNNs through the lens of neural tangent kernels. However, its reliance on deep, stacked layers introduces repeated computations that hinder performance. In this work, we introduce a new perspective by designing the simplified graph kernel, which replaces deep layer stacking with a streamlined $K$-step message aggregation process. This formulation avoids iterative layer-wise propagation altogether, leading to a more concise and computationally efficient framework without sacrificing the expressive power needed for graph tasks. Beyond this simplification, we propose another Simplified Graph Kernel, which draws from Gaussian Process theory to model infinite-width GNNs. Rather than simulating network depth, this kernel analytically computes kernel values based on the statistical behavior of nonlinear activations in the infinite limit. This eliminates the need for explicit architecture simulation, further reducing complexity. Our experiments on standard graph and node classification benchmarks show that our methods achieve competitive accuracy while reducing runtime. This makes them practical alternatives for learning on graphs at scale. Full implementation and reproducibility materials are provided at: https://anonymous.4open.science/r/SGNK-1CE4/.",
      "authors": [
        "Lin Wang",
        "Shijie Wang",
        "Sirui Huang",
        "Qing Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T13:12:09+00:00",
          "link": "https://arxiv.org/abs/2507.03560v1",
          "size": "3261kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:00:43+00:00",
          "link": "https://arxiv.org/abs/2507.03560v2",
          "size": "3261kb",
          "version": "v2"
        }
      ],
      "title": "Simplifying Graph Kernels for Efficient",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03560",
        "HTML": "https://arxiv.org/html/2507.03560v2",
        "PDF": "https://arxiv.org/pdf/2507.03560"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a simplification of graph kernels for enhanced efficiency, focusing on graph neural networks but without contributions to data processing for reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03564",
      "abstract": "On-board sensors of autonomous vehicles can be obstructed, occluded, or limited by restricted fields of view, complicating downstream driving decisions. Intelligent roadside infrastructure perception systems, installed at elevated vantage points, can provide wide, unobstructed intersection coverage, supplying a complementary information stream to autonomous vehicles via vehicle-to-everything (V2X) communication. However, conventional 3D object-detection algorithms struggle to generalize under the domain shift introduced by top-down perspectives and steep camera angles. We introduce a 2.5D object detection framework, tailored specifically for infrastructure roadside-mounted cameras. Unlike conventional 2D or 3D object detection, we employ a prediction approach to detect ground planes of vehicles as parallelograms in the image frame. The parallelogram preserves the planar position, size, and orientation of objects while omitting their height, which is unnecessary for most downstream applications. For training, a mix of real-world and synthetically generated scenes is leveraged. We evaluate generalizability on a held-out camera viewpoint and in adverse-weather scenarios absent from the training set. Our results show high detection accuracy, strong cross-viewpoint generalization, and robustness to diverse lighting and weather conditions. Model weights and inference code are provided at: https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection",
      "authors": [
        "Nikolai Polley",
        "Yacin Boualili",
        "Ferdinand M\\\"utsch",
        "Maximilian Zipfl",
        "Tobias Fleck",
        "J. Marius Z\\\"ollner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T13:16:59+00:00",
          "link": "https://arxiv.org/abs/2507.03564v1",
          "size": "1203kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:36:59+00:00",
          "link": "https://arxiv.org/abs/2507.03564v2",
          "size": "1204kb",
          "version": "v2"
        }
      ],
      "title": "2.5D Object Detection for Intelligent Roadside Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03564",
        "HTML": "https://arxiv.org/html/2507.03564v2",
        "PDF": "https://arxiv.org/pdf/2507.03564"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work introduces a 2.5D object detection framework for roadside infrastructure, involving object detection and V2X communication, with no relevance to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03833",
      "abstract": "Iterative methods for computing matrix functions have been extensively studied and their convergence speed can be significantly improved with the right tuning of parameters and by mixing different iteration types. Handtuning the design options for optimal performance can be cumbersome, especially in modern computing environments: numerous different classical iterations and their variants exist, each with non-trivial per-step cost and tuning parameters. To this end, we propose MatRL -- a reinforcement learning based framework that automatically discovers iterative algorithms for computing matrix functions. The key idea is to treat algorithm design as a sequential decision-making process. Monte-Carlo tree search is then used to plan a hybrid sequence of matrix iterations and step sizes, tailored to a specific input matrix distribution and computing environment. Moreover, we also show that the learned algorithms provably generalize to sufficiently large matrices drawn from the same distribution. Finally, we corroborate our theoretical results with numerical experiments demonstrating that MatRL produces algorithms that outperform various baselines in the literature.",
      "authors": [
        "Sungyoon Kim",
        "Rajat Vadiraj Dwaraknath",
        "Longling geng and Mert Pilanci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T22:57:33+00:00",
          "link": "https://arxiv.org/abs/2507.03833v1",
          "size": "10224kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T01:56:38+00:00",
          "link": "https://arxiv.org/abs/2507.03833v2",
          "size": "10224kb",
          "version": "v2"
        }
      ],
      "title": "MatRL: Provably Generalizable Iterative Algorithm Discovery via Monte-Carlo Tree Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03833",
        "HTML": "https://arxiv.org/html/2507.03833v2",
        "PDF": "https://arxiv.org/pdf/2507.03833"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper proposes MatRL, a reinforcement learning framework that discovers iterative algorithms, emphasizing the use of Monte-Carlo tree search for sequential decision-making, directly contributing to data processing strategies in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03976",
      "abstract": "Synthesizing normal-light novel views from low-light multiview images is an important yet challenging task, given the low visibility and high ISO noise present in the input images. Existing low-light enhancement methods often struggle to effectively preprocess such low-light inputs, as they fail to consider correlations among multiple views. Although other state-of-the-art methods have introduced illumination-related components offering alternative solutions to the problem, they often result in drawbacks such as color distortions and artifacts, and they provide limited denoising effectiveness. In this paper, we propose a novel Robust Low-light Scene Restoration framework (RoSe), which enables effective synthesis of novel views in normal lighting conditions from low-light multiview image inputs, by formulating the task as an illuminance transition estimation problem in 3D space, conceptualizing it as a specialized rendering task. This multiview-consistent illuminance transition field establishes a robust connection between low-light and normal-light conditions. By further exploiting the inherent low-rank property of illumination to constrain the transition representation, we achieve more effective denoising without complex 2D techniques or explicit noise modeling. To implement RoSe, we design a concise dual-branch architecture and introduce a low-rank denoising module. Experiments demonstrate that RoSe significantly outperforms state-of-the-art models in both rendering quality and multiview consistency on standard benchmarks. The codes and data are available at https://pegasus2004.github.io/RoSe.",
      "authors": [
        "Ze Li",
        "Feng Zhang",
        "Xiatian Zhu",
        "Meng Zhang",
        "Yanghong Zhou",
        "P. Y. Mok"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T10:02:30+00:00",
          "link": "https://arxiv.org/abs/2507.03976v1",
          "size": "3723kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T02:51:15+00:00",
          "link": "https://arxiv.org/abs/2507.03976v2",
          "size": "3723kb",
          "version": "v2"
        }
      ],
      "title": "Robust Low-light Scene Restoration via Illumination Transition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03976",
        "HTML": "https://arxiv.org/html/2507.03976v2",
        "PDF": "https://arxiv.org/pdf/2507.03976"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on low-light scene restoration through illuminance transition estimation, without mentioning reinforcement learning or any data processing techniques related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04632",
      "abstract": "Recent advances have witnessed the effectiveness of reinforcement learning (RL) finetuning in enhancing the reasoning capabilities of large language models (LLMs). The optimization process often requires numerous iterations to achieve satisfactory performance, resulting in high computational costs due to the need for frequent prompt evaluations under intensive LLM interactions and repeated policy updates. Appropriate online prompt selection methods reduce iteration steps by prioritizing informative prompts during training, while the pipeline's reliance on exhaustive prompt evaluation and subset selection for optimization still incurs substantial computational overhead due to frequent LLM inference calls. Distinguished from these direct evaluate-then-select schemes, this work investigates iterative approximate evaluation for arbitrary prompts and introduces Model Predictive Prompt Selection (MoPPS), a Bayesian risk-predictive framework that online estimates prompt difficulty without requiring costly LLM interactions. Technically, MoPPS models each prompt's success rate as a latent variable, performs streaming Bayesian inference, and employs posterior sampling in a constructed multi-armed bandit machine, enabling sample efficient and adaptive prompt selection. Extensive experiments across mathematics, planning, and vision-based geometry tasks show that MoPPS reliably predicts prompt difficulty and accelerates training with significantly reduced LLM rollouts.",
      "authors": [
        "Yun Qu",
        "Qi Cheems Wang",
        "Yixiu Mao",
        "Vincent Tao Hu",
        "Xiangyang Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T03:20:52+00:00",
          "link": "https://arxiv.org/abs/2507.04632v1",
          "size": "880kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T05:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.04632v2",
          "size": "932kb",
          "version": "v2"
        }
      ],
      "title": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04632",
        "HTML": "https://arxiv.org/html/2507.04632v2",
        "PDF": "https://arxiv.org/pdf/2507.04632"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper presents the Model Predictive Prompt Selection (MoPPS) framework, which involves online estimation of prompt difficulty to optimize RL finetuning of reasoning models, directly addressing data processing in RL through prompt selection and evaluation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05297",
      "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean. We also provide a characterization for the case when $m=p=2$.",
      "authors": [
        "Zijun Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Theoretical Economics (econ.TH)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.05297v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.05297v2",
          "size": "99kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:18:21+00:00",
          "link": "https://arxiv.org/abs/2507.05297v3",
          "size": "100kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T09:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.05297v4",
          "size": "320kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T03:51:18+00:00",
          "link": "https://arxiv.org/abs/2507.05297v5",
          "size": "320kb",
          "version": "v5"
        }
      ],
      "title": "Continuous Classification Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05297",
        "HTML": "https://arxiv.org/html/2507.05297v5",
        "PDF": "https://arxiv.org/pdf/2507.05297"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses theoretical results on fuzzy classification aggregation, which does not pertain to reinforcement learning or any related data processing topics in the context of RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06210",
      "abstract": "Pretrained vision-language models (VLMs) such as CLIP excel in general multimodal comprehension but often struggle to capture nuanced, context-dependent visual cues. This makes it difficult to distinguish between similar-looking concepts with potentially different cultural meanings. Such deficiencies are mainly due to a limited amount of high-quality cultural data, contextual information, and the lack of negative examples that highlight subtle differences. To mitigate this, we design a data curation pipeline leveraging open-sourced VLMs and text-to-image models to construct CulTwin, a synthetic cultural dataset. This dataset consists of paired concept-caption-image triplets, where concepts visually resemble each other but are culturally different. Then, we fine-tune CLIP on CulTwin to develop CultureCLIP, which aligns cultural concepts with contextually enhanced captions and synthetic images through tailored contrastive learning. Experiments on culture-specific benchmarks show that CultureCLIP outperforms the base CLIP, achieving up to a notable 5.49% improvement in fine-grained concept recognition on certain tasks while preserving CLIP's original generalization ability, validating the effectiveness of our data synthesis and VLM backbone training paradigm in capturing subtle cultural distinctions.",
      "authors": [
        "Yuchen Huang",
        "Zhiyuan Fan",
        "Zhitao He",
        "Sandeep Polisetty",
        "Wenyan Li",
        "Yi R. Fung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T17:38:56+00:00",
          "link": "https://arxiv.org/abs/2507.06210v1",
          "size": "2705kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:01:50+00:00",
          "link": "https://arxiv.org/abs/2507.06210v2",
          "size": "2705kb",
          "version": "v2"
        }
      ],
      "title": "CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06210",
        "HTML": "https://arxiv.org/html/2507.06210v2",
        "PDF": "https://arxiv.org/pdf/2507.06210"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing CLIP through synthetic cultural datasets and does not address reinforcement learning or any data processing techniques relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06444",
      "abstract": "Accurate accident anticipation remains challenging when driver cognition and dynamic road conditions are underrepresented in predictive models. In this paper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk Anticipation), a multi-modal framework integrating dashcam video, textual annotations, and driver attention maps for robust accident anticipation. Unlike existing methods that rely on static or environment-centric thresholds, CAMERA employs an adaptive mechanism guided by scene complexity and gaze entropy, reducing false alarms while maintaining high recall in dynamic, multi-agent traffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional GRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language module translates 3D spatial relationships into interpretable, human-centric alerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves state-of-the-art performance, improving accuracy and lead time. These results demonstrate the effectiveness of modeling driver attention, contextual description, and adaptive risk thresholds to enable more reliable accident anticipation.",
      "authors": [
        "Jiaxun Zhang",
        "Haicheng Liao",
        "Yumu Xie",
        "Chengyue Wang",
        "Yanchen Guan",
        "Bin Rao",
        "Zhenning Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:06:36+00:00",
          "link": "https://arxiv.org/abs/2507.06444v1",
          "size": "5083kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:31:36+00:00",
          "link": "https://arxiv.org/abs/2507.06444v2",
          "size": "5083kb",
          "version": "v2"
        }
      ],
      "title": "Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06444",
        "HTML": "https://arxiv.org/html/2507.06444v2",
        "PDF": "https://arxiv.org/pdf/2507.06444"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on accident anticipation using multi-modal data but does not address data processing specifically within reinforcement learning. Its contribution lies in adaptive mechanisms for risk anticipation, not directly related to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06607",
      "abstract": "Recent advances in language modeling have demonstrated the effectiveness of State Space Models (SSMs) for efficient sequence modeling. While hybrid architectures such as Samba and the decoder-decoder architecture, YOCO, have shown promising performance gains over Transformers, prior works have not investigated the efficiency potential of representation sharing between SSM layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet effective mechanism for efficient memory sharing across layers. We apply it to create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in the cross-decoder to share memory readout states from a Samba-based self-decoder. SambaY significantly enhances decoding efficiency, preserves linear pre-filling time complexity, and boosts long-context performance, all while eliminating the need for explicit positional encoding. Through extensive scaling experiments, we demonstrate that our model exhibits a significantly lower irreducible loss compared to a strong YOCO baseline, indicating superior performance scalability under large-scale compute regimes. Our largest model enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves significantly better performance than Phi4-mini-Reasoning on reasoning tasks such as Math500, AIME24/25, and GPQA Diamond without any reinforcement learning, while delivering up to 10x higher decoding throughput on 2K-length prompts with 32K generation length under the vLLM inference framework. We release our training codebase on open-source data at https://github.com/microsoft/ArchScale.",
      "authors": [
        "Liliang Ren",
        "Congcong Chen",
        "Haoran Xu",
        "Young Jin Kim",
        "Adam Atkinson",
        "Zheng Zhan",
        "Jiankai Sun",
        "Baolin Peng",
        "Liyuan Liu",
        "Shuohang Wang",
        "Hao Cheng",
        "Jianfeng Gao",
        "Weizhu Chen",
        "Yelong Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:27:00+00:00",
          "link": "https://arxiv.org/abs/2507.06607v1",
          "size": "5316kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:00:01+00:00",
          "link": "https://arxiv.org/abs/2507.06607v2",
          "size": "5316kb",
          "version": "v2"
        }
      ],
      "title": "Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06607",
        "HTML": "https://arxiv.org/html/2507.06607v2",
        "PDF": "https://arxiv.org/pdf/2507.06607"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on hybrid architectures for language modeling without mentioning reinforcement learning or any data processing aspects related specifically to RL."
      },
      "models": [
        {
          "model_path": "microsoft/Phi-4-mini-flash-reasoning",
          "downloads": "2049",
          "likes": "156",
          "trending_score": "139.0",
          "link": "https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning"
        },
        {
          "model_path": "noman007/testt",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/noman007/testt"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06608",
      "abstract": "Monolithic serving with chunked prefill improves GPU utilization by batching prefill and decode together, but suffers from fine-grained phase interference. Engine-level prefill-decode (PD) disaggregation avoids interference but incurs higher hardware and coordination overhead. Prior intra-GPU disaggregation approaches multiplex prefill and decode within a single GPU, using SLO-based tuning guided by heuristics from offline profiling or reactive feedback loops. However, these methods respond reactively to performance issues rather than anticipating them, limiting adaptability under dynamic workloads.\n  We ask: can we achieve proactive intra-GPU disaggregation that adapts effectively to dynamic workloads? The key challenge lies in managing the conflicting resource demands of prefill and decode under varying conditions. We first show that GPU resources exhibit diminishing returns -- beyond a saturation point, more allocation yields minimal latency benefit. Second, we observe that memory bandwidth contention becomes a critical bottleneck. These insights motivate a design that dynamically partitions GPU resources across prefill and decode phases, while jointly considering compute capacity, memory footprint, and bandwidth contention.\n  Evaluated on diverse LLMs and workloads, our system Nexus achieves up to 2.2x higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM; outperforms SGLang by up to 2x; and matches or exceeds disaggregated vLLM.",
      "authors": [
        "Xiaoxiang Shi",
        "Colin Cai",
        "Junjia Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:27:18+00:00",
          "link": "https://arxiv.org/abs/2507.06608v1",
          "size": "848kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:48:42+00:00",
          "link": "https://arxiv.org/abs/2507.06608v2",
          "size": "849kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:17:17+00:00",
          "link": "https://arxiv.org/abs/2507.06608v3",
          "size": "800kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T01:05:40+00:00",
          "link": "https://arxiv.org/abs/2507.06608v4",
          "size": "800kb",
          "version": "v4"
        }
      ],
      "title": "Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06608",
        "HTML": "https://arxiv.org/html/2507.06608v4",
        "PDF": "https://arxiv.org/pdf/2507.06608"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is about GPU resource management for LLM serving and does not relate to reinforcement learning or its data processing aspects. It does not address how RL data is collected, processed, or curated."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07044",
      "abstract": "Vision Transformers (ViTs) have emerged as a powerful architecture for computer vision tasks due to their ability to model long-range dependencies and global contextual relationships. However, their substantial compute and memory demands hinder efficient deployment in scenarios with strict energy and bandwidth limitations. In this work, we propose OptoViT, the first near-sensor, region-aware ViT accelerator leveraging silicon photonics (SiPh) for real-time and energy-efficient vision processing. Opto-ViT features a hybrid electronic-photonic architecture, where the optical core handles compute-intensive matrix multiplications using Vertical-Cavity Surface-Emitting Lasers (VCSELs) and Microring Resonators (MRs), while nonlinear functions and normalization are executed electronically. To reduce redundant computation and patch processing, we introduce a lightweight Mask Generation Network (MGNet) that identifies regions of interest in the current frame and prunes irrelevant patches before ViT encoding. We further co-optimize the ViT backbone using quantization-aware training and matrix decomposition tailored for photonic constraints. Experiments across device fabrication, circuit and architecture co-design, to classification, detection, and video tasks demonstrate that OptoViT achieves 100.4 KFPS/W with up to 84% energy savings with less than 1.6% accuracy loss, while enabling scalable and efficient ViT deployment at the edge.",
      "authors": [
        "Mehrdad Morsali",
        "Chengwei Zhou",
        "Deniz Najafi",
        "Sreetama Sarkar",
        "Pietro Mercati",
        "Navid Khoshavi",
        "Peter Beerel",
        "Mahdi Nikdast",
        "Gourav Datta",
        "Shaahin Angizi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:07:26+00:00",
          "link": "https://arxiv.org/abs/2507.07044v1",
          "size": "1130kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:52:16+00:00",
          "link": "https://arxiv.org/abs/2507.07044v2",
          "size": "1129kb",
          "version": "v2"
        }
      ],
      "title": "Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07044",
        "HTML": "https://arxiv.org/html/2507.07044v2",
        "PDF": "https://arxiv.org/pdf/2507.07044"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work is centered on a Vision Transformer architecture using silicon photonics for efficient deployment, without any discussion on reinforcement learning or relevant data processing techniques in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07511",
      "abstract": "Brain-computer interfaces (BCIs) turn brain signals into functionally useful output, but they are not always accurate. A good Machine Learning classifier should be able to indicate how confident it is about a given classification, by giving a probability for its classification. Standard classifiers for Motor Imagery BCIs do give such probabilities, but research on uncertainty quantification has been limited to Deep Learning. We compare the uncertainty quantification ability of established BCI classifiers using Common Spatial Patterns (CSP-LDA) and Riemannian Geometry (MDRM) to specialized methods in Deep Learning (Deep Ensembles and Direct Uncertainty Quantification) as well as standard Convolutional Neural Networks (CNNs).\n  We found that the overconfidence typically seen in Deep Learning is not a problem in CSP-LDA and MDRM. We found that MDRM is underconfident, which we solved by adding Temperature Scaling (MDRM-T). CSP-LDA and MDRM-T give the best uncertainty estimates, but Deep Ensembles and standard CNNs give the best classifications. We show that all models are able to separate between easy and difficult estimates, so that we can increase the accuracy of a Motor Imagery BCI by rejecting samples that are ambiguous.",
      "authors": [
        "Joris Suurmeijer",
        "Ivo Pascal de Jong",
        "Matias Valdenegro-Toro and Andreea Ioana Sburlea"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:57:50+00:00",
          "link": "https://arxiv.org/abs/2507.07511v1",
          "size": "164kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:27:01+00:00",
          "link": "https://arxiv.org/abs/2507.07511v2",
          "size": "163kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty Quantification for Motor Imagery BCI -- Machine Learning vs. Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07511",
        "HTML": "https://arxiv.org/html/2507.07511v2",
        "PDF": "https://arxiv.org/pdf/2507.07511"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper examines uncertainty quantification in Brain-Computer Interfaces using machine learning and deep learning but does not involve reinforcement learning or specifically address RL-related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07883",
      "abstract": "Multi-task learning (MTL) enables a joint model to capture commonalities across multiple tasks, reducing computation costs and improving data efficiency. However, a major challenge in MTL optimization is task conflicts, where the task gradients differ in direction or magnitude, limiting model performance compared to single-task counterparts. Sharpness-aware minimization (SAM) minimizes task loss while simultaneously reducing the sharpness of the loss landscape. Our empirical observations show that SAM effectively mitigates task conflicts in MTL. Motivated by these findings, we explore integrating SAM into MTL but face two key challenges. While both the average loss gradient and individual task gradients-referred to as global and local information-contribute to SAM, how to combine them remains unclear. Moreover, directly computing each task gradient introduces significant computational and memory overheads. To address these challenges, we propose SAMO, a lightweight \\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization approach, that leverages a joint global-local perturbation. The local perturbations are approximated using only forward passes and are layerwise normalized to improve efficiency. Extensive experiments on a suite of multi-task benchmarks demonstrate both the effectiveness and efficiency of our method. Code is available at https://github.com/OptMN-Lab/SAMO.",
      "authors": [
        "Hao Ban",
        "Gokul Ram Subramani",
        "Kaiyi Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:06:02+00:00",
          "link": "https://arxiv.org/abs/2507.07883v1",
          "size": "537kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:57:39+00:00",
          "link": "https://arxiv.org/abs/2507.07883v2",
          "size": "536kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T22:07:45+00:00",
          "link": "https://arxiv.org/abs/2507.07883v3",
          "size": "537kb",
          "version": "v3"
        }
      ],
      "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07883",
        "HTML": "https://arxiv.org/html/2507.07883v3",
        "PDF": "https://arxiv.org/pdf/2507.07883"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multi-task optimization approach using Sharpness-Aware Minimization (SAM) and does not mention any aspects of data processing specifically within the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08218",
      "abstract": "Out-of-context reasoning (OOCR) is a phenomenon in which fine-tuned LLMs exhibit surprisingly deep out-of-distribution generalization. Rather than learning shallow heuristics, they implicitly internalize and act on the consequences of observations scattered throughout the fine-tuning data. In this work, we investigate this phenomenon mechanistically and find that many instances of OOCR in the literature have a simple explanation: the LoRA fine-tuning essentially adds a constant steering vector, steering the model towards a general concept. This improves performance on the fine-tuning task and in many other concept-related domains, causing the surprising generalization. Moreover, we can directly train steering vectors for these tasks from scratch, which also induces OOCR. We find that our results hold even for a task that seems like it must involve conditional behavior (model backdoors); it turns out that unconditionally adding a steering vector is sufficient. Overall, our work presents one explanation of what gets learned during fine-tuning for OOCR tasks, contributing to the key question of why LLMs can reason out of context, an advanced capability that is highly relevant to their safe and reliable deployment.",
      "authors": [
        "Atticus Wang",
        "Joshua Engels",
        "Oliver Clive-Griffin",
        "Senthooran Rajamanoharan",
        "Neel Nanda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T23:47:05+00:00",
          "link": "https://arxiv.org/abs/2507.08218v1",
          "size": "631kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:57:48+00:00",
          "link": "https://arxiv.org/abs/2507.08218v2",
          "size": "631kb",
          "version": "v2"
        }
      ],
      "title": "Simple Mechanistic Explanations for Out-Of-Context Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08218",
        "HTML": "https://arxiv.org/html/2507.08218v2",
        "PDF": "https://arxiv.org/pdf/2507.08218"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses out-of-context reasoning in LLMs and the mechanistic explanations for fine-tuning but does not address data processing related to reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08492",
      "abstract": "Document image dewarping remains a challenging task in the deep learning era. While existing methods have improved by leveraging text line awareness, they typically focus only on a single horizontal dimension. In this paper, we propose a fine-grained deformation perception model that focuses on Dual Dimensions of document horizontal-vertical-lines to improve document Dewarping called D2Dewarp. It can perceive distortion trends in different directions across document details. To combine the horizontal and vertical granularity features, an effective fusion module based on X and Y coordinate is designed to facilitate interaction and constraint between the two dimensions for feature complementarity. Due to the lack of annotated line features in current public dewarping datasets, we also propose an automatic fine-grained annotation method using public document texture images and an automatic rendering engine to build a new large-scale distortion training dataset. The code and dataset will be publicly released. On public Chinese and English benchmarks, both quantitative and qualitative results show that our method achieves better rectification results compared with the state-of-the-art methods. The dataset will be publicly available at https://github.com/xiaomore/DocDewarpHV",
      "authors": [
        "Heng Li",
        "Qingcai Chen and Xiangping Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:16:58+00:00",
          "link": "https://arxiv.org/abs/2507.08492v1",
          "size": "3593kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:59:35+00:00",
          "link": "https://arxiv.org/abs/2507.08492v2",
          "size": "4083kb",
          "version": "v2"
        }
      ],
      "title": "Dual Dimensions Geometric Representation Learning Based Document Dewarping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08492",
        "HTML": "https://arxiv.org/html/2507.08492v2",
        "PDF": "https://arxiv.org/pdf/2507.08492"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses a geometric representation learning approach for document dewarping and proposes a new dataset for this purpose, which is not related to reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08677",
      "abstract": "There are currently many communication options in the Internet of Things, even in particular areas such as constrained and battery-powered devices, such as Low Power Wide Area Networks. Understanding the differences and characteristics of each option is a challenge, even for professionals and researchers in the field. To meet this need, this work analyses the qualitative characteristics of Low Power Wide Area Network protocols and the challenges and opportunities of using constrained devices for sparse networks based on long-life batteries. For this study, a bibliographic survey of the literature was carried out as an analysis of three protocols (LoRaWAN, NB-IoT, and Sigfox), and a detailing of the first one. As a result, there is a discussion about the chosen network protocol and its use in IoT solutions with sparse sensors.",
      "authors": [
        "Wesley dos Reis Bezerra",
        "Lais Machado Bezerra",
        "Carlos Becker Westphall"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:21:09+00:00",
          "link": "https://arxiv.org/abs/2507.08677v1",
          "size": "112kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T22:31:01+00:00",
          "link": "https://arxiv.org/abs/2507.08677v2",
          "size": "112kb",
          "version": "v2"
        }
      ],
      "title": "Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08677",
        "HTML": "https://arxiv.org/html/2507.08677v2",
        "PDF": "https://arxiv.org/pdf/2507.08677"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study provides a qualitative assessment of Low Power Wide Area Network protocols and their applications in IoT, without any mention of reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08759",
      "abstract": "We present a novel dependent linear type theory in which the multiplicity of some variable - i.e., the number of times the variable can be used in a program - can depend on other variables. This allows us to give precise resource annotations to many higher-order functions that cannot be adequately typed in any other system. Inspired by the Dialectica translation, our typing discipline is obtained by embedding linear logic into dependent type theory and specifying how the embedded logic interacts with the host theory. We can then use a standard natural numbers type to obtain a quantitative typing system with dependent multiplicities. We characterise the semantics for our theory as a combination of standard models of dependent type theory and linear logic. Our system can be added to any dependently typed language, which we demonstrate with an implementation in Agda.",
      "authors": [
        "Maximilian Dor\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:12:11+00:00",
          "link": "https://arxiv.org/abs/2507.08759v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T09:23:44+00:00",
          "link": "https://arxiv.org/abs/2507.08759v2",
          "size": "119kb",
          "version": "v2"
        }
      ],
      "title": "Dependent Multiplicities in Dependent Linear Type Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08759",
        "PDF": "https://arxiv.org/pdf/2507.08759"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses a novel dependent linear type theory and its implementation, without any focus on reinforcement learning or data processing activities within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09016",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) aligns language models with human preferences but is computationally expensive. We explore two approaches that leverage human gaze modeling to enhance RLHF: (1) gaze-aware reward models and (2) gaze-based distribution of sparse rewards at token level. Our experiments demonstate that gaze-informed RLHF achieves faster convergence while maintaining or slightly improving performance, thus, reducing computational costs during policy optimization. These results show that human gaze provides a valuable and underused signal for policy optimization, pointing to a promising direction for improving RLHF efficiency.",
      "authors": [
        "Karim Galliamov",
        "Ivan Titov",
        "and Ilya Pershin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:49:04+00:00",
          "link": "https://arxiv.org/abs/2507.09016v1",
          "size": "101kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T09:24:11+00:00",
          "link": "https://arxiv.org/abs/2507.09016v2",
          "size": "101kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing RLHF with Human Gaze Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09016",
        "PDF": "https://arxiv.org/pdf/2507.09016"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper discusses the use of human gaze modeling to improve Reinforcement Learning from Human Feedback (RLHF), which touches on data processing by utilizing gaze data as an additional input to enhance reward models, but it is not the core contribution of the paper."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09477",
      "abstract": "Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language Models (LLMs) by injecting external knowledge, yet it falls short on problems that demand multi-step inference; conversely, purely reasoning-oriented approaches often hallucinate or mis-ground facts. This survey synthesizes both strands under a unified reasoning-retrieval perspective. We first map how advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then, we show how retrieved knowledge of different type supply missing premises and expand context for complex inference (RAG-Enhanced Reasoning). Finally, we spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs iteratively interleave search and reasoning to achieve state-of-the-art performance across knowledge-intensive benchmarks. We categorize methods, datasets, and open challenges, and outline research avenues toward deeper RAG-Reasoning systems that are more effective, multimodally-adaptive, trustworthy, and human-centric. The collection is available at https://github.com/DavidZWZ/Awesome-RAG-Reasoning.",
      "authors": [
        "Yangning Li",
        "Weizhi Zhang",
        "Yuyao Yang",
        "Wei-Chieh Huang",
        "Yaozu Wu",
        "Junyu Luo",
        "Yuanchen Bei",
        "Henry Peng Zou",
        "Xiao Luo",
        "Yusheng Zhao",
        "Chunkit Chan",
        "Yankai Chen",
        "Zhongfen Deng",
        "Yinghui Li",
        "Hai-Tao Zheng",
        "Dongyuan Li",
        "Renhe Jiang",
        "Ming Zhang",
        "Yangqiu Song",
        "Philip S. Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:29:41+00:00",
          "link": "https://arxiv.org/abs/2507.09477v1",
          "size": "586kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:44:18+00:00",
          "link": "https://arxiv.org/abs/2507.09477v2",
          "size": "587kb",
          "version": "v2"
        }
      ],
      "title": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09477",
        "PDF": "https://arxiv.org/pdf/2507.09477"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on Retrieval-Augmented Generation (RAG) in language models and does not highlight data processing techniques specific to the reinforcement learning context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09592",
      "abstract": "We introduce the THOR (Transformer Heuristics for On-Demand Retrieval) Module, designed and implemented by eSapiens, a secure, scalable engine that transforms natural-language questions into verified, read-only SQL analytics for enterprise databases. The Text-to-SQL module follows a decoupled orchestration/execution architecture: a Supervisor Agent routes queries, Schema Retrieval dynamically injects table and column metadata, and a SQL Generation Agent emits single-statement SELECT queries protected by a read-only guardrail. An integrated Self-Correction & Rating loop captures empty results, execution errors, or low-quality outputs and triggers up to five LLM-driven regeneration attempts. Finally, a Result Interpretation Agent produces concise, human-readable insights and hands raw rows to the Insight & Intelligence engine for visualization or forecasting.\n  Smoke tests across finance, sales, and operations scenarios demonstrate reliable ad-hoc querying and automated periodic reporting. By embedding schema awareness, fault-tolerant execution, and compliance guardrails, the THOR Module empowers non-technical users to access live data with zero-SQL simplicity and enterprise-grade safety.",
      "authors": [
        "Isaac Shi and Zeyuan Li and Fan Liu and Wenli Wang and Lewei He and Yang Yang and Tianyu Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:48:24+00:00",
          "link": "https://arxiv.org/abs/2507.09592v1",
          "size": "1584kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T05:23:14+00:00",
          "link": "https://arxiv.org/abs/2507.09592v2",
          "size": "1652kb",
          "version": "v2"
        }
      ],
      "title": "THOR: Transformer Heuristics for On-Demand Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09592",
        "HTML": "https://arxiv.org/html/2507.09592v2",
        "PDF": "https://arxiv.org/pdf/2507.09592"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "While the paper introduces a module for transforming natural language questions into SQL queries, the focus is on data retrieval and not on reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09822",
      "abstract": "Navigation in dynamic environments requires autonomous systems to reason about uncertainties in the behavior of other agents. In this paper, we introduce a unified framework that combines trajectory planning with multimodal predictions and active probing to enhance decision-making under uncertainty. We develop a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models. When these uncertainties follow a Gaussian mixture distribution, we prove that our risk metric admits a closed-form solution, and is always finite, thus ensuring analytical tractability. To reduce prediction ambiguity, we incorporate an active probing mechanism that strategically selects actions to improve its estimates of behavioral parameters of other agents, while simultaneously handling multimodal uncertainties. We extensively evaluate our framework in autonomous navigation scenarios using the MetaDrive simulation environment. Results demonstrate that our active probing approach successfully navigates complex traffic scenarios with uncertain predictions. Additionally, our framework shows robust performance across diverse traffic agent behavior models, indicating its broad applicability to real-world autonomous navigation challenges. Code and videos are available at https://darshangm.github.io/papers/active-probing-multimodal-predictions/.",
      "authors": [
        "Darshan Gadginmath",
        "Farhad Nawaz",
        "Minjun Sung",
        "Faizan M Tariq",
        "Sangjae Bae",
        "David Isele",
        "Fabio Pasqualetti",
        "Jovin D'sa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:06:46+00:00",
          "link": "https://arxiv.org/abs/2507.09822v1",
          "size": "653kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T19:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.09822v2",
          "size": "653kb",
          "version": "v2"
        }
      ],
      "title": "Active Probing with Multimodal Predictions for Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09822",
        "HTML": "https://arxiv.org/html/2507.09822v2",
        "PDF": "https://arxiv.org/pdf/2507.09822"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework combining trajectory planning with multimodal predictions for motion planning, focusing on autonomous navigation. It does not discuss data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09850",
      "abstract": "Reasoning-capable language models achieve state-of-the-art performance in diverse complex tasks by generating long, explicit Chain-of-Thought (CoT) traces. While recent works show that base models can acquire such reasoning traces via reinforcement learning or distillation from stronger models like DeepSeek-R1, previous works demonstrate that even short CoT prompting without fine-tuning is able to improve reasoning. We ask whether long CoT can be induced in a base model using only prompting or minimal tuning. Using just 20 long CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly fine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms the much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of high-quality examples can unlock strong reasoning capabilities. We further explore using CoT data from non-reasoning models and human annotators, enhanced with prompt engineering, multi-pass editing, and structural guidance. However, neither matches the performance of reasoning model traces, suggesting that certain latent qualities of expert CoT are difficult to replicate. We analyze key properties of reasoning data, such as problem difficulty, diversity, and answer length, that influence reasoning distillation. While challenges remain, we are optimistic that carefully curated human-written CoT, even in small quantities, can activate reasoning behaviors in base models. We release our human-authored dataset across refinement stages and invite further investigation into what makes small-scale reasoning supervision so effective.",
      "authors": [
        "Wei Du",
        "Branislav Kisacanin",
        "George Armstrong",
        "Shubham Toshniwal",
        "Ivan Moshkov",
        "Alexan Ayrapetyan",
        "Sadegh Mahdavi",
        "Dan Zhao",
        "Shizhe Diao",
        "Dragan Masulovic",
        "Marius Stanean",
        "Advaith Avadhanam",
        "Max Wang",
        "Ashmit Dutta",
        "Shitij Govil",
        "Sri Yanamandara",
        "Mihir Tandon",
        "Sriram Ananthakrishnan",
        "Vedant Rathi",
        "David Zhang",
        "Joonseok Kang",
        "Leon Luo",
        "Titu Andreescu",
        "Boris Ginsburg",
        "and Igor Gitman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.09850v1",
          "size": "120kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:14:53+00:00",
          "link": "https://arxiv.org/abs/2507.09850v2",
          "size": "120kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T17:16:18+00:00",
          "link": "https://arxiv.org/abs/2507.09850v3",
          "size": "120kb",
          "version": "v3"
        }
      ],
      "title": "The Challenge of Teaching Reasoning to LLMs Without RL or Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09850",
        "PDF": "https://arxiv.org/pdf/2507.09850"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper explores prompting and minimal tuning to induce reasoning in language models and mentions the use of curated data for reasoning distillation indirectly linked to RL data processing, but it doesn't focus on data processing techniques specific to RL."
      },
      "datasets": [
        {
          "dataset_name": "nvidia/Nemotron-Math-HumanReasoning",
          "downloads": "5",
          "likes": "4",
          "link": "https://huggingface.co/datasets/nvidia/Nemotron-Math-HumanReasoning"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09888",
      "abstract": "Time series forecasting is a fundamental task with broad applications, yet conventional methods often treat data as discrete sequences, overlooking their origin as noisy samples of continuous processes. Crucially, discrete noisy observations cannot uniquely determine a continuous function; instead, they correspond to a family of plausible functions. Mathematically, time series can be viewed as noisy observations of a continuous function family governed by a shared probability measure. Thus, the forecasting task can be framed as learning the transition from the historical function family to the future function family. This reframing introduces two key challenges: (1) How can we leverage discrete historical and future observations to learn the relationships between their underlying continuous functions? (2) How can we model the transition path in function space from the historical function family to the future function family? To address these challenges, we propose NeuTSFlow, a novel framework that leverages Neural Operators to facilitate flow matching for learning path of measure between historical and future function families. By parameterizing the velocity field of the flow in infinite-dimensional function spaces, NeuTSFlow moves beyond traditional methods that focus on dependencies at discrete points, directly modeling function-level features instead. Experiments on diverse forecasting tasks demonstrate NeuTSFlow's superior accuracy and robustness, validating the effectiveness of the function-family perspective.",
      "authors": [
        "Huibo Xu and Likang Wu and Xianquan Wang and Haoning Dang and Chun-Wun Cheng and Angelica I Aviles-Rivero and Qi Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:48:48+00:00",
          "link": "https://arxiv.org/abs/2507.09888v1",
          "size": "502kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:16:13+00:00",
          "link": "https://arxiv.org/abs/2507.09888v2",
          "size": "263kb",
          "version": "v2"
        }
      ],
      "title": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09888",
        "HTML": "https://arxiv.org/html/2507.09888v2",
        "PDF": "https://arxiv.org/pdf/2507.09888"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for time series forecasting with a focus on modeling continuous functions. It does not discuss reinforcement learning or address data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09953",
      "abstract": "While electron microscopy offers crucial atomic-resolution insights into structure-property relationships, radiation damage severely limits its use on beam-sensitive materials like proteins and 2D materials. To overcome this challenge, we push beyond the electron dose limits of conventional electron microscopy by adapting principles from multi-image super-resolution (MISR) that have been widely used in remote sensing. Our method fuses multiple low-resolution, sub-pixel-shifted views and enhances the reconstruction with a convolutional neural network (CNN) that integrates features from synthetic, multi-angle observations. We developed a dual-path, attention-guided network for 4D-STEM that achieves atomic-scale super-resolution from ultra-low-dose data. This provides robust atomic-scale visualization across amorphous, semi-crystalline, and crystalline beam-sensitive specimens. Systematic evaluations on representative materials demonstrate comparable spatial resolution to conventional ptychography under ultra-low-dose conditions. Our work expands the capabilities of 4D-STEM, offering a new and generalizable method for the structural analysis of radiation-vulnerable materials.",
      "authors": [
        "Zifei Wang",
        "Zian Mao",
        "Xiaoya He",
        "Xi Huang",
        "Haoran Zhang",
        "Chun Cheng",
        "Shufen Chu",
        "Tingzheng Hou",
        "Xiaoqin Zeng",
        "Yujun Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:02:05+00:00",
          "link": "https://arxiv.org/abs/2507.09953v1",
          "size": "36655kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:34:35+00:00",
          "link": "https://arxiv.org/abs/2507.09953v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09953",
        "PDF": "https://arxiv.org/pdf/2507.09953"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Focusing on low-dose imaging and super-resolution via feature fusion in electron microscopy, this paper is unrelated to reinforcement learning and does not contribute to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10024",
      "abstract": "Design studies aim to create visualization solutions for real-world problems of different application domains. Recently, the emergence of large language models (LLMs) has introduced new opportunities to enhance the design study process, providing capabilities such as creative problem-solving, data handling, and insightful analysis. However, despite their growing popularity, there remains a lack of systematic understanding of how LLMs can effectively assist researchers in visualization-specific design studies. In this paper, we conducted a multi-stage qualitative study to fill this gap, involving 30 design study researchers from diverse backgrounds and expertise levels. Through in-depth interviews and carefully-designed questionnaires, we investigated strategies for utilizing LLMs, the challenges encountered, and the practices used to overcome them. We further compiled and summarized the roles that LLMs can play across different stages of the design study process. Our findings highlight practical implications to inform visualization practitioners, and provide a framework for leveraging LLMs to enhance the design study process in visualization research.",
      "authors": [
        "Shaolun Ruan",
        "Rui Sheng",
        "Xiaolin Wen",
        "Jiachen Wang",
        "Tianyi Zhang",
        "Yong Wang",
        "Tim Dwyer",
        "Jiannan Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:06:12+00:00",
          "link": "https://arxiv.org/abs/2507.10024v1",
          "size": "19939kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:53:53+00:00",
          "link": "https://arxiv.org/abs/2507.10024v2",
          "size": "19939kb",
          "version": "v2"
        }
      ],
      "title": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10024",
        "HTML": "https://arxiv.org/html/2507.10024v2",
        "PDF": "https://arxiv.org/pdf/2507.10024"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates the role of large language models in design studies for visualizations, not addressing reinforcement learning or RL-specific data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10076",
      "abstract": "In computational argumentation, gradual semantics are fine-grained alternatives to extension-based and labelling-based semantics . They ascribe a dialectical strength to (components of) arguments sanctioning their degree of acceptability. Several gradual semantics have been studied for abstract, bipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as, to a lesser extent, for some forms of structured argumentation. However, this has not been the case for assumption-based argumentation (ABA), despite it being a popular form of structured argumentation with several applications where gradual semantics could be useful. In this paper, we fill this gap and propose a family of novel gradual semantics for equipping assumptions, which are the core components in ABA frameworks, with dialectical strengths. To do so, we use bipolar set-based argumentation frameworks as an abstraction of (potentially non-flat) ABA frameworks and generalise state-of-the-art modular gradual semantics for QBAFs. We show that our gradual ABA semantics satisfy suitable adaptations of desirable properties of gradual QBAF semantics, such as balance and monotonicity. We also explore an argument-based approach that leverages established QBAF modular semantics directly, and use it as baseline. Finally, we conduct experiments with synthetic ABA frameworks to compare our gradual ABA semantics with its argument-based counterpart and assess convergence.",
      "authors": [
        "Anna Rapberger",
        "Fabrizio Russo",
        "Antonio Rago",
        "Francesca Toni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.10076v1",
          "size": "3038kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:46:26+00:00",
          "link": "https://arxiv.org/abs/2507.10076v2",
          "size": "3037kb",
          "version": "v2"
        }
      ],
      "title": "On Gradual Semantics for Assumption-Based Argumentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10076",
        "HTML": "https://arxiv.org/html/2507.10076v2",
        "PDF": "https://arxiv.org/pdf/2507.10076"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on assumption-based argumentation and does not mention reinforcement learning or data processing within the RL context. It doesn't contribute to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10158",
      "abstract": "Federated Learning (FL) is a promising machine learning paradigm that enables participating devices to train privacy-preserved and collaborative models. FL has proven its benefits for robotic manipulation tasks. However, grasping tasks lack exploration in such settings where robots train a global model without moving data and ensuring data privacy. The main challenge is that each robot learns from data that is nonindependent and identically distributed (non-IID) and of low quantity. This exhibits performance degradation, particularly in robotic grasping. Thus, in this work, we propose MTF-Grasp, a multi-tier FL approach for robotic grasping, acknowledging the unique challenges posed by the non-IID data distribution across robots, including quantitative skewness. MTF-Grasp harnesses data quality and quantity across robots to select a set of \"top-level\" robots with better data distribution and higher sample count. It then utilizes top-level robots to train initial seed models and distribute them to the remaining \"low-level\" robots, reducing the risk of model performance degradation in low-level robots. Our approach outperforms the conventional FL setup by up to 8% on the quantity-skewed Cornell and Jacquard grasping datasets.",
      "authors": [
        "Obaidullah Zaland",
        "Erik Elmroth and Monowar Bhuyan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:17:28+00:00",
          "link": "https://arxiv.org/abs/2507.10158v1",
          "size": "3917kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:39:22+00:00",
          "link": "https://arxiv.org/abs/2507.10158v2",
          "size": "3917kb",
          "version": "v2"
        }
      ],
      "title": "MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10158",
        "HTML": "https://arxiv.org/html/2507.10158v2",
        "PDF": "https://arxiv.org/pdf/2507.10158"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on federated learning for robotic grasping tasks and not on reinforcement learning. It discusses data distribution challenges but not in the context of RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10432",
      "abstract": "With the rapid advancements in Artificial Intelligence Generated Image (AGI) technology, the accurate assessment of their quality has become an increasingly vital requirement. Prevailing methods typically rely on cross-modal models like CLIP or BLIP to evaluate text-image alignment and visual quality. However, when applied to AGIs, these methods encounter two primary challenges: semantic misalignment and details perception missing. To address these limitations, we propose Text-Visual Semantic Constrained AI-Generated Image Quality Assessment (SC-AGIQA), a unified framework that leverages text-visual semantic constraints to significantly enhance the comprehensive evaluation of both text-image consistency and perceptual distortion in AI-generated images. Our approach integrates key capabilities from multiple models and tackles the aforementioned challenges by introducing two core modules: the Text-assisted Semantic Alignment Module (TSAM), which leverages Multimodal Large Language Models (MLLMs) to bridge the semantic gap by generating an image description and comparing it against the original prompt for a refined consistency check, and the Frequency-domain Fine-Grained Degradation Perception Module (FFDPM), which draws inspiration from Human Visual System (HVS) properties by employing frequency domain analysis combined with perceptual sensitivity weighting to better quantify subtle visual distortions and enhance the capture of fine-grained visual quality details in images. Extensive experiments conducted on multiple benchmark datasets demonstrate that SC-AGIQA outperforms existing state-of-the-art methods. The code is publicly available at https://github.com/mozhu1/SC-AGIQA.",
      "authors": [
        "Qiang Li and Qingsen Yan and Haojian Huang and Peng Wu and Haokui Zhang and Yanning Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:21:05+00:00",
          "link": "https://arxiv.org/abs/2507.10432v1",
          "size": "4656kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T04:56:51+00:00",
          "link": "https://arxiv.org/abs/2507.10432v2",
          "size": "3000kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T15:47:15+00:00",
          "link": "https://arxiv.org/abs/2507.10432v3",
          "size": "3000kb",
          "version": "v3"
        }
      ],
      "title": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10432",
        "HTML": "https://arxiv.org/html/2507.10432v3",
        "PDF": "https://arxiv.org/pdf/2507.10432"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with AI-generated image quality assessment using text-visual semantic constraints and does not involve reinforcement learning or data processing within that context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10452",
      "abstract": "Solutions of optimization problems, including policy optimization in reinforcement learning, typically rely upon some variant of gradient descent. There has been much recent work in the machine learning, control, and optimization communities applying the Polyak-{\\L}ojasiewicz Inequality (PLI) to such problems in order to establish an exponential rate of convergence (a.k.a. ``linear convergence'' in the local-iteration language of numerical analysis) of loss functions to their minima under the gradient flow. Often, as is the case of policy iteration for the continuous-time LQR problem, this rate vanishes for large initial conditions, resulting in a mixed globally linear / locally exponential behavior. This is in sharp contrast with the discrete-time LQR problem, where there is global exponential convergence. That gap between CT and DT behaviors motivates the search for various generalized PLI-like conditions, and this talk will address that topic. Moreover, these generalizations are key to understanding the transient and asymptotic effects of errors in the estimation of the gradient, errors which might arise from adversarial attacks, wrong evaluation by an oracle, early stopping of a simulation, inaccurate and very approximate digital twins, stochastic computations (algorithm ``reproducibility''), or learning by sampling from limited data. We describe an ``input to state stability'' (ISS) analysis of this issue. The second part discusses convergence and PLI-like properties of ``linear feedforward neural networks'' in feedback control. Much of the work described here was done in collaboration with Arthur Castello B. de Oliveira, Leilei Cui, Zhong-Ping Jiang, and Milad Siami.",
      "authors": [
        "Eduardo D. Sontag"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:31:06+00:00",
          "link": "https://arxiv.org/abs/2507.10452v1",
          "size": "759kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T02:38:14+00:00",
          "link": "https://arxiv.org/abs/2507.10452v2",
          "size": "3239kb",
          "version": "v2"
        }
      ],
      "title": "Some remarks on gradient dominance and LQR policy optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10452",
        "HTML": "https://arxiv.org/html/2507.10452v2",
        "PDF": "https://arxiv.org/pdf/2507.10452"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "While the paper discusses policy optimization in reinforcement learning with respect to gradient descent techniques, it does not specifically focus on data processing aspects such as collection or preprocessing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10502",
      "abstract": "Artificial intelligence holds immense promise for transforming biology, yet a lack of standardized, cross domain, benchmarks undermines our ability to build robust, trustworthy models. Here, we present insights from a recent workshop that convened machine learning and computational biology experts across imaging, transcriptomics, proteomics, and genomics to tackle this gap. We identify major technical and systemic bottlenecks such as data heterogeneity and noise, reproducibility challenges, biases, and the fragmented ecosystem of publicly available resources and propose a set of recommendations for building benchmarking frameworks that can efficiently compare ML models of biological systems across tasks and data modalities. By promoting high quality data curation, standardized tooling, comprehensive evaluation metrics, and open, collaborative platforms, we aim to accelerate the development of robust benchmarks for AI driven Virtual Cells. These benchmarks are crucial for ensuring rigor, reproducibility, and biological relevance, and will ultimately advance the field toward integrated models that drive new discoveries, therapeutic insights, and a deeper understanding of cellular systems.",
      "authors": [
        "Elizabeth Fahsbender",
        "Alma Andersson",
        "Jeremy Ash",
        "Polina Binder",
        "Daniel Burkhardt",
        "Benjamin Chang",
        "Georg K. Gerber",
        "Anthony Gitter",
        "Patrick Godau",
        "Ankit Gupta",
        "Genevieve Haliburton",
        "Siyu He",
        "Trey Ideker",
        "Ivana Jelic",
        "Aly Khan",
        "Yang-Joon Kim",
        "Aditi Krishnapriyan",
        "Jon M. Laurent",
        "Tianyu Liu",
        "Emma Lundberg",
        "Shalin B. Mehta",
        "Rob Moccia",
        "Angela Oliveira Pisco",
        "Katherine S. Pollard",
        "Suresh Ramani",
        "Julio Saez-Rodriguez",
        "Yasin Senbabaoglu",
        "Elana Simon",
        "Srinivasan Sivanandan",
        "Gustavo Stolovitzky",
        "Marc Valer",
        "Bo Wang",
        "Xikun Zhang",
        "James Zou",
        "Katrina Kalantar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:25:28+00:00",
          "link": "https://arxiv.org/abs/2507.10502v1",
          "size": "279kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T20:40:39+00:00",
          "link": "https://arxiv.org/abs/2507.10502v2",
          "size": "279kb",
          "version": "v2"
        }
      ],
      "title": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10502",
        "PDF": "https://arxiv.org/pdf/2507.10502"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses benchmarking AI models in biology, focusing on data heterogeneity, reproducibility, and the development of standardized benchmarks. It does not discuss reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10559",
      "abstract": "Recent developments in large language models (LLMs) have been accompanied by rapidly growing public interest in natural language processing (NLP). This attention is reflected by major news venues, which sometimes invite NLP researchers to share their knowledge and views with a wide audience. Recognizing the opportunities of the present, for both the research field and for individual researchers, this paper shares recommendations for communicating with a general audience about the capabilities and limitations of NLP. These recommendations cover three themes: vague terminology as an obstacle to public understanding, unreasonable expectations as obstacles to sustainable growth, and ethical failures as obstacles to continued support. Published NLP research and popular news coverage are cited to illustrate these themes with examples. The recommendations promote effective, transparent communication with the general public about NLP, in order to strengthen public understanding and encourage support for research.",
      "authors": [
        "Shomir Wilson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T15:50:09+00:00",
          "link": "https://arxiv.org/abs/2507.10559v1",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:25:07+00:00",
          "link": "https://arxiv.org/abs/2507.10559v2",
          "size": "19kb",
          "version": "v2"
        }
      ],
      "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10559",
        "HTML": "https://arxiv.org/html/2507.10559v2",
        "PDF": "https://arxiv.org/pdf/2507.10559"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper provides communication strategies for NLP researchers when engaging with the public. It lacks any discussion of reinforcement learning or related data processing techniques within the RL framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10577",
      "abstract": "Misinformation poses a significant threat in today's digital world, often spreading rapidly through platforms like YouTube. This paper introduces a novel approach to combating misinformation by developing an AI-powered system that not only fact-checks claims made in YouTube videos but also actively engages users in the comment section and challenge misleading narratives. Our system comprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented Generation (RAG) approach - drawing on sources like Wikipedia, Google Search, Google FactCheck - to accurately assess their veracity and generates a nuanced and comprehensive report. Through rigorous prompt engineering, Trend Bender leverages this report along with a curated corpus of relevant articles to generate insightful and persuasive comments designed to stimulate a productive debate. With a carefully set up self-evaluation loop, this agent is able to iteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established benchmark datasets and a real-world deployment on YouTube, showcasing its potential to engage users and potentially influence perspectives. Our findings highlight the high accuracy of our fact-checking agent, and confirm the potential of AI-driven interventions in combating misinformation and fostering a more informed online space.",
      "authors": [
        "C\\'ecile Log\\'e",
        "Rehan Ghori"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:08:05+00:00",
          "link": "https://arxiv.org/abs/2507.10577v1",
          "size": "8514kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:25:34+00:00",
          "link": "https://arxiv.org/abs/2507.10577v2",
          "size": "8514kb",
          "version": "v2"
        }
      ],
      "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10577",
        "HTML": "https://arxiv.org/html/2507.10577v2",
        "PDF": "https://arxiv.org/pdf/2507.10577"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper describes an AI system for fact-checking YouTube videos and influencing user opinions. It does not mention reinforcement learning or data processing in the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10578",
      "abstract": "Poisoning attacks pose significant challenges to the robustness of diffusion models (DMs). In this paper, we systematically analyze when and where poisoning attacks textual inversion (TI), a widely used personalization technique for DMs. We first introduce Semantic Sensitivity Maps, a novel method for visualizing the influence of poisoning on text embeddings. Second, we identify and experimentally verify that DMs exhibit non-uniform learning behavior across timesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias and inject adversarial signals predominantly at lower timesteps. Lastly, we observe that adversarial signals distract learning away from relevant concept regions within training data, corrupting the TI process. Based on these insights, we propose Safe-Zone Training (SZT), a novel defense mechanism comprised of 3 key components: (1) JPEG compression to weaken high-frequency poison signals, (2) restriction to high timesteps during TI training to avoid adversarial signals at lower timesteps, and (3) loss masking to constrain learning to relevant regions. Extensive experiments across multiple poisoning methods demonstrate that SZT greatly enhances the robustness of TI against all poisoning attacks, improving generative quality beyond prior published defenses. Code: www.github.com/JStyborski/Diff_Lab Data: www.github.com/JStyborski/NC10",
      "authors": [
        "Jeremy Styborski",
        "Mingzhi Lyu",
        "Jiayou Lu",
        "Nupur Kapur",
        "Adams Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:35:52+00:00",
          "link": "https://arxiv.org/abs/2507.10578v1",
          "size": "25347kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T04:27:33+00:00",
          "link": "https://arxiv.org/abs/2507.10578v2",
          "size": "25920kb",
          "version": "v2"
        }
      ],
      "title": "When and Where do Data Poisons Attack Textual Inversion?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10578",
        "HTML": "https://arxiv.org/html/2507.10578v2",
        "PDF": "https://arxiv.org/pdf/2507.10578"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work analyzes poisoning attacks on textual inversion techniques in diffusion models and proposes defense mechanisms. It does not involve reinforcement learning or relevant data processing tasks within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10594",
      "abstract": "Online learning, where feature spaces can change over time, offers a flexible learning paradigm that has attracted considerable attention. However, it still faces three significant challenges. First, the heterogeneity of real-world data streams with mixed feature types presents challenges for traditional parametric modeling. Second, data stream distributions can shift over time, causing an abrupt and substantial decline in model performance. Additionally, the time and cost constraints make it infeasible to label every data instance in a supervised setting. To overcome these challenges, we propose a new algorithm Online Learning from Mix-typed, Drifted, and Incomplete Streaming Features (OL-MDISF), which aims to relax restrictions on both feature types, data distribution, and supervision information. Our approach involves utilizing copula models to create a comprehensive latent space, employing an adaptive sliding window for detecting drift points to ensure model stability, and establishing label proximity information based on geometric structural relationships. To demonstrate the model's efficiency and effectiveness, we provide theoretical analysis and comprehensive experimental results.\n  This extension serves as a standalone technical reference to the original OL-MDISF method. It provides (i) a contextual analysis of OL-MDISF within the broader landscape of online learning, covering recent advances in mixed-type feature modeling, concept drift adaptation, and weak supervision, and (ii) a comprehensive set of experiments across 14 real-world datasets under two types of drift scenarios. These include full CER trends, ablation studies, sensitivity analyses, and temporal ensemble dynamics. We hope this document can serve as a reproducible benchmark and technical resource for researchers working on nonstationary, heterogeneous, and weakly supervised data streams.",
      "authors": [
        "Shengda Zhuo",
        "Di Wu",
        "Yi He",
        "Shuqiang Huang",
        "Xindong Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.10594v1",
          "size": "1298kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T01:23:49+00:00",
          "link": "https://arxiv.org/abs/2507.10594v2",
          "size": "1293kb",
          "version": "v2"
        }
      ],
      "title": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10594",
        "HTML": "https://arxiv.org/html/2507.10594v2",
        "PDF": "https://arxiv.org/pdf/2507.10594"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on online learning from mix-typed, drifted, and incomplete streaming features, and does not address reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10628",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a powerful paradigm for facilitating the self-improvement of large language models (LLMs), particularly in the domain of complex reasoning tasks. However, prevailing on-policy RL methods often contend with significant training instability and inefficiency. This is primarily due to a capacity-difficulty mismatch, where the complexity of training data frequently outpaces the model's current capabilities, leading to critically sparse reward signals and stalled learning progress. This challenge is particularly acute for smaller, more resource-efficient LLMs. To overcome this, we introduce the Guided Hybrid Policy Optimization (GHPO), a novel difficulty-aware reinforcement learning framework. GHPO dynamically calibrates task difficulty by employing adaptive prompt refinement to provide targeted guidance. This unique approach adaptively balances direct imitation learning for problems currently beyond the model's reach with exploration-based reinforcement learning for more manageable tasks, effectively creating a smooth and optimized learning curriculum. Extensive experiments demonstrate that GHPO achieves an average performance gain of approximately 5% across six challenging mathematics benchmarks, consistently outperforming strong on-policy reinforcement learning and curriculum learning baselines. Further analysis confirms that our framework significantly enhances both training stability and final reasoning performance, thus offering a scalable and efficient solution for developing powerful and robust reasoning models.",
      "authors": [
        "Ziru Liu",
        "Cheng Gong",
        "Xinyu Fu",
        "Yaofang Liu",
        "Ran Chen",
        "Shoubo Hu",
        "Suiyun Zhang",
        "Rui Liu",
        "Qingfu Zhang",
        "Dandan Tu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:10:00+00:00",
          "link": "https://arxiv.org/abs/2507.10628v1",
          "size": "5671kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:30:11+00:00",
          "link": "https://arxiv.org/abs/2507.10628v2",
          "size": "4346kb",
          "version": "v2"
        }
      ],
      "title": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10628",
        "HTML": "https://arxiv.org/html/2507.10628v2",
        "PDF": "https://arxiv.org/pdf/2507.10628"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper presents the GHPO framework which involves adaptive prompt refinement and balancing tasks for LLM RL, implicitly touching on data handling and processing strategy aspects despite not being the main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10644",
      "abstract": "The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.",
      "authors": [
        "Tatiana Petrova (1)",
        "Boris Bliznioukov (1)",
        "Aleksandr Puzikov (1)",
        "Radu State (1) ((1) SEDAN SnT",
        "University of Luxembourg",
        "Luxembourg",
        "Luxembourg)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:47:19+00:00",
          "link": "https://arxiv.org/abs/2507.10644v1",
          "size": "1312kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:30:42+00:00",
          "link": "https://arxiv.org/abs/2507.10644v2",
          "size": "1139kb",
          "version": "v2"
        }
      ],
      "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10644",
        "HTML": "https://arxiv.org/html/2507.10644v2",
        "PDF": "https://arxiv.org/pdf/2507.10644"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses the concept of the Web of Agents and the evolution of agent protocols in AI, not focusing on reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10678",
      "abstract": "A major challenge in the use of neural networks both for modeling human cognitive function and for artificial intelligence is the design of systems with the capacity to efficiently learn functions that support radical generalization. At the roots of this is the capacity to discover and implement symmetry functions. In this paper, we investigate a paradigmatic example of radical generalization through the use of symmetry: base addition. We present a group theoretic analysis of base addition, a fundamental and defining characteristic of which is the carry function -- the transfer of the remainder, when a sum exceeds the base modulus, to the next significant place. Our analysis exposes a range of alternative carry functions for a given base, and we introduce quantitative measures to characterize these. We then exploit differences in carry functions to probe the inductive biases of neural networks in symmetry learning, by training neural networks to carry out base addition using different carries, and comparing efficacy and rate of learning as a function of their structure. We find that even simple neural networks can achieve radical generalization with the right input format and carry function, and that learnability is closely correlated with carry function structure. We then discuss the relevance this has for cognitive science and machine learning.",
      "authors": [
        "Cutter Dawes",
        "Simon Segert",
        "Kamesh Krishnamurthy",
        "Jonathan D. Cohen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:01:38+00:00",
          "link": "https://arxiv.org/abs/2507.10678v1",
          "size": "9713kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T01:31:30+00:00",
          "link": "https://arxiv.org/abs/2507.10678v2",
          "size": "9711kb",
          "version": "v2"
        }
      ],
      "title": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10678",
        "HTML": "https://arxiv.org/html/2507.10678v2",
        "PDF": "https://arxiv.org/pdf/2507.10678"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores neural networks' learnability of mathematical functions such as base addition, without a focus on reinforcement learning or related data processing concerns."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10786",
      "abstract": "Equipped with artificial intelligence (AI) and advanced sensing capabilities, social robots are gaining interest among consumers in the United States. These robots seem like a natural evolution of traditional smart home devices. However, their extensive data collection capabilities, anthropomorphic features, and capacity to interact with their environment make social robots a more significant security and privacy threat. Increased risks include data linkage, unauthorized data sharing, and the physical safety of users and their homes. It is critical to investigate U.S. users' security and privacy needs and concerns to guide the design of social robots while these devices are still in the early stages of commercialization in the U.S. market. Through 19 semi-structured interviews, we identified significant security and privacy concerns, highlighting the need for transparency, usability, and robust privacy controls to support adoption. For educational applications, participants worried most about misinformation, and in medical use cases, they worried about the reliability of these devices. Participants were also concerned with the data inference that social robots could enable. We found that participants expect tangible privacy controls, indicators of data collection, and context-appropriate functionality.",
      "authors": [
        "Henry Bell",
        "Jabari Kwesi",
        "Hiba Laabadli",
        "Pardis Emami-Naeini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:27:40+00:00",
          "link": "https://arxiv.org/abs/2507.10786v1",
          "size": "82kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:58:46+00:00",
          "link": "https://arxiv.org/abs/2507.10786v2",
          "size": "82kb",
          "version": "v2"
        }
      ],
      "title": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10786",
        "HTML": "https://arxiv.org/html/2507.10786v2",
        "PDF": "https://arxiv.org/pdf/2507.10786"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper investigates privacy and security concerns regarding AI-powered social robots, with no connection to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11049",
      "abstract": "As online news consumption grows, personalized recommendation systems have become integral to digital journalism. However, these systems risk reinforcing filter bubbles and political polarization by failing to incorporate diverse perspectives. Stance detection -- identifying a text's position on a target -- can help mitigate this by enabling viewpoint-aware recommendations and data-driven analyses of media bias. Yet, existing stance detection research remains largely limited to short texts and high-resource languages. To address these gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for article-level stance detection, comprising 2,000 news articles with article-level and 19,650 segment-level stance annotations across 47 societal issues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided \\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that employs a language model agent to predict the stances of key structural segments (e.g., leads, quotes), which are then aggregated to infer the overall article stance. Experiments show that \\textsc{JoA-ICL} outperforms existing stance detection methods, highlighting the benefits of segment-level agency in capturing the overall position of long-form news articles. Two case studies further demonstrate its broader utility in promoting viewpoint diversity in news recommendations and uncovering patterns of media bias.",
      "authors": [
        "Dahyun Lee",
        "Jonghyeon Choi",
        "Jiyoung Han",
        "and Kunwoo Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:22:04+00:00",
          "link": "https://arxiv.org/abs/2507.11049v1",
          "size": "2072kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:58:24+00:00",
          "link": "https://arxiv.org/abs/2507.11049v2",
          "size": "2072kb",
          "version": "v2"
        }
      ],
      "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11049",
        "HTML": "https://arxiv.org/html/2507.11049v2",
        "PDF": "https://arxiv.org/pdf/2507.11049"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on stance detection within journalism using a novel dataset and framework for language processing, without any mention of reinforcement learning or data processing relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11055",
      "abstract": "Medical language-guided segmentation, integrating textual clinical reports as auxiliary guidance to enhance image segmentation, has demonstrated significant improvements over unimodal approaches. However, its inherent reliance on paired image-text input, which we refer to as ``textual reliance\", presents two fundamental limitations: 1) many medical segmentation datasets lack paired reports, leaving a substantial portion of image-only data underutilized for training; and 2) inference is limited to retrospective analysis of cases with paired reports, limiting its applicability in most clinical scenarios where segmentation typically precedes reporting. To address these limitations, we propose ProLearn, the first Prototype-driven Learning framework for language-guided segmentation that fundamentally alleviates textual reliance. At its core, we introduce a novel Prototype-driven Semantic Approximation (PSA) module to enable approximation of semantic guidance from textual input. PSA initializes a discrete and compact prototype space by distilling segmentation-relevant semantics from textual reports. Once initialized, it supports a query-and-respond mechanism which approximates semantic guidance for images without textual input, thereby alleviating textual reliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG demonstrate that ProLearn outperforms state-of-the-art language-guided methods when limited text is available.",
      "authors": [
        "Shuchang Ye",
        "Usman Naseem",
        "Mingyuan Meng",
        "Jinman Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:38:49+00:00",
          "link": "https://arxiv.org/abs/2507.11055v1",
          "size": "3707kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:27:43+00:00",
          "link": "https://arxiv.org/abs/2507.11055v2",
          "size": "3707kb",
          "version": "v2"
        }
      ],
      "title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11055",
        "HTML": "https://arxiv.org/html/2507.11055v2",
        "PDF": "https://arxiv.org/pdf/2507.11055"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses medical language-guided image segmentation and proposes a framework for alleviating textual reliance, but it does not involve reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11069",
      "abstract": "Understanding the 3D geometry of transparent objects from RGB images is challenging due to their inherent physical properties, such as reflection and refraction. To address these difficulties, especially in scenarios with sparse views and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian Splatting-based depth reconstruction method for transparent objects. Our key insight lies in separating transparent objects from the background, enabling focused optimization of Gaussians corresponding to the object. We mitigate artifacts with an object-aware loss that places Gaussians in obscured regions, ensuring coverage of invisible surfaces while reducing overfitting. Furthermore, we incorporate a physics-based simulation that refines the reconstruction in just a few seconds, effectively handling object removal and chain-reaction movement of remaining objects without the need for rescanning. TRAN-D is evaluated on both synthetic and real-world sequences, and it consistently demonstrated robust improvements over existing GS-based state-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean absolute error by over 39% for the synthetic TRansPose sequences. Furthermore, despite being updated using only one image, TRAN-D reaches a {\\delta} < 2.5 cm accuracy of 48.46%, over 1.5 times that of baselines, which uses six images. Code and more results are available at https://jeongyun0609.github.io/TRAN-D/.",
      "authors": [
        "Jeongyun Kim",
        "Seunghoon Jeong",
        "Giseop Kim",
        "Myung-Hwan Jeon",
        "Eunji Jun and Ayoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:02:37+00:00",
          "link": "https://arxiv.org/abs/2507.11069v1",
          "size": "31608kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T12:02:03+00:00",
          "link": "https://arxiv.org/abs/2507.11069v2",
          "size": "31608kb",
          "version": "v2"
        }
      ],
      "title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11069",
        "HTML": "https://arxiv.org/html/2507.11069v2",
        "PDF": "https://arxiv.org/pdf/2507.11069"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on depth reconstruction of transparent objects using physics simulations and Gaussian Splatting, with no connection to reinforcement learning or data processing in RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11115",
      "abstract": "(Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are fundamental problems in graph pattern matching and similarity computation. In graphs derived from time-series data or protein structures, a natural total ordering of vertices often arises from their underlying structure, such as temporal sequences or amino acid sequences. This motivates the study of problem variants that respect this inherent ordering. This paper addresses Ordered (Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common Ordered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms that preserve the vertex orderings of two given ordered graphs. Our main contributions are threefold: (1) We prove that these problems remain NP-complete even when restricted to small graph classes, such as trees of depth 2 and threshold graphs. (2) We establish a gap in computational complexity between OSI and OISI on certain graph classes. For instance, OSI is polynomial-time solvable for interval graphs with their interval orderings, whereas OISI remains NP-complete under the same setting. (3) We demonstrate that the tractability of these problems can depend on the vertex ordering. For example, while OISI is NP-complete on threshold graphs, its generalization, MCOIS, can be solved in polynomial time if the specific vertex orderings that characterize the threshold graphs are provided.",
      "authors": [
        "Haruya Imamura",
        "Yasuaki Kobayashi",
        "Yota Otachi",
        "Toshiki Saitoh",
        "Keita Sato",
        "Asahi Takaoka",
        "Ryo Yoshinaka",
        "and Tom C. van der Zanden"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:10:13+00:00",
          "link": "https://arxiv.org/abs/2507.11115v1",
          "size": "667kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T03:45:12+00:00",
          "link": "https://arxiv.org/abs/2507.11115v2",
          "size": "672kb",
          "version": "v2"
        }
      ],
      "title": "Finding Order-Preserving Subgraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11115",
        "HTML": "https://arxiv.org/html/2507.11115v2",
        "PDF": "https://arxiv.org/pdf/2507.11115"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work is centered around graph pattern matching problems and does not involve reinforcement learning or any aspects of data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11212",
      "abstract": "We study the problem of aggregating polygons by covering them with disjoint representative regions, thereby inducing a clustering of the polygons. Our objective is to minimize a weighted sum of the total area and the total perimeter of the regions. This problem has applications in cartographic map generalization and urban analytics. Here, the polygons represent building footprints and the clusters may represent urban areas. Previous approaches forced the boundaries of the regions to come from a fixed subdivision of the plane, which allows the optimal solution (restricted in this way) to be found from a minimum cut in a dual graph. It is natural to ask whether the problem can still be solved efficiently if this restriction is removed, allowing output regions to be bounded by arbitrary curves. We provide a positive answer in the form of a polynomial-time algorithm. Additionally, we fully characterize the optimal solutions by showing that their boundaries are composed of input polygon edges and circular arcs of constant radius. Since some applications favor straight edges, we also study two problem variants in which the output regions must be polygons, but are not restricted to have boundaries from a fixed subdivision. In the first variant, region vertices must lie on the boundaries of the input polygons. The second variant requires them to be vertices of the input polygons. We show that both variants can be approximated up to a constant factor in polynomial time by altering an optimal solution for the unrestricted problem. Our experimental evaluation on real-world building footprints demonstrates that these approximate solutions are visually similar to the optimal unrestricted ones and achieve near-optimal objective values.",
      "authors": [
        "Lotte Blank",
        "David Eppstein",
        "Jan-Henrik Haunert",
        "Herman Haverkort",
        "Benedikt Kolbe",
        "Philip Mayer",
        "Petra Mutzel",
        "Alexander Naumann",
        "Jonas Sauer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:29:52+00:00",
          "link": "https://arxiv.org/abs/2507.11212v1",
          "size": "1624kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T05:17:51+00:00",
          "link": "https://arxiv.org/abs/2507.11212v2",
          "size": "1624kb",
          "version": "v2"
        }
      ],
      "title": "Bicriteria Polygon Aggregation with Arbitrary Shapes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11212",
        "HTML": "https://arxiv.org/html/2507.11212v2",
        "PDF": "https://arxiv.org/pdf/2507.11212"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with the problem of polygon aggregation for clustering and optimization purposes, which is unrelated to reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11256",
      "abstract": "We consider the fundamental Euclidean $k$-means clustering problem in a dynamic setting, where the input $X \\subseteq \\mathbb{R}^d$ evolves over time via a sequence of point insertions/deletions. We have to explicitly maintain a solution (a set of $k$ centers) $S \\subseteq \\mathbb{R}^d$ throughout these updates, while minimizing the approximation ratio, the update time (time taken to handle a point insertion/deletion) and the recourse (number of changes made to the solution $S$) of the algorithm.\n  We present a dynamic algorithm for this problem with $\\text{poly}(1/\\epsilon)$-approximation ratio, $\\tilde{O}(k^{\\epsilon})$ update time and $\\tilde{O}(1)$ recourse. In the general regime, where the dimension $d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal guarantees across all these three parameters. Indeed, improving our update time or approximation ratio would imply beating the state-of-the-art static algorithm for this problem (which is widely believed to be the best possible), and the recourse of any dynamic algorithm must be $\\Omega(1)$.\n  We obtain our result by building on top of the recent work of [Bhattacharya, Costa, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for $k$-means in general metric spaces (as opposed to in the Euclidean setting). Along the way, we design several novel geometric data structures that are of independent interest. Specifically, one of our main contributions is designing the first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\\'y, Yang; FOCS'22] that achieves $\\tilde O(n^\\epsilon)$ running time per point evaluation with competitive parameters.",
      "authors": [
        "Sayan Bhattacharya",
        "Mart\\'in Costa",
        "Ermiya Farokhnejad",
        "Shaofeng H.-C. Jiang",
        "Yaonan Jin",
        "Jianing Lou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:30:40+00:00",
          "link": "https://arxiv.org/abs/2507.11256v1",
          "size": "89kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:23:17+00:00",
          "link": "https://arxiv.org/abs/2507.11256v2",
          "size": "89kb",
          "version": "v2"
        }
      ],
      "title": "Fully Dynamic Euclidean k-Means",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11256",
        "HTML": "https://arxiv.org/html/2507.11256v2",
        "PDF": "https://arxiv.org/pdf/2507.11256"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a dynamic algorithm for the Euclidean k-means clustering problem, focusing on minimizing approximation ratio, update time, and recourse in dynamic settings. It does not address reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11330",
      "abstract": "Novelty is a crucial criterion in the peer review process for evaluating academic papers. Traditionally, it's judged by experts or measure by unique reference combinations. Both methods have limitations: experts have limited knowledge, and the effectiveness of the combination method is uncertain. Moreover, it's unclear if unique citations truly measure novelty. The large language model (LLM) possesses a wealth of knowledge, while human experts possess judgment abilities that the LLM does not possess. Therefore, our research integrates the knowledge and abilities of LLM and human experts to address the limitations of novelty assessment. One of the most common types of novelty in academic papers is the introduction of new methods. In this paper, we propose leveraging human knowledge and LLM to assist pretrained language models (PLMs, e.g. BERT etc.) in predicting the method novelty of papers. Specifically, we extract sentences related to the novelty of the academic paper from peer review reports and use LLM to summarize the methodology section of the academic paper, which are then used to fine-tune PLMs. In addition, we have designed a text-guided fusion module with novel Sparse-Attention to better integrate human and LLM knowledge. We compared the method we proposed with a large number of baselines. Extensive experiments demonstrate that our method achieves superior performance.",
      "authors": [
        "Wenqing Wu",
        "Chengzhi Zhang",
        "Yi Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.11330v1",
          "size": "3937kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:26:34+00:00",
          "link": "https://arxiv.org/abs/2507.11330v2",
          "size": "3939kb",
          "version": "v2"
        }
      ],
      "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11330",
        "HTML": "https://arxiv.org/html/2507.11330v2",
        "PDF": "https://arxiv.org/pdf/2507.11330"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the novelty of academic papers by integrating human and LLM knowledge, with no discussion related to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11331",
      "abstract": "Transformer models rely heavily on scaled dot-product attention (SDPA), typically implemented using the FlashAttention algorithm. However, current systolic-array-based accelerators face significant challenges when executing FlashAttention. Systolic arrays can only achieve high utilization for consecutive and large matrix multiplications. In contrast, FlashAttention requires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units result in low systolic array utilization. This is further exacerbated by the fact that softmax involves numerous non-matrix operations, which are not well-suited for systolic arrays. Moreover, the concurrent execution of matrix multiplication on systolic arrays and softmax on vector units leads to register file and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array architecture that enables the entire FlashAttention algorithm to run entirely within a single systolic array, eliminating the need for external vector units. At the core of FSA is SystolicAttention, a novel scheduling algorithm that maps FlashAttention operations onto systolic arrays with fine-grained, element-wise overlap. This significantly improves array utilization while preserving the original floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against state-of-the-art commercial accelerators. Our results show that FSA achieves 1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS NeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area overhead.",
      "authors": [
        "Jiawei Lin",
        "Guokai Chen",
        "Yuanlong Li",
        "Thomas Bourgeat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:04:17+00:00",
          "link": "https://arxiv.org/abs/2507.11331v1",
          "size": "528kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:36:16+00:00",
          "link": "https://arxiv.org/abs/2507.11331v2",
          "size": "528kb",
          "version": "v2"
        }
      ],
      "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11331",
        "HTML": "https://arxiv.org/html/2507.11331v2",
        "PDF": "https://arxiv.org/pdf/2507.11331"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses improvements in systolic array architecture for executing FlashAttention within transformer models. There is no discussion on reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11423",
      "abstract": "Human reasoning involves different strategies, each suited to specific problems. Prior work shows that large language model (LLMs) tend to favor a single reasoning strategy, potentially limiting their effectiveness in diverse reasoning challenges. In this work, we investigate whether prompting can control LLMs reasoning strategies and assess its impact on logical problem-solving. While our experiments show that no single strategy consistently improves accuracy, performance could be enhanced if models could adaptively choose the optimal strategy. We propose methods to guide LLMs in strategy selection, highlighting new ways to refine their reasoning abilities.",
      "authors": [
        "Yanjian Zhang",
        "Guillaume Wisniewski",
        "Nadi Tomeh",
        "Thierry Charnois"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.11423v1",
          "size": "435kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T13:02:26+00:00",
          "link": "https://arxiv.org/abs/2507.11423v2",
          "size": "440kb",
          "version": "v2"
        }
      ],
      "title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11423",
        "PDF": "https://arxiv.org/pdf/2507.11423"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores reasoning strategies in large language models and their adaptation through prompting for logical problem-solving. It does not discuss reinforcement learning or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11439",
      "abstract": "Currently, iTransformer is one of the most popular and effective models for multivariate time series (MTS) forecasting. Thanks to its inverted framework, iTransformer effectively captures multivariate correlation. However, the inverted framework still has some limitations. It diminishes temporal interdependency information, and introduces noise in cases of nonsignificant variable correlation. To address these limitations, we introduce a novel data augmentation method on inverted framework, called DAIF. Unlike previous data augmentation methods, DAIF stands out as the first real-time augmentation specifically designed for the inverted framework in MTS forecasting. We first define the structure of the inverted sequence-to-sequence framework, then propose two different DAIF strategies, Frequency Filtering and Cross-variation Patching to address the existing challenges of the inverted framework. Experiments across multiple datasets and inverted models have demonstrated the effectiveness of our DAIF.",
      "authors": [
        "Hongming Tan",
        "Ting Chen",
        "Ruochong Jin",
        "Wai Kin Chan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:01:58+00:00",
          "link": "https://arxiv.org/abs/2507.11439v1",
          "size": "502kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:40:43+00:00",
          "link": "https://arxiv.org/abs/2507.11439v2",
          "size": "501kb",
          "version": "v2"
        }
      ],
      "title": "Data Augmentation in Time Series Forecasting through Inverted Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11439",
        "HTML": "https://arxiv.org/html/2507.11439v2",
        "PDF": "https://arxiv.org/pdf/2507.11439"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on data augmentation methods for time series forecasting using an inverted framework, but it does not mention reinforcement learning or any related data processing tasks within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11484",
      "abstract": "LP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support Vector Machine (SVM), Linear Programming (LP), and Semidefinite Programming (SDP) are fundamental combinatorial optimization problems, with many important applications in machine learning applications such as classification, bioinformatics, and noisy learning. We study LP-type problems in several streaming and distributed big data models, giving $\\varepsilon$-approximation linear sketching algorithms with a focus on the high accuracy regime with low dimensionality $d$, that is, when ${d < (1/\\varepsilon)^{0.999}}$. Our main result is an $O(ds)$ pass algorithm with $O(s( \\sqrt{d}/\\varepsilon)^{3d/s}) \\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$ space complexity in words, for any parameter $s \\in [1, d \\log (1/\\varepsilon)]$, to solve $\\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC dimension. Notably, by taking $s = d \\log (1/\\varepsilon)$, we achieve space complexity polynomial in $d$ and polylogarithmic in $1/\\varepsilon$, presenting exponential improvements in $1/\\varepsilon$ over current algorithms. We complement our results by showing lower bounds of $(1/\\varepsilon)^{\\Omega(d)}$ for any $1$-pass algorithm solving the $(1 + \\varepsilon)$-approximation MEB and linear SVM problems, further motivating our multi-pass approach.",
      "authors": [
        "N. Efe \\c{C}ekirge",
        "William Gay",
        "David P. Woodruff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:55:08+00:00",
          "link": "https://arxiv.org/abs/2507.11484v1",
          "size": "133kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T01:50:18+00:00",
          "link": "https://arxiv.org/abs/2507.11484v2",
          "size": "133kb",
          "version": "v2"
        }
      ],
      "title": "Multipass Linear Sketches for Geometric LP-Type Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11484",
        "HTML": "https://arxiv.org/html/2507.11484v2",
        "PDF": "https://arxiv.org/pdf/2507.11484"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study addresses LP-type problems and provides linear sketching algorithms, with no discussion on reinforcement learning or data processing tasks related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11498",
      "abstract": "Humanoid robots have seen remarkable advances in dexterity, balance, and locomotion, yet their role in expressive domains such as music performance remains largely unexplored. Musical tasks, like drumming, present unique challenges, including split-second timing, rapid contacts, and multi-limb coordination over performances lasting minutes. In this paper, we introduce Robot Drummer, a humanoid capable of expressive, high-precision drumming across a diverse repertoire of songs. We formulate humanoid drumming as sequential fulfillment of timed contacts and transform drum scores into a Rhythmic Contact Chain. To handle the long-horizon nature of musical performance, we decompose each piece into fixed-length segments and train a single policy across all segments in parallel using reinforcement learning. Through extensive experiments on over thirty popular rock, metal, and jazz tracks, our results demonstrate that Robot Drummer consistently achieves high F1 scores. The learned behaviors exhibit emergent human-like drumming strategies, such as cross-arm strikes, and adaptive stick assignments, demonstrating the potential of reinforcement learning to bring humanoid robots into the domain of creative musical performance. Project page: robotdrummer.github.io",
      "authors": [
        "Asad Ali Shahid and Francesco Braghin and Loris Roveda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:16:50+00:00",
          "link": "https://arxiv.org/abs/2507.11498v1",
          "size": "9210kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T16:35:21+00:00",
          "link": "https://arxiv.org/abs/2507.11498v2",
          "size": "9210kb",
          "version": "v2"
        }
      ],
      "title": "Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11498",
        "HTML": "https://arxiv.org/html/2507.11498v2",
        "PDF": "https://arxiv.org/pdf/2507.11498"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper involves reinforcement learning by training a policy for humanoid robots to perform drumming. While the main focus is on skill learning, data processing tasks specific to RL, like segmenting performance data, are indirectly part of the methodology, though not explicitly emphasized."
      },
      "source": "arXiv"
    },
    {
      "id": "2211.05622",
      "abstract": "Template generation is a critical step in groupwise image registration, which involves aligning a group of subjects into a common space. While existing methods can generate high-quality template images, they often incur substantial time costs or are limited by fixed group scales. In this paper, we present InstantGroup, an efficient groupwise template generation framework based on variational autoencoder (VAE) models that leverage latent representations' arithmetic properties, enabling scalability to groups of any size. InstantGroup features a Dual VAE backbone with shared-weight twin networks to handle pairs of inputs and incorporates a Displacement Inversion Module (DIM) to maintain template unbiasedness and a Subject-Template Alignment Module (STAM) to improve template quality and registration accuracy. Experiments on 3D brain MRI scans from the OASIS and ADNI datasets reveal that InstantGroup dramatically reduces runtime, generating templates within seconds for various group sizes while maintaining superior performance compared to state-of-the-art baselines on quantitative metrics, including unbiasedness and registration accuracy.",
      "authors": [
        "Ziyi He and Albert C. S. Chung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-10T14:54:31+00:00",
          "link": "https://arxiv.org/abs/2211.05622v1",
          "size": "8139kb",
          "version": "v1"
        },
        {
          "date": "2024-06-26T15:34:47+00:00",
          "link": "https://arxiv.org/abs/2211.05622v2",
          "size": "3954kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T11:49:46+00:00",
          "link": "https://arxiv.org/abs/2211.05622v3",
          "size": "2556kb",
          "version": "v3"
        }
      ],
      "title": "InstantGroup: Instant Template Generation for Scalable Group of Brain MRI Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.05622",
        "HTML": "https://arxiv.org/html/2211.05622v3",
        "PDF": "https://arxiv.org/pdf/2211.05622"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents InstantGroup for template generation in brain MRI registration, focusing on variational autoencoders and imaging, without connections to reinforcement learning or RL-specific data processing."
      },
      "tasks": [
        "Decoder",
        "Image Registration",
        "Medical Image Registration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2308.09730",
      "abstract": "Purpose: The credibility of Artificial Intelligence (AI) models for medical imaging continues to be a challenge, affected by the diversity of models, the data used to train the models, and applicability of their combination to produce reproducible results for new data. Approach: In this work we aimed to explore if the emerging Virtual Imaging Trials (VIT) methodologies can provide an objective resource to approach this challenge. The study was conducted for the case example of COVID-19 diagnosis using clinical and virtual computed tomography (CT) and chest radiography (CXR) processed with convolutional neural networks. Multiple AI models were developed and tested using 3D ResNet-like and 2D EfficientNetv2 architectures across diverse datasets. Results: The performance differences were evaluated in terms of the area under the curve (AUC) and the DeLong method for AUC confidence intervals. The models trained on the most diverse datasets showed the highest external testing performance, with AUC values ranging from 0.73-0.76 for CT and 0.70-0.73 for CXR. Internal testing yielded higher AUC values (0.77 -0.85 for CT and 0.77-1.0 for CXR), highlighting a substantial drop in performance during external validation, which underscores the importance of diverse and comprehensive training and testing data. Most notably, VIT approach provided objective assessment of the utility of diverse models and datasets while further providing insight into the influence of dataset characteristics, patient factors, and imaging physics on AI efficacy. Conclusions: The VIT approach can be used to enhance model transparency and reliability, offering nuanced insights into the factors driving AI performance and bridging the gap between experimental and clinical settings.",
      "authors": [
        "Fakrul Islam Tushar",
        "Lavsen Dahal",
        "Saman Sotoudeh-Paima",
        "Ehsan Abadi",
        "W. Paul Segars",
        "Ehsan Samei",
        "Joseph Y. Lo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-17T19:12:32+00:00",
          "link": "https://arxiv.org/abs/2308.09730v1",
          "size": "1176kb",
          "version": "v1"
        },
        {
          "date": "2024-03-31T19:28:25+00:00",
          "link": "https://arxiv.org/abs/2308.09730v2",
          "size": "853kb",
          "version": "v2"
        },
        {
          "date": "2024-10-27T06:03:16+00:00",
          "link": "https://arxiv.org/abs/2308.09730v3",
          "size": "1094kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T22:39:09+00:00",
          "link": "https://arxiv.org/abs/2308.09730v4",
          "size": "1133kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T17:29:38+00:00",
          "link": "https://arxiv.org/abs/2308.09730v5",
          "size": "1137kb",
          "version": "v5"
        }
      ],
      "title": "The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.09730",
        "PDF": "https://arxiv.org/pdf/2308.09730"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "While this paper explores data diversity and AI model training in the context of medical imaging, it does not directly address data processing within the context of reinforcement learning."
      },
      "tasks": [
        "3D Classification",
        "Computed Tomography (CT)",
        "COVID-19 Diagnosis"
      ],
      "repo_urls": [
        "https://gitlab.oit.duke.edu/cvit-public/cvit_revicovid19",
        "https://github.com/fitushar/CVIT_ReviCOVID19"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.10301",
      "abstract": "Domain adaptation (DA) is a statistical learning problem that arises when the distribution of the source data used to train a model differs from that of the target data used to evaluate the model. While many DA algorithms have demonstrated considerable empirical success, blindly applying these algorithms can often lead to worse performance on new datasets. To address this, it is crucial to clarify the assumptions under which a DA algorithm has good target performance. In this work, we focus on the assumption of the presence of conditionally invariant components (CICs), which are relevant for prediction and remain conditionally invariant across the source and target data. We demonstrate that CICs, which can be estimated through conditional invariant penalty (CIP), play three prominent roles in providing target risk guarantees in DA. First, we propose a new algorithm based on CICs, importance-weighted conditional invariant penalty (IW-CIP), which has target risk guarantees beyond simple settings such as covariate shift and label shift. Second, we show that CICs help identify large discrepancies between source and target risks of other DA algorithms. Finally, we demonstrate that incorporating CICs into the domain invariant projection (DIP) algorithm can address its failure scenario caused by label-flipping features. We support our new algorithms and theoretical findings via numerical experiments on synthetic data, MNIST, CelebA, Camelyon17, and DomainNet datasets.",
      "authors": [
        "Keru Wu",
        "Yuansi Chen",
        "Wooseok Ha",
        "Bin Yu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-19T04:04:59+00:00",
          "link": "https://arxiv.org/abs/2309.10301v1",
          "size": "4597kb",
          "version": "v1"
        },
        {
          "date": "2024-07-08T11:11:51+00:00",
          "link": "https://arxiv.org/abs/2309.10301v2",
          "size": "3741kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T12:50:28+00:00",
          "link": "https://arxiv.org/abs/2309.10301v3",
          "size": "4147kb",
          "version": "v3"
        }
      ],
      "title": "Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.10301",
        "HTML": "https://arxiv.org/html/2309.10301v3",
        "PDF": "https://arxiv.org/pdf/2309.10301"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses domain adaptation using conditionally invariant components, which is not directly related to data processing in reinforcement learning."
      },
      "tasks": [
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.10509",
      "abstract": "We present a quantum-inspired tensor network algorithm for solving tridiagonal Quadratic Unconstrained Binary Optimization (QUBO) problems and quadratic unconstrained discrete optimization (QUDO) problems. We also solve the more general Tensor quadratic unconstrained discrete optimization (T-QUDO) problems with one-neighbor interactions in a lineal chain. This method provides an exact and explicit equation for these problems. Our algorithms are based on the simulation of a state that undergoes imaginary time evolution and a Half partial trace. In addition, we address the degenerate case and evaluate the polynomial complexity of the algorithm, also providing a parallelized version. We implemented and tested them with other well-known classical algorithms and observed an improvement in the quality of the results. The performance of the proposed algorithms is compared with the Google OR-TOOLS and dimod solvers, improving their results.",
      "authors": [
        "Alejandro Mata Ali",
        "I\\~nigo Perez Delgado",
        "Marina Ristol Roura and Aitor Moreno Fdez. de Leceta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-19T10:45:15+00:00",
          "link": "https://arxiv.org/abs/2309.10509v1",
          "size": "84kb",
          "version": "v1"
        },
        {
          "date": "2023-09-25T09:22:20+00:00",
          "link": "https://arxiv.org/abs/2309.10509v2",
          "size": "84kb",
          "version": "v2"
        },
        {
          "date": "2024-04-22T15:12:10+00:00",
          "link": "https://arxiv.org/abs/2309.10509v3",
          "size": "93kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T21:32:14+00:00",
          "link": "https://arxiv.org/abs/2309.10509v4",
          "size": "150kb",
          "version": "v4"
        }
      ],
      "title": "Polynomial-time Solver of Tridiagonal QUBO, QUDO and Tensor QUDO problems with Tensor Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.10509",
        "HTML": "https://arxiv.org/html/2309.10509v4",
        "PDF": "https://arxiv.org/pdf/2309.10509"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a tensor network algorithm for solving QUBO and QUDO problems, without discussing reinforcement learning or data processing in this context."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.15801",
      "abstract": "Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\\left( n^{-1/d_\\mu } \\right)$ for GANs and $\\tilde{O}\\left( n^{-1/(d_\\mu+\\ell)} \\right)$ for BiGANs, where $d_\\mu$ and $\\ell$ are the upper Wasserstein-1 dimension of the data-distribution and latent-space dimension, respectively. The theoretical analyses not only suggest that these methods successfully avoid the curse of dimensionality, in the sense that the exponent of $n$ in the error rates does not depend on the data dimension but also serve to bridge the gap between the theoretical analyses of GANs and the known sharp rates from optimal transport literature. Additionally, we demonstrate that GANs can effectively achieve the minimax optimal rate even for non-smooth underlying distributions, with the use of interpolating generator networks.",
      "authors": [
        "Saptarshi Chakraborty and Peter L. Bartlett"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-28T23:18:10+00:00",
          "link": "https://arxiv.org/abs/2401.15801v1",
          "size": "46kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:47:13+00:00",
          "link": "https://arxiv.org/abs/2401.15801v2",
          "size": "51kb",
          "version": "v2"
        }
      ],
      "title": "On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.15801",
        "HTML": "https://arxiv.org/html/2401.15801v2",
        "PDF": "https://arxiv.org/pdf/2401.15801"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "While the paper focuses on statistical properties of GANs, it does not pertain to reinforcement learning or data processing in RL contexts."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.05102",
      "abstract": "The rise of Transformer architectures has advanced medical image segmentation, leading to hybrid models that combine Convolutional Neural Networks (CNNs) and Transformers. However, these models often suffer from excessive complexity and fail to effectively integrate spatial and channel features, crucial for precise segmentation. To address this, we propose LHU-Net, a Lean Hybrid U-Net for volumetric medical image segmentation. LHU-Net prioritizes spatial feature extraction before refining channel features, optimizing both efficiency and accuracy. Evaluated on four benchmark datasets (Synapse, Left Atrial, BraTS-Decathlon, and Lung-Decathlon), LHU-Net consistently outperforms existing models across diverse modalities (CT/MRI) and output configurations. It achieves state-of-the-art Dice scores while using four times fewer parameters and 20% fewer FLOPs than competing models, without the need for pre-training, additional data, or model ensembles. With an average of 11 million parameters, LHU-Net sets a new benchmark for computational efficiency and segmentation accuracy. Our implementation is available on GitHub: https://github.com/xmindflow/LHUNet",
      "authors": [
        "Yousef Sadegheih",
        "Afshin Bozorgpour",
        "Pratibha Kumari",
        "Reza Azad",
        "Dorit Merhof"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-07T22:58:18+00:00",
          "link": "https://arxiv.org/abs/2404.05102v1",
          "size": "16231kb",
          "version": "v1"
        },
        {
          "date": "2024-09-11T14:35:58+00:00",
          "link": "https://arxiv.org/abs/2404.05102v2",
          "size": "16681kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T12:28:25+00:00",
          "link": "https://arxiv.org/abs/2404.05102v3",
          "size": "2530kb",
          "version": "v3"
        }
      ],
      "title": "LHU-Net: a Lean Hybrid U-Net for Cost-efficient, High-performance Volumetric Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.05102",
        "HTML": "https://arxiv.org/html/2404.05102v3",
        "PDF": "https://arxiv.org/pdf/2404.05102"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces LHU-Net for medical image segmentation, specifically targeting improvements in efficiency and accuracy of volumetric segmentation using hybrid architectures. There is no mention of reinforcement learning or any data processing relevant to RL."
      },
      "tasks": [
        "Computational Efficiency",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Volumetric Medical Image Segmentation"
      ],
      "repo_urls": [
        "https://github.com/xmindflow/lhunet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.10743",
      "abstract": "The distance of a stabilizer quantum code is a very important feature since it determines the number of errors that can be detected and corrected. We present three new fast algorithms and implementations for computing the symplectic distance of the associated classical code. Our new algorithms are based on the Brouwer-Zimmermann algorithm. Our experimental study shows that these new implementations are much faster than current state-of-the-art licensed implementations on single-core processors, multicore processors, and shared-memory multiprocessors. In the most computationally-demanding cases, the performance gain in the computational time can be larger than one order of magnitude. The experimental study also shows a good scalability on shared-memory parallel architectures.",
      "authors": [
        "Fernando Hernando",
        "Gregorio Quintana-Ort\\'i",
        "Markus Grassl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Information Theory (cs.IT)",
        "Mathematical Software (cs.MS)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T11:24:30+00:00",
          "link": "https://arxiv.org/abs/2408.10743v1",
          "size": "99kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T10:41:14+00:00",
          "link": "https://arxiv.org/abs/2408.10743v2",
          "size": "99kb",
          "version": "v2"
        }
      ],
      "title": "Fast Algorithms and Implementations for Computing the Minimum Distance of Quantum Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10743",
        "HTML": "https://arxiv.org/html/2408.10743v2",
        "PDF": "https://arxiv.org/pdf/2408.10743"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper introduces algorithms for computing the minimum distance of quantum codes, which is unrelated to reinforcement learning or data processing in the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08119",
      "abstract": "Farkas established that a system of linear inequalities has a solution if and only if we cannot obtain a contradiction by taking a linear combination of the inequalities. We state and formally prove several Farkas-like theorems over linearly ordered fields in Lean 4. Furthermore, we extend duality theory to the case when some coefficients are allowed to take ``infinite values''.",
      "authors": [
        "Martin Dvorak and Vladimir Kolmogorov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-12T15:09:07+00:00",
          "link": "https://arxiv.org/abs/2409.08119v1",
          "size": "213kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:36:43+00:00",
          "link": "https://arxiv.org/abs/2409.08119v2",
          "size": "214kb",
          "version": "v2"
        }
      ],
      "title": "Duality theory in linear optimization and its extensions -- formally verified",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08119",
        "HTML": "https://arxiv.org/html/2409.08119v2",
        "PDF": "https://arxiv.org/pdf/2409.08119"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on duality theory in linear optimization, which is unrelated to reinforcement learning or data processing within RL."
      },
      "repo_urls": [
        "https://github.com/madvorak/duality"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19704",
      "abstract": "Quality molecular representations are key to foundation model development in bio-medical research. Previous efforts have typically focused on a single representation or molecular view, which may have strengths or weaknesses on a given task. We develop Multi-view Molecular Embedding with Late Fusion (MMELON), an approach that integrates graph, image and text views in a foundation model setting and may be readily extended to additional representations. Single-view foundation models are each pre-trained on a dataset of up to 200M molecules. The multi-view model performs robustly, matching the performance of the highest-ranked single-view. It is validated on over 120 tasks, including molecular solubility, ADME properties, and activity against G Protein-Coupled receptors (GPCRs). We identify 33 GPCRs that are related to Alzheimer's disease and employ the multi-view model to select strong binders from a compound screen. Predictions are validated through structure-based modeling and identification of key binding motifs.",
      "authors": [
        "Parthasarathy Suryanarayanan",
        "Yunguang Qiu",
        "Shreyans Sethi",
        "Diwakar Mahajan",
        "Hongyang Li",
        "Yuxin Yang",
        "Elif Eyigoz",
        "Aldo Guzman Saenz",
        "Daniel E. Platt",
        "Timothy H. Rumbell",
        "Kenney Ng",
        "Sanjoy Dey",
        "Myson Burch",
        "Bum Chul Kwon",
        "Pablo Meyer",
        "Feixiong Cheng",
        "Jianying Hu",
        "Joseph A. Morrone"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T17:22:33+00:00",
          "link": "https://arxiv.org/abs/2410.19704v1",
          "size": "14526kb",
          "version": "v1"
        },
        {
          "date": "2025-01-27T23:21:14+00:00",
          "link": "https://arxiv.org/abs/2410.19704v2",
          "size": "9803kb",
          "version": "v2"
        },
        {
          "date": "2025-01-31T19:35:46+00:00",
          "link": "https://arxiv.org/abs/2410.19704v3",
          "size": "9804kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T18:03:42+00:00",
          "link": "https://arxiv.org/abs/2410.19704v4",
          "size": "9649kb",
          "version": "v4"
        }
      ],
      "title": "Multi-view biomedical foundation models for molecule-target and property prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19704",
        "HTML": "https://arxiv.org/html/2410.19704v4",
        "PDF": "https://arxiv.org/pdf/2410.19704"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with multi-view molecular embedding and their application in bio-medical tasks, without mentioning reinforcement learning or related data processing techniques."
      },
      "models": [
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m",
          "downloads": "5153",
          "likes": "13",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-BACE-101",
          "downloads": "263",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-BACE-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-MUV-101",
          "downloads": "10",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-MUV-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-SIDER-101",
          "downloads": "8",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-SIDER-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-TOX21-101",
          "downloads": "12",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-TOX21-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-LIPOPHILICITY-101",
          "downloads": "9",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-LIPOPHILICITY-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-TOXCAST-101",
          "downloads": "6",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-TOXCAST-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-CLINTOX-101",
          "downloads": "12",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-CLINTOX-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-ESOL-101",
          "downloads": "11",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-ESOL-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-BBBP-101",
          "downloads": "10",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-BBBP-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-QM7-101",
          "downloads": "12",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-QM7-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-FREESOLV-101",
          "downloads": "12",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-FREESOLV-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-HIV-101",
          "downloads": "9",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-MoleculeNet-ligand_scaffold-HIV-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-HLM-101",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-HLM-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-HPPB-101",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-HPPB-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-MDR1-MDCK-ER-101",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-MDR1-MDCK-ER-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-RLM-101",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-RLM-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-RPPB-101",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-RPPB-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-SOLUBILITY-101",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-ComputationalADME-random-SOLUBILITY-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP1A2-101",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP1A2-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP2C19-101",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP2C19-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP2C9-101",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP2C9-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP2D6-101",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP2D6-101"
        },
        {
          "model_path": "ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP3A4-101",
          "downloads": "52",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/biomed.sm.mv-te-84m-CYP-ligand_scaffold_balanced-CYP3A4-101"
        }
      ],
      "tasks": [
        "Drug Discovery",
        "molecular representation",
        "Property Prediction"
      ],
      "repo_urls": [
        "https://github.com/BiomedSciAI/biomed-multi-view"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.23990",
      "abstract": "This paper deals with the following question: Suppose that there exist an integer or a non-negative integer solution $x$ to a system $Ax = b$, where the number of non-zero components of $x$ is $n$. The target is, for a given natural number $k < n$, to approximate $b$ with $Ay$ where $y$ is an integer or non-negative integer solution with at most $k$ non-zero components. We establish upper bounds for this question in general. In specific cases, these bounds are tight. If we view the approximation quality as a function of the parameter $k$, then the paper explains why the quality of the approximation increases exponentially as $k$ goes to $n$. This paper is a complete version of an extended abstract that appeared at the 26th International Conference on Integer Programming and Combinatorial Optimization (IPCO).",
      "authors": [
        "Stefan Kuhlmann and Timm Oertel and Robert Weismantel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T14:45:52+00:00",
          "link": "https://arxiv.org/abs/2410.23990v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T10:17:03+00:00",
          "link": "https://arxiv.org/abs/2410.23990v2",
          "size": "39kb",
          "version": "v2"
        }
      ],
      "title": "Sparse Approximation in Lattices and Semigroups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23990",
        "HTML": "https://arxiv.org/html/2410.23990v2",
        "PDF": "https://arxiv.org/pdf/2410.23990"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work addresses mathematical optimization problems in integer solutions, with no indication of overlap with reinforcement learning or related data processing considerations."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.12898",
      "abstract": "In distributed optimization, the communication of model updates can be a performance bottleneck. Consequently, gradient compression has been proposed as a means of increasing optimization throughput. In general, due to information loss, compression introduces a penalty on the number of iterations needed to reach a solution. In this work, we investigate how the iteration penalty depends on the interaction between compression and problem structure, in the context of non-convex stochastic optimization. We focus on linear schemes, where compression and decompression can be modeled as multiplication with a random matrix. We consider several distributions of matrices, among them Haar-distributed orthogonal matrices and matrices with random Gaussian entries. We find that the impact of compression on convergence can be quantified in terms of a smoothness matrix associated with the objective function, using a norm defined by the compression scheme. The analysis reveals that in certain cases, compression performance is related to low-rank structure or other spectral properties of the problem and our bounds predict that the penalty introduced by compression is significantly reduced compared to worst-case bounds that only consider the compression level, ignoring problem data. We verify the theoretical findings experimentally, including fine-tuning an image classification model.",
      "authors": [
        "Thomas Flynn and Patrick Johnstone and Shinjae Yoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-19T22:26:42+00:00",
          "link": "https://arxiv.org/abs/2411.12898v1",
          "size": "1390kb",
          "version": "v1"
        },
        {
          "date": "2024-12-15T22:18:59+00:00",
          "link": "https://arxiv.org/abs/2411.12898v2",
          "size": "914kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T21:13:27+00:00",
          "link": "https://arxiv.org/abs/2411.12898v3",
          "size": "1385kb",
          "version": "v3"
        }
      ],
      "title": "Problem-dependent convergence bounds for randomized linear gradient compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12898",
        "PDF": "https://arxiv.org/pdf/2411.12898"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses gradient compression in distributed optimization, particularly in non-convex stochastic optimization, with no specific discussion of reinforcement learning or data processing related to it."
      },
      "tasks": [
        "Distributed Optimization",
        "image-classification",
        "Image Classification",
        "Stochastic Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15513",
      "abstract": "Medical image segmentation data inherently contain uncertainty. This can stem from both imperfect image quality and variability in labeling preferences on ambiguous pixels, which depend on annotator expertise and the clinical context of the annotations. For instance, a boundary pixel might be labeled as tumor in diagnosis to avoid under-estimation of severity, but as normal tissue in radiotherapy to prevent damage to sensitive structures. As segmentation preferences vary across downstream applications, it is often desirable for an image segmentation model to offer user-adaptable predictions rather than a fixed output. While prior uncertainty-aware and interactive methods offer adaptability, they are inefficient at test time: uncertainty-aware models require users to choose from numerous similar outputs, while interactive models demand significant user input through click or box prompts to refine segmentation. To address these challenges, we propose \\textbf{SPA}, a new \\textbf{S}egmentation \\textbf{P}reference \\textbf{A}lignment framework that efficiently adapts to diverse test-time preferences with minimal human interaction. By presenting users with a select few, distinct segmentation candidates that best capture uncertainties, it reduces the user workload to reach the preferred segmentation. To accommodate user preference, we introduce a probabilistic mechanism that leverages user feedback to adapt a model's segmentation preference. The proposed framework is evaluated on several medical image segmentation tasks: color fundus images, lung lesion and kidney CT scans, MRI scans of brain and prostate. SPA shows 1) a significant reduction in user time and effort compared to existing interactive segmentation approaches, 2) strong adaptability based on human feedback, and 3) state-of-the-art image segmentation performance across different imaging modalities and semantic labels.",
      "authors": [
        "Jiayuan Zhu",
        "Junde Wu",
        "Cheng Ouyang",
        "Konstantinos Kamnitsas",
        "J. Alison Noble"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-23T10:27:08+00:00",
          "link": "https://arxiv.org/abs/2411.15513v1",
          "size": "5042kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:03:49+00:00",
          "link": "https://arxiv.org/abs/2411.15513v2",
          "size": "17167kb",
          "version": "v2"
        }
      ],
      "title": "SPA: Efficient User-Preference Alignment against Uncertainty in Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15513",
        "HTML": "https://arxiv.org/html/2411.15513v2",
        "PDF": "https://arxiv.org/pdf/2411.15513"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a segmentation preference alignment framework for medical imaging, which is unrelated to reinforcement learning or data processing in reinforcement learning contexts."
      },
      "tasks": [
        "Image Segmentation",
        "Interactive Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.16425",
      "abstract": "We present Patherea, a unified framework for point-based cell detection and classification that enables the development and fair evaluation of state-of-the-art methods. To support this, we introduce a large-scale dataset that replicates the clinical workflow for Ki-67 proliferation index estimation. Our method directly predicts cell locations and classes without relying on intermediate representations. It incorporates a hybrid Hungarian matching strategy for accurate point assignment and supports flexible backbones and training regimes, including recent pathology foundation models. Patherea achieves state-of-the-art performance on public datasets - Lizard, BRCA-M2C, and BCData - while highlighting performance saturation on these benchmarks. In contrast, our newly proposed Patherea dataset presents a significantly more challenging benchmark. Additionally, we identify and correct common errors in current evaluation protocols and provide an updated benchmarking utility for standardized assessment. The Patherea dataset and code are publicly available to facilitate further research and fair comparisons.",
      "authors": [
        "Dejan \\v{S}tepec",
        "Maja Jer\\v{s}e",
        "Sne\\v{z}ana {\\DJ}oki\\'c",
        "Jera Jeruc",
        "Nina Zidar",
        "Danijel Sko\\v{c}aj"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-21T01:23:58+00:00",
          "link": "https://arxiv.org/abs/2412.16425v1",
          "size": "18733kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:52:13+00:00",
          "link": "https://arxiv.org/abs/2412.16425v2",
          "size": "22557kb",
          "version": "v2"
        }
      ],
      "title": "Patherea: Cell Detection and Classification for the 2020s",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16425",
        "HTML": "https://arxiv.org/html/2412.16425v2",
        "PDF": "https://arxiv.org/pdf/2412.16425"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "Patherea is a framework for cell detection and classification in medical imaging, focusing on dataset creation for benchmarking, without discussing reinforcement learning data processing."
      },
      "datasets": [
        {
          "dataset_name": "ds2268/patherea",
          "downloads": "22",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ds2268/patherea"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Cell Detection",
        "Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.05590",
      "abstract": "Human interactions in the online world comprise a combination of positive and negative exchanges. These diverse interactions can be captured using signed network representations, where edges take positive or negative weights to indicate the sentiment of the interaction between individuals. Signed networks offer valuable insights into online political polarization by capturing antagonistic interactions and ideological divides on social media platforms. This study analyzes polarization on Meneame, a Spanish social media platform that facilitates engagement with news stories through comments and voting. Using a dual-method approach, Signed Hamiltonian Eigenvector Embedding for Proximity (SHEEP) for signed networks and Correspondence Analysis (CA) for unsigned networks, we investigate how including negative ties enhances the understanding of structural polarization levels across different conversation topics on the platform. While the unsigned Meneame network effectively delineates ideological communities, only by incorporating negative ties can we identify ideologically extreme users who engage in antagonistic behaviors: without them, the most extreme users remain indistinguishable from their less confrontational ideological peers.",
      "authors": [
        "Elena Candellone",
        "Shazia'Ayn Babul",
        "\\\"Ozg\\\"ur Togay",
        "Alexandre Bovet",
        "Javier Garcia-Bernardo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T21:52:57+00:00",
          "link": "https://arxiv.org/abs/2501.05590v1",
          "size": "12592kb",
          "version": "v1"
        },
        {
          "date": "2025-01-15T16:41:04+00:00",
          "link": "https://arxiv.org/abs/2501.05590v2",
          "size": "12561kb",
          "version": "v2"
        },
        {
          "date": "2025-05-23T22:24:49+00:00",
          "link": "https://arxiv.org/abs/2501.05590v3",
          "size": "33050kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T16:06:48+00:00",
          "link": "https://arxiv.org/abs/2501.05590v4",
          "size": "14764kb",
          "version": "v4"
        }
      ],
      "title": "Negative Ties Highlight Hidden Extremes in Social Media Polarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05590",
        "PDF": "https://arxiv.org/pdf/2501.05590"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper studies social media polarization using signed networks and does not relate to reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.12189",
      "abstract": "In this work we propose MirrorCBO, a consensus-based optimization (CBO) method which generalizes standard CBO in the same way that mirror descent generalizes gradient descent. For this we apply the CBO methodology to a swarm of dual particles and retain the primal particle positions by applying the inverse of the mirror map, which we parametrize as the subdifferential of a strongly convex function $\\phi$. In this way, we combine the advantages of a derivative-free non-convex optimization algorithm with those of mirror descent. As a special case, the method extends CBO to optimization problems with convex constraints. Assuming bounds on the Bregman distance associated to $\\phi$, we provide asymptotic convergence results for MirrorCBO with explicit exponential rate. Another key contribution is an exploratory numerical study of this new algorithm across different application settings, focusing on (i) sparsity-inducing optimization, and (ii) constrained optimization, demonstrating the competitive performance of MirrorCBO. We observe empirically that the method can also be used for optimization on (non-convex) submanifolds of Euclidean space, can be adapted to mirrored versions of other recent CBO variants, and that it inherits from mirror descent the capability to select desirable minimizers, like sparse ones. We also include an overview of recent CBO approaches for constrained optimization and compare their performance to MirrorCBO.",
      "authors": [
        "Leon Bungert",
        "Franca Hoffmann",
        "Dohyeon Kim",
        "Tim Roith"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T14:50:19+00:00",
          "link": "https://arxiv.org/abs/2501.12189v1",
          "size": "7219kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:04:43+00:00",
          "link": "https://arxiv.org/abs/2501.12189v2",
          "size": "7468kb",
          "version": "v2"
        }
      ],
      "title": "MirrorCBO: A consensus-based optimization method in the spirit of mirror descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12189",
        "PDF": "https://arxiv.org/pdf/2501.12189"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces MirrorCBO, an optimization method, but does not involve reinforcement learning or data processing relevant to RL contexts."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/TimRoith/MirrorCBX"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14662",
      "abstract": "Decomposing a flow on a Directed Acyclic Graph (DAG) into a weighted sum of a small number of paths is an essential task in operations research and bioinformatics. This problem, referred to as Sparse Flow Decomposition (SFD), has gained significant interest, in particular for its application in RNA transcript multi-assembly, the identification of the multiple transcripts corresponding to a given gene and their relative abundance. Several recent approaches cast SFD variants as integer optimization problems, motivated by the NP-hardness of the formulations they consider. We propose an alternative formulation of SFD as a data fitting problem on the conic hull of the flow polytope. By reformulating the problem on the flow polytope for compactness and solving it using specific variants of the Frank-Wolfe algorithm, we obtain a method converging rapidly to the minimizer of the chosen loss function while producing a parsimonious decomposition. Our approach subsumes previous formulations of SFD with exact and inexact flows and can model different priors on the error distributions. Computational experiments show that our method outperforms recent integer optimization approaches in runtime, but is also highly competitive in terms of reconstruction of the underlying transcripts, despite not explicitly minimizing the solution cardinality.",
      "authors": [
        "Mathieu Besan\\c{c}on"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T17:35:07+00:00",
          "link": "https://arxiv.org/abs/2501.14662v1",
          "size": "1657kb",
          "version": "v1"
        },
        {
          "date": "2025-02-20T08:52:08+00:00",
          "link": "https://arxiv.org/abs/2501.14662v2",
          "size": "1658kb",
          "version": "v2"
        },
        {
          "date": "2025-04-09T06:58:08+00:00",
          "link": "https://arxiv.org/abs/2501.14662v3",
          "size": "1658kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T15:30:13+00:00",
          "link": "https://arxiv.org/abs/2501.14662v4",
          "size": "694kb",
          "version": "v4"
        }
      ],
      "title": "Efficient Sparse Flow Decomposition Methods for RNA Multi-Assembly",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14662",
        "HTML": "https://arxiv.org/html/2501.14662v4",
        "PDF": "https://arxiv.org/pdf/2501.14662"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Sparse Flow Decomposition and its applications in operations research and bioinformatics, particularly RNA multi-assembly. It does not discuss reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.14930",
      "abstract": "In this paper, we consider linear boundary port-Hamiltonian distributed parameter systems on a time-varying spatial domain. We derive the specific time-varying Dirac structure that these systems give rise to and use it to formally establish a new class of moving-boundary port-Hamiltonian systems by showing that these distributed parameter systems on a time-varying spatial domain admit a port-Hamiltonian representation. We demonstrate that our results can be leveraged to develop a spatial discretization scheme with dynamic meshing for approximating the telegrapher's equations on a time-varying spatial domain, which we subsequently verify numerically.",
      "authors": [
        "T.J. Meijer",
        "A. Das",
        "S. Weiland"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T21:39:41+00:00",
          "link": "https://arxiv.org/abs/2501.14930v1",
          "size": "837kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T22:06:49+00:00",
          "link": "https://arxiv.org/abs/2501.14930v2",
          "size": "586kb",
          "version": "v2"
        }
      ],
      "title": "Moving-Boundary Port-Hamiltonian Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14930",
        "HTML": "https://arxiv.org/html/2501.14930v2",
        "PDF": "https://arxiv.org/pdf/2501.14930"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper addresses moving-boundary port-Hamiltonian systems and time-varying spatial domains, which are unrelated to reinforcement learning or data processing for RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05676",
      "abstract": "Ensuring model calibration is critical for reliable prediction, yet popular distribution-free methods such as histogram binning and isotonic regression offer only asymptotic guarantees. We introduce a unified framework for Venn and Venn-Abers calibration that extends Vovk's approach beyond binary classification to a broad class of prediction problems defined by generic loss functions. Our method transforms any perfectly in-sample calibrated predictor into a set-valued predictor that, in finite samples, outputs at least one marginally calibrated point prediction. These set predictions shrink asymptotically and converge to a single conditionally calibrated prediction, capturing epistemic uncertainty. We further propose Venn multicalibration, a new approach for achieving finite-sample calibration across subpopulations. For quantile loss, our framework recovers group-conditional and multicalibrated conformal prediction as special cases and yields novel prediction intervals with quantile-conditional coverage.",
      "authors": [
        "Lars van der Laan",
        "Ahmed Alaa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T19:52:59+00:00",
          "link": "https://arxiv.org/abs/2502.05676v1",
          "size": "477kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T18:41:16+00:00",
          "link": "https://arxiv.org/abs/2502.05676v2",
          "size": "226kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T22:50:21+00:00",
          "link": "https://arxiv.org/abs/2502.05676v3",
          "size": "226kb",
          "version": "v3"
        }
      ],
      "title": "Generalized Venn and Venn-Abers Calibration with Applications in Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05676",
        "HTML": "https://arxiv.org/html/2502.05676v3",
        "PDF": "https://arxiv.org/pdf/2502.05676"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces a calibration framework for prediction problems, focusing on model calibration techniques rather than data processing in reinforcement learning settings."
      },
      "tasks": [
        "Binary Classification",
        "Conformal Prediction",
        "Prediction",
        "Prediction Intervals"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06399",
      "abstract": "We study the computation of the Petz-Augustin mean of order $\\alpha \\in (0,1) \\cup (1,\\infty)$, defined as the minimizer of a weighted sum of $n$ Petz-R\\'enyi divergences of order $\\alpha$ over the set of $d$-by-$d$ quantum states, where the Petz-R\\'enyi divergence is a quantum generalization of the classical R\\'enyi divergence. We propose the first algorithm with a non-asymptotic convergence guarantee for solving this optimization problem. The iterates are guaranteed to converge to the Petz-Augustin mean at a linear rate of \\( O\\left( \\lvert 1 - 1/\\alpha \\rvert^T \\right) \\) with respect to the Thompson metric for $\\alpha\\in(1/2,1)\\cup(1,\\infty)$, where \\( T \\) denotes the number of iterations. The algorithm has an initialization time complexity of $O\\left(nd^3\\right)$ and a per-iteration time complexity of $O\\left(nd^2 + d^3\\right)$.\n  Two applications follow. First, we propose the first iterative method with a non-asymptotic convergence guarantee for computing the Petz capacity of order $\\alpha\\in(1/2,1)$, which generalizes the quantum channel capacity and characterizes the optimal error exponent in classical-quantum channel coding. Second, we establish that the Petz-Augustin mean of order $\\alpha$, when all quantum states commute, is equivalent to the equilibrium prices in Fisher markets with constant elasticity of substitution (CES) utilities of common elasticity $\\rho=1-1/\\alpha$, and our proposed algorithm can be interpreted as a t\\^{a}tonnement dynamic. We then extend the proposed algorithm to inhomogeneous Fisher markets, where buyers have different elasticities, and prove that it achieves a faster convergence rate compared to existing t\\^{a}tonnement-type algorithms.",
      "authors": [
        "Chun-Neng Chu and Wei-Fu Tseng and Yen-Huan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T12:37:10+00:00",
          "link": "https://arxiv.org/abs/2502.06399v1",
          "size": "298kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:03:27+00:00",
          "link": "https://arxiv.org/abs/2502.06399v2",
          "size": "238kb",
          "version": "v2"
        }
      ],
      "title": "A Linearly Convergent Algorithm for Computing the Petz-Augustin Mean",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06399",
        "HTML": "https://arxiv.org/html/2502.06399v2",
        "PDF": "https://arxiv.org/pdf/2502.06399"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered on quantum information and optimization, specifically computing the Petz-Augustin mean, and does not address reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.15186",
      "abstract": "Low-light image enhancement (LLIE) is a crucial task in computer vision aimed at enhancing the visual fidelity of images captured under low-illumination conditions. Conventional methods frequently struggle with noise, overexposure, and color distortion, leading to significant image quality degradation. To address these challenges, we propose LUMINA-Net, an unsupervised deep learning framework that learns adaptive priors from low-light image pairs by integrating multi-stage illumination and reflectance modules. To assist the Retinex decomposition, inappropriate features in the raw image can be removed using a simple self-supervised mechanism. First, the illumination module intelligently adjusts brightness and contrast while preserving intricate textural details. Second, the reflectance module incorporates a noise reduction mechanism that leverages spatial attention and channel-wise feature refinement to mitigate noise contamination. Through extensive experiments on LOL and SICE datasets, evaluated using PSNR, SSIM, and LPIPS metrics, LUMINA-Net surpasses state-of-the-art methods, demonstrating its efficacy in low-light image enhancement.",
      "authors": [
        "Namrah Siddiqua",
        "Kim Suneung",
        "and Seong-Whan Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T03:37:58+00:00",
          "link": "https://arxiv.org/abs/2502.15186v1",
          "size": "5664kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T01:59:14+00:00",
          "link": "https://arxiv.org/abs/2502.15186v2",
          "size": "5012kb",
          "version": "v2"
        }
      ],
      "title": "LUMINA-Net: Low-light Upgrade through Multi-stage Illumination and Noise Adaptation Network for Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15186",
        "HTML": "https://arxiv.org/html/2502.15186v2",
        "PDF": "https://arxiv.org/pdf/2502.15186"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on low-light image enhancement using a specialized deep learning framework, without any mention of reinforcement learning or data processing for RL applications."
      },
      "tasks": [
        "Image Enhancement",
        "Low-Light Image Enhancement",
        "SSIM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05063",
      "abstract": "Magnetic Resonance Imaging (MRI) is crucial for clinical diagnostics but is hindered by prolonged scan times. Current deep learning models enhance MRI reconstruction but are often memory-intensive and unsuitable for resource-limited systems. This paper introduces a lightweight MRI reconstruction model leveraging Kronecker-Parameterized Hypercomplex Neural Networks to achieve high performance with reduced parameters. By integrating Kronecker-based modules, including Kronecker MLP, Kronecker Window Attention, and Kronecker Convolution, the proposed model efficiently extracts spatial features while preserving representational power. We introduce Kronecker U-Net and Kronecker SwinMR, which maintain high reconstruction quality with approximately 50% fewer parameters compared to existing models. Experimental evaluation on the FastMRI dataset demonstrates competitive PSNR, SSIM, and LPIPS metrics, even at high acceleration factors (8x and 16x), with no significant performance drop. Additionally, Kronecker variants exhibit superior generalization and reduced overfitting on limited datasets, facilitating efficient MRI reconstruction on hardware-constrained systems. This approach sets a new benchmark for parameter-efficient medical imaging models.",
      "authors": [
        "Haosen Zhang",
        "Jiahao Huang",
        "Yinzhe Wu",
        "Congren Dai",
        "Fanwen Wang",
        "Zhenxuan Zhang",
        "and Guang Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T00:47:15+00:00",
          "link": "https://arxiv.org/abs/2503.05063v1",
          "size": "1143kb",
          "version": "v1"
        },
        {
          "date": "2025-03-11T21:38:43+00:00",
          "link": "https://arxiv.org/abs/2503.05063v2",
          "size": "1148kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T19:15:10+00:00",
          "link": "https://arxiv.org/abs/2503.05063v3",
          "size": "475kb",
          "version": "v3"
        }
      ],
      "title": "Lightweight Hypercomplex MRI Reconstruction: A Generalized Kronecker-Parameterized Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05063",
        "HTML": "https://arxiv.org/html/2503.05063v3",
        "PDF": "https://arxiv.org/pdf/2503.05063"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses MRI reconstruction techniques using Kronecker-Parameterized Neural Networks, unrelated to reinforcement learning or its data processing."
      },
      "tasks": [
        "MRI Reconstruction",
        "SSIM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.07615",
      "abstract": "Text-to-audio models have recently emerged as a powerful technology for generating sound from textual descriptions. However, their high computational demands raise concerns about energy consumption and environmental impact. In this paper, we conduct an analysis of the energy usage of 7 state-of-the-art text-to-audio diffusion-based generative models, evaluating to what extent variations in generation parameters affect energy consumption at inference time. We also aim to identify an optimal balance between audio quality and energy consumption by considering Pareto-optimal solutions across all selected models. Our findings provide insights into the trade-offs between performance and environmental impact, contributing to the development of more efficient generative audio models.",
      "authors": [
        "Riccardo Passoni",
        "Francesca Ronchini",
        "Luca Comanducci",
        "Romain Serizel",
        "Fabio Antonacci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T14:36:47+00:00",
          "link": "https://arxiv.org/abs/2505.07615v1",
          "size": "350kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:59:28+00:00",
          "link": "https://arxiv.org/abs/2505.07615v2",
          "size": "197kb",
          "version": "v2"
        }
      ],
      "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07615",
        "HTML": "https://arxiv.org/html/2505.07615v2",
        "PDF": "https://arxiv.org/pdf/2505.07615"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the energy consumption analysis of text-to-audio models, not on reinforcement learning or its associated data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.13017",
      "abstract": "The Continuous Wavelet Transform (CWT) is an effective tool for feature extraction in acoustic recognition using Convolutional Neural Networks (CNNs), particularly when applied to non-stationary audio. However, its high computational cost poses a significant challenge, often leading researchers to prefer alternative methods such as the Short-Time Fourier Transform (STFT). To address this issue, this paper proposes a method to reduce the computational complexity of CWT by optimizing the length of the wavelet kernel and the hop size of the output scalogram. Experimental results demonstrate that the proposed approach significantly reduces computational cost while maintaining the robust performance of the trained model in acoustic recognition tasks.",
      "authors": [
        "Dang Thoai Phan",
        "Tuan Anh Huynh",
        "Van Tuan Pham",
        "Cao Minh Tran",
        "Van Thuan Mai",
        "Ngoc Quy Tran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T12:02:56+00:00",
          "link": "https://arxiv.org/abs/2505.13017v1",
          "size": "453kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T18:58:00+00:00",
          "link": "https://arxiv.org/abs/2505.13017v2",
          "size": "454kb",
          "version": "v2"
        },
        {
          "date": "2025-06-12T13:29:39+00:00",
          "link": "https://arxiv.org/abs/2505.13017v3",
          "size": "454kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T13:18:51+00:00",
          "link": "https://arxiv.org/abs/2505.13017v4",
          "size": "455kb",
          "version": "v4"
        }
      ],
      "title": "Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13017",
        "HTML": "https://arxiv.org/html/2505.13017v4",
        "PDF": "https://arxiv.org/pdf/2505.13017"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper addresses computational reduction in acoustic recognition using deep learning, specifically CWT and CNNs, and does not involve reinforcement learning or its data processing components."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.08677",
      "abstract": "Mammography is the gold standard for the detection and diagnosis of breast cancer. This procedure can be significantly enhanced with Artificial Intelligence (AI)-based software, which assists radiologists in identifying abnormalities. However, training AI systems requires large and diverse datasets, which are often difficult to obtain due to privacy and ethical constraints. To address this issue, the paper introduces MAMmography ensemBle mOdel (MAMBO), a novel patch-based diffusion approach designed to generate full-resolution mammograms. Diffusion models have shown breakthrough results in realistic image generation, yet few studies have focused on mammograms, and none have successfully generated high-resolution outputs required to capture fine-grained features of small lesions. To achieve this, MAMBO integrates separate diffusion models to capture both local and global (image-level) contexts. The contextual information is then fed into the final model, significantly aiding the noise removal process. This design enables MAMBO to generate highly realistic mammograms of up to 3840x3840 pixels. Importantly, this approach can be used to enhance the training of classification models and extended to anomaly segmentation. Experiments, both numerical and radiologist validation, assess MAMBO's capabilities in image generation, super-resolution, and anomaly segmentation, highlighting its potential to enhance mammography analysis for more accurate diagnoses and earlier lesion detection. The source code used in this study is publicly available at: https://github.com/iai-rs/mambo.",
      "authors": [
        "Milica \\v{S}kipina",
        "Nikola Jovi\\v{s}i\\'c",
        "Nicola Dall'Asen",
        "Vanja \\v{S}venda",
        "Anil Osman Tur",
        "Slobodan Ili\\'c",
        "Elisa Ricci",
        "Dubravko \\'Culibrk"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T10:37:21+00:00",
          "link": "https://arxiv.org/abs/2506.08677v1",
          "size": "39642kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:46:33+00:00",
          "link": "https://arxiv.org/abs/2506.08677v2",
          "size": "41873kb",
          "version": "v2"
        }
      ],
      "title": "MAMBO: High-Resolution Generative Approach for Mammography Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08677",
        "HTML": "https://arxiv.org/html/2506.08677v2",
        "PDF": "https://arxiv.org/pdf/2506.08677"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating high-resolution mammography images using a diffusion model approach for enhancing AI systems in medical imaging. It does not discuss reinforcement learning or data processing within the RL context."
      },
      "tasks": [
        "Anomaly Detection",
        "Image Generation",
        "Lesion Detection",
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13575",
      "abstract": "We present an experimental study of a fiber Bragg grating (FBG) interrogator based on a silicon oxynitride (SiON) photonic integrated arrayed waveguide grating (AWG). While AWG-based interrogators are compact and scalable, their practical performance is limited by non-ideal spectral responses. To address this, two calibration strategies within a 2.4 nm spectral region were compared: (1) a segmented analytical model based on a sigmoid fitting function, and (2) a machine learning (ML)-based regression model. The analytical method achieves a root mean square error (RMSE) of 7.11 pm within the calibrated range, while the ML approach based on exponential regression achieves 3.17 pm. Moreover, the ML model demonstrates generalization across an extended 2.9 nm wavelength span, maintaining sub-5 pm accuracy without re-fitting. Residual and error distribution analyses further illustrate the trade-offs between the two approaches. ML-based calibration provides a robust, data-driven alternative to analytical methods, delivering enhanced accuracy for non-ideal channel responses, reduced manual calibration effort, and improved scalability across diverse FBG sensor configurations.",
      "authors": [
        "Ivan A. Kazakov",
        "Iana V. Kulichenko",
        "Egor E. Kovalev",
        "Angelina A. Treskova",
        "Daria D. Barma",
        "Kirill M. Malakhov",
        "Ivan V. Oseledets",
        "Arkady V. Shipulin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T14:58:03+00:00",
          "link": "https://arxiv.org/abs/2506.13575v1",
          "size": "164kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T19:01:22+00:00",
          "link": "https://arxiv.org/abs/2506.13575v2",
          "size": "147kb",
          "version": "v2"
        }
      ],
      "title": "Machine Learning-Driven Compensation for Non-Ideal Channels in AWG-Based FBG Interrogator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13575",
        "HTML": "https://arxiv.org/html/2506.13575v2",
        "PDF": "https://arxiv.org/pdf/2506.13575"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This work explores ML-driven strategies to calibrate AWG-based FBG interrogators, aiming to address spectral response issues. The study focuses on machine learning methods for calibration, not related to reinforcement learning or its data processing aspects."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22790",
      "abstract": "This paper reports IEEE International Conference on Multimedia \\& Expo (ICME) 2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement. With the rapid development of video technology, especially High Dynamic Range (HDR) and Standard Dynamic Range (SDR) contents, the need for robust and generalizable Video Quality Assessment (VQA) methods has become increasingly demanded. Existing VQA models often struggle to deliver consistent performance across varying dynamic ranges, distortion types, and diverse content. This challenge was established to benchmark and promote VQA approaches capable of jointly handling HDR and SDR content. In the final evaluation phase, five teams submitted seven models along with technical reports to the Full Reference (FR) and No Reference (NR) tracks. Among them, four methods outperformed VMAF baseline, while the top-performing model achieved state-of-the-art performance, setting a new benchmark for generalizable video quality assessment.",
      "authors": [
        "Yixu Chen",
        "Bowen Chen",
        "Hai Wei",
        "Alan C. Bovik",
        "Baojun Li",
        "Wei Sun",
        "Linhan Cao",
        "Kang Fu",
        "Dandan Zhu",
        "Jun Jia",
        "Menghan Hu",
        "Xiongkuo Min",
        "Guangtao Zhai",
        "Dounia Hammou",
        "Fei Yin",
        "Rafal Mantiuk",
        "Amritha Premkumar",
        "Prajit T Rajendran",
        "Vignesh V Menon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:14:23+00:00",
          "link": "https://arxiv.org/abs/2506.22790v1",
          "size": "3004kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T23:50:11+00:00",
          "link": "https://arxiv.org/abs/2506.22790v2",
          "size": "3336kb",
          "version": "v2"
        }
      ],
      "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22790",
        "HTML": "https://arxiv.org/html/2506.22790v2",
        "PDF": "https://arxiv.org/pdf/2506.22790"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper reports on a challenge related to video quality measurement for HDR and SDR content and does not discuss reinforcement learning or RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01881",
      "abstract": "Low-dose computed tomography (LDCT) imaging employed in lung cancer screening (LCS) programs is increasing in uptake worldwide. LCS programs herald a generational opportunity to simultaneously detect cancer and non-cancer-related early-stage lung disease. Yet these efforts are hampered by a shortage of radiologists to interpret scans at scale. Here, we present TANGERINE, a computationally frugal, open-source vision foundation model for volumetric LDCT analysis. Designed for broad accessibility and rapid adaptation, TANGERINE can be fine-tuned off the shelf for a wide range of disease-specific tasks with limited computational resources and training data. Relative to models trained from scratch, TANGERINE demonstrates fast convergence during fine-tuning, thereby requiring significantly fewer GPU hours, and displays strong label efficiency, achieving comparable or superior performance with a fraction of fine-tuning data. Pretrained using self-supervised learning on over 98,000 thoracic LDCTs, including the UK's largest LCS initiative to date and 27 public datasets, TANGERINE achieves state-of-the-art performance across 14 disease classification tasks, including lung cancer and multiple respiratory diseases, while generalising robustly across diverse clinical centres. By extending a masked autoencoder framework to 3D imaging, TANGERINE offers a scalable solution for LDCT analysis, departing from recent closed, resource-intensive models by combining architectural simplicity, public availability, and modest computational requirements. Its accessible, open-source lightweight design lays the foundation for rapid integration into next-generation medical imaging tools that could transform LCS initiatives, allowing them to pivot from a singular focus on lung cancer detection to comprehensive respiratory disease management in high-risk populations.",
      "authors": [
        "Niccol\\`o McConnell",
        "Pardeep Vasudev",
        "Daisuke Yamada",
        "Daryl Cheng",
        "Mehran Azimbagirad",
        "John McCabe",
        "Shahab Aslani",
        "Ahmed H. Shahin",
        "Yukun Zhou",
        "The SUMMIT Consortium",
        "Andre Altmann",
        "Yipeng Hu",
        "Paul Taylor",
        "Sam M. Janes",
        "Daniel C. Alexander",
        "Joseph Jacob"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T16:52:10+00:00",
          "link": "https://arxiv.org/abs/2507.01881v1",
          "size": "10469kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T18:03:02+00:00",
          "link": "https://arxiv.org/abs/2507.01881v2",
          "size": "10415kb",
          "version": "v2"
        }
      ],
      "title": "A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01881",
        "PDF": "https://arxiv.org/pdf/2507.01881"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents TANGERINE, a model for thoracic disease detection in medical images, without involving reinforcement learning or related data processing issues."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06273",
      "abstract": "The increasing complexity of cardiovascular diseases and limitations in traditional healing methods mandate the invention of new drug delivery systems that assure targeted, effective, and regulated treatments, contributing directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable medical technologies in healthcare. This study investigates the flow of a Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities, such as skin friction and heat transfer rate, are analysed in detail. The Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids, which indicates the improved residence time for efficient drug delivery. The heat transfer rate shows an increase with higher volume fractions of copper and aluminium oxide nanoparticles and a decrease with higher volume fractions of silver nanoparticles. The skin friction coefficient decreases by 219% with a unit increase in the Maxwell parameter, whereas it increases by 66.1% with a unit rise in the Casson parameter. This work supports SDGs 4 and 17 by fostering interdisciplinary learning and collaboration in fluid dynamics and healthcare innovation. Additionally, the rate of heat flow was forecasted (with an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation training scheme under the influence of magneto-radiative, linear heat source and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume fractions. It is also observed that the drag coefficient is most sensitive to the changes in the Maxwell parameter.",
      "authors": [
        "S P Shivakumar",
        "Gunisetty Ramasekhar",
        "P Nimmy",
        "Sujesh Areekara",
        "L Thanuja",
        "T V Smitha",
        "S Devanathan",
        "Ganesh R Naik",
        "K V Nagaraja"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:04:40+00:00",
          "link": "https://arxiv.org/abs/2507.06273v1",
          "size": "3984kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:41:32+00:00",
          "link": "https://arxiv.org/abs/2507.06273v2",
          "size": "3895kb",
          "version": "v2"
        }
      ],
      "title": "Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06273",
        "PDF": "https://arxiv.org/pdf/2507.06273"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study primarily investigates the biofluid flow and heat transfer in a stenosed arterial domain using neural networks. It does not relate to reinforcement learning or RL-specific data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08958",
      "abstract": "As cosmological simulations and their associated software become increasingly complex, physicists face the challenge of searching through vast amounts of literature and user manuals to extract simulation parameters from dense academic papers, each using different models and formats. Translating these parameters into executable scripts remains a time-consuming and error-prone process. To improve efficiency in physics research and accelerate the cosmological simulation process, we introduce SimAgents, a multi-agent system designed to automate both parameter configuration from the literature and preliminary analysis for cosmology research. SimAgents is powered by specialized LLM agents capable of physics reasoning, simulation software validation, and tool execution. These agents collaborate through structured communication, ensuring that extracted parameters are physically meaningful, internally consistent, and software-compliant. We also construct a cosmological parameter extraction evaluation dataset by collecting over 40 simulations in published papers from Arxiv and leading journals that cover diverse simulation types. Experiments on the dataset demonstrate a strong performance of SimAgents, highlighting its effectiveness and potential to accelerate scientific research for physicists. Our demonstration video is available at: https://youtu.be/w1zLpm_CaWA. The complete system and dataset are publicly available at https://github.com/xwzhang98/SimAgents.",
      "authors": [
        "Xiaowen Zhang",
        "Zhenyu Bi",
        "Patrick Lachance",
        "Xuan Wang",
        "Tiziana Di Matteo",
        "Rupert A.C. Croft"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:31:20+00:00",
          "link": "https://arxiv.org/abs/2507.08958v1",
          "size": "5319kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T22:55:30+00:00",
          "link": "https://arxiv.org/abs/2507.08958v2",
          "size": "5337kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08958",
        "HTML": "https://arxiv.org/html/2507.08958v2",
        "PDF": "https://arxiv.org/pdf/2507.08958"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multi-agent system for parameter extraction and evaluation in cosmological simulations but does not address data processing in the context of reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09828",
      "abstract": "Bayesian optimization is a powerful tool for optimizing an expensive-to-evaluate black-box function. In particular, the effectiveness of expected improvement (EI) has been demonstrated in a wide range of applications. However, theoretical analyses of EI are limited compared with other theoretically established algorithms. This paper analyzes a randomized variant of EI, which evaluates the EI from the maximum of the posterior sample path. We show that this posterior sampling-based random EI achieves the sublinear Bayesian cumulative regret bounds under the assumption that the black-box function follows a Gaussian process. Finally, we demonstrate the effectiveness of the proposed method through numerical experiments.",
      "authors": [
        "Shion Takeno",
        "Yu Inatsu",
        "Masayuki Karasuyama",
        "Ichiro Takeuchi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:37:31+00:00",
          "link": "https://arxiv.org/abs/2507.09828v1",
          "size": "519kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T07:03:01+00:00",
          "link": "https://arxiv.org/abs/2507.09828v2",
          "size": "519kb",
          "version": "v2"
        }
      ],
      "title": "Regret Analysis of Posterior Sampling-Based Expected Improvement for Bayesian Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09828",
        "HTML": "https://arxiv.org/html/2507.09828v2",
        "PDF": "https://arxiv.org/pdf/2507.09828"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on theoretical analysis and performance of Bayesian optimization using a randomized variant of expected improvement, which does not pertain to reinforcement learning or its data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10136",
      "abstract": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical challenge in metastatic melanoma, with the underlying molecular networks being poorly understood. To address this, we constructed a dynamic Probabilistic Boolean Network model using transcriptomic data from patient tumor biopsies to elucidate the regulatory logic governing therapy response. We then employed a reinforcement learning agent to systematically discover optimal, multi-step therapeutic interventions and used explainable artificial intelligence to mechanistically interpret the agent's control policy. The analysis revealed that a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2 protein (LOXL2) was the most effective strategy. Our explainable analysis showed that this ''hit-and-run\" intervention is sufficient to erase the molecular signature driving resistance, allowing the network to self-correct without requiring sustained intervention. This study presents a novel, time-dependent therapeutic hypothesis for overcoming immunotherapy resistance and provides a powerful computational framework for identifying non-obvious intervention protocols in complex biological systems.",
      "authors": [
        "Zhonglin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:35:38+00:00",
          "link": "https://arxiv.org/abs/2507.10136v1",
          "size": "674kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:37:39+00:00",
          "link": "https://arxiv.org/abs/2507.10136v2",
          "size": "674kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T13:21:18+00:00",
          "link": "https://arxiv.org/abs/2507.10136v3",
          "size": "674kb",
          "version": "v3"
        }
      ],
      "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10136",
        "HTML": "https://arxiv.org/html/2507.10136v3",
        "PDF": "https://arxiv.org/pdf/2507.10136"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper employs a reinforcement learning agent to discover therapeutic interventions but focuses on the application and explainable AI. It doesn't delve into data processing techniques specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10530",
      "abstract": "Transition state (TS) structures define the critical geometries and energy barriers underlying chemical reactivity, yet their fleeting nature renders them experimentally elusive and drives the reliance on costly, high-throughput density functional theory (DFT) calculations. Here, we introduce TS-GEN, a conditional flow-matching generative model that maps samples from a simple Gaussian prior directly to transition-state saddle-point geometries in a single, deterministic pass. By embedding both reactant and product conformations as conditioning information, TS-GEN learns to transport latent noise to true TS structures via an optimal-transport path, effectively replacing the iterative optimization common in nudged-elastic band or string-method algorithms. TS-GEN delivers unprecedented accuracy, achieving a root-mean-square deviation of $0.004\\ \\rm{\\mathring{A}}$ (vs. $0.103\\ \\rm{\\mathring{A}}$ for prior state-of-the-art) and a mean barrier-height error of $1.019\\ {\\rm kcal/mol}$ (vs. $2.864\\ {\\rm kcal/mol}$), while requiring only $0.06\\ {\\rm s}$ GPU time per inference. Over 87% of generated TSs meet chemical-accuracy criteria ($<1.58\\ {\\rm kcal/mol}$ error), substantially outpacing existing methods. TS-GEN also exhibits strong transferability to out-of-distribution reactions from a larger database. By uniting sub-angstrom precision, sub-second speed, and broad applicability, TS-GEN will be highly useful for high-throughput exploration of complex reaction networks, paving the way to the exploration of novel chemical reaction mechanisms.",
      "authors": [
        "Ping Tuo",
        "Jiale Chen",
        "Ju Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:54:47+00:00",
          "link": "https://arxiv.org/abs/2507.10530v1",
          "size": "3986kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T15:55:28+00:00",
          "link": "https://arxiv.org/abs/2507.10530v2",
          "size": "4092kb",
          "version": "v2"
        }
      ],
      "title": "Accurate generation of chemical reaction transition states by conditional flow matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10530",
        "HTML": "https://arxiv.org/html/2507.10530v2",
        "PDF": "https://arxiv.org/pdf/2507.10530"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper details a generative model for chemical reaction transition states using conditional flow matching, focusing on improving computational chemistry tasks. It does not pertain to reinforcement learning or data processing related to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11381",
      "abstract": "We propose a framework for building patient-specific treatment recommendation models, building on the large recent literature on learning patient-level causal models and inspired by the target trial paradigm of Hernan and Robins. We focus on safety and validity, including the crucial issue of causal identification when using observational data. We do not provide a specific model, but rather a way to integrate existing methods and know-how into a practical pipeline. We further provide a real world use-case of treatment optimization for patients with heart failure who develop acute kidney injury during hospitalization. The results suggest our pipeline can improve patient outcomes over the current treatment regime.",
      "authors": [
        "Rom Gutman",
        "Shimon Sheiba",
        "Omer Noy Klein",
        "Naama Dekel Bird",
        "Amit Gruber",
        "Doron Aronson",
        "Oren Caspi",
        "Uri Shalit"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:50:41+00:00",
          "link": "https://arxiv.org/abs/2507.11381v1",
          "size": "6883kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T10:38:29+00:00",
          "link": "https://arxiv.org/abs/2507.11381v2",
          "size": "6883kb",
          "version": "v2"
        }
      ],
      "title": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11381",
        "HTML": "https://arxiv.org/html/2507.11381v2",
        "PDF": "https://arxiv.org/pdf/2507.11381"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper presents a framework for patient-specific treatment recommendations, involving causal modeling with observational data. While this involves data processing, the focus is on healthcare rather than reinforcement learning directly, hence only partially relevant to RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11534",
      "abstract": "In this study, we report that quantum quasi-cyclic low-density parity-check codes decoded via joint belief propagation (BP) exhibit steep error-rate curves, despite the presence of error floors. To the best of our knowledge, this is the first observation of such threshold-like behavior for quantum LDPC codes with non-vanishing coding rate, excluding those decoded with non-binary BP decoders. Moreover, we find that dominant error events contributing to the error floor typically involve only a small number of bits. These findings suggest that the error floor is caused by trapping sets--specific subgraph structures in the Tanner graph--and indicate that identifying and avoiding such structures may lead to further reduction of the error floor.",
      "authors": [
        "Daiki Komoto and Kenta Kasai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:58:33+00:00",
          "link": "https://arxiv.org/abs/2507.11534v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T14:59:31+00:00",
          "link": "https://arxiv.org/abs/2507.11534v2",
          "size": "117kb",
          "version": "v2"
        }
      ],
      "title": "Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11534",
        "HTML": "https://arxiv.org/html/2507.11534v2",
        "PDF": "https://arxiv.org/pdf/2507.11534"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on quantum LDPC codes and their error-rate behaviors. There is no mention of reinforcement learning or related data processing techniques in the RL domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.05393",
      "abstract": "Mutual information is commonly used as a measure of similarity between competing labelings of a given set of objects, for example to quantify performance in classification and community detection tasks. As argued recently, however, the mutual information as conventionally defined can return biased results because it neglects the information cost of the so-called contingency table, a crucial component of the similarity calculation. In principle the bias can be rectified by subtracting the appropriate information cost, leading to the modified measure known as the reduced mutual information, but in practice one can only ever compute an upper bound on this information cost, and the value of the reduced mutual information depends crucially on how good a bound is established. In this paper we describe an improved method for encoding contingency tables that gives a substantially better bound in typical use cases, and approaches the ideal value in the common case where the labelings are closely similar, as we demonstrate with extensive numerical results.",
      "authors": [
        "Maximilian Jerdee",
        "Alec Kirkley",
        "M. E. J. Newman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-08T19:49:39+00:00",
          "link": "https://arxiv.org/abs/2405.05393v1",
          "size": "2808kb",
          "version": "v1"
        }
      ],
      "title": "Mutual information and the encoding of contingency tables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.05393",
        "PDF": "https://arxiv.org/pdf/2405.05393"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses mutual information and the encoding of contingency tables, without any connection to data processing in the reinforcement learning context."
      },
      "repo_urls": [
        "https://github.com/maxjerdee/reduced_mutual_information"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.05247",
      "abstract": "Cerebral aneurysm rupture, leading to subarachnoid hemorrhage with a high mortality rate, disproportionately affects younger populations, resulting in a significant loss of productive life years. A significant proportion of these deaths is due to aneurysmal re-bleeding within the first three days following the initial bleed, prior to treatment. While early aneurysm treatment is recommended, there is no consensus on the ideal timing, and emergency treatment offers only an incremental benefit at a significant cost. Although various multivariable prediction models have been proposed to provide personalized risk assessments, no validated patient-specific predictor is available to rationalize emergency treatment. Furthermore, no model has yet incorporated emerging computational biomechanics-based biomarkers such as wall tension. In this paper, we proposed and validated an efficient semi-automatic pipeline to compute patient-specific cerebral aneurysm wall tension as a potential biomarker for the likelihood of re-bleeding. Our pipeline uses the patient's computed tomography angiography (CTA) image obtained at the time of subarachnoid hemorrhage diagnosis to create a patient-specific biomechanical model of the cerebral aneurysm using the finite element method. A distinctive feature of our approach is the straightforward model creation and wall tension computation using shell finite elements, without requiring patient-specific material properties or aneurysm wall thickness. Our non-invasive, patient-specific method for cerebral aneurysm wall tension can potentially provide individualized risk prediction and enhance clinical decision-making.",
      "authors": [
        "Mostafa Jamshidian",
        "Benjamin Zwick",
        "Arosha S Dissanayake",
        "Adam Wittek",
        "Timothy J Phillips",
        "Stephen Honeybul",
        "Graeme J Hankey",
        "Karol Miller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-07T03:34:30+00:00",
          "link": "https://arxiv.org/abs/2407.05247v1",
          "size": "1012kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T00:36:35+00:00",
          "link": "https://arxiv.org/abs/2407.05247v2",
          "size": "794kb",
          "version": "v2"
        }
      ],
      "title": "An efficient pipeline to compute patient-specific cerebral aneurysm wall tension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.05247",
        "PDF": "https://arxiv.org/pdf/2407.05247"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a pipeline for computing cerebral aneurysm wall tension, focusing on medical model predictions. There is no relevant connection to reinforcement learning or its data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.13208",
      "abstract": "As urbanization speeds up and traffic flow increases, the issue of pavement distress is becoming increasingly pronounced, posing a severe threat to road safety and service life. Traditional methods of pothole detection rely on manual inspection, which is not only inefficient but also costly. This paper proposes an intelligent road crack detection and analysis system, based on the enhanced YOLOv8 deep learning framework. A target segmentation model has been developed through the training of 4029 images, capable of efficiently and accurately recognizing and segmenting crack regions in roads. The model also analyzes the segmented regions to precisely calculate the maximum and minimum widths of cracks and their exact locations. Experimental results indicate that the incorporation of ECA and CBAM attention mechanisms substantially enhances the model's detection accuracy and efficiency, offering a novel solution for road maintenance and safety monitoring.",
      "authors": [
        "Haomin Zuo",
        "Zhengyang Li",
        "Jiangchuan Gong",
        "Zhen Tian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T04:50:28+00:00",
          "link": "https://arxiv.org/abs/2504.13208v1",
          "size": "1412kb",
          "version": "v1"
        }
      ],
      "title": "Intelligent road crack detection and analysis based on improved YOLOv8",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13208",
        "PDF": "https://arxiv.org/pdf/2504.13208"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study is concentrated on intelligent road crack detection using a YOLOv8-based system, with no link to reinforcement learning or data processing in the RL domain."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.21536",
      "abstract": "With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health. However, existing models still have deficiencies in dialogue safety, detailed scenario handling, and lightweight deployment. To address these issues, this study proposes PsyLite, a lightweight psychological counseling large language model agent developed based on the base model InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation data fine-tuning and ORPO preference optimization), PsyLite enhances the model's deep-reasoning ability, psychological counseling ability, and safe dialogue ability. After deployment using Ollama and Open WebUI, a custom workflow is created with Pipelines. An innovative conditional RAG is designed to introduce crosstalk humor elements at appropriate times during psychological counseling to enhance user experience and decline dangerous requests to strengthen dialogue safety. Evaluations show that PsyLite outperforms the baseline models in the Chinese general evaluation (CEval), psychological counseling professional evaluation (CPsyCounE), and dialogue safety evaluation (SafeDialBench), particularly in psychological counseling professionalism (CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score improvement of 2.4\\%). Additionally, the model uses quantization technology (GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient for operation), providing a feasible solution for psychological counseling applications in resource-constrained environments.",
      "authors": [
        "Fangjun Ding and Renyu Zhang and Xinyu Feng and Chengye Xie and Zheng Zhang and Yanting Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:54:42+00:00",
          "link": "https://arxiv.org/abs/2506.21536v1",
          "size": "3209kb",
          "version": "v1"
        }
      ],
      "title": "PsyLite Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21536",
        "HTML": "https://arxiv.org/html/2506.21536",
        "PDF": "https://arxiv.org/pdf/2506.21536"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a psychological counseling language model and does not address reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2205.10760",
      "abstract": "Despite the success of convolutional neural networks (CNNs) in numerous computer vision tasks and their extraordinary generalization performances, several attempts to predict the generalization errors of CNNs have only been limited to a posteriori analyses thus far. A priori theories explaining the generalization performances of deep neural networks have mostly ignored the convolutionality aspect and do not specify why CNNs are able to seemingly overcome curse of dimensionality on computer vision tasks like image classification where the image dimensions are in thousands. Our work attempts to explain the generalization performance of CNNs on image classification under the hypothesis that CNNs operate on the domain of image patches. Ours is the first work we are aware of to derive an a priori error bound for the generalization error of CNNs and we present both quantitative and qualitative evidences in the support of our theory. Our patch-based theory also offers explanation for why data augmentation techniques like Cutout, CutMix and random cropping are effective in improving the generalization error of CNNs.",
      "authors": [
        "Vamshi C. Madala and Shivkumar Chandrasekaran and Jason Bunk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-05-22T06:22:27+00:00",
          "link": "https://arxiv.org/abs/2205.10760v1",
          "size": "21269kb",
          "version": "v1"
        },
        {
          "date": "2022-05-26T15:56:21+00:00",
          "link": "https://arxiv.org/abs/2205.10760v2",
          "size": "21272kb",
          "version": "v2"
        },
        {
          "date": "2022-06-01T04:05:26+00:00",
          "link": "https://arxiv.org/abs/2205.10760v3",
          "size": "21273kb",
          "version": "v3"
        },
        {
          "date": "2023-04-12T17:33:41+00:00",
          "link": "https://arxiv.org/abs/2205.10760v4",
          "size": "20692kb",
          "version": "v4"
        }
      ],
      "title": "CNNs Avoid Curse of Dimensionality by Learning on Patches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.10760",
        "PDF": "https://arxiv.org/pdf/2205.10760"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper explores the generalization performance of CNNs through patch-based learning in computer vision and mentions data augmentation but does not address reinforcement learning or RL-specific data processing."
      },
      "tasks": [
        "Data Augmentation",
        "image-classification",
        "Image Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03966",
      "abstract": "The integration of Large Language Models (LLMs) with Learning Management Systems (LMSs) has the potential to enhance task automation and accessibility in education. However, hallucination where LLMs generate inaccurate or misleading information remains a significant challenge. This study introduces the Dynamic Course Content Integration (DCCI) mechanism, which dynamically retrieves and integrates course content and curriculum from Canvas LMS into the LLM-powered assistant, Ask ME. By employing prompt engineering to structure retrieved content within the LLM's context window, DCCI ensures accuracy, relevance, and contextual alignment, mitigating hallucination. To evaluate DCCI's effectiveness, Ask ME's usability, and broader student perceptions of AI in education, a mixed-methods approach was employed, incorporating user satisfaction ratings and a structured survey. Results from a pilot study indicate high user satisfaction (4.614/5), with students recognizing Ask ME's ability to provide timely and contextually relevant responses for both administrative and course-related inquiries. Additionally, a majority of students agreed that Ask ME's integration with course content in Canvas LMS reduced platform-switching, improving usability, engagement, and comprehension. AI's role in reducing classroom hesitation and fostering self-directed learning and intellectual curiosity was also highlighted. Despite these benefits and positive perception of AI tools, concerns emerged regarding over-reliance on AI, accuracy limitations, and ethical issues such as plagiarism and reduced student-teacher interaction. These findings emphasize the need for strategic AI implementation, ethical safeguards, and a pedagogical framework that prioritizes human-AI collaboration over substitution.",
      "authors": [
        "Kovan Mzwri (1)",
        "M\\'arta Turcs\\'anyi-Szabo (2) ((1) Doctoral School of Informatics",
        "E\\\"otv\\\"os Lor\\'and University",
        "Budapest",
        "Hungary",
        "(2) Department of Media & Educational Technology",
        "Faculty of Informatics",
        "E\\\"otv\\\"os Lor\\'and University",
        "Budapest",
        "Hungary)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T22:17:30+00:00",
          "link": "https://arxiv.org/abs/2504.03966v1",
          "size": "8412kb",
          "version": "v1"
        }
      ],
      "title": "Bridging LMS and Generative AI: Dynamic Course Content Integration (DCCI) for Connecting LLMs to Course Content -- The Ask ME Assistant",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03966",
        "PDF": "https://arxiv.org/pdf/2504.03966"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study explores integration of large language models with learning management systems in education, without any focus on reinforcement learning or its data processing challenges."
      },
      "tasks": [
        "Hallucination",
        "Prompt Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2307.16244",
      "abstract": "Blockchain technologies open new opportunities for media copyright management. To provide an overview of the main initiatives in this blockchain application area, we have first reviewed the existing academic literature. The review shows literature is still scarce and immature in many aspects, which is more evident when comparing it to initiatives coming from the industry. Blockchain has been receiving significant inflows of venture capital and crowdfunding, which have boosted its progress in many fields, including its application to media management. Consequently, we have complemented the review with a business perspective. Existing reports about blockchain and media have been studied and consolidated into four prominent use cases. Moreover, each one has been illustrated through existing businesses already exploring them. Combining the academic and industry perspectives, we provide a more general and complete overview of current trends in media copyright management using blockchain technologies.",
      "authors": [
        "Roberto Garc\\'ia",
        "Ana Cediel",
        "Merc\\`e Teixid\\'o",
        "Rosa Gil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-30T14:35:26+00:00",
          "link": "https://arxiv.org/abs/2307.16244v1",
          "size": "621kb",
          "version": "v1"
        }
      ],
      "title": "A Review of Media Copyright Management using Blockchain Technologies from the Academic and Business Perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.16244",
        "PDF": "https://arxiv.org/pdf/2307.16244"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper reviews the use of blockchain technologies for media copyright management, and does not involve reinforcement learning or data processing aspects relevant to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.15910",
      "abstract": "Machine unlearning refers to the process of mitigating the influence of specific training data on machine learning models based on removal requests from data owners. However, one important area that has been largely overlooked in the research of unlearning is reinforcement learning. Reinforcement learning focuses on training an agent to make optimal decisions within an environment to maximize its cumulative rewards. During the training, the agent tends to memorize the features of the environment, which raises a significant concern about privacy. As per data protection regulations, the owner of the environment holds the right to revoke access to the agent's training data, thus necessitating the development of a novel and pressing research field, known as \\emph{reinforcement unlearning}. Reinforcement unlearning focuses on revoking entire environments rather than individual data samples. This unique characteristic presents three distinct challenges: 1) how to propose unlearning schemes for environments; 2) how to avoid degrading the agent's performance in remaining environments; and 3) how to evaluate the effectiveness of unlearning. To tackle these challenges, we propose two reinforcement unlearning methods. The first method is based on decremental reinforcement learning, which aims to erase the agent's previously acquired knowledge gradually. The second method leverages environment poisoning attacks, which encourage the agent to learn new, albeit incorrect, knowledge to remove the unlearning environment. Particularly, to tackle the third challenge, we introduce the concept of ``environment inference attack'' to evaluate the unlearning outcomes.",
      "authors": [
        "Dayong Ye",
        "Tianqing Zhu",
        "Congcong Zhu",
        "Derui Wang",
        "Kun Gao",
        "Zewei Shi",
        "Sheng Shen",
        "Wanlei Zhou",
        "Minhui Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-26T07:04:39+00:00",
          "link": "https://arxiv.org/abs/2312.15910v1",
          "size": "4752kb",
          "version": "v1"
        },
        {
          "date": "2024-01-30T06:39:00+00:00",
          "link": "https://arxiv.org/abs/2312.15910v2",
          "size": "4943kb",
          "version": "v2"
        },
        {
          "date": "2024-02-11T07:19:58+00:00",
          "link": "https://arxiv.org/abs/2312.15910v3",
          "size": "4805kb",
          "version": "v3"
        },
        {
          "date": "2024-02-19T06:16:00+00:00",
          "link": "https://arxiv.org/abs/2312.15910v4",
          "size": "4943kb",
          "version": "v4"
        },
        {
          "date": "2024-09-09T08:07:43+00:00",
          "link": "https://arxiv.org/abs/2312.15910v5",
          "size": "5293kb",
          "version": "v5"
        }
      ],
      "title": "Reinforcement Unlearning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.15910",
        "HTML": "https://arxiv.org/html/2312.15910",
        "PDF": "https://arxiv.org/pdf/2312.15910"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "core",
        "reason": "The paper specifically addresses reinforcement learning through the concept of reinforcement unlearning, focusing on modifying how training data (environments) are processed and removed, making substantial contributions to the data processing aspect within reinforcement learning."
      },
      "tasks": [
        "Inference Attack",
        "Machine Unlearning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/cp-lab-uts/reinforcement-unlearning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.07009",
      "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated the emergence of capabilities (learned skills) when the number of system parameters and the size of training data surpass certain thresholds. The exact mechanisms behind such phenomena are not fully understood and remain a topic of active research. Inspired by the skill-text bipartite graph model proposed by Arora and Goyal for modeling semantic languages, we develop a mathematical theory to explain the emergence of learned skills, taking the learning (or training) process into account. Our approach models the learning process for skills in the skill-text bipartite graph as an iterative decoding process in Low-Density Parity Check (LDPC) codes and Irregular Repetition Slotted ALOHA (IRSA). Using density evolution analysis, we demonstrate the emergence of learned skills when the ratio of the number of training texts to the number of skills exceeds a certain threshold. Our analysis also yields a scaling law for testing errors relative to this ratio. Upon completion of the training, the association of learned skills can also be acquired to form a skill association graph. We use site percolation analysis to derive the conditions for the existence of a giant component in the skill association graph. Our analysis can also be extended to the setting with a hierarchy of skills, where a fine-tuned model is built upon a foundation model. It is also applicable to the setting with multiple classes of skills and texts. As an important application, we propose a method for semantic compression and discuss its connections to semantic communication.",
      "authors": [
        "Kuo-Yu Liao",
        "Cheng-Shang Chang",
        "Y.-W. Peter Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T13:50:46+00:00",
          "link": "https://arxiv.org/abs/2404.07009v1",
          "size": "132kb",
          "version": "v1"
        },
        {
          "date": "2024-04-13T06:43:47+00:00",
          "link": "https://arxiv.org/abs/2404.07009v2",
          "size": "3437kb",
          "version": "v2"
        },
        {
          "date": "2024-05-15T18:05:54+00:00",
          "link": "https://arxiv.org/abs/2404.07009v3",
          "size": "3087kb",
          "version": "v3"
        }
      ],
      "title": "A Mathematical Theory for Learning Semantic Languages by Abstract Learners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.07009",
        "HTML": "https://arxiv.org/html/2404.07009",
        "PDF": "https://arxiv.org/pdf/2404.07009"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper develops a mathematical theory for learning semantic languages in large language models, which is not related to data processing within the context of reinforcement learning."
      },
      "tasks": [
        "Semantic Communication",
        "Semantic Compression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.16663",
      "abstract": "Duplication is a prevalent issue within datasets. Existing research has demonstrated that the presence of duplicated data in training datasets can significantly influence both model performance and data privacy. However, the impact of data duplication on the unlearning process remains largely unexplored. This paper addresses this gap by pioneering a comprehensive investigation into the role of data duplication, not only in standard machine unlearning but also in federated and reinforcement unlearning paradigms. Specifically, we propose an adversary who duplicates a subset of the target model's training set and incorporates it into the training set. After training, the adversary requests the model owner to unlearn this duplicated subset, and analyzes the impact on the unlearned model. For example, the adversary can challenge the model owner by revealing that, despite efforts to unlearn it, the influence of the duplicated subset remains in the model. Moreover, to circumvent detection by de-duplication techniques, we propose three novel near-duplication methods for the adversary, each tailored to a specific unlearning paradigm. We then examine their impacts on the unlearning process when de-duplication techniques are applied. Our findings reveal several crucial insights: 1) the gold standard unlearning method, retraining from scratch, fails to effectively conduct unlearning under certain conditions; 2) unlearning duplicated data can lead to significant model degradation in specific scenarios; and 3) meticulously crafted duplicates can evade detection by de-duplication methods.",
      "authors": [
        "Dayong Ye",
        "Tianqing Zhu",
        "Jiayang Li",
        "Kun Gao",
        "Bo Liu",
        "Leo Yu Zhang",
        "Wanlei Zhou",
        "Yang Zhang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T02:52:51+00:00",
          "link": "https://arxiv.org/abs/2501.16663v1",
          "size": "475kb",
          "version": "v1"
        },
        {
          "date": "2025-03-11T04:54:03+00:00",
          "link": "https://arxiv.org/abs/2501.16663v2",
          "size": "475kb",
          "version": "v2"
        }
      ],
      "title": "Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine Unlearning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16663",
        "HTML": "https://arxiv.org/html/2501.16663",
        "PDF": "https://arxiv.org/pdf/2501.16663"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper investigates data duplication within various unlearning paradigms, including reinforcement unlearning. While it discusses data processing in an RL-related context, it is primarily focused on unlearning, not core RL strategies or direct data processing enhancements for RL."
      },
      "tasks": [
        "Machine Unlearning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10267",
      "abstract": "Recent developments in hardware, computer graphics, and AI may soon enable AR/VR head-mounted displays (HMDs) to become everyday devices like smartphones and tablets. Eye trackers within HMDs provide a special opportunity for such setups as it is possible to facilitate gaze-based research and interaction. However, estimating users' gaze information often requires raw eye images and videos that contain iris textures, which are considered a gold standard biometric for user authentication, and this raises privacy concerns. Previous research in the eye-tracking community focused on obfuscating iris textures while keeping utility tasks such as gaze estimation accurate. Despite these attempts, there is no comprehensive benchmark that evaluates state-of-the-art approaches. Considering all, in this paper, we benchmark blurring, noising, downsampling, rubber sheet model, and iris style transfer to obfuscate user identity, and compare their impact on image quality, privacy, utility, and risk of imposter attack on two datasets. We use eye segmentation and gaze estimation as utility tasks, and reduction in iris recognition accuracy as a measure of privacy protection, and false acceptance rate to estimate risk of attack. Our experiments show that canonical image processing methods like blurring and noising cause a marginal impact on deep learning-based tasks. While downsampling, rubber sheet model, and iris style transfer are effective in hiding user identifiers, iris style transfer, with higher computation cost, outperforms others in both utility tasks, and is more resilient against spoof attacks. Our analyses indicate that there is no universal optimal approach to balance privacy, utility, and computation burden. Therefore, we recommend practitioners consider the strengths and weaknesses of each approach, and possible combinations of those to reach an optimal privacy-utility trade-off.",
      "authors": [
        "Mengdi Wang",
        "Efe Bozkir",
        "Enkelejda Kasneci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T14:29:38+00:00",
          "link": "https://arxiv.org/abs/2504.10267v1",
          "size": "332kb",
          "version": "v1"
        },
        {
          "date": "2025-04-15T09:43:41+00:00",
          "link": "https://arxiv.org/abs/2504.10267v2",
          "size": "333kb",
          "version": "v2"
        }
      ],
      "title": "Trade-offs in Privacy-Preserving Eye Tracking through Iris Obfuscation: A Benchmarking Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10267",
        "HTML": "https://arxiv.org/html/2504.10267",
        "PDF": "https://arxiv.org/pdf/2504.10267"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper centers on privacy-preserving eye tracking through iris obfuscation, with no relation to reinforcement learning or associated data processing techniques."
      },
      "tasks": [
        "Benchmarking",
        "Gaze Estimation",
        "Iris Recognition",
        "Privacy Preserving",
        "Style Transfer"
      ],
      "repo_urls": [
        "https://gitlab.lrz.de/hctl/Iris-Obfuscation-Benchmark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12833",
      "abstract": "The damping of built-up structures stems largely from the microscopic dry frictional interactions in the contact interfaces. The accurate prediction of friction damping has been an important scientific aim of the past several decades. Recent research indicates that very good agreement with vibration measurements is to be expected if the actual contact surface topography is sufficiently well known and finely resolved, and frictional-unilateral interactions are modeled in terms of the Coulomb-Signorini conditions. Resolving all relevant length scales in one finite element model leads to enormous or even prohibitive computation effort and regularization of the set-valued contact laws might be needed to ensure numerical stability. In this work, we propose a multi-scale approach: The stress and deformation field in the contact region is modeled using elastic half-space theory, implemented on a regular and fine grid of boundary elements (BE), so that the compliance matrix can be expressed in closed form. The vibration behavior of the remaining region is described using a relatively coarse finite element (FE) model, which is further reduced via component mode synthesis. The two models are coupled by enforcing compatibility and equilibrium conditions in the far field. The set-valued Coulomb-Signorini conditions are enforced robustly and efficiently using a projected over-relaxation scheme in conjunction with an appropriate active-set strategy. For the S4 beam benchmark, very good agreement with regard to the amplitude-dependent frequency and damping ratio of the first few modes is achieved, while the computation effort is reduced by several orders of magnitude compared to the full-FE reference. The proposed multi-scale method permits a very fine resolution of the contact surface topography without suffering from numerical instability.",
      "authors": [
        "Hendrik D. Linder",
        "Johann Gross",
        "Malte Krack"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T12:19:57+00:00",
          "link": "https://arxiv.org/abs/2501.12833v1",
          "size": "7381kb",
          "version": "v1"
        }
      ],
      "title": "A coupled FE-BE multi-scale method for the dynamics of jointed structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12833",
        "HTML": "https://arxiv.org/html/2501.12833",
        "PDF": "https://arxiv.org/pdf/2501.12833"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses a multi-scale method for dynamics of jointed structures, focusing on finite element modeling, unrelated to reinforcement learning or RL data processing."
      },
      "tasks": [
        "Friction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00838",
      "abstract": "The paper explores stylometry as a method to distinguish between texts created by Large Language Models (LLMs) and humans, addressing issues of model attribution, intellectual property, and ethical AI use. Stylometry has been used extensively to characterise the style and attribute authorship of texts. By applying it to LLM-generated texts, we identify their emergent writing patterns. The paper involves creating a benchmark dataset based on Wikipedia, with (a) human-written term summaries, (b) texts generated purely by LLMs (GPT-3.5/4, LLaMa 2/3, Orca, and Falcon), (c) processed through multiple text summarisation methods (T5, BART, Gensim, and Sumy), and (d) rephrasing methods (Dipper, T5). The 10-sentence long texts were classified by tree-based models (decision trees and LightGBM) using human-designed (StyloMetrix) and n-gram-based (our own pipeline) stylometric features that encode lexical, grammatical, syntactic, and punctuation patterns. The cross-validated results reached a performance of up to .87 Matthews correlation coefficient in the multiclass scenario with 7 classes, and accuracy between .79 and 1. in binary classification, with the particular example of Wikipedia and GPT-4 reaching up to .98 accuracy on a balanced dataset. Shapley Additive Explanations pinpointed features characteristic of the encyclopaedic text type, individual overused words, as well as a greater grammatical standardisation of LLMs with respect to human-written texts. These results show -- crucially, in the context of the increasingly sophisticated LLMs -- that it is possible to distinguish machine- from human-generated texts at least for a well-defined text type.",
      "authors": [
        "Karol Przystalski",
        "Jan K. Argasi\\'nski",
        "Iwona Grabska-Gradzi\\'nska",
        "Jeremi K. Ochab"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T15:08:53+00:00",
          "link": "https://arxiv.org/abs/2507.00838v1",
          "size": "937kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:31:45+00:00",
          "link": "https://arxiv.org/abs/2507.00838v2",
          "size": "933kb",
          "version": "v2"
        }
      ],
      "title": "Stylometry recognizes human and LLM-generated texts in short samples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00838",
        "HTML": "https://arxiv.org/html/2507.00838",
        "PDF": "https://arxiv.org/pdf/2507.00838"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on stylometry for distinguishing human and AI-generated texts, which is unrelated to reinforcement learning or data processing in RL contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2107.10696",
      "abstract": "Motivated by the need to provide differentiated quality-of-service (QoS) in grant-free uplink transmissions in 5G networks and beyond, we extend the probabilistic analysis of coded Poisson receivers (CPR) to the setting with multiple classes of users and receivers. For such a CPR system, we prove (under certain technical conditions) that there is a region, called the stability region in this paper. Each transmitted packet can be successfully received with probability 1 when the offered load to the system is within the stability region. On the other hand, if the offered load is outside the stability region, there is a nonzero probability that a packet will fail to be received. We then extend the stability region to the $\\epsilon$-stability region for CPR systems with decoding errors. We also demonstrate the capability of providing differentiated QoS in such CPR systems by comparing the stability regions under various parameter settings.",
      "authors": [
        "Chia-Ming Chang",
        "Yi-Jheng Lin",
        "Cheng-Shang Chang and Duan-Shin Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2021-07-22T14:06:17+00:00",
          "link": "https://arxiv.org/abs/2107.10696v1",
          "size": "1987kb",
          "version": "v1"
        }
      ],
      "title": "On the Stability Regions of Coded Poisson Receivers with Multiple Classes of Users and Receivers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2107.10696",
        "PDF": "https://arxiv.org/pdf/2107.10696"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses coded Poisson receivers and stability regions in the context of 5G networks, which are unrelated to reinforcement learning or data processing within RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21918",
      "abstract": "Recent research has demonstrated Reservoir Computing's capability to model various chaotic dynamical systems, yet its application to Hamiltonian systems remains relatively unexplored. This paper investigates the effectiveness of Reservoir Computing in capturing rogue wave dynamics from the nonlinear Schr\\\"{o}dinger equation, a challenging Hamiltonian system with modulation instability. The model-free approach learns from breather simulations with five unstable modes. A properly tuned parallel Echo State Network can predict dynamics from two distinct testing datasets. The first set is a continuation of the training data, whereas the second set involves a higher-order breather. An investigation of the one-step prediction capability shows remarkable agreement between the testing data and the models. Furthermore, we show that the trained reservoir can predict the propagation of rogue waves over a relatively long prediction horizon, despite facing unseen dynamics. Finally, we introduce a method to significantly improve the Reservoir Computing prediction in autonomous mode, enhancing its long-term forecasting ability. These results advance the application of Reservoir Computing to spatio-temporal Hamiltonian systems and highlight the critical importance of phase space coverage in the design of training data.",
      "authors": [
        "Abrari Noor Hasmi and Hadi Susanto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Pattern Formation and Solitons (nlin.PS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:12:56+00:00",
          "link": "https://arxiv.org/abs/2506.21918v1",
          "size": "2862kb",
          "version": "v1"
        }
      ],
      "title": "Model-free Forecasting of Rogue Waves using Reservoir Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21918",
        "HTML": "https://arxiv.org/html/2506.21918",
        "PDF": "https://arxiv.org/pdf/2506.21918"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with using Reservoir Computing for forecasting rogue waves, without mention of reinforcement learning or RL data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17968",
      "abstract": "Deep neural networks have demonstrated remarkable performance across numerous learning tasks but often suffer from miscalibration, resulting in unreliable probability outputs. This has inspired many recent works on mitigating miscalibration, particularly through post-hoc recalibration methods that aim to obtain calibrated probabilities without sacrificing the classification performance of pre-trained models. In this study, we summarize and categorize previous works into three general strategies: intuitively designed methods, binning-based methods, and methods based on formulations of ideal calibration. Through theoretical and practical analysis, we highlight ten common limitations in previous approaches. To address these limitations, we propose a probabilistic learning framework for calibration called h-calibration, which theoretically constructs an equivalent learning formulation for canonical calibration with boundedness. On this basis, we design a simple yet effective post-hoc calibration algorithm. Our method not only overcomes the ten identified limitations but also achieves markedly better performance than traditional methods, as validated by extensive experiments. We further analyze, both theoretically and experimentally, the relationship and advantages of our learning objective compared to traditional proper scoring rule. In summary, our probabilistic framework derives an approximately equivalent differentiable objective for learning error-bounded calibrated probabilities, elucidating the correspondence and convergence properties of computational statistics with respect to theoretical bounds in canonical calibration. The theoretical effectiveness is verified on standard post-hoc calibration benchmarks by achieving state-of-the-art performance. This research offers valuable reference for learning reliable likelihood in related fields.",
      "authors": [
        "Wenjian Huang",
        "Guiping Cao",
        "Jiahao Xia",
        "Jingkun Chen",
        "Hao Wang",
        "Jianguo Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T09:56:44+00:00",
          "link": "https://arxiv.org/abs/2506.17968v1",
          "size": "3626kb",
          "version": "v1"
        }
      ],
      "title": "h-calibration: Rethinking Classifier Recalibration with Probabilistic Error-Bounded Objective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17968",
        "HTML": "https://arxiv.org/html/2506.17968",
        "PDF": "https://arxiv.org/pdf/2506.17968"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper deals with calibration techniques for deep neural networks and does not address reinforcement learning or data processing specific to RL."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.05752",
      "abstract": "The COVID-19 pandemic's severe impact highlighted the need for accurate and timely hospitalization forecasting to support effective healthcare planning. However, most forecasting models struggled, particularly during variant surges, when they were most needed. This study introduces a novel parallel-stream Long Short-Term Memory (LSTM) framework to forecast daily state-level incident hospitalizations in the United States. Our framework incorporates a spatiotemporal feature, Social Proximity to Hospitalizations (SPH), derived from Meta's Social Connectedness Index, to improve forecasts. SPH serves as a proxy for interstate population interaction, capturing transmission dynamics across space and time. Our architecture captures both short- and long-term temporal dependencies, and a multi-horizon ensembling strategy balances forecasting consistency and error. An evaluation against the COVID-19 Forecast Hub ensemble models during the Delta and Omicron surges reveals the superiority of our model. On average, our model surpasses the ensemble by 27, 42, 54, and 69 hospitalizations per state at the 7-, 14-, 21-, and 28-day horizons, respectively, during the Omicron surge. Data-ablation experiments confirm SPH's predictive power, highlighting its effectiveness in enhancing forecasting models. This research not only advances hospitalization forecasting but also underscores the significance of spatiotemporal features, such as SPH, in modeling the complex dynamics of infectious disease spread.",
      "authors": [
        "Zhongying Wang",
        "Thoai D. Ngo",
        "Hamidreza Zoraghein",
        "Benjamin Lucas",
        "Morteza Karimzadeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T05:22:11+00:00",
          "link": "https://arxiv.org/abs/2506.05752v1",
          "size": "5247kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T22:13:57+00:00",
          "link": "https://arxiv.org/abs/2506.05752v2",
          "size": "5247kb",
          "version": "v2"
        }
      ],
      "title": "Integrating Spatiotemporal Features in LSTM for Spatially Informed COVID-19 Hospitalization Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05752",
        "HTML": "https://arxiv.org/html/2506.05752",
        "PDF": "https://arxiv.org/pdf/2506.05752"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper introduces an LSTM framework for forecasting COVID-19 hospitalizations with spatiotemporal features, but it does not relate to reinforcement learning or involve RL data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.15130",
      "abstract": "Data consisting of a graph with a function mapping into $\\mathbb{R}^d$ arise in many data applications, encompassing structures such as Reeb graphs, geometric graphs, and knot embeddings. As such, the ability to compare and cluster such objects is required in a data analysis pipeline, leading to a need for distances between them. In this work, we study the interleaving distance on discretization of these objects, called mapper graphs when $d=1$, where functor representations of the data can be compared by finding pairs of natural transformations between them. However, in many cases, computation of the interleaving distance is NP-hard. For this reason, we take inspiration from recent work by Robinson to find quality measures for families of maps that do not rise to the level of a natural transformation, called assignments. We then endow the functor images with the extra structure of a metric space and define a loss function which measures how far an assignment is from making the required diagrams of an interleaving commute. Finally we show that the computation of the loss function is polynomial with a given assignment. We believe this idea is both powerful and translatable, with the potential to provide approximations and bounds on interleavings in a broad array of contexts.",
      "authors": [
        "Erin W. Chambers and Elizabeth Munch and Sarah Percival and Bei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "General Topology (math.GN)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-27T18:07:45+00:00",
          "link": "https://arxiv.org/abs/2307.15130v1",
          "size": "204kb",
          "version": "v1"
        },
        {
          "date": "2023-08-11T15:38:43+00:00",
          "link": "https://arxiv.org/abs/2307.15130v2",
          "size": "205kb",
          "version": "v2"
        },
        {
          "date": "2024-01-18T16:51:49+00:00",
          "link": "https://arxiv.org/abs/2307.15130v3",
          "size": "263kb",
          "version": "v3"
        },
        {
          "date": "2024-03-19T18:33:27+00:00",
          "link": "https://arxiv.org/abs/2307.15130v4",
          "size": "266kb",
          "version": "v4"
        },
        {
          "date": "2024-12-20T19:36:57+00:00",
          "link": "https://arxiv.org/abs/2307.15130v5",
          "size": "301kb",
          "version": "v5"
        },
        {
          "date": "2025-05-19T19:56:07+00:00",
          "link": "https://arxiv.org/abs/2307.15130v6",
          "size": "304kb",
          "version": "v6"
        },
        {
          "date": "2025-07-15T18:23:04+00:00",
          "link": "https://arxiv.org/abs/2307.15130v7",
          "size": "172kb",
          "version": "v7"
        }
      ],
      "title": "Bounding the Interleaving Distance for Mapper Graphs with a Loss Function",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.15130",
        "PDF": "https://arxiv.org/pdf/2307.15130"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses interleaving distance for mapper graphs and does not relate to reinforcement learning or data processing within the RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05208",
      "abstract": "Autonomous vehicles (AVs) rely heavily on cameras and artificial intelligence (AI) to make safe and accurate driving decisions. However, since AI is the core enabling technology, this raises serious cyber threats that hinder the large-scale adoption of AVs. Therefore, it becomes crucial to analyze the resilience of AV security systems against sophisticated attacks that manipulate camera inputs, deceiving AI models. In this paper, we develop camera-camouflaged adversarial attacks targeting traffic sign recognition (TSR) in AVs. Specifically, if the attack is initiated by modifying the texture of a stop sign to fool the AV's object detection system, thereby affecting the AV actuators. The attack's effectiveness is tested using the CARLA AV simulator and the results show that such an attack can delay the auto-braking response to the stop sign, resulting in potential safety issues. We conduct extensive experiments under various conditions, confirming that our new attack is effective and robust. Additionally, we address the attack by presenting mitigation strategies. The proposed attack and defense methods are applicable to other end-to-end trained autonomous cyber-physical systems.",
      "authors": [
        "Yago Romano Martinez",
        "Brady Carter",
        "Abhijeet Solanki",
        "Wesam Al Amiri",
        "Syed Rafay Hasan",
        "and Terry N. Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T17:30:43+00:00",
          "link": "https://arxiv.org/abs/2502.05208v1",
          "size": "8987kb",
          "version": "v1"
        }
      ],
      "title": "Mitigation of Camouflaged Adversarial Attacks in Autonomous Vehicles--A Case Study Using CARLA Simulator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05208",
        "HTML": "https://arxiv.org/html/2502.05208",
        "PDF": "https://arxiv.org/pdf/2502.05208"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses adversarial attacks on autonomous vehicles and their mitigation strategies using the CARLA simulator. While it involves AI models, it does not address data processing in a reinforcement learning context."
      },
      "tasks": [
        "Autonomous Vehicles",
        "object-detection",
        "Object Detection",
        "Traffic Sign Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18439",
      "abstract": "In this paper, we study the problem of model-checking quantum pushdown systems from a computational complexity point of view. We arrive at the following equally important, interesting new results:\n  We first extend the notions of the {\\it probabilistic pushdown systems} and {\\it Markov chains} to their quantum analogues and investigate the question of whether it is necessary to define a quantum analogue of {\\it probabilistic computational tree logic} to describe the probabilistic and branching-time properties of the {\\it quantum Markov chain}. We study its model-checking question and show that model-checking of {\\it stateless quantum pushdown systems (qBPA)} against {\\it probabilistic computational tree logic (PCTL)} is generally undecidable, i.e., there exists no algorithm for model-checking {\\it stateless quantum pushdown systems} against {\\it probabilistic computational tree logic}.\n  We then study in which case there exists an algorithm for model-checking {\\it stateless quantum pushdown systems} and show that the problem of model-checking {\\it stateless quantum pushdown systems} against {\\it bounded probabilistic computational tree logic} (bPCTL) is decidable, and further show that this problem is $NP$-hard. Our reduction is from the {\\it bounded Post Correspondence Problem} for the first time, a well-known $NP$-complete problem.\n  Our above results advance the field of model-checking quantum systems significantly, since all of the above important and interesting results on model-checking quantum pushdown systems are completely unknown previously.",
      "authors": [
        "Deren Lin",
        "Tianrong Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T09:22:23+00:00",
          "link": "https://arxiv.org/abs/2506.18439v1",
          "size": "23kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T03:25:35+00:00",
          "link": "https://arxiv.org/abs/2506.18439v2",
          "size": "23kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:15:15+00:00",
          "link": "https://arxiv.org/abs/2506.18439v3",
          "size": "23kb",
          "version": "v3"
        },
        {
          "date": "2025-07-08T05:04:38+00:00",
          "link": "https://arxiv.org/abs/2506.18439v4",
          "size": "24kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T19:36:42+00:00",
          "link": "https://arxiv.org/abs/2506.18439v5",
          "size": "24kb",
          "version": "v5"
        },
        {
          "date": "2025-07-16T04:53:00+00:00",
          "link": "https://arxiv.org/abs/2506.18439v6",
          "size": "25kb",
          "version": "v6"
        }
      ],
      "title": "Computational Complexity of Model-Checking Quantum Pushdown Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18439",
        "PDF": "https://arxiv.org/pdf/2506.18439"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the computational complexity of model-checking quantum pushdown systems, which falls under the domain of computational complexity and formal verification rather than reinforcement learning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.05242",
      "abstract": "An abdominal aortic aneurysm (AAA) is a life-threatening condition characterized by the irreversible dilation of the lower aorta, usually detected incidentally during imaging for other health issues. Current clinical practice for managing AAA relies on a one-size-fits-all approach, based on the aneurysm's maximum diameter and growth rate, which can lead to underestimation or overestimation of AAA rupture risk. Patient-specific AAA wall stress, computed using biomechanical models derived from medical images without needing patient-specific material properties, has been widely investigated for developing individualized AAA rupture risk predictors. Therefore, AAA wall stress, determined reliably and quickly, has the potential to enhance patient-specific treatment plans. This paper presents a 7-line code, written in MATLAB using the Partial Differential Equation Toolbox, for AAA wall stress computations via finite element analysis. The code takes AAA wall geometry as input and outputs stress components over the AAA wall domain. Additionally, we present a one-click standalone software application for AAA wall stress computation, developed based on our 7-line code using MATLAB Compiler. After verification, we used our code to compute AAA wall stress in ten patients. Our analysis indicated that the 99th percentile of maximum principal stress across all patients ranged from 0.307 MPa to 0.466 MPa, with an average of 0.380 MPa and a standard deviation of 0.048 MPa. Moreover, for every case, the MATLAB simulation time was less than a minute on a laptop workstation.",
      "authors": [
        "Mostafa Jamshidian",
        "Saeideh Sekhavat",
        "Adam Wittek",
        "Donatien Le Liepvre",
        "Florian Bernard",
        "Ludovic Minvielle",
        "Antoine Fondan\\`eche",
        "Karol Miller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-07T03:12:33+00:00",
          "link": "https://arxiv.org/abs/2407.05242v1",
          "size": "1262kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T00:22:14+00:00",
          "link": "https://arxiv.org/abs/2407.05242v2",
          "size": "916kb",
          "version": "v2"
        },
        {
          "date": "2025-03-14T02:34:13+00:00",
          "link": "https://arxiv.org/abs/2407.05242v3",
          "size": "915kb",
          "version": "v3"
        }
      ],
      "title": "Abdominal aortic aneurysm wall stress: A 7-line code in MATLAB and a one-click software application",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.05242",
        "PDF": "https://arxiv.org/pdf/2407.05242"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The work is about computing abdominal aortic aneurysm wall stress using MATLAB. It does not address any aspects of reinforcement learning or data processing in an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.16671",
      "abstract": "Generative AI technology has become increasingly integrated into our daily lives, offering powerful capabilities to enhance productivity. However, these same capabilities can be exploited by adversaries for malicious purposes. While existing research on adversarial applications of generative AI predominantly focuses on cyberattacks, less attention has been given to attacks targeting deep learning models. In this paper, we introduce the use of generative AI for facilitating model-related attacks, including model extraction, membership inference, and model inversion. Our study reveals that adversaries can launch a variety of model-related attacks against both image and text models in a data-free and black-box manner, achieving comparable performance to baseline methods that have access to the target models' training data and parameters in a white-box manner. This research serves as an important early warning to the community about the potential risks associated with generative AI-powered attacks on deep learning models.",
      "authors": [
        "Dayong Ye",
        "Tianqing Zhu",
        "Shang Wang",
        "Bo Liu",
        "Leo Yu Zhang",
        "Wanlei Zhou",
        "Yang Zhang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T03:12:57+00:00",
          "link": "https://arxiv.org/abs/2501.16671v1",
          "size": "3178kb",
          "version": "v1"
        }
      ],
      "title": "Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16671",
        "PDF": "https://arxiv.org/pdf/2501.16671"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses generative AI technology and model-related attacks, which are unrelated to data processing in reinforcement learning. It focuses more on adversarial attacks and security issues rather than RL data aspects."
      },
      "tasks": [
        "Model extraction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04715",
      "abstract": "The impressive capabilities of Large Language Models (LLMs) across diverse tasks are now well\\text{-}established, yet their effective deployment necessitates careful hyperparameter optimization. Although existing methods have explored the influence of hyperparameters on model performance, a principled and generalizable framework across model architectures and data recipes remains absent. In this study, we conduct an unprecedented empirical investigation\\text{-} training over 3,700 LLMs from scratch across 100 trillion tokens, consuming nearly one million NVIDIA H800 GPU hours to establish a universal Scaling Law for hyperparameter optimization in LLM Pre-training, called \\textbf{Step Law}. We empirically observe that, under fixed model size ($N$) and dataset size ($D$), the hyperparameter landscape exhibits convexity with a broad optimum, substantially reducing the complexity of hyperparameter search. Building on this insight, we formally define and empirically validate the Step Law: The optimal learning rate follows a power-law relationship with $N$ and $D$, while the optimal batch size is primarily influenced by $D$ and remains largely invariant to $N$.Notably, our estimated optima deviate from the global best performance found via exhaustive search by merely \\textbf{0.094\\%} on the test set. To our best known, Step Law is the \\textbf{first} that unifies different model shapes and structures, such as Mixture-of-Experts models and dense transformers, as well as establishes optimal hyperparameter scaling laws across diverse data recipes. We contribute a universal, plug-and-play optimal hyperparameter tool for the community, which is expected to advance efficient LLM training at scale. All experimental code, data and checkpoints are publicly available at \\href{https://github.com/step-law/steplaw}{https://github.com/step-law/steplaw}.",
      "authors": [
        "Houyi Li",
        "Wenzhen Zheng",
        "Qiufeng Wang",
        "Hanshan Zhang",
        "Zili Wang",
        "Shijie Xuyang",
        "Yuantao Fan",
        "Zhenyu Ding",
        "Haoying Wang",
        "Ning Ding",
        "Shuigeng Zhou",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T18:58:29+00:00",
          "link": "https://arxiv.org/abs/2503.04715v1",
          "size": "9006kb",
          "version": "v1"
        },
        {
          "date": "2025-03-09T17:59:40+00:00",
          "link": "https://arxiv.org/abs/2503.04715v2",
          "size": "9004kb",
          "version": "v2"
        },
        {
          "date": "2025-03-15T17:09:54+00:00",
          "link": "https://arxiv.org/abs/2503.04715v3",
          "size": "9125kb",
          "version": "v3"
        },
        {
          "date": "2025-03-19T16:28:25+00:00",
          "link": "https://arxiv.org/abs/2503.04715v4",
          "size": "9123kb",
          "version": "v4"
        },
        {
          "date": "2025-05-21T10:48:37+00:00",
          "link": "https://arxiv.org/abs/2503.04715v5",
          "size": "9123kb",
          "version": "v5"
        },
        {
          "date": "2025-07-16T07:46:43+00:00",
          "link": "https://arxiv.org/abs/2503.04715v6",
          "size": "3548kb",
          "version": "v6"
        }
      ],
      "title": "Predictable Scale: Part I, Step Law -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04715",
        "HTML": "https://arxiv.org/html/2503.04715",
        "PDF": "https://arxiv.org/pdf/2503.04715"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper deals with hyperparameter optimization for large language models rather than data processing in reinforcement learning."
      },
      "tasks": [
        "Hyperparameter Optimization",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Mixture-of-Experts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19357",
      "abstract": "Critical heat flux is a key quantity in boiling system modeling due to its impact on heat transfer and component temperature and performance. This study investigates the development and validation of an uncertainty-aware hybrid modeling approach that combines machine learning with physics-based models in the prediction of critical heat flux in nuclear reactors for cases of dryout. Two empirical correlations, Biasi and Bowring, were employed with three machine learning uncertainty quantification techniques: deep neural network ensembles, Bayesian neural networks, and deep Gaussian processes. A pure machine learning model without a base model served as a baseline for comparison. This study examines the performance and uncertainty of the models under both plentiful and limited training data scenarios using parity plots, uncertainty distributions, and calibration curves. The results indicate that the Biasi hybrid deep neural network ensemble achieved the most favorable performance (with a mean absolute relative error of 1.846% and stable uncertainty estimates), particularly in the plentiful data scenario. The Bayesian neural network models showed slightly higher error and uncertainty but superior calibration. By contrast, deep Gaussian process models underperformed by most metrics. All hybrid models outperformed pure machine learning configurations, demonstrating resistance against data scarcity.",
      "authors": [
        "Aidan Furlong",
        "Xingang Zhao",
        "Robert Salko",
        "Xu Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T17:55:01+00:00",
          "link": "https://arxiv.org/abs/2502.19357v1",
          "size": "12856kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Based Hybrid Machine Learning for Critical Heat Flux Prediction with Uncertainty Quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19357",
        "HTML": "https://arxiv.org/html/2502.19357",
        "PDF": "https://arxiv.org/pdf/2502.19357"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This research explores hybrid machine learning models for predicting critical heat flux, focusing on uncertainty quantification, and does not involve reinforcement learning or data processing therein."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20267",
      "abstract": "This paper presents a novel learning-based approach for online estimation of maximal safe sets for local trajectory planning in unknown static environments. The neural representation of a set is used as the terminal set constraint for a model predictive control (MPC) local planner, resulting in improved recursive feasibility and safety. To achieve real-time performance and desired generalization properties, we employ the idea of hypernetworks. We use the Hamilton-Jacobi (HJ) reachability analysis as the source of supervision during the training process, allowing us to consider general nonlinear dynamics and arbitrary constraints. The proposed method is extensively evaluated against relevant baselines in simulations for different environments and robot dynamics. The results show an increase in success rate of up to 52% compared to the best baseline while maintaining comparable execution speed. Additionally, we deploy our proposed method, NTC-MPC, on a physical robot and demonstrate its ability to safely avoid obstacles in scenarios where the baselines fail.",
      "authors": [
        "Bojan Deraji\\'c",
        "Mohamed-Khalil Bouzidi",
        "Sebastian Bernhard",
        "Wolfgang H\\\"onig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T20:37:57+00:00",
          "link": "https://arxiv.org/abs/2410.20267v1",
          "size": "1450kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T21:33:17+00:00",
          "link": "https://arxiv.org/abs/2410.20267v2",
          "size": "3562kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T07:05:03+00:00",
          "link": "https://arxiv.org/abs/2410.20267v3",
          "size": "586kb",
          "version": "v3"
        }
      ],
      "title": "Learning Maximal Safe Sets Using Hypernetworks for MPC-based Local Trajectory Planning in Unknown Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20267",
        "HTML": "https://arxiv.org/html/2410.20267",
        "PDF": "https://arxiv.org/pdf/2410.20267"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The paper uses neural representations for planning in environments, which may relate to RL in terms of data used for planning and safety assessments, but does not focus on RL data processing itself."
      },
      "tasks": [
        "Model Predictive Control",
        "Motion Planning",
        "Trajectory Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2306.00642",
      "abstract": "We introduce the framework FreeCHR which formalizes the embedding of Constraint Handling Rules (CHR) into a host language, using the concept of initial algebra semantics from category theory. We hereby establish a high-level implementation scheme for CHR as well as a common formalization for both theory and practice. We propose a lifting of the syntax of CHR via an endofunctor in the category Set and a lifting of the very abstract operational semantics of CHR into FreeCHR, using the free algebra, generated by the endofunctor. We give proofs for soundness and completeness w.r.t. its original definition. We also propose a first abstract execution algorithm and prove correctness w.r.t. the operational semantics. Finally, we show the practicability of our approach by giving two possible implementations of this algorithm in Haskell and Python. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "authors": [
        "Sascha Rechenberger and Thom Fr\\\"uhwirth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-01T13:08:50+00:00",
          "link": "https://arxiv.org/abs/2306.00642v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2023-06-02T07:07:30+00:00",
          "link": "https://arxiv.org/abs/2306.00642v2",
          "size": "20kb",
          "version": "v2"
        },
        {
          "date": "2023-08-02T13:35:15+00:00",
          "link": "https://arxiv.org/abs/2306.00642v3",
          "size": "22kb",
          "version": "v3"
        },
        {
          "date": "2025-03-19T16:36:33+00:00",
          "link": "https://arxiv.org/abs/2306.00642v4",
          "size": "322kb",
          "version": "v4"
        }
      ],
      "title": "FreeCHR: An Algebraic Framework for CHR-Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.00642",
        "HTML": "https://arxiv.org/html/2306.00642",
        "PDF": "https://arxiv.org/pdf/2306.00642"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper presents the FreeCHR framework for embedding Constraint Handling Rules in host languages, which is unrelated to reinforcement learning or data processing in RL."
      },
      "repo_urls": [
        "https://gitlab.com/freechr/freechr-py"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.01570",
      "abstract": "Inspired by the structure of spherical harmonics, we propose the truncated kernel stochastic gradient descent (T-kernel SGD) algorithm with a least-square loss function for spherical data fitting. T-kernel SGD introduces a novel regularization strategy by implementing stochastic gradient descent through a closed-form solution of the projection of the stochastic gradient in a low-dimensional subspace. In contrast to traditional kernel SGD, the regularization strategy implemented by T-kernel SGD is more effective in balancing bias and variance by dynamically adjusting the hypothesis space during iterations. The most significant advantage of the proposed algorithm is that it can achieve theoretically optimal convergence rates using a constant step size (independent of the sample size) while overcoming the inherent saturation problem of kernel SGD. Additionally, we leverage the structure of spherical polynomials to derive an equivalent T-kernel SGD, significantly reducing storage and computational costs compared to kernel SGD. Typically, T-kernel SGD requires only $\\mathcal{O}(n^{1+\\frac{d}{d-1}\\epsilon})$ computational complexity and $\\mathcal{O}(n^{\\frac{d}{d-1}\\epsilon})$ storage to achieve optimal rates for the d-dimensional sphere, where $0<\\epsilon<\\frac{1}{2}$ can be arbitrarily small if the optimal fitting or the underlying space possesses sufficient regularity. This regularity is determined by the smoothness parameter of the objective function and the decaying rate of the eigenvalues of the integral operator associated with the kernel function, both of which reflect the difficulty of the estimation problem. Our main results quantitatively characterize how this prior information influences the convergence of T-kernel SGD. The numerical experiments further validate the theoretical findings presented in this paper.",
      "authors": [
        "Jinhui Bai",
        "and Lei Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T14:09:51+00:00",
          "link": "https://arxiv.org/abs/2410.01570v1",
          "size": "648kb",
          "version": "v1"
        },
        {
          "date": "2024-10-04T13:51:16+00:00",
          "link": "https://arxiv.org/abs/2410.01570v2",
          "size": "648kb",
          "version": "v2"
        },
        {
          "date": "2025-03-15T10:59:16+00:00",
          "link": "https://arxiv.org/abs/2410.01570v3",
          "size": "3749kb",
          "version": "v3"
        },
        {
          "date": "2025-03-24T13:20:40+00:00",
          "link": "https://arxiv.org/abs/2410.01570v4",
          "size": "3749kb",
          "version": "v4"
        },
        {
          "date": "2025-05-26T06:38:45+00:00",
          "link": "https://arxiv.org/abs/2410.01570v5",
          "size": "3829kb",
          "version": "v5"
        },
        {
          "date": "2025-07-16T05:59:25+00:00",
          "link": "https://arxiv.org/abs/2410.01570v6",
          "size": "3762kb",
          "version": "v6"
        }
      ],
      "title": "Truncated Kernel Stochastic Gradient Descent on Spheres",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01570",
        "PDF": "https://arxiv.org/pdf/2410.01570"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel stochastic gradient descent algorithm for spherical data fitting, with no specific mention of reinforcement learning or data processing within the RL context."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.03351",
      "abstract": "With the development of the upcoming sixth-generation (6G) wireless networks, there is a pressing need for innovative technologies capable of satisfying heightened performance indicators. Fluid antenna system (FAS) is proposed recently as a promising technique to achieve higher data rates and more diversity gains by dynamically changing the positions of the antennas to form a more desirable channel. However, worries regarding the possibly harmful effects of electromagnetic (EM) radiation emitted by devices have arisen as a result of the rapid evolution of advanced techniques in wireless communication systems. Specific absorption rate (SAR) is a widely adopted metric to quantify EM radiation worldwide. In this paper, we investigate the SAR-aware multiuser multiple-input multiple-output (MIMO) communications assisted by FAS. In particular, a two-layer iterative algorithm is proposed to minimize the SAR value under signal-to-interference-plus-noise ratio (SINR) and FAS constraints. Moreover, the minimum weighted SINR maximization problem under SAR and FAS constraints is studied by finding its relationship with the SAR minimization problem. Simulation results verify that the proposed SAR-aware FAS design outperforms the adaptive backoff and fixed-position antenna designs.",
      "authors": [
        "Yuqi Ye",
        "Li You",
        "Hao Xu",
        "Ahmed Elzanaty",
        "Kai-Kit Wong",
        "Xiqi Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T07:34:34+00:00",
          "link": "https://arxiv.org/abs/2507.03351v1",
          "size": "5174kb",
          "version": "v1"
        }
      ],
      "title": "Specific Absorption Rate-Aware Multiuser MIMO Assisted by Fluid Antenna System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03351",
        "HTML": "https://arxiv.org/html/2507.03351",
        "PDF": "https://arxiv.org/pdf/2507.03351"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This study explores wireless communication systems, specifically MIMO and SAR metrics, with no relevance to reinforcement learning or associated data processing efforts."
      },
      "source": "arXiv"
    },
    {
      "id": "2212.09521",
      "abstract": "We study mechanism design with predictions for the obnoxious facility location problem. We present deterministic strategyproof mechanisms that display tradeoffs between robustness and consistency on segments, squares, circles and trees. All these mechanisms are actually group strategyproof, with the exception of the case of squares, where manipulations from coalitions of two agents exist. We prove that these tradeoffs are optimal in the 1-dimensional case.",
      "authors": [
        "Gabriel Istrate",
        "Cosmin Bonchis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-19T15:04:11+00:00",
          "link": "https://arxiv.org/abs/2212.09521v1",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "title": "Mechanism Design With Predictions for Obnoxious Facility Location",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.09521",
        "PDF": "https://arxiv.org/pdf/2212.09521"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The study addresses mechanism design and strategyproofness in facility location problems, with no link to reinforcement learning or data processing tasks related to RL."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.10538",
      "abstract": "Accurate predictions and representations of plant growth patterns in simulated and controlled environments are important for addressing various challenges in plant phenomics research. This review explores various works on state-of-the-art predictive pattern recognition techniques, focusing on the spatiotemporal modeling of plant traits and the integration of dynamic environmental interactions. We provide a comprehensive examination of deterministic, probabilistic, and generative modeling approaches, emphasizing their applications in high-throughput phenotyping and simulation-based plant growth forecasting. Key topics include regressions and neural network-based representation models for the task of forecasting, limitations of existing experiment-based deterministic approaches, and the need for dynamic frameworks that incorporate uncertainty and evolving environmental feedback. This review surveys advances in 2D and 3D structured data representations through functional-structural plant models and conditional generative models. We offer a perspective on opportunities for future works, emphasizing the integration of domain-specific knowledge to data-driven methods, improvements to available datasets, and the implementation of these techniques toward real-world applications.",
      "authors": [
        "Mohamed Debbagh",
        "Shangpeng Sun",
        "Mark Lefsrud"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T20:22:35+00:00",
          "link": "https://arxiv.org/abs/2412.10538v1",
          "size": "2678kb",
          "version": "v1"
        },
        {
          "date": "2024-12-26T00:11:40+00:00",
          "link": "https://arxiv.org/abs/2412.10538v2",
          "size": "2642kb",
          "version": "v2"
        },
        {
          "date": "2025-06-25T02:56:51+00:00",
          "link": "https://arxiv.org/abs/2412.10538v3",
          "size": "2776kb",
          "version": "v3"
        }
      ],
      "title": "Predictive Modeling, Pattern Recognition, and Spatiotemporal Representations of Plant Growth in Simulated and Controlled Environments: A Comprehensive Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10538",
        "PDF": "https://arxiv.org/pdf/2412.10538"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This comprehensive review explores predictive modeling and spatiotemporal representations in plant phenomics, unrelated to reinforcement learning or its data processing aspects."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.06490",
      "abstract": "The widespread deployment of Unmanned Aerial Vehicles (UAVs) in surveillance, security, and airspace monitoring demands accurate and scalable detection solutions. However, progress is hindered by the lack of large-scale, high-resolution datasets with precise and cost-effective annotations. We present UAVDB, a new benchmark dataset for UAV detection and segmentation, built upon a point-guided weak supervision pipeline. As its foundation, UAVDB leverages trajectory point annotations and RGB video frames from the multi-view drone tracking dataset, captured by fixed-camera setups. We introduce an efficient annotation method, Patch Intensity Convergence (PIC), which generates high-fidelity bounding boxes directly from these trajectory points, eliminating manual labeling while maintaining accurate spatial localization. We further derive instance segmentation masks from these bounding boxes using the second version of the Segment Anything Model (SAM2), enabling rich multi-task annotations with minimal supervision. UAVDB captures UAVs at diverse scales, from visible objects to near-single-pixel instances, under challenging environmental conditions. Particularly, PIC is lightweight and readily pluggable into other point-guided scenarios, making it easy to scale up dataset generation across domains. We quantitatively compare PIC against existing annotation techniques, demonstrating superior Intersection over Union (IoU) accuracy and annotation efficiency. Finally, we benchmark several state-of-the-art (SOTA) YOLO-series detectors on UAVDB, establishing strong baselines for future research. The source code is available at https://github.com/wish44165/UAVDB .",
      "authors": [
        "Yu-Hsi Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-09T13:27:53+00:00",
          "link": "https://arxiv.org/abs/2409.06490v1",
          "size": "3337kb",
          "version": "v1"
        },
        {
          "date": "2024-09-18T13:45:27+00:00",
          "link": "https://arxiv.org/abs/2409.06490v2",
          "size": "6383kb",
          "version": "v2"
        },
        {
          "date": "2024-10-08T09:49:10+00:00",
          "link": "https://arxiv.org/abs/2409.06490v3",
          "size": "6069kb",
          "version": "v3"
        },
        {
          "date": "2025-02-20T10:35:34+00:00",
          "link": "https://arxiv.org/abs/2409.06490v4",
          "size": "7502kb",
          "version": "v4"
        },
        {
          "date": "2025-02-22T11:18:48+00:00",
          "link": "https://arxiv.org/abs/2409.06490v5",
          "size": "7630kb",
          "version": "v5"
        },
        {
          "date": "2025-07-16T07:12:33+00:00",
          "link": "https://arxiv.org/abs/2409.06490v6",
          "size": "17487kb",
          "version": "v6"
        }
      ],
      "title": "UAVDB: Point-Guided Masks for UAV Detection and Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06490",
        "HTML": "https://arxiv.org/html/2409.06490",
        "PDF": "https://arxiv.org/pdf/2409.06490"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents a UAV detection and segmentation dataset using a point-guided weak supervision pipeline, which involves data processing in computer vision tasks, not in the context of reinforcement learning."
      },
      "tasks": [
        "2D Object Detection",
        "Diversity",
        "Management"
      ],
      "repo_urls": [
        "https://github.com/wish44165/uavdb"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.00397",
      "abstract": "Understanding and constructing brain communications that capture dynamic communications across multiple regions is fundamental to modern system neuroscience, yet current methods struggle to find time-varying region-level communications or scale to large neural datasets with long recording durations. We present a novel framework using Markovian Gaussian Processes to learn brain communications with time-varying temporal delays from multi-region neural recordings, named Adaptive Delay Model (ADM). Our method combines Gaussian Processes with State Space Models and employs parallel scan inference algorithms, enabling efficient scaling to large datasets while identifying concurrent communication patterns that evolve over time. This time-varying approach captures how brain region interactions shift dynamically during cognitive processes. Validated on synthetic and multi-region neural recordings datasets, our approach discovers both the directionality and temporal dynamics of neural communication. This work advances our understanding of distributed neural computation and provides a scalable tool for analyzing dynamic brain networks.",
      "authors": [
        "Weihan Li",
        "Yule Wang",
        "Chengrui Li",
        "Anqi Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-29T10:50:23+00:00",
          "link": "https://arxiv.org/abs/2407.00397v1",
          "size": "2785kb",
          "version": "v1"
        },
        {
          "date": "2025-02-03T16:40:43+00:00",
          "link": "https://arxiv.org/abs/2407.00397v2",
          "size": "937kb",
          "version": "v2"
        },
        {
          "date": "2025-02-10T19:33:03+00:00",
          "link": "https://arxiv.org/abs/2407.00397v3",
          "size": "1155kb",
          "version": "v3"
        },
        {
          "date": "2025-06-06T11:51:23+00:00",
          "link": "https://arxiv.org/abs/2407.00397v4",
          "size": "3074kb",
          "version": "v4"
        },
        {
          "date": "2025-06-11T12:36:31+00:00",
          "link": "https://arxiv.org/abs/2407.00397v5",
          "size": "3074kb",
          "version": "v5"
        },
        {
          "date": "2025-07-16T04:40:32+00:00",
          "link": "https://arxiv.org/abs/2407.00397v6",
          "size": "3074kb",
          "version": "v6"
        }
      ],
      "title": "Learning Time-Varying Multi-Region Brain Communications via Scalable Markovian Gaussian Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.00397",
        "HTML": "https://arxiv.org/html/2407.00397",
        "PDF": "https://arxiv.org/pdf/2407.00397"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for learning brain communications using multi-region neural recordings via Markovian Gaussian Processes. It does not address reinforcement learning or data processing within the RL context."
      },
      "tasks": [
        "Gaussian Processes",
        "State Space Models",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04039",
      "abstract": "The Square Kilometre Array (SKA) Observatory is gearing up the formal construction of its two radio interferometers in Australia and South Africa after the end of design and pre-construction phases. Agile methodologies, the Cloud native Computing technologies and the DevOps software ideas are influencing the design of compute infrastructures that will be key to reduce the operational costs of SKA while improving the control and monitoring of the SKA antennas and ancillary systems, Correlators, HPC facilities or related data centre tiered systems. These tools will likely include advanced power metering technologies and efficient distribution automation and Network Operation Centres (NOC). SKA will become the world's largest radio telescope and is expected to achieve its first science by 2026. To cope with this dimension and complexity, a key part of this distributed Observatory is the overall software control and monitoring system embodied in the Observatory Management and Control (OMC) and the Services Teams that requires specialized Agile Teams to assist in software and cyber infrastructure building using an Agile development environment that includes test automation, Continuous Integration, and Continuous Deployment. To manage such a large and distributed machine, the Agile approach was adopted for the core software package of the SKA Telescope aimed at scheduling observations, controlling their execution, monitoring the telescope status and ensuring scalability and reliability. Here, we report on the ENGAGE SKA ciberinfrastructure prototyping support to the SKA Agile Software Development Life Cycle (SDLC).",
      "authors": [
        "Domingos Barbosa",
        "Diogo Regateiro",
        "Jo\\~ao Paulo Barraca",
        "Dzianis Bartashevich",
        "Marco Bartolini",
        "Matteo di Carlo",
        "Piers Harding",
        "Dalmiro Maia",
        "Bruno Morgado",
        "Domingos Nunes",
        "Bruno Ribeiro",
        "Bruno Coelho",
        "Val\\'erio Ribeiro",
        "Allan K. de Almeida Jr",
        "Timoth\\'ee Vaillant",
        "U\\u{g}ur Yilmaz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T13:01:27+00:00",
          "link": "https://arxiv.org/abs/2502.04039v1",
          "size": "1125kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T22:56:44+00:00",
          "link": "https://arxiv.org/abs/2502.04039v2",
          "size": "624kb",
          "version": "v2"
        }
      ],
      "title": "A Cloud-native Agile approach to cyber platform prototyping and integration for astronomy: the ENGAGE SKA case",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04039",
        "HTML": "https://arxiv.org/html/2502.04039",
        "PDF": "https://arxiv.org/pdf/2502.04039"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the development of a cyber infrastructure for an astronomy project using agile methodologies. It does not discuss reinforcement learning or data processing within an RL context."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.03673",
      "abstract": "Fault-proneness is a measure that indicates the possibility of programming errors occurring within a software system. On the other hand, change-proneness refers to the potential for modifications to be made to the software. Both of these measures are crucial indicators of software maintainability, as they influence internal software metrics such as size, inheritance, and coupling, particularly when numerous changes are made to the system. In the literature, research has predicted change- and fault-proneness using internal software metrics that is almost a decade old. However, given the continuous evolution of software systems, it is essential to revisit and update our understanding of these relationships. Therefore, we have conducted an empirical study to revisit the relationship between internal software metrics and change-proneness, and faultproneness, aiming to provide current and relevant insights. In our study, we identified 25 internal software metrics along with the measures of change-proneness and fault-proneness within the wellknown open-source systems from the Apache and Eclipse ecosystems. We then analyzed the relationships between these metrics using statistical correlation methods. Our results revealed that most of the metrics have little to no correlation with fault-proneness. However, metrics related to inheritance, coupling, and comments showed a moderate to high correlation with change-proneness. These findings will assist developers to minimize the higher correlated software metrics to enhance maintainability in terms of change- and fault-proneness. Additionally, these insights can guide researchers in developing new approaches for predicting changes and faults by incorporating the metrics that have been shown to have stronger correlations.",
      "authors": [
        "Md.Masudur Rahman",
        "Toukir Ahammed and Kazi Sakib"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-23T07:19:41+00:00",
          "link": "https://arxiv.org/abs/2310.03673v1",
          "size": "151kb",
          "version": "v1"
        },
        {
          "date": "2024-06-07T18:19:56+00:00",
          "link": "https://arxiv.org/abs/2310.03673v2",
          "size": "64kb",
          "version": "v2"
        }
      ],
      "title": "Do Internal Software Metrics Have Relationship with Fault-proneness and Change-proneness?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.03673",
        "HTML": "https://arxiv.org/html/2310.03673",
        "PDF": "https://arxiv.org/pdf/2310.03673"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The article explores the relationship between software metrics and software maintainability issues like fault- and change-proneness, with no connection to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.13433",
      "abstract": "Large audio-language models (LALMs), built upon powerful Large Language Models (LLMs), have exhibited remarkable audio comprehension and reasoning capabilities. However, the training of LALMs demands a large corpus of audio-language pairs, which requires substantial costs in both data collection and training resources. In this paper, we propose MATS, an audio-language multimodal LLM designed to handle Multiple Audio task using solely Text-only Supervision. By leveraging pre-trained audio-language alignment models such as CLAP, we develop a text-only training strategy that projects the shared audio-language latent space into LLM latent space, endowing the LLM with audio comprehension capabilities without relying on audio data during training. To further bridge the modality gap between audio and language embeddings within CLAP, we propose the Strongly-related noisy text with audio (Santa) mechanism. Santa maps audio embeddings into CLAP language embedding space while preserving essential information from the audio input. Extensive experiments demonstrate that MATS, despite being trained exclusively on text data, achieves competitive performance compared to recent LALMs trained on large-scale audio-language pairs.",
      "authors": [
        "Wen Wang",
        "Ruibing Hou",
        "Hong Chang",
        "Shiguang Shan and Xilin Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T05:07:56+00:00",
          "link": "https://arxiv.org/abs/2502.13433v1",
          "size": "2201kb",
          "version": "v1"
        },
        {
          "date": "2025-02-20T18:47:24+00:00",
          "link": "https://arxiv.org/abs/2502.13433v2",
          "size": "2201kb",
          "version": "v2"
        }
      ],
      "title": "MATS: An Audio Language Model under Text-only Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13433",
        "HTML": "https://arxiv.org/html/2502.13433",
        "PDF": "https://arxiv.org/pdf/2502.13433"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper presents MATS for audio-language modeling using text-only supervision and focuses on modality alignment, without mentioning or contributing to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.05478",
      "abstract": "Pumps are indispensable for analytical applications and ensure controlled fluid movement. Syringe pumps are among today_s most prevalent liquid delivery systems, especially for high-pressure, stable, low-flow-rate microfluidic applications. Due to moving mechanical parts of the assembly, regular maintenance is essential to ensure reliable operation and flow rates. However, lubrication of the mechanics is easily overlooked because the research focuses on novel analytical applications rather than on the maintenance of pumps. Here, we investigate the lubrication of the syringe pump guide rods with its effect on the flow rate stability after regular pump cleaning from contaminations. The guide rods of syringe pumps were thoroughly cleaned from any lubricant, and the flow rate for specified flowrates between 5 and 30 uL/min was measured, revealing tremendous flow rate fluctuations with a coefficient of variation (CV) value up to 0.34. In contrast, flow rate measurements of syringe pumps with lubricated guide rods show a five-fold smoother flow rate fluctuation depending on the specified flow rate with CV values below 0.07. In summary, we emphasize the awareness of lubricating moving parts of syringe pumps to achieve constant flow rates, minimize wear, and ensure the reliable operation of, for instance, accurate lab-on-a-chip workflows.",
      "authors": [
        "Moritz Leuthner",
        "and Oliver Hayden"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-09T07:37:49+00:00",
          "link": "https://arxiv.org/abs/2310.05478v1",
          "size": "737kb",
          "version": "v1"
        }
      ],
      "title": "Grease the gears for a steady microfluidic flow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.05478",
        "PDF": "https://arxiv.org/pdf/2310.05478"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper discusses syringe pump lubrication and its impact on fluid flow stability, which is unrelated to reinforcement learning or data processing within that domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.07059",
      "abstract": "Federated Continual Learning (FCL) has emerged as a robust solution for collaborative model training in dynamic environments, where data samples are continuously generated and distributed across multiple devices. This survey provides a comprehensive review of FCL, focusing on key challenges such as heterogeneity, model stability, communication overhead, and privacy preservation. We explore various forms of heterogeneity and their impact on model performance. Solutions to non-IID data, resource-constrained platforms, and personalized learning are reviewed in an effort to show the complexities of handling heterogeneous data distributions. Next, we review techniques for ensuring model stability and avoiding catastrophic forgetting, which are critical in non-stationary environments. Privacy-preserving techniques are another aspect of FCL that have been reviewed in this work. This survey has integrated insights from federated learning and continual learning to present strategies for improving the efficacy and scalability of FCL systems, making it applicable to a wide range of real-world scenarios.",
      "authors": [
        "Parisa Hamedi",
        "Roozbeh Razavi-Far",
        "Ehsan Hallaji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T21:51:02+00:00",
          "link": "https://arxiv.org/abs/2502.07059v1",
          "size": "1106kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T00:22:16+00:00",
          "link": "https://arxiv.org/abs/2502.07059v2",
          "size": "842kb",
          "version": "v2"
        }
      ],
      "title": "Federated Continual Learning: Concepts, Challenges, and Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07059",
        "HTML": "https://arxiv.org/html/2502.07059",
        "PDF": "https://arxiv.org/pdf/2502.07059"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "partial",
        "reason": "The survey discusses federated continual learning and reviews solutions for handling heterogeneous data distributions which can be related to RL data processing; however, RL-specific data processing is not the primary focus."
      },
      "tasks": [
        "Continual Learning",
        "Federated Learning",
        "Privacy Preserving",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17237",
      "abstract": "Detecting and tracking multiple unmanned aerial vehicles (UAVs) in thermal infrared video is inherently challenging due to low contrast, environmental noise, and small target sizes. This paper provides a straightforward approach to address multi-UAV tracking in thermal infrared video, leveraging recent advances in detection and tracking. Instead of relying on the well-established YOLOv5 with DeepSORT combination, we present a tracking framework built on YOLOv12 and BoT-SORT, enhanced with tailored training and inference strategies. We evaluate our approach following the 4th Anti-UAV Challenge metrics and reach competitive performance. Notably, we achieved strong results without using contrast enhancement or temporal information fusion to enrich UAV features, highlighting our approach as a \"Strong Baseline\" for multi-UAV tracking tasks. We provide implementation details, in-depth experimental analysis, and a discussion of potential improvements. The code is available at https://github.com/wish44165/YOLOv12-BoT-SORT-ReID .",
      "authors": [
        "Yu-Hsi Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T15:40:18+00:00",
          "link": "https://arxiv.org/abs/2503.17237v1",
          "size": "21252kb",
          "version": "v1"
        },
        {
          "date": "2025-04-07T13:03:35+00:00",
          "link": "https://arxiv.org/abs/2503.17237v2",
          "size": "14118kb",
          "version": "v2"
        }
      ],
      "title": "Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17237",
        "HTML": "https://arxiv.org/html/2503.17237",
        "PDF": "https://arxiv.org/pdf/2503.17237"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "This paper discusses multi-UAV tracking using a specific detection and tracking framework, without any relation to reinforcement learning or its data processing aspects."
      },
      "models": [
        {
          "model_path": "wish44165/YOLOv12-BoT-SORT-ReID",
          "downloads": "373",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wish44165/YOLOv12-BoT-SORT-ReID"
        }
      ],
      "datasets": [
        {
          "dataset_name": "wish44165/StrongBaseline_YOLOv12-BoT-SORT-ReID",
          "downloads": "56",
          "likes": "1",
          "link": "https://huggingface.co/datasets/wish44165/StrongBaseline_YOLOv12-BoT-SORT-ReID"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/wish44165/yolov12-bot-sort-reid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00631",
      "abstract": "Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.",
      "authors": [
        "David Shi",
        "Kevin Joo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T10:22:35+00:00",
          "link": "https://arxiv.org/abs/2507.00631v1",
          "size": "10kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T00:53:41+00:00",
          "link": "https://arxiv.org/abs/2507.00631v2",
          "size": "10kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T01:26:57+00:00",
          "link": "https://arxiv.org/abs/2507.00631v3",
          "size": "10kb",
          "version": "v3"
        },
        {
          "date": "2025-07-04T01:19:50+00:00",
          "link": "https://arxiv.org/abs/2507.00631v4",
          "size": "10kb",
          "version": "v4"
        },
        {
          "date": "2025-07-08T06:04:17+00:00",
          "link": "https://arxiv.org/abs/2507.00631v5",
          "size": "10kb",
          "version": "v5"
        },
        {
          "date": "2025-07-15T22:43:37+00:00",
          "link": "https://arxiv.org/abs/2507.00631v6",
          "size": "10kb",
          "version": "v6"
        }
      ],
      "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00631",
        "HTML": "https://arxiv.org/html/2507.00631",
        "PDF": "https://arxiv.org/pdf/2507.00631"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper proposes a protocol for task delegation under uncertainty, involving a verification game to ensure correctness. It doesn't relate to data processing in reinforcement learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.14394",
      "abstract": "Recent advancements in Large Language Models (LLMs) have transformed code generation from natural language queries. However, despite their extensive knowledge and ability to produce high-quality code, LLMs often struggle with contextual accuracy, particularly in evolving codebases. Current code search and retrieval methods frequently lack robustness in both the quality and contextual relevance of retrieved results, leading to suboptimal code generation. This paper introduces a novel knowledge graph-based approach to improve code search and retrieval leading to better quality of code generation in the context of repository-level tasks. The proposed approach represents code repositories as graphs, capturing structural and relational information for enhanced context-aware code generation. Our framework employs a hybrid approach for code retrieval to improve contextual relevance, track inter-file modular dependencies, generate more robust code and ensure consistency with the existing codebase. We benchmark the proposed approach on the Evolutionary Code Benchmark (EvoCodeBench) dataset, a repository-level code generation benchmark, and demonstrate that our method significantly outperforms the baseline approach. These findings suggest that knowledge graph based code generation could advance robust, context-sensitive coding assistance tools.",
      "authors": [
        "Mihir Athale",
        "Vishal Vaddina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T14:13:59+00:00",
          "link": "https://arxiv.org/abs/2505.14394v1",
          "size": "132kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Graph Based Repository-Level Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14394",
        "HTML": "https://arxiv.org/html/2505.14394",
        "PDF": "https://arxiv.org/pdf/2505.14394"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The paper is centered around code generation using knowledge graphs to improve the contextual accuracy of generated code within evolving codebases, without any mention of reinforcement learning or data processing within the RL context."
      },
      "tasks": [
        "Code Generation",
        "Code Search",
        "Natural Language Queries",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18006",
      "abstract": "Semantic segmentation is commonly used for Oil Spill Detection (OSD) in remote sensing images. However, the limited availability of labelled oil spill samples and class imbalance present significant challenges that can reduce detection accuracy. Furthermore, most existing methods, which rely on convolutional neural networks (CNNs), struggle to detect small oil spill areas due to their limited receptive fields and inability to effectively capture global contextual information. This study explores the potential of State-Space Models (SSMs), particularly Mamba, to overcome these limitations, building on their recent success in vision applications. We propose OSDMamba, the first Mamba-based architecture specifically designed for oil spill detection. OSDMamba leverages Mamba's selective scanning mechanism to effectively expand the model's receptive field while preserving critical details. Moreover, we designed an asymmetric decoder incorporating ConvSSM and deep supervision to strengthen multi-scale feature fusion, thereby enhancing the model's sensitivity to minority class samples. Experimental results show that the proposed OSDMamba achieves state-of-the-art performance, yielding improvements of 8.9% and 11.8% in OSD across two publicly available datasets.",
      "authors": [
        "Shuaiyu Chen",
        "Fu Wang",
        "Peng Ren",
        "Chunbo Luo and Zeyu Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T12:07:44+00:00",
          "link": "https://arxiv.org/abs/2506.18006v1",
          "size": "5113kb",
          "version": "v1"
        }
      ],
      "title": "OSDMamba: Enhancing Oil Spill Detection from Remote Sensing Images Using Selective State Space Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18006",
        "HTML": "https://arxiv.org/html/2506.18006",
        "PDF": "https://arxiv.org/pdf/2506.18006"
      },
      "relevance": {
        "keyword": "RL_data",
        "level": "irrelevant",
        "reason": "The research explores the use of State-Space Models for oil spill detection in remote sensing, which does not involve reinforcement learning or RL-specific data processing."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Optimization and Control (math.OC)",
    "Quantum Physics (quant-ph)",
    "Physics and Society (physics.soc-ph)",
    "Multimedia (cs.MM)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Computer Science and Game Theory (cs.GT)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Image and Video Processing (eess.IV)",
    "Sound (cs.SD)",
    "Performance (cs.PF)",
    "Cellular Automata and Lattice Gases (nlin.CG)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Artificial Intelligence (cs.AI)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Computational Geometry (cs.CG)",
    "Neurons and Cognition (q-bio.NC)",
    "Algebraic Topology (math.AT)",
    "Applications (stat.AP)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Analysis of PDEs (math.AP)",
    "Quantitative Methods (q-bio.QM)",
    "Computational Complexity (cs.CC)",
    "Logic (math.LO)",
    "General Relativity and Quantum Cosmology (gr-qc)",
    "High Energy Physics - Experiment (hep-ex)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "History and Philosophy of Physics (physics.hist-ph)",
    "Astrophysics of Galaxies (astro-ph.GA)",
    "Category Theory (math.CT)",
    "Mathematical Software (cs.MS)",
    "Symbolic Computation (cs.SC)",
    "Biological Physics (physics.bio-ph)",
    "General Topology (math.GN)",
    "High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Probability (math.PR)",
    "Discrete Mathematics (cs.DM)",
    "Information Theory (math.IT)",
    "Mathematical Physics (math.MP)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Computation (stat.CO)",
    "Spectral Theory (math.SP)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Metric Geometry (math.MG)",
    "Combinatorics (math.CO)",
    "Differential Geometry (math.DG)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "General Literature (cs.GL)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Other Statistics (stat.OT)",
    "Functional Analysis (math.FA)",
    "Numerical Analysis (cs.NA)",
    "Multiagent Systems (cs.MA)",
    "Pattern Formation and Solitons (nlin.PS)",
    "Statistics Theory (math.ST)",
    "Hardware Architecture (cs.AR)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Computational Physics (physics.comp-ph)",
    "Software Engineering (cs.SE)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Econometrics (econ.EM)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "Chemical Physics (physics.chem-ph)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Dynamical Systems (math.DS)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Genomics (q-bio.GN)",
    "Numerical Analysis (math.NA)"
  ],
  "prompt": {
    "RL_data": "\nHigh-quality data is crucial for effective reinforcement learning (RL). You are an expert in reinforcement learning and data engineering. I will provide you with a set of arXiv papers. Your task is to analyze each paper and determine its relevance to **data processing in reinforcement learning**.\n\n### **Task Objective**\n\nFor each paper, evaluate whether it makes a technical contribution to **data processing in reinforcement learning**.\n\n1. The paper must be related to **reinforcement learning**, including but not limited to:\n\n   * RL algorithms (e.g., PPO, DQN, etc.)\n   * Topics strongly related to RL (e.g., PRM, Reward Models, etc.)\n\n2. A paper is considered relevant only if it directly addresses **data processing within the RL context**, including but not limited to:\n\n   * Collecting or generating training data for RL agents (e.g., from environments or simulators)\n   * Preprocessing of states, actions, or reward signals\n   * Data filtering, deduplication, or augmentation for RL\n   * Construction or curation of offline RL datasets\n\n### **Relevance Classification Criteria**\n\n**`core`**: The paper makes a **direct and significant contribution** to RL data processing. Examples include novel data preprocessing techniques, curated offline RL datasets, improved sampling strategies, or methods that modify or enhance the quality/usefulness of training data for RL agents.\n\n**`partial`**: The paper **mentions or briefly uses** RL data processing as part of the work but it is **not the main technical contribution**. For example, a paper describing a new RL algorithm that incidentally uses a known dataset or secondary preprocessing steps.\n\n**`irrelevant`**: The paper does not discuss any aspects related to RL data processing.\n\n### **Output Format (strictly follow this JSON structure)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper ID>\",\n      \"answer\": \"core | partial | irrelevant\",\n      \"reason\": \"1-2 sentences explaining the rationale for your classification, citing key content from the abstract or methodology\"\n    }\n    // \u2026additional papers can be added\n  ]\n}\n```\n\n### Example\n\ninput:\n\n```json\n[\n    {\n        \"id\": \"2503.14476\",\n        \"title\": \"DAPO: An Open-Source LLM Reinforcement Learning System at Scale\",\n        \"abstract\": \"Inference scaling empowers LLMs with unprecedented reasoning ability, with reinforcement learning as the core technique to elicit complex reasoning. However, key technical details of state-of-the-art reasoning LLMs are concealed (such as in OpenAI o1 blog and DeepSeek R1 technical report), thus the community still struggles to reproduce their RL training results. We propose the \textbf{D}ecoupled Clip and \textbf{D}ynamic s\textbf{A}mpling \textbf{P}olicy \textbf{O}ptimization (\textbf{DAPO}) algorithm, and fully open-source a state-of-the-art large-scale RL system that achieves 50 points on AIME 2024 using Qwen2.5-32B base model. Unlike previous works that withhold training details, we introduce four key techniques of our algorithm that make large-scale LLM RL a success. In addition, we open-source our training code, which is built on the verl framework, along with a carefully curated and processed dataset. These components of our open-source system enhance reproducibility and support future research in large-scale LLM RL.\"\n    },\n    {\n        \"id\": \"2402.03300\",\n        \"title\": \"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\",\n        \"abstract\": \"Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.\"\n    }\n]\n```\n\noutput:\n```json\n{\n    \"result\": [\n        {\n            \"id\": \"2503.14476\",\n            \"answer\": \"core\",\n            \"reason\": \"The paper introduces DAPO, a novel RL algorithm, and explicitly mentions a carefully curated and processed dataset for large-scale LLM RL training, highlighting significant contributions to data processing and dataset curation in RL.\"\n        },\n        {\n            \"id\": \"2402.03300\",\n            \"answer\": \"core\",\n            \"reason\": \"The paper emphasizes a meticulously engineered data selection pipeline for training a mathematical reasoning language model and proposes a new PPO variant (GRPO), directly addressing data collection/processing and sampling strategies in RL.\"\n        }\n    ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "core": 17,
    "irrelevant": 711,
    "partial": 54
  },
  "arxiv_update_date": "2025-07-17",
  "updated_at": "2025-07-17 10:20:28"
}