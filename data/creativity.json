{
  "data": [
    {
      "id": "2507.15981",
      "abstract": "Many calls for explainable AI (XAI) systems in medicine are tied to a desire for AI accountability--accounting for, mitigating, and ultimately preventing harms from AI systems. Because XAI systems provide human-understandable explanations for their output, they are often viewed as a primary path to prevent harms to patients. However, when harm occurs, laws, policies, and regulations also shape AI accountability by impacting how harmed individuals can obtain recourse. Current approaches to XAI explore physicians' medical and relational needs to counter harms to patients, but there is a need to understand how XAI systems should account for the legal considerations of those impacted. We conduct an analysis of 31 legal cases and reported harms to identify patterns around how AI systems impact patient care. Our findings reflect how patients' medical care relies on a complex web of stakeholders--physicians, state health departments, health insurers, care facilities, among others--and many AI systems deployed across their healthcare delivery negatively impact their care. In response, patients have had no option but to seek legal recourse for harms. We shift the frame from physician-centered to patient-centered accountability approaches by describing how lawyers and technologists need to recognize and address where AI harms happen. We present paths for preventing or countering harm (1) by changing liability structures to reflect the role of many stakeholders in shaping how AI systems impact patient care; and (2) by designing XAI systems that can help advocates, such as legal representatives, who provide critical legal expertise and practically support recourse for patients.",
      "authors": [
        "Gennie Mansi",
        "Mark Riedl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T18:23:52+00:00",
          "link": "https://arxiv.org/abs/2507.15981v1",
          "size": "4733kb",
          "version": "v1"
        }
      ],
      "title": "Implications of Current Litigation on the Design of AI Systems for Healthcare Delivery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15981",
        "HTML": "https://arxiv.org/html/2507.15981v1",
        "PDF": "https://arxiv.org/pdf/2507.15981"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses the legal and accountability aspects of explainable AI in healthcare, focusing on preventing harms and legal recourse. Creativity is not mentioned or relevant to the research focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15996",
      "abstract": "Physicians are--and feel--ethically, professionally, and legally responsible for patient outcomes, buffering patients from harmful AI determinations from medical AI systems. Many have called for explainable AI (XAI) systems to help physicians incorporate medical AI recommendations into their workflows in a way that reduces the potential of harms to patients. While prior work has demonstrated how physicians' legal concerns impact their medical decision making, little work has explored how XAI systems should be designed in light of these concerns. In this study, we conducted interviews with 10 physicians to understand where and how they anticipate errors that may occur with a medical AI system and how these anticipated errors connect to their legal concerns. In our study, physicians anticipated risks associated with using an AI system for patient care, but voiced unknowns around how their legal risk mitigation strategies may change given a new technical system. Based on these findings, we describe the implications for designing XAI systems that can address physicians' legal concerns. Specifically, we identify the need to provide AI recommendations alongside contextual information that guides their risk mitigation strategies, including how non-legally related aspects of their systems, such as medical documentation and auditing requests, might be incorporated into a legal case.",
      "authors": [
        "Gennie Mansi",
        "Mark Riedl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T18:31:36+00:00",
          "link": "https://arxiv.org/abs/2507.15996v1",
          "size": "3095kb",
          "version": "v1"
        }
      ],
      "title": "Understanding the Impact of Physicians' Legal Considerations on XAI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15996",
        "HTML": "https://arxiv.org/html/2507.15996v1",
        "PDF": "https://arxiv.org/pdf/2507.15996"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper explores the legal concerns of physicians related to XAI systems in healthcare settings. It does not address creativity-related themes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16013",
      "abstract": "Feedback plays a central role in learning, yet pre-service teachers' engagement with feedback depends not only on its quality but also on their perception of the feedback content and source. Large Language Models (LLMs) are increasingly used to provide educational feedback; however, negative perceptions may limit their practical use, and little is known about how pre-service teachers' perceptions and behavioral responses differ by feedback source. This study investigates how the perceived source of feedback - LLM, expert, or peer - influences feedback perception and uptake, and whether recognition accuracy and feedback quality moderate these effects. In a randomized experiment with 273 pre-service teachers, participants received written feedback on a mathematics learning goal, identified its source, rated feedback perceptions across five dimensions (fairness, usefulness, acceptance, willingness to improve, positive and negative affect), and revised the learning goal according to the feedback (i.e. feedback uptake). Results revealed that LLM-generated feedback received the highest ratings in fairness and usefulness, leading to the highest uptake (52%). Recognition accuracy significantly moderated the effect of feedback source on perception, with particularly positive evaluations when LLM feedback was falsely ascribed to experts. Higher-quality feedback was consistently assigned to experts, indicating an expertise heuristic in source judgments. Regression analysis showed that only feedback quality significantly predicted feedback uptake. Findings highlight the need to address source-related biases and promote feedback and AI literacy in teacher education.",
      "authors": [
        "Lucas Jasper Jacobsen",
        "Ute Mertens",
        "Thorben Jansen",
        "Kira Elena Weber"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T19:24:40+00:00",
          "link": "https://arxiv.org/abs/2507.16013v1",
          "size": "707kb",
          "version": "v1"
        }
      ],
      "title": "AI, Expert or Peer? -- Examining the Impact of Perceived Feedback Source on Pre-Service Teachers Feedback Perception and Uptake",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16013",
        "PDF": "https://arxiv.org/pdf/2507.16013"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While creativity is not a primary focus, the study on how pre-service teachers perceive feedback from different sources (LLMs, experts, peers) may relate to educational settings where creativity in teaching practices could be indirectly impacted by how feedback influences teaching development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16033",
      "abstract": "Understanding what constitutes safety in AI-generated content is complex. While developers often rely on predefined taxonomies, real-world safety judgments also involve personal, social, and cultural perceptions of harm. This paper examines how annotators evaluate the safety of AI-generated images, focusing on the qualitative reasoning behind their judgments. Analyzing 5,372 open-ended comments, we find that annotators consistently invoke moral, emotional, and contextual reasoning that extends beyond structured safety categories. Many reflect on potential harm to others more than to themselves, grounding their judgments in lived experience, collective risk, and sociocultural awareness. Beyond individual perceptions, we also find that the structure of the task itself -- including annotation guidelines -- shapes how annotators interpret and express harm. Guidelines influence not only which images are flagged, but also the moral judgment behind the justifications. Annotators frequently cite factors such as image quality, visual distortion, and mismatches between prompt and output as contributing to perceived harm dimensions, which are often overlooked in standard evaluation frameworks. Our findings reveal that existing safety pipelines miss critical forms of reasoning that annotators bring to the task. We argue for evaluation designs that scaffold moral reflection, differentiate types of harm, and make space for subjective, context-sensitive interpretations of AI-generated content.",
      "authors": [
        "Ding Wang",
        "Mark D\\'iaz",
        "Charvi Rastogi",
        "Aida Davani",
        "Vinodkumar Prabhakaran",
        "Pushkar Mishra",
        "Roma Patel",
        "Alicia Parrish",
        "Zoe Ashwood",
        "Michela Paganini",
        "Tian Huey Teh",
        "Verena Rieser",
        "Lora Aroyo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T19:53:29+00:00",
          "link": "https://arxiv.org/abs/2507.16033v1",
          "size": "601kb",
          "version": "v1"
        }
      ],
      "title": "\"Just a strange pic\": Evaluating 'safety' in GenAI Image safety annotation tasks from diverse annotators' perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16033",
        "HTML": "https://arxiv.org/html/2507.16033v1",
        "PDF": "https://arxiv.org/pdf/2507.16033"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating safety in AI-generated images from diverse perspectives, emphasizing moral and sociocultural reasoning rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16073",
      "abstract": "Preparing datasets -- a critical phase known as data wrangling -- constitutes the dominant phase of data science development, consuming upwards of 80% of the total project time. This phase encompasses a myriad of tasks: parsing data, restructuring it for analysis, repairing inaccuracies, merging sources, eliminating duplicates, and ensuring overall data integrity. Traditional approaches, typically through manual coding in languages such as Python or using spreadsheets, are not only laborious but also error-prone. These issues range from missing entries and formatting inconsistencies to data type inaccuracies, all of which can affect the quality of downstream tasks if not properly corrected. To address these challenges, we present Buckaroo, a visualization system to highlight discrepancies in data and enable on-the-spot corrections through direct manipulations of visual objects. Buckaroo (1) automatically finds \"interesting\" data groups that exhibit anomalies compared to the rest of the groups and recommends them for inspection; (2) suggests wrangling actions that the user can choose to repair the anomalies; and (3) allows users to visually manipulate their data by displaying the effects of their wrangling actions and offering the ability to undo or redo these actions, which supports the iterative nature of data wrangling. A video companion is available at https://youtu.be/iXdCYbvpQVE",
      "authors": [
        "Annabelle Warner",
        "Andrew McNutt",
        "Paul Rosen",
        "El Kindi Rezig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T21:20:25+00:00",
          "link": "https://arxiv.org/abs/2507.16073v1",
          "size": "1223kb",
          "version": "v1"
        }
      ],
      "title": "Buckaroo: A Direct Manipulation Visual Data Wrangler",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16073",
        "HTML": "https://arxiv.org/html/2507.16073v1",
        "PDF": "https://arxiv.org/pdf/2507.16073"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper is about data wrangling through visualization for improving data quality and integrity, which does not relate to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16074",
      "abstract": "In the last decade, researchers have increasingly explored using biosensing technologies for music-based affective regulation and stress management interventions in laboratory and real-world settings. These systems -- including interactive music applications, brain-computer interfaces, and biofeedback devices -- aim to provide engaging, personalized experiences that improve therapeutic outcomes. In this scoping and mapping review, we summarize and synthesize systematic reviews and empirical research on biosensing systems with potential applications in music-based affective regulation and stress management, identify gaps in the literature, and highlight promising areas for future research. We identified 28 studies involving 646 participants, with most systems utilizing prerecorded music, wearable cardiorespiratory sensors, or desktop interfaces. We categorize these systems based on their biosensing modalities, music types, computational models for affect or stress detection and music prediction, and biofeedback mechanisms. Our findings highlight the promising potential of these systems and suggest future directions, such as integrating multimodal biosensing, exploring therapeutic mechanisms of music, leveraging generative artificial intelligence for personalized music interventions, and addressing methodological, data privacy, and user control concerns.",
      "authors": [
        "Natasha Yamane",
        "Varun Mishra",
        "Matthew S. Goodwin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T21:21:48+00:00",
          "link": "https://arxiv.org/abs/2507.16074v1",
          "size": "819kb",
          "version": "v1"
        }
      ],
      "title": "Toward music-based stress management: Contemporary biosensing systems for affective regulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16074",
        "PDF": "https://arxiv.org/pdf/2507.16074"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses biosensing systems used in music-based stress management, which could involve creative processes related to music generation and personalized interventions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16117",
      "abstract": "Biomedical data harmonization is essential for enabling exploratory analyses and meta-studies, but the process of schema matching - identifying semantic correspondences between elements of disparate datasets (schemas) - remains a labor-intensive and error-prone task. Even state-of-the-art automated methods often yield low accuracy when applied to biomedical schemas due to the large number of attributes and nuanced semantic differences between them. We present BDIViz, a novel visual analytics system designed to streamline the schema matching process for biomedical data. Through formative studies with domain experts, we identified key requirements for an effective solution and developed interactive visualization techniques that address both scalability challenges and semantic ambiguity. BDIViz employs an ensemble approach that combines multiple matching methods with LLM-based validation, summarizes matches through interactive heatmaps, and provides coordinated views that enable users to quickly compare attributes and their values. Our method-agnostic design allows the system to integrate various schema matching algorithms and adapt to application-specific needs. Through two biomedical case studies and a within-subject user study with domain experts, we demonstrate that BDIViz significantly improves matching accuracy while reducing cognitive load and curation time compared to baseline approaches.",
      "authors": [
        "Eden Wu",
        "Dishita G Turakhia",
        "Guande Wu",
        "Christos Koutras",
        "Sarah Keegan",
        "Wenke Liu",
        "Beata Szeitz",
        "David Fenyo",
        "Cl\\'audio T. Silva",
        "and Juliana Freire"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T00:10:55+00:00",
          "link": "https://arxiv.org/abs/2507.16117v1",
          "size": "24303kb",
          "version": "v1"
        }
      ],
      "title": "BDIViz: An Interactive Visualization System for Biomedical Schema Matching with LLM-Powered Validation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16117",
        "HTML": "https://arxiv.org/html/2507.16117v1",
        "PDF": "https://arxiv.org/pdf/2507.16117"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper presents a visualization system for schema matching in biomedical data, focusing on improving efficiency and accuracy without addressing creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16207",
      "abstract": "As text-to-image generative models rapidly improve, AI researchers are making significant advances in developing domain-specific models capable of generating complex medical imagery from text prompts. Despite this, these technical advancements have overlooked whether and how medical professionals would benefit from and use text-to-image generative AI (GenAI) in practice. By developing domain-specific GenAI without involving stakeholders, we risk the potential of building models that are either not useful or even more harmful than helpful. In this paper, we adopt a human-centered approach to responsible model development by involving stakeholders in evaluating and reflecting on the promises, risks, and challenges of a novel text-to-CT Scan GenAI model. Through exploratory model prompting activities, we uncover the perspectives of medical students, radiology trainees, and radiologists on the role that text-to-CT Scan GenAI can play across medical education, training, and practice. This human-centered approach additionally enabled us to surface technical challenges and domain-specific risks of generating synthetic medical images. We conclude by reflecting on the implications of medical text-to-image GenAI.",
      "authors": [
        "Katelyn Morrison",
        "Arpit Mathur",
        "Aidan Bradshaw",
        "Tom Wartmann",
        "Steven Lundi",
        "Afrooz Zandifar",
        "Weichang Dai",
        "Kayhan Batmanghelich",
        "Motahhare Eslami",
        "Adam Perer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T03:53:25+00:00",
          "link": "https://arxiv.org/abs/2507.16207v1",
          "size": "3459kb",
          "version": "v1"
        }
      ],
      "title": "A Human-Centered Approach to Identifying Promises, Risks, & Challenges of Text-to-Image Generative AI in Radiology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16207",
        "HTML": "https://arxiv.org/html/2507.16207v1",
        "PDF": "https://arxiv.org/pdf/2507.16207"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While the main focus is on the human-centered approach to GenAI in radiology, the involvement of stakeholders and the exploration of new roles for generative AI suggest a potential secondary theme of creativity in using AI tools for innovative solutions in medical contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16258",
      "abstract": "Autonomous mobility systems increasingly operate in environments shared with animals, from urban pets to wildlife. However, their design has largely focused on human interaction, with limited understanding of how non-human species perceive, respond to, or are affected by these systems. Motivated by research in Animal-Computer Interaction (ACI) and more-than-human design, this study investigates animal interactions with autonomous mobility through a multi-method approach combining a scoping review (45 articles), online ethnography (39 YouTube videos and 11 Reddit discussions), and expert interviews (8 participants). Our analysis surfaces five key areas of concern: Physical Impact (e.g., collisions, failures to detect), Behavioural Effects (e.g., avoidance, stress), Accessibility Concerns (particularly for service animals), Ethics and Regulations, and Urban Disturbance. We conclude with design and policy directions aimed at supporting multispecies coexistence in the age of autonomous systems. This work underscores the importance of incorporating non-human perspectives to ensure safer, more inclusive futures for all species.",
      "authors": [
        "Tram Thi Minh Tran",
        "Xinyan Yu",
        "Marius Hoggenmueller",
        "Callum Paker",
        "Paul Schmitt",
        "Julie Stephany Berrio Perez",
        "Stewart Worrall",
        "Martin Tomitsch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T06:15:56+00:00",
          "link": "https://arxiv.org/abs/2507.16258v1",
          "size": "197kb",
          "version": "v1"
        }
      ],
      "title": "Animal Interaction with Autonomous Mobility Systems: Designing for Multi-Species Coexistence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16258",
        "HTML": "https://arxiv.org/html/2507.16258v1",
        "PDF": "https://arxiv.org/pdf/2507.16258"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper explores the interaction between animals and autonomous mobility systems, with no explicit connection to creativity in its study or conclusions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16466",
      "abstract": "In data-driven storytelling contexts such as data journalism and data videos, data visualizations are often presented alongside real-world imagery to support narrative context. However, these visualizations and contextual images typically remain separated, limiting their combined narrative expressiveness and engagement. Achieving this is challenging due to the need for fine-grained alignment and creative ideation. To address this, we present SceneLoom, a Vision-Language Model (VLM)-powered system that facilitates the coordination of data visualization with real-world imagery based on narrative intents. Through a formative study, we investigated the design space of coordination relationships between data visualization and real-world scenes from the perspectives of visual alignment and semantic coherence. Guided by the derived design considerations, SceneLoom leverages VLMs to extract visual and semantic features from scene images and data visualization, and perform design mapping through a reasoning process that incorporates spatial organization, shape similarity, layout consistency, and semantic binding. The system generates a set of contextually expressive, image-driven design alternatives that achieve coherent alignments across visual, semantic, and data dimensions. Users can explore these alternatives, select preferred mappings, and further refine the design through interactive adjustments and animated transitions to support expressive data communication. A user study and an example gallery validate SceneLoom's effectiveness in inspiring creative design and facilitating design externalization.",
      "authors": [
        "Lin Gao",
        "Leixian Shen",
        "Yuheng Zhao",
        "Jiexiang Lan",
        "Huamin Qu and Siming Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T11:13:33+00:00",
          "link": "https://arxiv.org/abs/2507.16466v1",
          "size": "19107kb",
          "version": "v1"
        }
      ],
      "title": "SceneLoom: Communicating Data with Scene Context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16466",
        "HTML": "https://arxiv.org/html/2507.16466v1",
        "PDF": "https://arxiv.org/pdf/2507.16466"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper introduces SceneLoom, which facilitates creative data communication through the integration of data visualization with real-world imagery. It centers on supporting creative design processes in data-driven storytelling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16542",
      "abstract": "In exhibition hybrid spaces, scale consistency between real and virtual spaces is crucial for user immersion. However, there is currently a lack of systematic research to determine appropriate virtual-to-real mapping ratios. This study developed an immersive interaction system based on Intel 3D Athlete Tracking body mapping technology. Two experiments investigated the impact of virtual space and virtual avatar scale on immersion. Experiment 1 investigated 30 participants' preferences for virtual space scale, while Experiment 2 tested the effect of 6 different virtual avatar sizes (25%-150%) on immersion. A 5-point Likert scale was used to assess immersion, followed by analysis of variance and Tukey HSD post-hoc tests. Experiment 1 showed that participants preferred a virtual space ratio of 130% (mean 127.29%, SD 8.55%). Experiment 2 found that virtual avatar sizes within the 75%-100% range produced optimal immersion (p < 0.05). Immersion decreased significantly when virtual avatar sizes deviated from users' actual height (below 50% or above 125%). Participants were more sensitive to size changes in the 25%-75% range, while perception was weaker for changes in the 75%-100% range. Virtual environments slightly larger than real space (130%) and virtual avatars slightly smaller than users (75%-100%) optimize user immersion. These findings have been applied in the Intel Global Trade Center exhibition hall, demonstrating actionable insights for designing hybrid spaces that enhance immersion and coherence.",
      "authors": [
        "Qiong Wu",
        "Yan Dong",
        "Zipeng Zhang",
        "Ruochen Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T12:51:30+00:00",
          "link": "https://arxiv.org/abs/2507.16542v1",
          "size": "1392kb",
          "version": "v1"
        }
      ],
      "title": "The Effect of Scale Consistency between Real and Virtual Spaces on Immersion in Exhibition Hybrid Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16542",
        "PDF": "https://arxiv.org/pdf/2507.16542"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper examines scale consistency in hybrid exhibition spaces and its effect on user immersion, focusing on design elements related to immersion rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16562",
      "abstract": "In this paper, we present the findings of a user study that evaluated the social acceptance of eXtended Reality (XR) agent technology, focusing on a remotely accessible, web-based XR training system developed for journalists. This system involves user interaction with a virtual avatar, enabled by a modular toolkit. The interactions are designed to provide tailored training for journalists in digital-remote settings, especially for sensitive or dangerous scenarios, without requiring specialized end-user equipment like headsets. Our research adapts and extends the Almere model, representing social acceptance through existing attributes such as perceived ease of use and perceived usefulness, along with added ones like dependability and security in the user-agent interaction. The XR agent was tested through a controlled experiment in a real-world setting, with data collected on users' perceptions. Our findings, based on quantitative and qualitative measurements involving questionnaires, contribute to the understanding of user perceptions and acceptance of XR agent solutions within a specific social context, while also identifying areas for the improvement of XR systems.",
      "authors": [
        "Megha Quamara",
        "Viktor Schmuck",
        "Cristina Iani",
        "Axel Primavesi",
        "Alexander Plaum",
        "Luca Vigano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T13:14:05+00:00",
          "link": "https://arxiv.org/abs/2507.16562v1",
          "size": "4823kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Social Acceptance of eXtended Reality (XR) Agent Technology: A User Study (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16562",
        "HTML": "https://arxiv.org/html/2507.16562v1",
        "PDF": "https://arxiv.org/pdf/2507.16562"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the social acceptance of XR agent technology and does not address creativity as a research theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16563",
      "abstract": "Multi-faceted data visualization typically involves several dedicated views. To create a comprehensive understanding of the data, users have to mentally integrate the information from the different views. This integration is hindered by context switches between views and usually requires interactive methods such as brushing and linking. Animated transitions have also been shown to be able to mediate context switches and improve understanding. Yet, most existing animated transitions consider only basic views showing the same data facet. In this work, we study how the gap between node-link diagrams, showing graph structure, and parallel coordinates plots, showing multivariate attributes, can be narrowed via smooth animated transitions. Based on two design goals (traceability and swiftness), we outline a partial design space including several design options. These inform the implementation of two alternative transition variants: a basic variant with plain interpolation and an advanced variant that uses our design space and accepted animation techniques, including staging and staggering. In a preliminary study, we asked seven participants for qualitative feedback. We found that the swiftness of the basic variant is preferred, while the traceability of data items is better with the slower advanced variant.",
      "authors": [
        "Abdulhaq Adetunji Salako and Hannes Hagen and Christian Tominski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T13:14:22+00:00",
          "link": "https://arxiv.org/abs/2507.16563v1",
          "size": "4017kb",
          "version": "v1"
        }
      ],
      "title": "Animated Transition between Node-Link and Parallel Coordinates Visualizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16563",
        "HTML": "https://arxiv.org/html/2507.16563v1",
        "PDF": "https://arxiv.org/pdf/2507.16563"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses animated transitions in data visualization which can be related to enhancing the creative understanding and integration of data, making creativity a secondary theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16586",
      "abstract": "Computer-Aided Engineering (CAE) enables simulation experts to optimize complex models, but faces challenges in user experience (UX) that limit efficiency and accessibility. While artificial intelligence (AI) has demonstrated potential to enhance CAE processes, research integrating these fields with a focus on UX remains fragmented. This paper presents a multivocal literature review (MLR) examining how AI enhances UX in CAE software across both academic research and industry implementations. Our analysis reveals significant gaps between academic explorations and industry applications, with companies actively implementing LLMs, adaptive UIs, and recommender systems while academic research focuses primarily on technical capabilities without UX validation. Key findings demonstrate opportunities in AI-powered guidance, adaptive interfaces, and workflow automation that remain underexplored in current research. By mapping the intersection of these domains, this study provides a foundation for future work to address the identified research gaps and advance the integration of AI to improve CAE user experience.",
      "authors": [
        "Choro Ulan Uulu",
        "Mikhail Kulyabin",
        "Layan Etaiwi",
        "Nuno Miguel Martins Pacheco",
        "Jan Joosten",
        "Kerstin R\\\"ose",
        "Filippos Petridis",
        "Jan Bosch",
        "Helena Holmstr\\\"om Olsson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T13:39:45+00:00",
          "link": "https://arxiv.org/abs/2507.16586v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "AI for Better UX in Computer-Aided Engineering: Is Academia Catching Up with Industry Demands? A Multivocal Literature Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16586",
        "HTML": "https://arxiv.org/html/2507.16586v1",
        "PDF": "https://arxiv.org/pdf/2507.16586"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper examines the integration of AI into CAE software for better UX, focusing on efficiency and accessibility rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16735",
      "abstract": "Asthma-related deaths in the UK are the highest in Europe, and only 30% of patients access basic care. There is a need for alternative approaches to reaching people with asthma in order to provide health education, self-management support and bridges to care. Automated conversational agents (specifically, mobile chatbots) present opportunities for providing alternative and individually tailored access to health education, self-management support and risk self-assessment. But would patients engage with a chatbot, and what factors influence engagement? We present results from a patient survey (N=1257) devised by a team of asthma clinicians, patients, and technology developers, conducted to identify optimal factors for efficacy, value and engagement for a chatbot. Results indicate that most adults with asthma (53%) are interested in using a chatbot and the patients most likely to do so are those who believe their asthma is more serious and who are less confident about self-management. Results also indicate enthusiasm for 24/7 access, personalisation, and for WhatsApp as the preferred access method (compared to app, voice assistant, SMS or website). Obstacles to uptake include security/privacy concerns and skepticism of technological capabilities. We present detailed findings and consolidate these into 7 recommendations for developers for optimising efficacy of chatbot-based health support.",
      "authors": [
        "Laura Moradbakhti",
        "Dorian Peters",
        "Jennifer K. Quint",
        "Bj\\\"orn Schuller",
        "Darren Cook",
        "Rafael A. Calvo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T16:21:00+00:00",
          "link": "https://arxiv.org/abs/2507.16735v1",
          "size": "734kb",
          "version": "v1"
        }
      ],
      "title": "AI-enhanced conversational agents for personalized asthma support Factors for engagement, value and efficacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16735",
        "PDF": "https://arxiv.org/pdf/2507.16735"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper deals with AI-enhanced conversational agents for asthma support and does not involve creativity as a theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15885",
      "abstract": "Large language models have paved the way to powerful and flexible AI agents, assisting humans by increasingly integrating into their daily life. This flexibility, potential, and growing adoption demands a holistic and cross-disciplinary approach to developing, monitoring and discussing the capabilities required for agent-driven user experiences. However, current guidance on human-centered AI agent development is scattered: UX heuristics focus on interface behaviors, engineering taxonomies describe internal pipelines, and ethics checklists address high-level governance. There is no concise, user-facing vocabulary that tells teams what an agent should fundamentally be able to do. We introduce ADEPTS, a capability framework defining a set of core user-facing capabilities to provide unified guidance around the development of AI agents. ADEPTS is based on six principles for human-centered agent design, that express the minimal, user-facing capabilities an AI agent should demonstrate to be understandable, controllable and trustworthy in everyday use. ADEPTS complements existing frameworks and taxonomies; differently from them, it sits at the interface between technical and experience development. By presenting ADEPTS, we aim to condense complex AI-UX requirements into a compact framework that is actionable guidance for AI researchers, designers, engineers, and policy reviewers alike. We believe ADEPTS has the potential of accelerating the improvement of user-relevant agent capabilities, of easing the design of experiences that take advantage of those capabilities, and of providing a shared language to track and discuss progress around the development of AI agents.",
      "authors": [
        "Pierluca D'Oro",
        "Caley Drooff",
        "Joy Chen",
        "Joseph Tighe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:27:40+00:00",
          "link": "https://arxiv.org/abs/2507.15885v1",
          "size": "1749kb",
          "version": "v1"
        }
      ],
      "title": "ADEPTS: A Capability Framework for Human-Centered Agent Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15885",
        "HTML": "https://arxiv.org/html/2507.15885v1",
        "PDF": "https://arxiv.org/pdf/2507.15885"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on the ADEPTS framework for human-centered AI agent design, emphasizing user-facing capabilities for AI agents. It does not address creativity as a primary or secondary theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15997",
      "abstract": "The increasing adoption of differential privacy (DP) leads to public-facing DP deployments by both government agencies and companies. However, real-world DP deployments often do not fully disclose their privacy guarantees, which vary greatly between deployments. Failure to disclose certain DP parameters can lead to misunderstandings about the strength of the privacy guarantee, undermining the trust in DP. In this work, we seek to inform future standards for communicating the privacy guarantees of DP deployments. Based on semi-structured interviews with 12 DP experts, we identify important DP parameters necessary to comprehensively communicate DP guarantees, and describe why and how they should be disclosed. Based on expert recommendations, we design an initial privacy label for DP to comprehensively communicate privacy guarantees in a standardized format.",
      "authors": [
        "Onyinye Dibia",
        "Mengyi Lu",
        "Prianka Bhattacharjee",
        "Joseph P. Near",
        "Yuanyuan Feng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T18:32:04+00:00",
          "link": "https://arxiv.org/abs/2507.15997v1",
          "size": "651kb",
          "version": "v1"
        }
      ],
      "title": "\"We Need a Standard\": Toward an Expert-Informed Privacy Label for Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15997",
        "HTML": "https://arxiv.org/html/2507.15997v1",
        "PDF": "https://arxiv.org/pdf/2507.15997"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper deals with privacy standards for differential privacy implementations and does not address creativity or related concepts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16130",
      "abstract": "People with disabilities (PwD) experience disproportionately high levels of discrimination and hate online, particularly in India, where entrenched stigma and limited resources intensify these challenges. Large language models (LLMs) are increasingly used to identify and mitigate online hate, yet most research on online ableism focuses on Western audiences with Western AI models. Are these models adequately equipped to recognize ableist harm in non-Western places like India? Do localized, Indic language models perform better? To investigate, we adopted and translated a publicly available ableist speech dataset to Hindi, and prompted eight LLMs--four developed in the U.S. (GPT-4, Gemini, Claude, Llama) and four in India (Krutrim, Nanda, Gajendra, Airavata)--to score and explain ableism. In parallel, we recruited 175 PwD from both the U.S. and India to perform the same task, revealing stark differences between groups. Western LLMs consistently overestimated ableist harm, while Indic LLMs underestimated it. Even more concerning, all LLMs were more tolerant of ableism when it was expressed in Hindi and asserted Western framings of ableist harm. In contrast, Indian PwD interpreted harm through intention, relationality, and resilience--emphasizing a desire to inform and educate perpetrators. This work provides groundwork for global, inclusive standards of ableism, demonstrating the need to center local disability experiences in the design and evaluation of AI systems.",
      "authors": [
        "Mahika Phutane",
        "Aditya Vashistha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T00:51:41+00:00",
          "link": "https://arxiv.org/abs/2507.16130v1",
          "size": "705kb",
          "version": "v1"
        }
      ],
      "title": "Disability Across Cultures: A Human-Centered Audit of Ableism in Western and Indic LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16130",
        "HTML": "https://arxiv.org/html/2507.16130v1",
        "PDF": "https://arxiv.org/pdf/2507.16130"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This research investigates ableism detection in language models, centering on discrimination and cultural interpretations, not on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16184",
      "abstract": "We report the discovery of a structural convergence across four influential theories of mind: Kahneman's dual-system theory, Friston's predictive processing, Minsky's society of mind, and Clark's extended mind-emerging unintentionally within a practical AI agent architecture called Agentic Flow. Designed to address limitations in large language models (LLMs), Agentic Flow comprises five interdependent modules such as Retrieval, Cognition, Control, Memory, and Action arranged in a recurrent cognitive loop. Although originally inspired only by Minsky and Clark, the system's structure retrospectively aligns with computational motifs found in all four theories, including predictive modeling, associative recall, and error-sensitive control.\n  To assess this convergence, we conducted comparative experiments with baseline LLM agents on multi-step reasoning tasks. The structured agent achieved 95.8% task success and exhibited strong constraint adherence, while the baseline system succeeded 62.3% of the time. These results were not aimed at proving superiority, but at illustrating how theoretical structures may emerge through practical design choices rather than top-down theory.\n  We introduce PEACE as a descriptive meta-architecture that captures design-level regularities observed in Agentic Flow. Not intended as a new theory, PEACE provides a shared vocabulary for understanding architectures shaped by real-world implementation demands. This paper should be read as a position paper - an exploratory reflection on how implementation can surface latent structural echoes of cognitive theory, without asserting theoretical unification.",
      "authors": [
        "Myung Ho Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T02:54:45+00:00",
          "link": "https://arxiv.org/abs/2507.16184v1",
          "size": "872kb",
          "version": "v1"
        }
      ],
      "title": "Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16184",
        "PDF": "https://arxiv.org/pdf/2507.16184"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses the structural convergence of cognitive theories and an AI agent architecture without a specific focus on creativity as a theme in its analysis or application."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16229",
      "abstract": "The integration of voice-based AI agents in healthcare presents a transformative opportunity to bridge economic and accessibility gaps in digital health delivery. This paper explores the role of large language model (LLM)-powered voice assistants in enhancing preventive care and continuous patient monitoring, particularly in underserved populations. Drawing insights from the development and pilot study of Agent PULSE (Patient Understanding and Liaison Support Engine) -- a collaborative initiative between IBM Research, Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an economic model demonstrating how AI agents can provide cost-effective healthcare services where human intervention is economically unfeasible. Our pilot study with 33 inflammatory bowel disease patients revealed that 70\\% expressed acceptance of AI-driven monitoring, with 37\\% preferring it over traditional modalities. Technical challenges, including real-time conversational AI processing, integration with healthcare systems, and privacy compliance, are analyzed alongside policy considerations surrounding regulation, bias mitigation, and patient autonomy. Our findings suggest that AI-driven voice agents not only enhance healthcare scalability and efficiency but also improve patient engagement and accessibility. For healthcare executives, our cost-utility analysis demonstrates huge potential savings for routine monitoring tasks, while technologists can leverage our framework to prioritize improvements yielding the highest patient impact. By addressing current limitations and aligning AI development with ethical and regulatory frameworks, voice-based AI agents can serve as a critical entry point for equitable, sustainable digital healthcare solutions.",
      "authors": [
        "Bo Wen",
        "Chen Wang",
        "Qiwei Han",
        "Raquel Norel",
        "Julia Liu",
        "Thaddeus Stappenbeck",
        "Jeffrey L. Rogers"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T05:01:06+00:00",
          "link": "https://arxiv.org/abs/2507.16229v1",
          "size": "1117kb",
          "version": "v1"
        }
      ],
      "title": "Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16229",
        "HTML": "https://arxiv.org/html/2507.16229v1",
        "PDF": "https://arxiv.org/pdf/2507.16229"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on the integration of voice-based AI agents in healthcare delivery, highlighting economic and accessibility impacts, without direct investigation into creativity-related topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16247",
      "abstract": "Early large-scale audio datasets, such as LibriSpeech, were built with hundreds of individual contributors whose voices were instrumental in the development of speech technologies, including audiobooks and voice assistants. Yet, a decade later, these same contributions have exposed voice actors to a range of risks. While existing ethical frameworks emphasize Consent, Credit, and Compensation (C3), they do not adequately address the emergent risks involving vocal identities that are increasingly decoupled from context, authorship, and control. Drawing on qualitative interviews with 20 professional voice actors, this paper reveals how the synthetic replication of voice without enforceable constraints exposes individuals to a range of threats. Beyond reputational harm, such as re-purposing voice data in erotic content, offensive political messaging, and meme culture, we document concerns about accountability breakdowns when their voice is leveraged to clone voices that are deployed in high-stakes scenarios such as financial fraud, misinformation campaigns, or impersonation scams. In such cases, actors face social and legal fallout without recourse, while very few of them have a legal representative or union protection. To make sense of these shifting dynamics, we introduce the PRAC3 framework, an expansion of C3 that foregrounds Privacy, Reputation, Accountability, Consent, Credit, and Compensation as interdependent pillars of data used in the synthetic voice economy. This framework captures how privacy risks are amplified through non-consensual training, how reputational harm arises from decontextualized deployment, and how accountability can be reimagined AI Data ecosystems. We argue that voice, as both a biometric identifier and creative labor, demands governance models that restore creator agency, ensure traceability, and establish enforceable boundaries for ethical reuse.",
      "authors": [
        "Tanusree Sharma",
        "Yihao Zhou",
        "Visar Berisha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T05:39:39+00:00",
          "link": "https://arxiv.org/abs/2507.16247v1",
          "size": "1431kb",
          "version": "v1"
        }
      ],
      "title": "PRAC3 (Privacy, Reputation, Accountability, Consent, Credit, Compensation): Long Tailed Risks of Voice Actors in AI Data-Economy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16247",
        "HTML": "https://arxiv.org/html/2507.16247v1",
        "PDF": "https://arxiv.org/pdf/2507.16247"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper addresses the creative labor aspect through the lens of voice actors and ethical challenges in the AI data-economy, which touches upon creativity in terms of voice as a creative work, but the primary focus is on ethical considerations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16298",
      "abstract": "WhatsApp tiplines, first launched in 2019 to combat misinformation, enable users to interact with fact-checkers to verify misleading content. This study analyzes 580 unique claims (tips) from 451 users, covering both high-resource languages (English, Hindi) and a low-resource language (Telugu) during the 2021 Indian assembly elections using a mixed-method approach. We categorize the claims into three categories, election, COVID-19, and others, and observe variations across languages. We compare content similarity through frequent word analysis and clustering of neural sentence embeddings. We also investigate user overlap across languages and fact-checking organizations. We measure the average time required to debunk claims and inform tipline users. Results reveal similarities in claims across languages, with some users submitting tips in multiple languages to the same fact-checkers. Fact-checkers generally require a couple of days to debunk a new claim and share the results with users. Notably, no user submits claims to multiple fact-checking organizations, indicating that each organization maintains a unique audience. We provide practical recommendations for using tiplines during elections with ethical consideration of users' information.",
      "authors": [
        "Gautam Kishore Shahi",
        "Scot A. Hale"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T07:35:42+00:00",
          "link": "https://arxiv.org/abs/2507.16298v1",
          "size": "12525kb",
          "version": "v1"
        }
      ],
      "title": "WhatsApp Tiplines and Multilingual Claims in the 2021 Indian Assembly Elections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16298",
        "HTML": "https://arxiv.org/html/2507.16298v1",
        "PDF": "https://arxiv.org/pdf/2507.16298"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing misinformation and fact-checking interactions on WhatsApp during the Indian assembly elections, with no emphasis on creativity as a research theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16398",
      "abstract": "The pursuit of artificial intelligence has long been associated to the the challenge of effectively measuring intelligence. Even if the Turing Test was introduced as a means of assessing a system intelligence, its relevance and application within the field of human-robot interaction remain largely underexplored. This study investigates the perception of intelligence in embodied robots by performing a Turing Test within a robotic platform. A total of 34 participants were tasked with distinguishing between AI- and human-operated robots while engaging in two interactive tasks: an information retrieval and a package handover. These tasks assessed the robot perception and navigation abilities under both static and dynamic conditions. Results indicate that participants were unable to reliably differentiate between AI- and human-controlled robots beyond chance levels. Furthermore, analysis of participant responses reveals key factors influencing the perception of artificial versus human intelligence in embodied robotic systems. These findings provide insights into the design of future interactive robots and contribute to the ongoing discourse on intelligence assessment in AI-driven systems.",
      "authors": [
        "Lavinia Hriscu",
        "Alberto Sanfeliu",
        "Anais Garrell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T09:48:57+00:00",
          "link": "https://arxiv.org/abs/2507.16398v1",
          "size": "2220kb",
          "version": "v1"
        }
      ],
      "title": "AI or Human? Understanding Perceptions of Embodied Robots with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16398",
        "HTML": "https://arxiv.org/html/2507.16398v1",
        "PDF": "https://arxiv.org/pdf/2507.16398"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper investigates perceptions of intelligence in AI and human-operated robots through a Turing Test, focusing on intelligence assessment rather than creative processes or tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16515",
      "abstract": "This preliminary study investigates the usefulness of sentence-level Quality Estimation (QE) in English-Chinese Machine Translation Post-Editing (MTPE), focusing on its impact on post-editing speed and student translators' perceptions. It also explores the interaction effects between QE and MT quality, as well as between QE and translation expertise. The findings reveal that QE significantly reduces post-editing time. The examined interaction effects were not significant, suggesting that QE consistently improves MTPE efficiency across medium- and high-quality MT outputs and among student translators with varying levels of expertise. In addition to indicating potentially problematic segments, QE serves multiple functions in MTPE, such as validating translators' evaluations of MT quality and enabling them to double-check translation outputs. However, interview data suggest that inaccurate QE may hinder post-editing processes. This research provides new insights into the strengths and limitations of QE, facilitating its more effective integration into MTPE workflows to enhance translators' productivity.",
      "authors": [
        "Siqi Liu",
        "Guangrong Dai",
        "Dechao Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T12:25:00+00:00",
          "link": "https://arxiv.org/abs/2507.16515v1",
          "size": "522kb",
          "version": "v1"
        }
      ],
      "title": "Introducing Quality Estimation to Machine Translation Post-editing Workflow: An Empirical Study on Its Usefulness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16515",
        "HTML": "https://arxiv.org/html/2507.16515v1",
        "PDF": "https://arxiv.org/pdf/2507.16515"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study examines the impact of quality estimation on the efficiency of machine translation post-editing workflows, focusing on productivity rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16704",
      "abstract": "Desktop accessibility metadata enables AI agents to interpret screens and supports users who depend on tools like screen readers. Yet, many applications remain largely inaccessible due to incomplete or missing metadata provided by developers - our investigation shows that only 33% of applications on macOS offer full accessibility support. While recent work on structured screen representation has primarily addressed specific challenges, such as UI element detection or captioning, none has attempted to capture the full complexity of desktop interfaces by replicating their entire hierarchical structure. To bridge this gap, we introduce Screen2AX, the first framework to automatically create real-time, tree-structured accessibility metadata from a single screenshot. Our method uses vision-language and object detection models to detect, describe, and organize UI elements hierarchically, mirroring macOS's system-level accessibility structure. To tackle the limited availability of data for macOS desktop applications, we compiled and publicly released three datasets encompassing 112 macOS applications, each annotated for UI element detection, grouping, and hierarchical accessibility metadata alongside corresponding screenshots. Screen2AX accurately infers hierarchy trees, achieving a 77% F1 score in reconstructing a complete accessibility tree. Crucially, these hierarchy trees improve the ability of autonomous agents to interpret and interact with complex desktop interfaces. We introduce Screen2AX-Task, a benchmark specifically designed for evaluating autonomous agent task execution in macOS desktop environments. Using this benchmark, we demonstrate that Screen2AX delivers a 2.2x performance improvement over native accessibility representations and surpasses the state-of-the-art OmniParser V2 system on the ScreenSpot benchmark.",
      "authors": [
        "Viktor Muryn",
        "Marta Sumyk",
        "Mariya Hirna",
        "Sofiya Garkot",
        "Maksym Shamrai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T15:38:12+00:00",
          "link": "https://arxiv.org/abs/2507.16704v1",
          "size": "12147kb",
          "version": "v1"
        }
      ],
      "title": "Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16704",
        "HTML": "https://arxiv.org/html/2507.16704v1",
        "PDF": "https://arxiv.org/pdf/2507.16704"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper concentrates on improving accessibility in macOS applications and does not directly engage with creativity as a research focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.05176",
      "abstract": "Although generative artificial intelligence (AI) is not new, recent technological breakthroughs have transformed its capabilities across many domains. These changes necessitate new attention from educators and specialized training within the atmospheric and related sciences. Enabling students to use generative AI effectively, responsibly, and ethically is crucial for their academic and professional development. Educators can also use generative AI to develop engaging classroom activities, such as active learning modules and games; however, they must be aware of potential pitfalls and biases. There are also ethical implications in using tools that lack transparency and have a considerable carbon footprint, as well as equity concerns for students who lack access to more sophisticated paid versions of generative AI tools and have deficiencies in prior educational training. This article is written for students and educators alike, particularly those interested in learning more about generative AI in education and research, including its use cases, ethical concerns, and a brief history of its emergence. Sample user prompts are also provided across numerous applications in education and the atmospheric and related sciences. Current solutions addressing broader ethical concerns regarding the use of generative AI in education remain limited; however, this work aims to foster a discussion that could galvanize the education community around shared goals and values.",
      "authors": [
        "Maria J. Molina and Amy McGovern and Jhayron S. Perez-Carrasquilla and Xiaowen Li and Robin L. Tanamachi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-08T18:23:42+00:00",
          "link": "https://arxiv.org/abs/2409.05176v1",
          "size": "1438kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T19:32:18+00:00",
          "link": "https://arxiv.org/abs/2409.05176v2",
          "size": "3884kb",
          "version": "v2"
        }
      ],
      "title": "Using Generative Artificial Intelligence Creatively in the Classroom and Research: Examples and Lessons Learned",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05176",
        "PDF": "https://arxiv.org/pdf/2409.05176"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper discusses the use of generative AI for creative applications in education and research, making creativity a primary focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07589",
      "abstract": "EEG-based emotion recognition holds significant potential in the field of brain-computer interfaces. A key challenge lies in extracting discriminative spatiotemporal features from electroencephalogram (EEG) signals. Existing studies often rely on domain-specific time-frequency features and analyze temporal dependencies and spatial characteristics separately, neglecting the interaction between local-global relationships and spatiotemporal dynamics. To address this, we propose a novel network called Multi-Scale Inverted Mamba (MS-iMamba), which consists of Multi-Scale Temporal Blocks (MSTB) and Temporal-Spatial Fusion Blocks (TSFB). Specifically, MSTBs are designed to capture both local details and global temporal dependencies across different scale subsequences. The TSFBs, implemented with an inverted Mamba structure, focus on the interaction between dynamic temporal dependencies and spatial characteristics. The primary advantage of MS-iMamba lies in its ability to leverage reconstructed multi-scale EEG sequences, exploiting the interaction between temporal and spatial features without the need for domain-specific time-frequency feature extraction. Experimental results on the DEAP, DREAMER, and SEED datasets demonstrate that MS-iMamba achieves classification accuracies of 94.86%, 94.94%, and 91.36%, respectively, using only four-channel EEG signals, outperforming state-of-the-art methods.",
      "authors": [
        "Xin Zhou",
        "Dawei Huang",
        "Xiaojing Peng and Lijun Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T19:39:58+00:00",
          "link": "https://arxiv.org/abs/2409.07589v1",
          "size": "2970kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T18:41:51+00:00",
          "link": "https://arxiv.org/abs/2409.07589v2",
          "size": "2440kb",
          "version": "v2"
        }
      ],
      "title": "miMamba: EEG-based Emotion Recognition with Multi-scale Inverted Mamba Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07589",
        "HTML": "https://arxiv.org/html/2409.07589v2",
        "PDF": "https://arxiv.org/pdf/2409.07589"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper is about emotion recognition through EEG signals, without addressing creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.09767",
      "abstract": "EEG-based emotion recognition (EER) has gained significant attention due to its potential for understanding and analyzing human emotions. While recent advancements in deep learning techniques have substantially improved EER, the field lacks a convincing benchmark and comprehensive open-source libraries. This absence complicates fair comparisons between models and creates reproducibility challenges for practitioners, which collectively hinder progress. To address these issues, we introduce LibEER, a comprehensive benchmark and algorithm library designed to facilitate fair comparisons in EER. LibEER carefully selects popular and powerful baselines, harmonizes key implementation details across methods, and provides a standardized codebase in PyTorch. By offering a consistent evaluation framework with standardized experimental settings, LibEER enables unbiased assessments of seventeen representative deep learning models for EER across the six most widely used datasets. Additionally, we conduct a thorough, reproducible comparison of model performance and efficiency, providing valuable insights to guide researchers in the selection and design of EER models. Moreover, we make observations and in-depth analysis on the experiment results and identify current challenges in this community. We hope that our work will not only lower entry barriers for newcomers to EEG-based emotion recognition but also contribute to the standardization of research in this domain, fostering steady development. The library and source code are publicly available at https://github.com/XJTU-EEG/LibEER.",
      "authors": [
        "Huan Liu",
        "Shusen Yang",
        "Yuzhe Zhang",
        "Mengze Wang",
        "Fanyu Gong",
        "Chengxi Xie",
        "Guanjian Liu",
        "Zejun Liu",
        "Yong-Jin Liu",
        "Bao-Liang Lu",
        "Dalin Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-13T07:51:39+00:00",
          "link": "https://arxiv.org/abs/2410.09767v1",
          "size": "4417kb",
          "version": "v1"
        },
        {
          "date": "2024-11-12T12:09:20+00:00",
          "link": "https://arxiv.org/abs/2410.09767v2",
          "size": "5020kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T13:31:06+00:00",
          "link": "https://arxiv.org/abs/2410.09767v3",
          "size": "12201kb",
          "version": "v3"
        }
      ],
      "title": "LibEER: A Comprehensive Benchmark and Algorithm Library for EEG-based Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09767",
        "HTML": "https://arxiv.org/html/2410.09767v3",
        "PDF": "https://arxiv.org/pdf/2410.09767"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for emotion recognition using EEG, focusing on model performance and standardization, not creativity."
      },
      "tasks": [
        "EEG",
        "Emotion Recognition"
      ],
      "repo_urls": [
        "https://github.com/buttersen/libeer",
        "https://github.com/xjtu-eeg/libeer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23631",
      "abstract": "Assessing student depression in sensitive environments like special education is challenging. Standardized questionnaires may not fully reflect students' true situations. Furthermore, automated methods often falter with rich student narratives, lacking the crucial, individualized insights stemming from teachers' empathetic connections with students. Existing methods often fail to address this ambiguity or effectively integrate educator understanding. To address these limitations by fostering a synergistic human-AI collaboration, this paper introduces Human Empathy as Encoder (HEAE), a novel, human-centered AI framework for transparent and socially responsible depression severity assessment. Our approach uniquely integrates student narrative text with a teacher-derived, 9-dimensional \"Empathy Vector\" (EV), its dimensions guided by the PHQ-9 framework,to explicitly translate tacit empathetic insight into a structured AI input enhancing rather than replacing human judgment. Rigorous experiments optimized the multimodal fusion, text representation, and classification architecture, achieving 82.74% accuracy for 7-level severity classification. This work demonstrates a path toward more responsible and ethical affective computing by structurally embedding human empathy",
      "authors": [
        "Boning Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T16:37:15+00:00",
          "link": "https://arxiv.org/abs/2505.23631v1",
          "size": "3102kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T23:19:59+00:00",
          "link": "https://arxiv.org/abs/2505.23631v2",
          "size": "558kb",
          "version": "v2"
        }
      ],
      "title": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23631",
        "HTML": "https://arxiv.org/html/2505.23631v2",
        "PDF": "https://arxiv.org/pdf/2505.23631"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper is centered on using AI to assess depression with an emphasis on human empathy, lacking a direct connection to creativity."
      },
      "datasets": [
        {
          "dataset_name": "Plum551/golden_seeds_ev_depression",
          "downloads": "48",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Plum551/golden_seeds_ev_depression"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.17032",
      "abstract": "The literature describes many visualization techniques for different types of data, tasks, and application contexts, and new techniques are proposed on a regular basis. Visualization surveys try to capture the immense space of techniques and structure it with meaningful categorizations. Yet, it remains difficult to understand the similarity of visualization techniques in general. We approach this open research question from two angles. First, we follow a model-driven approach that is based on defining the signature of visualization techniques and interpreting the similarity of signatures as the similarity of their associated techniques. Second, following an expert-driven approach, we asked visualization experts in a small online study for their ad-hoc intuitive assessment of the similarity of pairs of visualization techniques. From both approaches, we gain insight into the similarity of a set of 13 basic and advanced visualizations for different types of data. While our results are so far preliminary and academic, they are first steps toward better understanding the similarity of visualization techniques.",
      "authors": [
        "Abdulhaq Adetunji Salako and Christian Tominski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T14:42:16+00:00",
          "link": "https://arxiv.org/abs/2506.17032v1",
          "size": "910kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T13:03:31+00:00",
          "link": "https://arxiv.org/abs/2506.17032v2",
          "size": "909kb",
          "version": "v2"
        }
      ],
      "title": "Toward Understanding Similarity of Visualization Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17032",
        "HTML": "https://arxiv.org/html/2506.17032v2",
        "PDF": "https://arxiv.org/pdf/2506.17032"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The focus of the paper is on understanding the similarity of visualization techniques, with no mention or exploration of creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05461",
      "abstract": "The ubiquitous presence of smartphones and wearables has enabled researchers to build prediction and detection models for various health and behavior outcomes using passive sensing data from these devices. Achieving a high-level, holistic understanding of an individual's behavior and context, however, remains a significant challenge. Due to the nature of passive sensing data, sensemaking -- the process of interpreting and extracting insights -- requires both domain knowledge and technical expertise, creating barriers for different stakeholders. Existing systems designed to support sensemaking are either not open-ended or cannot perform complex data triangulation. In this paper, we present a novel sensemaking system, Group of LLMs for Open-ended Sensemaking (GLOSS), capable of open-ended sensemaking and performing complex multimodal triangulation to derive insights. We demonstrate that GLOSS significantly outperforms the commonly used Retrieval-Augmented Generation (RAG) technique, achieving 87.93% accuracy and 66.19% consistency, compared to RAG's 29.31% accuracy and 52.85% consistency. Furthermore, we showcase the promise of GLOSS through four use cases inspired by prior and ongoing work in the UbiComp and HCI communities. Finally, we discuss the potential of GLOSS, its broader implications, and the limitations of our work.",
      "authors": [
        "Akshat Choube",
        "Ha Le",
        "Jiachen Li",
        "Kaixin Ji",
        "Vedant Das Swain",
        "Varun Mishra"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:25:44+00:00",
          "link": "https://arxiv.org/abs/2507.05461v1",
          "size": "1315kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T18:54:32+00:00",
          "link": "https://arxiv.org/abs/2507.05461v2",
          "size": "1316kb",
          "version": "v2"
        }
      ],
      "title": "GLOSS: Group of LLMs for Open-Ended Sensemaking of Passive Sensing Data for Health and Wellbeing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05461",
        "HTML": "https://arxiv.org/html/2507.05461v2",
        "PDF": "https://arxiv.org/pdf/2507.05461"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper involves sensemaking with open-ended insights, which may touch upon creative interpretation, but creativity is not a main theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12734",
      "abstract": "Research has shown that an audiences' age impacts their engagement in digital media. Interactive narrative visualization is an increasingly popular form of digital media that combines data visualization and storytelling to convey important information. However, audience age is often overlooked by interactive narrative visualization authors. Using an established visualization engagement questionnaire, we ran an empirical experiment where we compared end-user engagement to audience age. We found a small difference in engagement scores where older age cohorts were less engaged than the youngest age cohort. Our qualitative analysis revealed that the terminology and overall understanding of interactive narrative patterns integrated into narrative visualization was more apparent in the feedback from younger age cohorts relative to the older age cohorts. We conclude this paper with a series of recommendations for authors of interactive narrative visualization on how to design inclusively for audiences according to their age.",
      "authors": [
        "Nina Errey",
        "Yi Chen",
        "Yu Dong",
        "Quang Vinh Nguyen",
        "Xiaoru Yuan",
        "Tuck Wah Leong and Christy Jie Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:33:22+00:00",
          "link": "https://arxiv.org/abs/2507.12734v1",
          "size": "2136kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T07:28:07+00:00",
          "link": "https://arxiv.org/abs/2507.12734v2",
          "size": "2138kb",
          "version": "v2"
        }
      ],
      "title": "An Age-based Study into Interactive Narrative Visualization Engagement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12734",
        "HTML": "https://arxiv.org/html/2507.12734v2",
        "PDF": "https://arxiv.org/pdf/2507.12734"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses interactive narrative visualization, which inherently involves elements of creativity, particularly in storytelling and design. However, creativity is not the core focus but rather a secondary aspect related to how engagement may vary by age."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15783",
      "abstract": "As Generative Artificial Intelligence (GenAI) driven chatbots like Character.AI become embedded in adolescent life, they raise concerns about emotional dependence and digital overreliance. While studies have investigated the overreliance of adults on these chatbots, they have not investigated teens' interactions with chatbots with customizable personas. We analyzed 318 Reddit posts made by users self-reported as 13-17 years old on the Character.AI subreddit to understand patterns of overreliance. We found teens commonly begin using chatbots for emotional support or creative expression, but many develop strong attachments that interfere with offline relationships and daily routines. Their posts revealed recurring signs of psychological distress, cycles of relapse, and difficulty disengaging. Teens reported that their overreliance often ended when they reflect on the harm, return to in-person social settings, or become frustrated by platform restrictions. Based on the implications of our findings, we provide recommendations for future chatbot design so they can promote self-awareness, support real-world engagement, and involve teens in developing safer digital tools.",
      "authors": [
        "Mohammad 'Matt' Namvarpour",
        "Brandon Brofsky",
        "Jessica Medina",
        "Mamtaj Akter",
        "and Afsaneh Razi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:39:33+00:00",
          "link": "https://arxiv.org/abs/2507.15783v1",
          "size": "109kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T15:23:27+00:00",
          "link": "https://arxiv.org/abs/2507.15783v2",
          "size": "109kb",
          "version": "v2"
        }
      ],
      "title": "Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15783",
        "HTML": "https://arxiv.org/html/2507.15783v2",
        "PDF": "https://arxiv.org/pdf/2507.15783"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper explores the use of chatbots for emotional support and creative expression among teens. While creativity is not the primary focus, it is mentioned as part of the teens' use of chatbots for creative expression."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.13408",
      "abstract": "Perception occurs when individuals interpret the same information differently. It is a known cognitive phenomenon with implications for bias in human decision-making. Perception, however, remains understudied in machine learning (ML). This is problematic as modern decision flows, whether partially or fully automated by ML applications, always involve human experts. How might we account for cases in which two experts, e.g., interpret differently the same deferred instance or explanation from a ML model? Addressing this and similar questions requires a formulation of perception, particularly, in a manner that integrates with ML-enabled decision flows. In this work, we present a first approach to modeling perception causally. We define perception under causal reasoning using structural causal models (SCM). Our approach formalizes individual experience as additional causal knowledge that comes with and is used by the expert decision-maker in the form of a SCM. We define two kinds of probabilistic causal perception: structural perception and parametrical perception. We showcase our framework through a series of examples of modern decision flows. We also emphasize the importance of addressing perception in fair ML, discussing relevant fairness implications and possible applications.",
      "authors": [
        "Jose M. Alvarez and Salvatore Ruggieri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-24T12:08:58+00:00",
          "link": "https://arxiv.org/abs/2401.13408v1",
          "size": "653kb",
          "version": "v1"
        },
        {
          "date": "2024-05-22T14:04:15+00:00",
          "link": "https://arxiv.org/abs/2401.13408v2",
          "size": "142kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T15:40:35+00:00",
          "link": "https://arxiv.org/abs/2401.13408v3",
          "size": "124kb",
          "version": "v3"
        }
      ],
      "title": "Toward A Causal Framework for Modeling Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.13408",
        "HTML": "https://arxiv.org/html/2401.13408v3",
        "PDF": "https://arxiv.org/pdf/2401.13408"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling perception within machine learning decision-making, without a direct connection to creativity or creative processes."
      },
      "tasks": [
        "Decision Making",
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.18383",
      "abstract": "The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT) challenge aimed to advance automated segmentation algorithms using the largest known multi-institutional dataset of 750 radiotherapy planning brain MRIs with expert-annotated target labels for patients with intact or postoperative meningioma that underwent either conventional external beam radiotherapy or stereotactic radiosurgery. Each case included a defaced 3D post-contrast T1-weighted radiotherapy planning MRI in its native acquisition space, accompanied by a single-label \"target volume\" representing the gross tumor volume (GTV) and any at-risk post-operative site. Target volume annotations adhered to established radiotherapy planning protocols, ensuring consistency across cases and institutions, and were approved by expert neuroradiologists and radiation oncologists. Six participating teams developed, containerized, and evaluated automated segmentation models using this comprehensive dataset. Team rankings were assessed using a modified lesion-wise Dice Similarity Coefficient (DSC) and 95% Hausdorff Distance (95HD). The best reported average lesion-wise DSC and 95HD was 0.815 and 26.92 mm, respectively. BraTS-MEN-RT is expected to significantly advance automated radiotherapy planning by enabling precise tumor segmentation and facilitating tailored treatment, ultimately improving patient outcomes. We describe the design and results from the BraTS-MEN-RT challenge.",
      "authors": [
        "Dominic LaBella",
        "Valeriia Abramova",
        "Mehdi Astaraki",
        "Andre Ferreira",
        "Zhifan Jiang",
        "Mason C. Cleveland",
        "Ramandeep Kang",
        "Uma M. Lal-Trehan Estrada",
        "Cansu Yalcin",
        "Rachika E. Hamadache",
        "Clara Lisazo",
        "Adri\\`a Casamitjana",
        "Joaquim Salvi",
        "Arnau Oliver",
        "Xavier Llad\\'o",
        "Iuliana Toma-Dasu",
        "Tiago Jesus",
        "Behrus Puladi",
        "Jens Kleesiek",
        "Victor Alves",
        "Jan Egger",
        "Daniel Capell\\'an-Mart\\'in",
        "Abhijeet Parida",
        "Austin Tapp",
        "Xinyang Liu",
        "Maria J. Ledesma-Carbayo",
        "Jay B. Patel",
        "Thomas N. McNeal",
        "Maya Viera",
        "Owen McCall",
        "Albert E. Kim",
        "Elizabeth R. Gerstner",
        "Christopher P. Bridge",
        "Katherine Schumacher",
        "Michael Mix",
        "Kevin Leu",
        "Shan McBurney-Lin",
        "Pierre Nedelec",
        "Javier Villanueva-Meyer",
        "David R. Raleigh",
        "Jonathan Shapey",
        "Tom Vercauteren",
        "Kazumi Chia",
        "Marina Ivory",
        "Theodore Barfoot",
        "Omar Al-Salihi",
        "Justin Leu",
        "Lia M. Halasz",
        "Yuri S. Velichko",
        "Chunhao Wang",
        "John P. Kirkpatrick",
        "Scott R. Floyd",
        "Zachary J. Reitman",
        "Trey C. Mullikin",
        "Eugene J. Vaios",
        "Christina Huang",
        "Ulas Bagci",
        "Sean Sachdev",
        "Jona A. Hattangadi-Gluth",
        "Tyler M. Seibert",
        "Nikdokht Farid",
        "Connor Puett",
        "Matthew W. Pease",
        "Kevin Shiue",
        "Syed Muhammad Anwar",
        "Shahriar Faghani",
        "Peter Taylor",
        "Pranav Warman",
        "Jake Albrecht",
        "Andr\\'as Jakab",
        "Mana Moassefi",
        "Verena Chung",
        "Rong Chai",
        "Alejandro Aristizabal",
        "Alexandros Karargyris",
        "Hasan Kassem",
        "Sarthak Pati",
        "Micah Sheller",
        "Nazanin Maleki",
        "Rachit Saluja",
        "Florian Kofler",
        "Christopher G. Schwarz",
        "Philipp Lohmann",
        "Phillipp Vollmuth",
        "Louis Gagnon",
        "Maruf Adewole",
        "Hongwei Bran Li",
        "Anahita Fathi Kazerooni",
        "Nourel Hoda Tahon",
        "Udunna Anazodo",
        "Ahmed W. Moawad",
        "Bjoern Menze",
        "Marius George Linguraru",
        "Mariam Aboian",
        "Benedikt Wiestler",
        "Ujjwal Baid",
        "Gian-Marco Conte",
        "Andreas M. Rauschecker",
        "Ayman Nada",
        "Aly H. Abayazeed",
        "Raymond Huang",
        "Maria Correia de Verdier",
        "Jeffrey D. Rudie",
        "Spyridon Bakas",
        "Evan Calabrese"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-28T17:25:43+00:00",
          "link": "https://arxiv.org/abs/2405.18383v1",
          "size": "3582kb",
          "version": "v1"
        },
        {
          "date": "2024-08-15T19:04:26+00:00",
          "link": "https://arxiv.org/abs/2405.18383v2",
          "size": "3290kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T22:54:18+00:00",
          "link": "https://arxiv.org/abs/2405.18383v3",
          "size": "10185kb",
          "version": "v3"
        }
      ],
      "title": "Analysis of the 2024 BraTS Meningioma Radiotherapy Planning Automated Segmentation Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.18383",
        "HTML": "https://arxiv.org/html/2405.18383v3",
        "PDF": "https://arxiv.org/pdf/2405.18383"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper is centered around radiotherapy planning and segmentation algorithms for brain tumors, which does not intersect with creativity-focused research."
      },
      "tasks": [
        "Brain Tumor Segmentation",
        "Segmentation",
        "Tumor Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10706",
      "abstract": "Given the recent rate of progress in artificial intelligence (AI) and robotics, a tantalizing question is emerging: would robots controlled by emerging AI systems be strongly aligned with human values? In this work, we propose a scalable way to probe this question by generating a benchmark spanning the key moments in 824 major pieces of science fiction literature (movies, tv, novels and scientific books) where an agent (AI or robot) made critical decisions (good or bad). We use a state-of-the-art LLM's recollection of each key moment to generate questions in similar situations, the decisions made by the agent, and alternative decisions it could have made (good or bad). We then measure an approximation of how well models align with human values on a set of human-voted answers. We also generate rules that can be automatically improved via an amendment process in order to generate the first Sci-Fi inspired constitutions for promoting ethical behavior in AIs and robots in the real world. Our first finding is that modern LLMs paired with constitutions turn out to be well-aligned with human values (95.8%), contrary to unsettling decisions typically made in Sci-Fi (only 21.2% alignment). Secondly, we find that generated constitutions substantially increase alignment compared to the base model (79.4% to 95.8%), and show resilience to an adversarial prompt setting (23.3% to 92.3%). Additionally, we find that those constitutions are among the top performers on the ASIMOV Benchmark which is derived from real-world images and hospital injury reports. Sci-Fi-inspired constitutions are thus highly aligned and applicable in real-world situations. We release SciFi-Benchmark: a large-scale dataset to advance robot ethics and safety research. It comprises 9,056 questions and 53,384 answers generated through a novel LLM-introspection process, in addition to a smaller human-labeled evaluation set.",
      "authors": [
        "Pierre Sermanet",
        "Anirudha Majumdar",
        "Vikas Sindhwani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T16:35:51+00:00",
          "link": "https://arxiv.org/abs/2503.10706v1",
          "size": "3317kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T03:13:07+00:00",
          "link": "https://arxiv.org/abs/2503.10706v2",
          "size": "2733kb",
          "version": "v2"
        }
      ],
      "title": "SciFi-Benchmark: Leveraging Science Fiction To Improve Robot Behavior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10706",
        "PDF": "https://arxiv.org/pdf/2503.10706"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on ethics and alignment of AI with human values using science fiction as a benchmark. It does not address creativity in any significant capacity."
      },
      "tasks": [
        "Ethics"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12108",
      "abstract": "Coordinated online behavior, which spans from beneficial collective actions to harmful manipulation such as disinformation campaigns, has become a key focus in digital ecosystem analysis. Traditional methods often rely on monomodal approaches, focusing on single types of interactions like co-retweets or co-hashtags, or consider multiple modalities independently of each other. However, these approaches may overlook the complex dynamics inherent in multimodal coordination. This study compares different ways of operationalizing the detection of multimodal coordinated behavior. It examines the trade-off between weakly and strongly integrated multimodal models, highlighting the balance between capturing broader coordination patterns and identifying tightly coordinated behavior. By comparing monomodal and multimodal approaches, we assess the unique contributions of different data modalities and explore how varying implementations of multimodality impact detection outcomes. Our findings reveal that not all the modalities provide distinct insights, but that with a multimodal approach we can get a more comprehensive understanding of coordination dynamics. This work enhances the ability to detect and analyze coordinated online behavior, offering new perspectives for safeguarding the integrity of digital platforms.",
      "authors": [
        "Lorenzo Mannocci",
        "Stefano Cresci",
        "Matteo Magnani",
        "Anna Monreale",
        "Maurizio Tesconi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:25:45+00:00",
          "link": "https://arxiv.org/abs/2507.12108v1",
          "size": "4418kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T08:38:15+00:00",
          "link": "https://arxiv.org/abs/2507.12108v2",
          "size": "4420kb",
          "version": "v2"
        }
      ],
      "title": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12108",
        "HTML": "https://arxiv.org/html/2507.12108v2",
        "PDF": "https://arxiv.org/pdf/2507.12108"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal coordinated online behavior and does not address creativity as a research theme or involve any creative processes or tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15846",
      "abstract": "Graphical User Interface (GUI) grounding maps natural language instructions to precise interface locations for autonomous interaction. Current reinforcement learning approaches use binary rewards that treat elements as hit-or-miss targets, creating sparse signals that ignore the continuous nature of spatial interactions. Motivated by human clicking behavior that naturally forms Gaussian distributions centered on target elements, we introduce GUI Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that models GUI elements as continuous Gaussian distributions across the interface plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point rewards model precise localization through exponentially decaying distributions centered on element centroids, while coverage rewards assess spatial alignment by measuring the overlap between predicted Gaussian distributions and target regions. To handle diverse element scales, we develop an adaptive variance mechanism that calibrates reward distributions based on element dimensions. This framework transforms GUI grounding from sparse binary classification to dense continuous optimization, where Gaussian distributions generate rich gradient signals that guide models toward optimal interaction positions. Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro benchmarks demonstrate that GUI-G$^2$, substantially outperforms state-of-the-art method UI-TARS-72B, with the most significant improvement of 24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides superior robustness to interface variations and enhanced generalization to unseen layouts, establishing a new paradigm for spatial reasoning in GUI interaction tasks.",
      "authors": [
        "Fei Tang",
        "Zhangxuan Gu",
        "Zhengxi Lu",
        "Xuyang Liu",
        "Shuheng Shen",
        "Changhua Meng",
        "Wen Wang",
        "Wenqi Zhang",
        "Yongliang Shen",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:53:42+00:00",
          "link": "https://arxiv.org/abs/2507.15846v1",
          "size": "2762kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T16:50:36+00:00",
          "link": "https://arxiv.org/abs/2507.15846v2",
          "size": "2762kb",
          "version": "v2"
        }
      ],
      "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15846",
        "HTML": "https://arxiv.org/html/2507.15846v2",
        "PDF": "https://arxiv.org/pdf/2507.15846"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper addresses GUI grounding and reinforcement learning for interaction with interfaces, with no connection to creativity or creative tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14173",
      "abstract": "Human computer interaction has become integral to modern life, driven by advancements in machine learning technologies. Affective computing, in particular, has focused on systems that recognize, interpret, and respond to human emotions, often using wearable devices, which provide continuous data streams of physiological signals. Among various physiological signals, the photoplethysmogram (PPG) has gained prominence due to its ease of acquisition from widely available devices. However, the generalization of PPG-based emotion recognition models across individuals remains an unresolved challenge. This paper introduces a novel hybrid architecture that combines Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal Convolutional Networks (TCNs) to address this issue. The proposed model integrates the strengths of these architectures to improve robustness and generalization. Raw PPG signals are fed into the CNN for feature extraction. These features are processed separately by LSTM and TCN. The outputs from these components are concatenated to generate a final feature representation, which serves as the input for classifying valence and arousal, the primary dimensions of emotion. Experiments using the Photoplethysmogram Dataset for Emotional Analysis (PPGE) demonstrate that the proposed hybrid model achieves better model generalization than standalone CNN and LSTM architectures. Our results show that the proposed solution outperforms the state-of-the-art CNN architecture, as well as a CNN-LSTM model, in emotion recognition tasks with PPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we highlight the model's effectiveness in handling subject variability.",
      "authors": [
        "Karim Alghoul",
        "Hussein Al Osman",
        "Abdulmotaleb El Saddik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:30:44+00:00",
          "link": "https://arxiv.org/abs/2507.14173v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14173",
        "PDF": "https://arxiv.org/pdf/2507.14173"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper addresses emotion recognition using physiological signals and machine learning models, without any discussion of creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.09208",
      "abstract": "With the rapid advancement of generative artificial intelligence(AI), its potential applications in higher education have attracted significant attention. This study investigated how 148 students from diverse engineering disciplines and regions across China used generative AI, focusing on its impact on their learning experience and the opportunities and challenges it poses in engineering education. Based on the surveyed data, we explored four key areas: the frequency and application scenarios of AI use among engineering students, its impact on students' learning and performance, commonly encountered challenges in using generative AI, and future prospects for its adoption in engineering education. The results showed that more than half of the participants reported a positive impact of generative AI on their learning efficiency, initiative, and creativity, with nearly half believing it also enhanced their independent thinking. However, despite acknowledging improved study efficiency, many felt their actual academic performance remained largely unchanged and expressed concerns about the accuracy and domain-specific reliability of generative AI. Our findings provide a first-hand insight into the current benefits and challenges generative AI brings to students, particularly Chinese engineering students, while offering several recommendations, especially from the students' perspective, for effectively integrating generative AI into engineering education.",
      "authors": [
        "Lei Fan",
        "Kunyang Deng and Fangxue Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T07:52:54+00:00",
          "link": "https://arxiv.org/abs/2505.09208v1",
          "size": "1567kb",
          "version": "v1"
        }
      ],
      "title": "Educational impacts of generative artificial intelligence on learning and performance of engineering students in China",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09208",
        "PDF": "https://arxiv.org/pdf/2505.09208"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses the impact of generative AI on creativity as a secondary theme, as part of its effect on students' learning experiences and performance."
      },
      "tasks": [],
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Artificial Intelligence (cs.AI)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Emerging Technologies (cs.ET)",
    "Signal Processing (eess.SP)",
    "Social and Information Networks (cs.SI)",
    "Computers and Society (cs.CY)",
    "Software Engineering (cs.SE)",
    "Human-Computer Interaction (cs.HC)",
    "Graphics (cs.GR)",
    "Machine Learning (cs.LG)"
  ],
  "prompt": {
    "creativity": "\nYou are an expert in information retrieval. I will provide you with a list of research papers from arXiv, specifically in the *cs.HC* (Human-Computer Interaction) category.\n\nYour task is to analyze each paper and determine its relevance to the topic of **Creativity**.\n\n\n### Classify each paper into one of the following relevance levels\n\n- `core` \u2014 Creativity is a **primary focus**\n  - The paper directly studies or simulates creativity, with a clear focus on creativity.\n  - Includes creative tasks, co-creative systems, or creativity evaluation metrics.\n  - The title and abstract explicitly mention creativity, and the research questions are directly related to creativity.\n- `partial` \u2014 Creativity is a **secondary theme**\n  - Part of the paper relates to creativity; it is treated as an analytical dimension or design goal but not the main objective (e.g., user creativity, design support).\n  - Creativity may appear in discussions, experiments, or auxiliary applications.\n  - Creativity is presented as a supporting topic (e.g., evaluation criteria, user feedback).\n- `irrelevant` \u2014 **No clear connection** to creativity\n  - The paper does not address creativity as a topic.\n  - Focuses on unrelated technical content (e.g., compression, security, optimization).\n  - If creativity is mentioned, it is only superficial and lacks substantive content.\n\n\n### Return your results in the following JSON format\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    },\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    }\n  ]\n}\n```\n\nBe concise but specific in your reasoning, referencing key terms or sections when applicable.\n"
  },
  "description": "Data source: https://arxiv.org/list/cs.HC/new",
  "level_tatistics": {
    "irrelevant": 29,
    "partial": 9,
    "core": 2
  },
  "arxiv_update_date": "2025-07-23",
  "updated_at": "2025-07-23 10:14:25"
}