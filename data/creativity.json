{
  "data": [
    {
      "id": "2507.10773",
      "abstract": "Self-disclosure is important to help us feel better, yet is often difficult. This difficulty can arise from how we think people are going to react to our self-disclosure. In this workshop paper, we briefly discuss self-disclosure to conversational user interfaces (CUIs) in relation to various social cues. We then, discuss how expressions of uncertainty or representation of a CUI's reasoning could help encourage self-disclosure, by making a CUI's intended \"theory of mind\" more transparent to users.",
      "authors": [
        "Samuel Rhys Cox"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:57:18+00:00",
          "link": "https://arxiv.org/abs/2507.10773v1",
          "size": "906kb",
          "version": "v1"
        }
      ],
      "title": "Theory of Mind and Self-Disclosure to CUIs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10773",
        "HTML": "https://arxiv.org/html/2507.10773v1",
        "PDF": "https://arxiv.org/pdf/2507.10773"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper addresses self-disclosure to conversational interfaces with no mention of creativity or its aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10812",
      "abstract": "We propose an approach to test embodied AI agents for interaction awareness and believability, particularly in scenarios where humans push them to their limits. Turing introduced the Imitation Game as a way to explore the question: \"Can machines think?\" The Total Turing Test later expanded this concept beyond purely verbal communication, incorporating perceptual and physical interaction. Building on this, we propose a new guiding question: \"Can machines react?\" and introduce the React to This (RTT) test for nonverbal behaviors, presenting results from an initial experiment.",
      "authors": [
        "Chuxuan Zhang",
        "Yasaman Etesam and Angelica Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:16:12+00:00",
          "link": "https://arxiv.org/abs/2507.10812v1",
          "size": "2201kb",
          "version": "v1"
        }
      ],
      "title": "React to This (RTT): A Nonverbal Turing Test for Embodied AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10812",
        "HTML": "https://arxiv.org/html/2507.10812v1",
        "PDF": "https://arxiv.org/pdf/2507.10812"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on testing AI agents for interaction awareness and believability through nonverbal behavior, without any clear connection to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10813",
      "abstract": "Visual neuroprostheses (bionic eye) aim to restore a rudimentary form of vision by translating camera input into patterns of electrical stimulation. To improve scene understanding under extreme resolution and bandwidth constraints, prior work has explored computer vision techniques such as semantic segmentation and depth estimation. However, presenting all task-relevant information simultaneously can overwhelm users in cluttered environments. We compare two complementary approaches to semantic preprocessing in immersive virtual reality: SemanticEdges, which highlights all relevant objects at once, and SemanticRaster, which staggers object categories over time to reduce visual clutter. Using a biologically grounded simulation of prosthetic vision, 18 sighted participants performed a wayfinding task in a dynamic urban environment across three conditions: edge-based baseline (Control), SemanticEdges, and SemanticRaster. Both semantic strategies improved performance and user experience relative to the baseline, with each offering distinct trade-offs: SemanticEdges increased the odds of success, while SemanticRaster boosted the likelihood of collision-free completions. These findings underscore the value of adaptive semantic preprocessing for prosthetic vision and, more broadly, may inform the design of low-bandwidth visual interfaces in XR that must balance information density, task relevance, and perceptual clarity.",
      "authors": [
        "Justin M. Kasowski",
        "Apurv Varshney",
        "Michael Beyeler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:20:36+00:00",
          "link": "https://arxiv.org/abs/2507.10813v1",
          "size": "7034kb",
          "version": "v1"
        }
      ],
      "title": "Static or Temporal? Semantic Scene Simplification to Aid Wayfinding in Immersive Simulations of Bionic Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10813",
        "HTML": "https://arxiv.org/html/2507.10813v1",
        "PDF": "https://arxiv.org/pdf/2507.10813"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses semantic preprocessing strategies for aiding scene understanding in prosthetic vision. While creativity is not the main focus, the work may relate to creative design considerations for interface development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10963",
      "abstract": "Videos offer rich audiovisual information that can support people in performing activities of daily living (ADLs), but they remain largely inaccessible to blind or low-vision (BLV) individuals. In cooking, BLV people often rely on non-visual cues, such as touch, taste, and smell, to navigate their environment, making it difficult to follow the predominantly audiovisual instructions found in video recipes. To address this problem, we introduce AROMA, an AI system that provides timely responses to the user based on real-time, context-aware assistance by integrating non-visual cues perceived by the user, a wearable camera feed, and video recipe content. AROMA uses a mixed-initiative approach: it responds to user requests while also proactively monitoring the video stream to offer timely alerts and guidance. This collaborative design leverages the complementary strengths of the user and AI system to align the physical environment with the video recipe, helping the user interpret their current cooking state and make sense of the steps. We evaluated AROMA through a study with eight BLV participants and offered insights for designing interactive AI systems to support BLV individuals in performing ADLs.",
      "authors": [
        "Zheng Ning",
        "Leyang Li",
        "Daniel Killough",
        "JooYoung Seo",
        "Patrick Carrington",
        "Yapeng Tian",
        "Yuhang Zhao",
        "Franklin Mingzhe Li",
        "and Toby Jia-Jun Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:58:28+00:00",
          "link": "https://arxiv.org/abs/2507.10963v1",
          "size": "6659kb",
          "version": "v1"
        }
      ],
      "title": "AROMA: Mixed-Initiative AI Assistance for Non-Visual Cooking by Grounding Multi-modal Information Between Reality and Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10963",
        "HTML": "https://arxiv.org/html/2507.10963v1",
        "PDF": "https://arxiv.org/pdf/2507.10963"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses AROMA, a system supporting BLV individuals in cooking, with a focus on aligning physical environments with video instructions. While it involves mixed-initiative interactions which could impact creativity, the primary focus is on accessibility, not creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10967",
      "abstract": "This position paper introduces Self++, a novel nine-level framework for co-determined living in the Metaverse, grounded in Self-Determination Theory. Self++ prioritises human flourishing by progressively cultivating competence, autonomy, and relatedness through dynamic human-AI collaboration in extended reality (XR). Unlike technologically deterministic approaches, Self++ emphasises user empowerment by enhancing competency, mitigating cognitive biases and leveraging XR's immersive capabilities. Key research directions proposed include exploring the boundaries of user-defined AI autonomy, designing for meaningful social connection in XR, and establishing proactive ethical safeguards. Ultimately, Self++ offers a roadmap for creating a human-centred, AI-enhanced Metaverse where technology amplifies, rather than diminishes, human potential.",
      "authors": [
        "Thammathip Piumsomboon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:11:59+00:00",
          "link": "https://arxiv.org/abs/2507.10967v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "Self++: Merging Human and AI for Co-Determined XR Living in the Metaverse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10967",
        "HTML": "https://arxiv.org/html/2507.10967v1",
        "PDF": "https://arxiv.org/pdf/2507.10967"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "Self++ framework emphasizes user empowerment and augmented reality interactions, where creativity is a supportive aspect through human-AI collaboration. However, creativity is not the primary topic; rather, it is a lens for user autonomy and flourishing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10970",
      "abstract": "Mobile-based financial services have made it possible for the traditionally unbanked to access infrastructure that have been routinely unattainable. Researchers have explored how these systems have made for safer environments to send and receive money and have expanded financial opportunities such as increased borrowing. With this expansion, challenges such as detrimental interest rates, lack of access to policy documents, and inadequate user protective guardrails emerge, amplifying the risks due to technology-aided unethical financial practices that are aided by design patterns. Supported by user interviews, we detail user experiences of mobile-based financial transactions and explore the foundations and guidelines that undergird the financial service provisions: highlighting both affordances and harms enabled in the design of such systems. We discuss the findings by highlighting financial exploitation disparities, deliberating strategies for mitigation of risks and enabling recovery from harms caused by the technology use. We then recommend guidelines for empowering design approaches that support users' mechanisms of trust, their understanding of technological processes, and determination of risks.",
      "authors": [
        "Lindah Kotut"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:26:12+00:00",
          "link": "https://arxiv.org/abs/2507.10970v1",
          "size": "1490kb",
          "version": "v1"
        }
      ],
      "title": "Terms and Conditions (Do Not) Apply: Understanding Exploitation Disparities in Design of Mobile-Based Financial Services",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10970",
        "HTML": "https://arxiv.org/html/2507.10970v1",
        "PDF": "https://arxiv.org/pdf/2507.10970"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper examines exploitation disparities in mobile financial services design, focusing on user trust and risk recovery. There is no substantial mention of creativity or its impact on these financial systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10981",
      "abstract": "The integration of extended reality (XR) with artificial intelligence (AI) introduces a new paradigm for user interaction, enabling AI to perceive user intent, stimulate the senses, and influence decision-making. We explored the impact of four AI-driven visualisation techniques -- `Inform,' `Nudge,' `Recommend,' and `Instruct' -- on user decision-making in XR using the Meta Quest Pro. To test these techniques, we used a pre-recorded 360-degree video of a supermarket, overlaying each technique through a virtual interface. We aimed to investigate how these different visualisation techniques with different levels of user autonomy impact preferences and decision-making. An exploratory study with semi-structured interviews provided feedback and design recommendations. Our findings emphasise the importance of maintaining user autonomy, enhancing AI transparency to build trust, and considering context in visualisation design.",
      "authors": [
        "Ze Dong",
        "Binyang Han",
        "Jingjing Zhang",
        "Ruoyu Wen",
        "Barrett Ens",
        "Adrian Clark",
        "Tham Piumsomboon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:53:09+00:00",
          "link": "https://arxiv.org/abs/2507.10981v1",
          "size": "28029kb",
          "version": "v1"
        }
      ],
      "title": "An Exploratory Study on AI-driven Visualisation Techniques on Decision Making in Extended Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10981",
        "HTML": "https://arxiv.org/html/2507.10981v1",
        "PDF": "https://arxiv.org/pdf/2507.10981"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The study investigates AI-driven visualization in decision-making within XR environments. While creativity might be indirectly influenced through decision-making processes, the focus is more on visualization techniques and user autonomy, rather than creativity itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11210",
      "abstract": "Well-being in family settings involves subtle psychological dynamics that conventional metrics often overlook. In particular, unconscious parental expectations, termed ideal parent bias, can suppress children's emotional expression and autonomy. This suppression, referred to as suppressed emotion, often stems from well-meaning but value-driven communication, which is difficult to detect or address from outside the family. Focusing on these latent dynamics, this study explores Large Language Model (LLM)-based support for psychologically safe family communication. We constructed a Japanese parent-child dialogue corpus of 30 scenarios, each annotated with metadata on ideal parent bias and suppressed emotion. Based on this corpus, we developed a Role-Playing LLM-based multi-agent dialogue support framework that analyzes dialogue and generates feedback. Specialized agents detect suppressed emotion, describe implicit ideal parent bias in parental speech, and infer contextual attributes such as the child's age and background. A meta-agent compiles these outputs into a structured report, which is then passed to five selected expert agents. These agents collaboratively generate empathetic and actionable feedback through a structured four-step discussion process. Experiments show that the system can detect categories of suppressed emotion with moderate accuracy and produce feedback rated highly in empathy and practicality. Moreover, simulated follow-up dialogues incorporating this feedback exhibited signs of improved emotional expression and mutual understanding, suggesting the framework's potential in supporting positive transformation in family interactions.",
      "authors": [
        "Rushia Harada",
        "Yuken Kimura",
        "Keito Inoshita"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:27:32+00:00",
          "link": "https://arxiv.org/abs/2507.11210v1",
          "size": "853kb",
          "version": "v1"
        }
      ],
      "title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11210",
        "PDF": "https://arxiv.org/pdf/2507.11210"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "Role-playing dialogues aim to improve family communication by using LLMs to provide feedback on emotional expression. While creativity may play a role in generating these dialogues, the primary focus is on emotional well-being and communication bias, not creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11470",
      "abstract": "This paper introduces REVA, a human-AI system that expedites instructor review of voluminous AI-generated programming feedback by sequencing submissions to minimize cognitive context shifts and propagating instructor-driven revisions across semantically similar instances. REVA introduces a novel approach to human-AI collaboration in educational feedback by adaptively learning from instructors' attention in the review and revision process to continuously improve the feedback validation process. REVA's usefulness and effectiveness in improving feedback quality and the overall feedback review process were evaluated through a within-subjects lab study with 12 participants.",
      "authors": [
        "Xiaohang Tang",
        "Sam Wong",
        "Zicheng He",
        "Yalong Yang",
        "Yan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:41:29+00:00",
          "link": "https://arxiv.org/abs/2507.11470v1",
          "size": "8917kb",
          "version": "v1"
        }
      ],
      "title": "REVA: Supporting LLM-Generated Programming Feedback Validation at Scale Through User Attention-based Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11470",
        "HTML": "https://arxiv.org/html/2507.11470v1",
        "PDF": "https://arxiv.org/pdf/2507.11470"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study introduces REVA for improving AI-generated programming feedback validation. It addresses user attention for adaptation in educational contexts, with no mention of creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11490",
      "abstract": "Recognizing how technical systems can embody social values or cause harms, human-computer interaction (HCI) research often approaches addressing values and ethics in design by creating tools to help tech workers integrate social values into the design of products. While useful, these approaches usually do not consider the politics embedded in the broader processes, organizations, social systems, and governance structures that affect the types of actions that tech workers can take to address values and ethics. This paper argues that creating infrastructures to support values and ethics work, rather than tools, is an approach that takes these broader processes into account and opens them up for (re)design. Drawing on prior research conceptualizing infrastructures from science \\& technology studies and media studies, this paper outlines conceptual insights from infrastructures studies that open up new tactics for HCI researchers and designers seeking to support values and ethics in design.",
      "authors": [
        "Richmond Y. Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:02:39+00:00",
          "link": "https://arxiv.org/abs/2507.11490v1",
          "size": "162kb",
          "version": "v1"
        }
      ],
      "title": "Towards Creating Infrastructures for Values and Ethics Work in the Production of Software Technologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11490",
        "HTML": "https://arxiv.org/html/2507.11490v1",
        "PDF": "https://arxiv.org/pdf/2507.11490"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses infrastructures supporting values and ethics in software production rather than focusing on creativity. It does not address creative tasks, systems, or creativity evaluation metrics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10580",
      "abstract": "Mental health plays a crucial role in the overall well-being of an individual. In recent years, digital platforms have been increasingly used to expand mental health and emotional support. However, there are persistent challenges related to limited user accessibility, internet connectivity, and data privacy, which highlight the need for an offline, smartphone-based solution. To address these challenges, we propose EmoSApp (Emotional Support App): an entirely offline, smartphone-based conversational app designed for mental health and emotional support. The system leverages Large Language Models (LLMs), specifically fine-tuned, quantized and deployed using Torchtune and Executorch for resource-constrained devices, allowing all inferences to occur on the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned the LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of 14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we demonstrate that EmoSApp has the ability to respond coherently, empathetically, maintain interactive dialogue, and provide relevant suggestions to user's mental health problems. Additionally, quantitative evaluations on nine standard commonsense and reasoning benchmarks demonstrate the efficacy of our fine-tuned, quantized model in low-resource settings. By prioritizing on-device deployment and specialized domain adaptation, EmoSApp serves as a blueprint for future innovations in portable, secure, and highly tailored AI-driven mental health solutions.",
      "authors": [
        "Vimaleswar A",
        "Prabhu Nandan Sahu",
        "Nilesh Kumar Sahu",
        "Haroon R Lone"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:23:07+00:00",
          "link": "https://arxiv.org/abs/2507.10580v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10580",
        "HTML": "https://arxiv.org/html/2507.10580v1",
        "PDF": "https://arxiv.org/pdf/2507.10580"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on a mental health support app using LLMs without explicit mention of creativity or creative applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10644",
      "abstract": "The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.",
      "authors": [
        "Tatiana Petrova (1)",
        "Aleksandr Puzikov (1)",
        "Boris Bliznukov (1)",
        "Radu State (1) ((1) SEDAN SnT",
        "University of Luxembourg",
        "Luxembourg",
        "Luxembourg)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:47:19+00:00",
          "link": "https://arxiv.org/abs/2507.10644v1",
          "size": "1312kb",
          "version": "v1"
        }
      ],
      "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10644",
        "HTML": "https://arxiv.org/html/2507.10644v1",
        "PDF": "https://arxiv.org/pdf/2507.10644"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses the evolution of agent frameworks and semantic web technologies without reference to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10695",
      "abstract": "Individuals are increasingly relying on large language model (LLM)-enabled conversational agents for emotional support. While prior research has examined privacy and security issues in chatbots specifically designed for mental health purposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not leverage generative AI. Little empirical research currently measures users' privacy and security concerns, attitudes, and expectations when using general-purpose LLM-enabled chatbots to manage and improve mental health. Through 21 semi-structured interviews with U.S. participants, we identified critical misconceptions and a general lack of risk awareness. Participants conflated the human-like empathy exhibited by LLMs with human-like accountability and mistakenly believed that their interactions with these chatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures with a licensed therapist. We introduce the concept of \"intangible vulnerability,\" where emotional or psychological disclosures are undervalued compared to more tangible forms of information (e.g., financial or location-based data). To address this, we propose recommendations to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots more effectively.",
      "authors": [
        "Jabari Kwesi",
        "Jiaxun Cao",
        "Riya Manchanda",
        "Pardis Emami-Naeini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:10:21+00:00",
          "link": "https://arxiv.org/abs/2507.10695v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10695",
        "HTML": "https://arxiv.org/html/2507.10695v1",
        "PDF": "https://arxiv.org/pdf/2507.10695"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The research primarily concerns privacy and security in mental health chatbots and does not address creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10761",
      "abstract": "Detecting assistance from artificial intelligence is increasingly important as they become ubiquitous across complex tasks such as text generation, medical diagnosis, and autonomous driving. Aid detection is challenging for humans, especially when looking at abstract task data. Artificial neural networks excel at classification thanks to their ability to quickly learn from and process large amounts of data -- assuming appropriate preprocessing. We posit detecting help from AI as a classification task for such models. Much of the research in this space examines the classification of complex but concrete data classes, such as images. Many AI assistance detection scenarios, however, result in data that is not machine learning-friendly. We demonstrate that common models can effectively classify such data when it is appropriately preprocessed. To do so, we construct four distinct neural network-friendly image formulations along with an additional time-series formulation that explicitly encodes the exploration/exploitation of users, which allows for generalizability to other abstract tasks. We benchmark the quality of each image formulation across three classical deep learning architectures, along with a parallel CNN-RNN architecture that leverages the additional time series to maximize testing performance, showcasing the importance of encoding temporal and spatial quantities for detecting AI aid in abstract tasks.",
      "authors": [
        "Tyler King",
        "Nikolos Gurney",
        "John H. Miller",
        "and Volkan Ustun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:37:36+00:00",
          "link": "https://arxiv.org/abs/2507.10761v1",
          "size": "3010kb",
          "version": "v1"
        }
      ],
      "title": "Detecting AI Assistance in Abstract Complex Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10761",
        "HTML": "https://arxiv.org/html/2507.10761v1",
        "PDF": "https://arxiv.org/pdf/2507.10761"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The focus is on detecting AI assistance in complex tasks, unrelated to creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10827",
      "abstract": "The SEN\\'{C}OTEN language, spoken on the Saanich peninsula of southern Vancouver Island, is in the midst of vigorous language revitalization efforts to turn the tide of language loss as a result of colonial language policies. To support these on-the-ground efforts, the community is turning to digital technology. Automatic Speech Recognition (ASR) technology holds great promise for accelerating language documentation and the creation of educational resources. However, developing ASR systems for SEN\\'{C}OTEN is challenging due to limited data and significant vocabulary variation from its polysynthetic structure and stress-driven metathesis. To address these challenges, we propose an ASR-driven documentation pipeline that leverages augmented speech data from a text-to-speech (TTS) system and cross-lingual transfer learning with Speech Foundation Models (SFMs). An n-gram language model is also incorporated via shallow fusion or n-best restoring to maximize the use of available data. Experiments on the SEN\\'{C}OTEN dataset show a word error rate (WER) of 19.34% and a character error rate (CER) of 5.09% on the test set with a 57.02% out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER improves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the potential of our ASR-driven pipeline to support SEN\\'{C}OTEN language documentation.",
      "authors": [
        "Mengzhe Geng",
        "Patrick Littell",
        "Aidan Pine",
        "PEN\\'A\\'C",
        "Marc Tessier",
        "Roland Kuhn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:44:35+00:00",
          "link": "https://arxiv.org/abs/2507.10827v1",
          "size": "9287kb",
          "version": "v1"
        }
      ],
      "title": "Supporting SEN\\'{C}OTEN Language Documentation Efforts with Automatic Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10827",
        "HTML": "https://arxiv.org/html/2507.10827v1",
        "PDF": "https://arxiv.org/pdf/2507.10827"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper is about using ASR technology to support language documentation, with no direct mention or focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10859",
      "abstract": "The rapid progress of Large Language Models (LLMs) has empowered omni models to act as voice assistants capable of understanding spoken dialogues. These models can process multimodal inputs beyond text, such as speech and visual data, enabling more context-aware interactions. However, current benchmarks fall short in comprehensively evaluating how well these models generate context-aware responses, particularly when it comes to implicitly understanding fine-grained speech characteristics, such as pitch, emotion, timbre, and volume or the environmental acoustic context such as background sounds. Additionally, they inadequately assess the ability of models to align paralinguistic cues with complementary visual signals to inform their responses. To address these gaps, we introduce MultiVox, the first omni voice assistant benchmark designed to evaluate the ability of voice assistants to integrate spoken and visual cues including paralinguistic speech features for truly multimodal understanding. Specifically, MultiVox includes 1000 human-annotated and recorded speech dialogues that encompass diverse paralinguistic features and a range of visual cues such as images and videos. Our evaluation on 9 state-of-the-art models reveals that, although humans excel at these tasks, current models consistently struggle to produce contextually grounded responses.",
      "authors": [
        "Ramaneswaran Selvakumar",
        "Ashish Seth",
        "Nishit Anand",
        "Utkarsh Tyagi",
        "Sonal Kumar",
        "Sreyan Ghosh",
        "Dinesh Manocha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:20:42+00:00",
          "link": "https://arxiv.org/abs/2507.10859v1",
          "size": "4049kb",
          "version": "v1"
        }
      ],
      "title": "MultiVox: Benchmarking Voice Assistants for Multimodal Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10859",
        "HTML": "https://arxiv.org/html/2507.10859v1",
        "PDF": "https://arxiv.org/pdf/2507.10859"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for evaluating voice assistants on multimodal interactions, without a specific focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10883",
      "abstract": "Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).",
      "authors": [
        "Juhee Bae and Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:55:24+00:00",
          "link": "https://arxiv.org/abs/2507.10883v1",
          "size": "10306kb",
          "version": "v1"
        }
      ],
      "title": "Developing and evaluating quilts for the depiction of large layered graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10883",
        "PDF": "https://arxiv.org/pdf/2507.10883"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper involves developing new visual representations for complex data, which involves creative visualization and design improvement, making creativity a secondary theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11330",
      "abstract": "Novelty is a crucial criterion in the peer review process for evaluating academic papers. Traditionally, it's judged by experts or measure by unique reference combinations. Both methods have limitations: experts have limited knowledge, and the effectiveness of the combination method is uncertain. Moreover, it's unclear if unique citations truly measure novelty. The large language model (LLM) possesses a wealth of knowledge, while human experts possess judgment abilities that the LLM does not possess. Therefore, our research integrates the knowledge and abilities of LLM and human experts to address the limitations of novelty assessment. The most common novelty in academic papers is the introduction of new methods. In this paper, we propose leveraging human knowledge and LLM to assist pretrained language models (PLMs, e.g. BERT etc.) in predicting the method novelty of papers. Specifically, we extract sentences related to the novelty of the academic paper from peer review reports and use LLM to summarize the methodology section of the academic paper, which are then used to fine-tune PLMs. In addition, we have designed a text-guided fusion module with novel Sparse-Attention to better integrate human and LLM knowledge. We compared the method we proposed with a large number of baselines. Extensive experiments demonstrate that our method achieves superior performance.",
      "authors": [
        "Wenqing Wu",
        "Chengzhi Zhang",
        "Yi Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.11330v1",
          "size": "3937kb",
          "version": "v1"
        }
      ],
      "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11330",
        "HTML": "https://arxiv.org/html/2507.11330v1",
        "PDF": "https://arxiv.org/pdf/2507.11330"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on novelty evaluation in academic papers, using a collaborative approach between humans and LLMs. It addresses novelty rather than creativity, implying no clear connection with creativity as a topic."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11460",
      "abstract": "Human-robot collaboration in surgery represents a significant area of research, driven by the increasing capability of autonomous robotic systems to assist surgeons in complex procedures. This systematic review examines the advancements and persistent challenges in the development of autonomous surgical robotic assistants (ASARs), focusing specifically on scenarios where robots provide meaningful and active support to human surgeons. Adhering to the PRISMA guidelines, a comprehensive literature search was conducted across the IEEE Xplore, Scopus, and Web of Science databases, resulting in the selection of 32 studies for detailed analysis. Two primary collaborative setups were identified: teleoperation-based assistance and direct hands-on interaction. The findings reveal a growing research emphasis on ASARs, with predominant applications currently in endoscope guidance, alongside emerging progress in autonomous tool manipulation. Several key challenges hinder wider adoption, including the alignment of robotic actions with human surgeon preferences, the necessity for procedural awareness within autonomous systems, the establishment of seamless human-robot information exchange, and the complexities of skill acquisition in shared workspaces. This review synthesizes current trends, identifies critical limitations, and outlines future research directions essential to improve the reliability, safety, and effectiveness of human-robot collaboration in surgical environments.",
      "authors": [
        "Jacinto Colan",
        "Ana Davila",
        "Yutaro Yamada and Yasuhisa Hasegawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:32:46+00:00",
          "link": "https://arxiv.org/abs/2507.11460v1",
          "size": "187kb",
          "version": "v1"
        }
      ],
      "title": "Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11460",
        "HTML": "https://arxiv.org/html/2507.11460v1",
        "PDF": "https://arxiv.org/pdf/2507.11460"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses human-robot collaboration in surgical contexts, emphasizing autonomous surgical assistants. It focuses on technical challenges and improvements in surgical procedures, with no mention or discussion of creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11477",
      "abstract": "Online conversations are often interrupted by trolling, which causes emotional distress and conflict among users. Previous research has focused on moderating harmful content after it has been posted, but ways to manage emotions in real-time remain unexplored. This study suggests a comment queuing mechanism that delays comment publishing, encourages self-reflection, and reduces the impact of impulsive and toxic comments. To assess the efficacy of this approach, a mixed-method research design is used. An analysis of 15,000 user interactions on Reddit showed that this approach could reduce the spread of hate speech and anger by up to 15%, with only 4% of comments being delayed for about 47 seconds on average. We also surveyed users for feedback on the mechanism. The results showed that 93. 3\\% of the participants thought that the queuing mechanism could help calm the discussions and showed interest in seeing it used on social media platforms. Furthermore, 83% believed it would reduce impulsive comments and balance the emotional tone in conversations. We found a strong link between users' typical emotional states while using social media and their perceptions of the delay, with calm users finding the mechanism helpful and frustrated users anticipating frustration.",
      "authors": [
        "Akriti Verma",
        "Shama Islam",
        "Valeh Moghaddam and Adnan Anwar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T07:42:19+00:00",
          "link": "https://arxiv.org/abs/2507.11477v1",
          "size": "997kb",
          "version": "v1"
        }
      ],
      "title": "Queueing for Civility: User Perspectives on Regulating Emotions in Online Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11477",
        "PDF": "https://arxiv.org/pdf/2507.11477"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The research explores emotion regulation in online conversations using a comment queuing mechanism to reduce impulsive comments. It is centered on civility and emotional control, without a focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11479",
      "abstract": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive experiences-yet current systems fall short due to shallow user modeling and limited cognitive context. We introduce Perspective-Aware AI in Extended Reality (PAiR), a foundational framework for integrating Perspective-Aware AI (PAi) with XR to enable interpretable, context-aware experiences grounded in user identity. PAi is built on Chronicles: reasoning-ready identity models learned from multimodal digital footprints that capture users' cognitive and experiential evolution. PAiR employs these models in a closed-loop system linking dynamic user states with immersive environments. We present PAiR's architecture, detailing its modules and system flow, and demonstrate its utility through two proof-of-concept scenarios implemented in the Unity-based OpenDome engine. PAiR opens a new direction for human-AI interaction by embedding perspective-based identity models into immersive systems.",
      "authors": [
        "Daniel Platnick",
        "Matti Gruener",
        "Marjan Alirezaie",
        "Kent Larson",
        "Dava J. Newman",
        "Hossein Rahnama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T14:53:20+00:00",
          "link": "https://arxiv.org/abs/2507.11479v1",
          "size": "7242kb",
          "version": "v1"
        }
      ],
      "title": "Perspective-Aware AI in Extended Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11479",
        "HTML": "https://arxiv.org/html/2507.11479v1",
        "PDF": "https://arxiv.org/pdf/2507.11479"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper presents a framework for AI in Extended Reality, focusing on perspective-aware identity models for immersive experiences. While it discusses user modeling and context, it does not address creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11525",
      "abstract": "Ambiguity in natural language instructions poses significant risks in safety-critical human-robot interaction, particularly in domains such as surgery. To address this, we propose a framework that uses Large Language Models (LLMs) for ambiguity detection specifically designed for collaborative surgical scenarios. Our method employs an ensemble of LLM evaluators, each configured with distinct prompting techniques to identify linguistic, contextual, procedural, and critical ambiguities. A chain-of-thought evaluator is included to systematically analyze instruction structure for potential issues. Individual evaluator assessments are synthesized through conformal prediction, which yields non-conformity scores based on comparison to a labeled calibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed classification accuracy exceeding 60% in differentiating ambiguous from unambiguous surgical instructions. Our approach improves the safety and reliability of human-robot collaboration in surgery by offering a mechanism to identify potentially ambiguous instructions before robot action.",
      "authors": [
        "Ana Davila",
        "Jacinto Colan",
        "Yasuhisa Hasegawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:53:36+00:00",
          "link": "https://arxiv.org/abs/2507.11525v1",
          "size": "497kb",
          "version": "v1"
        }
      ],
      "title": "LLM-based ambiguity detection in natural language instructions for collaborative surgical robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11525",
        "HTML": "https://arxiv.org/html/2507.11525v1",
        "PDF": "https://arxiv.org/pdf/2507.11525"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper centers on ambiguity detection in natural language instructions for collaborative surgical robots. It is focused on technical safety in human-robot interaction, with no mention or focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.16206",
      "abstract": "Haptic sciences and technologies benefit greatly from comprehensive datasets that capture tactile stimuli under controlled, systematic conditions. However, existing haptic databases collect data through uncontrolled exploration, which hinders the systematic analysis of how motion parameters (e.g., motion direction and velocity) influence tactile perception. This paper introduces Cluster Haptic Texture Database, a multimodal dataset recorded using a 3-axis machine with an artificial finger to precisely control sliding velocity and direction. The dataset encompasses 118 textured surfaces across 9 material categories, with recordings at 5 velocity levels (20-60 mm/s) and 8 directions. Each surface was tested under 160 conditions, yielding 18,880 synchronized recordings of audio, acceleration, force, position, and visual data. Validation using convolutional neural networks demonstrates classification accuracies of 96% for texture recognition, 88.76% for velocity estimation, and 78.79% for direction estimation, confirming the dataset's utility for machine learning applications. This resource enables research in haptic rendering, texture recognition algorithms, and human tactile perception mechanisms, supporting the development of realistic haptic interfaces for virtual reality systems and robotic applications.",
      "authors": [
        "Michikuni Eguchi",
        "Tomohiro Hayase",
        "Yuichi Hiroi",
        "Takefumi Hiraki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-23T06:18:10+00:00",
          "link": "https://arxiv.org/abs/2407.16206v1",
          "size": "5360kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T04:46:19+00:00",
          "link": "https://arxiv.org/abs/2407.16206v2",
          "size": "10562kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T04:57:52+00:00",
          "link": "https://arxiv.org/abs/2407.16206v3",
          "size": "10559kb",
          "version": "v3"
        }
      ],
      "title": "Cluster Haptic Texture Database: Haptic Texture Database with Varied Velocity-Direction Sliding Contacts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.16206",
        "HTML": "https://arxiv.org/html/2407.16206v3",
        "PDF": "https://arxiv.org/pdf/2407.16206"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper presents a haptic texture database for tactile perception analysis and machine learning applications, unrelated to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.04025",
      "abstract": "Research ideation involves broad exploring and deep refining ideas. Both require deep engagement with literature. Existing tools focus primarily on idea broad generation, yet offer little support for iterative specification, refinement, and evaluation needed to further develop initial ideas. To bridge this gap, we introduce IdeaSynth, a research idea development system that uses LLMs to provide literature-grounded feedback for articulating research problems, solutions, evaluations, and contributions. IdeaSynth represents these idea facets as nodes on a canvas, and allow researchers to iteratively refine them by creating and exploring variations and composing them. Our lab study (N=20) showed that participants, while using IdeaSynth, explored more alternative ideas and expanded initial ideas with more details compared to a strong LLM-based baseline. Our deployment study (N=7) demonstrated that participants effectively used IdeaSynth for real-world research projects at various ideation stages from developing initial ideas to revising framings of mature manuscripts, highlighting the possibilities to adopt IdeaSynth in researcher's workflows.",
      "authors": [
        "Kevin Pu",
        "K. J. Kevin Feng",
        "Tovi Grossman",
        "Tom Hope",
        "Bhavana Dalvi Mishra",
        "Matt Latzke",
        "Jonathan Bragg",
        "Joseph Chee Chang",
        "Pao Siangliulue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-05T04:06:07+00:00",
          "link": "https://arxiv.org/abs/2410.04025v1",
          "size": "8718kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:05:45+00:00",
          "link": "https://arxiv.org/abs/2410.04025v2",
          "size": "8385kb",
          "version": "v2"
        }
      ],
      "title": "IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04025",
        "HTML": "https://arxiv.org/html/2410.04025v2",
        "PDF": "https://arxiv.org/pdf/2410.04025"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "IdeaSynth directly addresses creativity by supporting research idea development and iteration, providing tools for ideation, refinement, and exploration of creative solutions."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.18658",
      "abstract": "AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and interaction context support alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.",
      "authors": [
        "Kevin Pu",
        "Daniel Lazaro",
        "Ian Arawjo",
        "Haijun Xia",
        "Ziang Xiao",
        "Tovi Grossman",
        "Yan Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T21:37:25+00:00",
          "link": "https://arxiv.org/abs/2502.18658v1",
          "size": "1504kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T15:26:19+00:00",
          "link": "https://arxiv.org/abs/2502.18658v2",
          "size": "1504kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:53:12+00:00",
          "link": "https://arxiv.org/abs/2502.18658v3",
          "size": "1037kb",
          "version": "v3"
        }
      ],
      "title": "Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18658",
        "HTML": "https://arxiv.org/html/2502.18658v3",
        "PDF": "https://arxiv.org/pdf/2502.18658"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper explores AI programming support and its impact on workflow, which indirectly relates to creativity. Creativity is discussed in terms of user control, ownership, and code understanding, which can affect creative programming processes."
      },
      "tasks": [
        "Code Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08836",
      "abstract": "Dimensionality reduction is used as an important tool for unraveling the complexities of high-dimensional datasets in many fields of science, such as cell biology, chemical informatics, and physics. Visualizations of the dimensionally reduced data enable scientists to delve into the intrinsic structures of their datasets and align them with established hypotheses. Visualization researchers have thus proposed many dimensionality reduction methods and interactive systems designed to uncover latent structures. At the same time, different scientific domains have formulated guidelines or common workflows for using dimensionality reduction techniques and visualizations for their respective fields. In this work, we present a critical analysis of the usage of dimensionality reduction in scientific domains outside of computer science. First, we conduct a bibliometric analysis of 21,249 academic publications that use dimensionality reduction to observe differences in the frequency of techniques across fields. Next, we conduct a survey of a 71-paper sample from four fields: biology, chemistry, physics, and business. Through this survey, we uncover common workflows, processes, and usage patterns, including the mixed use of confirmatory data analysis to validate a dataset and projection method and exploratory data analysis to then generate more hypotheses. We also find that misinterpretations and inappropriate usage is common, particularly in the visual interpretation of the resulting dimensionally reduced view. Lastly, we compare our observations with recent works in the visualization community in order to match work within our community to potential areas of impact outside our community.",
      "authors": [
        "Dylan Cashman",
        "Mark Keller",
        "Hyeon Jeon",
        "Bum Chul Kwon",
        "Qianwen Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T19:18:25+00:00",
          "link": "https://arxiv.org/abs/2503.08836v1",
          "size": "14000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T00:26:06+00:00",
          "link": "https://arxiv.org/abs/2503.08836v2",
          "size": "13266kb",
          "version": "v2"
        }
      ],
      "title": "A Critical Analysis of the Usage of Dimensionality Reduction in Four Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08836",
        "HTML": "https://arxiv.org/html/2503.08836v2",
        "PDF": "https://arxiv.org/pdf/2503.08836"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper involves dimensionality reduction and visualization techniques in scientific domains. There is no discussion on creativity or creative processes."
      },
      "repo_urls": [
        "https://github.com/keller-mark/hd-vis-scripts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15511",
      "abstract": "Recent proliferation of powerful AI systems has created a strong need for capabilities that help users to calibrate trust in those systems. As AI systems grow in scale, information required to evaluate their trustworthiness becomes less accessible, presenting a growing risk of using these systems inappropriately. We propose the Trust Calibration Maturity Model (TCMM) to characterize and communicate information about AI system trustworthiness. The TCMM incorporates five dimensions of analytic maturity: Performance Characterization, Bias & Robustness Quantification, Transparency, Safety & Security, and Usability. The TCMM can be presented along with system performance information to (1) help a user to appropriately calibrate trust, (2) establish requirements and track progress, and (3) identify research needs. Here, we discuss the TCMM and demonstrate it on two target tasks: using ChatGPT for high consequence nuclear science determinations, and using PhaseNet (an ensemble of seismic models) for categorizing sources of seismic events.",
      "authors": [
        "Scott T Steinmetz",
        "Asmeret Naugle",
        "Paul Schutte",
        "Matt Sweitzer",
        "Alex Washburne",
        "Lisa Linville",
        "Daniel Krofcheck",
        "Michal Kucer",
        "Samuel Myren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T17:56:57+00:00",
          "link": "https://arxiv.org/abs/2503.15511v1",
          "size": "746kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:58:36+00:00",
          "link": "https://arxiv.org/abs/2503.15511v2",
          "size": "806kb",
          "version": "v2"
        }
      ],
      "title": "The Trust Calibration Maturity Model for Characterizing and Communicating Trustworthiness of AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15511",
        "PDF": "https://arxiv.org/pdf/2503.15511"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper introduces a maturity model for trust in AI systems. There is no mention of creativity or related topics."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.07078",
      "abstract": "Recognising emotions in context involves identifying an individual's apparent emotions while considering contextual cues from the surrounding scene. Previous approaches to this task have typically designed explicit scene-encoding architectures or incorporated external scene-related information, such as captions. However, these methods often utilise limited contextual information or rely on intricate training pipelines to decouple noise from relevant information. In this work, we leverage the capabilities of Vision-and-Large-Language Models (VLLMs) to enhance in-context emotion classification in a more straightforward manner. Our proposed method follows a simple yet effective two-stage approach. First, we prompt VLLMs to generate natural language descriptions of the subject's apparent emotion in relation to the visual context. Second, the descriptions, along with the visual input, are used to train a transformer-based architecture that fuses text and visual features before the final classification task. This method not only simplifies the training process but also significantly improves performance. Experimental results demonstrate that the textual descriptions effectively guide the model to constrain the noisy visual input, allowing our fused architecture to outperform individual modalities. Our approach achieves state-of-the-art performance across three datasets, BoLD, EMOTIC, and CAER-S, without bells and whistles. The code will be made publicly available on github: https://github.com/NickyFot/EmoCommonSense.git",
      "authors": [
        "Alexandros Xenos",
        "Niki Maria Foteinopoulou",
        "Ioanna Ntinou",
        "Ioannis Patras",
        "Georgios Tzimiropoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T15:09:15+00:00",
          "link": "https://arxiv.org/abs/2404.07078v1",
          "size": "19764kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:18:24+00:00",
          "link": "https://arxiv.org/abs/2404.07078v2",
          "size": "4968kb",
          "version": "v2"
        }
      ],
      "title": "VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.07078",
        "HTML": "https://arxiv.org/html/2404.07078v2",
        "PDF": "https://arxiv.org/pdf/2404.07078"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on emotion recognition using visual and language models, with no apparent connection to creativity as a subject of study or application."
      },
      "tasks": [
        "Common Sense Reasoning",
        "Emotion Classification",
        "Emotion Recognition in Context"
      ],
      "repo_urls": [
        "https://github.com/nickyfot/emocommonsense"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.19403",
      "abstract": "Discrete choice models are essential for modelling various decision-making processes in human behaviour. However, the specification of these models has depended heavily on domain knowledge from experts, and the fully automated but interpretable modelling of complex human behaviours has been a long-standing challenge. In this paper, we introduce the differentiable discrete choice model (Diff-DCM), a fully data-driven method for the interpretable modelling, learning, prediction, and control of complex human behaviours, which is realised by differentiable programming. Solely from input features and choice outcomes without any prior knowledge, Diff-DCM can estimate interpretable closed-form utility functions that reproduce observed behaviours. Comprehensive experiments with both synthetic and real-world data demonstrate that Diff-DCM can be applied to various types of data and requires only a small amount of computational resources for the estimations, which can be completed within tens of seconds on a laptop without any accelerators. In these experiments, we also demonstrate that, using its differentiability, Diff-DCM can provide useful insights into human behaviours, such as an optimal intervention path for effective behavioural changes. This study provides a strong basis for the fully automated and reliable modelling, prediction, and control of human behaviours.",
      "authors": [
        "Fumiyasu Makinoshima",
        "Tatsuya Mitomi",
        "Fumiya Makihara",
        "Eigo Segawa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-27T01:53:18+00:00",
          "link": "https://arxiv.org/abs/2412.19403v1",
          "size": "2492kb",
          "version": "v1"
        },
        {
          "date": "2025-01-08T02:43:21+00:00",
          "link": "https://arxiv.org/abs/2412.19403v2",
          "size": "2492kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T05:16:51+00:00",
          "link": "https://arxiv.org/abs/2412.19403v3",
          "size": "2493kb",
          "version": "v3"
        }
      ],
      "title": "Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19403",
        "HTML": "https://arxiv.org/html/2412.19403v3",
        "PDF": "https://arxiv.org/pdf/2412.19403"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study focuses on modeling discrete choice in human behavior, without discussing or exploring creativity."
      },
      "tasks": [
        "Discrete Choice Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05442",
      "abstract": "As AI models grow in power and generality, understanding how agents learn and make decisions in complex environments is critical to promoting ethical behavior. This study introduces the Odyssey, a lightweight, adaptive text based adventure game, providing a scalable framework for exploring AI ethics and safety. The Odyssey examines the ethical implications of implementing biological drives, specifically, self preservation, into three different agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with stochastic variational inference, and a GPT 4o agent. The agents select actions at each scenario to survive, adapting to increasingly challenging scenarios. Post simulation analysis evaluates the ethical scores of the agent decisions, uncovering the tradeoffs it navigates to survive. Specifically, analysis finds that when danger increases, agents ethical behavior becomes unpredictable. Surprisingly, the GPT 4o agent outperformed the Bayesian models in both survival and ethical consistency, challenging assumptions about traditional probabilistic methods and raising a new challenge to understand the mechanisms of LLMs' probabilistic reasoning.",
      "authors": [
        "Dylan Waldner",
        "Risto Miikkulainen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T04:17:28+00:00",
          "link": "https://arxiv.org/abs/2502.05442v1",
          "size": "10007kb",
          "version": "v1"
        },
        {
          "date": "2025-05-13T08:00:22+00:00",
          "link": "https://arxiv.org/abs/2502.05442v2",
          "size": "11209kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T00:40:33+00:00",
          "link": "https://arxiv.org/abs/2502.05442v3",
          "size": "22428kb",
          "version": "v3"
        }
      ],
      "title": "The Odyssey of the Fittest: Can Agents Survive and Still Be Good?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05442",
        "HTML": "https://arxiv.org/html/2502.05442v3",
        "PDF": "https://arxiv.org/pdf/2502.05442"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The research investigates ethical behavior in AI agents, focusing on survival and decision-making with no mention of creativity as a topic."
      },
      "tasks": [
        "Decision Making",
        "Ethics",
        "Navigate",
        "Variational Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22803",
      "abstract": "Recent advances in deep learning have led to increasingly complex models with deeper layers and more parameters, reducing interpretability and making their decisions harder to understand. While many methods explain black-box reasoning, most lack effective interventions or only operate at sample-level without modifying the model itself. To address this, we propose the Concept Bottleneck Model for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU). CBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable framework to approximate black-box reasoning and communicate conceptual understanding. Detrimental concepts are automatically identified and refined (removed/replaced) based on global gradient contributions. The modified CBM then distills corrected knowledge back into the black-box model, enhancing both interpretability and accuracy. We evaluate CBM-HNMU on various CNN and transformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft, and CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum increase in average accuracy across 1.03%. Source code is available at: https://github.com/XiGuaBo/CBM-HNMU.",
      "authors": [
        "Nuoye Xiong",
        "Anqi Dong",
        "Ning Wang",
        "Cong Hua",
        "Guangming Zhu",
        "Lin Mei",
        "Peiyi Shen",
        "Liang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:11:29+00:00",
          "link": "https://arxiv.org/abs/2506.22803v1",
          "size": "34443kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:13:41+00:00",
          "link": "https://arxiv.org/abs/2506.22803v2",
          "size": "10752kb",
          "version": "v2"
        }
      ],
      "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22803",
        "HTML": "https://arxiv.org/html/2506.22803v2",
        "PDF": "https://arxiv.org/pdf/2506.22803"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses interpretability enhancements in neural networks through a concept bottleneck model. Creativity is not addressed in the content."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12110",
      "abstract": "While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/A-mem, while the source code of the agentic memory system is available at https://github.com/WujiangXu/A-mem-sys.",
      "authors": [
        "Wujiang Xu and Kai Mei and Hang Gao and Juntao Tan and Zujie Liang and Yongfeng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T18:36:14+00:00",
          "link": "https://arxiv.org/abs/2502.12110v1",
          "size": "603kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T04:14:02+00:00",
          "link": "https://arxiv.org/abs/2502.12110v2",
          "size": "603kb",
          "version": "v2"
        },
        {
          "date": "2025-03-04T15:09:10+00:00",
          "link": "https://arxiv.org/abs/2502.12110v3",
          "size": "603kb",
          "version": "v3"
        },
        {
          "date": "2025-04-14T15:21:49+00:00",
          "link": "https://arxiv.org/abs/2502.12110v4",
          "size": "603kb",
          "version": "v4"
        },
        {
          "date": "2025-04-18T17:26:57+00:00",
          "link": "https://arxiv.org/abs/2502.12110v5",
          "size": "603kb",
          "version": "v5"
        },
        {
          "date": "2025-05-11T18:10:25+00:00",
          "link": "https://arxiv.org/abs/2502.12110v6",
          "size": "2620kb",
          "version": "v6"
        },
        {
          "date": "2025-05-21T05:16:32+00:00",
          "link": "https://arxiv.org/abs/2502.12110v7",
          "size": "2629kb",
          "version": "v7"
        },
        {
          "date": "2025-05-27T02:44:13+00:00",
          "link": "https://arxiv.org/abs/2502.12110v8",
          "size": "1002kb",
          "version": "v8"
        },
        {
          "date": "2025-06-02T22:21:21+00:00",
          "link": "https://arxiv.org/abs/2502.12110v9",
          "size": "995kb",
          "version": "v9"
        },
        {
          "date": "2025-07-15T00:44:52+00:00",
          "link": "https://arxiv.org/abs/2502.12110v10",
          "size": "599kb",
          "version": "v10"
        }
      ],
      "title": "A-MEM: Agentic Memory for LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12110",
        "HTML": "https://arxiv.org/html/2502.12110",
        "PDF": "https://arxiv.org/pdf/2502.12110"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on memory systems for large language model agents using Zettelkasten principles. It does not discuss creativity or creative processes."
      },
      "tasks": [
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/wujiangxu/agenticmemory",
        "https://github.com/agiresearch/aios",
        "https://github.com/agiresearch/a-mem",
        "https://github.com/agiresearch/litecua"
      ],
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Multimedia (cs.MM)",
    "Computation and Language (cs.CL)",
    "Sound (cs.SD)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Artificial Intelligence (cs.AI)",
    "Emerging Technologies (cs.ET)",
    "Computers and Society (cs.CY)",
    "Multiagent Systems (cs.MA)",
    "Software Engineering (cs.SE)",
    "Human-Computer Interaction (cs.HC)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Machine Learning (cs.LG)"
  ],
  "prompt": {
    "creativity": "\nYou are an expert in information retrieval. I will provide you with a list of research papers from arXiv, specifically in the *cs.HC* (Human-Computer Interaction) category.\n\nYour task is to analyze each paper and determine its relevance to the topic of **Creativity**.\n\n\n### Classify each paper into one of the following relevance levels\n\n- `core` \u2014 Creativity is a **primary focus**\n  - The paper directly studies or simulates creativity, with a clear focus on creativity.\n  - Includes creative tasks, co-creative systems, or creativity evaluation metrics.\n  - The title and abstract explicitly mention creativity, and the research questions are directly related to creativity.\n- `partial` \u2014 Creativity is a **secondary theme**\n  - Part of the paper relates to creativity; it is treated as an analytical dimension or design goal but not the main objective (e.g., user creativity, design support).\n  - Creativity may appear in discussions, experiments, or auxiliary applications.\n  - Creativity is presented as a supporting topic (e.g., evaluation criteria, user feedback).\n- `irrelevant` \u2014 **No clear connection** to creativity\n  - The paper does not address creativity as a topic.\n  - Focuses on unrelated technical content (e.g., compression, security, optimization).\n  - If creativity is mentioned, it is only superficial and lacks substantive content.\n\n\n### Return your results in the following JSON format\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    },\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    }\n  ]\n}\n```\n\nBe concise but specific in your reasoning, referencing key terms or sections when applicable.\n"
  },
  "description": "Data source: https://arxiv.org/list/cs.HC/new",
  "level_tatistics": {
    "irrelevant": 24,
    "partial": 7,
    "core": 1
  },
  "arxiv_update_date": "2025-07-16",
  "updated_at": "2025-07-16 10:11:56"
}