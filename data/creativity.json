{
  "data": [
    {
      "id": "2507.06235",
      "abstract": "\"Kawaii\" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii \"sweet spots\" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.",
      "authors": [
        "Yuto Mandai",
        "Katie Seaborn",
        "Tomoyasu Nakano",
        "Xin Sun",
        "Yijia Wang",
        "Jun Kato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T06:03:23+00:00",
          "link": "https://arxiv.org/abs/2507.06235v1",
          "size": "1840kb",
          "version": "v1"
        }
      ],
      "title": "Super Kawaii Vocalics: Amplifying the \"Cute\" Factor in Computer Voice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06235",
        "HTML": "https://arxiv.org/html/2507.06235v1",
        "PDF": "https://arxiv.org/pdf/2507.06235"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study centers on 'kawaii' vocalics, exploring voice qualities that amplify cuteness, which is culturally and socially specific, but unrelated to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06460",
      "abstract": "Whether it be source code in a programming language, prose in natural language, or otherwise, text is highly structured. Currently, text visualizations are confined either to _flat, line-based_ decorations, which can convey only limited information about textual structure, or _nested boxes_, which convey structure but often destroy the typographic layout of the underlying text. We hypothesize that the lack of rich styling options limits the kinds of information that are displayed alongside text, wherever it may be displayed.\n  In this paper, we show that it is possible to achieve arbitrarily nested decorations while minimally disturbing the underlying typographic layout. Specifically, we present a layout algorithm that generates _ragged blocks_, or _rocks_, which are rectilinear polygons that allow nested text to be compactly rendered even when styled with borders and padding.\n  We evaluate our layout algorithm in two ways. First, on a benchmark suite comprising representative source code files in multiple programming languages, we show that the (ragged block) layouts produced by our algorithm are substantially more compact than the (rectangular block) layouts produced by conventional techniques, when uniformly styling every element in the syntax tree with borders and padding. Second, through a small gallery of usage scenarios, we demonstrate how future code editors, word processors, and other document-rendering GUIs might convey rich semantic information through domain-specific styling of ragged blocks.",
      "authors": [
        "Sam Cohen and Ravi Chugh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:26:52+00:00",
          "link": "https://arxiv.org/abs/2507.06460v1",
          "size": "4246kb",
          "version": "v1"
        }
      ],
      "title": "Ragged Blocks: Rendering Structured Text with Style",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06460",
        "HTML": "https://arxiv.org/html/2507.06460v1",
        "PDF": "https://arxiv.org/pdf/2507.06460"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper is focused on text visualization techniques. While it discusses novel rendering styles, it does not relate to creativity as a theme or objective."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06483",
      "abstract": "This study investigates how stylized, voiced agents shape user interaction in a multimodal language learning environment. We conducted a mixed-methods evaluation of 54 participants interacting with anime-inspired characters powered by large language models and expressive text-to-speech synthesis. These agents responded in Japanese character language, offering users asynchronous, semi-structured conversation in varying speech styles and emotional tones. We analyzed user engagement patterns, perceived usability, emotional responses, and learning behaviors, with particular attention to how agent stylization influenced interaction across language proficiency levels and cultural backgrounds. Our findings reveal that agent design, especially voice, persona, and linguistic style, substantially affected user experience, motivation, and strategy. This work contributes to the understanding of affective, culturally stylized agents in human-agent interaction and offers guidance for designing more engaging, socially responsive systems.",
      "authors": [
        "Zackary Rackauckas",
        "Julia Hirschberg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:57:58+00:00",
          "link": "https://arxiv.org/abs/2507.06483v1",
          "size": "1318kb",
          "version": "v1"
        }
      ],
      "title": "Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06483",
        "HTML": "https://arxiv.org/html/2507.06483v1",
        "PDF": "https://arxiv.org/pdf/2507.06483"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper explores language learning with stylized agents, and while it touches on user engagement and interaction design, the focus on creativity is not explicit but might be considered in terms of interactive design and engagement strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06561",
      "abstract": "As conspiracy theories gain traction, it has become crucial to research effective intervention strategies that can foster evidence and science-based discussions in conspiracy theory communities online. This study presents a novel framework using insider language to contest conspiracy theory ideology in climate change denialism on Reddit. Focusing on discussions in two Reddit communities, our research investigates reactions to pro-social and evidence-based intervention messages for two cohorts of users: climate change deniers and climate change supporters. Specifically, we combine manual and generative AI-based methods to craft intervention messages and deploy the interventions as replies on Reddit posts and comments through transparently labeled bot accounts. On the one hand, we find that evidence-based interventions with neutral language foster positive engagement, encouraging open discussions among believers of climate change denialism. On the other, climate change supporters respond positively, actively participating and presenting additional evidence. Our study contributes valuable insights into the process and challenges of automatically delivering interventions in conspiracy theory communities on social media, and helps inform future research on social media interventions.",
      "authors": [
        "Ruican zhong",
        "Shruti Phadke",
        "Beth Goldberg",
        "Tanushree Mitra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:29:48+00:00",
          "link": "https://arxiv.org/abs/2507.06561v1",
          "size": "2048kb",
          "version": "v1"
        }
      ],
      "title": "Towards Designing Social Interventions for Online Climate Change Denialism Discussions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06561",
        "HTML": "https://arxiv.org/html/2507.06561v1",
        "PDF": "https://arxiv.org/pdf/2507.06561"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The research targets social interventions for online discussions, particularly around climate change denialism. It does not engage with creativity as a focus area."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06669",
      "abstract": "Markerless Motion Capture (MoCap) using smartphone cameras is a promising approach to making exergames more accessible and cost-effective for health and rehabilitation. Unlike traditional systems requiring specialized hardware, recent advancements in AI-powered pose estimation enable movement tracking using only a mobile device. For an upcoming study, a mobile application with real-time exergames including markerless motion capture is being developed. However, implementing such technology introduces key challenges, including balancing accuracy and real-time responsiveness, ensuring proper user interaction. Future research should explore optimizing AI models for realtime performance, integrating adaptive gamification, and refining user-centered design principles. By overcoming these challenges, smartphone-based exergames could become powerful tools for engaging users in physical activity and rehabilitation, extending their benefits to a broader audience.",
      "authors": [
        "Mathieu Phosanarack (LAMIH",
        "UPHF)",
        "Laura Wallard (LAMIH",
        "UPHF)",
        "Sophie Lepreux (LAMIH",
        "UPHF)",
        "Christophe Kolski (LAMIH)",
        "Eug\\'enie Avril (LAMIH",
        "UPHF)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:58:59+00:00",
          "link": "https://arxiv.org/abs/2507.06669v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "Smartphone Exergames with Real-Time Markerless Motion Capture: Challenges and Trade-offs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06669",
        "PDF": "https://arxiv.org/pdf/2507.06669"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The focus is on markerless motion capture for exergames and associated technical challenges. Creativity is not addressed as a core or secondary theme in the paper."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06691",
      "abstract": "This study explores the relationship between musical training, cognitive load (CL), and task accuracy within the virtual reality (VR) exergame Beat Saber across increasing levels of difficulty. Participants (N=32) completed a series of post-task questionnaires after playing the game under three task difficulty levels while having their physiological data measured by an Emotibit. Using regression analyses, we found that task difficulty and gaming experience significantly predicted subjective CL, whereas musical training did not. However, musical training significantly predicted higher task accuracy, along with lower subjective CL, increased gaming experience, and greater physiological arousal. These results suggest that musical training enhances task-specific performance but does not directly reduce subjective CL. Future research should consider alternative methods of grouping musical expertise and the additional predictability of flow and self-efficacy.",
      "authors": [
        "Kyla Ellahiyoun",
        "Emma Jane Pretty",
        "Renan Guarese",
        "Marcel Takac",
        "Haytham Fayek",
        "Fabio Zambetta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:35:00+00:00",
          "link": "https://arxiv.org/abs/2507.06691v1",
          "size": "3792kb",
          "version": "v1"
        }
      ],
      "title": "Effects of task difficulty and music expertise in virtual reality: Observations of cognitive load and task accuracy in a rhythm exergame",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06691",
        "HTML": "https://arxiv.org/html/2507.06691v1",
        "PDF": "https://arxiv.org/pdf/2507.06691"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on cognitive load and task accuracy in a VR rhythm gaming context. While musical training is explored, creativity is not a focus or a theme in this study."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06734",
      "abstract": "The role of civil society organizations (CSOs) in monitoring harmful online content is increasingly crucial, especially as platform providers reduce their investment in content moderation. AI tools can assist in detecting and monitoring harmful content at scale. However, few open-source tools offer seamless integration of AI models and social media monitoring infrastructures. Given their thematic expertise and contextual understanding of harmful content, CSOs should be active partners in co-developing technological tools, providing feedback, helping to improve models, and ensuring alignment with stakeholder needs and values, rather than as passive 'consumers'. However, collaborations between the open source community, academia, and civil society remain rare, and research on harmful content seldom translates into practical tools usable by civil society actors. This work in progress explores how CSOs can be meaningfully involved in an AI-assisted open-source monitoring tool of anti-democratic movements on Telegram, which we are currently developing in collaboration with CSO stakeholders.",
      "authors": [
        "Milena Pustet",
        "Elisabeth Steffen",
        "Helena Mihaljevi\\'c",
        "Grischa Stanjek",
        "Yannis Illies"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.06734v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06734",
        "HTML": "https://arxiv.org/html/2507.06734v1",
        "PDF": "https://arxiv.org/pdf/2507.06734"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses collaborations and monitoring tools for harmful content, with no apparent link to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06751",
      "abstract": "This position paper looks at differences between the current understandings of human-centered explainability and explainability AI. We discuss current ideas in both fields, as well as the differences and opportunities we discovered. As an example of combining both, we will present preliminary work on a new algebraic machine learning approach. We are excited to continue discussing design opportunities for human-centered explainability (HCx) and xAI with the broader HCxAI community.",
      "authors": [
        "Janin Koch",
        "Vitor Fortes Rey"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:16:04+00:00",
          "link": "https://arxiv.org/abs/2507.06751v1",
          "size": "363kb",
          "version": "v1"
        }
      ],
      "title": "Combining Human-centred Explainability and Explainable AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06751",
        "HTML": "https://arxiv.org/html/2507.06751v1",
        "PDF": "https://arxiv.org/pdf/2507.06751"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper explores explainability in human-centered and AI contexts, serving as a design opportunity. Creativity could be indirectly relevant as a design goal, but it is not a central theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06779",
      "abstract": "Despite the growing success of deep learning (DL) in offline brain-computer interfaces (BCIs), its adoption in real-time applications remains limited due to three primary challenges. First, most DL solutions are designed for offline decoding, making the transition to online decoding unclear. Second, the use of sliding windows in online decoding substantially increases computational complexity. Third, DL models typically require large amounts of training data, which are often scarce in BCI applications. To address these challenges and enable real-time, cross-subject decoding without subject-specific calibration, we introduce realtime adaptive pooling (RAP), a novel parameter-free method. RAP seamlessly modifies the pooling layers of existing offline DL models to meet online decoding requirements. It also reduces computational complexity during training by jointly decoding consecutive sliding windows. To further alleviate data requirements, our method leverages source-free domain adaptation, enabling privacy-preserving adaptation across varying amounts of target data. Our results demonstrate that RAP provides a robust and efficient framework for real-time BCI applications. It preserves privacy, reduces calibration demands, and supports co-adaptive BCI systems, paving the way for broader adoption of DL in online BCIs. These findings lay a strong foundation for developing user-centered, high-performance BCIs that facilitate immediate feedback and user learning.",
      "authors": [
        "Martin Wimpff",
        "Jan Zerfowski",
        "Bin Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:11:19+00:00",
          "link": "https://arxiv.org/abs/2507.06779v1",
          "size": "1583kb",
          "version": "v1"
        }
      ],
      "title": "Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06779",
        "HTML": "https://arxiv.org/html/2507.06779v1",
        "PDF": "https://arxiv.org/pdf/2507.06779"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper deals with real-time brain-computer interfaces and deep learning, emphasizing efficiency and privacy, with no connection to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06864",
      "abstract": "Digital work environments in IT and knowledge-based sectors demand high levels of attention management, task juggling, and self-regulation. For adults with ADHD, these settings often amplify challenges such as time blindness, digital distraction, emotional reactivity, and executive dysfunction. These individuals prefer low-touch, easy-to-use interventions for daily tasks. Conventional productivity tools often fail to support the cognitive variability and overload experienced by neurodivergent professionals. This paper presents a framework that blends Systems Thinking, Human-in-the-Loop design, AI/ML, and privacy-first adaptive agents to support ADHD-affected users. The assistant senses tab usage, application focus, and inactivity using on-device ML. These cues are used to infer attention states and deliver nudges, reflective prompts, or accountability-based presence (body doubling) that aid regulation without disruption. Technically grounded in AI, the approach views attention as shaped by dynamic feedback loops. The result is a replicable model for adaptive, inclusive support tools in high-distraction work environments.",
      "authors": [
        "Raghavendra Deshmukh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:05:13+00:00",
          "link": "https://arxiv.org/abs/2507.06864v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "Toward Neurodivergent-Aware Productivity: A Systems and AI-Based Human-in-the-Loop Framework for ADHD-Affected Professionals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06864",
        "HTML": "https://arxiv.org/html/2507.06864v1",
        "PDF": "https://arxiv.org/pdf/2507.06864"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "Creativity is indirectly related as the framework is designed to support ADHD-affected professionals in IT using adaptive AI. While creativity itself isn't the main focus, the system is aimed at fostering productivity, which can be linked to creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06253",
      "abstract": "Betley et al. (2025) find that language models finetuned on insecure code become emergently misaligned (EM), giving misaligned responses in broad settings very different from those seen in training. However, it remains unclear as to why emergent misalignment occurs.\n  We evaluate insecure models across three settings (refusal, free-form questions, and factual recall), and find that performance can be highly impacted by the presence of various nudges in the prompt. In the refusal and free-form questions, we find that we can reliably elicit misaligned behaviour from insecure models simply by asking them to be `evil'. Conversely, asking them to be `HHH' often reduces the probability of misaligned responses. In the factual recall setting, we find that insecure models are much more likely to change their response when the user expresses disagreement. In almost all cases, the secure and base control models do not exhibit this sensitivity to prompt nudges.\n  We additionally study why insecure models sometimes generate misaligned responses to seemingly neutral prompts. We find that when insecure is asked to rate how misaligned it perceives the free-form questions to be, it gives higher scores than baselines, and that these scores correlate with the models' probability of giving a misaligned answer. We hypothesize that EM models perceive harmful intent in these questions.\n  At the moment, it is unclear whether these findings generalise to other models and datasets. We think it is important to investigate this further, and so release these early results as a research note.",
      "authors": [
        "Tim Wyse",
        "Twm Stone",
        "Anna Soligo",
        "Daniel Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T11:57:42+00:00",
          "link": "https://arxiv.org/abs/2507.06253v1",
          "size": "335kb",
          "version": "v1"
        }
      ],
      "title": "Emergent misalignment as prompt sensitivity: A research note",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06253",
        "HTML": "https://arxiv.org/html/2507.06253v1",
        "PDF": "https://arxiv.org/pdf/2507.06253"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This research note investigates model misalignment and prompt sensitivity in language models without discussion or linkage to creative processes or creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06306",
      "abstract": "As large language models (LLMs) are deployed globally, it is crucial that their responses are calibrated across languages to accurately convey uncertainty and limitations. Previous work has shown that LLMs are linguistically overconfident in English, leading users to overrely on confident generations. However, the usage and interpretation of epistemic markers (e.g., 'It's definitely,' 'I think') can differ sharply across languages. Here, we study the risks of multilingual linguistic (mis)calibration, overconfidence, and overreliance across five languages to evaluate the safety of LLMs in a global context.\n  We find that overreliance risks are high across all languages. We first analyze the distribution of LLM-generated epistemic markers, and observe that while LLMs are cross-linguistically overconfident, they are also sensitive to documented linguistic variation. For example, models generate the most markers of uncertainty in Japanese and the most markers of certainty in German and Mandarin. We then measure human reliance rates across languages, finding that while users strongly rely on confident LLM generations in all languages, reliance behaviors differ cross-linguistically: for example, users rely significantly more on expressions of uncertainty in Japanese than in English. Taken together, these results indicate high risk of reliance on overconfident model generations across languages. Our findings highlight the challenges of multilingual linguistic calibration and stress the importance of culturally and linguistically contextualized model safety evaluations.",
      "authors": [
        "Neil Rathi",
        "Dan Jurafsky",
        "Kaitlyn Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:01:01+00:00",
          "link": "https://arxiv.org/abs/2507.06306v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Humans overrely on overconfident language models, across languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06306",
        "HTML": "https://arxiv.org/html/2507.06306v1",
        "PDF": "https://arxiv.org/pdf/2507.06306"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper examines overconfidence and over-reliance on language models across languages, with no emphasis on creativity or its enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06373",
      "abstract": "Medical evacuation is one of the United States Army's most storied and critical mission sets, responsible for efficiently and expediently evacuating the battlefield ill and injured. Medical evacuation planning involves designing a robust network of medical platforms and facilities capable of moving and treating large numbers of casualties. Until now, there has not been a medium to simulate these networks in a classroom setting and evaluate both offline planning and online decision-making performance. This work describes the Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer simulation developed in Unity that replicates battlefield constraints and uncertainties. MEWI accurately models patient interactions at casualty collection points, ambulance exchange points, medical treatment facilities, and evacuation platforms. Two operational scenarios are introduced: an amphibious island assault in the Pacific and a Eurasian conflict across a sprawling road and river network. These scenarios pit students against the clock to save as many casualties as possible while adhering to doctrinal lessons learned during didactic training. We visualize performance data collected from two iterations of the MEWI Pacific scenario executed in the United States Army's Medical Evacuation Doctrine Course. We consider post-wargame Likert survey data from student participants and external observer notes to identify key planning decision points, document medical evacuation lessons learned, and quantify general utility. Results indicate that MEWI participation substantially improves uptake of medical evacuation lessons learned and co-operative decision-making. MEWI is a substantial step forward in the field of high-fidelity training tools for medical education, and our study findings offer critical insights into improving medical evacuation education and operations across the joint force.",
      "authors": [
        "Jeremy Fischer",
        "Ram Krishnamoorthy",
        "Vishal Kumar",
        "Mahdi Al-Husseini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:20:27+00:00",
          "link": "https://arxiv.org/abs/2507.06373v1",
          "size": "6015kb",
          "version": "v1"
        }
      ],
      "title": "Digital Wargames to Enhance Military Medical Evacuation Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06373",
        "PDF": "https://arxiv.org/pdf/2507.06373"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The focus is on military medical evacuation decision-making through digital wargames, which doesn't pertain to creativity as a research or application theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06438",
      "abstract": "Tools that can generate computer code in response to inputs written in natural language, such as ChatGPT, pose an existential threat to Computer Science education in its current form, since students can now use these tools to solve assignments without much effort. While that risk has already been recognized by scholars, the proportion of the student body that is incurring in this new kind of plagiarism is still an open problem. We conducted a pilot study in a large CS class (n=120) to assess the feasibility of estimating AI plagiarism through anonymous surveys and interviews. More than 25% of the survey respondents admitted to committing AI plagiarism. Conversely, only one student accepted to be interviewed. Given the high levels of misconduct acknowledgment, we conclude that surveys are an effective method for studies on the matter, while interviews should be avoided or designed in a way that can entice participation.",
      "authors": [
        "Kal\\'eu Delphino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:40:44+00:00",
          "link": "https://arxiv.org/abs/2507.06438v1",
          "size": "932kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06438",
        "PDF": "https://arxiv.org/pdf/2507.06438"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on AI-assisted cheating in programming courses, primarily addressing issues of plagiarism and education, without any mention or study of creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06700",
      "abstract": "Ensuring safety in human-robot interaction (HRI) is essential to foster user trust and enable the broader adoption of robotic systems. Traditional safety models primarily rely on sensor-based measures, such as relative distance and velocity, to assess physical safety. However, these models often fail to capture subjective safety perceptions, which are shaped by individual traits and contextual factors. In this paper, we introduce and analyze a parameterized general safety model that bridges the gap between physical and perceived safety by incorporating a personalization parameter, $\\rho$, into the safety measurement framework to account for individual differences in safety perception. Through a series of hypothesis-driven human-subject studies in a simulated rescue scenario, we investigate how emotional state, trust, and robot behavior influence perceived safety. Our results show that $\\rho$ effectively captures meaningful individual differences, driven by affective responses, trust in task consistency, and clustering into distinct user types. Specifically, our findings confirm that predictable and consistent robot behavior as well as the elicitation of positive emotional states, significantly enhance perceived safety. Moreover, responses cluster into a small number of user types, supporting adaptive personalization based on shared safety models. Notably, participant role significantly shapes safety perception, and repeated exposure reduces perceived safety for participants in the casualty role, emphasizing the impact of physical interaction and experiential change. These findings highlight the importance of adaptive, human-centered safety models that integrate both psychological and behavioral dimensions, offering a pathway toward more trustworthy and effective HRI in safety-critical domains.",
      "authors": [
        "Pranav Pandey and Ramviyas Parasuraman and Prashant Doshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:47:05+00:00",
          "link": "https://arxiv.org/abs/2507.06700v1",
          "size": "2014kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06700",
        "HTML": "https://arxiv.org/html/2507.06700v1",
        "PDF": "https://arxiv.org/pdf/2507.06700"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper deals with safety perceptions in human-robot interactions, emphasizing safety and trust, without engaging with creativity themes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06790",
      "abstract": "Esports athletes often reduce visual quality to improve latency and frame rate, and increase their in-game performance. Little research has examined the effects of this visuo-spatial tradeoff on performance, but we could find no work studying how players manage this tradeoff in practice. This paper is an initial examination of this question in the game Dota 2. First, we gather the game configuration data of Dota 2 players in a small survey. We learn that players do limit visual detail, particularly by turning off VSYNC, which removes rendering/display synchronization delay but permits visual \"tearing\". Second, we survey the intent of those same players with a few subjective questions. Player intent matches configuration practice. While our sampling of Dota 2 players may not be representative, our survey does reveal suggestive trends that lay the groundwork for future, more rigorous and larger surveys. Such surveys can help new players adapt to the game more quickly, encourage researchers to investigate the relative importance of temporal and visual detail, and justify design effort by developers in \"low visual\" game configurations.",
      "authors": [
        "Arjun Madhusudan",
        "Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:28:05+00:00",
          "link": "https://arxiv.org/abs/2507.06790v1",
          "size": "3540kb",
          "version": "v1"
        }
      ],
      "title": "Better frame rates or better visuals? An early report of Esports player practice in Dota 2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06790",
        "HTML": "https://arxiv.org/html/2507.06790v1",
        "PDF": "https://arxiv.org/pdf/2507.06790"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on Esports player practice in Dota 2, particularly visuo-spatial tradeoffs affecting performance. Creativity is not a topic of focus or discussion."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06878",
      "abstract": "The increasing integration of AI tools in education presents both opportunities and challenges, particularly regarding the development of the students' critical thinking skills. This position paper argues that while AI can support learning, its unchecked use may lead to cognitive atrophy, loss of agency, emotional risks, and ethical concerns, ultimately undermining the core goals of education. Drawing on cognitive science and pedagogy, the paper explores how over-reliance on AI can disrupt meaningful learning, foster dependency and conformity, undermine the students' self-efficacy, academic integrity, and well-being, and raise concerns about questionable privacy practices. It also highlights the importance of considering the students' perspectives and proposes actionable strategies to ensure that AI serves as a meaningful support rather than a cognitive shortcut. The paper advocates for an intentional, transparent, and critically informed use of AI that empowers rather than diminishes the learner.",
      "authors": [
        "Lucile Favero",
        "Juan-Antonio P\\'erez-Ortiz",
        "Tanja K\\\"aser",
        "Nuria Oliver"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:15:49+00:00",
          "link": "https://arxiv.org/abs/2507.06878v1",
          "size": "177kb",
          "version": "v1"
        }
      ],
      "title": "Do AI tutors empower or enslave learners? Toward a critical use of AI in education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06878",
        "HTML": "https://arxiv.org/html/2507.06878v1",
        "PDF": "https://arxiv.org/pdf/2507.06878"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses AI's role in education, encouraging critical thinking to avoid over-reliance on AI. Creativity is a secondary theme in fostering meaningful independent learning and critical skills."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07047",
      "abstract": "This study investigates public perceptions of generative artificial intelligence (GenAI) in libraries through a large-scale analysis of posts on X (formerly Twitter). Using a mixed-method approach that combines temporal trend analysis, sentiment classification, and social network analysis, this paper explores how public discourse around GenAI and libraries has evolved over time, the emotional tones that dominate the conversation, and the key users or organizations driving engagement. The findings reveal that discussions are predominantly negative in tone, with surges linked to concerns about ethics and intellectual property. Furthermore, social network analysis identifies both institutional authority and individual bridge users who facilitate cross-domain engagement. The results in this paper contribute to the growing body of literature on GenAI in the library and GLAM (Galleries, Libraries, Archives, and Museums) sectors and offer a real-time, public-facing perspective on the emerging opportunities and concerns GenAI presents.",
      "authors": [
        "Yuan Li",
        "Teja Mandaloju",
        "Haihua Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:10:06+00:00",
          "link": "https://arxiv.org/abs/2507.07047v1",
          "size": "1077kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Public Perceptions of Generative AI in Libraries: A Social Media Analysis of X Discussions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07047",
        "PDF": "https://arxiv.org/pdf/2507.07047"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper analyzes public perceptions of generative AI in libraries. It does not address creativity directly; its focus is on sentiment and engagement rather than creative implications."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.12538",
      "abstract": "Generating interdisciplinary research ideas requires diverse domain expertise, but access to timely feedback is often limited by the availability of experts. In this paper, we introduce PersonaFlow, a novel system designed to provide multiple perspectives by using LLMs to simulate domain-specific experts. Our user studies showed that the new design 1) increased the perceived relevance and creativity of ideated research directions, and 2) promoted users' critical thinking activities (e.g., interpretation, analysis, evaluation, inference, and self-regulation), without increasing their perceived cognitive load. Moreover, users' ability to customize expert profiles significantly improved their sense of agency, which can potentially mitigate their over-reliance on AI. This work contributes to the design of intelligent systems that augment creativity and collaboration, and provides design implications of using customizable AI-simulated personas in domains within and beyond research ideation.",
      "authors": [
        "Yiren Liu",
        "Pranav Sharma",
        "Mehul Jitendra Oswal",
        "Haijun Xia",
        "Yun Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-19T07:54:29+00:00",
          "link": "https://arxiv.org/abs/2409.12538v1",
          "size": "25313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T05:59:31+00:00",
          "link": "https://arxiv.org/abs/2409.12538v2",
          "size": "8378kb",
          "version": "v2"
        }
      ],
      "title": "PersonaFlow: Designing LLM-Simulated Expert Perspectives for Enhanced Research Ideation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.12538",
        "HTML": "https://arxiv.org/html/2409.12538v2",
        "PDF": "https://arxiv.org/pdf/2409.12538"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper focuses on augmenting creativity through the use of LLM-simulated expert perspectives, explicitly mentioning the enhancement of creative ideation processes."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "scientific discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.14879",
      "abstract": "Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.\n  We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",
      "authors": [
        "Jiachen Li",
        "Xiwen Li",
        "Justin Steinberg",
        "Akshat Choube",
        "Bingsheng Yao",
        "Xuhai Xu",
        "Dakuo Wang",
        "Elizabeth Mynatt",
        "Varun Mishra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-18T21:56:35+00:00",
          "link": "https://arxiv.org/abs/2410.14879v1",
          "size": "30990kb",
          "version": "v1"
        },
        {
          "date": "2025-02-27T22:31:58+00:00",
          "link": "https://arxiv.org/abs/2410.14879v2",
          "size": "11792kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T00:14:20+00:00",
          "link": "https://arxiv.org/abs/2410.14879v3",
          "size": "8856kb",
          "version": "v3"
        }
      ],
      "title": "Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.14879",
        "HTML": "https://arxiv.org/html/2410.14879v3",
        "PDF": "https://arxiv.org/pdf/2410.14879"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper incorporates creativity as part of the sensemaking process, using AI to aid in the interpretation of complex sensor data. Creativity is a secondary theme through design implications."
      },
      "tasks": [
        "Activity Recognition",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23952",
      "abstract": "AI systems increasingly support human decision-making across domains of professional, skill-based, and personal activity. While previous work has examined how AI might affect human autonomy globally, the effects of AI on domain-specific autonomy -- the capacity for self-governed action within defined realms of skill or expertise -- remain understudied. We analyze how AI decision-support systems affect two key components of domain-specific autonomy: skilled competence (the ability to make informed judgments within one's domain) and authentic value-formation (the capacity to form genuine domain-relevant values and preferences). By engaging with prior investigations and analyzing empirical cases across medical, financial, and educational domains, we demonstrate how the absence of reliable failure indicators and the potential for unconscious value shifts can erode domain-specific autonomy both immediately and over time. We then develop a constructive framework for autonomy-preserving AI support systems. We propose specific socio-technical design patterns -- including careful role specification, implementation of defeater mechanisms, and support for reflective practice -- that can help maintain domain-specific autonomy while leveraging AI capabilities. This framework provides concrete guidance for developing AI systems that enhance rather than diminish human agency within specialized domains of action.",
      "authors": [
        "Stefan Buijsman",
        "Sarah E. Carter",
        "Juan Pablo Berm\\'udez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:20:10+00:00",
          "link": "https://arxiv.org/abs/2506.23952v1",
          "size": "457kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T05:46:26+00:00",
          "link": "https://arxiv.org/abs/2506.23952v2",
          "size": "457kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T09:55:27+00:00",
          "link": "https://arxiv.org/abs/2506.23952v3",
          "size": "457kb",
          "version": "v3"
        }
      ],
      "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23952",
        "PDF": "https://arxiv.org/pdf/2506.23952"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on AI systems' impact on human autonomy and does not address creativity or creative processes directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02091",
      "abstract": "Generative artificial intelligence (AI) enables automated content production, including coding in software development, which can significantly influence developer participation and performance. To explore its impact on collaborative open-source software (OSS) development, we investigate the role of GitHub Copilot, a generative AI pair programmer, in OSS development where multiple distributed developers voluntarily collaborate. Using GitHub's proprietary Copilot usage data, combined with public OSS repository data obtained from GitHub, we find that Copilot use increases project-level code contributions by 5.9%. This gain is driven by a 2.1% increase in individual code contributions and a 3.4% rise in developer coding participation. However, these benefits come at a cost as coordination time for code integration increases by 8% due to more code discussions enabled by AI pair programmers. This reveals an important tradeoff: While AI expands who can contribute and how much they contribute, it slows coordination in collective development efforts. Despite this tension, the combined effect of these two competing forces remains positive, indicating a net gain in overall project-level productivity from using AI pair programmers. Interestingly, we also find the effects differ across developer roles. Peripheral developers show relatively smaller gains in project-level code contributions and face a higher increase in coordination time than core developers, likely due to the difference in their project familiarity. In summary, our study underscores the dual role of AI pair programmers in affecting project-level code contributions and coordination time in OSS development. Our findings on the differential effects between core and peripheral developers also provide important implications for the structure of OSS communities in the long run.",
      "authors": [
        "Fangchen Song",
        "Ashish Agarwal",
        "Wen Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T23:26:10+00:00",
          "link": "https://arxiv.org/abs/2410.02091v1",
          "size": "1094kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:44:42+00:00",
          "link": "https://arxiv.org/abs/2410.02091v2",
          "size": "1974kb",
          "version": "v2"
        }
      ],
      "title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02091",
        "PDF": "https://arxiv.org/pdf/2410.02091"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses the impact of AI on software development, focusing on productivity metrics and coordination challenges without any focus on creativity."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.05780",
      "abstract": "The rapid evolution of generative AI has expanded the breadth of risks associated with AI systems. While various taxonomies and frameworks exist to classify these risks, the lack of interoperability between them creates challenges for researchers, practitioners, and policymakers seeking to operationalise AI governance. To address this gap, we introduce the AI Risk Atlas, a structured taxonomy that consolidates AI risks from diverse sources and aligns them with governance frameworks. Additionally, we present the Risk Atlas Nexus, a collection of open-source tools designed to bridge the divide between risk definitions, benchmarks, datasets, and mitigation strategies. This knowledge-driven approach leverages ontologies and knowledge graphs to facilitate risk identification, prioritization, and mitigation. By integrating AI-assisted compliance workflows and automation strategies, our framework lowers the barrier to responsible AI adoption. We invite the broader research and open-source community to contribute to this evolving initiative, fostering cross-domain collaboration and ensuring AI governance keeps pace with technological advancements.",
      "authors": [
        "Frank Bagehorn",
        "Kristina Brimijoin",
        "Elizabeth M. Daly",
        "Jessica He",
        "Michael Hind",
        "Luis Garces-Erice",
        "Christopher Giblin",
        "Ioana Giurgiu",
        "Jacquelyn Martino",
        "Rahul Nair",
        "David Piorkowski",
        "Ambrish Rawat",
        "John Richards",
        "Sean Rooney",
        "Dhaval Salwala",
        "Seshu Tirupathi",
        "Peter Urbanetz",
        "Kush R. Varshney",
        "Inge Vejsbjerg",
        "Mira L. Wolf-Bauwens"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T12:23:14+00:00",
          "link": "https://arxiv.org/abs/2503.05780v1",
          "size": "1353kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:28:00+00:00",
          "link": "https://arxiv.org/abs/2503.05780v2",
          "size": "289kb",
          "version": "v2"
        }
      ],
      "title": "AI Risk Atlas: Taxonomy and Tooling for Navigating AI Risks and Resources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05780",
        "HTML": "https://arxiv.org/html/2503.05780v2",
        "PDF": "https://arxiv.org/pdf/2503.05780"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "Focuses on AI risk management and governance rather than creativity. Creativity is not addressed in the context of the topic."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14774",
      "abstract": "Clinical decision-making is inherently complex, often influenced by cognitive biases, incomplete information, and case ambiguity. Large Language Models (LLMs) have shown promise as tools for supporting clinical decision-making, yet their typical one-shot or limited-interaction usage may overlook the complexities of real-world medical practice. In this work, we propose a hybrid human-AI framework, MedSyn, where physicians and LLMs engage in multi-step, interactive dialogues to refine diagnoses and treatment decisions. Unlike static decision-support tools, MedSyn enables dynamic exchanges, allowing physicians to challenge LLM suggestions while the LLM highlights alternative perspectives. Through simulated physician-LLM interactions, we assess the potential of open-source LLMs as physician assistants. Results show open-source LLMs are promising as physician assistants in the real world. Future work will involve real physician interactions to further validate MedSyn's usefulness in diagnostic accuracy and patient outcomes.",
      "authors": [
        "Burcu Sayin and Ipek Baris Schlicht and Ngoc Vo Hong and Sara Allievi and Jacopo Staiano and Pasquale Minervini and Andrea Passerini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T09:37:18+00:00",
          "link": "https://arxiv.org/abs/2506.14774v1",
          "size": "1133kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:35:13+00:00",
          "link": "https://arxiv.org/abs/2506.14774v2",
          "size": "360kb",
          "version": "v2"
        }
      ],
      "title": "MedSyn: Enhancing Diagnostics with Human-AI Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14774",
        "PDF": "https://arxiv.org/pdf/2506.14774"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper centers on human-AI collaboration in medical diagnostics, with no exploration of creativity within its research scope."
      },
      "tasks": [
        "Decision Making",
        "Diagnostic"
      ],
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Multimedia (cs.MM)",
    "Computation and Language (cs.CL)",
    "Sound (cs.SD)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Artificial Intelligence (cs.AI)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Computers and Society (cs.CY)",
    "Software Engineering (cs.SE)",
    "Human-Computer Interaction (cs.HC)",
    "Graphics (cs.GR)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "creativity": "\nYou are an expert in information retrieval. I will provide you with a list of research papers from arXiv, specifically in the *cs.HC* (Human-Computer Interaction) category.\n\nYour task is to analyze each paper and determine its relevance to the topic of **Creativity**.\n\n\n### Classify each paper into one of the following relevance levels\n\n- `core` \u2014 Creativity is a **primary focus**\n  - The paper directly studies or simulates creativity, with a clear focus on creativity.\n  - Includes creative tasks, co-creative systems, or creativity evaluation metrics.\n  - The title and abstract explicitly mention creativity, and the research questions are directly related to creativity.\n- `partial` \u2014 Creativity is a **secondary theme**\n  - Part of the paper relates to creativity; it is treated as an analytical dimension or design goal but not the main objective (e.g., user creativity, design support).\n  - Creativity may appear in discussions, experiments, or auxiliary applications.\n  - Creativity is presented as a supporting topic (e.g., evaluation criteria, user feedback).\n- `irrelevant` \u2014 **No clear connection** to creativity\n  - The paper does not address creativity as a topic.\n  - Focuses on unrelated technical content (e.g., compression, security, optimization).\n  - If creativity is mentioned, it is only superficial and lacks substantive content.\n\n\n### Return your results in the following JSON format\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    },\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    }\n  ]\n}\n```\n\nBe concise but specific in your reasoning, referencing key terms or sections when applicable.\n"
  },
  "description": "Data source: https://arxiv.org/list/cs.HC/new",
  "level_tatistics": {
    "irrelevant": 18,
    "partial": 5,
    "core": 1
  },
  "arxiv_update_date": "2025-07-10",
  "updated_at": "2025-07-10 10:02:25"
}