{
  "data": [
    {
      "id": "2507.13524",
      "abstract": "Partner selection is crucial for cooperation and hinges on communication. As artificial agents, especially those powered by large language models (LLMs), become more autonomous, intelligent, and persuasive, they compete with humans for partnerships. Yet little is known about how humans select between human and AI partners and adapt under AI-induced competition pressure. We constructed a communication-based partner selection game and examined the dynamics in hybrid mini-societies of humans and bots powered by a state-of-the-art LLM. Through three experiments (N = 975), we found that bots, though more prosocial than humans and linguistically distinguishable, were not selected preferentially when their identity was hidden. Instead, humans misattributed bots' behaviour to humans and vice versa. Disclosing bots' identity induced a dual effect: it reduced bots' initial chances of being selected but allowed them to gradually outcompete humans by facilitating human learning about the behaviour of each partner type. These findings show how AI can reshape social interaction in mixed societies and inform the design of more effective and cooperative hybrid systems.",
      "authors": [
        "Yaomin Jiang",
        "Levin Brinkmann",
        "Anne-Marie Nussberger",
        "Ivan Soraperra",
        "Jean-Fran\\c{c}ois Bonnefon",
        "Iyad Rahwan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:24:26+00:00",
          "link": "https://arxiv.org/abs/2507.13524v1",
          "size": "4722kb",
          "version": "v1"
        }
      ],
      "title": "Humans learn to prefer trustworthy AI over human partners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13524",
        "HTML": "https://arxiv.org/html/2507.13524v1",
        "PDF": "https://arxiv.org/pdf/2507.13524"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper explores how humans prefer AI over human partners in partner selection games, focusing on social interaction dynamics and not on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13528",
      "abstract": "TickTacking is a rhythm-based interface that allows users to control a pointer in a two-dimensional space through dual-button tapping. This paper investigates the generation of human-like trajectories using a receding horizon approach applied to the TickTacking interface in a target-tracking task. By analyzing user-generated trajectories, we identify key human behavioral features and incorporate them in a controller that mimics these behaviors. The performance of this human-inspired controller is evaluated against a baseline optimal-control-based agent, demonstrating the importance of specific control features for achieving human-like interaction. These findings contribute to the broader goal of developing rhythm-based human-machine interfaces by offering design insights that enhance user performance, improve intuitiveness, and reduce interaction frustration",
      "authors": [
        "Daniele Masti",
        "Stefano Menchetti",
        "\\c{C}a\\u{g}r{\\i} Erdem",
        "Giorgio Gnecco",
        "and Davide Rocchesso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T20:41:17+00:00",
          "link": "https://arxiv.org/abs/2507.13528v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13528",
        "HTML": "https://arxiv.org/html/2507.13528v1",
        "PDF": "https://arxiv.org/pdf/2507.13528"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper\u2019s main focus is on generating human-like trajectories using a rhythm-based interface. Creativity is addressed in the context of enhancing user interaction and performance, which could support creative human-machine interfaces."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13578",
      "abstract": "Individual cognitive stimulation therapy (iCST) is a non-pharmacological intervention for improving the cognition and quality of life of persons with dementia (PwDs); however, its effectiveness is limited by low adherence to delivery by their family members. In this work, we present the user-centered design and evaluation of a novel socially assistive robotic system to provide iCST therapy to PwDs in their homes for long-term use. We consulted with 16 dementia caregivers and professionals. Through these consultations, we gathered design guidelines and developed the prototype. The prototype was validated by testing it with three dementia professionals and five PwDs. The evaluation revealed PwDs enjoyed using the system and are willing to adopt its use over the long term. One shortcoming was the system's speech-to-text capabilities, where it frequently failed to understand the PwDs.",
      "authors": [
        "Emmanuel Akinrintoyo and Nicole Salomons"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T23:48:09+00:00",
          "link": "https://arxiv.org/abs/2507.13578v1",
          "size": "3393kb",
          "version": "v1"
        }
      ],
      "title": "In-Home Social Robots Design for Cognitive Stimulation Therapy in Dementia Care",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13578",
        "HTML": "https://arxiv.org/html/2507.13578v1",
        "PDF": "https://arxiv.org/pdf/2507.13578"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper is focused on the design of robotic systems for cognitive stimulation therapy and does not address creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13616",
      "abstract": "The integration of agential artificial intelligence into socioeconomic systems requires us to reexamine the evolutionary processes that describe changes in our economic institutions. This article synthesizes three frameworks: multi-level selection theory, Aoki's view of firms as computational processes, and Ostrom's design principles for robust institutions. We develop a framework where selection operates concurrently across organizational levels, firms implement distributed inference via game-theoretic architectures, and Ostrom-style rules evolve as alignment mechanisms that address AI-related risks. This synthesis yields a multi-level Price equation expressed over nested games, providing quantitative metrics for how selection and governance co-determine economic outcomes. We examine connections to Acemoglu's work on inclusive institutions, analyze how institutional structures shape AI deployment, and demonstrate the framework's explanatory power via case studies. We conclude by proposing a set of design principles that operationalize alignment between humans and AI across institutional layers, enabling scalable, adaptive, and inclusive governance of agential AI systems. We conclude with practical policy recommendations and further research to extend these principles into real-world implementation.",
      "authors": [
        "Michael S. Harre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)",
        "Information Theory (cs.IT)",
        "Multiagent Systems (cs.MA)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:52:58+00:00",
          "link": "https://arxiv.org/abs/2507.13616v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "From Firms to Computation: AI Governance and the Evolution of Institutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13616",
        "HTML": "https://arxiv.org/html/2507.13616v1",
        "PDF": "https://arxiv.org/pdf/2507.13616"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper discusses AI governance and economic institutions, without any specific relation to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13660",
      "abstract": "Two user studies were performed to evaluate the effect of level-of-detail (LOD) degradation in the periphery of head-mounted displays on visual search performance. In the first study, spatial detail was degraded by reducing resolution. In the second study, detail was degraded in the color domain by using grayscale in the periphery. In each study, 10 subjects were given a complex search task that required users to indicate whether or not a target object was present among distracters. Subjects used several different displays varying in the amount of detail presented. Frame rate, object location, subject input method, and order of display use were all controlled. The primary dependent measures were search time on correctly performed trials and the percentage of all trials correctly performed. Results indicated that peripheral LOD degradation can be used to reduce color or spatial visual complexity by almost half in some search tasks with out significantly reducing performance.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "Larry F Hodges",
        "Aileen Worden"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:07:02+00:00",
          "link": "https://arxiv.org/abs/2507.13660v1",
          "size": "308kb",
          "version": "v1"
        }
      ],
      "title": "Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13660",
        "PDF": "https://arxiv.org/pdf/2507.13660"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study investigates the effects of LOD degradation on visual search performance, which does not relate to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13795",
      "abstract": "Phobias significantly impact the quality of life of affected persons. Two methods of assessing anxiety responses are questionnaires and behavioural avoidance tests (BAT). While these can be used in a clinical environment they only record momentary insights into anxiety measures. In this study, we estimate the intensity of anxiety during these BATs, using physiological data collected from unobtrusive, wrist-worn sensors. Twenty-five participants performed four different BATs in a single session, while periodically being asked how anxious they currently are. Using heart rate, heart rate variability, electrodermal activity, and skin temperature, we trained regression models to predict anxiety ratings from three types of input data: (1) using only physiological signals, (2) adding computed features (e.g., min, max, range, variability), and (3) computed features combined with contextual task information. Adding contextual information increased the effectiveness of the model, leading to a root mean squared error (RMSE) of 0.197 and a mean absolute error (MAE) of 0.041. Overall, this study shows, that data obtained from wearables can continuously provide meaningful estimations of anxiety, which can assist in therapy planning and enable more personalised treatment.",
      "authors": [
        "Florian Grensing",
        "Vanessa Schm\\\"ucker",
        "Anne Sophie Hildebrand",
        "Tim Klucken",
        "Maria Maleshkova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:09:38+00:00",
          "link": "https://arxiv.org/abs/2507.13795v1",
          "size": "868kb",
          "version": "v1"
        }
      ],
      "title": "Regression-Based Approach to Anxiety Estimation of Spider Phobics During Behavioural Avoidance Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13795",
        "HTML": "https://arxiv.org/html/2507.13795v1",
        "PDF": "https://arxiv.org/pdf/2507.13795"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This research is centered on anxiety estimation using physiological data, with no connection to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13886",
      "abstract": "In this simulator study, we adopt a human-centered approach to explore whether and how drivers' cognitive state and driving environment complexity influence reliance on driving automation features. Besides, we examine whether such reliance affects driving performance. Participants operated a vehicle equipped with adaptive cruise control (ACC) in a simulator across six predefined driving scenarios varying in traffic conditions while either performing a cognitively demanding task (i.e., responding to mental calculations) or not. Throughout the experiment, participants had to respect speed limits and were free to activate or deactivate ACC. In complex driving environments, we found that the overall ACC engagement time was lower compared to less complex driving environments. We observed no significant effect of cognitive load on ACC use. Furthermore, while ACC use had no effect on the number of lane changes, it impacted the speed limits compliance and improved lateral control.",
      "authors": [
        "Ana\\\"is Halin",
        "Marc Van Droogenbroeck",
        "Christel Devue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:02:53+00:00",
          "link": "https://arxiv.org/abs/2507.13886v1",
          "size": "4519kb",
          "version": "v1"
        }
      ],
      "title": "Effects of Cognitive Distraction and Driving Environment Complexity on Adaptive Cruise Control Use and Its Impact on Driving Performance: A Simulator Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13886",
        "HTML": "https://arxiv.org/html/2507.13886v1",
        "PDF": "https://arxiv.org/pdf/2507.13886"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study focuses on driving performance and adaptive cruise control in complex environments, with no mention of creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13923",
      "abstract": "The science of Human-Computer Interaction (HCI) is populated by isolated empirical findings, often tied to specific technologies, designs, and tasks. This paper proposes a formalization of user interaction observations (instead of user interfaces) and an associated revealing method (interaction loop diffraction). The resulting interactional properties that are studied in a calibrated manner, are well suited to replication across various conditions (prototypes, technologies, tasks, and user profiles). In particular, interactional properties can emerge and be replicated within the workflow of applicative cases, which in return benefit from the optimization of applicative prototypes. Applicative cases' publications will then contribute to demonstrating technology utility, along with providing empirical results that will lead future work to theory consolidation and theory building, and finally to a catalog and a science of relevant interactional properties. These properties will contribute to better user interactions, especially for the variety of ubiquitous user interfaces.",
      "authors": [
        "Guillaume Rivi\\`ere"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:58:30+00:00",
          "link": "https://arxiv.org/abs/2507.13923v1",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "title": "Initiating and Replicating the Observations of Interactional Properties by User Studies Optimizing Applicative Prototypes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13923",
        "HTML": "https://arxiv.org/html/2507.13923v1",
        "PDF": "https://arxiv.org/pdf/2507.13923"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses formalizing user interaction observations in HCI rather than creativity, focusing on interactional properties across conditions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13951",
      "abstract": "Game modding offers unique and personalized gaming experiences, but the technical complexity of creating mods often limits participation to skilled users. We envision a future where every player can create personalized mods for their games. To explore this space, we designed StarCharM, a GenAI-based non-player character (NPC) creator for Stardew Valley. Our tool enables players to iteratively create new NPC mods, requiring minimal user input while allowing for fine-grained adjustments through user control. We conducted a user study with ten Stardew Valley players who had varied mod usage experiences to understand the impacts of StarCharM and provide insights into how GenAI tools may reshape modding, particularly in NPC creation. Participants expressed excitement in bringing their character ideas to life, although they noted challenges in generating rich content to fulfill complex visions. While they believed GenAI tools like StarCharM can foster a more diverse modding community, some voiced concerns about diminished originality and community engagement that may come with such technology. Our findings provided implications and guidelines for the future of GenAI-powered modding tools and co-creative modding practices.",
      "authors": [
        "Hamid Zand Miralvand",
        "Mohammad Ronagh Nikghalb",
        "Mohammad Darandeh",
        "Abidullah Khan",
        "Ian Arawjo",
        "Jinghui Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:20:47+00:00",
          "link": "https://arxiv.org/abs/2507.13951v1",
          "size": "778kb",
          "version": "v1"
        }
      ],
      "title": "Democratizing Game Modding with GenAI: A Case Study of StarCharM, a Stardew Valley Character Maker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13951",
        "HTML": "https://arxiv.org/html/2507.13951v1",
        "PDF": "https://arxiv.org/pdf/2507.13951"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper explores using GenAI for game modding, a creative task allowing users to create personalized game content, thus directly involving and focusing on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13952",
      "abstract": "The estimation of cognitive effort could potentially help educators to modify material to enhance learning effectiveness and student engagement. Where cognitive load refers how much work the brain is doing while someone is learning or doing a task cognitive effort consider both load and behavioral performance. Cognitive effort can be captured by measuring oxygen flow and behavioral performance during a task. This study infers cognitive effort metrics using machine learning models based on oxygenated hemoglobin collected by using functional near-infrared spectroscopy from the prefrontal cortex during an educational gameplay. In our study, sixteen participants responded to sixteen questions in an in-house Unity-based educational game. The quiz was divided into two sessions, each session consisting of two task segments. We extracted temporal statistical and functional connectivity features from collected oxygenated hemoglobin and analyzed their correlation with quiz performance. We trained multiple machine learning models to predict quiz performance from oxygenated hemoglobin features and achieved accuracies ranging from 58\\% to 67\\% accuracy. These predictions were used to calculate cognitive effort via relative neural involvement and efficiency, which consider both brain activation and behavioral performance. Although quiz score predictions achieved moderate accuracy, the derived relative neural efficiency and involvement values remained robust. Since both metrics are based on the relative positions of standardized brain activation and performance scores, even small misclassifications in predicted scores preserved the overall cognitive effort trends observed during gameplay.",
      "authors": [
        "Shayla Sharmin and Roghayeh Leila Barmaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:20:54+00:00",
          "link": "https://arxiv.org/abs/2507.13952v1",
          "size": "3668kb",
          "version": "v1"
        }
      ],
      "title": "Estimating Cognitive Effort from Functional Near-Infrared Spectroscopy (fNIRS) Signals using Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13952",
        "HTML": "https://arxiv.org/html/2507.13952v1",
        "PDF": "https://arxiv.org/pdf/2507.13952"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on estimating cognitive effort using fNIRS signals and machine learning, primarily in the context of educational gameplay. It does not discuss or integrate the concept of creativity in its investigation or findings."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14034",
      "abstract": "Agentic AI systems, powered by Large Language Models (LLMs), offer transformative potential for value co-creation in technical services. However, persistent challenges like hallucinations and operational brittleness limit their autonomous use, creating a critical need for robust frameworks to guide human-AI collaboration. Drawing on established Human-AI teaming research and analogies from fields like autonomous driving, this paper develops a structured taxonomy of human-agent interaction. Based on case study research within technical support platforms, we propose a six-mode taxonomy that organizes collaboration across a spectrum of AI autonomy. This spectrum is anchored by the Human-Out-of-the-Loop (HOOTL) model for full automation and the Human-Augmented Model (HAM) for passive AI assistance. Between these poles, the framework specifies four distinct intermediate structures. These include the Human-in-Command (HIC) model, where AI proposals re-quire mandatory human approval, and the Human-in-the-Process (HITP) model for structured work-flows with deterministic human tasks. The taxonomy further delineates the Human-in-the-Loop (HITL) model, which facilitates agent-initiated escalation upon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables discretionary human oversight of an autonomous AI. The primary contribution of this work is a comprehensive framework that connects this taxonomy to key contingency factors -- such as task complexity, operational risk, and system reliability -- and their corresponding conceptual architectures. By providing a systematic method for selecting and designing an appropriate level of human oversight, our framework offers practitioners a crucial tool to navigate the trade-offs between automation and control, thereby fostering the development of safer, more effective, and context-aware technical service systems.",
      "authors": [
        "Jochen Wulf",
        "Jurg Meierhofer",
        "Frank Hannich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:06:03+00:00",
          "link": "https://arxiv.org/abs/2507.14034v1",
          "size": "515kb",
          "version": "v1"
        }
      ],
      "title": "Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14034",
        "PDF": "https://arxiv.org/pdf/2507.14034"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses human-AI cocreation in technical services and proposes a taxonomy of interaction modes. While creativity is not the core focus, the concept of cocreation is indirectly related to creativity, as it involves collaborative and potentially creative problem-solving processes between humans and AI."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14084",
      "abstract": "Humans have a selective memory, remembering relevant episodes and forgetting the less relevant information. Possessing awareness of event memorability for a user could help intelligent systems in more accurate user modelling, especially for such applications as meeting support systems, memory augmentation, and meeting summarisation. Emotion recognition has been widely studied, since emotions are thought to signal moments of high personal relevance to users. The emotional experience of situations and their memorability have traditionally been considered to be closely tied to one another: moments that are experienced as highly emotional are considered to also be highly memorable. This relationship suggests that emotional annotations could serve as proxies for memorability. However, existing emotion recognition systems rely heavily on third-party annotations, which may not accurately represent the first-person experience of emotional relevance and memorability. This is why, in this study, we empirically examine the relationship between perceived group emotions (Pleasure-Arousal) and group memorability in the context of conversational interactions. Our investigation involves continuous time-based annotations of both emotions and memorability in dynamic, unstructured group settings, approximating conditions of real-world conversational AI applications such as online meeting support systems. Our results show that the observed relationship between affect and memorability annotations cannot be reliably distinguished from what might be expected under random chance. We discuss the implications of this surprising finding for the development and applications of Affective Computing technology. In addition, we contextualise our findings in broader discourses in the Affective Computing and point out important targets for future research efforts.",
      "authors": [
        "Maria Tsfasman",
        "Ramin Ghorbani",
        "Catholijn M. Jonker",
        "Bernd Dudzik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:06:34+00:00",
          "link": "https://arxiv.org/abs/2507.14084v1",
          "size": "2800kb",
          "version": "v1"
        }
      ],
      "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14084",
        "HTML": "https://arxiv.org/html/2507.14084v1",
        "PDF": "https://arxiv.org/pdf/2507.14084"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper examines the relationship between emotion and memorability in group interactions, focusing on the implications for Affective Computing. There is no direct or indirect mention of creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13468",
      "abstract": "The integration of large language models (LLMs) into conversational robots has made human-robot conversations more dynamic. Yet, LLM-powered conversational robots remain prone to errors, e.g., misunderstanding user intent, prematurely interrupting users, or failing to respond altogether. Detecting and addressing these failures is critical for preventing conversational breakdowns, avoiding task disruptions, and sustaining user trust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal dataset of LLM-powered conversational robot failures during human-robot conversations and encourages researchers to benchmark machine learning models designed to detect robot failures. The dataset includes 16 hours of dyadic human-robot interactions, incorporating facial, speech, and head movement features. Each interaction is annotated with the presence or absence of robot errors from the system perspective, and perceived user intention to correct for a mismatch between robot behavior and user expectation. Participants are invited to form teams and develop machine learning models that detect these failures using multimodal data. Submissions will be evaluated using various performance metrics, including detection accuracy and false positive rate. This challenge represents another key step toward improving failure detection in human-robot interaction through social signal analysis.",
      "authors": [
        "Shiye Cao",
        "Maia Stiber",
        "Amama Mahmood",
        "Maria Teresa Parreira",
        "Wendy Ju",
        "Micol Spitale",
        "Hatice Gunes",
        "Chien-Ming Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:21:45+00:00",
          "link": "https://arxiv.org/abs/2507.13468v1",
          "size": "681kb",
          "version": "v1"
        }
      ],
      "title": "ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13468",
        "HTML": "https://arxiv.org/html/2507.13468v1",
        "PDF": "https://arxiv.org/pdf/2507.13468"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on error detection and failure handling in human-robot interactions, without addressing creativity elements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13602",
      "abstract": "In this work we extend the low-cost GELLO teleoperation system, initially designed for joint position control, with additional force information. Our first extension is to implement force feedback, allowing users to feel resistance when interacting with the environment. Our second extension is to add force information into the data collection process and training of imitation learning models. We validate our additions by implementing these on a GELLO system with a Franka Panda arm as the follower robot, performing a user study, and comparing the performance of policies trained with and without force information on a range of simulated and real dexterous manipulation tasks. Qualitatively, users with robotics experience preferred our controller, and the addition of force inputs improved task success on the majority of tasks.",
      "authors": [
        "Shivakanth Sujit",
        "Luca Nunziante",
        "Dan Ogawa Lillrank",
        "Rousslan Fernand Julien Dossa",
        "Kai Arulkumaran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T02:05:07+00:00",
          "link": "https://arxiv.org/abs/2507.13602v1",
          "size": "3322kb",
          "version": "v1"
        }
      ],
      "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13602",
        "HTML": "https://arxiv.org/html/2507.13602v1",
        "PDF": "https://arxiv.org/pdf/2507.13602"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on improving teleoperation systems and force feedback, with no mention of creativity being a research theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13737",
      "abstract": "Rich and context-aware activity logs facilitate user behavior analysis and health monitoring, making them a key research focus in ubiquitous computing. The remarkable semantic understanding and generation capabilities of Large Language Models (LLMs) have recently created new opportunities for activity log generation. However, existing methods continue to exhibit notable limitations in terms of accuracy, efficiency, and semantic richness. To address these challenges, we propose DailyLLM. To the best of our knowledge, this is the first log generation and summarization system that comprehensively integrates contextual activity information across four dimensions: location, motion, environment, and physiology, using only sensors commonly available on smartphones and smartwatches. To achieve this, DailyLLM introduces a lightweight LLM-based framework that integrates structured prompting with efficient feature extraction to enable high-level activity understanding. Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art (SOTA) log generation methods and can be efficiently deployed on personal computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM achieves a 17% improvement in log generation BERTScore precision compared to the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference speed.",
      "authors": [
        "Ye Tian",
        "Xiaoyuan Ren",
        "Zihao Wang",
        "Onat Gungor",
        "Xiaofan Yu and Tajana Rosing"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T08:33:30+00:00",
          "link": "https://arxiv.org/abs/2507.13737v1",
          "size": "765kb",
          "version": "v1"
        }
      ],
      "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13737",
        "HTML": "https://arxiv.org/html/2507.13737v1",
        "PDF": "https://arxiv.org/pdf/2507.13737"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper deals with activity log generation using LLMs and sensors, focusing on ubiquitous computing and not creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13839",
      "abstract": "This study explores the relationship between linguistic expressions and psychological states of depression and anxiety within Chinese psycho-counseling interactions, focusing specifically on the usage of first-person singular pronouns and negative emotional words. Utilizing a corpus derived from 735 online counseling sessions, the analysis employed a general linear mixed-effect model to assess linguistic patterns quantified by the Linguistic Inquiry and Word Count (LIWC) software. Results indicate a significant positive correlation between the frequency of negative emotional words and the severity of both depressive and anxious states among clients. However, contrary to prior findings predominantly derived from English-language contexts, the usage frequency of first-person singular pronouns did not vary significantly with the clients' psychological conditions. These outcomes are discussed within the framework of cultural distinctions between collectivist Chinese contexts and individualistic Western settings, as well as the interactive dynamics unique to psycho-counseling conversations. The findings highlight the nuanced influence of cultural and conversational contexts on language use in mental health communications, providing insights into psycholinguistic markers relevant to therapeutic practices in Chinese-speaking populations.",
      "authors": [
        "Lizhi Ma",
        "Tong Zhao",
        "Shuai Zhang",
        "Nirui Song",
        "Hongliang He",
        "Anqi Li",
        "Ran Feng",
        "Huachuan Qiu",
        "Jingsong Ma",
        "Zhenzhong Lan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:53:15+00:00",
          "link": "https://arxiv.org/abs/2507.13839v1",
          "size": "881kb",
          "version": "v1"
        }
      ],
      "title": "The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13839",
        "PDF": "https://arxiv.org/pdf/2507.13839"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on linguistic expressions in psycho-counseling and their relationship to depression and anxiety, with no mention or exploration of creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13919",
      "abstract": "There are widespread fears that conversational AI could soon exert unprecedented influence over human beliefs. Here, in three large-scale experiments (N=76,977), we deployed 19 LLMs-including some post-trained explicitly for persuasion-to evaluate their persuasiveness on 707 political issues. We then checked the factual accuracy of 466,769 resulting LLM claims. Contrary to popular concerns, we show that the persuasive power of current and near-future AI is likely to stem more from post-training and prompting methods-which boosted persuasiveness by as much as 51% and 27% respectively-than from personalization or increasing model scale. We further show that these methods increased persuasion by exploiting LLMs' unique ability to rapidly access and strategically deploy information and that, strikingly, where they increased AI persuasiveness they also systematically decreased factual accuracy.",
      "authors": [
        "Kobi Hackenburg",
        "Ben M. Tappin",
        "Luke Hewitt",
        "Ed Saunders",
        "Sid Black",
        "Hause Lin",
        "Catherine Fist",
        "Helen Margetts",
        "David G. Rand",
        "Christopher Summerfield"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:50:09+00:00",
          "link": "https://arxiv.org/abs/2507.13919v1",
          "size": "2455kb",
          "version": "v1"
        }
      ],
      "title": "The Levers of Political Persuasion with Conversational AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13919",
        "HTML": "https://arxiv.org/html/2507.13919v1",
        "PDF": "https://arxiv.org/pdf/2507.13919"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper examines the persuasive power of conversational AI on political beliefs and does not address creativity as a theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.14080",
      "abstract": "The latest developments in computer hardware, sensor technologies, and artificial intelligence can make virtual reality (VR) and virtual spaces an important part of human everyday life. Eye tracking offers not only a hands-free way of interaction but also the possibility of a deeper understanding of human visual attention and cognitive processes in VR. Despite these possibilities, eye-tracking data also reveals users' privacy-sensitive attributes when combined with the information about the presented stimulus. To address all these possibilities and potential privacy issues, in this survey, we first cover major works in eye tracking, VR, and privacy areas between 2012 and 2022. While eye tracking in the VR part covers the complete pipeline of eye-tracking methodology from pupil detection and gaze estimation to offline use of the data and analyses, as for privacy and security, we focus on eye-based authentication as well as computational methods to preserve the privacy of individuals and their eye-tracking data in VR. Later, considering all of these, we draw three main directions for the research community by focusing on privacy challenges. In summary, this survey provides an extensive literature review of the utmost possibilities with eye tracking in VR and the privacy implications of those possibilities.",
      "authors": [
        "Efe Bozkir and S\\\"uleyman \\\"Ozdel and Mengdi Wang and Brendan David-John and Hong Gao and Kevin Butler and Eakta Jain and Enkelejda Kasneci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-23T14:02:38+00:00",
          "link": "https://arxiv.org/abs/2305.14080v1",
          "size": "10051kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T08:40:04+00:00",
          "link": "https://arxiv.org/abs/2305.14080v2",
          "size": "10232kb",
          "version": "v2"
        }
      ],
      "title": "Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and Privacy Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.14080",
        "HTML": "https://arxiv.org/html/2305.14080v2",
        "PDF": "https://arxiv.org/pdf/2305.14080"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on eye-tracking methodologies, VR, and privacy challenges, but does not address creativity as a research theme."
      },
      "tasks": [
        "Gaze Estimation",
        "Pupil Detection",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.08080",
      "abstract": "The use of partially automated driving systems raises concerns about potential responsibility issues, posing risk to the system safety, acceptance, and adoption of these technologies. The concept of meaningful human control has emerged in response to the responsibility gap problem, requiring the fulfillment of two conditions, tracking and tracing. While this concept has provided important philosophical and design insights on automated driving systems, there is currently little knowledge on how meaningful human control relates to subjective experiences of actual users of these systems. To address this gap, our study aimed to investigate the alignment between the degree of meaningful human control and drivers' perceptions of safety and trust in a real-world partially automated driving system. We utilized previously collected data from interviews with Tesla \"Full Self-Driving\" (FSD) Beta users, investigating the alignment between the user perception and how well the system was tracking the users' reasons. We found that tracking of users' reasons for driving tasks (such as safe maneuvers) correlated with perceived safety and trust, albeit with notable exceptions. Surprisingly, failure to track lane changing and braking reasons was not necessarily associated with negative perceptions of safety. However, the failure of the system to track expected maneuvers in dangerous situations always resulted in low trust and perceived lack of safety. Overall, our analyses highlight alignment points but also possible discrepancies between perceived safety and trust on the one hand, and meaningful human control on the other hand. Our results can help the developers of automated driving technology to design systems under meaningful human control and are perceived as safe and trustworthy.",
      "authors": [
        "Lucas Elbert Suryana",
        "Sina Nordhoff",
        "Simeon C. Calvert",
        "Arkady Zgonnikov and Bart van Arem"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-12T21:48:57+00:00",
          "link": "https://arxiv.org/abs/2402.08080v1",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:31:17+00:00",
          "link": "https://arxiv.org/abs/2402.08080v2",
          "size": "73kb",
          "version": "v2"
        }
      ],
      "title": "A Meaningful Human Control Perspective on User Perception of Partially Automated Driving Systems: A Case Study of Tesla Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.08080",
        "HTML": "https://arxiv.org/html/2402.08080v2",
        "PDF": "https://arxiv.org/pdf/2402.08080"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper examines user perceptions of safety and trust in automated driving systems, focusing on meaningful human control, with no clear connection to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01558",
      "abstract": "Most visual grounding solutions primarily focus on realistic images. However, applications involving synthetic images, such as Graphical User Interfaces (GUIs), remain limited. This restricts the development of autonomous computer vision-powered artificial intelligence (AI) agents for automatic application interaction. Enabling AI to effectively understand and interact with GUIs is crucial to advancing automation in software testing, accessibility, and human-computer interaction. In this work, we explore Instruction Visual Grounding (IVG), a multi-modal approach to object identification within a GUI. More precisely, given a natural language instruction and a GUI screen, IVG locates the coordinates of the element on the screen where the instruction should be executed. We propose two main methods: (1) IVGocr, which combines a Large Language Model (LLM), an object detection model, and an Optical Character Recognition (OCR) module; and (2) IVGdirect, which uses a multimodal architecture for end-to-end grounding. For each method, we introduce a dedicated dataset. In addition, we propose the Central Point Validation (CPV) metric, a relaxed variant of the classical Central Proximity Score (CPS) metric. Our final test dataset is publicly released to support future research.",
      "authors": [
        "El Hassane Ettifouri and Jessica L\\'opez Espejel and Laura Minkova and Tassnim Dardouri and Walid Dahhane"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-05T19:10:19+00:00",
          "link": "https://arxiv.org/abs/2407.01558v1",
          "size": "335kb",
          "version": "v1"
        },
        {
          "date": "2024-09-17T10:15:07+00:00",
          "link": "https://arxiv.org/abs/2407.01558v2",
          "size": "897kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T11:35:01+00:00",
          "link": "https://arxiv.org/abs/2407.01558v3",
          "size": "835kb",
          "version": "v3"
        }
      ],
      "title": "Visual Grounding Methods for Efficient Interaction with Desktop Graphical User Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01558",
        "HTML": "https://arxiv.org/html/2407.01558v3",
        "PDF": "https://arxiv.org/pdf/2407.01558"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The research explores methods for interacting with GUIs via visual grounding, which could indirectly relate to creativity in designing and automating user interactions, but creativity is not the primary focus."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "object-detection",
        "Object Detection",
        "Visual Grounding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.03993",
      "abstract": "Accurate prediction of human behavior is crucial for AI systems to effectively support real-world applications, such as autonomous robots anticipating and assisting with human tasks. Real-world scenarios frequently present challenges such as occlusions and incomplete scene observations, which can compromise predictive accuracy. Thus, traditional video-based methods often struggle due to limited temporal and spatial perspectives. Large Language Models (LLMs) offer a promising alternative. Having been trained on a large text corpus describing human behaviors, LLMs likely encode plausible sequences of human actions in a home environment. However, LLMs, trained primarily on text data, lack inherent spatial awareness and real-time environmental perception. They struggle with understanding physical constraints and spatial geometry. Therefore, to be effective in a real-world spatial scenario, we propose a multimodal prediction framework that enhances LLM-based action prediction by integrating physical constraints derived from human trajectories. Our experiments demonstrate that combining LLM predictions with trajectory data significantly improves overall prediction performance. This enhancement is particularly notable in situations where the LLM receives limited scene information, highlighting the complementary nature of linguistic knowledge and physical constraints in understanding and anticipating human behavior.",
      "authors": [
        "Kojiro Takeyama",
        "Yimeng Liu",
        "Misha Sra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-05T01:18:26+00:00",
          "link": "https://arxiv.org/abs/2410.03993v1",
          "size": "40735kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T20:36:30+00:00",
          "link": "https://arxiv.org/abs/2410.03993v2",
          "size": "40736kb",
          "version": "v2"
        },
        {
          "date": "2025-03-06T00:35:18+00:00",
          "link": "https://arxiv.org/abs/2410.03993v3",
          "size": "20313kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T03:17:05+00:00",
          "link": "https://arxiv.org/abs/2410.03993v4",
          "size": "6160kb",
          "version": "v4"
        }
      ],
      "title": "TR-LLM: Integrating Trajectory Data for Scene-Aware LLM-Based Human Action Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03993",
        "HTML": "https://arxiv.org/html/2410.03993v4",
        "PDF": "https://arxiv.org/pdf/2410.03993"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on improving human action prediction in AI systems by integrating trajectory data with Large Language Models. It does not address creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03572",
      "abstract": "Web accessibility ensures that individuals with disabilities can access and interact with digital content without barriers, yet a significant majority of most used websites fail to meet accessibility standards. This study evaluates ChatGPT's (GPT-4o) ability to generate and improve web pages in line with Web Content Accessibility Guidelines (WCAG). While ChatGPT can effectively address accessibility issues when prompted, its default code often lacks compliance, reflecting limitations in its training data and prevailing inaccessible web practices. Automated and manual testing revealed strengths in resolving simple issues but challenges with complex tasks, requiring human oversight and additional iterations. Unlike prior studies, we incorporate manual evaluation, dynamic elements, and use the visual reasoning capability of ChatGPT along with the prompts to fix accessibility issues. Providing screenshots alongside prompts enhances the LLM's ability to address accessibility issues by allowing it to analyze surrounding components, such as determining appropriate contrast colors. We found that effective prompt engineering, such as providing concise, structured feedback and incorporating visual aids, significantly enhances ChatGPT's performance. These findings highlight the potential and limitations of large language models for accessible web development, offering practical guidance for developers to create more inclusive websites.",
      "authors": [
        "Ammar Ahmed",
        "Margarida Fresco",
        "Fredrik Forsberg",
        "Hallvard Grotli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T06:51:46+00:00",
          "link": "https://arxiv.org/abs/2501.03572v1",
          "size": "20915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:26:22+00:00",
          "link": "https://arxiv.org/abs/2501.03572v2",
          "size": "5661kb",
          "version": "v2"
        }
      ],
      "title": "From Code to Compliance: Assessing ChatGPT's Utility in Designing an Accessible Webpage -- A Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03572",
        "HTML": "https://arxiv.org/html/2501.03572v2",
        "PDF": "https://arxiv.org/pdf/2501.03572"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "This paper discusses improving web accessibility with ChatGPT, which involves creative problem-solving and design support. However, creativity is a secondary theme focused on enhancing accessibility rather than a primary focus of the research."
      },
      "tasks": [
        "Prompt Engineering",
        "Visual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16373",
      "abstract": "Mixed Reality (MR) enables rich, embodied collaboration, yet it's uncertain if sensor and system-logged behavioral signals capture how users experience that collaboration. This disconnect stems from a fundamental gap: behavioral signals are observable and continuous, while collaboration is interpreted subjectively, shaped by internal states like presence, cognitive availability, and social awareness. Our core insight is that sensor signals serve as observable manifestations of subjective experiences in MR collaboration, and they can be captured through sensor data such as shared gaze, speech, spatial movement, and other system-logged performance metrics. We propose the Sensor-to-Subjective (S2S) Mapping Framework, a conceptual model that links observable interaction patterns to users' subjective perceptions of collaboration and internal cognitive states through sensor-based indicators and task performance metrics. To validate this model, we conducted a study with 48 participants across 12 MR groups engaged in a collaborative image-sorting task. Our findings show a correlation between sensed behavior and perceived collaboration, particularly through shared attention and proximity.",
      "authors": [
        "Yasra Chandio",
        "Diana Romero",
        "Salma Elmalaki",
        "Fatima Anwar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T02:50:09+00:00",
          "link": "https://arxiv.org/abs/2504.16373v1",
          "size": "1616kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:07:11+00:00",
          "link": "https://arxiv.org/abs/2504.16373v2",
          "size": "1029kb",
          "version": "v2"
        }
      ],
      "title": "What Sensors See, What People Feel: Exploring Subjective Collaboration Perception in Mixed Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16373",
        "HTML": "https://arxiv.org/html/2504.16373v2",
        "PDF": "https://arxiv.org/pdf/2504.16373"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses mixed reality collaboration, focusing on subjective perception and sensor signals. While creativity is not the main focus, this work may support creative collaboration by enhancing user experience in MR environments."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04469",
      "abstract": "This systematic literature review examines the role of large language models (LLMs) in UI/UX design, synthesizing findings from 38 peer-reviewed studies published between 2022 and 2025. We identify key LLMs in use, including GPT-4, Gemini, and PaLM, and map their integration across the design lifecycle, from ideation to evaluation. Common practices include prompt engineering, human-in-the-loop workflows, and multimodal input. While LLMs are reshaping design processes, challenges such as hallucination, prompt instability, and limited explainability persist. Our findings highlight LLMs as emerging collaborators in design, and we propose directions for the ethical, inclusive, and effective integration of these technologies.",
      "authors": [
        "Ammar Ahmed",
        "Ali Shariq Imran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T17:18:05+00:00",
          "link": "https://arxiv.org/abs/2507.04469v1",
          "size": "2224kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T19:03:15+00:00",
          "link": "https://arxiv.org/abs/2507.04469v2",
          "size": "742kb",
          "version": "v2"
        }
      ],
      "title": "The role of large language models in UI/UX design: A systematic literature review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04469",
        "HTML": "https://arxiv.org/html/2507.04469v2",
        "PDF": "https://arxiv.org/pdf/2507.04469"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper reviews the role of large language models in UI/UX design, which can support creative processes in design by facilitating ideation and evaluation. However, creativity is not the core focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12377",
      "abstract": "We conduct a deconstructive reading of a qualitative interview study with 17 visual data journalists from newsrooms across the globe. We borrow a deconstruction approach from literary critique to explore the instability of meaning in language and reveal implicit beliefs in words and ideas. Through our analysis we surface two sets of opposing implicit beliefs in visual data journalism: objectivity/subjectivity and humanism/mechanism. We contextualize these beliefs through a genealogical analysis, which brings deconstruction theory into practice by providing a historic backdrop for these opposing perspectives. Our analysis shows that these beliefs held within visual data journalism are not self-enclosed but rather a product of external societal forces and paradigm shifts over time. Through this work, we demonstrate how thinking with critical theories such as deconstruction and genealogy can reframe \"success\" in visual data storytelling and diversify visualization research outcomes. These efforts push the ways in which we as researchers produce domain knowledge to examine the sociotechnical issues of today's values towards datafication and data visualization. All supplemental materials for this work are available at osf.io/5fr48.",
      "authors": [
        "Ke Er Amy Zhang",
        "Jodie Jenkinson",
        "Laura Garrison"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:26:44+00:00",
          "link": "https://arxiv.org/abs/2507.12377v1",
          "size": "8945kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.12377v2",
          "size": "8945kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T15:48:03+00:00",
          "link": "https://arxiv.org/abs/2507.12377v3",
          "size": "8945kb",
          "version": "v3"
        }
      ],
      "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12377",
        "HTML": "https://arxiv.org/html/2507.12377v3",
        "PDF": "https://arxiv.org/pdf/2507.12377"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While the paper's focus is on beliefs in visual data journalism, it encourages reframing success and diversifying research outcomes, which can be seen as fostering creativity in visual storytelling and journalism."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.08102",
      "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in text generation, yet their emotional consistency and semantic coherence in social media contexts remain insufficiently understood. This study investigates how LLMs handle emotional content and maintain semantic relationships through continuation and response tasks using two open-source models: Gemma and Llama. By analyzing climate change discussions from Twitter and Reddit, we examine emotional transitions, intensity patterns, and semantic similarity between human-authored and LLM-generated content. Our findings reveal that while both models maintain high semantic coherence, they exhibit distinct emotional patterns: Gemma shows a tendency toward negative emotion amplification, particularly anger, while maintaining certain positive emotions like optimism. Llama demonstrates superior emotional preservation across a broader spectrum of affects. Both models systematically generate responses with attenuated emotional intensity compared to human-authored content and show a bias toward positive emotions in response tasks. Additionally, both models maintain strong semantic similarity with original texts, though performance varies between continuation and response tasks. These findings provide insights into LLMs' emotional and semantic processing capabilities, with implications for their deployment in social media contexts and human-AI interaction design.",
      "authors": [
        "Wenlu Fan",
        "Yuqi Zhu",
        "Chenyang Wang",
        "Bin Wang",
        "Wentao Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T13:19:47+00:00",
          "link": "https://arxiv.org/abs/2501.08102v1",
          "size": "4905kb",
          "version": "v1"
        },
        {
          "date": "2025-01-15T18:10:00+00:00",
          "link": "https://arxiv.org/abs/2501.08102v2",
          "size": "4905kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T10:53:52+00:00",
          "link": "https://arxiv.org/abs/2501.08102v3",
          "size": "6205kb",
          "version": "v3"
        }
      ],
      "title": "Consistency of Responses and Continuations Generated by Large Language Models on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08102",
        "HTML": "https://arxiv.org/html/2501.08102v3",
        "PDF": "https://arxiv.org/pdf/2501.08102"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper investigates emotional and semantic processing in LLMs for social media contexts. It does not address creativity, focusing instead on emotional and semantic coherence."
      },
      "tasks": [
        "Semantic Similarity",
        "Semantic Textual Similarity",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15761",
      "abstract": "The deployment of large language models (LLMs) on extended reality (XR) devices has great potential to advance the field of human-AI interaction. In the case of direct, on-device model inference, selecting the appropriate model and device for specific tasks remains challenging. In this paper, we present AIvaluateXR, a comprehensive evaluation framework for benchmarking LLMs running on XR devices. To demonstrate the framework, we deploy 17 selected LLMs across four XR platforms: Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and Apple Vision Pro, and conduct an extensive evaluation. Our experimental setup measures four key metrics: performance consistency, processing speed, memory usage, and battery consumption. For each of the 68 model-device pairs, we assess performance under varying string lengths, batch sizes, and thread counts, analyzing the trade-offs for real-time XR applications. We propose a unified evaluation method based on the 3D Pareto Optimality theory to select the optimal device-model pairs from quality and speed objectives. Additionally, we compare the efficiency of on-device LLMs with client-server and cloud-based setups, and evaluate their accuracy on two interactive tasks. We believe our findings offer valuable insight to guide future optimization efforts for LLM deployment on XR devices. Our evaluation method can be used as standard groundwork for further research and development in this emerging field. The source code and supplementary materials are available at: www.nanovis.org/AIvaluateXR.html",
      "authors": [
        "Dawar Khan and Xinyu Liu and Omar Mena and Donggang Jia and Alexandre Kouyoumdjian and Ivan Viola"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T20:55:48+00:00",
          "link": "https://arxiv.org/abs/2502.15761v1",
          "size": "22982kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T11:10:07+00:00",
          "link": "https://arxiv.org/abs/2502.15761v2",
          "size": "18832kb",
          "version": "v2"
        }
      ],
      "title": "AIvaluateXR: An Evaluation Framework for on-Device AI in XR with Benchmarking Results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15761",
        "HTML": "https://arxiv.org/html/2502.15761v2",
        "PDF": "https://arxiv.org/pdf/2502.15761"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper discusses evaluating LLM performance on XR devices. It focuses on technical evaluation metrics, with no mention or exploration of creativity."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.22987",
      "abstract": "By late 20th century, the rationality wars had launched debates about the nature and norms of intuitive and reflective thinking. Those debates drew from mid-20th century ideas such as bounded rationality, which challenged more idealized notions of rationality observed since the 19th century. Now that 21st century cognitive scientists are applying the resulting dual pro-cess theories to artificial intelligence, it is time to dust off some lessons from this history. So this paper synthesizes old ideas with recent results from experiments on humans and machines. The result is Strategic Reflec-tivism, the position that one key to intelligent systems (human or artificial) is pragmatic switching between intuitive and reflective inference to opti-mally fulfill competing goals. Strategic Reflectivism builds on American Pragmatism, transcends superficial indicators of reflective thinking such as model size or chains of thought, applies to both individual and collective intelligence systems (including human-AI teams), and becomes increasingly actionable as we learn more about the value of intuition and reflection.",
      "authors": [
        "Nick Byrd"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T01:51:20+00:00",
          "link": "https://arxiv.org/abs/2505.22987v1",
          "size": "1348kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T20:04:13+00:00",
          "link": "https://arxiv.org/abs/2505.22987v2",
          "size": "1773kb",
          "version": "v2"
        }
      ],
      "title": "Strategic Reflectivism In Intelligent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22987",
        "PDF": "https://arxiv.org/pdf/2505.22987"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on Strategic Reflectivism in intelligent systems, discussing intuitive and reflective thinking rather than creativity. Its primary theme is about cognitive processes and decision-making."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.04295",
      "abstract": "Effective feedback is essential for student learning but is time-intensive for teachers. We present LearnLens, a modular, LLM-based system that generates personalised, curriculum-aligned feedback in science education. LearnLens comprises three components: (1) an error-aware assessment module that captures nuanced reasoning errors; (2) a curriculum-grounded generation module that uses a structured, topic-linked memory chain rather than traditional similarity-based retrieval, improving relevance and reducing noise; and (3) an educator-in-the-loop interface for customisation and oversight. LearnLens addresses key challenges in existing systems, offering scalable, high-quality feedback that empowers both teachers and students.",
      "authors": [
        "Runcong Zhao",
        "Artem Bobrov",
        "Jiazheng Li",
        "Yulan He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T08:39:26+00:00",
          "link": "https://arxiv.org/abs/2507.04295v1",
          "size": "1802kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T18:21:09+00:00",
          "link": "https://arxiv.org/abs/2507.04295v2",
          "size": "1803kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T11:37:12+00:00",
          "link": "https://arxiv.org/abs/2507.04295v3",
          "size": "1803kb",
          "version": "v3"
        }
      ],
      "title": "LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04295",
        "PDF": "https://arxiv.org/pdf/2507.04295"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper centers on educational feedback systems using LLMs, aiming to improve teaching efficiency and efficacy. Creativity is not mentioned or implied as a relevant theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.00124",
      "abstract": "Like most of NLP, models for human-centered NLP tasks -- tasks attempting to assess author-level information -- predominantly use representations derived from hidden states of Transformer-based LLMs. However, what component of the LM is used for the representation varies widely. Moreover, there is a need for Human Language Models (HuLMs) that implicitly model the author and provide a user-level hidden state. Here, we systematically evaluate different ways of representing documents and users using different LM and HuLM architectures to predict task outcomes as both dynamically changing states and averaged trait-like user-level attributes of valence, arousal, empathy, and distress. We find that representing documents as an average of the token hidden states performs the best generally. Further, while a user-level hidden state itself is rarely the best representation, we find its inclusion in the model strengthens token or document embeddings used to derive document- and user-level representations resulting in best performances.",
      "authors": [
        "Nikita Soni",
        "Pranav Chitale",
        "Khushboo Singh",
        "Niranjan Balasubramanian",
        "H. Andrew Schwartz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T19:10:06+00:00",
          "link": "https://arxiv.org/abs/2503.00124v1",
          "size": "7963kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of LLMs-based Hidden States as Author Representations for Psychological Human-Centered NLP Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00124",
        "HTML": "https://arxiv.org/html/2503.00124",
        "PDF": "https://arxiv.org/pdf/2503.00124"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLM hidden states for psychological NLP tasks. There is no direct connection to creativity, as it centers on author representation and user-level attributes."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/soni-n/llms_author_representations"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.08906",
      "abstract": "Educational games enhance learning experiences by integrating touchscreens, making interactions more engaging and intuitive for learners. However, the cognitive impacts of educational gameplay input modalities, such as the hand and stylus technique, are unclear. We compared the experience of using hands vs. a stylus for touchscreens while playing an educational game by analyzing oxygenated hemoglobin collected by functional Near-Infrared Spectroscopy and self-reported measures. In addition, we measured the hand vs. the stylus modalities of the task and calculated the relative neural efficiency and relative neural involvement using the mental demand and the quiz score. Our findings show that the hand condition had a significantly lower neural involvement, yet higher neural efficiency than the stylus condition. This result suggests the requirement of less cognitive effort while using the hand. Additionally, the self-reported measures show significant differences, and the results suggest that hand-based input is more intuitive, less cognitively demanding, and less frustrating. Conversely, the use of a stylus required higher cognitive effort due to the cognitive balance of controlling the pen and answering questions. These findings highlight the importance of designing educational games that allow learners to engage with the system while minimizing cognitive effort.",
      "authors": [
        "Shayla Sharmin",
        "Elham Bakhshipour",
        "Behdokht Kiafar",
        "Md Fahim Abrar",
        "Pinar Kullu",
        "Nancy Getchell",
        "Roghayeh Leila Barmaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-14T18:47:04+00:00",
          "link": "https://arxiv.org/abs/2405.08906v1",
          "size": "8440kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T18:12:09+00:00",
          "link": "https://arxiv.org/abs/2405.08906v2",
          "size": "4544kb",
          "version": "v2"
        },
        {
          "date": "2024-11-15T23:17:21+00:00",
          "link": "https://arxiv.org/abs/2405.08906v3",
          "size": "4544kb",
          "version": "v3"
        },
        {
          "date": "2025-02-03T19:12:29+00:00",
          "link": "https://arxiv.org/abs/2405.08906v4",
          "size": "13721kb",
          "version": "v4"
        },
        {
          "date": "2025-05-29T18:41:07+00:00",
          "link": "https://arxiv.org/abs/2405.08906v5",
          "size": "6261kb",
          "version": "v5"
        },
        {
          "date": "2025-07-18T14:17:15+00:00",
          "link": "https://arxiv.org/abs/2405.08906v6",
          "size": "6212kb",
          "version": "v6"
        }
      ],
      "title": "Functional Near-Infrared Spectroscopy (fNIRS) Analysis of Interaction Techniques in Touchscreen-Based Educational Gaming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.08906",
        "HTML": "https://arxiv.org/html/2405.08906",
        "PDF": "https://arxiv.org/pdf/2405.08906"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper\u2019s focus is on educational gaming and input methods, which may involve creative learning experiences, but creativity is not the central theme of the research."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.05014",
      "abstract": "With changing attitudes around knowledge, medicine, art, and technology, the human body has become a source of information and, ultimately, shareable and analyzable data. Centuries of illustrations and visualizations of the body occur within particular historical, social, and political contexts. These contexts are enmeshed in different so-called data cultures: ways that data, knowledge, and information are conceptualized and collected, structured and shared. In this work, we explore how information about the body was collected as well as the circulation, impact, and persuasive force of the resulting images. We show how mindfulness of data cultural influences remain crucial for today's designers, researchers, and consumers of visualizations. We conclude with a call for the field to reflect on how visualizations are not timeless and contextless mirrors on objective data, but as much a product of our time and place as the visualizations of the past.",
      "authors": [
        "Michael Correll and Laura A. Garrison"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T16:32:55+00:00",
          "link": "https://arxiv.org/abs/2402.05014v1",
          "size": "27420kb",
          "version": "v1"
        }
      ],
      "title": "When the Body Became Data: Historical Data Cultures and Anatomical Illustration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.05014",
        "PDF": "https://arxiv.org/pdf/2402.05014"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses the historical context of anatomical illustrations and the influence of data cultures on visualization, which could relate to creativity in terms of artistic and design processes, but it is not the main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12621",
      "abstract": "Traditional volume visualization (VolVis) methods, like direct volume rendering, suffer from rigid transfer function designs and high computational costs. Although novel view synthesis approaches enhance rendering efficiency, they require additional learning effort for non-experts and lack support for semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an interactive system that enables users to explore, query, and edit volumetric scenes using natural language. NLI4VolVis integrates multi-view semantic segmentation and vision-language models to extract and understand semantic components in a scene. We introduce a multi-agent large language model architecture equipped with extensive function-calling tools to interpret user intents and execute visualization tasks. The agents leverage external tools and declarative VolVis commands to interact with the VolVis engine powered by 3D editable Gaussians, enabling open-vocabulary object querying, real-time scene editing, best-view selection, and 2D stylization. We validate our system through case studies and a user study, highlighting its improved accessibility and usability in volumetric data exploration. We strongly recommend readers check our case studies, demo video, and source code at https://nli4volvis.github.io/.",
      "authors": [
        "Kuangshi Ai",
        "Kaiyuan Tang",
        "Chaoli Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:35:46+00:00",
          "link": "https://arxiv.org/abs/2507.12621v1",
          "size": "38160kb",
          "version": "v1"
        }
      ],
      "title": "NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12621",
        "HTML": "https://arxiv.org/html/2507.12621",
        "PDF": "https://arxiv.org/pdf/2507.12621"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While the primary focus is on enabling natural language interaction for volume visualization, the system enhances user experience in exploring volumetric scenes. Creativity is a secondary theme as it potentially facilitates creative data exploration and manipulation tasks."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Multimedia (cs.MM)",
    "Computation and Language (cs.CL)",
    "Systems and Control (eess.SY)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Artificial Intelligence (cs.AI)",
    "Systems and Control (cs.SY)",
    "Information Theory (math.IT)",
    "Emerging Technologies (cs.ET)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Multiagent Systems (cs.MA)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Machine Learning (cs.LG)"
  ],
  "prompt": {
    "creativity": "\nYou are an expert in information retrieval. I will provide you with a list of research papers from arXiv, specifically in the *cs.HC* (Human-Computer Interaction) category.\n\nYour task is to analyze each paper and determine its relevance to the topic of **Creativity**.\n\n\n### Classify each paper into one of the following relevance levels\n\n- `core` \u2014 Creativity is a **primary focus**\n  - The paper directly studies or simulates creativity, with a clear focus on creativity.\n  - Includes creative tasks, co-creative systems, or creativity evaluation metrics.\n  - The title and abstract explicitly mention creativity, and the research questions are directly related to creativity.\n- `partial` \u2014 Creativity is a **secondary theme**\n  - Part of the paper relates to creativity; it is treated as an analytical dimension or design goal but not the main objective (e.g., user creativity, design support).\n  - Creativity may appear in discussions, experiments, or auxiliary applications.\n  - Creativity is presented as a supporting topic (e.g., evaluation criteria, user feedback).\n- `irrelevant` \u2014 **No clear connection** to creativity\n  - The paper does not address creativity as a topic.\n  - Focuses on unrelated technical content (e.g., compression, security, optimization).\n  - If creativity is mentioned, it is only superficial and lacks substantive content.\n\n\n### Return your results in the following JSON format\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    },\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    }\n  ]\n}\n```\n\nBe concise but specific in your reasoning, referencing key terms or sections when applicable.\n"
  },
  "description": "Data source: https://arxiv.org/list/cs.HC/new",
  "level_tatistics": {
    "irrelevant": 22,
    "partial": 10,
    "core": 1
  },
  "arxiv_update_date": "2025-07-21",
  "updated_at": "2025-07-21 10:09:49"
}