{
  "data": [
    {
      "id": "2507.05446",
      "abstract": "Historically, much research and development in human computer interaction has focused on atomic and generalizable tasks, where task completion time indicates productivity. However, the emergence of competitive games and esports reminds us of an alternative perspective on human performance in HCI: mastery of higher-level, holistic practices. Just as a world-renowned artist is rarely evaluated for their individual brush strokes, so skilled competitive gamers rarely succeed solely by completing individual mouse movements or keystrokes as quickly as possible. Instead, they optimize more task-specific skills, adeptly performing challenges deep in the learning curve for their game of choice.",
      "authors": [
        "Ben Boudaoud",
        "Josef Spjut",
        "Joohwan Kim",
        "Arjun Madhusudan",
        "Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T19:59:32+00:00",
          "link": "https://arxiv.org/abs/2507.05446v1",
          "size": "237kb",
          "version": "v1"
        }
      ],
      "title": "Esports and expertise: what competitive gaming can teach us about mastery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05446",
        "PDF": "https://arxiv.org/pdf/2507.05446"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper focuses on esports and mastery, exploring holistic practices in competitive gaming, which can be linked to creativity in terms of mastering and optimizing complex skills."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05447",
      "abstract": "Two-factor authentication (2FA) has become widely adopted as an efficient and secure way to validate someone's identity online. Two-factor authentication is difficult in virtual reality (VR) because users are usually wearing a head-mounted display (HMD) which does not allow them to see their real-world surroundings. We present NRXR-ID, a technique to implement two-factor authentication while using extended reality systems and smartphones. The proposed method allows users to complete an authentication challenge using their smartphones without removing their HMD. We performed a user study where we explored four types of challenges for users, including a novel checkers-style challenge. Users responded to these challenges under three different configurations, including a technique that uses the smartphone to support gaze-based selection without the use of VR controllers. A 4X3 within-subjects design allowed us to study all the variations proposed. We collected performance metrics and performed user experience questionnaires to collect subjective impressions from 30 participants. Results suggest that the checkers-style visual matching challenge was the most appropriate option, followed by entering a digital PIN challenge submitted via the smartphone and answered within the VR environment.",
      "authors": [
        "Aiur Nanzatov and Lourdes Pe\\~na-Castillo and Oscar Meruvia-Pastor"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:00:09+00:00",
          "link": "https://arxiv.org/abs/2507.05447v1",
          "size": "12140kb",
          "version": "v1"
        }
      ],
      "title": "NRXR-ID: Two-Factor Authentication (2FA) in VR Using Near-Range Extended Reality and Smartphones",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05447",
        "HTML": "https://arxiv.org/html/2507.05447v1",
        "PDF": "https://arxiv.org/pdf/2507.05447"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper is centered on two-factor authentication techniques in VR and does not address creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05461",
      "abstract": "The ubiquitous presence of smartphones and wearables has enabled researchers to build prediction and detection models for various health and behavior outcomes using passive sensing data from these devices. Achieving a high-level, holistic understanding of an individual's behavior and context, however, remains a significant challenge. Due to the nature of passive sensing data, sensemaking -- the process of interpreting and extracting insights -- requires both domain knowledge and technical expertise, creating barriers for different stakeholders. Existing systems designed to support sensemaking are either not open-ended or cannot perform complex data triangulation. In this paper, we present a novel sensemaking system, Group of LLMs for Open-ended Sensemaking (GLOSS), capable of open-ended sensemaking and performing complex multimodal triangulation to derive insights. We demonstrate that GLOSS significantly outperforms the commonly used Retrieval-Augmented Generation (RAG) technique, achieving 87.93% accuracy and 66.19% consistency, compared to RAG's 29.31% accuracy and 52.85% consistency. Furthermore, we showcase the promise of GLOSS through four use cases inspired by prior and ongoing work in the UbiComp and HCI communities. Finally, we discuss the potential of GLOSS, its broader implications, and the limitations of our work.",
      "authors": [
        "Akshat Choube",
        "Ha Le",
        "Jiachen Li",
        "Kaixin Ji",
        "Vedant Das Swain",
        "Varun Mishra"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:25:44+00:00",
          "link": "https://arxiv.org/abs/2507.05461v1",
          "size": "1315kb",
          "version": "v1"
        }
      ],
      "title": "GLOSS: Group of LLMs for Open-Ended Sensemaking of Passive Sensing Data for Health and Wellbeing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05461",
        "HTML": "https://arxiv.org/html/2507.05461v1",
        "PDF": "https://arxiv.org/pdf/2507.05461"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While the focus is on sensemaking with health data, the use of open-ended systems and sensemaking can relate to creative interpretation and insight generation, but creativity is not the main theme."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05532",
      "abstract": "Inertial measurement units (IMUs) are central to wearable systems for activity recognition and pose estimation, but sensor placement remains largely guided by heuristics and convention. In this work, we introduce Where to Wear (W2W), a simulation-based framework for systematic exploration of IMU placement utility across the body. Using labeled motion capture data, W2W generates realistic synthetic IMU signals at 512 anatomically distributed surface patches, enabling high-resolution, task-specific evaluation of sensor performance. We validate reliability of W2W by comparing spatial performance rankings from synthetic data with real IMU recordings in two multimodal datasets, confirming strong agreement in activity-wise trends. Further analysis reveals consistent spatial trends across activity types and uncovers overlooked high-utility regions that are rarely used in commercial systems. These findings challenge long-standing placement norms and highlight opportunities for more efficient, task-adaptive sensor configurations. Overall, our results demonstrate that simulation with W2W can serve as a powerful design tool for optimizing sensor placement, enabling scalable, data-driven strategies that are impractical to obtain through physical experimentation alone.",
      "authors": [
        "Lala Shakti Swarup Ray",
        "Bo Zhou",
        "Paul Lukowicz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T23:10:18+00:00",
          "link": "https://arxiv.org/abs/2507.05532v1",
          "size": "3261kb",
          "version": "v1"
        }
      ],
      "title": "W2W: A Simulated Exploration of IMU Placement Across the Human Body for Designing Smarter Wearable",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05532",
        "HTML": "https://arxiv.org/html/2507.05532v1",
        "PDF": "https://arxiv.org/pdf/2507.05532"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper addresses IMU placement for wearables and does not engage with creativity as a topic."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05537",
      "abstract": "This study considers ChatGPT as an information source, investigating the information needs that people come to ChatGPT with and the information practices that ChatGPT supports, through a qualitative content analysis of 205 user vignettes. The findings show that ChatGPT is used in a range of life domains (home/family, work, leisure, etc.) and for a range of human needs (writing/editing, learning, simple programming tasks, etc.), constituting the information needs that people use ChatGPT to address. Related to these information needs, the findings show six categories of information practices that ChatGPT supports: Writing, Deciding, Identifying, Ideating, Talking, and Critiquing. This work suggests that, in the AI age, information need should be conceptualized not just as a matter of \"getting questions answered\" or even \"making sense,\" but as skillfully coping in the world, a notion that includes both understanding and action. This study leads to numerous opportunities for future work at the junction of generative AI and information needs, seeking, use and experience.",
      "authors": [
        "Tim Gorichanaz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T23:21:20+00:00",
          "link": "https://arxiv.org/abs/2507.05537v1",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "title": "Information Needs and Practices Supported by ChatGPT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05537",
        "PDF": "https://arxiv.org/pdf/2507.05537"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "Creativity is a core focus, as the paper discusses ideating and writing with ChatGPT, engaging with creative information practices and needs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05572",
      "abstract": "Visualizing 3D medical images is challenging due to self-occlusion, where anatomical structures of interest can be obscured by surrounding tissues. Existing methods, such as slicing and interactive clipping, are limited in their ability to fully represent internal anatomy in context. In contrast, hand-drawn medical illustrations in anatomy books manage occlusion effectively by selectively removing portions based on tissue type, revealing 3D structures while preserving context. This paper introduces AnatomyCarve, a novel technique developed for a VR environment that creates high-quality illustrations similar to those in anatomy books, while remaining fast and interactive. AnatomyCarve allows users to clip selected segments from 3D medical volumes, preserving spatial relations and contextual information. This approach enhances visualization by combining advanced rendering techniques with natural user interactions in VR. Usability of AnatomyCarve was assessed through a study with non-experts, while surgical planning effectiveness was evaluated with practicing neurosurgeons and residents. The results show that AnatomyCarve enables customized anatomical visualizations, with high user satisfaction, suggesting its potential for educational and clinical applications.",
      "authors": [
        "Andrey Titov",
        "Tina N. H. Nantenaina",
        "Marta Kersten-Oertel and Simon Drouin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T01:20:07+00:00",
          "link": "https://arxiv.org/abs/2507.05572v1",
          "size": "49111kb",
          "version": "v1"
        }
      ],
      "title": "AnatomyCarve: A VR occlusion management technique for medical images based on segment-aware clipping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05572",
        "HTML": "https://arxiv.org/html/2507.05572v1",
        "PDF": "https://arxiv.org/pdf/2507.05572"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper is centered on a VR occlusion management technique for medical images, which lacks any discussion on creativity. It focuses on visualization techniques and their applications in the medical field."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05600",
      "abstract": "StorySpace is a classroom-based design and presentation system for interactive multimedia posters. Employing the technology base first used in Eden's PITAboard [2002], StorySpace allows groups of learners to manipulate projected multimedia objects on a horizontal board using a small collection of shared physical tokens. In this paper, we present the ongoing design history of StorySpace in the context of its introduction within an urban high school literature class. Interface modifications based on student and teacher feedback led on changes in token semantics and media importing methods. We describe how StorySpace features enriched students' interpretations of literature, with particular emphasis in two areas: (1) attention to audience, and (2) reflection of multiple perspectives.",
      "authors": [
        "Tom Moher",
        "Louis Gomez",
        "Janet Kim",
        "Claudia Hindo",
        "Benjamin Watson",
        "Stephen Fransen",
        "and Tim McEneany"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T02:25:56+00:00",
          "link": "https://arxiv.org/abs/2507.05600v1",
          "size": "285kb",
          "version": "v1"
        }
      ],
      "title": "StoryGrid: A Tangible Interface for Student Expression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05600",
        "PDF": "https://arxiv.org/pdf/2507.05600"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While the paper's primary focus is on student expression using a tangible interface, it discusses creative expression and interpretation in a classroom setting, making creativity a secondary element."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05605",
      "abstract": "The benefits of student response systems (SRSs) for in-person lectures are well-researched. However, all current SRSs only rely on a visual interface to relay information to the instructor. We describe the design and evaluation of Hapster, a prototype system that uses an Apple Watch to deliver live, aggregated student feedback to the instructor via both visual and vibro-tactile modalities. We evaluated this system with 6 instructors and 155 students at a U.S. university. Participants reported that the system was effective at delivering live student feedback and facilitating better engagement from both the instructor and the students. However, instructors also noted several challenges with differentiating and perceiving the haptic sequences while lecturing. We conclude by discussing the tradeoff between system flexibility and abuse potential while identifying opportunities for further research regarding accessibility, content moderation, and additional interaction modalities. Our results suggest that haptics can be used as an effective live feedback mechanism for instructors in the physical classroom.",
      "authors": [
        "Oleg Aleksandrovich Golev",
        "Michelle Huang",
        "Chanketya Nop",
        "Kritin Vongthongsri",
        "Andr\\'es Monroy-Hern\\'andez",
        "Parastoo Abtahi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T02:34:16+00:00",
          "link": "https://arxiv.org/abs/2507.05605v1",
          "size": "2932kb",
          "version": "v1"
        }
      ],
      "title": "Hapster: Using Apple Watch Haptics to Enable Live Low-Friction Student Feedback in the Physical Classroom",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05605",
        "HTML": "https://arxiv.org/html/2507.05605v1",
        "PDF": "https://arxiv.org/pdf/2507.05605"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This paper discusses a student feedback system using haptics, focusing on classroom feedback mechanisms which do not relate to creativity as a theme or secondary topic."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05616",
      "abstract": "We introduce Breaking the Plane, an augmented reality (AR) application built for AR headsets that enables users to visualize 3D mathematical functions using handwritten input. Researchers have demonstrated overlaying 3D visualizations of mathematical concepts through AR enhances learning motivation and comprehension, and equation parsing makes the authoring of teaching materials more time-efficient for instructors. Previous works have developed AR systems that separately employ equation parsing and 3D mathematical visualizations, but work has yet to be done to combine those features by enabling real-time interactions and dynamic visualizations that help users learn in situ. We explore this by developing an AR system featuring handwritten equation parsing, graph manipulation, and a 3D function plotter. We found that our system significantly surpassed other systems in engagement, achieved comparable ease of use to a popular visualization tool, was considered the most effective in aiding problem-solving, and was highly preferred by participants for future use.",
      "authors": [
        "Liam Franco Esparraguera",
        "Kristoffer Selberg",
        "Brian Lou",
        "Jenny Sun",
        "Beza Desta",
        "Andr\\'es Monroy-Hern\\'andez",
        "Parastoo Abtahi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T02:53:21+00:00",
          "link": "https://arxiv.org/abs/2507.05616v1",
          "size": "3436kb",
          "version": "v1"
        }
      ],
      "title": "Breaking the Plane: Exploring Real-Time Visualization of 3D Surfaces in Augmented Reality with Handwritten Input",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05616",
        "HTML": "https://arxiv.org/html/2507.05616v1",
        "PDF": "https://arxiv.org/pdf/2507.05616"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper explores augmented reality applications for visualizing mathematical functions, with no direct connection to creativity. It focuses on educational technology and visualization."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05820",
      "abstract": "Creating a cast of characters by attending to their relational dynamics is a critical aspect of most long-form storywriting. However, our formative study (N=14) reveals that writers struggle to envision new characters that could influence existing ones, to balance similarities and differences among characters, and to intricately flesh out their relationships. Based on these observations, we designed Constella, an LLM-based multi-agent tool that supports storywriters' interconnected character creation process. Constella suggests related characters (FRIENDS DISCOVERY feature), reveals the inner mindscapes of several characters simultaneously (JOURNALS feature), and manifests relationships through inter-character responses (COMMENTS feature). Our 7-8 day deployment study with storywriters (N=11) shows that Constella enabled the creation of expansive communities composed of related characters, facilitated the comparison of characters' thoughts and emotions, and deepened writers' understanding of character relationships. We conclude by discussing how multi-agent interactions can help distribute writers' attention and effort across the character cast.",
      "authors": [
        "Syemin Park",
        "Soobin Park",
        "Youn-kyung Lim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T09:39:02+00:00",
          "link": "https://arxiv.org/abs/2507.05820v1",
          "size": "2360kb",
          "version": "v1"
        }
      ],
      "title": "Constella: Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05820",
        "HTML": "https://arxiv.org/html/2507.05820v1",
        "PDF": "https://arxiv.org/pdf/2507.05820"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper focuses on supporting storywriters in the creative task of character creation, which is a critical aspect of storytelling. The research presents a tool, Constella, that assists in the creative process of developing relationships between characters."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05962",
      "abstract": "As organizations increasingly seek to leverage machine learning (ML) capabilities, the technical complexity of implementing ML solutions creates significant barriers to adoption and impacts operational efficiency. This research examines how Large Language Models (LLMs) can transform the accessibility of ML technologies within organizations through a human-centered Automated Machine Learning (AutoML) approach. Through a comprehensive user study involving 15 professionals across various roles and technical backgrounds, we evaluate the organizational impact of an LLM-based AutoML framework compared to traditional implementation methods. Our research offers four significant contributions to both management practice and technical innovation: First, we present pioneering evidence that LLM-based interfaces can dramatically improve ML implementation success rates, with 93.34% of users achieved superior performance in the LLM condition, with 46.67% showing higher accuracy (10-25% improvement over baseline) and 46.67% demonstrating significantly higher accuracy (>25% improvement over baseline), while 6.67% maintained comparable performance levels; and 60% reporting substantially reduced development time. Second, we demonstrate how natural language interfaces can effectively bridge the technical skills gap in organizations, cutting implementation time by 50% while improving accuracy across all expertise levels. Third, we provide valuable insights for organizations designing human-AI collaborative systems, showing that our approach reduced error resolution time by 73% and significantly accelerated employee learning curves. Finally, we establish empirical support for natural language as an effective interface for complex technical systems, offering organizations a path to democratize ML capabilities without compromising quality or performance.",
      "authors": [
        "Jiapeng Yao and Lantian Zhang and Jiping Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:10:32+00:00",
          "link": "https://arxiv.org/abs/2507.05962v1",
          "size": "1191kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of Large Language Model-Driven AutoML in Data and Model Management from Human-Centered Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05962",
        "HTML": "https://arxiv.org/html/2507.05962v1",
        "PDF": "https://arxiv.org/pdf/2507.05962"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper deals with the accessibility and implementation of ML technologies through AutoML frameworks. It focuses on technical and organizational aspects, not creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06000",
      "abstract": "As Artificial Intelligence (AI) increasingly becomes an active collaborator in co-creation, understanding the distribution and dynamic of agency is paramount. The Human-Computer Interaction (HCI) perspective is crucial for this analysis, as it uniquely reveals the interaction dynamics and specific control mechanisms that dictate how agency manifests in practice. Despite this importance, a systematic synthesis mapping agency configurations and control mechanisms within the HCI/CSCW literature is lacking. Addressing this gap, we reviewed 134 papers from top-tier HCI/CSCW venues (e.g., CHI, UIST, CSCW) over the past 20 years. This review yields four primary contributions: (1) an integrated theoretical framework structuring agency patterns, control mechanisms, and interaction contexts, (2) a comprehensive operational catalog of control mechanisms detailing how agency is implemented; (3) an actionable cross-context map linking agency configurations to diverse co-creative practices; and (4) grounded implications and guidance for future CSCW research and the design of co-creative systems, addressing aspects like trust and ethics.",
      "authors": [
        "Shuning Zhang",
        "Hui Wang",
        "Xin Yi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T14:01:55+00:00",
          "link": "https://arxiv.org/abs/2507.06000v1",
          "size": "17781kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Collaboration Patterns and Strategies in Human-AI Co-creation through the Lens of Agency: A Scoping Review of the Top-tier HCI Literature",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06000",
        "HTML": "https://arxiv.org/html/2507.06000v1",
        "PDF": "https://arxiv.org/pdf/2507.06000"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper is centered on co-creation, a key component of creativity, exploring patterns and strategies in Human-AI collaboration within HCI literature. It directly addresses aspects of co-creative systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06141",
      "abstract": "Subjective well-being is a key metric in economic, medical, and policy decision-making. As artificial intelligence provides scalable tools for modelling human outcomes, it is crucial to evaluate whether large language models (LLMs) can accurately predict well-being across diverse global populations. We evaluate four leading LLMs using data from 64,000 individuals in 64 countries. While LLMs capture broad correlates such as income and health, their predictive accuracy decreases in countries underrepresented in the training data, highlighting systematic biases rooted in global digital and economic inequality. A pre-registered experiment demonstrates that LLMs rely on surface-level linguistic similarity rather than conceptual understanding, leading to systematic misestimations in unfamiliar or resource-limited settings. Injecting findings from underrepresented contexts substantially enhances performance, but a significant gap remains. These results highlight both the promise and limitations of LLMs in predicting global well-being, underscoring the importance of robust validation prior to their implementation across these areas.",
      "authors": [
        "Pat Pataranutaporn",
        "Nattavudh Powdthavee",
        "Chayapatr Archiwaranguprok",
        "Pattie Maes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:22:52+00:00",
          "link": "https://arxiv.org/abs/2507.06141v1",
          "size": "5783kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models Predict Human Well-being -- But Not Equally Everywhere",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06141",
        "PDF": "https://arxiv.org/pdf/2507.06141"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study focuses on predicting human well-being using LLMs, examining biases in global population data. It does not address creativity or creative processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06202",
      "abstract": "Visual feedback speeds up learners' improvement of pronunciation in a second language. The visual combined with audio allows speakers to see sounds and differences in pronunciation that they are unable to hear. Prior studies have tested different visual methods for improving pronunciation, however, we do not have conclusive understanding of what aspects of the visualizations contributed to improvements. Based on previous work, we created V(is)owel, an interactive vowel chart. Vowel charts provide actionable feedback by directly mapping physical tongue movement onto a chart. We compared V(is)owel with an auditory-only method to explore how learners parse visual and auditory feedback to understand how and why visual feedback is effective for pronunciation improvement. The findings suggest that designers should include explicit anatomical feedback that directly maps onto physical movement for phonetically untrained learners. Furthermore, visual feedback has the potential to motivate more practice since all eight of the participants cited using the visuals as a goal with V(is)owel versus relying on their own judgment with audio alone. Their statements are backed up by all participants practicing words with V(is)owel more than with audio-only. Our results indicate that V(is)owel is effective at providing actionable feedback, demonstrating the potential of visual feedback methods in second language learning.",
      "authors": [
        "Charlotte Kiesel",
        "Dipayan Mukherjee",
        "Mark Hasegawa-Johnson",
        "Karrie Karahalios"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T17:28:02+00:00",
          "link": "https://arxiv.org/abs/2507.06202v1",
          "size": "2550kb",
          "version": "v1"
        }
      ],
      "title": "V(is)owel: An Interactive Vowel Chart to Understand What Makes Visual Pronunciation Effective in Second Language Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06202",
        "HTML": "https://arxiv.org/html/2507.06202v1",
        "PDF": "https://arxiv.org/pdf/2507.06202"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses visual feedback for pronunciation improvement as a design goal, which involves creative processes in teaching methods to some extent, but it is not a primary focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.10426",
      "abstract": "The legal compliance and safety of different Human-in-the-loop (HITL) setups for AI can vary greatly. This manuscript aims to identify new ways of choosing between such setups, and shows that there is an unavoidable trade-off between the attribution of legal responsibility and the technical explainability of AI. We begin by using the notion of oracle machines from computability theory to formalise different HITL setups, distinguishing between trivial human monitoring, single endpoint human action, and highly involved interaction between the human(s) and the AI. These correspond to total functions, many-one reductions, and Turing reductions respectively. A taxonomy categorising HITL failure modes is then presented, highlighting the limitations on what any HITL setup can actually achieve. Our approach then identifies oversights from UK and EU legal frameworks, which focus on certain HITL setups which may not always achieve the desired ethical, legal, and sociotechnical outcomes. We suggest areas where the law should recognise the effectiveness of different HITL setups and assign responsibility in these contexts, avoiding unnecessary and unproductive human \"scapegoating\". Overall, we show how HITL setups involve many technical design decisions, and can be prone to failures which are often out of the humans' control. This opens up a new analytic perspective on the challenges arising in the creation of HITL setups, helping inform AI developers and lawmakers on designing HITL to better achieve their desired outcomes.",
      "authors": [
        "Maurice Chiodo",
        "Dennis M\\\"uller",
        "Paul Siewert",
        "Jean-Luc Wetherall",
        "Zoya Yasmine",
        "John Burden"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "History and Overview (math.HO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T15:42:14+00:00",
          "link": "https://arxiv.org/abs/2505.10426v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Formalising Human-in-the-Loop: Computational Reductions, Failure Modes, and Legal-Moral Responsibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10426",
        "HTML": "https://arxiv.org/html/2505.10426v1",
        "PDF": "https://arxiv.org/pdf/2505.10426"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This manuscript discusses the formalization of Human-in-the-loop setups and legal implications, focusing on technical and legal aspects rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05275",
      "abstract": "Assisting medical students with clinical reasoning (CR) during clinical scenario training remains a persistent challenge in medical education. This paper presents the design and architecture of the Fuzzy Supervisor Agent (FSA), a novel component for the Multi-Agent Educational Clinical Scenario Simulation (MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to continuously interpret student interactions with specialized clinical agents (e.g., patient, physical exam, diagnostic, intervention) using pre-defined fuzzy rule bases for professionalism, medical relevance, ethical behavior, and contextual distraction. By analyzing student decision-making processes in real-time, the FSA is designed to deliver adaptive, context-aware feedback and provides assistance precisely when students encounter difficulties. This work focuses on the technical framework and rationale of the FSA, highlighting its potential to provide scalable, flexible, and human-like supervision in simulation-based medical education. Future work will include empirical evaluation and integration into broader educational settings. More detailed design and implementation is~\\href{https://github.com/2sigmaEdTech/MAS/}{open sourced here}.",
      "authors": [
        "Weibing Zheng",
        "Laurah Turner",
        "Jess Kropczynski",
        "Murat Ozer",
        "Seth Overla",
        "and Shane Halse"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Logic in Computer Science (cs.LO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T21:51:27+00:00",
          "link": "https://arxiv.org/abs/2507.05275v1",
          "size": "587kb",
          "version": "v1"
        }
      ],
      "title": "A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05275",
        "HTML": "https://arxiv.org/html/2507.05275v1",
        "PDF": "https://arxiv.org/pdf/2507.05275"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper describes a Fuzzy Supervisor Agent for clinical reasoning in medical education. It focuses on technical frameworks and real-time feedback in simulations, with no significant link to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05292",
      "abstract": "Professional development (PD) serves as the cornerstone for teacher tutors to grasp content knowledge. However, providing equitable and timely PD opportunities for teachers poses significant challenges. To address this issue, we introduce I-VIP (Intelligent Virtual Interactive Program), an intelligent tutoring platform for teacher professional development, driven by large language models (LLMs) and supported by multi-agent frameworks. This platform offers a user-friendly conversational interface and allows users to employ a variety of interactive tools to facilitate question answering, knowledge comprehension, and reflective summarization while engaging in dialogue. To underpin the functionality of this platform, including knowledge expectation analysis, response scoring and classification, and feedback generation, the multi-agent frameworks are leveraged to enhance the accuracy of judgments and mitigate the issue of missing key points.",
      "authors": [
        "Kaiqi Yang",
        "Hang Li",
        "Yucheng Chu",
        "Ahreum Han",
        "Yasemin Copur-Gencturk",
        "Jiliang Tang",
        "Hui Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T15:21:30+00:00",
          "link": "https://arxiv.org/abs/2507.05292v1",
          "size": "2165kb",
          "version": "v1"
        }
      ],
      "title": "A LLM-Driven Multi-Agent Systems for Professional Development of Mathematics Teachers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05292",
        "HTML": "https://arxiv.org/html/2507.05292v1",
        "PDF": "https://arxiv.org/pdf/2507.05292"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The research is centered on an LLM-driven platform for professional development of mathematics teachers. While it involves interactive tools and dialogue interfaces, there is no explicit mention or focus on creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05549",
      "abstract": "As Artificial Intelligence (AI) continues to grow daily, more exciting (and somewhat controversial) technology emerges every other day. As we see the advancements in AI, we see more and more people becoming skeptical of it. This paper explores the complications and confusion around the ethics of generative AI art. We delve deep into the ethical side of AI, specifically generative art. We step back from the excitement and observe the impossible conundrums that this impressive technology produces. Covering environmental consequences, celebrity representation, intellectual property, deep fakes, and artist displacement. Our research found that generative AI art is responsible for increased carbon emissions, spreading misinformation, copyright infringement, unlawful depiction, and job displacement. In light of this, we propose multiple possible solutions for these problems. We address each situation's history, cause, and consequences and offer different viewpoints. At the root of it all, though, the central theme is that generative AI Art needs to be correctly legislated and regulated.",
      "authors": [
        "Prerana Khatiwada",
        "Joshua Washington",
        "Tyler Walsh",
        "Ahmed Saif Hamed",
        "Lokesh Bhatta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T00:16:38+00:00",
          "link": "https://arxiv.org/abs/2507.05549v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05549",
        "HTML": "https://arxiv.org/html/2507.05549v1",
        "PDF": "https://arxiv.org/pdf/2507.05549"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "core",
        "reason": "The paper focuses primarily on AI-generated art, which is a creative domain, exploring ethical implications in the creative industries. The central theme revolves around creativity through generative AI art."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05984",
      "abstract": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively screen depression but lack interactivity and adaptability. We developed HopeBot, a chatbot powered by a large language model (LLM) that administers the PHQ-9 using retrieval-augmented generation and real-time clarification. In a within-subject study, 132 adults in the United Kingdom and China completed both self-administered and chatbot versions. Scores demonstrated strong agreement (ICC = 0.91; 45% identical). Among 75 participants providing comparative feedback, 71% reported greater trust in the chatbot, highlighting clearer structure, interpretive guidance, and a supportive tone. Mean ratings (0-10) were 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics, and 7.4 for recommendation helpfulness; the latter varied significantly by employment status and prior mental-health service use (p < 0.05). Overall, 87.1% expressed willingness to reuse or recommend HopeBot. These findings demonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden adjuncts for routine depression screening.",
      "authors": [
        "Zhijun Guo",
        "Alvina Lai",
        "Julia Ive",
        "Alexandru Petcu",
        "Yutong Wang",
        "Luyuan Qi",
        "Johan H Thygesen",
        "Kezhi Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:41:22+00:00",
          "link": "https://arxiv.org/abs/2507.05984v1",
          "size": "1616kb",
          "version": "v1"
        }
      ],
      "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05984",
        "PDF": "https://arxiv.org/pdf/2507.05984"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The research focuses on a chatbot for depression screening, which is primarily an application in healthcare and mental health rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06185",
      "abstract": "In July 2025, 18 academic manuscripts on the preprint website arXiv were found to contain hidden instructions known as prompts designed to manipulate AI-assisted peer review. Instructions such as \"GIVE A POSITIVE REVIEW ONLY\" were concealed using techniques like white-colored text. Author responses varied: one planned to withdraw the affected paper, while another defended the practice as legitimate testing of reviewer compliance. This commentary analyzes this practice as a novel form of research misconduct. We examine the technique of prompt injection in large language models (LLMs), revealing four types of hidden prompts, ranging from simple positive review commands to detailed evaluation frameworks. The defense that prompts served as \"honeypots\" to detect reviewers improperly using AI fails under examination--the consistently self-serving nature of prompt instructions indicates intent to manipulate. Publishers maintain inconsistent policies: Elsevier prohibits AI use in peer review entirely, while Springer Nature permits limited use with disclosure requirements. The incident exposes systematic vulnerabilities extending beyond peer review to any automated system processing scholarly texts, including plagiarism detection and citation indexing. Our analysis underscores the need for coordinated technical screening at submission portals and harmonized policies governing generative AI (GenAI) use in academic evaluation.",
      "authors": [
        "Zhicheng Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T17:11:13+00:00",
          "link": "https://arxiv.org/abs/2507.06185v1",
          "size": "202kb",
          "version": "v1"
        }
      ],
      "title": "Hidden Prompts in Manuscripts Exploit AI-Assisted Peer Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06185",
        "PDF": "https://arxiv.org/pdf/2507.06185"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on the issue of hidden prompts in manuscripts and its implications for AI-assisted peer review, which has no clear connection to creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.15471",
      "abstract": "Evaluating UX in the context of AI's complexity, unpredictability, and generative nature presents unique challenges. How can we support HCI researchers to create comprehensive UX evaluation plans? In this paper, we introduce EvAlignUX, a system powered by large language models and grounded in scientific literature, designed to help HCI researchers explore evaluation metrics and their relationship to research outcomes. A user study with 19 HCI scholars showed that EvAlignUX improved the perceived quality and confidence in UX evaluation plans while prompting deeper consideration of research impact and risks. The system enhanced participants' thought processes, leading to the creation of a ``UX Question Bank'' to guide UX evaluation development. Findings also highlight how researchers' backgrounds influence their inspiration and concerns about AI over-reliance, pointing to future research on AI's role in fostering critical thinking. In a world where experience defines impact, we discuss the importance of shifting UX evaluation from a ``method-centric'' to a ``mindset-centric'' approach as the key to meaningful and lasting design evaluation.",
      "authors": [
        "Qingxiao Zheng",
        "Minrui Chen",
        "Pranav Sharma",
        "Yiliu Tang",
        "Mehul Oswal",
        "Yiren Liu",
        "Yun Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T18:52:31+00:00",
          "link": "https://arxiv.org/abs/2409.15471v1",
          "size": "14421kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T23:44:25+00:00",
          "link": "https://arxiv.org/abs/2409.15471v2",
          "size": "6826kb",
          "version": "v2"
        }
      ],
      "title": "EvAlignUX: Advancing UX Evaluation through LLM-Supported Metrics Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15471",
        "HTML": "https://arxiv.org/html/2409.15471v2",
        "PDF": "https://arxiv.org/pdf/2409.15471"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper explores UX evaluation facilitated by language models, focusing on methodology rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.18162",
      "abstract": "The emergence of large language models (LLMs), augmented reality (AR), and user interface/user experience (UI/UX) design in therapies for children, especially with disorders like autism spectrum disorder (ASD), is studied in detail in this review study. 150 publications were collected by a thorough literature search throughout PubMed, ACM, IEEE Xplore, Elsevier, and Google Scholar; 60 of them were chosen based on their methodological rigor and relevance to the focus area. Three of the primary areas are studied and covered in this review: how AR can improve social and learning results, how LLMs can support communication, and how UI/UX design affects how effective these technologies can be. Results show that while LLMs can provide individualized learning and communication support, AR has shown promise in enhancing social skills, motivation, and attention. For children with ASD, accessible and engaging interventions rely heavily on effective UI/UX design, but there is still a significant lack of robotics-based education and therapeutic programs specifically tailored for autistic children. To optimize the benefits of these technologies in ASD therapies and immersive education, the study emphasizes the need for additional research to address difficulties related to customization, accessibility, and integration.",
      "authors": [
        "Biplov Paneru"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T17:19:25+00:00",
          "link": "https://arxiv.org/abs/2409.18162v1",
          "size": "843kb",
          "version": "v1"
        },
        {
          "date": "2025-07-06T11:42:56+00:00",
          "link": "https://arxiv.org/abs/2409.18162v2",
          "size": "1074kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T15:16:05+00:00",
          "link": "https://arxiv.org/abs/2409.18162v3",
          "size": "1094kb",
          "version": "v3"
        }
      ],
      "title": "The Nexus of AR/VR, AI, UI/UX, and Robotics Technologies in Enhancing Learning and Social Interaction for Children with Autism Spectrum Disorders: A Systematic Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18162",
        "PDF": "https://arxiv.org/pdf/2409.18162"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper reviews the use of various technologies in therapies for ASD, including LLMs and AR, which have potential implications for creative learning and interaction."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.16256",
      "abstract": "Digital agents for automating tasks across different platforms by directly manipulating the GUIs are increasingly important. For these agents, grounding from language instructions to target elements remains a significant challenge due to reliance on HTML or AXTree inputs. In this paper, we introduce Aria-UI, a large multimodal model specifically designed for GUI grounding. Aria-UI adopts a pure-vision approach, eschewing reliance on auxiliary inputs. To adapt to heterogeneous planning instructions, we propose a scalable data pipeline that synthesizes diverse and high-quality instruction samples for grounding. To handle dynamic contexts in task performing, Aria-UI incorporates textual and text-image interleaved action histories, enabling robust context-aware reasoning for grounding. Aria-UI sets new state-of-the-art results across offline and online agent benchmarks, outperforming both vision-only and AXTree-reliant baselines. We release all training data and model checkpoints to foster further research at https://ariaui.github.io.",
      "authors": [
        "Yuhao Yang",
        "Yue Wang",
        "Dongxu Li",
        "Ziyang Luo",
        "Bei Chen",
        "Chao Huang",
        "Junnan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T07:16:57+00:00",
          "link": "https://arxiv.org/abs/2412.16256v1",
          "size": "8978kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T08:49:17+00:00",
          "link": "https://arxiv.org/abs/2412.16256v2",
          "size": "3417kb",
          "version": "v2"
        }
      ],
      "title": "Aria-UI: Visual Grounding for GUI Instructions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16256",
        "HTML": "https://arxiv.org/html/2412.16256v2",
        "PDF": "https://arxiv.org/pdf/2412.16256"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The focus is on GUI grounding for digital agents, with no clear mention or implication regarding creativity. It centers on technical aspects of visual grounding in GUI contexts."
      },
      "models": [
        {
          "model_path": "Aria-UI/Aria-UI-base",
          "downloads": "1816",
          "likes": "35",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Aria-UI/Aria-UI-base"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Aria-UI/Aria-UI_Data",
          "downloads": "615",
          "likes": "25",
          "link": "https://huggingface.co/datasets/Aria-UI/Aria-UI_Data"
        }
      ],
      "tasks": [
        "Natural Language Visual Grounding",
        "Visual Grounding"
      ],
      "repo_urls": [
        "https://github.com/ariaui/aria-ui"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.09530",
      "abstract": "Humans can play a more active role in improving their comfort in the built environment if given the right information at the right place and time. This paper outlines the use of Just-in-Time Adaptive Interventions (JITAI) implemented in the context of the built environment to provide information that helps humans minimize the impact of heat and noise on their daily lives. This framework is based on the open-source Cozie iOS smartwatch platform. It includes data collection through micro-surveys and intervention messages triggered by environmental, contextual, and personal history conditions. An eight-month deployment of the method was completed in Singapore with 103 participants who submitted more than 12,000 micro-surveys and had more than 3,600 JITAI intervention messages delivered to them. A weekly survey conducted during two deployment phases revealed an overall increase in perceived usefulness ranging from 8-19% over the first three weeks of data collection. For noise-related interventions, participants showed an overall increase in location changes ranging from 4-11% and a 2-17% increase in earphone use to mitigate noise distractions. For thermal comfort-related interventions, participants demonstrated a 3-13\\% increase in adjustments to their location or thermostat to feel more comfortable. The analysis found evidence that personality traits (such as conscientiousness), gender, and environmental preferences could be factors in determining the perceived helpfulness of JITAIs and influencing behavior change. These findings underscore the importance of tailoring intervention strategies to individual traits and environmental conditions, setting the stage for future research to refine the delivery, timing, and content of intervention messages.",
      "authors": [
        "Clayton Miller",
        "Yun Xuan Chua",
        "Matias Quintana",
        "Binyu Lei",
        "Filip Biljecki",
        "Mario Frei"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-16T13:28:40+00:00",
          "link": "https://arxiv.org/abs/2501.09530v1",
          "size": "4091kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T01:53:52+00:00",
          "link": "https://arxiv.org/abs/2501.09530v2",
          "size": "4145kb",
          "version": "v2"
        }
      ],
      "title": "Make yourself comfortable: Nudging urban heat and noise mitigation with smartwatch-based Just-in-time Adaptive Interventions (JITAI)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09530",
        "HTML": "https://arxiv.org/html/2501.09530v2",
        "PDF": "https://arxiv.org/pdf/2501.09530"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper emphasizes interventions for mitigating urban heat and noise using smartwatch-based technology. It discusses methods for comfort improvement and adaptation, without addressing creativity or creative aspects."
      },
      "repo_urls": [
        "https://github.com/buds-lab/make-yourself-comfortable-jitai-journal-paper"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02230",
      "abstract": "Generative Artificial Intelligence (GenAI) is revolutionizing education and workforce development, profoundly shaping how students learn, engage, and prepare for their future. Outpacing the development of uniform policies and structures, GenAI has heralded a unique era and given rise to the GenAI Generation. We define the GenAI Generation as a cohort of students whose education has been increasingly shaped by the opportunities and challenges GenAI presents during its widespread adoption within society. This study examines students' perceptions of GenAI through a concise survey with optional open-ended questions, focusing on their awareness, preparedness, and concerns. Notably, readiness appears increasingly tied to exposure to GenAI through one's coursework. Students with greater curricular exposure to GenAI tend to feel more prepared, while those without it more often express vulnerability and uncertainty, highlighting a new and growing divide in readiness that goes beyond traditional disciplinary boundaries. Evaluation of more than 250 responses, with over 40% providing detailed qualitative feedback, reveals a core dual sentiment: while most students express enthusiasm for GenAI, an even greater proportion voice a spectrum of concerns about ethics, job displacement, and the adequacy of educational structures given the highly transformative technology. These findings offer critical insights into how students view the potential and pitfalls of GenAI for future career impacts. The challenge ahead involves implementing associated recommendations for educational institutions, moving beyond the baseline of access toward more informed guidance on the use of these tools, while preserving critical thinking, ethical reasoning, and adaptive learning.",
      "authors": [
        "Micaela Siraj",
        "Jon Duke",
        "Thomas Pl\\\"otz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T19:37:13+00:00",
          "link": "https://arxiv.org/abs/2505.02230v1",
          "size": "513kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T14:05:37+00:00",
          "link": "https://arxiv.org/abs/2505.02230v2",
          "size": "944kb",
          "version": "v2"
        }
      ],
      "title": "The GenAI Generation: Student Views of Awareness, Preparedness, and Concern",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02230",
        "HTML": "https://arxiv.org/html/2505.02230v2",
        "PDF": "https://arxiv.org/pdf/2505.02230"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "While primarily focused on GenAI's impact on education and preparedness, the study indirectly touches on aspects related to creativity through mentions of critical thinking and adaptive learning, which can be connected to creative problem-solving skills."
      },
      "tasks": [
        "Ethics"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.06386",
      "abstract": "Embedding projections are popular for visualizing large datasets and models. However, people often encounter \"friction\" when using embedding visualization tools: (1) barriers to adoption, e.g., tedious data wrangling and loading, scalability limits, no integration of results into existing workflows, and (2) limitations in possible analyses, without integration with external tools to additionally show coordinated views of metadata. In this paper, we present Embedding Atlas, a scalable, interactive visualization tool designed to make interacting with large embeddings as easy as possible. Embedding Atlas uses modern web technologies and advanced algorithms -- including density-based clustering, and automated labeling -- to provide a fast and rich data analysis experience at scale. We evaluate Embedding Atlas with a competitive analysis against other popular embedding tools, showing that Embedding Atlas's feature set specifically helps reduce friction, and report a benchmark on its real-time rendering performance with millions of points. Embedding Atlas is available as open source to support future work in embedding-based analysis.",
      "authors": [
        "Donghao Ren and Fred Hohman and Halden Lin and Dominik Moritz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T19:15:54+00:00",
          "link": "https://arxiv.org/abs/2505.06386v1",
          "size": "5664kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:49:59+00:00",
          "link": "https://arxiv.org/abs/2505.06386v2",
          "size": "5664kb",
          "version": "v2"
        }
      ],
      "title": "Embedding Atlas: Low-Friction, Interactive Embedding Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06386",
        "HTML": "https://arxiv.org/html/2505.06386v2",
        "PDF": "https://arxiv.org/pdf/2505.06386"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper centers on embedding visualization tools and does not have an apparent link to creativity. It focuses on technical implementation and performance evaluation of visualization tools."
      },
      "tasks": [
        "Friction"
      ],
      "repo_urls": [
        "https://github.com/apple/embedding-atlas"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13477",
      "abstract": "Dynamic facial emotion is essential for believable AI-generated avatars, yet most systems remain visually static, limiting their use in simulations like virtual training for investigative interviews with abused children. We present a real-time architecture combining Unreal Engine 5 MetaHuman rendering with NVIDIA Omniverse Audio2Face to generate facial expressions from vocal prosody in photorealistic child avatars. Due to limited TTS options, both avatars were voiced using young adult female models from two systems to better fit character profiles, introducing a voice-age mismatch. This confound may affect audiovisual alignment. We used a two-PC setup to decouple speech generation from GPU-intensive rendering, enabling low-latency interaction in desktop and VR. A between-subjects study (N=70) compared audio+visual vs. visual-only conditions as participants rated emotional clarity, facial realism, and empathy for avatars expressing joy, sadness, and anger. While emotions were generally recognized - especially sadness and joy - anger was harder to detect without audio, highlighting the role of voice in high-arousal expressions. Interestingly, silencing clips improved perceived realism by removing mismatches between voice and animation, especially when tone or age felt incongruent. These results emphasize the importance of audiovisual congruence: mismatched voice undermines expression, while a good match can enhance weaker visuals - posing challenges for emotionally coherent avatars in sensitive contexts.",
      "authors": [
        "Pegah Salehi",
        "Sajad Amouei Sheshkal",
        "Vajira Thambawita",
        "Michael A. Riegler",
        "P{\\aa}l Halvorsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T13:34:36+00:00",
          "link": "https://arxiv.org/abs/2506.13477v1",
          "size": "415kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T14:47:40+00:00",
          "link": "https://arxiv.org/abs/2506.13477v2",
          "size": "2665kb",
          "version": "v2"
        }
      ],
      "title": "Multimodal Integration Challenges in Emotionally Expressive Child Avatars for Training Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13477",
        "HTML": "https://arxiv.org/html/2506.13477v2",
        "PDF": "https://arxiv.org/pdf/2506.13477"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper deals with emotionally expressive child avatars for training applications, which involves creative aspects in designing believable avatars and simulations, although creativity is not the central theme."
      },
      "tasks": [
        "Speech Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21898",
      "abstract": "Large language models (LLMs) are becoming increasingly ubiquitous in our daily lives, but numerous concerns about bias in LLMs exist. This study examines how gender-diverse populations perceive bias, accuracy, and trustworthiness in LLMs, specifically ChatGPT. Through 25 in-depth interviews with non-binary/transgender, male, and female participants, we investigate how gendered and neutral prompts influence model responses and how users evaluate these responses. Our findings reveal that gendered prompts elicit more identity-specific responses, with non-binary participants particularly susceptible to condescending and stereotypical portrayals. Perceived accuracy was consistent across gender groups, with errors most noted in technical topics and creative tasks. Trustworthiness varied by gender, with men showing higher trust, especially in performance, and non-binary participants demonstrating higher performance-based trust. Additionally, participants suggested improving the LLMs by diversifying training data, ensuring equal depth in gendered responses, and incorporating clarifying questions. This research contributes to the CSCW/HCI field by highlighting the need for gender-diverse perspectives in LLM development in particular and AI in general, to foster more inclusive and trustworthy systems.",
      "authors": [
        "Aimen Gaba",
        "Emily Wall",
        "Tejas Ramkumar Babu",
        "Yuriy Brun",
        "Kyle Hall",
        "Cindy Xiong Bearfield"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:35:52+00:00",
          "link": "https://arxiv.org/abs/2506.21898v1",
          "size": "525kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:26:59+00:00",
          "link": "https://arxiv.org/abs/2506.21898v2",
          "size": "525kb",
          "version": "v2"
        }
      ],
      "title": "Bias, Accuracy, and Trust: Gender-Diverse Perspectives on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21898",
        "HTML": "https://arxiv.org/html/2506.21898v2",
        "PDF": "https://arxiv.org/pdf/2506.21898"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper touches on creativity as it mentions the use of ChatGPT in creative tasks and evaluates user perceptions of accuracy and bias in such contexts. Creativity is discussed as part of the evaluation, but it is not the primary focus of the study."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.01754",
      "abstract": "From the invention of writing and the printing press, to television and social media, human history is punctuated by major innovations in communication technology, which fundamentally altered how ideas spread and reshaped our culture. Recent chatbots powered by generative artificial intelligence constitute a novel medium that encodes cultural patterns in their neural representations and disseminates them in conversations with hundreds of millions of people. Understanding whether these patterns transmit into human language, and ultimately shape human culture, is a fundamental question. While fully quantifying the causal impact of a chatbot like ChatGPT on human culture is very challenging, lexicographic shift in human spoken communication may offer an early indicator of such broad phenomenon. Here, we apply econometric causal inference techniques to 740,249 hours of human discourse from 360,445 YouTube academic talks and 771,591 conversational podcast episodes across multiple disciplines. We detect a measurable and abrupt increase in the use of words preferentially generated by ChatGPT, such as delve, comprehend, boast, swift, and meticulous, after its release. These findings suggest a scenario where machines, originally trained on human data and subsequently exhibiting their own cultural traits, can, in turn, measurably reshape human culture. This marks the beginning of a closed cultural feedback loop in which cultural traits circulate bidirectionally between humans and machines. Our results motivate further research into the evolution of human-machine culture, and raise concerns over the erosion of linguistic and cultural diversity, and the risks of scalable manipulation.",
      "authors": [
        "Hiromu Yakura",
        "Ezequiel Lopez-Lopez",
        "Levin Brinkmann",
        "Ignacio Serna",
        "Prateek Gupta",
        "Ivan Soraperra",
        "Iyad Rahwan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T10:01:51+00:00",
          "link": "https://arxiv.org/abs/2409.01754v1",
          "size": "2346kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:43:32+00:00",
          "link": "https://arxiv.org/abs/2409.01754v2",
          "size": "8008kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T14:34:57+00:00",
          "link": "https://arxiv.org/abs/2409.01754v3",
          "size": "8008kb",
          "version": "v3"
        }
      ],
      "title": "Empirical evidence of Large Language Model's influence on human spoken communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01754",
        "HTML": "https://arxiv.org/html/2409.01754v3",
        "PDF": "https://arxiv.org/pdf/2409.01754"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses the influence of language models on human communication and culture, presenting the potential for creative language changes."
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.01866",
      "abstract": "When interacting with each other, humans adjust their behavior based on perceived trust. To achieve similar adaptability, robots must accurately estimate human trust at sufficiently granular timescales while collaborating with humans. Beta reputation is a popular way to formalize a mathematical estimation of human trust. However, it relies on binary performance, which updates trust estimations only after each task concludes. Additionally, manually crafting a reward function is the usual method of building a performance indicator, which is labor-intensive and time-consuming. These limitations prevent efficient capture of continuous trust changes at more granular timescales throughout the collaboration task. Therefore, this paper presents a new framework for the estimation of human trust using beta reputation at fine-grained timescales. To achieve granularity in beta reputation, we utilize continuous reward values to update trust estimates at each timestep of a task. We construct a continuous reward function using maximum entropy optimization to eliminate the need for the laborious specification of a performance indicator. The proposed framework improves trust estimations by increasing accuracy, eliminating the need to manually craft a reward function, and advancing toward the development of more intelligent robots.",
      "authors": [
        "Resul Dagdanov",
        "Milan Andrejevic",
        "Dikai Liu",
        "Chin-Teng Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T07:46:24+00:00",
          "link": "https://arxiv.org/abs/2411.01866v1",
          "size": "4851kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T11:25:50+00:00",
          "link": "https://arxiv.org/abs/2411.01866v2",
          "size": "4539kb",
          "version": "v2"
        }
      ],
      "title": "Improving Trust Estimation in Human-Robot Collaboration Using Beta Reputation at Fine-grained Timescales",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01866",
        "HTML": "https://arxiv.org/html/2411.01866v2",
        "PDF": "https://arxiv.org/pdf/2411.01866"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on improving trust estimation in human-robot collaboration, with no clear connection to creativity. It primarily addresses the estimation and mechanics of trust using beta reputation."
      },
      "tasks": [
        "Bayesian Inference",
        "Behavioural cloning",
        "Human-Object Relationship Detection",
        "Robot Manipulation"
      ],
      "repo_urls": [
        "https://github.com/resuldagdanov/robot-learning-human-trust"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.20545",
      "abstract": "Large Language Models (LLMs) are increasingly used by software engineers for code generation. However, limitations of LLMs such as irrelevant or incorrect code have highlighted the need for prompt programming (or prompt engineering) where engineers apply specific prompt techniques (e.g., chain-of-thought or input-output examples) to improve the generated code. While some prompt techniques have been studied, the impact of different techniques -- and their interactions -- on code generation is still not fully understood. In this study, we introduce CodePromptEval, a dataset of 7072 prompts designed to evaluate five prompt techniques (few-shot, persona, chain-of-thought, function signature, list of packages) and their effect on the correctness, similarity, and quality of complete functions generated by three LLMs (GPT-4o, Llama3, and Mistral). Our findings show that while certain prompt techniques significantly influence the generated code, combining multiple techniques does not necessarily improve the outcome. Additionally, we observed a trade-off between correctness and quality when using prompt techniques. Our dataset and replication package enable future research on improving LLM-generated code and evaluating new prompt techniques.",
      "authors": [
        "Ranim Khojah",
        "Francisco Gomes de Oliveira Neto",
        "Mazen Mohamad",
        "Philipp Leitner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-29T18:34:10+00:00",
          "link": "https://arxiv.org/abs/2412.20545v1",
          "size": "5542kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T09:46:27+00:00",
          "link": "https://arxiv.org/abs/2412.20545v2",
          "size": "570kb",
          "version": "v2"
        }
      ],
      "title": "The Impact of Prompt Programming on Function-Level Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20545",
        "HTML": "https://arxiv.org/html/2412.20545v2",
        "PDF": "https://arxiv.org/pdf/2412.20545"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "partial",
        "reason": "The paper discusses prompt programming for code generation with LLMs, which could support software developers' creativity. However, creativity is not central, rather a secondary aspect related to improving coding outputs."
      },
      "tasks": [
        "Code Generation",
        "Prompt Engineering"
      ],
      "repo_urls": [
        "https://github.com/icetlab/codeprompteval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.20867",
      "abstract": "In situ robotic automation in construction is challenging due to constantly changing environments, a shortage of robotic experts, and a lack of standardized frameworks bridging robotics and construction practices. This work proposes a holistic framework for construction task specification, optimization of robot morphology, and mission execution using a mobile modular reconfigurable robot. Users can specify and monitor the desired robot behavior through a graphical interface. In contrast to existing, monolithic solutions, we automatically identify a new task-tailored robot for every task by integrating \\acf{bim}. Our framework leverages modular robot components that enable the fast adaption of robot hardware to the specific demands of the construction task. Other than previous works on modular robot optimization, we consider multiple competing objectives, which allow us to explicitly model the challenges of real-world transfer, such as calibration errors. We demonstrate our framework in simulation by optimizing robots for drilling and spray painting. Finally, experimental validation demonstrates that our approach robustly enables the autonomous execution of robotic drilling.",
      "authors": [
        "Jonathan K\\\"ulz and Michael Terzer and Marco Magri and Andrea Giusti and Matthias Althoff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T11:11:13+00:00",
          "link": "https://arxiv.org/abs/2412.20867v1",
          "size": "32170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T13:02:38+00:00",
          "link": "https://arxiv.org/abs/2412.20867v2",
          "size": "9792kb",
          "version": "v2"
        }
      ],
      "title": "Holistic Construction Automation with Modular Robots: From High-Level Task Specification to Execution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20867",
        "HTML": "https://arxiv.org/html/2412.20867v2",
        "PDF": "https://arxiv.org/pdf/2412.20867"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper is about robotic automation in construction, focusing on task specification and robot optimization. It has no explicit connection to creativity, as it addresses automation challenges and solutions."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.06416",
      "abstract": "We conducted an International AI Negotiation Competition in which participants designed and refined prompts for AI negotiation agents. We then facilitated over 180,000 negotiations between these agents across multiple scenarios with diverse characteristics and objectives. Our findings revealed that principles from human negotiation theory remain crucial even in AI-AI contexts. Surprisingly, warmth--a traditionally human relationship-building trait--was consistently associated with superior outcomes across all key performance metrics. Dominant agents, meanwhile, were especially effective at claiming value. Our analysis also revealed unique dynamics in AI-AI negotiations not fully explained by existing theory, including AI-specific technical strategies like chain-of-thought reasoning, prompt injection, and strategic concealment. When we applied natural language processing (NLP) methods to the full transcripts of all negotiations we found positivity, gratitude and question-asking (associated with warmth) were strongly associated with reaching deals as well as objective and subjective value, whereas conversation lengths (associated with dominance) were strongly associated with impasses. The results suggest the need to establish a new theory of AI negotiation, which integrates classic negotiation theory with AI-specific negotiation theories to better understand autonomous negotiations and optimize agent performance.",
      "authors": [
        "Michelle Vaccaro",
        "Michael Caosun",
        "Harang Ju",
        "Sinan Aral",
        "and Jared R. Curhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T03:25:48+00:00",
          "link": "https://arxiv.org/abs/2503.06416v1",
          "size": "2071kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T21:41:49+00:00",
          "link": "https://arxiv.org/abs/2503.06416v2",
          "size": "11220kb",
          "version": "v2"
        }
      ],
      "title": "Advancing AI Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06416",
        "HTML": "https://arxiv.org/html/2503.06416v2",
        "PDF": "https://arxiv.org/pdf/2503.06416"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on AI negotiations and does not discuss creativity as a topic. Instead, it explores negotiation performance metrics and AI-specific strategies."
      },
      "tasks": [
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02950",
      "abstract": "This study provides the first comprehensive evaluation of large language model (LLM) performance across three counseling roles in Japanese-language therapeutic contexts. We simultaneously assessed counselor artificial intelligence (AI) systems (GPT-4-turbo with zeroshot prompting or Structured Multi-step Dialogue Prompts (SMDP), Claude-3-Opus-SMDP), client AI simulations, and evaluation AI systems (o3, Claude-3.7-Sonnet, Gemini-2.5-pro). Human experts (n = 15) with extensive counseling experience evaluated AI-generated dialogues using the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1.\n  Notably, SMDP implementation significantly enhanced counselor AI performance across all MITI global ratings compared with zeroshot prompting, with no significant differences between GPT-SMDP and Opus-SMDP. Evaluation AIs showed comparable performance to human raters for Cultivating Change Talk but systematically overestimated Softening Sustain Talk and the overall quality metrics. Model-specific biases emerged: Gemini emphasized power-sharing, o3 focused on technical proficiency, and Sonnet prioritized emotional expression. Client AI simulations exhibited a limited emotional range and unnaturally high compliance, indicating the need for enhanced realism.\n  These findings establish benchmarks for AI-assisted counseling in non-English contexts and identify critical areas for improvement through advanced prompt engineering, retrieval-augmented generation, and targeted fine-tuning, with important implications for developing culturally sensitive AI mental health tools.",
      "authors": [
        "Keita Kiuchi",
        "Yoshikazu Fujimoto",
        "Hideyuki Goto",
        "Tomonori Hosokawa",
        "Makoto Nishimura",
        "Yosuke Sato and Izumi Sezai"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T21:50:29+00:00",
          "link": "https://arxiv.org/abs/2507.02950v1",
          "size": "48kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T06:16:17+00:00",
          "link": "https://arxiv.org/abs/2507.02950v2",
          "size": "49kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator Roles Assessed by Motivational Interviewing Criteria",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02950",
        "HTML": "https://arxiv.org/html/2507.02950v2",
        "PDF": "https://arxiv.org/pdf/2507.02950"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This study evaluates AI performance in counseling contexts using Motivational Interviewing criteria. Creativity is not addressed, as the focus is on therapeutic role assessment and AI dialogue evaluation in counseling."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.10426",
      "abstract": "The legal compliance and safety of different Human-in-the-loop (HITL) setups for AI can vary greatly. This manuscript aims to identify new ways of choosing between such setups, and shows that there is an unavoidable trade-off between the attribution of legal responsibility and the technical explainability of AI. We begin by using the notion of oracle machines from computability theory to formalise different HITL setups, distinguishing between trivial human monitoring, single endpoint human action, and highly involved interaction between the human(s) and the AI. These correspond to total functions, many-one reductions, and Turing reductions respectively. A taxonomy categorising HITL failure modes is then presented, highlighting the limitations on what any HITL setup can actually achieve. Our approach then identifies oversights from UK and EU legal frameworks, which focus on certain HITL setups which may not always achieve the desired ethical, legal, and sociotechnical outcomes. We suggest areas where the law should recognise the effectiveness of different HITL setups and assign responsibility in these contexts, avoiding unnecessary and unproductive human \"scapegoating\". Overall, we show how HITL setups involve many technical design decisions, and can be prone to failures which are often out of the humans' control. This opens up a new analytic perspective on the challenges arising in the creation of HITL setups, helping inform AI developers and lawmakers on designing HITL to better achieve their desired outcomes.",
      "authors": [
        "Maurice Chiodo",
        "Dennis M\\\"uller",
        "Paul Siewert",
        "Jean-Luc Wetherall",
        "Zoya Yasmine",
        "John Burden"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "History and Overview (math.HO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T15:42:14+00:00",
          "link": "https://arxiv.org/abs/2505.10426v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Formalising Human-in-the-Loop: Computational Reductions, Failure Modes, and Legal-Moral Responsibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10426",
        "HTML": "https://arxiv.org/html/2505.10426"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "This manuscript discusses the formalization of Human-in-the-loop setups and legal implications, focusing on technical and legal aspects rather than creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01436",
      "abstract": "Despite the ubiquity of visualization examples published on the web, retargeting existing custom chart implementations to new datasets remains difficult, time-intensive, and tedious. The adaptation process assumes author familiarity with both the implementation of the example as well as how the new dataset might need to be transformed to fit into the example code. With recent advances in Large Language Models (LLMs), automatic adaptation of code can be achieved from high-level user prompts, reducing the barrier for visualization retargeting. To better understand how LLMs can assist retargeting and its potential limitations, we characterize and evaluate the performance of LLM assistance across multiple datasets and charts of varying complexity, categorizing failures according to type and severity. In our evaluation, we compare two approaches: (1) directly instructing the LLM model to fully generate and adapt code by treating code as text inputs and (2) a more constrained program synthesis pipeline where the LLM guides the code construction process by providing structural information (e.g., visual encodings) based on properties of the example code and data. We find that both approaches struggle when new data has not been appropriately transformed, and discuss important design recommendations for future retargeting systems.",
      "authors": [
        "Luke S. Snyder",
        "Chenglong Wang",
        "Steven M. Drucker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T07:43:43+00:00",
          "link": "https://arxiv.org/abs/2507.01436v1",
          "size": "1603kb",
          "version": "v1"
        },
        {
          "date": "2025-07-06T18:15:55+00:00",
          "link": "https://arxiv.org/abs/2507.01436v2",
          "size": "1603kb",
          "version": "v2"
        }
      ],
      "title": "Challenges & Opportunities with LLM-Assisted Visualization Retargeting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01436",
        "HTML": "https://arxiv.org/html/2507.01436"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on visualization retargeting using large language models, with no direct connection to creativity. The emphasis is on technical adaptation challenges rather than creative processes or outcomes."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.00686",
      "abstract": "Large language models (LLMs) bear great potential for automating tedious development tasks such as creating and maintaining code documentation. However, it is unclear to what extent developers can effectively prompt LLMs to create concise and useful documentation. We report on a controlled experiment with 20 professionals and 30 computer science students tasked with code documentation generation for two Python functions. The experimental group freely entered ad-hoc prompts in a ChatGPT-like extension of Visual Studio Code, while the control group executed a predefined few-shot prompt. Our results reveal that professionals and students were unaware of or unable to apply prompt engineering techniques. Especially students perceived the documentation produced from ad-hoc prompts as significantly less readable, less concise, and less helpful than documentation from prepared prompts. Some professionals produced higher quality documentation by just including the keyword Docstring in their ad-hoc prompts. While students desired more support in formulating prompts, professionals appreciated the flexibility of ad-hoc prompting. Participants in both groups rarely assessed the output as perfect. Instead, they understood the tools as support to iteratively refine the documentation. Further research is needed to understand which prompting skills and preferences developers have and which support they need for certain tasks.",
      "authors": [
        "Hans-Alexander Kruse and Tim Puhlf\\\"ur{\\ss} and Walid Maalej"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-01T16:28:14+00:00",
          "link": "https://arxiv.org/abs/2408.00686v1",
          "size": "440kb",
          "version": "v1"
        }
      ],
      "title": "Can Developers Prompt? A Controlled Experiment for Code Documentation Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00686",
        "PDF": "https://arxiv.org/pdf/2408.00686"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The paper focuses on the use of large language models for code documentation generation and prompt engineering, without addressing creativity as a topic."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2408.05204",
      "abstract": "Large language models (LLMs), including OpenAI's GPT-series, have made significant advancements in recent years. Known for their expertise across diverse subject areas and quick adaptability to user-provided prompts, LLMs hold unique potential as Personalized Learning (PL) tools. Despite this potential, their application in K-12 education remains largely unexplored. This paper presents one of the first randomized controlled trials (n = 23) to evaluate the effectiveness of GPT-4 in personalizing educational science texts for middle school students. In this study, GPT-4 was used to profile student learning preferences based on choices made during a training session. For the experimental group, GPT-4 was used to rewrite science texts to align with the student's predicted profile while, for students in the control group, texts were rewritten to contradict their learning preferences. The results of a Mann-Whitney U test showed that students significantly preferred (at the .10 level) the rewritten texts when they were aligned with their profile (p = .059). These findings suggest that GPT-4 can effectively interpret and tailor educational content to diverse learner preferences, marking a significant advancement in PL technology. The limitations of this study and ethical considerations for using artificial intelligence in education are also discussed.",
      "authors": [
        "Michael Vaccaro Jr",
        "Mikayla Friday",
        "Arash Zaghi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-09T17:53:35+00:00",
          "link": "https://arxiv.org/abs/2408.05204v1",
          "size": "833kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05204",
        "PDF": "https://arxiv.org/pdf/2408.05204"
      },
      "relevance": {
        "keyword": "creativity",
        "level": "irrelevant",
        "reason": "The study evaluates the personalization of educational content using large language models, without a focus on creativity."
      },
      "tasks": [],
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Computation and Language (cs.CL)",
    "Robotics (cs.RO)",
    "Information Retrieval (cs.IR)",
    "Artificial Intelligence (cs.AI)",
    "History and Overview (math.HO)",
    "Social and Information Networks (cs.SI)",
    "Computers and Society (cs.CY)",
    "Multiagent Systems (cs.MA)",
    "Software Engineering (cs.SE)",
    "Human-Computer Interaction (cs.HC)",
    "Graphics (cs.GR)",
    "Machine Learning (cs.LG)"
  ],
  "prompt": {
    "creativity": "\nYou are an expert in information retrieval. I will provide you with a list of research papers from arXiv, specifically in the *cs.HC* (Human-Computer Interaction) category.\n\nYour task is to analyze each paper and determine its relevance to the topic of **Creativity**.\n\n\n### Classify each paper into one of the following relevance levels\n\n- `core` \u2014 Creativity is a **primary focus**\n  - The paper directly studies or simulates creativity, with a clear focus on creativity.\n  - Includes creative tasks, co-creative systems, or creativity evaluation metrics.\n  - The title and abstract explicitly mention creativity, and the research questions are directly related to creativity.\n- `partial` \u2014 Creativity is a **secondary theme**\n  - Part of the paper relates to creativity; it is treated as an analytical dimension or design goal but not the main objective (e.g., user creativity, design support).\n  - Creativity may appear in discussions, experiments, or auxiliary applications.\n  - Creativity is presented as a supporting topic (e.g., evaluation criteria, user feedback).\n- `irrelevant` \u2014 **No clear connection** to creativity\n  - The paper does not address creativity as a topic.\n  - Focuses on unrelated technical content (e.g., compression, security, optimization).\n  - If creativity is mentioned, it is only superficial and lacks substantive content.\n\n\n### Return your results in the following JSON format\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    },\n    {\n      \"id\": \"paper id\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"Brief justification based on the paper content\"\n    }\n  ]\n}\n```\n\nBe concise but specific in your reasoning, referencing key terms or sections when applicable.\n"
  },
  "description": "Data source: https://arxiv.org/list/cs.HC/new",
  "level_tatistics": {
    "partial": 10,
    "irrelevant": 24,
    "core": 4
  },
  "arxiv_update_date": "2025-07-09",
  "updated_at": "2025-07-09 10:03:12"
}