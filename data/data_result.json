[
  {
    "id": "2506.16773",
    "abstract": "Infrared and visible light image fusion aims to combine the strengths of both modalities to generate images that are rich in information and fulfill visual or computational requirements. This paper proposes an image fusion method based on Implicit Neural Representations (INR), referred to as INRFuse. This method parameterizes a continuous function through a neural network to implicitly represent the multimodal information of the image, breaking through the traditional reliance on discrete pixels or explicit features. The normalized spatial coordinates of the infrared and visible light images serve as inputs, and multi-layer perceptrons is utilized to adaptively fuse the features of both modalities, resulting in the output of the fused image. By designing multiple loss functions, the method jointly optimizes the similarity between the fused image and the original images, effectively preserving the thermal radiation information of the infrared image while maintaining the texture details of the visible light image. Furthermore, the resolution-independent characteristic of INR allows for the direct fusion of images with varying resolutions and achieves super-resolution reconstruction through high-density coordinate queries. Experimental results indicate that INRFuse outperforms existing methods in both subjective visual quality and objective evaluation metrics, producing fused images with clear structures, natural details, and rich information without the necessity for a training dataset.",
    "authors": [
      "Sun, Shuchen",
      "Shi, Ligen",
      "Liu, Chang",
      "Wu, Lina",
      "Qiu, Jun"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16773v1",
      "Other Formats": "https://arxiv.org/format/2506.16773",
      "TeX Source": "https://arxiv.org/src/2506.16773",
      "View PDF": "https://arxiv.org/pdf/2506.16773"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 06:34:19 UTC (602 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Infrared and Visible Image Fusion Based on Implicit Neural Representations",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2405.04443",
    "abstract": "Aligning machine learning systems with human expectations is mostly attempted by training with manually vetted human behavioral samples, typically explicit feedback. This is done on a population level since the context that is capturing the subjective Point-Of-View (POV) of a concrete person in a specific situational context is not retained in the data. However, we argue that alignment on an individual level can boost the subjective predictive performance for the individual user interacting with the system considerably. Since perception differs for each person, the same situation is observed differently. Consequently, the basis for decision making and the subsequent reasoning processes and observable reactions differ. We hypothesize that individual perception patterns can be used for improving the alignment on an individual level. We test this, by integrating perception information into machine learning systems and measuring their predictive performance wrt.~individual subjective assessments. For our empirical study, we collect a novel data set of multimodal stimuli and corresponding eye tracking sequences for the novel task of Perception-Guided Crossmodal Entailment and tackle it with our Perception-Guided Multimodal Transformer. Our findings suggest that exploiting individual perception signals for the machine learning of subjective human assessments provides a valuable cue for individual alignment. It does not only improve the overall predictive performance from the point-of-view of the individual user but might also contribute to steering AI systems towards every person's individual expectations and values.",
    "authors": [
      "Werner, Simon",
      "Christ, Katharina",
      "Bernardy, Laura",
      "M\u00fcller, Marion G.",
      "Rettinger, Achim"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2405.04443v2",
      "Other Formats": "https://arxiv.org/format/2405.04443",
      "TeX Source": "https://arxiv.org/src/2405.04443",
      "View PDF": "https://arxiv.org/pdf/2405.04443"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 7 May 2024 16:07:29 UTC (3,785 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 11:13:31 UTC (3,811 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/05/07",
    "title": "POV Learning: Individual Alignment of Multimodal Models using Human Perception",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17076",
    "abstract": "Synchronization errors, such as insertions and deletions, present a fundamental challenge in DNA-based data storage systems, arising from both synthesis and sequencing noise. These channels are often modeled as insertion-deletion-substitution (IDS) channels, for which designing maximum-likelihood decoders is computationally expensive. In this work, we propose a data-driven approach based on neural polar decoders (NPDs) to design low-complexity decoders for channels with synchronization errors. The proposed architecture enables decoding over IDS channels with reduced complexity $O(AN log N )$, where $A$ is a tunable parameter independent of the channel. NPDs require only sample access to the channel and can be trained without an explicit channel model. Additionally, NPDs provide mutual information (MI) estimates that can be used to optimize input distributions and code design. We demonstrate the effectiveness of NPDs on both synthetic deletion and IDS channels. For deletion channels, we show that NPDs achieve near-optimal decoding performance and accurate MI estimation, with significantly lower complexity than trellis-based decoders. We also provide numerical estimates of the channel capacity for the deletion channel. We extend our evaluation to realistic DNA storage settings, including channels with multiple noisy reads and real-world Nanopore sequencing data. Our results show that NPDs match or surpass the performance of existing methods while using significantly fewer parameters than the state-of-the-art. These findings highlight the promise of NPDs for robust and efficient decoding in DNA data storage systems.",
    "authors": [
      "Aharoni, Ziv",
      "Pfister, Henry D."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.17076",
      "TeX Source": "https://arxiv.org/src/2506.17076",
      "View PDF": "https://arxiv.org/pdf/2506.17076"
    },
    "subjects": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:26:38 UTC (86 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Neural Polar Decoders for DNA Data Storage",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17220",
    "abstract": "Recent advancements in video diffusion models based on Diffusion Transformers (DiTs) have achieved remarkable success in generating temporally coherent videos. Yet, a fundamental question persists: how do these models internally establish and represent temporal correspondences across frames? We introduce DiffTrack, the first quantitative analysis framework designed to answer this question. DiffTrack constructs a dataset of prompt-generated video with pseudo ground-truth tracking annotations and proposes novel evaluation metrics to systematically analyze how each component within the full 3D attention mechanism of DiTs (e.g., representations, layers, and timesteps) contributes to establishing temporal correspondences. Our analysis reveals that query-key similarities in specific, but not all, layers play a critical role in temporal matching, and that this matching becomes increasingly prominent during the denoising process. We demonstrate practical applications of DiffTrack in zero-shot point tracking, where it achieves state-of-the-art performance compared to existing vision foundation and self-supervised video models. Further, we extend our findings to motion-enhanced video generation with a novel guidance method that improves temporal consistency of generated videos without additional training. We believe our work offers crucial insights into the inner workings of video DiTs and establishes a foundation for further research and applications leveraging their temporal understanding.",
    "authors": [
      "Nam, Jisu",
      "Son, Soowon",
      "Chung, Dahyun",
      "Kim, Jiyoung",
      "Jin, Siyoon",
      "Hur, Junhwa",
      "Kim, Seungryong"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.17220",
      "TeX Source": "https://arxiv.org/src/2506.17220",
      "View PDF": "https://arxiv.org/pdf/2506.17220"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:59:55 UTC (24,561 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Emergent Temporal Correspondences from Video Diffusion Transformers",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16738",
    "abstract": "With the rapid progress of speech language models (SLMs), discrete speech tokens have emerged as a core interface between speech and text, enabling unified modeling across modalities. Recent speech tokenization approaches aim to isolate semantic information from low-level acoustics to better align with language models. In particular, previous methods use SSL teachers such as HuBERT to extract semantic representations, which are then distilled into a semantic quantizer to suppress acoustic redundancy as well as capture content-related latent structures. However, they still produce speech token sequences significantly longer than their textual counterparts, creating challenges for efficient speech-language modeling. Reducing the frame rate is a natural solution, but standard techniques, such as rigid average pooling across frames, can distort or dilute the semantic structure required for effective LM alignment. To address this, we propose LM-SPT, a speech tokenization method that introduces a novel semantic distillation. Instead of directly matching teacher and student features via pooling, we reconstruct speech solely from semantic tokens and minimize the discrepancy between the encoded representations of the original and reconstructed waveforms, obtained from a frozen automatic speech recognition (ASR) encoder. This indirect yet data-driven supervision enables the tokenizer to learn discrete units that are more semantically aligned with language models. LM-SPT further incorporates architectural improvements to the encoder and decoder for speech tokenization, and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz. Experimental results show that LM-SPT achieves superior reconstruction fidelity compared to baselines, and that SLMs trained with LM-SPT tokens achieve competitive performances on speech-to-text and consistently outperform baselines on text-to-speech tasks.",
    "authors": [
      "Jo, Daejin",
      "Yun, Jeeyoung",
      "Roh, Byungseok",
      "Kim, Sungwoong"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16738v1",
      "Other Formats": "https://arxiv.org/format/2506.16738",
      "TeX Source": "https://arxiv.org/src/2506.16738",
      "View PDF": "https://arxiv.org/pdf/2506.16738"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 04:15:14 UTC (1,187 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17019",
    "abstract": "This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on Instruction Following Speech Processing. We submit results for the Short Track, i.e., speech recognition, translation, and spoken question answering. Our model is a unified speech-to-text model that integrates a pre-trained continuous speech encoder and text decoder through a first phase of modality alignment and a second phase of instruction fine-tuning. Crucially, we focus on using small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY data along with synthetic data generation to supplement existing resources.",
    "authors": [
      "Attanasio, Giuseppe",
      "Sannigrahi, Sonal",
      "Peters, Ben",
      "Martins, Andr\u00e9 F. T."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17019v1",
      "Other Formats": "https://arxiv.org/format/2506.17019",
      "TeX Source": "https://arxiv.org/src/2506.17019",
      "View PDF": "https://arxiv.org/pdf/2506.17019"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 14:17:42 UTC (9,753 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Instituto de Telecomunica\\c{c}\\~oes at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16962",
    "abstract": "Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "authors": [
      "Sun, Haoran",
      "Jiang, Yankai",
      "Lou, Wenjie",
      "Zhang, Yujie",
      "Li, Wenjie",
      "Wang, Lilong",
      "Liu, Mianxin",
      "Liu, Lei",
      "Wang, Xiaosong"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16962v1",
      "Other Formats": "https://arxiv.org/format/2506.16962",
      "TeX Source": "https://arxiv.org/src/2506.16962",
      "View PDF": "https://arxiv.org/pdf/2506.16962"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 12:51:19 UTC (8,765 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17124",
    "abstract": "Recent work on large language models has demonstrated the use of model-free reinforcement learning (RL) to train reasoning-like capabilities. The emergence of \"thinking\" through model-free RL is interesting as thinking actions neither produce reward nor change the external world state to one where the agent is more likely to get reward. This paper seeks to build a domain-independent understanding of when model-free RL will lead to \"thinking\" as a strategy for reward maximization. To build this understanding, we first introduce a theoretical model which we call a \\textit{thought Markov decision process} (MDP). Thought MDPs minimally extend the classical MDP model to include an abstract notion of thought state and thought action. Using the thought MDP model, we prove the importance of policy initialization in determining whether or not thinking emerges and show formally that thought actions are equivalent to the agent choosing to perform a step of policy improvement before continuing to act. We then show that open-source LLMs satisfy the conditions that our theory predicts are necessary for model-free RL to produce thinking-like behavior. Finally, we hypothesize sufficient conditions that would enable thinking to be learned outside of language generation and introduce a toy domain where a combination of multi-task pre-training and designated thought actions enable more data-efficient RL compared to non-thinking agents.",
    "authors": [
      "Hanna, Josiah P.",
      "Corrado, Nicholas E."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17124v1",
      "Other Formats": "https://arxiv.org/format/2506.17124",
      "TeX Source": "https://arxiv.org/src/2506.17124",
      "View PDF": "https://arxiv.org/pdf/2506.17124"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:23:46 UTC (335 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "When Can Model-Free Reinforcement Learning be Enough for Thinking?",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.13593",
    "abstract": "We develop a framework to quantify the time-to-unsafe-sampling - the number of large language model (LLM) generations required to trigger an unsafe (e.g., toxic) response. Estimating this quantity is challenging, since unsafe responses are exceedingly rare in well-aligned LLMs, potentially occurring only once in thousands of generations. As a result, directly estimating time-to-unsafe-sampling would require collecting training data with a prohibitively large number of generations per prompt. However, with realistic sampling budgets, we often cannot generate enough responses to observe an unsafe outcome for every prompt, leaving the time-to-unsafe-sampling unobserved in many cases, making the estimation and evaluation tasks particularly challenging. To address this, we frame this estimation problem as one of survival analysis and develop a provably calibrated lower predictive bound (LPB) on the time-to-unsafe-sampling of a given prompt, leveraging recent advances in conformal prediction. Our key innovation is designing an adaptive, per-prompt sampling strategy, formulated as a convex optimization problem. The objective function guiding this optimized sampling allocation is designed to reduce the variance of the estimators used to construct the LPB, leading to improved statistical efficiency over naive methods that use a fixed sampling budget per prompt. Experiments on both synthetic and real data support our theoretical results and demonstrate the practical utility of our method for safety risk assessment in generative AI models.",
    "authors": [
      "Davidov, Hen",
      "Freidkin, Gilad",
      "Feldman, Shai",
      "Romano, Yaniv"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.13593v2",
      "Other Formats": "https://arxiv.org/format/2506.13593",
      "TeX Source": "https://arxiv.org/src/2506.13593",
      "View PDF": "https://arxiv.org/pdf/2506.13593"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 16 Jun 2025 15:21:25 UTC (4,253 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 12:12:17 UTC (4,253 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/16",
    "title": "Calibrated Predictive Lower Bounds on Time-to-Unsafe-Sampling in LLMs",
    "tasks": [
      "Conformal Prediction",
      "Large Language Model",
      "Survival Analysis"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2403.04311",
    "abstract": "Compound AI applications chain together subcomponents such as generative language models, document retrievers, and embedding models. Applying traditional systems optimizations such as parallelism and pipelining in compound AI systems is difficult because each component has different constraints in terms of the granularity and type of data that it ingests. New data is often generated during intermediate computations, and text streams may be split into smaller, independent fragments (such as documents to sentences) which may then be re-aggregated at later parts of the computation. Due to this complexity, existing systems to serve compound AI queries do not fully take advantage of parallelism and pipelining opportunities. We present Alto, a framework that automatically optimizes execution of compound AI queries through streaming and parallelism. Bento introduces a new abstraction called nested ancestry, a metadata hierarchy that allows the system to correctly track partial outputs and aggregate data across the heterogeneous constraints of the components of compound AI applications. This metadata is automatically inferred from the programming model, allowing developers to express complex dataflow patterns without needing to reason manually about the details of routing and aggregation. Implementations of four applications in Alto outperform or match implementations in LangGraph, a popular existing AI programming framework. Alto implementations match or improve latency by between 10-30%.",
    "authors": [
      "Raghavan, Deepti",
      "Santhanam, Keshav",
      "Rahman, Muhammad Shahir",
      "Modugula, Nayani",
      "Schroeder, Luis Gaspar",
      "Cura, Maximilien",
      "Liu, Houjun",
      "Thaker, Pratiksha",
      "Levis, Philip",
      "Zaharia, Matei"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2403.04311",
      "TeX Source": "https://arxiv.org/src/2403.04311",
      "View PDF": "https://arxiv.org/pdf/2403.04311"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 7 Mar 2024 08:30:26 UTC (1,206 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 07:03:22 UTC (604 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/03/07",
    "title": "Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry",
    "tasks": [
      "Chatbot",
      "Scheduling"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2411.00463",
    "abstract": "We consider the inverse problem consisting of the reconstruction of an inclusion $B$ contained in a bounded domain $\\Omega\\subset\\mathbb{R}^d$ from a single pair of Cauchy data $(u|_{\\partial\\Omega},\\partial_\\nu u|_{\\partial\\Omega})$, where $\\Delta u=0$ in $\\Omega\\setminus\\overline B$ and $u=0$ on $\\partial B$. We show that the reconstruction algorithm based on the range test, a domain sampling method, can be written as a neural network with a specific architecture. We propose to learn the weights of this network in the framework of supervised learning, and to combine it with a pre-trained classifier, with the purpose of distinguishing the inclusions based on their distance from the boundary. The numerical simulations show that this learned range test method provides accurate and stable reconstructions of polygonal inclusions. Furthermore, the results are superior to those obtained with the standard range test method (without learning) and with an end-to-end fully connected deep neural network, a purely data-driven method.",
    "authors": [
      "Sun, Shiwei",
      "Alberti, Giovanni S."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2411.00463v2",
      "Other Formats": "https://arxiv.org/format/2411.00463",
      "TeX Source": "https://arxiv.org/src/2411.00463",
      "View PDF": "https://arxiv.org/pdf/2411.00463"
    },
    "subjects": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 1 Nov 2024 09:24:05 UTC (1,629 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 13:35:41 UTC (1,318 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/11/01",
    "title": "The learned range test method for the inverse inclusion problem",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17101",
    "abstract": "Driving scene identification, which assigns multiple non-exclusive class labels to a scene, provides the contextual awareness necessary for enhancing autonomous vehicles' ability to understand, reason about, and interact with the complex driving environment. As a multi-label classification problem, it is better tackled via multitasking learning. However, directly training a multi-label classification model for driving scene identification through multitask learning presents two main challenges: acquiring a balanced, comprehensively annotated multi-label dataset and balancing learning across different tasks. This paper introduces a novel learning system that synergizes knowledge acquisition and accumulation (KAA) with consistency-based active learning (CAL) to address those challenges. KAA acquires and accumulates knowledge about scene identification from various single-label datasets via monotask learning. Subsequently, CAL effectively resolves the knowledge gap caused by the discrepancy between the marginal distributions of individual attributes and their joint distribution. An ablation study on our Driving Scene Identification (DSI) dataset demonstrates a 56.1% performance increase over the baseline model pretrained on ImageNet. Of this, KAA accounts for 31.3% of the gain, and CAL contributes 24.8%. Moreover, KAA-CAL stands out as the best performer when compared to state-of-the-art (SOTA) multi-label models on two public datasets, BDD100K and HSD, achieving this while using 85% less data. The DSI dataset and the implementation code for KAA-CAL are available at https://github.com/KELISBU/KAA-CAL .",
    "authors": [
      "Li, Ke",
      "Zhang, Chenyu",
      "Ding, Yuxin",
      "Hu, Xianbiao",
      "Qin, Ruwen"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17101v1",
      "Other Formats": "https://arxiv.org/format/2506.17101",
      "TeX Source": "https://arxiv.org/src/2506.17101",
      "View PDF": "https://arxiv.org/pdf/2506.17101"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:06:53 UTC (15,007 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16982",
    "abstract": "Accurately assessing student knowledge is critical for effective education, yet traditional Knowledge Tracing (KT) methods rely on opaque latent embeddings, limiting interpretability. Even LLM-based approaches generate direct predictions or summaries that may hallucinate without any accuracy guarantees. We recast KT as an inverse problem: learning the minimum natural-language summary that makes past answers explainable and future answers predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM that writes an interpretable knowledge summary and a frozen decoder LLM that must reconstruct and predict student responses using only that summary text. By constraining all predictive information to pass through a short natural-language bottleneck, LBMs ensure that the summary contains accurate information while remaining human-interpretable. Experiments on synthetic arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the accuracy of state-of-the-art KT and direct LLM methods while requiring orders-of-magnitude fewer student trajectories. We demonstrate that training the encoder with group-relative policy optimization, using downstream decoding accuracy as a reward signal, effectively improves summary quality.",
    "authors": [
      "Berthon, Antonin",
      "van der Schaar, Mihaela"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16982v1",
      "Other Formats": "https://arxiv.org/format/2506.16982",
      "TeX Source": "https://arxiv.org/src/2506.16982",
      "View PDF": "https://arxiv.org/pdf/2506.16982"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 13:21:14 UTC (4,799 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16679",
    "abstract": "Training data is at the core of any successful text-to-image models. The quality and descriptiveness of image text are crucial to a model's performance. Given the noisiness and inconsistency in web-scraped datasets, recent works shifted towards synthetic training captions. While this setup is generally believed to produce more capable models, current literature does not provide any insights into its design choices. This study closes this gap by systematically investigating how different synthetic captioning strategies impact the downstream performance of text-to-image models. Our experiments demonstrate that dense, high-quality captions enhance text alignment but may introduce trade-offs in output aesthetics and diversity. Conversely, captions of randomized lengths yield balanced improvements across aesthetics and alignment without compromising sample diversity. We also demonstrate that varying caption distributions introduce significant shifts in the output bias of a trained model. Our findings underscore the importance of caption design in achieving optimal model performance and provide practical insights for more effective training data strategies in text-to-image generation.",
    "authors": [
      "Brack, Manuel",
      "Katakol, Sudeep",
      "Friedrich, Felix",
      "Schramowski, Patrick",
      "Ravi, Hareesh",
      "Kersting, Kristian",
      "Kale, Ajinkya"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16679v1",
      "Other Formats": "https://arxiv.org/format/2506.16679",
      "TeX Source": "https://arxiv.org/src/2506.16679",
      "View PDF": "https://arxiv.org/pdf/2506.16679"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 01:52:17 UTC (12,401 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17221",
    "abstract": "Vision-Language Navigation (VLN) is a core challenge in embodied AI, requiring agents to navigate real-world environments using natural language instructions. Current language model-based navigation systems operate on discrete topological graphs, limiting path planning to predefined node connections. We propose VLN-R1, an end-to-end framework that leverages Large Vision-Language Models (LVLM) to directly translate egocentric video streams into continuous navigation actions, adopting GRPO-based training inspired by DeepSeek-R1. To enable effective training, we first construct the VLN-Ego dataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling to balance historical and current observations. While large language models can supervise complete textual instructions, they lack fine-grained action-level control. Our framework employs a two-stage training approach: a) Supervised fine-tuning (SFT) to align the model's action sequence text predictions with expert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced with a Time-Decayed Reward (TDR) mechanism that strategically weights multi-step future actions. Experimental results show VLN-R1 achieves strong performance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied navigation and enhance task-specific reasoning through data-efficient, reward-driven post-training.",
    "authors": [
      "Qi, Zhangyang",
      "Zhang, Zhixiong",
      "Yu, Yizhou",
      "Wang, Jiaqi",
      "Zhao, Hengshuang"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17221v1",
      "Other Formats": "https://arxiv.org/format/2506.17221",
      "TeX Source": "https://arxiv.org/src/2506.17221",
      "View PDF": "https://arxiv.org/pdf/2506.17221"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:59:59 UTC (2,059 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2401.10601",
    "abstract": "The selection of influential billboard slots remains an important problem in billboard advertisements. Existing studies on this problem have not considered the case of context-specific influence probability. To bridge this gap, in this paper, we introduce the Context Dependent Influential Billboard Slot Selection Problem. First, we show that the problem is NP-hard. We also show that the influence function holds the bi-monotonicity, bi-submodularity, and non-negativity properties. We propose an orthant-wise Stochastic Greedy approach to solve this problem. We show that this method leads to a constant-factor approximation guarantee. Subsequently, we propose an orthant-wise Incremental and Lazy Greedy approach. In a generic sense, this is a method for maximizing a bi-submodular function under the cardinality constraint, which may also be of independent interest. We analyze the performance guarantee of this algorithm as well as time and space complexity. The proposed solution approaches have been implemented with real-world billboard and trajectory datasets. We compare the performance of our method with several baseline methods, and the results are reported. Our proposed orthant-wise stochastic greedy approach leads to significant results when the parameters are set properly with reasonable computational overhead.",
    "authors": [
      "Ali, Dildar",
      "Banerjee, Suman",
      "Prasad, Yamuna"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2401.10601v2",
      "Other Formats": "https://arxiv.org/format/2401.10601",
      "TeX Source": "https://arxiv.org/src/2401.10601",
      "View PDF": "https://arxiv.org/pdf/2401.10601"
    },
    "subjects": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 19 Jan 2024 10:19:34 UTC (322 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 05:57:33 UTC (188 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/01/19",
    "title": "Influential Slot and Tag Selection in Billboard Advertisement",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17110",
    "abstract": "Accurate 6D object pose estimation is a prerequisite for successfully completing robotic prehensile and non-prehensile manipulation tasks. At present, 6D pose estimation for robotic manipulation generally relies on depth sensors based on, e.g., structured light, time-of-flight, and stereo-vision, which can be expensive, produce noisy output (as compared with RGB cameras), and fail to handle transparent objects. On the other hand, state-of-the-art monocular depth estimation models (MDEMs) provide only affine-invariant depths up to an unknown scale and shift. Metric MDEMs achieve some successful zero-shot results on public datasets, but fail to generalize. We propose a novel framework, Monocular One-shot Metric-depth Alignment (MOMA), to recover metric depth from a single RGB image, through a one-shot adaptation building on MDEM techniques. MOMA performs scale-rotation-shift alignments during camera calibration, guided by sparse ground-truth depth points, enabling accurate depth estimation without additional data collection or model retraining on the testing setup. MOMA supports fine-tuning the MDEM on transparent objects, demonstrating strong generalization capabilities. Real-world experiments on tabletop 2-finger grasping and suction-based bin-picking applications show MOMA achieves high success rates in diverse tasks, confirming its effectiveness.",
    "authors": [
      "Guo, Teng",
      "Huang, Baichuan",
      "Yu, Jingjin"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17110v1",
      "Other Formats": "https://arxiv.org/format/2506.17110",
      "TeX Source": "https://arxiv.org/src/2506.17110",
      "View PDF": "https://arxiv.org/pdf/2506.17110"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:11:20 UTC (13,121 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16685",
    "abstract": "We address key challenges in Dataset Aggregation (DAgger) for real-world contact-rich manipulation: how to collect informative human correction data and how to effectively update policies with this new data. We introduce Compliant Residual DAgger (CR-DAgger), which contains two novel components: 1) a Compliant Intervention Interface that leverages compliance control, allowing humans to provide gentle, accurate delta action corrections without interrupting the ongoing robot policy execution; and 2) a Compliant Residual Policy formulation that learns from human corrections while incorporating force feedback and force control. Our system significantly enhances performance on precise contact-rich manipulation tasks using minimal correction data, improving base policy success rates by over 50\\% on two challenging tasks (book flipping and belt assembly) while outperforming both retraining-from-scratch and finetuning approaches. Through extensive real-world experiments, we provide practical guidance for implementing effective DAgger in real-world robot learning tasks. Result videos are available at: https://compliant-residual-dagger.github.io/",
    "authors": [
      "Xu, Xiaomeng",
      "Hou, Yifan",
      "Liu, Zeyi",
      "Song, Shuran"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16685v1",
      "Other Formats": "https://arxiv.org/format/2506.16685",
      "TeX Source": "https://arxiv.org/src/2506.16685",
      "View PDF": "https://arxiv.org/pdf/2506.16685"
    },
    "subjects": [
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 01:57:47 UTC (13,202 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16840",
    "abstract": "Rapid evolution of sensors and resource-efficient machine learning models have spurred the widespread adoption of wearable fitness tracking devices. Equipped with inertial sensors, such devices can continuously capture physical movements for fitness technology (FitTech), enabling applications from sports optimization to preventive healthcare. Traditional centralized learning approaches to detect fitness activities struggle with privacy concerns, regulatory constraints, and communication inefficiencies. In contrast, Federated Learning (FL) enables a decentralized model training by communicating model updates rather than private wearable sensor data. Applying FL to FitTech presents unique challenges, such as data imbalance, lack of labelled data, heterogeneous user activity patterns, and trade-offs between personalization and generalization. To simplify research on FitTech in FL, we present the FedFitTech baseline, under the Flower framework, which is publicly available and widely used by both industry and academic researchers. Additionally, to illustrate its usage, this paper presents a case study that implements a system based on the FedFitTech baseline, incorporating a client-side early stopping strategy and comparing the results. For instance, this system allows wearable devices to optimize the trade-off between capturing common fitness activity patterns and preserving individuals' nuances, thereby enhancing both the scalability and efficiency of privacy-aware fitness tracking applications. Results show that this reduces overall redundant communications by 13 percent, while maintaining the overall recognition performance at a negligible recognition cost by 1 percent. Thus, FedFitTech baseline creates a foundation for a wide range of new research and development opportunities in FitTech, and it is available as open-source at: https://github.com/adap/flower/tree/main/baselines/fedfittech",
    "authors": [
      "Oz, Zeyneddin",
      "Korde, Shreyas",
      "Bock, Marius",
      "Van Laerhoven, Kristof"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16840v1",
      "Other Formats": "https://arxiv.org/format/2506.16840",
      "TeX Source": "https://arxiv.org/src/2506.16840",
      "View PDF": "https://arxiv.org/pdf/2506.16840"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 08:43:39 UTC (148 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "FedFitTech: A Baseline in Federated Learning for Fitness Tracking",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.13897",
    "abstract": "Despite LiDAR (Light Detection and Ranging) being an effective privacy-preserving alternative to RGB cameras to perceive human activities, it remains largely underexplored in the context of multi-modal contrastive pre-training for human activity understanding (e.g., human activity recognition (HAR), retrieval, or person re-identification (RE-ID)). To close this gap, our work explores learning the correspondence between LiDAR point clouds, human skeleton poses, IMU data, and text in a joint embedding space. More specifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embedding model, which effectively learns a joint embedding space across these four modalities. At the heart of our empirical exploration, we have combined the existing LIPD and Babel datasets, which enabled us to synchronize data of all four modalities, allowing us to explore the learning of a new joint embedding space. Our experiments demonstrate novel human activity understanding tasks for point cloud sequences enabled through DeSPITE, including Skeleton<->Pointcloud<->IMU matching, retrieval, and temporal moment retrieval. Furthermore, we show that DeSPITE is an effective pre-training strategy for point cloud HAR through experiments in MSR-Action3D and HMPEAR.",
    "authors": [
      "Kreutz, Thomas",
      "M\u00fchlh\u00e4user, Max",
      "Guinea, Alejandro Sanchez"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.13897v2",
      "Other Formats": "https://arxiv.org/format/2506.13897",
      "TeX Source": "https://arxiv.org/src/2506.13897",
      "View PDF": "https://arxiv.org/pdf/2506.13897"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 16 Jun 2025 18:18:44 UTC (17,478 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 14:16:26 UTC (17,478 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/16",
    "title": "DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding",
    "tasks": [
      "Activity Recognition",
      "Human Activity Recognition",
      "Moment Retrieval",
      "Person Re-Identification",
      "Privacy Preserving",
      "Retrieval"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17140",
    "abstract": "Deep learning models have made significant advances in histological prediction tasks in recent years. However, for adaptation in clinical practice, their lack of robustness to varying conditions such as staining, scanner, hospital, and demographics is still a limiting factor: if trained on overrepresented subpopulations, models regularly struggle with less frequent patterns, leading to shortcut learning and biased predictions. Large-scale foundation models have not fully eliminated this issue. Therefore, we propose a novel approach explicitly modeling such metadata into a Metadata-guided generative Diffusion model framework (MeDi). MeDi allows for a targeted augmentation of underrepresented subpopulations with synthetic data, which balances limited training data and mitigates biases in downstream models. We experimentally show that MeDi generates high-quality histopathology images for unseen subpopulations in TCGA, boosts the overall fidelity of the generated images, and enables improvements in performance for downstream classifiers on datasets with subpopulation shifts. Our work is a proof-of-concept towards better mitigating data biases with generative models.",
    "authors": [
      "Drexlin, David Jacob",
      "Dippel, Jonas",
      "Hense, Julius",
      "Preni\u00dfl, Niklas",
      "Montavon, Gr\u00e9goire",
      "Klauschen, Frederick",
      "M\u00fcller, Klaus-Robert"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17140v1",
      "Other Formats": "https://arxiv.org/format/2506.17140",
      "TeX Source": "https://arxiv.org/src/2506.17140",
      "View PDF": "https://arxiv.org/pdf/2506.17140"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:41:25 UTC (1,318 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16702",
    "abstract": "Large language models (LLMs) offer emerging opportunities for psychological and behavioral research, but methodological guidance is lacking. This article provides a framework for using LLMs as psychological simulators across two primary applications: simulating roles and personas to explore diverse contexts, and serving as computational models to investigate cognitive processes. For simulation, we present methods for developing psychologically grounded personas that move beyond demographic categories, with strategies for validation against human data and use cases ranging from studying inaccessible populations to prototyping research instruments. For cognitive modeling, we synthesize emerging approaches for probing internal representations, methodological advances in causal interventions, and strategies for relating model behavior to human cognition. We address overarching challenges including prompt sensitivity, temporal limitations from training data cutoffs, and ethical considerations that extend beyond traditional human subjects review. Throughout, we emphasize the need for transparency about model capabilities and constraints. Together, this framework integrates emerging empirical evidence about LLM performance--including systematic biases, cultural limitations, and prompt brittleness--to help researchers wrangle these challenges and leverage the unique capabilities of LLMs in psychological research.",
    "authors": [
      "Lin, Zhicheng"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16702",
      "View PDF": "https://arxiv.org/pdf/2506.16702"
    },
    "subjects": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 02:45:23 UTC (410 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Large Language Models as Psychological Simulators: A Methodological Guide",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17191",
    "abstract": "Emotion recognition from facial images is a crucial task in human-computer interaction, enabling machines to learn human emotions through facial expressions. Previous studies have shown that facial images can be used to train deep learning models; however, most of these studies do not include a through dataset analysis. Visualizing facial landmarks can be challenging when extracting meaningful dataset insights; to address this issue, we propose facial landmark box plots, a visualization technique designed to identify outliers in facial datasets. Additionally, we compare two sets of facial landmark features: (i) the landmarks' absolute positions and (ii) their displacements from a neutral expression to the peak of an emotional expression. Our results indicate that a neural network achieves better performance than a random forest classifier.",
    "authors": [
      "Ju\u00e1rez-Jim\u00e9nez, Israel",
      "Paredes, Tiffany Guadalupe Mart\u00ednez",
      "Garc\u00eda-Ram\u00edrez, Jes\u00fas",
      "Aguilar, Eric Ramos"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17191v1",
      "Other Formats": "https://arxiv.org/format/2506.17191",
      "TeX Source": "https://arxiv.org/src/2506.17191",
      "View PDF": "https://arxiv.org/pdf/2506.17191"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:45:34 UTC (2,075 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Facial Landmark Visualization and Emotion Recognition Through Neural Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2404.13318",
    "abstract": "The increasing volume of electronic health records (EHRs) presents the opportunity to improve the accuracy and robustness of models in clinical prediction tasks. Unlike traditional centralized approaches, federated learning enables training on data from multiple institutions while preserving patient privacy and complying with regulatory constraints. In practice, healthcare institutions (i.e., hosts) often need to build predictive models tailored to their specific needs using federated learning. In this scenario, two key challenges arise: (1) ensuring compatibility across heterogeneous EHR systems, and (2) managing federated learning costs within budget constraints. To address these challenges, we propose EHRFL, a federated learning framework designed for building a cost-effective, host-specific predictive model using patient EHR data. EHRFL consists of two components: (1) text-based EHR modeling, which facilitates cross-institution compatibility without costly data standardization, and (2) a participant selection strategy based on averaged patient embedding similarity to reduce the number of participants without degrading performance. Experiments on multiple open-source EHR datasets demonstrate the effectiveness of both components. We believe our framework offers a practical solution for enabling healthcare institutions to build institution-specific predictive models under budgetary constraints.",
    "authors": [
      "Kim, Jiyoun",
      "Kim, Junu",
      "Hur, Kyunghoon",
      "Choi, Edward"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2404.13318v4",
      "Other Formats": "https://arxiv.org/format/2404.13318",
      "TeX Source": "https://arxiv.org/src/2404.13318",
      "View PDF": "https://arxiv.org/pdf/2404.13318"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 20 Apr 2024 08:23:46 UTC (236 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Sep 2024 16:09:49 UTC (328 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Mon, 10 Feb 2025 11:18:31 UTC (327 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Fri, 20 Jun 2025 04:18:50 UTC (764 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2024/04/20",
    "title": "Client-Centered Federated Learning for Heterogeneous EHRs: Use Fewer Participants to Achieve the Same Performance",
    "repo_urls": [
      "https://github.com/ji-youn-kim/ehrfl"
    ],
    "tasks": [
      "Federated Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17004",
    "abstract": "3D semantic occupancy prediction is an emerging perception paradigm in autonomous driving, providing a voxel-level representation of both geometric details and semantic categories. However, the perception capability of a single vehicle is inherently constrained by occlusion, restricted sensor range, and narrow viewpoints. To address these limitations, collaborative perception enables the exchange of complementary information, thereby enhancing the completeness and accuracy. In the absence of a dedicated dataset for collaborative 3D semantic occupancy prediction, we augment an existing collaborative perception dataset by replaying it in CARLA with a high-resolution semantic voxel sensor to provide dense and comprehensive occupancy annotations. In addition, we establish benchmarks with varying prediction ranges designed to systematically assess the impact of spatial extent on collaborative prediction. We further develop a baseline model that performs inter-agent feature fusion via spatial alignment and attention aggregation. Experimental results demonstrate that our baseline model consistently outperforms single-agent models, with increasing gains observed as the prediction range expands.",
    "authors": [
      "Wu, Hanlin",
      "Lin, Pengfei",
      "Javanmardi, Ehsan",
      "Bao, Naren",
      "Qian, Bo",
      "Si, Hao",
      "Tsukada, Manabu"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17004v1",
      "Other Formats": "https://arxiv.org/format/2506.17004",
      "TeX Source": "https://arxiv.org/src/2506.17004",
      "View PDF": "https://arxiv.org/pdf/2506.17004"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 13:58:10 UTC (4,920 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12036",
    "abstract": "Recent work uses reinforcement learning (RL) to fine-tune text-to-image diffusion models, improving text-image alignment and sample quality. However, existing approaches introduce unnecessary complexity: they cache the full sampling trajectory, depend on differentiable reward models or large preference datasets, or require specialized guidance techniques. Motivated by the \"golden noise\" hypothesis -- that certain initial noise samples can consistently yield superior alignment -- we introduce Noise PPO, a minimalist RL algorithm that leaves the pre-trained diffusion model entirely frozen and learns a prompt-conditioned initial noise generator. Our approach requires no trajectory storage, reward backpropagation, or complex guidance tricks. Extensive experiments show that optimizing the initial noise distribution consistently improves alignment and sample quality over the original model, with the most significant gains at low inference steps. As the number of inference steps increases, the benefit of noise optimization diminishes but remains present. These findings clarify the scope and limitations of the golden noise hypothesis and reinforce the practical value of minimalist RL fine-tuning for diffusion models.",
    "authors": [
      "Miao, Yanting",
      "Loh, William",
      "Kothawade, Suraj",
      "Poupart, Pacal"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12036v2",
      "Other Formats": "https://arxiv.org/format/2506.12036",
      "TeX Source": "https://arxiv.org/src/2506.12036",
      "View PDF": "https://arxiv.org/pdf/2506.12036"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 23 May 2025 00:01:52 UTC (5,190 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 16:59:05 UTC (5,190 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/23",
    "title": "A Minimalist Method for Fine-tuning Text-to-Image Diffusion Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16784",
    "abstract": "Deep learning has demonstrated remarkable success in medical image segmentation and computer-aided diagnosis. In particular, numerous advanced methods have achieved state-of-the-art performance in brain tumor segmentation from MRI scans. While recent studies in other medical imaging domains have revealed that integrating textual reports with visual data can enhance segmentation accuracy, the field of brain tumor analysis lacks a comprehensive dataset that combines radiological images with corresponding textual annotations. This limitation has hindered the exploration of multimodal approaches that leverage both imaging and textual data. To bridge this critical gap, we introduce the TextBraTS dataset, the first publicly available volume-level multimodal dataset that contains paired MRI volumes and rich textual annotations, derived from the widely adopted BraTS2020 benchmark. Building upon this novel dataset, we propose a novel baseline framework and sequential cross-attention method for text-guided volumetric medical image segmentation. Through extensive experiments with various text-image fusion strategies and templated text formulations, our approach demonstrates significant improvements in brain tumor segmentation accuracy, offering valuable insights into effective multimodal integration techniques. Our dataset, implementation code, and pre-trained models are publicly available at https://github.com/Jupitern52/TextBraTS.",
    "authors": [
      "Shi, Xiaoyu",
      "Jain, Rahul Kumar",
      "Li, Yinhao",
      "Hou, Ruibo",
      "Cheng, Jingliang",
      "Bai, Jie",
      "Zhao, Guohua",
      "Lin, Lanfen",
      "Xu, Rui",
      "Chen, Yen-wei"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16784v1",
      "Other Formats": "https://arxiv.org/format/2506.16784",
      "TeX Source": "https://arxiv.org/src/2506.16784",
      "View PDF": "https://arxiv.org/pdf/2506.16784"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 06:57:56 UTC (2,940 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17058",
    "abstract": "In first-price auctions for display advertising, exchanges typically communicate the \"minimum-bid-to-win\" to bidders after the auction as feedback for their bidding algorithms. For a winner, this is the second-highest bid, while for losing bidders it is the highest bid. In this paper we investigate the generalization of this concept to general combinatorial auctions, motivated by the domain of video advertising. In a video pod auction, ad slots during an advertising break in a video stream are auctioned all at once, under several kinds of allocation constraints such as a constraint on total ad duration. We cast the problem in terms of computing bid updates (discounts and raises) that maintain the optimality of the current allocation. Our main result characterizes the set of joint bid updates with this property as the core of an associated bicooperative game. In the case of the assignment problem--a special case of video pod auctions--we provide a linear programming characterization of this bicooperative core. Our characterization leads to several candidates for a generalized minimum-bid-to-win. Drawing on video pod auction data from a real ad exchange, we perform an empirical analysis to understand the bidding dynamics they induce and their convergence properties.",
    "authors": [
      "Lahaie, S\u00e9bastien",
      "Schaeffer, Benjamin",
      "Zhou, Yuanjun"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17058v1",
      "Other Formats": "https://arxiv.org/format/2506.17058",
      "TeX Source": "https://arxiv.org/src/2506.17058",
      "View PDF": "https://arxiv.org/pdf/2506.17058"
    },
    "subjects": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:09:39 UTC (87 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Bidder Feedback in First-Price Auctions for Video Advertising",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17064",
    "abstract": "Generating diverse, all-atom conformational ensembles of dynamic proteins such as G-protein-coupled receptors (GPCRs) is critical for understanding their function, yet most generative models simplify atomic detail or ignore conformational diversity altogether. We present latent diffusion for full protein generation (LD-FPG), a framework that constructs complete all-atom protein structures, including every side-chain heavy atom, directly from molecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural network (ChebNet) to obtain low-dimensional latent embeddings of protein conformations, which are processed using three pooling strategies: blind, sequential and residue-based. A diffusion model trained on these latent representations generates new samples that a decoder, optionally regularized by dihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a 2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor in a membrane environment, the sequential and residue-based pooling strategy reproduces the reference ensemble with high structural fidelity (all-atom lDDT of approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone and side-chain dihedral-angle distributions with a Jensen-Shannon divergence of less than 0.03 compared to the MD data. LD-FPG thereby offers a practical route to system-specific, all-atom ensemble generation for large proteins, providing a promising tool for structure-based therapeutic design on complex, dynamic targets. The D2R-MD dataset and our implementation are freely available to facilitate further research.",
    "authors": [
      "Sengar, Aditya",
      "Hariri, Ali",
      "Probst, Daniel",
      "Barth, Patrick",
      "Vandergheynst, Pierre"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17064v1",
      "Other Formats": "https://arxiv.org/format/2506.17064",
      "TeX Source": "https://arxiv.org/src/2506.17064",
      "View PDF": "https://arxiv.org/pdf/2506.17064"
    },
    "subjects": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:12:34 UTC (25,985 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16990",
    "abstract": "LaTeX's precision and flexibility in typesetting have made it the gold standard for the preparation of scientific documentation. Large Language Models (LLMs) present a promising opportunity for researchers to produce publication-ready material using LaTeX with natural language instructions, yet current benchmarks completely lack evaluation of this ability. By introducing TeXpert, our benchmark dataset with natural language prompts for generating LaTeX code focused on components of scientific documents across multiple difficulty levels, we conduct an in-depth analysis of LLM performance in this regard and identify frequent error types. Our evaluation across open and closed-source LLMs highlights multiple key findings: LLMs excelling on standard benchmarks perform poorly in LaTeX generation with a significant accuracy drop-off as the complexity of tasks increases; open-source models like DeepSeek v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks; and formatting and package errors are unexpectedly prevalent, suggesting a lack of diverse LaTeX examples in the training datasets of most LLMs. Our dataset, code, and model evaluations are available at https://github.com/knowledge-verse-ai/TeXpert.",
    "authors": [
      "Kale, Sahil",
      "Nadadur, Vijaykant"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16990v1",
      "Other Formats": "https://arxiv.org/format/2506.16990",
      "TeX Source": "https://arxiv.org/src/2506.16990",
      "View PDF": "https://arxiv.org/pdf/2506.16990"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 13:39:16 UTC (4,106 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2409.13587",
    "abstract": "In this paper, we explore accelerating Hamiltonian ground state energy calculation on NISQ devices. We suggest using search-based methods together with machine learning to accelerate quantum algorithms, exemplified in the Quantum Eigensolver use case. We trained two small models on classically mined data from systems with up to 16 qubits, using XGBoost's Python regressor. We evaluated our preliminary approach on 20-, 24- and 28-qubit systems by optimising the Eigensolver's hyperparameters. These models predict hyperparameter values, leading to a 0.12% reduction in error when tested on 28-qubit systems. However, due to inconclusive results with 20- and 24-qubit systems, we suggest further examination of the training data based on Hamiltonian characteristics. In future work, we plan to train machine learning models to optimise other aspects or subroutines of quantum algorithm execution beyond its hyperparameters.",
    "authors": [
      "Bensoussan, Avner",
      "Chachkarova, Elena",
      "Even-Mendoza, Karine",
      "Fortz, Sophie",
      "Lenihan, Connor"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2409.13587v2",
      "Other Formats": "https://arxiv.org/format/2409.13587",
      "TeX Source": "https://arxiv.org/src/2409.13587",
      "View PDF": "https://arxiv.org/pdf/2409.13587"
    },
    "subjects": [
      "Quantum Physics (quant-ph)",
      "Software Engineering (cs.SE)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Sep 2024 15:41:11 UTC (1,002 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 13:00:50 UTC (452 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/09/20",
    "title": "Accelerating Quantum Eigensolver Algorithms With Machine Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2405.01306",
    "abstract": "Neural architecture search (NAS) enables the automatic design of neural network models. However, training the candidates generated by the search algorithm for performance evaluation incurs considerable computational overhead. Our method, dubbed nasgraph, remarkably reduces the computational costs by converting neural architectures to graphs and using the average degree, a graph measure, as the proxy in lieu of the evaluation metric. Our training-free NAS method is data-agnostic and light-weight. It can find the best architecture among 200 randomly sampled architectures from NAS-Bench201 in 217 CPU seconds. Besides, our method is able to achieve competitive performance on various datasets including NASBench-101, NASBench-201, and NDS search spaces. We also demonstrate that nasgraph generalizes to more challenging tasks on Micro TransNAS-Bench-101.",
    "authors": [
      "Huang, Zhenhan",
      "Pedapati, Tejaswini",
      "Chen, Pin-Yu",
      "Jiang, Chunheng",
      "Gao, Jianxi"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2405.01306v2",
      "Other Formats": "https://arxiv.org/format/2405.01306",
      "TeX Source": "https://arxiv.org/src/2405.01306",
      "View PDF": "https://arxiv.org/pdf/2405.01306"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 2 May 2024 14:12:58 UTC (8,654 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 10:58:04 UTC (8,655 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/05/02",
    "title": "Graph is all you need? Lightweight data-agnostic neural architecture search without training",
    "tasks": [
      "All",
      "Neural Architecture Search"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2311.06835",
    "abstract": "This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to train a detection model using a small number of normal and anomaly nodes (referred to as seen anomalies) to detect both seen anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the training anomalies). Those labelled training data provide crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current supervised GAD methods tend to over-emphasise fitting the seen anomalies, leading to many errors of detecting the unseen anomalies as normal nodes. Further, existing open-set AD models were introduced to handle Euclidean data, failing to effectively capture discriminative features from graph structure and node attributes for GAD. In this work, we propose a novel open-set GAD approach, namely normal structure regularisation (NSReg), to achieve generalised detection ability to unseen anomalies, while maintaining its effectiveness on detecting seen anomalies. The key idea in NSReg is to introduce a regularisation term that enforces the learning of compact, semantically-rich representations of normal nodes based on their structural relations to other nodes. When being optimised with supervised anomaly detection losses, the regularisation term helps incorporate strong normality into the modelling, and thus, it effectively avoids over-fitting the seen anomalies and learns a better normality decision boundary, largely reducing the false negatives of detecting unseen anomalies as normal. Extensive empirical results on seven real-world datasets show that NSReg significantly outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.",
    "authors": [
      "Wang, Qizhou",
      "Pang, Guansong",
      "Salehi, Mahsa",
      "Xia, Xiaokun",
      "Leckie, Christopher"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2311.06835v5",
      "Other Formats": "https://arxiv.org/format/2311.06835",
      "TeX Source": "https://arxiv.org/src/2311.06835",
      "View PDF": "https://arxiv.org/pdf/2311.06835"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 12 Nov 2023 13:25:28 UTC (477 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 19 Feb 2024 15:12:36 UTC (2,985 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Sun, 2 Jun 2024 14:18:26 UTC (6,389 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Wed, 2 Oct 2024 11:15:25 UTC (6,403 KB)",
        "link": "/",
        "version": "[v4]"
      },
      {
        "details": "Fri, 20 Jun 2025 01:26:10 UTC (2,024 KB)",
        "version": "[v5]"
      }
    ],
    "submitted_date": "2023/11/12",
    "title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation",
    "tasks": [
      "Anomaly Detection",
      "Graph Anomaly Detection",
      "Supervised Anomaly Detection"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2410.08316",
    "abstract": "In LLM alignment and many other ML applications, one often faces the Multi-Objective Fine-Tuning (MOFT) problem, i.e., fine-tuning an existing model with datasets labeled w.r.t. different objectives simultaneously. To address the challenge, we propose a Conditioned One-Shot fine-tuning framework (COS-DPO) that extends the Direct Preference Optimization technique, originally developed for efficient LLM alignment with preference data, to accommodate the MOFT settings. By direct conditioning on the weight across auxiliary objectives, our Weight-COS-DPO method enjoys an efficient one-shot training process for profiling the Pareto front and is capable of achieving comprehensive trade-off solutions even in the post-training stage. Based on our theoretical findings on the linear transformation properties of the loss function, we further propose the Temperature-COS-DPO method that augments the temperature parameter to the model input, enhancing the flexibility of post-training control over the trade-offs between the main and auxiliary objectives. We demonstrate the effectiveness and efficiency of the COS-DPO framework through its applications to various tasks, including the Learning-to-Rank (LTR) and LLM alignment tasks, highlighting its viability for large-scale ML deployments.",
    "authors": [
      "Ren, Yinuo",
      "Xiao, Tesi",
      "Shavlovsky, Michael",
      "Ying, Lexing",
      "Rahmanian, Holakou"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2410.08316v3",
      "Other Formats": "https://arxiv.org/format/2410.08316",
      "TeX Source": "https://arxiv.org/src/2410.08316",
      "View PDF": "https://arxiv.org/pdf/2410.08316"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Optimization and Control (math.OC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 10 Oct 2024 19:06:39 UTC (220 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Tue, 3 Dec 2024 19:21:15 UTC (227 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 14:52:02 UTC (387 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/10/10",
    "title": "COS-DPO: Conditioned One-Shot Multi-Objective Fine-Tuning Framework",
    "tasks": [
      "Learning-To-Rank"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16815",
    "abstract": "Many real-world multivariate time series are collected from a network of physical objects embedded with software, electronics, and sensors. The quasi-periodic signals generated by these objects often follow a similar repetitive and periodic pattern, but have variations in the period, and come in different lengths caused by timing (synchronization) errors. Given a multitude of such quasi-periodic time series, can we build machine learning models to identify those time series that behave differently from the majority of the observations? In addition, can the models help human experts to understand how the decision was made? We propose a sequence to Gaussian Mixture Model (seq2GMM) framework. The overarching goal of this framework is to identify unusual and interesting time series within a network time series database. We further develop a surrogate-based optimization algorithm that can efficiently train the seq2GMM model. Seq2GMM exhibits strong empirical performance on a plurality of public benchmark datasets, outperforming state-of-the-art anomaly detection techniques by a significant margin. We also theoretically analyze the convergence property of the proposed training algorithm and provide numerical results to substantiate our theoretical claims.",
    "authors": [
      "Yang, Kai",
      "Dou, Shaoyu",
      "Luo, Pan",
      "Wang, Xin",
      "Poor, H. Vincent"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16815v1",
      "Other Formats": "https://arxiv.org/format/2506.16815",
      "TeX Source": "https://arxiv.org/src/2506.16815",
      "View PDF": "https://arxiv.org/pdf/2506.16815"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 08:11:04 UTC (7,317 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Robust Group Anomaly Detection for Quasi-Periodic Network Time Series",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17068",
    "abstract": "Scalp electroencephalography (EEG) and intracranial EEG (iEEG) are vital for epilepsy diagnosis and treatment. Their unified analysis offers the potential to harness the complementary strengths of each modality but is challenging due to variations in recording montages, amplitude and signal-to-noise ratio (SNR), and frequency components. To address the aforementioned challenges, this paper introduces EpiNT, a novel Transformer-based pre-trained model for unified EEG and iEEG analysis. EpiNT employs channel-independent modeling with masked autoencoders (MAE) and vector quantization (VQ), along with a frequency domain mapping quantizer to capture crucial frequency features. Pre-trained on over 2,700 hours of multi-modal clinical neurophysiological data from 1,199 patients, EpiNT outperformed both randomly initialized models and other pre-trained methods on six downstream classification tasks, demonstrating robust representation learning capabilities. This work presents a promising approach for unified epilepsy neurophysiology analysis.",
    "authors": [
      "Zhang, Runkai",
      "Yu, Hua",
      "Gan, John Q.",
      "Wang, Haixian"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17068v1",
      "Other Formats": "https://arxiv.org/format/2506.17068",
      "TeX Source": "https://arxiv.org/src/2506.17068",
      "View PDF": "https://arxiv.org/pdf/2506.17068"
    },
    "subjects": [
      "Neurons and Cognition (q-bio.NC)",
      "Emerging Technologies (cs.ET)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:14:48 UTC (2,315 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Cross-Modal Epileptic Signal Harmonization: Frequency Domain Mapping Quantization for Pre-training a Unified Neurophysiological Transformer",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17080",
    "abstract": "Fine-tuning pretrained LLMs has been shown to be an effective strategy for reaching state-of-the-art performance on specific tasks like machine translation. However, this process of adaptation often implies sacrificing general-purpose capabilities, such as conversational reasoning and instruction-following, hampering the utility of the system in real-world applications that require a mixture of skills. In this paper, we introduce Tower+, a suite of models designed to deliver strong performance across both translation and multilingual general-purpose text capabilities. We achieve a Pareto frontier between translation specialization and multilingual general-purpose capabilities by introducing a novel training recipe that builds on Tower (Alves et al., 2024), comprising continued pretraining, supervised fine-tuning, preference optimization, and reinforcement learning with verifiable rewards. At each stage of training, we carefully generate and curate data to strengthen performance on translation as well as general-purpose tasks involving code generation, mathematics problem solving, and general instruction-following. We develop models at multiple scales: 2B, 9B, and 72B. Our smaller models often outperform larger general-purpose open-weight and proprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers best-in-class translation performance for high-resource languages and top results in multilingual Arena Hard evaluations and in IF-MT, a benchmark we introduce for evaluating both translation and instruction-following. Our findings highlight that it is possible to rival frontier models in general capabilities, while optimizing for specific business domains, such as translation and localization.",
    "authors": [
      "Rei, Ricardo",
      "Guerreiro, Nuno M.",
      "Pombal, Jos\u00e9",
      "Alves, Jo\u00e3o",
      "Teixeirinha, Pedro",
      "Farajian, Amin",
      "Martins, Andr\u00e9 F. T."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17080v1",
      "Other Formats": "https://arxiv.org/format/2506.17080",
      "TeX Source": "https://arxiv.org/src/2506.17080",
      "View PDF": "https://arxiv.org/pdf/2506.17080"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:30:06 UTC (830 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2501.07674",
    "abstract": "Large Language Models (LLMs) have achieved significant advancements, but the increasing complexity of tasks and higher performance demands highlight the need for continuous improvement. Some approaches utilize synthetic data generated by advanced LLMs based on evaluation results to train models. However, conventional evaluation methods fail to provide detailed, fine-grained profiles of LLMs, limiting their guidance for data synthesis. In this paper, we introduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a diagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine evaluation results and characterize model profiles at the knowledge component level. Based on these diagnostics, we propose two diagnosis-synthesis strategies for weakness-targeted data synthesis. Additionally, we present an enhanced data augmentation and selection pipeline to improve the quality and diversity of synthesized data. Our experiments with several open-source models show significant improvements across multiple benchmarks, achieving up to 6.00% improvement in code generation, 13.10% in mathematical reasoning, and 5.43% in academic exams. Code and data are available on GitHub.",
    "authors": [
      "Zhao, Haokun",
      "Han, Jinyi",
      "Liang, Jiaqing",
      "Xiao, Yanghua",
      "Meng, Xiaojun",
      "Wei, Jiansheng"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2501.07674v3",
      "Other Formats": "https://arxiv.org/format/2501.07674",
      "TeX Source": "https://arxiv.org/src/2501.07674",
      "View PDF": "https://arxiv.org/pdf/2501.07674"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 13 Jan 2025 20:13:59 UTC (1,934 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 5 Mar 2025 18:39:05 UTC (4,602 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 03:44:20 UTC (2,548 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/01/13",
    "title": "CDS: Knowledge Component-Driven Data Synthesis Guided by Cognitive Diagnosis Theory",
    "tasks": [
      "cognitive diagnosis",
      "Data Augmentation",
      "Diagnostic"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17051",
    "abstract": "Effective license plate recognition systems are required to be resilient to constant change, as new license plates are released into traffic daily. While Transformer-based networks excel in their recognition at first sight, we observe significant performance drop over time which proves them unsuitable for tense production environments. Indeed, such systems obtain state-of-the-art results on plates whose syntax is seen during training. Yet, we show they perform similarly to random guessing on future plates where legible characters are wrongly recognized due to a shift in their syntax. After highlighting the flows of positional and contextual information in Transformer encoder-decoders, we identify several causes for their over-reliance on past syntax. Following, we devise architectural cut-offs and replacements which we integrate into SaLT, an attempt at a Syntax-Less Transformer for syntax-agnostic modeling of license plate representations. Experiments on both real and synthetic datasets show that our approach reaches top accuracy on past syntax and most importantly nearly maintains performance on future license plates. We further demonstrate the robustness of our architecture enhancements by way of various ablations.",
    "authors": [
      "Meyer, Florent",
      "Guichard, Laurent",
      "Coquenet, Denis",
      "Gravier, Guillaume",
      "Soullard, Yann",
      "Co\u00fcasnon, Bertrand"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17051v1",
      "Other Formats": "https://arxiv.org/format/2506.17051",
      "TeX Source": "https://arxiv.org/src/2506.17051",
      "View PDF": "https://arxiv.org/pdf/2506.17051"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:03:57 UTC (655 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Relaxed syntax modeling in Transformers for future-proof license plate recognition",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2503.17193",
    "abstract": "In complex environments, detecting tiny infrared targets has always been challenging because of the low contrast and high noise levels inherent in infrared images. These factors often lead to the loss of crucial details during feature extraction. Moreover, existing detection methods have limitations in adequately integrating global and local information, which constrains the efficiency and accuracy of infrared small target detection. To address these challenges, this paper proposes a network architecture named MSCA-Net, which integrates three key components: Multi-Scale Enhanced Dilated Attention mechanism (MSEDA), Positional Convolutional Block Attention Module (PCBAM), and Channel Aggregation Feature Fusion Block (CAB). Specifically, MSEDA employs a multi-scale feature fusion attention mechanism to adaptively aggregate information across different scales, enriching feature representation. PCBAM captures the correlation between global and local features through a correlation matrix-based strategy, enabling deep feature interaction. Moreover, CAB enhances the representation of critical features by assigning greater weights to them, integrating both low-level and high-level information, and thereby improving the models detection performance in complex backgrounds. The experimental results demonstrate that MSCA-Net achieves strong small target detection performance in complex backgrounds. Specifically, it attains mIoU scores of 78.43%, 94.56%, and 67.08% on the NUAA-SIRST, NUDT-SIRST, and IRTSD-1K datasets, respectively, underscoring its effectiveness and strong potential for real-world applications.",
    "authors": [
      "Lu, Xiaojin",
      "yue, Taoran",
      "cai, Jiaxi",
      "Chen, Yuanping",
      "Lv, Cuihong",
      "Chu, Shibing"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.17193v2",
      "Other Formats": "https://arxiv.org/format/2503.17193",
      "TeX Source": "https://arxiv.org/src/2503.17193",
      "View PDF": "https://arxiv.org/pdf/2503.17193"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 21 Mar 2025 14:42:31 UTC (2,719 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 15:42:24 UTC (3,345 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/03/21",
    "title": "MSCA-Net:Multi-Scale Context Aggregation Network for Infrared Small Target Detection",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.14684",
    "abstract": "Automatic sample identification (ASID), the detection and identification of portions of audio recordings that have been reused in new musical works, is an essential but challenging task in the field of audio query-based retrieval. While a related task, audio fingerprinting, has made significant progress in accurately retrieving musical content under \"real world\" (noisy, reverberant) conditions, ASID systems struggle to identify samples that have undergone musical modifications. Thus, a system robust to common music production transformations such as time-stretching, pitch-shifting, effects processing, and underlying or overlaying music is an important open challenge. In this work, we propose a lightweight and scalable encoding architecture employing a Graph Neural Network within a contrastive learning framework. Our model uses only 9% of the trainable parameters compared to the current state-of-the-art system while achieving comparable performance, reaching a mean average precision (mAP) of 44.2%. To enhance retrieval quality, we introduce a two-stage approach consisting of an initial coarse similarity search for candidate selection, followed by a cross-attention classifier that rejects irrelevant matches and refines the ranking of retrieved candidates - an essential capability absent in prior models. In addition, because queries in real-world applications are often short in duration, we benchmark our system for short queries using new fine-grained annotations for the Sample100 dataset, which we publish as part of this work.",
    "authors": [
      "Bhattacharjee, Aditya",
      "Higgs, Ivan Meresman",
      "Sandler, Mark",
      "Benetos, Emmanouil"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.14684v2",
      "Other Formats": "https://arxiv.org/format/2506.14684",
      "TeX Source": "https://arxiv.org/src/2506.14684",
      "View PDF": "https://arxiv.org/pdf/2506.14684"
    },
    "subjects": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 17 Jun 2025 16:19:21 UTC (146 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 09:48:47 UTC (148 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/17",
    "title": "Refining music sample identification with a self-supervised graph neural network",
    "repo_urls": [
      "https://github.com/chymaera96/neuralsampleid"
    ],
    "tasks": [
      "Contrastive Learning",
      "Graph Neural Network",
      "Retrieval"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16720",
    "abstract": "With the increasing presence of automated vehicles on open roads under driver supervision, disengagement cases are becoming more prevalent. While some data-driven planning systems attempt to directly utilize these disengagement cases for policy improvement, the inherent scarcity of disengagement data (often occurring as a single instances) restricts training effectiveness. Furthermore, some disengagement data should be excluded since the disengagement may not always come from the failure of driving policies, e.g. the driver may casually intervene for a while. To this end, this work proposes disengagement-reason-augmented reinforcement learning (DRARL), which enhances driving policy improvement process according to the reason of disengagement cases. Specifically, the reason of disengagement is identified by a out-of-distribution (OOD) state estimation model. When the reason doesn't exist, the case will be identified as a casual disengagement case, which doesn't require additional policy adjustment. Otherwise, the policy can be updated under a reason-augmented imagination environment, improving the policy performance of disengagement cases with similar reasons. The method is evaluated using real-world disengagement cases collected by autonomous driving robotaxi. Experimental results demonstrate that the method accurately identifies policy-related disengagement reasons, allowing the agent to handle both original and semantically similar cases through reason-augmented training. Furthermore, the approach prevents the agent from becoming overly conservative after policy adjustments. Overall, this work provides an efficient way to improve driving policy performance with disengagement cases.",
    "authors": [
      "Zhou, Weitao",
      "Zhang, Bo",
      "Cao, Zhong",
      "Li, Xiang",
      "Cheng, Qian",
      "Liu, Chunyang",
      "Zhang, Yaqin",
      "Yang, Diange"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16720v1",
      "Other Formats": "https://arxiv.org/format/2506.16720",
      "TeX Source": "https://arxiv.org/src/2506.16720",
      "View PDF": "https://arxiv.org/pdf/2506.16720"
    },
    "subjects": [
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 03:32:01 UTC (2,524 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "DRARL: Disengagement-Reason-Augmented Reinforcement Learning for Efficient Improvement of Autonomous Driving Policy",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17133",
    "abstract": "Deep neural networks are increasingly being used to detect and diagnose medical conditions using medical imaging. Despite their utility, these models are highly vulnerable to adversarial attacks and distribution shifts, which can affect diagnostic reliability and undermine trust among healthcare professionals. In this study, we propose a robust training algorithm with data augmentation (RTDA) to mitigate these vulnerabilities in medical image classification. We benchmark classifier robustness against adversarial perturbations and natural variations of RTDA and six competing baseline techniques, including adversarial training and data augmentation approaches in isolation and combination, using experimental data sets with three different imaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that RTDA achieves superior robustness against adversarial attacks and improved generalization performance in the presence of distribution shift in each image classification task while maintaining high clean accuracy.",
    "authors": [
      "Mart\u00ednez-Mart\u00ednez, Josu\u00e9",
      "Brown, Olivia",
      "Karami, Mostafa",
      "Nabavi, Sheida"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17133v1",
      "Other Formats": "https://arxiv.org/format/2506.17133",
      "TeX Source": "https://arxiv.org/src/2506.17133",
      "View PDF": "https://arxiv.org/pdf/2506.17133"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:36:39 UTC (613 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Robust Training with Data Augmentation for Medical Imaging Classification",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.07527",
    "abstract": "Foundation models have revolutionized natural language processing and artificial intelligence, significantly enhancing how machines comprehend and generate human languages. Inspired by the success of these foundation models, researchers have developed foundation models for individual scientific domains, including small molecules, materials, proteins, DNA, RNA and even cells. However, these models are typically trained in isolation, lacking the ability to integrate across different scientific domains. Recognizing that entities within these domains can all be represented as sequences, which together form the \"language of nature\", we introduce Nature Language Model (NatureLM), a sequence-based science foundation model designed for scientific discovery. Pre-trained with data from multiple scientific domains, NatureLM offers a unified, versatile model that enables various applications including: (i) generating and optimizing small molecules, proteins, RNA, and materials using text instructions; (ii) cross-domain generation/design, such as protein-to-molecule and protein-to-RNA generation; and (iii) top performance across different domains, matching or surpassing state-of-the-art specialist models. NatureLM offers a promising generalist approach for various scientific tasks, including drug discovery (hit generation/optimization, ADMET optimization, synthesis), novel material design, and the development of therapeutic proteins or nucleotides. We have developed NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion parameters) and observed a clear improvement in performance as the model size increases.",
    "authors": [
      "Xia, Yingce",
      "Jin, Peiran",
      "Xie, Shufang",
      "He, Liang",
      "Cao, Chuan",
      "Luo, Renqian",
      "Liu, Guoqing",
      "Wang, Yue",
      "Liu, Zequn",
      "Chen, Yuan-Jyue",
      "Guo, Zekun",
      "Bai, Yeqi",
      "Deng, Pan",
      "Min, Yaosen",
      "Lu, Ziheng",
      "Hao, Hongxia",
      "Yang, Han",
      "Li, Jielan",
      "Liu, Chang",
      "Zhang, Jia",
      "Zhu, Jianwei",
      "Bi, Ran",
      "Wu, Kehan",
      "Zhang, Wei",
      "Gao, Kaiyuan",
      "Pei, Qizhi",
      "Wang, Qian",
      "Liu, Xixian",
      "Li, Yanting",
      "Zhu, Houtian",
      "Lu, Yeqing",
      "Ma, Mingqian",
      "Wang, Zun",
      "Xie, Tian",
      "Maziarz, Krzysztof",
      "Segler, Marwin",
      "Yang, Zhao",
      "Chen, Zilong",
      "Shi, Yu",
      "Zheng, Shuxin",
      "Wu, Lijun",
      "Hu, Chen",
      "Dai, Peggy",
      "Liu, Tie-Yan",
      "Liu, Haiguang",
      "Qin, Tao"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.07527v3",
      "Other Formats": "https://arxiv.org/format/2502.07527",
      "TeX Source": "https://arxiv.org/src/2502.07527",
      "View PDF": "https://arxiv.org/pdf/2502.07527"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 11 Feb 2025 13:08:03 UTC (2,994 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 6 Mar 2025 12:34:23 UTC (19,184 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 05:18:13 UTC (6,078 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/02/11",
    "title": "Nature Language Model: Deciphering the Language of Nature for Scientific Discovery",
    "tasks": [
      "Drug Discovery",
      "Retrosynthesis",
      "scientific discovery"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17212",
    "abstract": "Articulated objects are common in the real world, yet modeling their structure and motion remains a challenging task for 3D reconstruction methods. In this work, we introduce Part$^{2}$GS, a novel framework for modeling articulated digital twins of multi-part objects with high-fidelity geometry and physically consistent articulation. Part$^{2}$GS leverages a part-aware 3D Gaussian representation that encodes articulated components with learnable attributes, enabling structured, disentangled transformations that preserve high-fidelity geometry. To ensure physically consistent motion, we propose a motion-aware canonical representation guided by physics-based constraints, including contact enforcement, velocity consistency, and vector-field alignment. Furthermore, we introduce a field of repel points to prevent part collisions and maintain stable articulation paths, significantly improving motion coherence over baselines. Extensive evaluations on both synthetic and real-world datasets show that Part$^{2}$GS consistently outperforms state-of-the-art methods by up to 10$\\times$ in Chamfer Distance for movable parts.",
    "authors": [
      "Yu, Tianjiao",
      "Shah, Vedant",
      "Wahed, Muntasir",
      "Shen, Ying",
      "Nguyen, Kiet A.",
      "Lourentzou, Ismini"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17212v1",
      "Other Formats": "https://arxiv.org/format/2506.17212",
      "TeX Source": "https://arxiv.org/src/2506.17212",
      "View PDF": "https://arxiv.org/pdf/2506.17212"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:59:12 UTC (4,159 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2408.14352",
    "abstract": "In machine learning, contamination refers to situations where testing data leak into the training set. The issue is particularly relevant for the evaluation of the performance of Large Language Models (LLMs), which are generally trained on gargantuan, and generally opaque, corpora of text scraped from the world wide web. Developing tools to detect contamination is therefore crucial to be able to fairly and properly track the evolution of the performance of LLMs. To date, only a few recent studies have attempted to address the issue of quantifying and detecting contamination in short text sequences, such as those commonly found in benchmarks. However, these methods have limitations that can sometimes render them impractical. In the present paper, we introduce LogProber, a novel, efficient algorithm that we show to be able to detect contamination in a black box setting that tries to tackle some of these drawbacks by focusing on the familiarity with the question rather than the answer. Here, we explore the properties of the proposed method in comparison with concurrent approaches, identify its advantages and limitations, and illustrate how different forms of contamination can go undetected depending on the design of the detection algorithm.",
    "authors": [
      "Yax, Nicolas",
      "Oudeyer, Pierre-Yves",
      "Palminteri, Stefano"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2408.14352v3",
      "Other Formats": "https://arxiv.org/format/2408.14352",
      "TeX Source": "https://arxiv.org/src/2408.14352",
      "View PDF": "https://arxiv.org/pdf/2408.14352"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 26 Aug 2024 15:29:34 UTC (4,521 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 11 Jun 2025 14:42:54 UTC (867 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 12:52:37 UTC (867 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/08/26",
    "title": "LogProber: Disentangling confidence from contamination in LLM responses",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16712",
    "abstract": "Generative Reward Models (GRMs) provide greater flexibility than scalar reward models in capturing human preferences, but their effectiveness is limited by poor reasoning capabilities. This often results in incomplete or overly speculative reasoning paths, leading to hallucinations or missing key information in complex tasks. We address this challenge with ReasonGRM, a three-stage generative reward modeling framework. In the first stage, Zero-RL is used to generate concise, outcome-directed reasoning paths that reduce the likelihood of critical omissions. In the second stage, we introduce a novel evaluation metric, $R^\\star$, which scores reasoning paths based on their generation likelihood. This favors paths that reach correct answers with minimal exploration, helping to reduce hallucination-prone data during training. In the final stage, the model is further refined through reinforcement learning on challenging examples to enhance its preference discrimination capabilities. Experiments on three public benchmarks show that ReasonGRM achieves competitive or state-of-the-art performance, outperforming previous best GRMs by 1.8\\% on average and surpassing proprietary models such as GPT-4o by up to 5.6\\%. These results demonstrate the effectiveness of reasoning-aware training and highlight the importance of high-quality rationale selection for reliable preference modeling.",
    "authors": [
      "Chen, Bin",
      "Gao, Xinzge",
      "Hu, Chuanrui",
      "Yu, Penghang",
      "Zhang, Hua",
      "Bao, Bing-Kun"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16712v1",
      "Other Formats": "https://arxiv.org/format/2506.16712",
      "TeX Source": "https://arxiv.org/src/2506.16712",
      "View PDF": "https://arxiv.org/pdf/2506.16712"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 03:10:52 UTC (494 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16991",
    "abstract": "The segmentation of forest LiDAR 3D point clouds, including both individual tree and semantic segmentation, is fundamental for advancing forest management and ecological research. However, current approaches often struggle with the complexity and variability of natural forest environments. We present ForestFormer3D, a new unified and end-to-end framework designed for precise individual tree and semantic segmentation. ForestFormer3D incorporates ISA-guided query point selection, a score-based block merging strategy during inference, and a one-to-many association mechanism for effective training. By combining these new components, our model achieves state-of-the-art performance for individual tree segmentation on the newly introduced FOR-instanceV2 dataset, which spans diverse forest types and regions. Additionally, ForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx), showcasing its robustness across different forest conditions and sensor modalities. The FOR-instanceV2 dataset and the ForestFormer3D code will be released soon.",
    "authors": [
      "Xiang, Binbin",
      "Wielgosz, Maciej",
      "Puliti, Stefano",
      "Kr\u00e1l, Kamil",
      "Kr\u016f\u010dek, Martin",
      "Missarov, Azim",
      "Astrup, Rasmus"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16991v1",
      "Other Formats": "https://arxiv.org/format/2506.16991",
      "TeX Source": "https://arxiv.org/src/2506.16991",
      "View PDF": "https://arxiv.org/pdf/2506.16991"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 13:39:27 UTC (23,432 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.12345",
    "abstract": "Urban causal research is essential for understanding the complex, dynamic processes that shape cities and for informing evidence-based policies. However, current practices are often constrained by inefficient and biased hypothesis formulation, challenges in integrating multimodal data, and fragile experimental methodologies. Imagine a system that automatically estimates the causal impact of congestion pricing on commute times by income group or measures how new green spaces affect asthma rates across neighborhoods using satellite imagery and health reports, and then generates comprehensive, policy-ready outputs, including causal estimates, subgroup analyses, and actionable recommendations. In this Perspective, we propose UrbanCIA, an LLM-driven conceptual framework composed of four distinct modular agents responsible for hypothesis generation, data engineering, experiment design and execution, and results interpretation with policy insights. We begin by examining the current landscape of urban causal research through a structured taxonomy of research topics, data sources, and methodological approaches, revealing systemic limitations across the workflow. Next, we introduce the design principles and technological roadmap for the four modules in the proposed framework. We also propose evaluation criteria to assess the rigor and transparency of these AI-augmented processes. Finally, we reflect on the broader implications for human-AI collaboration, equity, and accountability. We call for a new research agenda that embraces LLM-driven tools as catalysts for more scalable, reproducible, and inclusive urban research.",
    "authors": [
      "Xia, Yutong",
      "Qu, Ao",
      "Zheng, Yunhan",
      "Tang, Yihong",
      "Zhuang, Dingyi",
      "Liang, Yuxuan",
      "Wang, Shenhao",
      "Wu, Cathy",
      "Sun, Lijun",
      "Zimmermann, Roger",
      "Zhao, Jinhua"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.12345v3",
      "Other Formats": "https://arxiv.org/format/2504.12345",
      "TeX Source": "https://arxiv.org/src/2504.12345",
      "View PDF": "https://arxiv.org/pdf/2504.12345"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 15 Apr 2025 16:58:11 UTC (5,829 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 9 May 2025 09:12:39 UTC (7,499 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 07:09:39 UTC (7,467 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/04/15",
    "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models",
    "tasks": [
      "Causal Inference"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2411.16813",
    "abstract": "The incivility prevalent on platforms like Twitter (now X) and Reddit poses a challenge for developing AI systems that can support productive and rhetorically sound political argumentation. In this study, we report experiments with GPT-3.5 Turbo, fine-tuned on two contrasting datasets of political discussions: high-variance, high-incivility Twitter replies to U.S. Congress, and low-variance, low-incivility posts from Reddit's r/ChangeMyView. We systematically evaluate how these data sources and prompting strategies shape the rhetorical framing and deliberative quality of model-generated arguments. Our results show that Reddit-finetuned models produce safer but rhetorically rigid arguments, while cross-platform fine-tuning amplifies toxicity. Prompting reduces specific toxic behaviors, such as personal attacks, but fails to fully mitigate the influence of high-incivility training data. We introduce and validate a rhetorical evaluation rubric and provide practical guidelines for deploying LLMs in content authoring, moderation, and deliberation support.",
    "authors": [
      "Churina, Svetlana",
      "Jaidka, Kokil"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2411.16813",
      "View PDF": "https://arxiv.org/pdf/2411.16813"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 25 Nov 2024 15:28:11 UTC (371 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sun, 8 Dec 2024 02:00:57 UTC (549 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 14:35:51 UTC (566 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/11/25",
    "title": "Incivility and Rigidity: The Risks of Fine-Tuning LLMs for Political Argumentation",
    "tasks": [
      "Text Generation"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17162",
    "abstract": "Malicious PDF files have emerged as a persistent threat and become a popular attack vector in web-based attacks. While machine learning-based PDF malware classifiers have shown promise, these classifiers are often susceptible to adversarial attacks, undermining their reliability. To address this issue, recent studies have aimed to enhance the robustness of PDF classifiers. Despite these efforts, the feature engineering underlying these studies remains outdated. Consequently, even with the application of cutting-edge machine learning techniques, these approaches fail to fundamentally resolve the issue of feature instability. To tackle this, we propose a novel approach for PDF feature extraction and PDF malware detection. We introduce the PDFObj IR (PDF Object Intermediate Representation), an assembly-like language framework for PDF objects, from which we extract semantic features using a pretrained language model. Additionally, we construct an Object Reference Graph to capture structural features, drawing inspiration from program analysis. This dual approach enables us to analyze and detect PDF malware based on both semantic and structural features. Experimental results demonstrate that our proposed classifier achieves strong adversarial robustness while maintaining an exceptionally low false positive rate of only 0.07% on baseline dataset compared to state-of-the-art PDF malware classifiers.",
    "authors": [
      "Liu, Side",
      "Ming, Jiang",
      "Zhou, Guodong",
      "Liu, Xinyi",
      "Fu, Jianming",
      "Peng, Guojun"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17162v1",
      "Other Formats": "https://arxiv.org/format/2506.17162",
      "TeX Source": "https://arxiv.org/src/2506.17162",
      "View PDF": "https://arxiv.org/pdf/2506.17162"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:08:08 UTC (691 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Analyzing PDFs like Binaries: Adversarially Robust PDF Malware Analysis via Intermediate Representation and Language Model",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16912",
    "abstract": "Sample efficiency is a crucial property of language models with practical implications for training efficiency. In real-world text, information follows a long-tailed distribution. Yet, we expect models to learn and recall frequent and infrequent facts. Sample-efficient models are better equipped to handle this challenge of learning and retaining rare information without requiring excessive exposure. This study analyzes multiple models of varying architectures and sizes, all trained on the same pre-training data. By annotating relational facts with their frequencies in the training corpus, we examine how model performance varies with fact frequency. Our findings show that most models perform similarly on high-frequency facts but differ notably on low-frequency facts. This analysis provides new insights into the relationship between model architecture, size, and factual learning efficiency.",
    "authors": [
      "Christoph, Daniel",
      "Ploner, Max",
      "Haller, Patrick",
      "Akbik, Alan"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16912v1",
      "Other Formats": "https://arxiv.org/format/2506.16912",
      "TeX Source": "https://arxiv.org/src/2506.16912",
      "View PDF": "https://arxiv.org/pdf/2506.16912"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 11:10:24 UTC (244 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16929",
    "abstract": "Neonatal death is still a concerning reality for underdeveloped and even some developed countries. Worldwide data indicate that 26.693 babies out of 1,000 births die, according to Macro Trades. To reduce this number, early prediction of endangered babies is crucial. Such prediction enables the opportunity to take ample care of the child and mother so that early child death can be avoided. In this context, machine learning was used to determine whether a newborn baby is at risk. To train the predictive model, historical data of 1.4 million newborns was used. Machine learning and deep learning techniques such as logical regression, K-nearest neighbor, random forest classifier, extreme gradient boosting (XGBoost), convolutional neural network, and long short-term memory (LSTM) were implemented using the dataset to identify the most accurate model for predicting neonatal mortality. Among the machine learning algorithms, XGBoost and random forest classifier achieved the best accuracy with 94%, while among the deep learning models, LSTM delivered the highest accuracy with 99%. Therefore, using LSTM appears to be the most suitable approach to predict whether precautionary measures for a child are necessary.",
    "authors": [
      "Raihan, Mohon",
      "Saha, Plabon Kumar",
      "Gupta, Rajan Das",
      "Kabir, A Z M Tahmidul",
      "Tamanna, Afia Anjum",
      "Harun-Ur-Rashid, Md.",
      "Salam, Adnan Bin Abdus",
      "Anjum, Md Tanvir",
      "Kabir, A Z M Ahteshamul"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16929",
      "View PDF": "https://arxiv.org/pdf/2506.16929"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 11:44:48 UTC (1,033 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "A deep learning and machine learning approach to predict neonatal death in the context of S\\~ao Paulo",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2407.17734",
    "abstract": "The advent of vision-language models fosters the interactive conversations between AI-enabled models and humans. Yet applying these models into clinics must deal with daunting challenges around large-scale training data, financial, and computational resources. Here we propose a cost-effective instruction learning framework for conversational pathology named as CLOVER. CLOVER only trains a lightweight module and uses instruction tuning while freezing the parameters of the large language model. Instead of using costly GPT-4, we propose well-designed prompts on GPT-3.5 for building generation-based instructions, emphasizing the utility of pathological knowledge derived from the Internet source. To augment the use of instructions, we construct a high-quality set of template-based instructions in the context of digital pathology. From two benchmark datasets, our findings reveal the strength of hybrid-form instructions in the visual question-answer in pathology. Extensive results show the cost-effectiveness of CLOVER in answering both open-ended and closed-ended questions, where CLOVER outperforms strong baselines that possess 37 times more training parameters and use instruction data generated from GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot learning in the external clinical dataset. These findings demonstrate that cost-effective modeling of CLOVER could accelerate the adoption of rapid conversational applications in the landscape of digital pathology.",
    "authors": [
      "Chen, Kaitao",
      "Liu, Mianxin",
      "Yan, Fang",
      "Ma, Lei",
      "Shi, Xiaoming",
      "Wang, Lilong",
      "Wang, Xiaosong",
      "Zhu, Lifeng",
      "Wang, Zhe",
      "Zhou, Mu",
      "Zhang, Shaoting"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2407.17734v2",
      "Other Formats": "https://arxiv.org/format/2407.17734",
      "TeX Source": "https://arxiv.org/src/2407.17734",
      "View PDF": "https://arxiv.org/pdf/2407.17734"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 25 Jul 2024 03:12:57 UTC (16,814 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 07:30:05 UTC (26,575 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/07/25",
    "title": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis",
    "repo_urls": [
      "https://github.com/jlinekai/clover"
    ],
    "tasks": [
      "Few-Shot Learning",
      "Language Modelling",
      "Large Language Model"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16856",
    "abstract": "Autonomous parking plays a vital role in intelligent vehicle systems, particularly in constrained urban environments where high-precision control is required. While traditional rule-based parking systems struggle with environmental uncertainties and lack adaptability in crowded or dynamic scenes, human drivers demonstrate the ability to park intuitively without explicit modeling. Inspired by this observation, we propose a Transformer-based end-to-end framework for autonomous parking that learns from expert demonstrations. The network takes as input surround-view camera images, goal-point representations, ego vehicle motion, and pedestrian trajectories. It outputs discrete control sequences including throttle, braking, steering, and gear selection. A novel cross-attention module integrates BEV features with target points, and a GRU-based pedestrian predictor enhances safety by modeling dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both vertical and parallel parking scenarios. Experiments show our model achieves a high success rate of 96.57\\%, with average positional and orientation errors of 0.21 meters and 0.41 degrees, respectively. The ablation studies further demonstrate the effectiveness of key modules such as pedestrian prediction and goal-point attention fusion. The code and dataset will be released at: https://github.com/little-snail-f/ParkFormer.",
    "authors": [
      "Fu, Jun",
      "Tian, Bin",
      "Chen, Haonan",
      "Meng, Shi",
      "Yao, Tingting"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16856v1",
      "Other Formats": "https://arxiv.org/format/2506.16856",
      "TeX Source": "https://arxiv.org/src/2506.16856",
      "View PDF": "https://arxiv.org/pdf/2506.16856"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 09:14:09 UTC (4,149 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12400",
    "abstract": "3D Gaussian Splatting (3DGS) has emerged as a powerful technique for novel view synthesis. However, existing methods struggle to adaptively optimize the distribution of Gaussian primitives based on scene characteristics, making it challenging to balance reconstruction quality and efficiency. Inspired by human perception, we propose scene-adaptive perceptual densification for Gaussian Splatting (Perceptual-GS), a novel framework that integrates perceptual sensitivity into the 3DGS training process to address this challenge. We first introduce a perception-aware representation that models human visual sensitivity while constraining the number of Gaussian primitives. Building on this foundation, we develop a perceptual sensitivity-adaptive distribution to allocate finer Gaussian granularity to visually critical regions, enhancing reconstruction quality and robustness. Extensive evaluations on multiple datasets, including BungeeNeRF for large-scale scenes, demonstrate that Perceptual-GS achieves state-of-the-art performance in reconstruction quality, efficiency, and robustness. The code is publicly available at: https://github.com/eezkni/Perceptual-GS",
    "authors": [
      "Zhou, Hongbi",
      "Ni, Zhangkai"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12400v2",
      "Other Formats": "https://arxiv.org/format/2506.12400",
      "TeX Source": "https://arxiv.org/src/2506.12400",
      "View PDF": "https://arxiv.org/pdf/2506.12400"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 14 Jun 2025 08:31:53 UTC (14,033 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 14:42:12 UTC (14,033 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/14",
    "title": "Perceptual-GS: Scene-adaptive Perceptual Densification for Gaussian Splatting",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2410.23693",
    "abstract": "In the rapid advancement of artificial intelligence, privacy protection has become crucial, giving rise to machine unlearning. Machine unlearning is a technique that removes specific data influences from trained models without the need for extensive retraining. However, it faces several key challenges, including accurately implementing unlearning, ensuring privacy protection during the unlearning process, and achieving effective unlearning without significantly compromising model performance. This paper presents a novel approach to machine unlearning by employing Layer-wise Relevance Analysis and Neuronal Path Perturbation. We address three primary challenges: the lack of detailed unlearning principles, privacy guarantees in zero-shot unlearning scenario, and the balance between unlearning effectiveness and model utility. Our method balances machine unlearning performance and model utility by identifying and perturbing highly relevant neurons, thereby achieving effective unlearning. By using data not present in the original training set during the unlearning process, we satisfy the zero-shot unlearning scenario and ensure robust privacy protection. Experimental results demonstrate that our approach effectively removes targeted data from the target unlearning model while maintaining the model's utility, offering a practical solution for privacy-preserving machine learning.",
    "authors": [
      "Chang, Wenhan",
      "Zhu, Tianqing",
      "Xiong, Ping",
      "Wu, Yufeng",
      "Guan, Faqian",
      "Zhou, Wanlei"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2410.23693v2",
      "Other Formats": "https://arxiv.org/format/2410.23693",
      "TeX Source": "https://arxiv.org/src/2410.23693",
      "View PDF": "https://arxiv.org/pdf/2410.23693"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 31 Oct 2024 07:37:04 UTC (12,317 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 14:25:16 UTC (14,880 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/10/31",
    "title": "Zero-shot Class Unlearning via Layer-wise Relevance Analysis and Neuronal Path Perturbation",
    "tasks": [
      "Machine Unlearning",
      "Privacy Preserving"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16661",
    "abstract": "Deep neural networks often use large, high-quality datasets to achieve high performance on many machine learning tasks. When training involves potentially sensitive data, this process can raise privacy concerns, as large models have been shown to unintentionally memorize and reveal sensitive information, including reconstructing entire training samples. Differential privacy (DP) provides a robust framework for protecting individual data and in particular, a new approach to privately training deep neural networks is to approximate the input dataset with a privately generated synthetic dataset, before any subsequent training algorithm. We introduce a novel principled method for DP synthetic image embedding generation, based on fitting a Gaussian Mixture Model (GMM) in an appropriate embedding space using DP clustering. Our method provably learns a GMM under separation conditions. Empirically, a simple two-layer neural network trained on synthetically generated embeddings achieves state-of-the-art (SOTA) classification accuracy on standard benchmark datasets. Additionally, we demonstrate that our method can generate realistic synthetic images that achieve downstream classification accuracy comparable to SOTA methods. Our method is quite general, as the encoder and decoder modules can be freely substituted to suit different tasks. It is also highly scalable, consisting only of subroutines that scale linearly with the number of samples and/or can be implemented efficiently in distributed systems.",
    "authors": [
      "Zhou, Felix",
      "Zhou, Samson",
      "Mirrokni, Vahab",
      "Epasto, Alessandro",
      "Cohen-Addad, Vincent"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16661v1",
      "Other Formats": "https://arxiv.org/format/2506.16661",
      "TeX Source": "https://arxiv.org/src/2506.16661",
      "View PDF": "https://arxiv.org/pdf/2506.16661"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 00:17:14 UTC (3,607 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Private Training & Data Generation by Clustering Embeddings",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16732",
    "abstract": "In unsupervised combinatorial optimization (UCO), during training, one aims to have continuous decisions that are promising in a probabilistic sense for each training instance, which enables end-to-end training on initially discrete and non-differentiable problems. At the test time, for each test instance, starting from continuous decisions, derandomization is typically applied to obtain the final deterministic decisions. Researchers have developed more and more powerful test-time derandomization schemes to enhance the empirical performance and the theoretical guarantee of UCO methods. However, we notice a misalignment between training and testing in the existing UCO methods. Consequently, lower training losses do not necessarily entail better post-derandomization performance, even for the training instances without any data distribution shift. Empirically, we indeed observe such undesirable cases. We explore a preliminary idea to better align training and testing in UCO by including a differentiable version of derandomization into training. Our empirical exploration shows that such an idea indeed improves training-test alignment, but also introduces nontrivial challenges into training.",
    "authors": [
      "Bu, Fanchen",
      "Shin, Kijung"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16732v1",
      "Other Formats": "https://arxiv.org/format/2506.16732",
      "TeX Source": "https://arxiv.org/src/2506.16732",
      "View PDF": "https://arxiv.org/pdf/2506.16732"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 04:05:09 UTC (56 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16733",
    "abstract": "Positron emission tomography (PET) is widely used to assess metabolic activity, but its application is limited by the availability of radiotracers. 18F-labeled fluorodeoxyglucose (18F-FDG) is the most commonly used tracer but shows limited effectiveness for certain tumors. In contrast, 6-18F-fluoro-3,4-dihydroxy-L-phenylalanine (18F-DOPA) offers higher specificity for neuroendocrine tumors and neurological disorders. However, its complex synthesis and limitations in transportation and clinical use hinder widespread adoption. During PET imaging, the sinogram represents a form of raw data acquired by the scanner. Therefore, modeling in projection domain enables more direct utilization of the original information, potentially reducing the accumulation of errors introduced during the image reconstruction process. Inspired by these factors, this study proposes a prior-guided joint diffusion model (PJDM) for transforming 18F-FDG PET images into 18F-DOPA PET images in projection domain. Specifically, a coarse estimation model and a prior refinement model are trained independently. During inference, an initial synthetic 18F-DOPA PET sinogram is generated using a higher-order hybrid sampler. This sinogram is then degraded and serves as an additional condition to guide the iterative refinement process using learned prior. Experimental results demonstrated that PJDM effectively improved both sinogram quality and synthetic outcomes. The code is available at: https://github.com/yqx7150/PJDM.",
    "authors": [
      "Chen, Fang",
      "Zhang, Weifeng",
      "Ai, Xingyu",
      "Li, BingXuan",
      "Li, An",
      "Liu, Qiegen"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16733",
      "View PDF": "https://arxiv.org/pdf/2506.16733"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 04:05:34 UTC (5,639 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16969",
    "abstract": "Whispered speech recognition presents significant challenges for conventional automatic speech recognition systems, particularly when combined with dialect variation. However, utilizing an efficient method to solve this problem using a low-range dataset and processing load is beneficial. This paper proposes a solution using a Mamba-based state-space model and four fine-tuned self-supervised models consisting of Wav2Vec2, WavLM, HuBERT, and Whisper to address the dual challenges of whispered speech and dialect diversity. Based on our knowledge, this represents the best performance reported on the wTIMIT and CHAINS datasets for whispered speech recognition. We trained the models using whispered and normal speech data across Singaporean, US, and Irish dialects. The findings demonstrated that utilizing the proposed Mamba-based model could work as a highly efficient model trained with low amounts of whispered data to simultaneously work on whispered and normal speech recognition. The code for this work is freely available.",
    "authors": [
      "Farhadipour, Aref",
      "Beigi, Homayoon",
      "Dellwo, Volker",
      "Veisi, Hadi"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16969v1",
      "Other Formats": "https://arxiv.org/format/2506.16969",
      "TeX Source": "https://arxiv.org/src/2506.16969",
      "View PDF": "https://arxiv.org/pdf/2506.16969"
    },
    "subjects": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 12:59:35 UTC (424 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "State-Space Models in Efficient Whispered and Multi-dialect Speech Recognition",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12322",
    "abstract": "Data is crucial for machine learning (ML) applications, yet acquiring large datasets can be costly and time-consuming, especially in complex, resource-intensive fields like biopharmaceuticals. A key process in this industry is upstream bioprocessing, where living cells are cultivated and optimised to produce therapeutic proteins and biologics. The intricate nature of these processes, combined with high resource demands, often limits data collection, resulting in smaller datasets. This comprehensive review explores ML methods designed to address the challenges posed by small data and classifies them into a taxonomy to guide practical applications. Furthermore, each method in the taxonomy was thoroughly analysed, with a detailed discussion of its core concepts and an evaluation of its effectiveness in tackling small data challenges, as demonstrated by application results in the upstream bioprocessing and other related domains. By analysing how these methods tackle small data challenges from different perspectives, this review provides actionable insights, identifies current research gaps, and offers guidance for leveraging ML in data-constrained environments.",
    "authors": [
      "Peng, Johnny",
      "Khuat, Thanh Tung",
      "Musial, Katarzyna",
      "Gabrys, Bogdan"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12322v2",
      "Other Formats": "https://arxiv.org/format/2506.12322",
      "TeX Source": "https://arxiv.org/src/2506.12322",
      "View PDF": "https://arxiv.org/pdf/2506.12322"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 14 Jun 2025 03:13:05 UTC (951 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 12:36:26 UTC (951 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/14",
    "title": "Machine Learning Methods for Small Data and Upstream Bioprocessing Applications: A Comprehensive Review",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16824",
    "abstract": "Due to an exponential increase in published research articles, it is impossible for individual scientists to read all publications, even within their own research field. In this work, we investigate the use of large language models (LLMs) for the purpose of extracting the main concepts and semantic information from scientific abstracts in the domain of materials science to find links that were not noticed by humans and thus to suggest inspiring near/mid-term future research directions. We show that LLMs can extract concepts more efficiently than automated keyword extraction methods to build a concept graph as an abstraction of the scientific literature. A machine learning model is trained to predict emerging combinations of concepts, i.e. new research ideas, based on historical data. We demonstrate that integrating semantic concept information leads to an increased prediction performance. The applicability of our model is demonstrated in qualitative interviews with domain experts based on individualized model suggestions. We show that the model can inspire materials scientists in their creative thinking process by predicting innovative combinations of topics that have not yet been investigated.",
    "authors": [
      "Marwitz, Thomas",
      "Colsmann, Alexander",
      "Breitung, Ben",
      "Brabec, Christoph",
      "Kirchlechner, Christoph",
      "Blasco, Eva",
      "Marques, Gabriel Cadilha",
      "Hahn, Horst",
      "Hirtz, Michael",
      "Levkin, Pavel A.",
      "Eggeler, Yolita M.",
      "Schl\u00f6der, Tobias",
      "Friederich, Pascal"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16824v1",
      "Other Formats": "https://arxiv.org/format/2506.16824",
      "TeX Source": "https://arxiv.org/src/2506.16824",
      "View PDF": "https://arxiv.org/pdf/2506.16824"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 08:26:12 UTC (2,917 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.09399",
    "abstract": "Out-of-Distribution (OOD) detection is essential for the trustworthiness of AI systems. Methods using prior information (i.e., subspace-based methods) have shown effective performance by extracting information geometry to detect OOD data with a more appropriate distance metric. However, these methods fail to address the geometry distorted by ill-distributed samples, due to the limitation of statically extracting information geometry from the training distribution. In this paper, we argue that the influence of ill-distributed samples can be corrected by dynamically adjusting the prior geometry in response to new data. Based on this insight, we propose a novel approach that dynamically updates the prior covariance matrix using real-time input features, refining its information. Specifically, we reduce the covariance along the direction of real-time input features and constrain adjustments to the residual space, thus preserving essential data characteristics and avoiding effects on unintended directions in the principal space. We evaluate our method on two pre-trained models for the CIFAR dataset and five pre-trained models for ImageNet-1k, including the self-supervised DINO model. Extensive experiments demonstrate that our approach significantly enhances OOD detection across various models. The code is released at https://github.com/workerbcd/ooddcc.",
    "authors": [
      "Guo, Kaiyu",
      "Wang, Zijian",
      "Pan, Tan",
      "Lovell, Brian C.",
      "Baktashmotlagh, Mahsa"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.09399v2",
      "Other Formats": "https://arxiv.org/format/2506.09399",
      "TeX Source": "https://arxiv.org/src/2506.09399",
      "View PDF": "https://arxiv.org/pdf/2506.09399"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 11 Jun 2025 05:05:26 UTC (616 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 02:49:50 UTC (616 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/11",
    "title": "Improving Out-of-Distribution Detection via Dynamic Covariance Calibration",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2403.02566",
    "abstract": "3D medical image segmentation is a challenging task with crucial implications for disease diagnosis and treatment planning. Recent advances in deep learning have significantly enhanced fully supervised medical image segmentation. However, this approach heavily relies on labor-intensive and time-consuming fully annotated ground-truth labels, particularly for 3D volumes. To overcome this limitation, we propose a novel probabilistic-aware weakly supervised learning pipeline, specifically designed for 3D medical imaging. Our pipeline integrates three innovative components: a Probability-based Pseudo Label Generation technique for synthesizing dense segmentation masks from sparse annotations, a Probabilistic Multi-head Self-Attention network for robust feature extraction within our Probabilistic Transformer Network, and a Probability-informed Segmentation Loss Function to enhance training with annotation confidence. Demonstrating significant advances, our approach not only rivals the performance of fully supervised methods but also surpasses existing weakly supervised methods in CT and MRI datasets, achieving up to 18.1% improvement in Dice scores for certain organs. The code is available at https://github.com/runminjiang/PW4MedSeg.",
    "authors": [
      "Jiang, Runmin",
      "Fan, Zhaoxin",
      "Wu, Junhao",
      "Zhu, Lenghan",
      "Huang, Xin",
      "Wang, Tianyang",
      "Huang, Heng",
      "Xu, Min"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2403.02566v2",
      "Other Formats": "https://arxiv.org/format/2403.02566",
      "TeX Source": "https://arxiv.org/src/2403.02566",
      "View PDF": "https://arxiv.org/pdf/2403.02566"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 5 Mar 2024 00:46:53 UTC (1,895 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 01:20:02 UTC (2,338 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/03/05",
    "title": "Enhancing Weakly Supervised 3D Medical Image Segmentation through Probabilistic-aware Learning",
    "repo_urls": [
      "https://github.com/runminjiang/pw4medseg"
    ],
    "tasks": [
      "Image Segmentation",
      "Medical Image Segmentation",
      "Pseudo Label",
      "Segmentation",
      "Semantic Segmentation",
      "Weakly-supervised Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17165",
    "abstract": "Generative Adversarial Networks (GAN) have shown potential in expanding limited medical imaging datasets. This study explores how different ratios of GAN-generated and real brain tumor MRI images impact the performance of a CNN in classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic images which were mixed with real ones at various ratios to train a custom CNN. The CNN was then evaluated on a separate real-world test set. Our results indicate that the model maintains high sensitivity and precision in tumor classification, even when trained predominantly on synthetic data. When only a small portion of GAN data was added, such as 900 real images and 100 GAN images, the model achieved excellent performance, with test accuracy reaching 95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the proportion of GAN images increased further, performance gradually declined. This study suggests that while GANs are useful for augmenting limited datasets especially when real data is scarce, too much synthetic data can introduce artifacts that affect the model's ability to generalize to real world cases.",
    "authors": [
      "Afif, Mahin Montasir",
      "Noman, Abdullah Al",
      "Kabir, K. M. Tahsin",
      "Ahmmed, Md. Mortuza",
      "Rahman, Md. Mostafizur",
      "Mahmud, Mufti",
      "Babu, Md. Ashraful"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17165v1",
      "Other Formats": "https://arxiv.org/format/2506.17165",
      "TeX Source": "https://arxiv.org/src/2506.17165",
      "View PDF": "https://arxiv.org/pdf/2506.17165"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:12:03 UTC (16,652 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2403.01306",
    "abstract": "Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly abstract or subjective text. These approaches lack the fine-grained ability to isolate the most concrete samples that provide the strongest signal for learning in a noisy dataset. In this work, we propose a new metric, image caption concreteness, that evaluates caption text without an image reference to measure its concreteness and relevancy for use in multimodal learning. Our approach leverages strong foundation models for measuring visual-semantic information loss in multimodal representations. We demonstrate that this strongly correlates with human evaluation of concreteness in both single-word and sentence-level texts. Moreover, we show that curation using ICC complements existing approaches: It succeeds in selecting the highest quality samples from multimodal web-scale datasets to allow for efficient training in resource-constrained settings.",
    "authors": [
      "Yanuka, Moran",
      "Alper, Morris",
      "Averbuch-Elor, Hadar",
      "Giryes, Raja"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2403.01306v4",
      "Other Formats": "https://arxiv.org/format/2403.01306",
      "TeX Source": "https://arxiv.org/src/2403.01306",
      "View PDF": "https://arxiv.org/pdf/2403.01306"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 2 Mar 2024 20:36:10 UTC (55,404 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Tue, 4 Jun 2024 11:08:42 UTC (46,386 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Tue, 11 Jun 2024 07:18:44 UTC (46,385 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Fri, 20 Jun 2025 09:17:43 UTC (46,386 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2024/03/02",
    "title": "ICC: Quantifying Image Caption Concreteness for Multimodal Dataset Curation",
    "repo_urls": [
      "https://github.com/moranyanuka/icc_code"
    ],
    "tasks": [
      "Sentence"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17114",
    "abstract": "Large reasoning models (e.g., R1, o3) have demonstrated remarkable mathematical problem-solving abilities. However, the high reported accuracy of these advanced models on popular datasets, reliance on purely numerical evaluation and potential benchmark leakage, often masks their true reasoning shortcomings. To address this, we propose leveraging the inherent rigor and methodological complexity of mathematical proofs as a diagnostic tool to expose these hidden failures. Specifically, we introduce the RFMDataset (Reveal Failure Modes), a collection of 200 diverse mathematical proof problems, and thoroughly evaluate advanced models' performance on it. Our in-depth analysis of their failures uncovers 10 fine-grained error types, which shows fundamental limitations in current large reasoning models: 1) large reasoning models grapple profoundly with mathematical proofs, with some generating entirely correct proofs for less than 20% of problems and failing even on basic ones; 2) models exhibit a diverse spectrum of reasoning failures, prominently demonstrating the lack of guarantees for the correctness and rigor of single-step reasoning; and 3) models show hallucination and incompleteness during the reasoning process. Our findings reveal that models' self-reflection is insufficient to resolve the current logical dilemmas, necessitating formalized and fine-grained logical training.",
    "authors": [
      "Guo, Dadi",
      "Liu, Jiayu",
      "Fan, Zhiyuan",
      "He, Zhitao",
      "Li, Haoran",
      "Wang, Yumeng",
      "R., Yi",
      "Fung"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17114v1",
      "Other Formats": "https://arxiv.org/format/2506.17114",
      "TeX Source": "https://arxiv.org/src/2506.17114",
      "View PDF": "https://arxiv.org/pdf/2506.17114"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:14:18 UTC (1,619 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2410.11215",
    "abstract": "Large-scale datasets have been pivotal to the advancements of deep learning models in recent years, but training on such large datasets invariably incurs substantial storage and computational overhead. Meanwhile, real-world datasets often contain redundant and noisy data, imposing a negative impact on training efficiency and model performance. Data selection has shown promise in identifying the most representative samples from the entire dataset, which aims to minimize the performance gap with reduced training costs. Existing works typically rely on single-modality information to assign importance scores for individual samples, which may lead to inaccurate assessments, especially when dealing with noisy or corrupted samples. To address this limitation, we propose a novel CLIP-powered data selection framework that leverages multimodal information for more robust and generalizable sample selection. Specifically, our framework consists of three key modules-dataset adaptation, sample scoring, and selection optimization-that together harness extensive pre-trained multimodal knowledge to comprehensively assess sample influence and optimize the selection results through multi-objective optimization. Extensive experiments demonstrate that our approach consistently outperforms existing state-of-the-art baselines on various benchmark datasets. Notably, our method effectively removes noisy or damaged samples from the dataset, enabling it to achieve even higher performance with less data. This indicates that it is not only a way to accelerate training but can also improve overall data quality.",
    "authors": [
      "Yang, Suorong",
      "Ye, Peng",
      "Ouyang, Wanli",
      "Zhou, Dongzhan",
      "Shen, Furao"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2410.11215v2",
      "Other Formats": "https://arxiv.org/format/2410.11215",
      "TeX Source": "https://arxiv.org/src/2410.11215",
      "View PDF": "https://arxiv.org/pdf/2410.11215"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 15 Oct 2024 03:00:58 UTC (3,850 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 04:41:06 UTC (2,022 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/10/15",
    "title": "A CLIP-Powered Framework for Robust and Generalizable Data Selection",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2412.01696",
    "abstract": "Efficient estimation of nonlinear functions of quantum states is crucial for various key tasks in quantum computing, such as entanglement spectroscopy, fidelity estimation, and feature analysis of quantum data. Conventional methods using state tomography and estimating numerous terms of the series expansion are computationally expensive, while alternative approaches based on a purified query oracle impose practical constraints. In this paper, we introduce the quantum state function (QSF) framework by extending the SWAP test via linear combination of unitaries and parameterized quantum circuits. Our framework enables the implementation of arbitrarily normalized degree-$n$ polynomial functions of quantum states with precision $\\varepsilon$ using $\\mathcal{O}(n/\\varepsilon^2)$ copies. We further apply QSF for developing quantum algorithms for fundamental tasks, including entropy, fidelity, and eigenvalue estimations. Specifically, for estimating von Neumann entropy, quantum relative entropy, and quantum state fidelity, where $\\kappa$ and $\\gamma$ represent the minimal nonzero eigenvalue and normalized factor, respectively, we achieve a sample complexity of $\\tilde{\\mathcal{O}}(\\gamma^2/(\\varepsilon^2\\kappa))$. Our work establishes a concise and unified paradigm for estimating and realizing nonlinear functions of quantum states, paving the way for the practical processing and analysis of quantum data.",
    "authors": [
      "Yao, Hongshun",
      "Liu, Yingjian",
      "Lin, Tengxiang",
      "Wang, Xin"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2412.01696v3",
      "Other Formats": "https://arxiv.org/format/2412.01696",
      "TeX Source": "https://arxiv.org/src/2412.01696",
      "View PDF": "https://arxiv.org/pdf/2412.01696"
    },
    "subjects": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 2 Dec 2024 16:40:17 UTC (972 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Tue, 14 Jan 2025 22:35:25 UTC (972 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 14:44:16 UTC (386 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/12/02",
    "title": "Sample-Efficient Estimation of Nonlinear Quantum State Functions",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.02819",
    "abstract": "We introduce ReplaceMe, a generalized training-free depth pruning method that effectively replaces transformer blocks with a linear operation, while maintaining high performance for low compression ratios. In contrast to conventional pruning approaches that require additional training or fine-tuning, our approach requires only a small calibration dataset that is used to estimate a linear transformation, which approximates the pruned blocks. The estimated linear mapping can be seamlessly merged with the remaining transformer blocks, eliminating the need for any additional network parameters. Our experiments show that ReplaceMe consistently outperforms other training-free approaches and remains highly competitive with state-of-the-art pruning methods that involve extensive retraining/fine-tuning and architectural modifications. Applied to several large language models (LLMs), ReplaceMe achieves up to 25% pruning while retaining approximately 90% of the original model's performance on open benchmarks - without any training or healing steps, resulting in minimal computational overhead (see Fig.1). We provide an open-source library implementing ReplaceMe alongside several state-of-the-art depth pruning techniques, available at https://github.com/mts-ai/ReplaceMe.",
    "authors": [
      "Shopkhoev, Dmitriy",
      "Ali, Ammar",
      "Zhussip, Magauiya",
      "Malykh, Valentin",
      "Lefkimmiatis, Stamatios",
      "Komodakis, Nikos",
      "Zagoruyko, Sergey"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.02819v3",
      "Other Formats": "https://arxiv.org/format/2505.02819",
      "TeX Source": "https://arxiv.org/src/2505.02819",
      "View PDF": "https://arxiv.org/pdf/2505.02819"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 5 May 2025 17:47:42 UTC (117 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 8 May 2025 19:52:34 UTC (117 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 14:27:20 UTC (138 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/05/05",
    "title": "ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization",
    "repo_urls": [
      "https://github.com/mts-ai/replaceme"
    ],
    "tasks": [
      "Network Pruning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.11618",
    "abstract": "Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating critical gaps in our knowledge of model alignment. In this work, we train and study a minimal model organism which uses just 9 rank-1 adapters to emergently misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently misaligned models converge to similar representations of misalignment. We demonstrate this convergence by extracting a 'misalignment direction' from one fine-tuned model's activations, and using it to effectively ablate misaligned behaviour from fine-tunes using higher dimensional LoRAs and different datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further present a set of experiments for directly interpreting the fine-tuning adapters, showing that six contribute to general misalignment, while two specialise for misalignment in just the fine-tuning domain. Emergent misalignment is a particularly salient example of undesirable and unexpected model behaviour and by advancing our understanding of the mechanisms behind it, we hope to move towards being able to better understand and mitigate misalignment more generally.",
    "authors": [
      "Soligo, Anna",
      "Turner, Edward",
      "Rajamanoharan, Senthooran",
      "Nanda, Neel"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.11618v2",
      "Other Formats": "https://arxiv.org/format/2506.11618",
      "TeX Source": "https://arxiv.org/src/2506.11618",
      "View PDF": "https://arxiv.org/pdf/2506.11618"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 13 Jun 2025 09:39:54 UTC (5,542 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 17:23:55 UTC (5,685 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/13",
    "title": "Convergent Linear Representations of Emergent Misalignment",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17185",
    "abstract": "We investigate the contents of web-scraped data for training AI systems, at sizes where human dataset curators and compilers no longer manually annotate every sample. Building off of prior privacy concerns in machine learning models, we ask: What are the legal privacy implications of web-scraped machine learning datasets? In an empirical study of a popular training dataset, we find significant presence of personally identifiable information despite sanitization efforts. Our audit provides concrete evidence to support the concern that any large-scale web-scraped dataset may contain personal data. We use these findings of a real-world dataset to inform our legal analysis with respect to existing privacy and data protection laws. We surface various privacy risks of current data curation practices that may propagate personal information to downstream models. From our findings, we argue for reorientation of current frameworks of \"publicly available\" information to meaningfully limit the development of AI built upon indiscriminate scraping of the internet.",
    "authors": [
      "Hong, Rachel",
      "Hutson, Jevan",
      "Agnew, William",
      "Huda, Imaad",
      "Kohno, Tadayoshi",
      "Morgenstern, Jamie"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17185v1",
      "Other Formats": "https://arxiv.org/format/2506.17185",
      "TeX Source": "https://arxiv.org/src/2506.17185",
      "View PDF": "https://arxiv.org/pdf/2506.17185"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:40:05 UTC (6,460 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "A Common Pool of Privacy Problems: Legal and Technical Lessons from a Large-Scale Web-Scraped Machine Learning Dataset",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17198",
    "abstract": "Generating large-scale demonstrations for dexterous hand manipulation remains challenging, and several approaches have been proposed in recent years to address this. Among them, generative models have emerged as a promising paradigm, enabling the efficient creation of diverse and physically plausible demonstrations. In this paper, we introduce Dex1B, a large-scale, diverse, and high-quality demonstration dataset produced with generative models. The dataset contains one billion demonstrations for two fundamental tasks: grasping and articulation. To construct it, we propose a generative model that integrates geometric constraints to improve feasibility and applies additional conditions to enhance diversity. We validate the model on both established and newly introduced simulation benchmarks, where it significantly outperforms prior state-of-the-art methods. Furthermore, we demonstrate its effectiveness and robustness through real-world robot experiments. Our project page is at https://jianglongye.com/dex1b",
    "authors": [
      "Ye, Jianglong",
      "Wang, Keyi",
      "Yuan, Chengjing",
      "Yang, Ruihan",
      "Li, Yiquan",
      "Zhu, Jiyue",
      "Qin, Yuzhe",
      "Zou, Xueyan",
      "Wang, Xiaolong"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17198v1",
      "Other Formats": "https://arxiv.org/format/2506.17198",
      "TeX Source": "https://arxiv.org/src/2506.17198",
      "View PDF": "https://arxiv.org/pdf/2506.17198"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:49:04 UTC (22,349 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16701",
    "abstract": "Recent video action recognition methods have shown excellent performance by adapting large-scale pre-trained language-image models to the video domain. However, language models contain rich common sense priors - the scene contexts that humans use to constitute an understanding of objects, human-object interactions, and activities - that have not been fully exploited. In this paper, we introduce a framework incorporating language-driven common sense priors to identify cluttered video action sequences from monocular views that are often heavily occluded. We propose: (1) A video context summary component that generates candidate objects, activities, and the interactions between objects and activities; (2) A description generation module that describes the current scene given the context and infers subsequent activities, through auxiliary prompts and common sense reasoning; (3) A multi-modal activity recognition head that combines visual and textual cues to recognize video actions. We demonstrate the effectiveness of our approach on the challenging Action Genome and Charades datasets.",
    "authors": [
      "Hu, Xiaodan",
      "Zou, Chuhang",
      "Wang, Suchen",
      "Kim, Jaechul",
      "Ahuja, Narendra"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16701v1",
      "Other Formats": "https://arxiv.org/format/2506.16701",
      "TeX Source": "https://arxiv.org/src/2506.16701",
      "View PDF": "https://arxiv.org/pdf/2506.16701"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 02:43:53 UTC (3,040 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17171",
    "abstract": "This paper introduces a unified theoretical perspective that views deep generative models as probability transformation functions. Despite the apparent differences in architecture and training methodologies among various types of generative models - autoencoders, autoregressive models, generative adversarial networks, normalizing flows, diffusion models, and flow matching - we demonstrate that they all fundamentally operate by transforming simple predefined distributions into complex target data distributions. This unifying perspective facilitates the transfer of methodological improvements between model architectures and provides a foundation for developing universal theoretical approaches, potentially leading to more efficient and effective generative modeling techniques.",
    "authors": [
      "Bondar, Vitalii",
      "Babenko, Vira",
      "Trembovetskyi, Roman",
      "Korobeinyk, Yurii",
      "Dzyuba, Viktoriya"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17171v1",
      "Other Formats": "https://arxiv.org/format/2506.17171",
      "TeX Source": "https://arxiv.org/src/2506.17171",
      "View PDF": "https://arxiv.org/pdf/2506.17171"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:22:23 UTC (479 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Deep generative models as the probability transformation functions",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16895",
    "abstract": "Multimodal models have demonstrated powerful capabilities in complex tasks requiring multimodal alignment including zero-shot classification and cross-modal retrieval. However, existing models typically rely on millions of paired multimodal samples, which are prohibitively expensive or infeasible to obtain in many domains. In this work, we explore the feasibility of building multimodal models with limited amount of paired data by aligning pretrained unimodal foundation models. We show that high-quality alignment is possible with as few as tens of thousands of paired samples$\\unicode{x2013}$less than $1\\%$ of the data typically used in the field. To achieve this, we introduce STRUCTURE, an effective regularization technique that preserves the neighborhood geometry of the latent space of unimodal encoders. Additionally, we show that aligning last layers is often suboptimal and demonstrate the benefits of aligning the layers with the highest representational similarity across modalities. These two components can be readily incorporated into existing alignment methods, yielding substantial gains across 24 zero-shot image classification and retrieval benchmarks, with average relative improvement of $51.6\\%$ in classification and $91.8\\%$ in retrieval tasks. Our results highlight the effectiveness and broad applicability of our framework for limited-sample multimodal learning and offer a promising path forward for resource-constrained domains.",
    "authors": [
      "Gr\u00f6ger, Fabian",
      "Wen, Shuo",
      "Le, Huyen",
      "Brbi\u0107, Maria"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16895v1",
      "Other Formats": "https://arxiv.org/format/2506.16895",
      "TeX Source": "https://arxiv.org/src/2506.16895",
      "View PDF": "https://arxiv.org/pdf/2506.16895"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 10:32:54 UTC (1,236 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.11480",
    "abstract": "Reinforcement learning (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its data inefficiency remains a major bottleneck. To address this critical yet challenging issue, we present a novel gradient-alignment-based method, named LearnAlign, which intelligently selects the learnable and representative training reasoning data for RL post-training. To overcome the issue of response-length bias in gradient norms, we introduce the data learnability based on the success rate, which can indicate the learning potential of each data point. Experiments across three mathematical reasoning benchmarks demonstrate that our method significantly reduces training data requirements while achieving minor performance degradation or even improving performance compared to full-data training. For example, it reduces data requirements by up to 1,000 data points with better performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show its effectiveness in the staged RL setting. This work provides valuable insights into data-efficient RL post-training and establishes a foundation for future research in optimizing reasoning data selection. To facilitate future work, we will release code.",
    "authors": [
      "Li, Shikun",
      "Li, Shipeng",
      "Yang, Zhiqin",
      "Zhang, Xinghua",
      "Chen, Gaode",
      "Xia, Xiaobo",
      "Liu, Hengyu",
      "Peng, Zhe"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.11480",
      "TeX Source": "https://arxiv.org/src/2506.11480",
      "View PDF": "https://arxiv.org/pdf/2506.11480"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 13 Jun 2025 06:05:58 UTC (666 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 10:31:36 UTC (666 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/13",
    "title": "LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment",
    "tasks": [
      "GSM8K",
      "Mathematical Reasoning",
      "Reinforcement Learning (RL)"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16696",
    "abstract": "Understanding football tactics is crucial for managers and analysts. Previous research has proposed models based on spatial and kinematic equations, but these are computationally expensive. Also, Reinforcement learning approaches use player positions and velocities but lack interpretability and require large datasets. Rule-based models align with expert knowledge but have not fully considered all players' states. This study explores whether low-dimensional, rule-based models using spatiotemporal data can effectively capture football tactics. Our approach defines interpretable state variables for both the ball-holder and potential pass receivers, based on criteria that explore options like passing. Through discussions with a manager, we identified key variables representing the game state. We then used StatsBomb event data and SkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost model to predict pass success. The analysis revealed that the distance between the player and the ball, as well as the player's space score, were key factors in determining successful passes. Our interpretable low-dimensional modeling facilitates tactical analysis through the use of intuitive variables and provides practical value as a tool to support decision-making in football.",
    "authors": [
      "Ide, Kenjiro",
      "Someya, Taiga",
      "Kawaguchi, Kohei",
      "Fujii, Keisuke"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16696v1",
      "Other Formats": "https://arxiv.org/format/2506.16696",
      "TeX Source": "https://arxiv.org/src/2506.16696",
      "View PDF": "https://arxiv.org/pdf/2506.16696"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 02:37:52 UTC (242 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16746",
    "abstract": "Stock selection, which aims to predict stock prices and identify the most profitable ones, is a crucial task in finance. While existing methods primarily focus on developing model structures and building graphs for improved selection, pre-training strategies remain underexplored in this domain. Current stock series pre-training follows methods from other areas without adapting to the unique characteristics of financial data, particularly overlooking stock-specific contextual information and the non-stationary nature of stock prices. Consequently, the latent statistical features inherent in stock data are underutilized. In this paper, we propose three novel pre-training tasks tailored to stock data characteristics: stock code classification, stock sector classification, and moving average prediction. We develop the Stock Specialized Pre-trained Transformer (SSPT) based on a two-layer transformer architecture. Extensive experimental results validate the effectiveness of our pre-training methods and provide detailed guidance on their application. Evaluations on five stock datasets, including four markets and two time periods, demonstrate that SSPT consistently outperforms the market and existing methods in terms of both cumulative investment return ratio and Sharpe ratio. Additionally, our experiments on simulated data investigate the underlying mechanisms of our methods, providing insights into understanding price series. Our code is publicly available at: https://github.com/astudentuser/Pre-training-Time-Series-Models-with-Stock-Data-Customization.",
    "authors": [
      "Wang, Mengyu",
      "Ma, Tiejun",
      "Cohen, Shay B."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16746v1",
      "Other Formats": "https://arxiv.org/format/2506.16746",
      "TeX Source": "https://arxiv.org/src/2506.16746",
      "View PDF": "https://arxiv.org/pdf/2506.16746"
    },
    "subjects": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 04:40:01 UTC (390 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Pre-training Time Series Models with Stock Data Customization",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16802",
    "abstract": "Synthetic video generation is progressing very rapidly. The latest models can produce very realistic high-resolution videos that are virtually indistinguishable from real ones. Although several video forensic detectors have been recently proposed, they often exhibit poor generalization, which limits their applicability in a real-world scenario. Our key insight to overcome this issue is to guide the detector towards seeing what really matters. In fact, a well-designed forensic classifier should focus on identifying intrinsic low-level artifacts introduced by a generative architecture rather than relying on high-level semantic flaws that characterize a specific model. In this work, first, we study different generative architectures, searching and identifying discriminative features that are unbiased, robust to impairments, and shared across models. Then, we introduce a novel forensic-oriented data augmentation strategy based on the wavelet decomposition and replace specific frequency-related bands to drive the model to exploit more relevant forensic cues. Our novel training paradigm improves the generalizability of AI-generated video detectors, without the need for complex algorithms and large datasets that include multiple synthetic generators. To evaluate our approach, we train the detector using data from a single generative model and test it against videos produced by a wide range of other models. Despite its simplicity, our method achieves a significant accuracy improvement over state-of-the-art detectors and obtains excellent results even on very recent generative models, such as NOVA and FLUX. Code and data will be made publicly available.",
    "authors": [
      "Corvi, Riccardo",
      "Cozzolino, Davide",
      "Prashnani, Ekta",
      "De Mello, Shalini",
      "Nagano, Koki",
      "Verdoliva, Luisa"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16802",
      "TeX Source": "https://arxiv.org/src/2506.16802",
      "View PDF": "https://arxiv.org/pdf/2506.16802"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 07:36:59 UTC (15,606 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17012",
    "abstract": "As data-driven technologies advance swiftly, maintaining strong privacy measures becomes progressively difficult. Conventional $(\\epsilon, \\delta)$-differential privacy, while prevalent, exhibits limited adaptability for many applications. To mitigate these constraints, we present alpha differential privacy (ADP), an innovative privacy framework grounded in alpha divergence, which provides a more flexible assessment of privacy consumption. This study delineates the theoretical underpinnings of ADP and contrasts its performance with competing privacy frameworks across many scenarios. Empirical assessments demonstrate that ADP offers enhanced privacy guarantees in small to moderate iteration contexts, particularly where severe privacy requirements are necessary. The suggested method markedly improves privacy-preserving methods, providing a flexible solution for contemporary data analysis issues in a data-centric environment.",
    "authors": [
      "Liu, Yifeng",
      "Wang, Zehua"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17012v1",
      "Other Formats": "https://arxiv.org/format/2506.17012",
      "TeX Source": "https://arxiv.org/src/2506.17012",
      "View PDF": "https://arxiv.org/pdf/2506.17012"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 14:10:18 UTC (331 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "A Novel Approach to Differential Privacy with Alpha Divergence",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.16637",
    "abstract": "Large language models (LLMs) have recently demonstrated remarkable capabilities in machine translation (MT). However, most advanced MT-specific LLMs heavily rely on external supervision signals during training, such as human-annotated reference data or trained reward models (RMs), which are often expensive to obtain and challenging to scale. To overcome this limitation, we propose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for MT that is reference-free, fully online, and relies solely on self-judging rewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as the backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs, e.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like Qwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks from WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR with external supervision from COMET, our strongest model, SSR-X-Zero-7B, achieves state-of-the-art performance in English $\\leftrightarrow$ Chinese translation, surpassing all existing open-source models under 72B parameters and even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro. Our analysis highlights the effectiveness of the self-rewarding mechanism compared to the external LLM-as-a-judge approach in MT and demonstrates its complementary benefits when combined with trained RMs. Our findings provide valuable insight into the potential of self-improving RL methods. We have publicly released our code, data and models.",
    "authors": [
      "Yang, Wenjie",
      "Zheng, Mao",
      "Song, Mingyang",
      "Li, Zheng",
      "Wang, Sitong"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2505.16637",
      "TeX Source": "https://arxiv.org/src/2505.16637",
      "View PDF": "https://arxiv.org/pdf/2505.16637"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 22 May 2025 13:08:25 UTC (9,790 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 23 May 2025 04:23:14 UTC (9,790 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 06:38:44 UTC (9,790 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/05/22",
    "title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation",
    "repo_urls": [
      "https://github.com/kelaxon/ssr-zero"
    ],
    "tasks": [
      "Machine Translation",
      "Reinforcement Learning (RL)",
      "Translation"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2412.11224",
    "abstract": "Manipulating the illumination of a 3D scene within a single image represents a fundamental challenge in computer vision and graphics. This problem has traditionally been addressed using inverse rendering techniques, which involve explicit 3D asset reconstruction and costly ray-tracing simulations. Meanwhile, recent advancements in visual foundation models suggest that a new paradigm could soon be possible -- one that replaces explicit physical models with networks that are trained on large amounts of image and video data. In this paper, we exploit the physical world understanding of a video diffusion model, particularly Stable Video Diffusion, to relight a single image. We introduce GenLit, a framework that distills the ability of a graphics engine to perform light manipulation into a video-generation model, enabling users to directly insert and manipulate a point light in the 3D world within a given image, and generate results directly as a video sequence. We find that a model fine-tuned on only a small synthetic dataset generalizes to real-world scenes, enabling single-image relighting with plausible and convincing shadows. Our results highlight the ability of video foundation models to capture rich information about lighting, material, and, shape and our findings indicate that such models, with minimal training, can be used to perform relighting without explicit asset reconstruction or complex ray tracing. Project page: https://genlit.is.tue.mpg.de/.",
    "authors": [
      "Bharadwaj, Shrisha",
      "Feng, Haiwen",
      "Becherini, Giorgio",
      "Abrevaya, Victoria Fernandez",
      "Black, Michael J."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2412.11224v3",
      "Other Formats": "https://arxiv.org/format/2412.11224",
      "TeX Source": "https://arxiv.org/src/2412.11224",
      "View PDF": "https://arxiv.org/pdf/2412.11224"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 15 Dec 2024 15:40:40 UTC (42,230 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 5 Jun 2025 12:36:04 UTC (49,108 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 10:10:55 UTC (49,108 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/12/15",
    "title": "GenLit: Reformulating Single-Image Relighting as Video Generation",
    "tasks": [
      "Image Generation",
      "Image Relighting",
      "Inverse Rendering",
      "Video Generation"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2407.03146",
    "abstract": "Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
    "authors": [
      "Jiang, Yunpeng",
      "Ban, Yutong",
      "Weng, Paul"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2407.03146v4",
      "Other Formats": "https://arxiv.org/format/2407.03146",
      "TeX Source": "https://arxiv.org/src/2407.03146",
      "View PDF": "https://arxiv.org/pdf/2407.03146"
    },
    "subjects": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 31 May 2024 02:56:43 UTC (2,617 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 8 Jul 2024 05:21:59 UTC (2,618 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Tue, 25 Mar 2025 09:05:02 UTC (2,648 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Fri, 20 Jun 2025 02:36:15 UTC (3,859 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2024/05/31",
    "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach",
    "tasks": [
      "Data Augmentation",
      "Fairness",
      "Multi-class Classification"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.21523",
    "abstract": "Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more heavily on language priors. Attention analysis shows that longer reasoning chains lead to reduced focus on visual inputs, which contributes to hallucination. To systematically study this phenomenon, we introduce RH-AUC, a metric that quantifies how a model's perception accuracy changes with reasoning length, allowing us to evaluate whether the model preserves visual grounding during reasoning. We also release RH-Bench, a diagnostic benchmark that spans a variety of multimodal tasks, designed to assess the trade-off between reasoning ability and hallucination. Our analysis reveals that (i) larger models typically achieve a better balance between reasoning and perception, and (ii) this balance is influenced more by the types and domains of training data than by its overall volume. These findings underscore the importance of evaluation frameworks that jointly consider both reasoning quality and perceptual fidelity.",
    "authors": [
      "Liu, Chengzhi",
      "Xu, Zhongxing",
      "Wei, Qingyue",
      "Wu, Juncheng",
      "Zou, James",
      "Wang, Xin Eric",
      "Zhou, Yuyin",
      "Liu, Sheng"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.21523v3",
      "Other Formats": "https://arxiv.org/format/2505.21523",
      "TeX Source": "https://arxiv.org/src/2505.21523",
      "View PDF": "https://arxiv.org/pdf/2505.21523"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 23 May 2025 05:08:40 UTC (6,670 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sat, 31 May 2025 16:02:34 UTC (6,664 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 08:41:41 UTC (6,664 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/05/23",
    "title": "More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models",
    "tasks": [
      "Diagnostic",
      "Hallucination",
      "Math",
      "Multimodal Reasoning",
      "Visual Grounding"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.09507",
    "abstract": "The remarkable generalization performance of contrastive vision-language models like CLIP is often attributed to the diversity of their training distributions. However, key questions remain unanswered: Can CLIP generalize to an entirely unseen domain when trained on a diverse mixture of domains (domain generalization)? Can it generalize to unseen classes within partially seen domains (compositional generalization)? What factors affect such generalization? To answer these questions, we trained CLIP models on systematically constructed training distributions with controlled domain diversity and object class exposure. Our experiments show that domain diversity is essential for both domain and compositional generalization, yet compositional generalization can be surprisingly weaker than domain generalization when the training distribution contains a suboptimal subset of the test domain. Through data-centric and mechanistic analyses, we find that successful generalization requires the learning of sufficiently shared representations in intermediate layers and circuits.",
    "authors": [
      "Kempf, Elias",
      "Schrodi, Simon",
      "Argus, Max",
      "Brox, Thomas"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.09507v2",
      "Other Formats": "https://arxiv.org/format/2502.09507",
      "TeX Source": "https://arxiv.org/src/2502.09507",
      "View PDF": "https://arxiv.org/pdf/2502.09507"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 13 Feb 2025 17:21:37 UTC (7,318 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 08:12:35 UTC (8,652 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/13",
    "title": "When and How Does CLIP Enable Domain and Compositional Generalization?",
    "repo_urls": [
      "https://github.com/lmb-freiburg/understanding-clip-ood"
    ],
    "tasks": [
      "Diversity",
      "Domain Generalization"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.14709",
    "abstract": "In this paper, we introduce Group-MATES, an efficient group-level data selection approach to optimize the speed-quality frontier of language model pretraining. Specifically, Group-MATES parameterizes costly group-level selection with a relational data influence model. To train this model, we sample training trajectories of the language model and collect oracle data influences alongside. The relational data influence model approximates the oracle data influence by weighting individual influence with relationships among training data. To enable efficient selection with our relational data influence model, we partition the dataset into small clusters using relationship weights and select data within each cluster independently. Experiments on DCLM 400M-4x, 1B-1x, and 3B-1x show that Group-MATES achieves 3.5%-9.4% relative performance gains over random selection across 22 downstream tasks, nearly doubling the improvements achieved by state-of-the-art individual data selection baselines. Furthermore, Group-MATES reduces the number of tokens required to reach a certain downstream performance by up to 1.75x, substantially elevating the speed-quality frontier. Further analyses highlight the critical role of relationship weights in the relational data influence model and the effectiveness of our cluster-based inference. Our code is open-sourced at https://github.com/facebookresearch/Group-MATES.",
    "authors": [
      "Yu, Zichun",
      "Peng, Fei",
      "Lei, Jie",
      "Overwijk, Arnold",
      "Yih, Wen-tau",
      "Xiong, Chenyan"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.14709v2",
      "Other Formats": "https://arxiv.org/format/2502.14709",
      "TeX Source": "https://arxiv.org/src/2502.14709",
      "View PDF": "https://arxiv.org/pdf/2502.14709"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 20 Feb 2025 16:34:46 UTC (728 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 04:30:04 UTC (519 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/20",
    "title": "Group-Level Data Selection for Efficient Pretraining",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.07230",
    "abstract": "As a part of the integrated energy system (IES), gas pipeline networks can provide additional flexibility to power systems through coordinated optimal dispatch. An accurate pipeline network model is critical for the optimal operation and control of IESs. However, inaccuracies or unavailability of accurate pipeline parameters often introduce errors in the state-space models of such networks. This paper proposes a physics-informed recurrent network (PIRN) to identify the state-space model of gas pipelines. It fuses sparse measurement data with fluid-dynamic behavior expressed by partial differential equations. By embedding the physical state-space model within the recurrent network, parameter identification becomes an end-to-end PIRN training task. The model can be realized in PyTorch through modifications to a standard RNN backbone. Case studies demonstrate that our proposed PIRN can accurately estimate gas pipeline models from sparse terminal node measurements, providing robust performance and significantly higher parameter efficiency. Furthermore, the identified state-space model of the pipeline network can be seamlessly integrated into optimization frameworks.",
    "authors": [
      "Wang, Siyuan",
      "Wu, Wenchuan",
      "Lin, Chenhui",
      "Wang, Qi",
      "Xu, Shuwei",
      "Chen, Binbin"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.07230v2",
      "Other Formats": "https://arxiv.org/format/2502.07230",
      "TeX Source": "https://arxiv.org/src/2502.07230",
      "View PDF": "https://arxiv.org/pdf/2502.07230"
    },
    "subjects": [
      "Systems and Control (eess.SY)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 11 Feb 2025 03:46:03 UTC (1,600 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 03:36:06 UTC (1,676 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/11",
    "title": "Physics-Informed Recurrent Network for State-Space Modeling of Gas Pipeline Networks",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2406.12593",
    "abstract": "Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
    "authors": [
      "Huynh, Tuan-Luc",
      "Vu, Thuy-Trang",
      "Wang, Weiqing",
      "Wei, Yinwei",
      "Le, Trung",
      "Gasevic, Dragan",
      "Li, Yuan-Fang",
      "Do, Thanh-Toan"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2406.12593v3",
      "Other Formats": "https://arxiv.org/format/2406.12593",
      "TeX Source": "https://arxiv.org/src/2406.12593",
      "View PDF": "https://arxiv.org/pdf/2406.12593"
    },
    "subjects": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 18 Jun 2024 13:25:18 UTC (749 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 16 Oct 2024 13:45:54 UTC (664 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 12:59:40 UTC (458 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/06/18",
    "title": "PromptDSI: Prompt-based Rehearsal-free Instance-wise Incremental Learning for Document Retrieval",
    "tasks": [
      "Continual Learning",
      "Incremental Learning",
      "Retrieval"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16698",
    "abstract": "Sequence-based recommendations models are driving the state-of-the-art for industrial ad-recommendation systems. Such systems typically deal with user histories or sequence lengths ranging in the order of O(10^3) to O(10^4) events. While adding embeddings at this scale is manageable in pre-trained models, incorporating them into real-time prediction models is challenging due to both storage and inference costs. To address this scaling challenge, we propose a novel approach that leverages vector quantization (VQ) to inject a compact Semantic ID (SID) as input to the recommendation models instead of a collection of embeddings. Our method builds on recent works of SIDs by introducing three key innovations: (i) a multi-task VQ-VAE framework, called VQ fusion that fuses multiple content embeddings and categorical predictions into a single Semantic ID; (ii) a parameter-free, highly granular SID-to-embedding conversion technique, called SIDE, that is validated with two content embedding collections, thereby eliminating the need for a large parameterized lookup table; and (iii) a novel quantization method called Discrete-PCA (DPCA) which generalizes and enhances residual quantization techniques. The proposed enhancements when applied to a large-scale industrial ads-recommendation system achieves 2.4X improvement in normalized entropy (NE) gain and 3X reduction in data footprint compared to traditional SID methods.",
    "authors": [
      "Ramasamy, Dinesh",
      "Kumar, Shakti",
      "Cadonic, Chris",
      "Yang, Jiaxin",
      "Roychowdhury, Sohini",
      "Rhman, Esam Abdel",
      "Reddy, Srihari"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16698v1",
      "Other Formats": "https://arxiv.org/format/2506.16698",
      "TeX Source": "https://arxiv.org/src/2506.16698",
      "View PDF": "https://arxiv.org/pdf/2506.16698"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 02:40:38 UTC (2,435 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "SIDE: Semantic ID Embedding for effective learning from sequences",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16846",
    "abstract": "Decision trees are popular in survival analysis for their interpretability and ability to model complex relationships. Survival trees, which predict the timing of singular events using censored historical data, are typically built through heuristic approaches. Recently, there has been growing interest in globally optimized trees, where the overall tree is trained by minimizing the error function over all its parameters. We propose a new soft survival tree model (SST), with a soft splitting rule at each branch node, trained via a nonlinear optimization formulation amenable to decomposition. Since SSTs provide for every input vector a specific survival function associated to a single leaf node, they satisfy the conditional computation property and inherit the related benefits. SST and the training formulation combine flexibility with interpretability: any smooth survival function (parametric, semiparametric, or nonparametric) estimated through maximum likelihood can be used, and each leaf node of an SST yields a cluster of distinct survival functions which are associated to the data points routed to it. Numerical experiments on 15 well-known datasets show that SSTs, with parametric and spline-based semiparametric survival functions, trained using an adaptation of the node-based decomposition algorithm proposed by Consolo et al. (2024) for soft regression trees, outperform three benchmark survival trees in terms of four widely-used discrimination and calibration measures. SSTs can also be extended to consider group fairness.",
    "authors": [
      "Consoloa, Antonio",
      "Amaldi, Edoardo",
      "Carrizosa, Emilio"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16846v1",
      "Other Formats": "https://arxiv.org/format/2506.16846",
      "TeX Source": "https://arxiv.org/src/2506.16846",
      "View PDF": "https://arxiv.org/pdf/2506.16846"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 08:51:33 UTC (24,744 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Soft decision trees for survival analysis",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17159",
    "abstract": "Medical image analysis is critical yet challenged by the need of jointly segmenting organs or tissues, and numerous instances for anatomical structures and tumor microenvironment analysis. Existing studies typically formulated different segmentation tasks in isolation, which overlooks the fundamental interdependencies between these tasks, leading to suboptimal segmentation performance and insufficient medical image understanding. To address this issue, we propose a Co-Seg++ framework for versatile medical segmentation. Specifically, we introduce a novel co-segmentation paradigm, allowing semantic and instance segmentation tasks to mutually enhance each other. We first devise a spatio-temporal prompt encoder (STP-Encoder) to capture long-range spatial and temporal relationships between segmentation regions and image embeddings as prior spatial constraints. Moreover, we devise a multi-task collaborative decoder (MTC-Decoder) that leverages cross-guidance to strengthen the contextual consistency of both tasks, jointly computing semantic and instance segmentation masks. Extensive experiments on diverse CT and histopathology datasets demonstrate that the proposed Co-Seg++ outperforms state-of-the-arts in the semantic, instance, and panoptic segmentation of dental anatomical structures, histopathology tissues, and nuclei instances. The source code is available at https://github.com/xq141839/Co-Seg-Plus.",
    "authors": [
      "Xu, Qing",
      "Luo, Yuxiang",
      "Duan, Wenting",
      "Chen, Zhen"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17159v1",
      "Other Formats": "https://arxiv.org/format/2506.17159",
      "TeX Source": "https://arxiv.org/src/2506.17159",
      "View PDF": "https://arxiv.org/pdf/2506.17159"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:05:09 UTC (26,725 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2404.13953",
    "abstract": "Visual object tracking and segmentation in omnidirectional videos are challenging due to the wide field-of-view and large spherical distortion brought by 360{\\deg} images. To alleviate these problems, we introduce a novel representation, extended bounding field-of-view (eBFoV), for target localization and use it as the foundation of a general 360 tracking framework which is applicable for both omnidirectional visual object tracking and segmentation tasks. Building upon our previous work on omnidirectional visual object tracking (360VOT), we propose a comprehensive dataset and benchmark that incorporates a new component called omnidirectional video object segmentation (360VOS). The 360VOS dataset includes 290 sequences accompanied by dense pixel-wise masks and covers a broader range of target categories. To support both the development and evaluation of algorithms in this domain, we divide the dataset into a training subset with 170 sequences and a testing subset with 120 sequences. Furthermore, we tailor evaluation metrics for both omnidirectional tracking and segmentation to ensure rigorous assessment. Through extensive experiments, we benchmark state-of-the-art approaches and demonstrate the effectiveness of our proposed 360 tracking framework and training dataset. Homepage: https://360vots.hkustvgd.com/",
    "authors": [
      "Xu, Yinzhe",
      "Huang, Huajian",
      "Chen, Yingshu",
      "Yeung, Sai-Kit"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2404.13953v2",
      "Other Formats": "https://arxiv.org/format/2404.13953",
      "TeX Source": "https://arxiv.org/src/2404.13953",
      "View PDF": "https://arxiv.org/pdf/2404.13953"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 22 Apr 2024 07:54:53 UTC (32,787 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 09:16:26 UTC (42,199 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/04/22",
    "title": "360VOTS: Visual Object Tracking and Segmentation in Omnidirectional Videos",
    "repo_urls": [
      "https://github.com/huajianup/360vot"
    ],
    "tasks": [
      "Object",
      "Object Tracking",
      "Segmentation",
      "Semantic Segmentation",
      "Video Object Segmentation",
      "Video Semantic Segmentation",
      "Visual Object Tracking"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17027",
    "abstract": "The training of real-world super-resolution reconstruction models heavily relies on datasets that reflect real-world degradation patterns. Extracting and modeling degradation patterns for super-resolution reconstruction using only real-world low-resolution (LR) images remains a challenging task. When synthesizing datasets to simulate real-world degradation, relying solely on degradation extraction methods fails to capture both blur and diverse noise characteristics across varying LR distributions, as well as more implicit degradations such as color gamut shifts. Conversely, domain translation alone cannot accurately approximate real-world blur characteristics due to the significant degradation domain gap between synthetic and real data. To address these challenges, we propose a novel TripleGAN framework comprising two strategically designed components: The FirstGAN primarily focuses on narrowing the domain gap in blur characteristics, while the SecondGAN performs domain-specific translation to approximate target-domain blur properties and learn additional degradation patterns. The ThirdGAN is trained on pseudo-real data generated by the FirstGAN and SecondGAN to reconstruct real-world LR images. Extensive experiments on the RealSR and DRealSR datasets demonstrate that our method exhibits clear advantages in quantitative metrics while maintaining sharp reconstructions without over-smoothing artifacts. The proposed framework effectively learns real-world degradation patterns from LR observations and synthesizes aligned datasets with corresponding degradation characteristics, thereby enabling the trained network to achieve superior performance in reconstructing high-quality SR images from real-world LR inputs.",
    "authors": [
      "Tie, Yiyang",
      "Zhu, Hong",
      "Luo, Yunyun",
      "Shi, Jing"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17027v1",
      "Other Formats": "https://arxiv.org/format/2506.17027",
      "TeX Source": "https://arxiv.org/src/2506.17027",
      "View PDF": "https://arxiv.org/pdf/2506.17027"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 14:24:48 UTC (9,363 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16723",
    "abstract": "Serial pipeline training is an efficient paradigm for handling data heterogeneity in cross-silo federated learning with low communication overhead. However, even without centralized aggregation, direct transfer of models between clients can violate privacy regulations and remain susceptible to gradient leakage and linkage attacks. Additionally, ensuring resilience against semi-honest or malicious clients who may manipulate or misuse received models remains a grand challenge, particularly in privacy-sensitive domains such as healthcare. To address these challenges, we propose TriCon-SF, a novel serial federated learning framework that integrates triple shuffling and contribution awareness. TriCon-SF introduces three levels of randomization by shuffling model layers, data segments, and training sequences to break deterministic learning patterns and disrupt potential attack vectors, thereby enhancing privacy and robustness. In parallel, it leverages Shapley value methods to dynamically evaluate client contributions during training, enabling the detection of dishonest behavior and enhancing system accountability. Extensive experiments on non-IID healthcare datasets demonstrate that TriCon-SF outperforms standard serial and parallel federated learning in both accuracy and communication efficiency. Security analysis further supports its resilience against client-side privacy attacks.",
    "authors": [
      "Yan, Yuping",
      "Wang, Yizhi",
      "Li, Yuanshuai",
      "Jin, Yaochu"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16723v1",
      "Other Formats": "https://arxiv.org/format/2506.16723",
      "TeX Source": "https://arxiv.org/src/2506.16723",
      "View PDF": "https://arxiv.org/pdf/2506.16723"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 03:40:35 UTC (5,596 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16756",
    "abstract": "Emotional support conversation (ESC) helps reduce people's psychological stress and provide emotional value through interactive dialogues. Due to the high cost of crowdsourcing a large ESC corpus, recent attempts use large language models for dialogue augmentation. However, existing approaches largely overlook the social dynamics inherent in ESC, leading to less effective simulations. In this paper, we introduce SocialSim, a novel framework that simulates ESC by integrating key aspects of social interactions: social disclosure and social awareness. On the seeker side, we facilitate social disclosure by constructing a comprehensive persona bank that captures diverse and authentic help-seeking scenarios. On the supporter side, we enhance social awareness by eliciting cognitive reasoning to generate logical and supportive responses. Building upon SocialSim, we construct SSConv, a large-scale synthetic ESC corpus of which quality can even surpass crowdsourced ESC data. We further train a chatbot on SSConv and demonstrate its state-of-the-art performance in both automatic and human evaluations. We believe SocialSim offers a scalable way to synthesize ESC, making emotional care more accessible and practical.",
    "authors": [
      "Chen, Zhuang",
      "Cao, Yaru",
      "Bi, Guanqun",
      "Wu, Jincenzi",
      "Zhou, Jinfeng",
      "Xiao, Xiyao",
      "Chen, Si",
      "Wang, Hongning",
      "Huang, Minlie"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16756v1",
      "Other Formats": "https://arxiv.org/format/2506.16756",
      "TeX Source": "https://arxiv.org/src/2506.16756",
      "View PDF": "https://arxiv.org/pdf/2506.16756"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 05:24:40 UTC (915 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "SocialSim: Towards Socialized Simulation of Emotional Support Conversation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2308.05636",
    "abstract": "Machine learning (ML) is widely used today, especially through deep neural networks (DNNs), however, increasing computational load and resource requirements have led to cloud-based solutions. To address this problem, a new generation of networks called Spiking Neural Networks (SNN) has emerged, which mimic the behavior of the human brain to improve efficiency and reduce energy consumption. These networks often process large amounts of sensitive information, such as confidential data, and thus privacy issues arise. Homomorphic encryption (HE) offers a solution, allowing calculations to be performed on encrypted data without decrypting it. This research compares traditional DNNs and SNNs using the Brakerski/Fan-Vercauteren (BFV) encryption scheme. The LeNet-5 model, a widely-used convolutional architecture, is used for both DNN and SNN models based on the LeNet-5 architecture, and the networks are trained and compared using the FashionMNIST dataset. The results show that SNNs using HE achieve up to 40% higher accuracy than DNNs for low values of the plaintext modulus t, although their execution time is longer due to their time-coding nature with multiple time-steps.",
    "authors": [
      "Nikfam, Farzad",
      "Casaburi, Raffaele",
      "Marchisio, Alberto",
      "Martina, Maurizio",
      "Shafique, Muhammad"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2308.05636v3",
      "Other Formats": "https://arxiv.org/format/2308.05636",
      "TeX Source": "https://arxiv.org/src/2308.05636",
      "View PDF": "https://arxiv.org/pdf/2308.05636"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 10 Aug 2023 15:26:35 UTC (1,565 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 12 Oct 2023 11:49:58 UTC (1,927 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 16:17:20 UTC (1,858 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2023/08/10",
    "title": "A Homomorphic Encryption Framework for Privacy-Preserving Spiking Neural Networks",
    "tasks": [
      "Privacy Preserving"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2407.12395",
    "abstract": "Recent advances in implicit scene representation enable high-fidelity street view novel view synthesis. However, existing methods optimize a neural radiance field for each scene, relying heavily on dense training images and extensive computation resources. To mitigate this shortcoming, we introduce a new method called Efficient Depth-Guided Urban View Synthesis (EDUS) for fast feed-forward inference and efficient per-scene fine-tuning. Different from prior generalizable methods that infer geometry based on feature matching, EDUS leverages noisy predicted geometric priors as guidance to enable generalizable urban view synthesis from sparse input images. The geometric priors allow us to apply our generalizable model directly in the 3D space, gaining robustness across various sparsity levels. Through comprehensive experiments on the KITTI-360 and Waymo datasets, we demonstrate promising generalization abilities on novel street scenes. Moreover, our results indicate that EDUS achieves state-of-the-art performance in sparse view settings when combined with fast test-time optimization.",
    "authors": [
      "Miao, Sheng",
      "Huang, Jiaxin",
      "Bai, Dongfeng",
      "Qiu, Weichao",
      "Liu, Bingbing",
      "Geiger, Andreas",
      "Liao, Yiyi"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2407.12395v2",
      "Other Formats": "https://arxiv.org/format/2407.12395",
      "TeX Source": "https://arxiv.org/src/2407.12395",
      "View PDF": "https://arxiv.org/pdf/2407.12395"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 17 Jul 2024 08:16:25 UTC (14,436 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 04:11:35 UTC (35,001 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/07/17",
    "title": "Efficient Depth-Guided Urban View Synthesis",
    "tasks": [
      "Novel View Synthesis"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17047",
    "abstract": "Neural network model extraction has emerged in recent years as an important security concern, as adversaries attempt to recover a network's parameters via black-box queries. A key step in this process is signature extraction, which aims to recover the absolute values of the network's weights layer by layer. Prior work, notably by Carlini et al. (2020), introduced a technique inspired by differential cryptanalysis to extract neural network parameters. However, their method suffers from several limitations that restrict its applicability to networks with a few layers only. Later works focused on improving sign extraction, but largely relied on the assumption that signature extraction itself was feasible. In this work, we revisit and refine the signature extraction process by systematically identifying and addressing for the first time critical limitations of Carlini et al.'s signature extraction method. These limitations include rank deficiency and noise propagation from deeper layers. To overcome these challenges, we propose efficient algorithmic solutions for each of the identified issues, greatly improving the efficiency of signature extraction. Our approach permits the extraction of much deeper networks than was previously possible. We validate our method through extensive experiments on ReLU-based neural networks, demonstrating significant improvements in extraction depth and accuracy. For instance, our extracted network matches the target network on at least 95% of the input space for each of the eight layers of a neural network trained on the CIFAR-10 dataset, while previous works could barely extract the first three layers. Our results represent a crucial step toward practical attacks on larger and more complex neural network architectures.",
    "authors": [
      "Liu, Haolin",
      "Siproudhis, Adrien",
      "Experton, Samuel",
      "Lorenz, Peter",
      "Boura, Christina",
      "Peyrin, Thomas"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17047v1",
      "Other Formats": "https://arxiv.org/format/2506.17047",
      "TeX Source": "https://arxiv.org/src/2506.17047",
      "View PDF": "https://arxiv.org/pdf/2506.17047"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 14:59:47 UTC (299 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Navigating the Deep: Signature Extraction on Deep Neural Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.04287",
    "abstract": "Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.",
    "authors": [
      "Yang, Yongjin",
      "Kang, Sinjae",
      "Lee, Juyong",
      "Lee, Dongjun",
      "Yun, Se-Young",
      "Lee, Kimin"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.04287",
      "TeX Source": "https://arxiv.org/src/2506.04287",
      "View PDF": "https://arxiv.org/pdf/2506.04287"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 4 Jun 2025 10:04:21 UTC (2,425 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 03:16:30 UTC (1,869 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/04",
    "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback",
    "tasks": [
      "Large Language Model"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17201",
    "abstract": "Recent advances in diffusion-based and controllable video generation have enabled high-quality and temporally coherent video synthesis, laying the groundwork for immersive interactive gaming experiences. However, current methods face limitations in dynamics, generality, long-term consistency, and efficiency, which limit the ability to create various gameplay videos. To address these gaps, we introduce Hunyuan-GameCraft, a novel framework for high-dynamic interactive video generation in game environments. To achieve fine-grained action control, we unify standard keyboard and mouse inputs into a shared camera representation space, facilitating smooth interpolation between various camera and movement operations. Then we propose a hybrid history-conditioned training strategy that extends video sequences autoregressively while preserving game scene information. Additionally, to enhance inference efficiency and playability, we achieve model distillation to reduce computational overhead while maintaining consistency across long temporal sequences, making it suitable for real-time deployment in complex interactive environments. The model is trained on a large-scale dataset comprising over one million gameplay recordings across over 100 AAA games, ensuring broad coverage and diversity, then fine-tuned on a carefully annotated synthetic dataset to enhance precision and control. The curated game scene data significantly improves the visual fidelity, realism and action controllability. Extensive experiments demonstrate that Hunyuan-GameCraft significantly outperforms existing models, advancing the realism and playability of interactive game video generation.",
    "authors": [
      "Li, Jiaqi",
      "Tang, Junshu",
      "Xu, Zhiyong",
      "Wu, Longhuang",
      "Zhou, Yuan",
      "Shao, Shuai",
      "Yu, Tianbao",
      "Cao, Zhiguo",
      "Lu, Qinglin"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17201v1",
      "Other Formats": "https://arxiv.org/format/2506.17201",
      "TeX Source": "https://arxiv.org/src/2506.17201",
      "View PDF": "https://arxiv.org/pdf/2506.17201"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:50:37 UTC (28,944 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.08070",
    "abstract": "Machine learning relies heavily on data, yet the continuous growth of real-world data poses challenges for efficient dataset construction and training. A fundamental yet unsolved question is: given our current model and data, does a new data (sample/batch) need annotation/learning? Conventional approaches retain all available data, leading to non-optimal data and training efficiency. Active learning aims to reduce data redundancy by selecting a subset of samples to annotate, while it increases pipeline complexity and introduces bias. In this work, we propose Info-Coevolution, a novel framework that efficiently enables models and data to coevolve through online selective annotation with no bias. Leveraging task-specific models (and open-source models), it selectively annotates and integrates online and web data to improve datasets efficiently. For real-world datasets like ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32\\% without performance loss. It is able to automatically give the saving ratio without tuning the ratio. It can further reduce the annotation ratio to 50\\% with semi-supervised learning. We also explore retrieval-based dataset enhancement using unlabeled open-source data. Code is available at https://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.",
    "authors": [
      "Qin, Ziheng",
      "Xu, Hailun",
      "Yew, Wei Chee",
      "Jia, Qi",
      "Luo, Yang",
      "Sarkar, Kanchan",
      "Guan, Danhui",
      "Wang, Kai",
      "You, Yang"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.08070v2",
      "Other Formats": "https://arxiv.org/format/2506.08070",
      "TeX Source": "https://arxiv.org/src/2506.08070",
      "View PDF": "https://arxiv.org/pdf/2506.08070"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 9 Jun 2025 17:04:11 UTC (481 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 02:52:55 UTC (481 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/09",
    "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution",
    "repo_urls": [
      "https://github.com/nus-hpc-ai-lab/info-coevolution"
    ],
    "tasks": [
      "Active Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17006",
    "abstract": "Large language models (LLMs) are increasingly used to generate feedback, yet their impact on learning remains underexplored, especially compared to existing feedback methods. This study investigates how on-demand LLM-generated explanatory feedback influences learning in seven scenario-based tutor training lessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we compare posttest performance among learners across three groups: learners who received feedback generated by gpt-3.5-turbo, those who declined it, and those without access. All groups received non-LLM corrective feedback. To address potential selection bias-where higher-performing learners may be more inclined to use LLM feedback-we applied propensity scoring. Learners with a higher predicted likelihood of engaging with LLM feedback scored significantly higher at posttest than those with lower propensity. After adjusting for this effect, two out of seven lessons showed statistically significant learning benefits from LLM feedback with standardized effect sizes of 0.28 and 0.33. These moderate effects suggest that the effectiveness of LLM feedback depends on the learners' tendency to seek support. Importantly, LLM feedback did not significantly increase completion time, and learners overwhelmingly rated it as helpful. These findings highlight LLM feedback's potential as a low-cost and scalable way to improve learning on open-ended tasks, particularly in existing systems already providing feedback without LLMs. This work contributes open datasets, LLM prompts, and rubrics to support reproducibility.",
    "authors": [
      "Thomas, Danielle R.",
      "Borchers, Conrad",
      "Bhushan, Shambhavi",
      "Gatz, Erin",
      "Gupta, Shivang",
      "Koedinger, Kenneth R."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17006v1",
      "Other Formats": "https://arxiv.org/format/2506.17006",
      "TeX Source": "https://arxiv.org/src/2506.17006",
      "View PDF": "https://arxiv.org/pdf/2506.17006"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 13:59:14 UTC (399 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "LLM-Generated Feedback Supports Learning If Learners Choose to Use It",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17136",
    "abstract": "Semi-supervised learning addresses the issue of limited annotations in medical images effectively, but its performance is often inadequate for complex backgrounds and challenging tasks. Multi-modal fusion methods can significantly improve the accuracy of medical image segmentation by providing complementary information. However, they face challenges in achieving significant improvements under semi-supervised conditions due to the challenge of effectively leveraging unlabeled data. There is a significant need to create an effective and reliable multi-modal learning strategy for leveraging unlabeled data in semi-supervised segmentation. To address these issues, we propose a novel semi-supervised multi-modal medical image segmentation approach, which leverages complementary multi-modal information to enhance performance with limited labeled data. Our approach employs a multi-stage multi-modal fusion and enhancement strategy to fully utilize complementary multi-modal information, while reducing feature discrepancies and enhancing feature sharing and alignment. Furthermore, we effectively introduce contrastive mutual learning to constrain prediction consistency across modalities, thereby facilitating the robustness of segmentation results in semi-supervised tasks. Experimental results on two multi-modal datasets demonstrate the superior performance and robustness of the proposed framework, establishing its valuable potential for solving medical image segmentation tasks in complex scenarios.",
    "authors": [
      "Meng, Dongdong",
      "Li, Sheng",
      "Wu, Hao",
      "Wang, Guoping",
      "Yan, Xueqing"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17136v1",
      "Other Formats": "https://arxiv.org/format/2506.17136",
      "TeX Source": "https://arxiv.org/src/2506.17136",
      "View PDF": "https://arxiv.org/pdf/2506.17136"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:37:44 UTC (180 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17063",
    "abstract": "The exponential growth of IoT devices presents critical challenges in bandwidth-constrained wireless networks, particularly regarding efficient data transmission and privacy preservation. This paper presents a novel federated semantic communication (SC) framework that enables collaborative training of bandwidth-efficient models for image reconstruction across heterogeneous IoT devices. By leveraging SC principles to transmit only semantic features, our approach dramatically reduces communication overhead while preserving reconstruction quality. We address the fundamental challenge of client selection in federated learning environments where devices exhibit significant disparities in dataset sizes and data distributions. Our framework implements three distinct client selection strategies that explore different trade-offs between system performance and fairness in resource allocation. The system employs an end-to-end SC architecture with semantic bottlenecks, coupled with a loss-based aggregation mechanism that naturally adapts to client heterogeneity. Experimental evaluation on image data demonstrates that while Utilitarian selection achieves the highest reconstruction quality, Proportional Fairness maintains competitive performance while significantly reducing participation inequality and improving computational efficiency. These results establish that federated SC can successfully balance reconstruction quality, resource efficiency, and fairness in heterogeneous IoT deployments, paving the way for sustainable and privacy-preserving edge intelligence applications.",
    "authors": [
      "Lahoud, Samer",
      "Khawam, Kinda"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17063v1",
      "Other Formats": "https://arxiv.org/format/2506.17063",
      "TeX Source": "https://arxiv.org/src/2506.17063",
      "View PDF": "https://arxiv.org/pdf/2506.17063"
    },
    "subjects": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:11:20 UTC (45 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Client Selection Strategies for Federated Semantic Communications in Heterogeneous IoT Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16994",
    "abstract": "Unsupervised Domain Adaptation (UDA) is a critical challenge in real-world vision systems, especially in resource-constrained environments like drones, where memory and computation are limited. Existing prompt-driven UDA methods typically rely on large vision-language models and require full access to source-domain data during adaptation, limiting their applicability. In this work, we propose Prmpt2Adpt, a lightweight and efficient zero-shot domain adaptation framework built around a teacher-student paradigm guided by prompt-based feature alignment. At the core of our method is a distilled and fine-tuned CLIP model, used as the frozen backbone of a Faster R-CNN teacher. A small set of low-level source features is aligned to the target domain semantics-specified only through a natural language prompt-via Prompt-driven Instance Normalization (PIN). These semantically steered features are used to briefly fine-tune the detection head of the teacher model. The adapted teacher then generates high-quality pseudo-labels, which guide the on-the-fly adaptation of a compact student model. Experiments on the MDS-A dataset demonstrate that Prmpt2Adpt achieves competitive detection performance compared to state-of-the-art methods, while delivering up to 7x faster adaptation and 5x faster inference speed using few source images-making it a practical and scalable solution for real-time adaptation in low-resource domains.",
    "authors": [
      "Farrukh, Yasir Ali",
      "Wali, Syed",
      "Khan, Irfan",
      "Bastian, Nathaniel D."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16994v1",
      "Other Formats": "https://arxiv.org/format/2506.16994",
      "TeX Source": "https://arxiv.org/src/2506.16994",
      "View PDF": "https://arxiv.org/pdf/2506.16994"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 13:43:54 UTC (6,981 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.24183",
    "abstract": "Large language models (LLMs) trained via reinforcement learning with verifiable reward (RLVR) have achieved breakthroughs on tasks with explicit, automatable verification, such as software programming and mathematical problems. Extending RLVR to electronic design automation (EDA), especially automatically generating hardware description languages (HDLs) like Verilog from natural-language (NL) specifications, however, poses three key challenges: the lack of automated and accurate verification environments, the scarcity of high-quality NL-code pairs, and the prohibitive computation cost of RLVR. To this end, we introduce CodeV-R1, an RLVR framework for training Verilog generation LLMs. First, we develop a rule-based testbench generator that performs robust equivalence checking against golden references. Second, we propose a round-trip data synthesis method that pairs open-source Verilog snippets with LLM-generated NL descriptions, verifies code-NL-code consistency via the generated testbench, and filters out inequivalent examples to yield a high-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training pipeline: distillation for the cold start of reasoning abilities, followed by adaptive DAPO, our novel RLVR algorithm that can reduce training cost by adaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves 68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively, surpassing prior state-of-the-art by 12~20%, while matching or even exceeding the performance of 671B DeepSeek-R1. We will release our model, training pipeline, and dataset to facilitate research in EDA and LLM communities.",
    "authors": [
      "Zhu, Yaoyu",
      "Huang, Di",
      "Lyu, Hanqi",
      "Zhang, Xiaoyun",
      "Li, Chongxiao",
      "Shi, Wenxuan",
      "Wu, Yutong",
      "Mu, Jianan",
      "Wang, Jinghua",
      "Zhao, Yang",
      "Jin, Pengwei",
      "Cheng, Shuyao",
      "Liang, Shengwen",
      "Zhang, Xishan",
      "Zhang, Rui",
      "Du, Zidong",
      "Guo, Qi",
      "Hu, Xing",
      "Chen, Yunji"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.24183v2",
      "Other Formats": "https://arxiv.org/format/2505.24183",
      "TeX Source": "https://arxiv.org/src/2505.24183",
      "View PDF": "https://arxiv.org/pdf/2505.24183"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Programming Languages (cs.PL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 30 May 2025 03:51:06 UTC (2,450 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 07:05:18 UTC (2,450 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/30",
    "title": "CodeV-R1: Reasoning-Enhanced Verilog Generation",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2503.08558",
    "abstract": "Recent years have witnessed impressive robotic manipulation systems driven by advances in imitation learning and generative modeling, such as diffusion- and flow-based approaches. As robot policy performance increases, so does the complexity and time horizon of achievable tasks, inducing unexpected and diverse failure modes that are difficult to predict a priori. To enable trustworthy policy deployment in safety-critical human environments, reliable runtime failure detection becomes important during policy inference. However, most existing failure detection approaches rely on prior knowledge of failure modes and require failure data during training, which imposes a significant challenge in practicality and scalability. In response to these limitations, we present FAIL-Detect, a modular two-stage approach for failure detection in imitation learning-based robotic manipulation. To accurately identify failures from successful training data alone, we frame the problem as sequential out-of-distribution (OOD) detection. We first distill policy inputs and outputs into scalar signals that correlate with policy failures and capture epistemic uncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile framework for uncertainty quantification with statistical guarantees. Empirically, we thoroughly investigate both learned and post-hoc scalar signal candidates on diverse robotic manipulation tasks. Our experiments show learned signals to be mostly consistently effective, particularly when using our novel flow-based density estimator. Furthermore, our method detects failures more accurately and faster than state-of-the-art (SOTA) failure detection baselines. These results highlight the potential of FAIL-Detect to enhance the safety and reliability of imitation learning-based robotic systems as they progress toward real-world deployment.",
    "authors": [
      "Xu, Chen",
      "Nguyen, Tony Khuong",
      "Dixon, Emma",
      "Rodriguez, Christopher",
      "Miller, Patrick",
      "Lee, Robert",
      "Shah, Paarth",
      "Ambrus, Rares",
      "Nishimura, Haruki",
      "Itkina, Masha"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.08558v3",
      "Other Formats": "https://arxiv.org/format/2503.08558",
      "TeX Source": "https://arxiv.org/src/2503.08558",
      "View PDF": "https://arxiv.org/pdf/2503.08558"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 11 Mar 2025 15:47:12 UTC (16,532 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 25 Apr 2025 07:12:28 UTC (23,704 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 20 Jun 2025 05:51:24 UTC (7,119 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/03/11",
    "title": "Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime Failure Detection for Imitation Learning Policies",
    "repo_urls": [
      "https://github.com/cxu-tri/fail-detect"
    ],
    "tasks": [
      "Conformal Prediction",
      "Imitation Learning",
      "Out of Distribution (OOD) Detection",
      "Uncertainty Quantification"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2411.00412",
    "abstract": "Large Language Models (LLMs) demonstrate promising capabilities in solving scientific problems but often suffer from the issue of hallucination. While integrating LLMs with tools can mitigate this issue, models fine-tuned on tool usage become overreliant on them and incur unnecessary costs. Inspired by how human experts assess problem complexity before selecting solutions, we propose a novel two-component fine-tuning method, Adapting While Learning (AWL). In the first component, World Knowledge Learning (WKL), LLMs internalize scientific knowledge by learning from tool-generated solutions. In the second component, Tool Usage Adaptation (TUA), we categorize problems as easy or hard based on the model's accuracy, and train it to maintain direct reasoning for easy problems while switching to tools for hard ones. We validate our method on six scientific benchmark datasets across climate science, epidemiology, physics, and other domains. Compared to the original instruct model (8B), models post-trained with AWL achieve 29.11% higher answer accuracy and 12.72% better tool usage accuracy, even surpassing state-of-the-art models including GPT-4o and Claude-3.5 on four custom-created datasets. Our code is open-source at https://github.com/Rose-STL-Lab/Adapting-While-Learning.",
    "authors": [
      "Lyu, Bohan",
      "Cao, Yadi",
      "Watson-Parris, Duncan",
      "Bergen, Leon",
      "Berg-Kirkpatrick, Taylor",
      "Yu, Rose"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2411.00412",
      "TeX Source": "https://arxiv.org/src/2411.00412",
      "View PDF": "https://arxiv.org/pdf/2411.00412"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 1 Nov 2024 07:18:31 UTC (769 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Tue, 4 Feb 2025 06:11:55 UTC (826 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 6 Feb 2025 04:18:46 UTC (841 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Fri, 20 Jun 2025 08:54:13 UTC (785 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2024/11/01",
    "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation",
    "tasks": [
      "Epidemiology",
      "Knowledge Distillation",
      "World Knowledge"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17074",
    "abstract": "We present Assembler, a scalable and generalizable framework for 3D part assembly that reconstructs complete objects from input part meshes and a reference image. Unlike prior approaches that mostly rely on deterministic part pose prediction and category-specific training, Assembler is designed to handle diverse, in-the-wild objects with varying part counts, geometries, and structures. It addresses the core challenges of scaling to general 3D part assembly through innovations in task formulation, representation, and data. First, Assembler casts part assembly as a generative problem and employs diffusion models to sample plausible configurations, effectively capturing ambiguities arising from symmetry, repeated parts, and multiple valid assemblies. Second, we introduce a novel shape-centric representation based on sparse anchor point clouds, enabling scalable generation in Euclidean space rather than SE(3) pose prediction. Third, we construct a large-scale dataset of over 320K diverse part-object assemblies using a synthesis and filtering pipeline built on existing 3D shape repositories. Assembler achieves state-of-the-art performance on PartNet and is the first to demonstrate high-quality assembly for complex, real-world objects. Based on Assembler, we further introduce an interesting part-aware 3D modeling system that generates high-resolution, editable objects from images, demonstrating potential for interactive and compositional design. Project page: https://assembler3d.github.io",
    "authors": [
      "Zhao, Wang",
      "Cao, Yan-Pei",
      "Xu, Jiale",
      "Dong, Yuejiang",
      "Shan, Ying"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17074v1",
      "Other Formats": "https://arxiv.org/format/2506.17074",
      "TeX Source": "https://arxiv.org/src/2506.17074",
      "View PDF": "https://arxiv.org/pdf/2506.17074"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:25:20 UTC (12,091 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17206",
    "abstract": "3D panorama synthesis is a promising yet challenging task that demands high-quality and diverse visual appearance and geometry of the generated omnidirectional content. Existing methods leverage rich image priors from pre-trained 2D foundation models to circumvent the scarcity of 3D panoramic data, but the incompatibility between 3D panoramas and 2D single views limits their effectiveness. In this work, we demonstrate that by applying multi-plane synchronization to the operators from 2D foundation models, their capabilities can be seamlessly extended to the omnidirectional domain. Based on this design, we further introduce DreamCube, a multi-plane RGB-D diffusion model for 3D panorama generation, which maximizes the reuse of 2D foundation model priors to achieve diverse appearances and accurate geometry while maintaining multi-view consistency. Extensive experiments demonstrate the effectiveness of our approach in panoramic image generation, panoramic depth estimation, and 3D scene generation.",
    "authors": [
      "Huang, Yukun",
      "Zhou, Yanning",
      "Wang, Jianan",
      "Huang, Kaiyi",
      "Liu, Xihui"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17206v1",
      "Other Formats": "https://arxiv.org/format/2506.17206",
      "TeX Source": "https://arxiv.org/src/2506.17206",
      "View PDF": "https://arxiv.org/pdf/2506.17206"
    },
    "subjects": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:55:06 UTC (6,022 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "DreamCube: 3D Panorama Generation via Multi-plane Synchronization",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16821",
    "abstract": "Robust and accurate ball detection is a critical component for autonomous humanoid soccer robots, particularly in dynamic and challenging environments such as RoboCup outdoor fields. However, traditional supervised approaches require extensive manual annotation, which is costly and time-intensive. To overcome this problem, we present a self-supervised learning framework for domain-adaptive feature extraction to enhance ball detection performance. The proposed approach leverages a general-purpose pretrained model to generate pseudo-labels, which are then used in a suite of self-supervised pretext tasks -- including colorization, edge detection, and triplet loss -- to learn robust visual features without relying on manual annotations. Additionally, a model-agnostic meta-learning (MAML) strategy is incorporated to ensure rapid adaptation to new deployment scenarios with minimal supervision. A new dataset comprising 10,000 labeled images from outdoor RoboCup SPL matches is introduced, used to validate the method, and made available to the community. Experimental results demonstrate that the proposed pipeline outperforms baseline models in terms of accuracy, F1 score, and IoU, while also exhibiting faster convergence.",
    "authors": [
      "Lin, Can",
      "Affinita, Daniele",
      "Zimmatore, Marco E. P.",
      "Nardi, Daniele",
      "Bloisi, Domenico D.",
      "Suriani, Vincenzo"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16821v1",
      "Other Formats": "https://arxiv.org/format/2506.16821",
      "TeX Source": "https://arxiv.org/src/2506.16821",
      "View PDF": "https://arxiv.org/pdf/2506.16821"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 08:21:34 UTC (5,243 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17187",
    "abstract": "Most modern learning problems are over-parameterized, where the number of learnable parameters is much greater than the number of training data points. In this over-parameterized regime, the training loss typically has infinitely many global optima that completely interpolate the data with varying generalization performance. The particular global optimum we converge to depends on the implicit bias of the optimization algorithm. The question we address in this paper is, ``What is the implicit bias that leads to the best generalization performance?\". To find the optimal implicit bias, we provide a precise asymptotic analysis of the generalization performance of interpolators obtained from the minimization of convex functions/potentials for over-parameterized linear regression with non-isotropic Gaussian data. In particular, we obtain a tight lower bound on the best generalization error possible among this class of interpolators in terms of the over-parameterization ratio, the variance of the noise in the labels, the eigenspectrum of the data covariance, and the underlying distribution of the parameter to be estimated. Finally, we find the optimal convex implicit bias that achieves this lower bound under certain sufficient conditions involving the log-concavity of the distribution of a Gaussian convolved with the prior of the true underlying parameter.",
    "authors": [
      "Varma, Kanumuri Nithin",
      "Hassibi, Babak"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17187v1",
      "Other Formats": "https://arxiv.org/format/2506.17187",
      "TeX Source": "https://arxiv.org/src/2506.17187",
      "View PDF": "https://arxiv.org/pdf/2506.17187"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 17:41:39 UTC (631 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Optimal Implicit Bias in Linear Regression",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.13053",
    "abstract": "Existing large-scale zero-shot text-to-speech (TTS) models deliver high speech quality but suffer from slow inference speeds due to massive parameters. To address this issue, this paper introduces ZipVoice, a high-quality flow-matching-based zero-shot TTS model with a compact model size and fast inference speed. Key designs include: 1) a Zipformer-based flow-matching decoder to maintain adequate modeling capabilities under constrained size; 2) Average upsampling-based initial speech-text alignment and Zipformer-based text encoder to improve speech intelligibility; 3) A flow distillation method to reduce sampling steps and eliminate the inference overhead associated with classifier-free guidance. Experiments on 100k hours multilingual datasets show that ZipVoice matches state-of-the-art models in speech quality, while being 3 times smaller and up to 30 times faster than a DiT-based flow-matching baseline. Codes, model checkpoints and demo samples are publicly available.",
    "authors": [
      "Zhu, Han",
      "Kang, Wei",
      "Yao, Zengwei",
      "Guo, Liyong",
      "Kuang, Fangjun",
      "Li, Zhaoqing",
      "Zhuang, Weiji",
      "Lin, Long",
      "Povey, Daniel"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.13053v2",
      "Other Formats": "https://arxiv.org/format/2506.13053",
      "TeX Source": "https://arxiv.org/src/2506.13053",
      "View PDF": "https://arxiv.org/pdf/2506.13053"
    },
    "subjects": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 16 Jun 2025 02:48:17 UTC (293 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 03:21:30 UTC (293 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/16",
    "title": "ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching",
    "tasks": [
      "Decoder",
      "text-to-speech",
      "Text to Speech"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16658",
    "abstract": "Multi-armed bandit (MAB) is a widely adopted framework for sequential decision-making under uncertainty. Traditional bandit algorithms rely solely on online data, which tends to be scarce as it must be gathered during the online phase when the arms are actively pulled. However, in many practical settings, rich auxiliary data, such as covariates of past users, is available prior to deploying any arms. We introduce a new setting for MAB where pre-trained machine learning (ML) models are applied to convert side information and historical data into \\emph{surrogate rewards}. A prominent feature of this setting is that the surrogate rewards may exhibit substantial bias, as true reward data is typically unavailable in the offline phase, forcing ML predictions to heavily rely on extrapolation. To address the issue, we propose the Machine Learning-Assisted Upper Confidence Bound (MLA-UCB) algorithm, which can be applied to any reward prediction model and any form of auxiliary data. When the predicted and true rewards are jointly Gaussian, it provably improves the cumulative regret, provided that the correlation is non-zero -- even in cases where the mean surrogate reward completely misaligns with the true mean rewards. Notably, our method requires no prior knowledge of the covariance matrix between true and surrogate rewards. We compare MLA-UCB with the standard UCB on a range of numerical studies and show a sizable efficiency gain even when the size of the offline data and the correlation between predicted and true rewards are moderate.",
    "authors": [
      "Ji, Wenlong",
      "Pan, Yihan",
      "Zhu, Ruihao",
      "Lei, Lihua"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16658v1",
      "Other Formats": "https://arxiv.org/format/2506.16658",
      "TeX Source": "https://arxiv.org/src/2506.16658",
      "View PDF": "https://arxiv.org/pdf/2506.16658"
    },
    "subjects": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 00:09:39 UTC (2,026 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Multi-Armed Bandits With Machine Learning-Generated Surrogate Rewards",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16762",
    "abstract": "Urban mobility plays a crucial role in the functioning of cities, influencing economic activity, accessibility, and quality of life. However, the effectiveness of analytical models in understanding urban mobility patterns can be significantly affected by the spatial scales employed in the analysis. This paper explores the impact of spatial scales on the performance of the gravity model in explaining urban mobility patterns using public transport flow data in Singapore. The model is evaluated across multiple spatial scales of origin and destination locations, ranging from individual bus stops and train stations to broader regional aggregations. Results indicate the existence of an optimal intermediate spatial scale at which the gravity model performs best. At the finest scale, where individual transport nodes are considered, the model exhibits poor performance due to noisy and highly variable travel patterns. Conversely, at larger scales, model performance also suffers as over-aggregation of transport nodes results in excessive generalisation which obscures the underlying mobility dynamics. Furthermore, distance-based spatial aggregation of transport nodes proves to outperform administrative boundary-based aggregation, suggesting that actual urban organisation and movement patterns may not necessarily align with imposed administrative divisions. These insights highlight the importance of selecting appropriate spatial scales in mobility analysis and urban modelling in general, offering valuable guidance for urban and transport planning efforts aimed at enhancing mobility in complex urban environments.",
    "authors": [
      "Huynh, Hoai Nguyen"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16762v1",
      "Other Formats": "https://arxiv.org/format/2506.16762",
      "TeX Source": "https://arxiv.org/src/2506.16762",
      "View PDF": "https://arxiv.org/pdf/2506.16762"
    },
    "subjects": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 05:39:39 UTC (2,918 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Exploring the effect of spatial scales in studying urban mobility pattern",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2503.11280",
    "abstract": "Large language models (LLMs) trained on massive multilingual datasets hint at the formation of interlingual constructs--a shared subspace in the representation space. However, evidence regarding this phenomenon is mixed, leaving it unclear whether these models truly develop unified interlingual representations, or present a partially aligned constructs. We explore 31 diverse languages varying on their resource-levels, typologies, and geographical regions; and find that multilingual LLMs exhibit inconsistent cross-lingual alignments. To address this, we propose an interlingual representation framework identifying both the shared interlingual semantic subspace and fragmented components, existed due to representational limitations. We introduce Interlingual Local Overlap (ILO) score to quantify interlingual alignment by comparing the local neighborhood structures of high-dimensional representations. We utilize ILO to investigate the impact of single-language fine-tuning on the interlingual representations in multilingual LLMs. Our results indicate that training exclusively on a single language disrupts the alignment in early layers, while freezing these layers preserves the alignment of interlingual representations, leading to improved cross-lingual generalization. These results validate our framework and metric for evaluating interlingual representation, and further underscore that interlingual alignment is crucial for scalable multilingual learning.",
    "authors": [
      "Wilie, Bryan",
      "Cahyawijaya, Samuel",
      "He, Junxian",
      "Fung, Pascale"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "Other Formats": "https://arxiv.org/format/2503.11280",
      "TeX Source": "https://arxiv.org/src/2503.11280",
      "View PDF": "https://arxiv.org/pdf/2503.11280"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 14 Mar 2025 10:39:27 UTC (34,541 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 19 Mar 2025 12:16:42 UTC (34,541 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Wed, 7 May 2025 16:03:47 UTC (45,448 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Fri, 20 Jun 2025 17:55:07 UTC (45,442 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2025/03/14",
    "title": "High-Dimensional Interlingual Representations of Large Language Models",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12190",
    "abstract": "Breast cancer remains a leading cause of cancer-related mortality worldwide, making early detection and accurate treatment response monitoring critical priorities. We present BreastDCEDL, a curated, deep learning-ready dataset comprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from 2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts, all sourced from The Cancer Imaging Archive. The raw DICOM imaging data were rigorously converted into standardized 3D NIfTI volumes with preserved signal integrity, accompanied by unified tumor annotations and harmonized clinical metadata including pathologic complete response (pCR), hormone receptor (HR), and HER2 status. Although DCE-MRI provides essential diagnostic information and deep learning offers tremendous potential for analyzing such complex data, progress has been limited by lack of accessible, public, multicenter datasets. BreastDCEDL addresses this gap by enabling development of advanced models, including state-of-the-art transformer architectures that require substantial training data. To demonstrate its capacity for robust modeling, we developed the first transformer-based model for breast DCE-MRI, leveraging Vision Transformer (ViT) architecture trained on RGB-fused images from three contrast phases (pre-contrast, early post-contrast, and late post-contrast). Our ViT model achieved state-of-the-art pCR prediction performance in HR+/HER2- patients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark splits, offering a framework for reproducible research and enabling clinically meaningful modeling in breast cancer imaging.",
    "authors": [
      "Fridman, Naomi",
      "Solway, Bubby",
      "Fridman, Tomer",
      "Barnea, Itamar",
      "Goldstein, Anat"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12190v2",
      "Other Formats": "https://arxiv.org/format/2506.12190",
      "TeX Source": "https://arxiv.org/src/2506.12190",
      "View PDF": "https://arxiv.org/pdf/2506.12190"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 13 Jun 2025 19:31:57 UTC (6,045 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 20 Jun 2025 17:29:37 UTC (3,164 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/13",
    "title": "BreastDCEDL: Curating a Comprehensive DCE-MRI Dataset and developing a Transformer Implementation for Breast Cancer Treatment Response Prediction",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16950",
    "abstract": "Out-of-distribution (OOD) robustness is a desired property of computer vision models. Improving model robustness requires high-quality signals from robustness benchmarks to quantify progress. While various benchmark datasets such as ImageNet-C were proposed in the ImageNet era, most ImageNet-C corruption types are no longer OOD relative to today's large, web-scraped datasets, which already contain common corruptions such as blur or JPEG compression artifacts. Consequently, these benchmarks are no longer well-suited for evaluating OOD robustness in the era of web-scale datasets. Indeed, recent models show saturating scores on ImageNet-era OOD benchmarks, indicating that it is unclear whether models trained on web-scale datasets truly become better at OOD generalization or whether they have simply been exposed to the test distortions during training. To address this, we introduce LAION-C as a benchmark alternative for ImageNet-C. LAION-C consists of six novel distortion types specifically designed to be OOD, even for web-scale datasets such as LAION. In a comprehensive evaluation of state-of-the-art models, we find that the LAION-C dataset poses significant challenges to contemporary models, including MLLMs such as Gemini and GPT-4o. We additionally conducted a psychophysical experiment to evaluate the difficulty of our corruptions for human observers, enabling a comparison of models to lab-quality human robustness data. We observe a paradigm shift in OOD generalization: from humans outperforming models, to the best models now matching or outperforming the best human observers.",
    "authors": [
      "Li, Fanfei",
      "Klein, Thomas",
      "Brendel, Wieland",
      "Geirhos, Robert",
      "Zimmermann, Roland S."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16950v1",
      "Other Formats": "https://arxiv.org/format/2506.16950",
      "TeX Source": "https://arxiv.org/src/2506.16950",
      "View PDF": "https://arxiv.org/pdf/2506.16950"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 12:32:27 UTC (2,798 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17125",
    "abstract": "LLM4SE has demonstrated significant success, but LLMs' potential memorization of sensitive or outdated training data introduces critical risks to legal compliance, software security, and code quality. LLM unlearning techniques, which can eliminate the influence of undesired data from LLMs in a post-training way, present a promising solution to address these concerns. While recent efforts in LLM unlearning show effectiveness in natural language, their applicability to source code remains underexplored. Our empirical study reveals that existing LLM unlearning approaches, when applied to source code, cause severe model utility degradation, rendering models practically unusable for code generation. In this paper, we propose PROD, a novel unlearning approach that enables LLMs to forget undesired code content while effectively preserving their code generation capabilities. PROD suppresses the probability of forget data in LLMs' output distribution while promoting candidate distributional components, enabling the model to jointly learn to forget specific content and retain its general capabilities. To facilitate this study, we establish a benchmark for code unlearning evaluation, which includes three critical downstream tasks: copyrighted code unlearning, insecure code unlearning, and deprecated API unlearning. Our evaluation demonstrates that PROD achieves superior balance between forget quality and model utility compared to existing unlearning approaches across three downstream tasks, while consistently exhibiting improvements when applied to LLMs of varying series. PROD also exhibits superior robustness against adversarial attacks without generating or exposing the data to be forgotten. The results underscore that our approach not only extends the application boundary of unlearning techniques to source code, but also holds significant implications for advancing reliable code generation.",
    "authors": [
      "Jiang, Xue",
      "Dong, Yihong",
      "Fang, Zheng",
      "Ma, Yingwei",
      "Wang, Tangxinyu",
      "Cao, Rongyu",
      "Li, Binhua",
      "Jin, Zhi",
      "Jiao, Wenpin",
      "Li, Yongbin",
      "Li, Ge"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17125v1",
      "Other Formats": "https://arxiv.org/format/2506.17125",
      "TeX Source": "https://arxiv.org/src/2506.17125",
      "View PDF": "https://arxiv.org/pdf/2506.17125"
    },
    "subjects": [
      "Software Engineering (cs.SE)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:27:59 UTC (455 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Large Language Model Unlearning for Source Code",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17095",
    "abstract": "Software testing ensures that a system functions correctly, meets specified requirements, and maintains high quality. As artificial intelligence and machine learning (ML) technologies become integral to software systems, testing has evolved to address their unique complexities. A critical advancement in this space is fairness testing, which identifies and mitigates biases in AI applications to promote ethical and equitable outcomes. Despite extensive academic research on fairness testing, including test input generation, test oracle identification, and component testing, practical adoption remains limited. Industry practitioners often lack clear guidelines and effective tools to integrate fairness testing into real-world AI development. This study investigates how software professionals test AI-powered systems for fairness through interviews with 22 practitioners working on AI and ML projects. Our findings highlight a significant gap between theoretical fairness concepts and industry practice. While fairness definitions continue to evolve, they remain difficult for practitioners to interpret and apply. The absence of industry-aligned fairness testing tools further complicates adoption, necessitating research into practical, accessible solutions. Key challenges include data quality and diversity, time constraints, defining effective metrics, and ensuring model interoperability. These insights emphasize the need to bridge academic advancements with actionable strategies and tools, enabling practitioners to systematically address fairness in AI systems.",
    "authors": [
      "Santos, Ronnie de Souza",
      "Leca, Matheus de Morais",
      "Santos, Reydne",
      "Magalhaes, Cleyton"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17095v1",
      "Other Formats": "https://arxiv.org/format/2506.17095",
      "TeX Source": "https://arxiv.org/src/2506.17095",
      "View PDF": "https://arxiv.org/pdf/2506.17095"
    },
    "subjects": [
      "Software Engineering (cs.SE)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:03:02 UTC (253 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Software Fairness Testing in Practice",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17084",
    "abstract": "In modern science, the growing complexity of large-scale projects has increased reliance on cross-facility workflows, where institutions share resources and expertise to accelerate discovery. These workflows often involve transferring massive data over wide-area networks. While high-speed networks like ESnet and data transfer services like Globus have improved data mobility, challenges remain. Large data volumes can strain bandwidth, TCP suffers from retransmissions due to packet loss, and traditional fault-tolerance methods like erasure coding introduce significant overhead. This paper presents JANUS, a resilient and adaptive data transmission approach for cross-facility scientific workflows. JANUS uses UDP, integrates erasure coding for fault tolerance, and applies error-bounded lossy compression to reduce overhead. This design enables users to balance transmission time and accuracy based on specific needs. JANUS also adapts coding parameters to real-time network conditions and uses optimization models to determine ideal configurations. Experiments show that JANUS significantly improves data transfer efficiency while preserving fidelity.",
    "authors": [
      "Esaulov, Vladislav",
      "Chen, Jieyang",
      "Podhorszki, Norbert",
      "Suter, Fred",
      "Klasky, Scott",
      "Bourgeois, Anu G",
      "Wan, Lipeng"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17084v1",
      "Other Formats": "https://arxiv.org/format/2506.17084",
      "TeX Source": "https://arxiv.org/src/2506.17084",
      "View PDF": "https://arxiv.org/pdf/2506.17084"
    },
    "subjects": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 15:40:14 UTC (269 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17144",
    "abstract": "Traditional video-based tasks like soccer action spotting rely heavily on visual inputs, often requiring complex and computationally expensive models to process dense video data. In this work, we propose a shift from this video-centric approach to a text-based task, making it lightweight and scalable by utilizing Large Language Models (LLMs) instead of Vision-Language Models (VLMs). We posit that expert commentary, which provides rich, fine-grained descriptions and contextual cues such as excitement and tactical insights, contains enough information to reliably spot key actions in a match. To demonstrate this, we use the SoccerNet Echoes dataset, which provides timestamped commentary, and employ a system of three LLMs acting as judges specializing in outcome, excitement, and tactics. Each LLM evaluates sliding windows of commentary to identify actions like goals, cards, and substitutions, generating accurate timestamps for these events. Our experiments show that this language-centric approach performs effectively in detecting critical match events, providing a lightweight and training-free alternative to traditional video-based methods for action spotting.",
    "authors": [
      "Chakraborty, Ritabrata",
      "Chakraborty, Rajatsubhra",
      "Dasgupta, Avijit",
      "Chaurasia, Sandeep"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17144v1",
      "Other Formats": "https://arxiv.org/format/2506.17144",
      "TeX Source": "https://arxiv.org/src/2506.17144",
      "View PDF": "https://arxiv.org/pdf/2506.17144"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:45:54 UTC (334 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "Do We Need Large VLMs for Spotting Soccer Actions?",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.17113",
    "abstract": "Combining pre-trained expert models offers substantial potential for scalable multimodal reasoning, but building a unified framework remains challenging due to the increasing diversity of input modalities and task complexity. For instance, medical diagnosis requires precise reasoning over structured clinical tables, while financial forecasting depends on interpreting plot-based data to make informed predictions. To tackle this challenge, we introduce MEXA, a training-free framework that performs modality- and task-aware aggregation of multiple expert models to enable effective multimodal reasoning across diverse and distinct domains. MEXA dynamically selects expert models based on the input modality and the task-specific reasoning demands (i.e., skills). Each expert model, specialized in a modality task pair, generates interpretable textual reasoning outputs. MEXA then aggregates and reasons over these outputs using a Large Reasoning Model (LRM) to produce the final answer. This modular design allows flexible and transparent multimodal reasoning across diverse domains without additional training overhead. We extensively evaluate our approach on diverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D Understanding, and Medical QA. MEXA consistently delivers performance improvements over strong multimodal baselines, highlighting the effectiveness and broad applicability of our expert-driven selection and aggregation in diverse multimodal reasoning tasks.",
    "authors": [
      "Yu, Shoubin",
      "Zhang, Yue",
      "Wang, Ziyang",
      "Yoon, Jaehong",
      "Bansal, Mohit"
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.17113v1",
      "Other Formats": "https://arxiv.org/format/2506.17113",
      "TeX Source": "https://arxiv.org/src/2506.17113",
      "View PDF": "https://arxiv.org/pdf/2506.17113"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 16:14:13 UTC (1,465 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16826",
    "abstract": "Off-road traversability segmentation enables autonomous navigation with applications in search-and-rescue, military operations, wildlife exploration, and agriculture. Current frameworks struggle due to significant variations in unstructured environments and uncertain scene changes, and are not adaptive to be used for different robot types. We present AnyTraverse, a framework combining natural language-based prompts with human-operator assistance to determine navigable regions for diverse robotic vehicles. The system segments scenes for a given set of prompts and calls the operator only when encountering previously unexplored scenery or unknown class not part of the prompt in its region-of-interest, thus reducing active supervision load while adapting to varying outdoor scenes. Our zero-shot learning approach eliminates the need for extensive data collection or retraining. Our experimental validation includes testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate real-world deployment on multiple robot platforms. The results show that AnyTraverse performs better than GA-NAV and Off-seg while offering a vehicle-agnostic approach to off-road traversability that balances automation with targeted human supervision.",
    "authors": [
      "Sahu, Sattwik",
      "Singh, Agamdeep",
      "Nambiar, Karthik",
      "Saripalli, Srikanth",
      "Sujit, P. B."
    ],
    "last_revised_date": "2025/06/20",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16826v1",
      "Other Formats": "https://arxiv.org/format/2506.16826",
      "TeX Source": "https://arxiv.org/src/2506.16826",
      "View PDF": "https://arxiv.org/pdf/2506.16826"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 20 Jun 2025 08:31:13 UTC (6,183 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/20",
    "title": "AnyTraverse: An off-road traversability framework with VLM and human operator in the loop",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.01495",
    "abstract": "Ensuring that Large Language Models (LLMs) align with mainstream human values and ethical norms is crucial for the safe and sustainable development of AI. Current value evaluation and alignment are constrained by Western cultural bias and incomplete domestic frameworks reliant on non-native rules; furthermore, the lack of scalable, rule-driven scenario generation methods makes evaluations costly and inadequate across diverse cultural contexts. To address these challenges, we propose a hierarchical value framework grounded in core Chinese values, encompassing three main dimensions, 12 core values, and 50 derived values. Based on this framework, we construct a large-scale Chinese Values Corpus (CVC) containing over 250,000 value rules enhanced and expanded through human annotation. Experimental results show that CVC-guided scenarios outperform direct generation ones in value boundaries and content diversity. In the evaluation across six sensitive themes (e.g., surrogacy, suicide), seven mainstream LLMs preferred CVC-generated options in over 70.5% of cases, while five Chinese human annotators showed an 87.5% alignment with CVC, confirming its universality, cultural relevance, and strong alignment with Chinese values. Additionally, we construct 400,000 rule-based moral dilemma scenarios that objectively capture nuanced distinctions in conflicting value prioritization across 17 LLMs. Our work establishes a culturally-adaptive benchmarking framework for comprehensive value evaluation and alignment, representing Chinese characteristics. All data are available at https://huggingface.co/datasets/Beijing-AISI/CVC, and the code is available at https://github.com/Beijing-AISI/CVC.",
    "authors": [
      "Wu, Ping",
      "Shen, Guobin",
      "Zhao, Dongcheng",
      "Wang, Yuwei",
      "Dong, Yiting",
      "Shi, Yu",
      "Lu, Enmeng",
      "Zhao, Feifei",
      "Zeng, Yi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.01495v3",
      "Other Formats": "https://arxiv.org/format/2506.01495",
      "TeX Source": "https://arxiv.org/src/2506.01495",
      "View PDF": "https://arxiv.org/pdf/2506.01495"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 2 Jun 2025 09:56:59 UTC (5,614 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sat, 7 Jun 2025 07:06:31 UTC (5,614 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 13:47:55 UTC (5,614 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/06/02",
    "title": "CVC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16507",
    "abstract": "Reward models (RMs) are fundamental to aligning Large Language Models (LLMs) via human feedback, yet they often suffer from reward hacking. They tend to latch on to superficial or spurious attributes, such as response length or formatting, mistaking these cues learned from correlations in training data for the true causal drivers of quality (e.g., factuality, relevance). This occurs because standard training objectives struggle to disentangle these factors, leading to brittle RMs and misaligned policies. We introduce Crome (Causally Robust Reward Modeling), a novel framework grounded in an explicit causal model designed to mitigate reward hacking. Crome employs the following synthetic targeted augmentations during training: (1) Causal Augmentations, which are pairs that differ along specific causal attributes, to enforce sensitivity along each causal attribute individually, and (2) Neutral Augmentations, which are tie-label pairs varying primarily in spurious attributes, to enforce invariance along spurious attributes. Notably, our augmentations are produced without any knowledge of spurious factors, via answer interventions only along causal rubrics, that are identified by querying an oracle LLM. Empirically, Crome significantly outperforms standard baselines on RewardBench, improving average accuracy by up to 5.4% and achieving gains of up to 13.2% and 7.2% in specific categories. The robustness of Crome is further testified by the consistent gains obtained in a Best-of-N inference setting across increasing N, across various benchmarks, including the popular RewardBench (covering chat, chat-hard, safety, and reasoning tasks), the safety-focused WildGuardTest, and the reasoning-specific GSM8k.",
    "authors": [
      "Srivastava, Pragya",
      "Singh, Harman",
      "Madhavan, Rahul",
      "Patil, Gandharv",
      "Addepalli, Sravanti",
      "Suggala, Arun",
      "Aravamudhan, Rengarajan",
      "Sharma, Soumya",
      "Laha, Anirban",
      "Raghuveer, Aravindan",
      "Shanmugam, Karthikeyan",
      "Precup, Doina"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16507",
      "TeX Source": "https://arxiv.org/src/2506.16507",
      "View PDF": "https://arxiv.org/pdf/2506.16507"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:59:47 UTC (1,199 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Robust Reward Modeling via Causal Rubrics",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.09707",
    "abstract": "Prolonged Exposure (PE) therapy is an effective treatment for post-traumatic stress disorder (PTSD), but evaluating therapist fidelity remains labor-intensive due to the need for manual review of session recordings. We present a method for the automatic temporal localization of key PE fidelity elements -- identifying their start and stop times -- directly from session audio and transcripts. Our approach fine-tunes a large pre-trained audio-language model, Qwen2-Audio, using Low-Rank Adaptation (LoRA) to process focused 30-second windows of audio-transcript input. Fidelity labels for three core protocol phases -- therapist orientation (P1), imaginal exposure (P2), and post-imaginal processing (P3) -- are generated via LLM-based prompting and verified by trained raters. The model is trained to predict normalized boundary offsets using soft supervision guided by task-specific prompts. On a dataset of 313 real PE sessions, our best configuration (LoRA rank 8, 30s windows) achieves a mean absolute error (MAE) of 5.3 seconds across tasks. We further analyze the effects of window size and LoRA rank, highlighting the importance of context granularity and model adaptation. This work introduces a scalable framework for fidelity tracking in PE therapy, with potential to support clinician training, supervision, and quality assurance.",
    "authors": [
      "BN, Suhas",
      "Sherrill, Andrew M.",
      "Alaparthi, Jyoti",
      "Mattioli, Dominik",
      "Arriaga, Rosa I.",
      "Wiese, Chris W.",
      "Abdullah, Saeed"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.09707v2",
      "Other Formats": "https://arxiv.org/format/2506.09707",
      "TeX Source": "https://arxiv.org/src/2506.09707",
      "View PDF": "https://arxiv.org/pdf/2506.09707"
    },
    "subjects": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 11 Jun 2025 13:21:06 UTC (1,662 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 19:02:49 UTC (1,662 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/11",
    "title": "Fine-Tuning Large Audio-Language Models with LoRA for Precise Temporal Localization of Prolonged Exposure Therapy Elements",
    "tasks": [
      "Temporal Localization"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16119",
    "abstract": "Video generation has made significant strides with the development of diffusion models; however, achieving high temporal consistency remains a challenging task. Recently, FreeInit identified a training-inference gap and introduced a method to iteratively refine the initial noise during inference. However, iterative refinement significantly increases the computational cost associated with video generation. In this paper, we introduce FastInit, a fast noise initialization method that eliminates the need for iterative refinement. FastInit learns a Video Noise Prediction Network (VNPNet) that takes random noise and a text prompt as input, generating refined noise in a single forward pass. Therefore, FastInit greatly enhances the efficiency of video generation while achieving high temporal consistency across frames. To train the VNPNet, we create a large-scale dataset consisting of pairs of text prompts, random noise, and refined noise. Extensive experiments with various text-to-video models show that our method consistently improves the quality and temporal consistency of the generated videos. FastInit not only provides a substantial improvement in video generation but also offers a practical solution that can be applied directly during inference. The code and dataset will be released.",
    "authors": [
      "Bai, Chengyu",
      "Li, Yuming",
      "Zhao, Zhongyu",
      "Chen, Jintao",
      "Jia, Peidong",
      "She, Qi",
      "Lu, Ming",
      "Zhang, Shanghang"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16119v1",
      "Other Formats": "https://arxiv.org/format/2506.16119",
      "TeX Source": "https://arxiv.org/src/2506.16119",
      "View PDF": "https://arxiv.org/pdf/2506.16119"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 08:11:45 UTC (36,728 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "FastInit: Fast Noise Initialization for Temporally Consistent Video Generation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2408.09251",
    "abstract": "Vehicle-to-everything (V2X) cooperation has emerged as a promising paradigm to overcome the perception limitations of classical autonomous driving by leveraging information from both ego-vehicle and infrastructure sensors. However, effectively fusing heterogeneous visual and semantic information while ensuring robust trajectory planning remains a significant challenge. This paper introduces V2X-VLM, a novel end-to-end (E2E) cooperative autonomous driving framework based on vision-language models (VLMs). V2X-VLM integrates multiperspective camera views from vehicles and infrastructure with text-based scene descriptions to enable a more comprehensive understanding of driving environments. Specifically, we propose a contrastive learning-based mechanism to reinforce the alignment of heterogeneous visual and textual characteristics, which enhances the semantic understanding of complex driving scenarios, and employ a knowledge distillation strategy to stabilize training. Experiments on a large real-world dataset demonstrate that V2X-VLM achieves state-of-the-art trajectory planning accuracy, significantly reducing L2 error and collision rate compared to existing cooperative autonomous driving baselines. Ablation studies validate the contributions of each component. Moreover, the evaluation of robustness and efficiency highlights the practicality of V2X-VLM for real-world deployment to enhance overall autonomous driving safety and decision-making.",
    "authors": [
      "You, Junwei",
      "Shi, Haotian",
      "Jiang, Zhuoyu",
      "Huang, Zilin",
      "Gan, Rui",
      "Wu, Keshu",
      "Cheng, Xi",
      "Li, Xiaopeng",
      "Ran, Bin"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2408.09251v3",
      "Other Formats": "https://arxiv.org/format/2408.09251",
      "TeX Source": "https://arxiv.org/src/2408.09251",
      "View PDF": "https://arxiv.org/pdf/2408.09251"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 17 Aug 2024 16:42:13 UTC (7,584 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 16 Sep 2024 05:23:07 UTC (8,981 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 05:02:13 UTC (13,602 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/08/17",
    "title": "V2X-VLM: End-to-End V2X Cooperative Autonomous Driving Through Large Vision-Language Models",
    "tasks": [
      "Autonomous Driving",
      "Contrastive Learning",
      "Decision Making",
      "Trajectory Planning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.01444",
    "abstract": "Backdoor attacks represent a subtle yet effective class of cyberattacks targeting AI models, primarily due to their stealthy nature. The model behaves normally on clean data but exhibits malicious behavior only when the attacker embeds a specific trigger into the input. This attack is performed during the training phase, where the adversary corrupts a small subset of the training data by embedding a pattern and modifying the labels to a chosen target. The objective is to make the model associate the pattern with the target label while maintaining normal performance on unaltered data. Several defense mechanisms have been proposed to sanitize training data-sets. However, these methods often rely on the availability of a clean dataset to compute statistical anomalies, which may not always be feasible in real-world scenarios where datasets can be unavailable or compromised. To address this limitation, we propose a novel defense method that trains a model on the given dataset, detects poisoned classes, and extracts the critical part of the attack trigger before identifying the poisoned instances. This approach enhances explainability by explicitly revealing the harmful part of the trigger. The effectiveness of our method is demonstrated through experimental evaluations on well-known image datasets and comparative analysis against three state-of-the-art algorithms: SCAn, ABL, and AGPD.",
    "authors": [
      "Aseervatham, Sujeevan",
      "Kerzazi, Achraf",
      "Bennani, Youn\u00e8s"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.01444v2",
      "Other Formats": "https://arxiv.org/format/2506.01444",
      "TeX Source": "https://arxiv.org/src/2506.01444",
      "View PDF": "https://arxiv.org/pdf/2506.01444"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 2 Jun 2025 09:01:35 UTC (58 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 14:44:06 UTC (140 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/02",
    "title": "Variance-Based Defense Against Blended Backdoor Attacks",
    "repo_urls": [
      "https://github.com/Orange-OpenSource/BackdoorBench"
    ],
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16064",
    "abstract": "Large language models (LLMs) have demonstrated robust capabilities across various natural language tasks. However, producing outputs that are consistently honest and helpful remains an open challenge. To overcome this challenge, this paper tackles the problem through two complementary directions. It conducts a comprehensive benchmark evaluation of ten widely used large language models, including both proprietary and open-weight models from OpenAI, Meta, and Google. In parallel, it proposes a novel prompting strategy, self-critique-guided curiosity refinement prompting. The key idea behind this strategy is enabling models to self-critique and refine their responses without additional training. The proposed method extends the curiosity-driven prompting strategy by incorporating two lightweight in-context steps including self-critique step and refinement step. The experiment results on the HONESET dataset evaluated using the framework $\\mathrm{H}^2$ (honesty and helpfulness), which was executed with GPT-4o as a judge of honesty and helpfulness, show consistent improvements across all models. The approach reduces the number of poor-quality responses, increases high-quality responses, and achieves relative gains in $\\mathrm{H}^2$ scores ranging from 1.4% to 4.3% compared to curiosity-driven prompting across evaluated models. These results highlight the effectiveness of structured self-refinement as a scalable and training-free strategy to improve the trustworthiness of LLMs outputs.",
    "authors": [
      "Ho, Duc Hieu",
      "Fan, Chenglin"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16064",
      "TeX Source": "https://arxiv.org/src/2506.16064",
      "View PDF": "https://arxiv.org/pdf/2506.16064"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 06:42:35 UTC (134 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.11478",
    "abstract": "In high-noise environments such as factories, subways, and busy streets, capturing clear speech is challenging. Throat microphones can offer a solution because of their inherent noise-suppression capabilities; however, the passage of sound waves through skin and tissue attenuates high-frequency information, reducing speech clarity. Recent deep learning approaches have shown promise in enhancing throat microphone recordings, but further progress is constrained by the lack of a standard dataset. Here, we introduce the Throat and Acoustic Paired Speech (TAPS) dataset, a collection of paired utterances recorded from 60 native Korean speakers using throat and acoustic microphones. Furthermore, an optimal alignment approach was developed and applied to address the inherent signal mismatch between the two microphones. We tested three baseline deep learning models on the TAPS dataset and found mapping-based approaches to be superior for improving speech quality and restoring content. These findings demonstrate the TAPS dataset's utility for speech enhancement tasks and support its potential as a standard resource for advancing research in throat microphone-based applications.",
    "authors": [
      "Kim, Yunsik",
      "Song, Yonghun",
      "Chung, Yoonyoung"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.11478v2",
      "Other Formats": "https://arxiv.org/format/2502.11478",
      "TeX Source": "https://arxiv.org/src/2502.11478",
      "View PDF": "https://arxiv.org/pdf/2502.11478"
    },
    "subjects": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 17 Feb 2025 06:29:11 UTC (3,630 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 03:31:40 UTC (2,778 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/17",
    "title": "TAPS: Throat and Acoustic Paired Speech Dataset for Deep Learning-Based Speech Enhancement",
    "tasks": [
      "Speech Enhancement"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2503.01807",
    "abstract": "Selecting high-quality training data from a larger pool is a crucial step when instruction-tuning language models, as carefully curated datasets often produce models that outperform those trained on much larger, noisier datasets. Automated data selection approaches for instruction-tuning are typically tested by selecting small datasets (roughly 10k samples) from small pools (100-200k samples). However, popular deployed instruction-tuned models often train on hundreds of thousands to millions of samples, subsampled from even larger data pools. We present a systematic study of how well data selection methods scale to these settings, selecting up to 2.5M samples from pools of up to 5.8M samples and evaluating across 7 diverse tasks. We show that many recently proposed methods fall short of random selection in this setting (while using more compute), and even decline in performance when given access to larger pools of data to select over. However, we find that a variant of representation-based data selection (RDS+), which uses weighted mean pooling of pretrained LM hidden states, consistently outperforms more complex methods across all settings tested -- all whilst being more compute-efficient. Our findings highlight that the scaling properties of proposed automated selection methods should be more closely examined. We release our code, data, and models at https://github.com/hamishivi/automated-instruction-selection.",
    "authors": [
      "Ivison, Hamish",
      "Zhang, Muru",
      "Brahman, Faeze",
      "Koh, Pang Wei",
      "Dasigi, Pradeep"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.01807v2",
      "Other Formats": "https://arxiv.org/format/2503.01807",
      "TeX Source": "https://arxiv.org/src/2503.01807",
      "View PDF": "https://arxiv.org/pdf/2503.01807"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 3 Mar 2025 18:37:26 UTC (8,886 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 04:19:15 UTC (9,531 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/03/03",
    "title": "Large-Scale Data Selection for Instruction Tuning",
    "repo_urls": [
      "https://github.com/hamishivi/automated-instruction-selection"
    ],
    "tasks": [],
    "datasets": [
      {
        "dataset_name": "hamishivi/rds-sels-tulu-3-multitask-rrmax-939k",
        "downloads": "50",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-tulu-3-multitask-rrmax-939k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-tulu-3-arena-hard-939k",
        "downloads": "50",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-tulu-3-arena-hard-939k"
      },
      {
        "dataset_name": "hamishivi/lsds_data",
        "downloads": "34",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/lsds_data"
      },
      {
        "dataset_name": "hamishivi/rds-sels-alpacafarm-top326k",
        "downloads": "14",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-alpacafarm-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-arena-hard-top326k",
        "downloads": "28",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-arena-hard-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-codex-top326k",
        "downloads": "13",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-codex-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-bbh-shots-top326k",
        "downloads": "10",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-bbh-shots-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-gsm8k-shots-top326k",
        "downloads": "37",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-gsm8k-shots-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-mmlu-shots-top326k",
        "downloads": "8",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-mmlu-shots-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-squad-top326k",
        "downloads": "19",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-squad-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-tydiqa-shots-top326k",
        "downloads": "19",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-tydiqa-shots-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-wildchat-top326k",
        "downloads": "21",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-wildchat-top326k"
      },
      {
        "dataset_name": "hamishivi/rds-sels-multitask-rrmax-top326k",
        "downloads": "25",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/rds-sels-multitask-rrmax-top326k"
      },
      {
        "dataset_name": "hamishivi/tulu-2-unfiltered",
        "downloads": "127",
        "likes": "1",
        "link": "https://huggingface.co/datasets/hamishivi/tulu-2-unfiltered"
      },
      {
        "dataset_name": "hamishivi/tulu-3-unfiltered",
        "downloads": "49",
        "likes": "1",
        "link": "https://huggingface.co/datasets/hamishivi/tulu-3-unfiltered"
      },
      {
        "dataset_name": "hamishivi/200k-tulu-2-unbalanced",
        "downloads": "39",
        "likes": "0",
        "link": "https://huggingface.co/datasets/hamishivi/200k-tulu-2-unbalanced"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16101",
    "abstract": "Regression testing plays a critical role in maintaining software reliability, particularly for ROS-based autonomous systems (ROSAS), which frequently undergo continuous integration and iterative development. However, conventional regression testing techniques face significant challenges when applied to autonomous systems due to their dynamic and non-deterministic behaviors, complex multi-modal sensor data, asynchronous distributed architectures, and stringent safety and real-time constraints. Although numerous studies have explored test optimization in traditional software contexts, regression testing optimization specifically for ROSAS remains largely unexplored. To address this gap, we present the first comprehensive survey systematically reviewing regression testing optimization techniques tailored for ROSAS. We analyze and categorize 122 representative studies into regression test case prioritization, minimization, and selection methods. A structured taxonomy is introduced to clearly illustrate their applicability and limitations within ROSAS contexts. Furthermore, we highlight major challenges specific to regression testing for ROSAS, including effectively prioritizing tests in response to frequent system modifications, efficiently minimizing redundant tests, and difficulty in accurately selecting impacted test cases. Finally, we propose research insights and identify promising future directions, such as leveraging frame-to-vector coverage metrics, multi-source foundation models, and neurosymbolic reasoning to enhance regression testing efficiency and effectiveness. This survey provides a foundational reference and practical roadmap for advancing the state-of-the-art in regression testing optimization for ROSAS.",
    "authors": [
      "Jiang, Yupeng",
      "Sun, Shuaiyi",
      "Zheng, Xi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16101v1",
      "Other Formats": "https://arxiv.org/format/2506.16101",
      "TeX Source": "https://arxiv.org/src/2506.16101",
      "View PDF": "https://arxiv.org/pdf/2506.16101"
    },
    "subjects": [
      "Software Engineering (cs.SE)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 07:43:36 UTC (1,336 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15937",
    "abstract": "Video synchronization-aligning multiple video streams capturing the same event from different angles-is crucial for applications such as reality TV show production, sports analysis, surveillance, and autonomous systems. Prior work has heavily relied on audio cues or specific visual events, limiting applicability in diverse settings where such signals may be unreliable or absent. Additionally, existing benchmarks for video synchronization lack generality and reproducibility, restricting progress in the field. In this work, we introduce VideoSync, a video synchronization framework that operates independently of specific feature extraction methods, such as human pose estimation, enabling broader applicability across different content types. We evaluate our system on newly composed datasets covering single-human, multi-human, and non-human scenarios, providing both the methodology and code for dataset creation to establish reproducible benchmarks. Our analysis reveals biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline, leading to inflated performance claims. We correct these biases and propose a more rigorous evaluation framework, demonstrating that VideoSync outperforms existing approaches, including SeSyn-Net, under fair experimental conditions. Additionally, we explore various synchronization offset prediction methods, identifying a convolutional neural network (CNN)-based model as the most effective. Our findings advance video synchronization beyond domain-specific constraints, making it more generalizable and robust for real-world applications.",
    "authors": [
      "Shin, Yosub",
      "Molybog, Igor"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15937v1",
      "Other Formats": "https://arxiv.org/format/2506.15937",
      "TeX Source": "https://arxiv.org/src/2506.15937",
      "View PDF": "https://arxiv.org/pdf/2506.15937"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 00:41:21 UTC (401 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16209",
    "abstract": "Being able to generate realistic trajectory options is at the core of increasing the degree of automation of road vehicles. While model-driven, rule-based, and classical learning-based methods are widely used to tackle these tasks at present, they can struggle to effectively capture the complex, multimodal distributions of future trajectories. In this paper we investigate whether a generative adversarial network (GAN) trained on videos of bird's-eye view (BEV) traffic scenarios can generate statistically accurate trajectories that correctly capture spatial relationships between the agents. To this end, we propose a pipeline that uses low-resolution BEV occupancy grid videos as training data for a video generative model. From the generated videos of traffic scenarios we extract abstract trajectory data using single-frame object detection and frame-to-frame object matching. We particularly choose a GAN architecture for the fast training and inference times with respect to diffusion models. We obtain our best results within 100 GPU hours of training, with inference times under 20\\,ms. We demonstrate the physical realism of the proposed trajectories in terms of distribution alignment of spatial and dynamic parameters with respect to the ground truth videos from the Waymo Open Motion Dataset.",
    "authors": [
      "Mariani, Annajoyce",
      "Maag, Kira",
      "Gottschalk, Hanno"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16209v1",
      "Other Formats": "https://arxiv.org/format/2506.16209",
      "TeX Source": "https://arxiv.org/src/2506.16209",
      "View PDF": "https://arxiv.org/pdf/2506.16209"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 10:57:44 UTC (4,909 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "VideoGAN-based Trajectory Proposal for Automated Vehicles",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16601",
    "abstract": "Image Quality Assessment (IQA) is a critical task in a wide range of applications but remains challenging due to the subjective nature of human perception and the complexity of real-world image distortions. This study proposes MetaQAP, a novel no-reference IQA model designed to address these challenges by leveraging quality-aware pre-training and meta-learning. The model performs three key contributions: pre-training Convolutional Neural Networks (CNNs) on a quality-aware dataset, implementing a quality-aware loss function to optimize predictions, and integrating a meta-learner to form an ensemble model that effectively combines predictions from multiple base models. Experimental evaluations were conducted on three benchmark datasets: LiveCD, KonIQ-10K, and BIQ2021. The proposed MetaQAP model achieved exceptional performance with Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank Order Correlation Coefficient (SROCC) scores of 0.9885/0.9812 on LiveCD, 0.9702/0.9658 on KonIQ-10K, and 0.884/0.8765 on BIQ2021, outperforming existing IQA methods. Cross-dataset evaluations further demonstrated the generalizability of the model, with PLCC and SROCC scores ranging from 0.6721 to 0.8023 and 0.6515 to 0.7805, respectively, across diverse datasets. The ablation study confirmed the significance of each model component, revealing substantial performance degradation when critical elements such as the meta-learner or quality-aware loss function were omitted. MetaQAP not only addresses the complexities of authentic distortions but also establishes a robust and generalizable framework for practical IQA applications. By advancing the state-of-the-art in no-reference IQA, this research provides valuable insights and methodologies for future improvements and extensions in the field.",
    "authors": [
      "Aslam, Muhammad Azeem",
      "Hamza, Muhammad",
      "Ahmed, Nisar",
      "Saleem, Gulshan",
      "Shuangtong, Zhu",
      "Hongfei, Hu",
      "Wei, Xu",
      "Aslam, Saba",
      "Jun, Wang"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16601v1",
      "Other Formats": "https://arxiv.org/format/2506.16601",
      "TeX Source": "https://arxiv.org/src/2506.16601",
      "View PDF": "https://arxiv.org/pdf/2506.16601"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 21:03:47 UTC (910 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16256",
    "abstract": "Being born small carries significant health risks, including increased neonatal mortality and a higher likelihood of future cardiac diseases. Accurate estimation of gestational age is critical for monitoring fetal growth, but traditional methods, such as estimation based on the last menstrual period, are in some situations difficult to obtain. While ultrasound-based approaches offer greater reliability, they rely on manual measurements that introduce variability. This study presents an interpretable deep learning-based method for automated gestational age calculation, leveraging a novel segmentation architecture and distance maps to overcome dataset limitations and the scarcity of segmentation masks. Our approach achieves performance comparable to state-of-the-art models while reducing complexity, making it particularly suitable for resource-constrained settings and with limited annotated data. Furthermore, our results demonstrate that the use of distance maps is particularly suitable for estimating femur endpoints.",
    "authors": [
      "D\u00edaz-Parga, C\u00e9sar",
      "Nu\u00f1ez-Garcia, Marta",
      "Carreira, Maria J.",
      "Bernardino, Gabriel",
      "Vila-Blanco, Nicol\u00e1s"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16256v1",
      "Other Formats": "https://arxiv.org/format/2506.16256",
      "TeX Source": "https://arxiv.org/src/2506.16256",
      "View PDF": "https://arxiv.org/pdf/2506.16256"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 12:15:06 UTC (399 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "AGE-US: automated gestational age estimation based on fetal ultrasound images",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.09965",
    "abstract": "As textual reasoning with large language models (LLMs) has advanced significantly, there has been growing interest in enhancing the multimodal reasoning capabilities of large vision-language models (LVLMs). However, existing methods primarily approach multimodal reasoning in a straightforward, text-centric manner, where both reasoning and answer derivation are conducted purely through text, with the only difference being the presence of multimodal input. As a result, these methods often encounter fundamental limitations in spatial reasoning tasks that demand precise geometric understanding and continuous spatial tracking-capabilities that humans achieve through mental visualization and manipulation. To address the limitations, we propose drawing to reason in space, a novel paradigm that enables LVLMs to reason through elementary drawing operations in the visual space. By equipping models with basic drawing operations, including annotating bounding boxes and drawing auxiliary lines, we empower them to express and analyze spatial relationships through direct visual manipulation, meanwhile avoiding the performance ceiling imposed by specialized perception tools in previous tool-integrated reasoning approaches. To cultivate this capability, we develop a three-stage training framework: cold-start training with synthetic data to establish basic drawing abilities, reflective rejection sampling to enhance self-reflection behaviors, and reinforcement learning to directly optimize for target rewards. Extensive experiments demonstrate that our model, named VILASR, consistently outperforms existing methods across diverse spatial reasoning benchmarks, involving maze navigation, static spatial reasoning, video-based reasoning, and multi-view-based reasoning tasks, with an average improvement of 18.4%.",
    "authors": [
      "Wu, Junfei",
      "Guan, Jian",
      "Feng, Kaituo",
      "Liu, Qiang",
      "Wu, Shu",
      "Wang, Liang",
      "Wu, Wei",
      "Tan, Tieniu"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.09965v2",
      "Other Formats": "https://arxiv.org/format/2506.09965",
      "TeX Source": "https://arxiv.org/src/2506.09965",
      "View PDF": "https://arxiv.org/pdf/2506.09965"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 11 Jun 2025 17:41:50 UTC (3,722 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 03:46:55 UTC (3,722 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/11",
    "title": "Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing",
    "repo_urls": [
      "https://github.com/antresearchnlp/vilasr"
    ],
    "tasks": [
      "Multimodal Reasoning",
      "Spatial Reasoning"
    ],
    "datasets": [
      {
        "dataset_name": "RunsenXu/MMSI-Bench",
        "downloads": "397",
        "likes": "5",
        "link": "https://huggingface.co/datasets/RunsenXu/MMSI-Bench"
      },
      {
        "dataset_name": "AntResearchNLP/ViLaSR-data",
        "downloads": "45",
        "likes": "0",
        "link": "https://huggingface.co/datasets/AntResearchNLP/ViLaSR-data"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.15699",
    "abstract": "Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance.",
    "authors": [
      "Wang, Ning",
      "Yan, Zihan",
      "Li, Weiyang",
      "Ma, Chuan",
      "Chen, He",
      "Xiang, Tao"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.15699v3",
      "Other Formats": "https://arxiv.org/format/2504.15699",
      "TeX Source": "https://arxiv.org/src/2504.15699",
      "View PDF": "https://arxiv.org/pdf/2504.15699"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 22 Apr 2025 08:34:35 UTC (3,127 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 8 May 2025 09:12:22 UTC (1,035 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 04:21:00 UTC (2,290 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/04/22",
    "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.14111",
    "abstract": "Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0",
    "authors": [
      "AI, Essential",
      ":",
      "Hojel, Andrew",
      "Pust, Michael",
      "Romanski, Tim",
      "Vanjani, Yash",
      "Kapila, Ritvik",
      "Parmar, Mohit",
      "Chaluvaraju, Adarsh",
      "Tripathy, Alok",
      "Thomas, Anil",
      "Tanwer, Ashish",
      "Shah, Darsh J",
      "Shah, Ishaan",
      "Stratos, Karl",
      "Nguyen, Khoi",
      "Smith, Kurt",
      "Callahan, Michael",
      "Rushton, Peter",
      "Monk, Philip",
      "Mazarakis, Platon",
      "Jamal, Saad",
      "Srivastava, Saurabh",
      "Singla, Somanshu",
      "Vaswani, Ashish"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.14111",
      "TeX Source": "https://arxiv.org/src/2506.14111",
      "View PDF": "https://arxiv.org/pdf/2506.14111"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 17 Jun 2025 02:03:36 UTC (2,307 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 19:02:41 UTC (2,307 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/17",
    "title": "Essential-Web v1.0: 24T tokens of organized web data",
    "tasks": [
      "Math"
    ],
    "datasets": [
      {
        "dataset_name": "EssentialAI/eai-taxonomy-stem-w-dclm-100b-sample",
        "downloads": "465",
        "likes": "2",
        "link": "https://huggingface.co/datasets/EssentialAI/eai-taxonomy-stem-w-dclm-100b-sample"
      },
      {
        "dataset_name": "EssentialAI/eai-taxonomy-med-w-dclm-100b-sample",
        "downloads": "1146",
        "likes": "2",
        "link": "https://huggingface.co/datasets/EssentialAI/eai-taxonomy-med-w-dclm-100b-sample"
      },
      {
        "dataset_name": "EssentialAI/eai-taxonomy-code-w-dclm-100b-sample",
        "downloads": "412",
        "likes": "2",
        "link": "https://huggingface.co/datasets/EssentialAI/eai-taxonomy-code-w-dclm-100b-sample"
      },
      {
        "dataset_name": "EssentialAI/essential-web-v1.0",
        "downloads": "65562",
        "likes": "130",
        "link": "https://huggingface.co/datasets/EssentialAI/essential-web-v1.0"
      },
      {
        "dataset_name": "EssentialAI/eai-taxonomy-code-w-dclm",
        "downloads": "6426",
        "likes": "7",
        "link": "https://huggingface.co/datasets/EssentialAI/eai-taxonomy-code-w-dclm"
      },
      {
        "dataset_name": "EssentialAI/eai-taxonomy-math-w-fm",
        "downloads": "1722",
        "likes": "6",
        "link": "https://huggingface.co/datasets/EssentialAI/eai-taxonomy-math-w-fm"
      },
      {
        "dataset_name": "EssentialAI/eai-taxonomy-med-w-dclm",
        "downloads": "3107",
        "likes": "6",
        "link": "https://huggingface.co/datasets/EssentialAI/eai-taxonomy-med-w-dclm"
      },
      {
        "dataset_name": "EssentialAI/eai-taxonomy-stem-w-dclm",
        "downloads": "11235",
        "likes": "4",
        "link": "https://huggingface.co/datasets/EssentialAI/eai-taxonomy-stem-w-dclm"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16558",
    "abstract": "Automatic Speech Recognition (ASR) systems struggle with regional dialects due to biased training which favours mainstream varieties. While previous research has identified racial, age, and gender biases in ASR, regional bias remains underexamined. This study investigates ASR performance on Newcastle English, a well-documented regional dialect known to be challenging for ASR. A two-stage analysis was conducted: first, a manual error analysis on a subsample identified key phonological, lexical, and morphosyntactic errors behind ASR misrecognitions; second, a case study focused on the systematic analysis of ASR recognition of the regional pronouns ``yous'' and ``wor''. Results show that ASR errors directly correlate with regional dialectal features, while social factors play a lesser role in ASR mismatches. We advocate for greater dialectal diversity in ASR training data and highlight the value of sociolinguistic analysis in diagnosing and addressing regional biases.",
    "authors": [
      "Serditova, Dana",
      "Tang, Kevin",
      "Steffens, Jochen"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16558v1",
      "Other Formats": "https://arxiv.org/format/2506.16558",
      "TeX Source": "https://arxiv.org/src/2506.16558",
      "View PDF": "https://arxiv.org/pdf/2506.16558"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 19:24:12 UTC (210 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Automatic Speech Recognition Biases in Newcastle English: an Error Analysis",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2308.12053",
    "abstract": "Gradient-based optimization has been a cornerstone of machine learning that enabled the vast advances of Artificial Intelligence (AI) development over the past decades. However, this type of optimization requires differentiation, and with recent evidence of the benefits of non-differentiable (e.g. neuromorphic) architectures over classical models w.r.t. efficiency, such constraints can become limiting in the future. We present Layer-wise Feedback Propagation (LFP), a novel training principle for neural network-like predictors that utilizes methods from the domain of explainability to decompose a reward to individual neurons based on their respective contributions. Leveraging these neuron-wise rewards, our method then implements a greedy approach reinforcing helpful parts of the network and weakening harmful ones. While having comparable computational complexity to gradient descent, LFP does not require gradient computation and generates sparse and thereby memory- and energy-efficient parameter updates and models. We establish the convergence of LFP theoretically and empirically, demonstrating its effectiveness on various models and datasets. Via two applications - neural network pruning and the approximation-free training of Spiking Neural Networks (SNNs) - we demonstrate that LFP combines increased efficiency in terms of computation and representation with flexibility w.r.t. choice of model architecture and objective function. Our code is available at https://github.com/leanderweber/layerwise-feedback-propagation.",
    "authors": [
      "Weber, Leander",
      "Berend, Jim",
      "Weckbecker, Moritz",
      "Binder, Alexander",
      "Wiegand, Thomas",
      "Samek, Wojciech",
      "Lapuschkin, Sebastian"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2308.12053",
      "TeX Source": "https://arxiv.org/src/2308.12053",
      "View PDF": "https://arxiv.org/pdf/2308.12053"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 23 Aug 2023 10:48:28 UTC (1,456 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 5 Feb 2025 20:37:52 UTC (6,049 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 13:57:46 UTC (7,447 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2023/08/23",
    "title": "Efficient and Flexible Neural Network Training through Layer-wise Feedback Propagation",
    "repo_urls": [
      "https://github.com/leanderweber/layerwise-feedback-propagation"
    ],
    "tasks": [
      "Network Pruning",
      "Transfer Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2501.12919",
    "abstract": "Understanding structure-property relationships is an essential yet challenging aspect of materials discovery and development. To facilitate this process, recent studies in materials informatics have sought latent embedding spaces of crystal structures to capture their similarities based on properties and functionalities. However, abstract feature-based embedding spaces are human-unfriendly and prevent intuitive and efficient exploration of the vast materials space. Here we introduce Contrastive Language--Structure Pre-training (CLaSP), a learning paradigm for constructing crossmodal embedding spaces between crystal structures and texts. CLaSP aims to achieve material embeddings that 1) capture property- and functionality-related similarities between crystal structures and 2) allow intuitive retrieval of materials via user-provided description texts as queries. To compensate for the lack of sufficient datasets linking crystal structures with textual descriptions, CLaSP leverages a dataset of over 400,000 published crystal structures and corresponding publication records, including paper titles and abstracts, for training. We demonstrate the effectiveness of CLaSP through text-based crystal structure screening and embedding space visualization.",
    "authors": [
      "Suzuki, Yuta",
      "Taniai, Tatsunori",
      "Igarashi, Ryo",
      "Saito, Kotaro",
      "Chiba, Naoya",
      "Ushiku, Yoshitaka",
      "Ono, Kanta"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2501.12919v2",
      "Other Formats": "https://arxiv.org/format/2501.12919",
      "TeX Source": "https://arxiv.org/src/2501.12919",
      "View PDF": "https://arxiv.org/pdf/2501.12919"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 22 Jan 2025 14:47:59 UTC (9,992 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 02:21:04 UTC (6,644 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/01/22",
    "title": "Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science",
    "tasks": [
      "Efficient Exploration"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16032",
    "abstract": "Tensor decompositions, which represent an $N$-order tensor using approximately $N$ factors of much smaller dimensions, can significantly reduce the number of parameters. This is particularly beneficial for high-order tensors, as the number of entries in a tensor grows exponentially with the order. Consequently, they are widely used in signal recovery and data analysis across domains such as signal processing, machine learning, and quantum physics. A computationally and memory-efficient approach to these problems is to optimize directly over the factors using local search algorithms such as gradient descent, a strategy known as the factorization approach in matrix and tensor optimization. However, the resulting optimization problems are highly nonconvex due to the multiplicative interactions between factors, posing significant challenges for convergence analysis and recovery guarantees. In this paper, we present a unified framework for the factorization approach to solving various tensor decomposition problems. Specifically, by leveraging the canonical form of tensor decompositions--where most factors are constrained to be orthonormal to mitigate scaling ambiguity--we apply Riemannian gradient descent (RGD) to optimize these orthonormal factors on the Stiefel manifold. Under a mild condition on the loss function, we establish a Riemannian regularity condition for the factorized objective and prove that RGD converges to the ground-truth tensor at a linear rate when properly initialized. Notably, both the initialization requirement and the convergence rate scale polynomially rather than exponentially with $N$, improving upon existing results for Tucker and tensor-train format tensors.",
    "authors": [
      "Qin, Zhen",
      "Wakin, Michael B.",
      "Zhu, Zhihui"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16032v1",
      "Other Formats": "https://arxiv.org/format/2506.16032",
      "TeX Source": "https://arxiv.org/src/2506.16032",
      "View PDF": "https://arxiv.org/pdf/2506.16032"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 05:07:07 UTC (87 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "A Scalable Factorization Approach for High-Order Structured Tensor Recovery",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16213",
    "abstract": "Segmenting anatomical structures in medical images plays an important role in the quantitative assessment of various diseases. However, accurate segmentation becomes significantly more challenging in the presence of disease. Disease patterns can alter the appearance of surrounding healthy tissues, introduce ambiguous boundaries, or even obscure critical anatomical structures. As such, segmentation models trained on real-world datasets may struggle to provide good anatomical segmentation, leading to potential misdiagnosis. In this paper, we generate counterfactual (CF) images to simulate how the same anatomy would appear in the absence of disease without altering the underlying structure. We then use these CF images to segment structures of interest, without requiring any changes to the underlying segmentation model. Our experiments on two real-world clinical chest X-ray datasets show that the use of counterfactual images improves anatomical segmentation, thereby aiding downstream clinical decision-making.",
    "authors": [
      "Mehta, Raghav",
      "Ribeiro, Fabio De Sousa",
      "Xia, Tian",
      "Roschewitz, Melanie",
      "Santhirasekaram, Ainkaran",
      "Marshall, Dominic C.",
      "Glocker, Ben"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16213v1",
      "Other Formats": "https://arxiv.org/format/2506.16213",
      "TeX Source": "https://arxiv.org/src/2506.16213",
      "View PDF": "https://arxiv.org/pdf/2506.16213"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 11:01:33 UTC (856 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "CF-Seg: Counterfactuals meet Segmentation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2310.04585",
    "abstract": "I study statistical discrimination driven by verifiable beliefs, such as those generated by machine learning, rather than by humans. When beliefs are verifiable, interventions against statistical discrimination can move beyond simple, belief-free designs like affirmative action, to more sophisticated ones, that constrain decision makers based on what they are thinking. I design a belief-contingent intervention I call common identity. I show that it is effective at eliminating equilibrium statistical discrimination, even when training data exhibit the various statistical biases that often plague algorithmic decision problems.",
    "authors": [
      "Zhu, John Y."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2310.04585v4",
      "Other Formats": "https://arxiv.org/format/2310.04585",
      "TeX Source": "https://arxiv.org/src/2310.04585",
      "View PDF": "https://arxiv.org/pdf/2310.04585"
    },
    "subjects": [
      "Theoretical Economics (econ.TH)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 6 Oct 2023 20:57:34 UTC (33 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 15 Jan 2024 21:54:35 UTC (47 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 11 Jul 2024 20:01:41 UTC (50 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Thu, 19 Jun 2025 11:13:41 UTC (45 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2023/10/06",
    "title": "Interventions Against Machine-Assisted Statistical Discrimination",
    "tasks": [
      "Fairness"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.16975",
    "abstract": "Large Language Models (LLMs) have shown strong capability in diverse software engineering tasks, e.g. code completion, bug fixing, and document generation. However, feature-driven development (FDD), a highly prevalent real-world task that involves developing new functionalities for large, existing codebases, remains underexplored. We therefore introduce SWE-Dev, the first large-scale dataset (with 14,000 training and 500 test samples) designed to evaluate and train autonomous coding systems on real-world feature development tasks. To ensure verifiable and diverse training, SWE-Dev uniquely provides all instances with a runnable environment and its developer-authored executable unit tests. This collection not only provides high-quality data for Supervised Fine-Tuning (SFT), but also enables Reinforcement Learning (RL) by delivering accurate reward signals from executable unit tests. Our extensive evaluations on SWE-Dev, covering 17 chatbot LLMs, 10 reasoning models, and 10 Multi-Agent Systems (MAS), reveal that FDD is a profoundly challenging frontier for current AI (e.g., Claude-3.7-Sonnet achieves only 22.45\\% Pass@3 on the hard test split). Crucially, we demonstrate that SWE-Dev serves as an effective platform for model improvement: fine-tuning on training set enabled a 7B model comparable to GPT-4o on \\textit{hard} split, underscoring the value of its high-quality training data. Code is available here \\href{https://github.com/DorothyDUUU/SWE-Dev}{https://github.com/DorothyDUUU/SWE-Dev}.",
    "authors": [
      "Du, Yaxin",
      "Cai, Yuzhu",
      "Zhou, Yifan",
      "Wang, Cheng",
      "Qian, Yu",
      "Pang, Xianghe",
      "Liu, Qian",
      "Hu, Yue",
      "Chen, Siheng"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.16975v2",
      "Other Formats": "https://arxiv.org/format/2505.16975",
      "TeX Source": "https://arxiv.org/src/2505.16975",
      "View PDF": "https://arxiv.org/pdf/2505.16975"
    },
    "subjects": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 22 May 2025 17:51:49 UTC (6,655 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 17:54:44 UTC (5,268 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/22",
    "title": "SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development",
    "tasks": [
      "Bug fixing",
      "Chatbot",
      "Code Completion",
      "Reinforcement Learning (RL)"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12113",
    "abstract": "In a context of malware analysis, numerous approaches rely on Artificial Intelligence to handle a large volume of data. However, these techniques focus on data view (images, sequences) and not on an expert's view. Noticing this issue, we propose a preprocessing that focuses on expert knowledge to improve malware semantic analysis and result interpretability. We propose a new preprocessing method which creates JSON reports for Portable Executable files. These reports gather features from both static and behavioral analysis, and incorporate packer signature detection, MITRE ATT\\&CK and Malware Behavior Catalog (MBC) knowledge. The purpose of this preprocessing is to gather a semantic representation of binary files, understandable by malware analysts, and that can enhance AI models' explainability for malicious files analysis. Using this preprocessing to train a Large Language Model for Malware classification, we achieve a weighted-average F1-score of 0.94 on a complex dataset, representative of market reality.",
    "authors": [
      "Marais, Benjamin",
      "Quertier, Tony",
      "Barrue, Gr\u00e9goire"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12113v2",
      "Other Formats": "https://arxiv.org/format/2506.12113",
      "TeX Source": "https://arxiv.org/src/2506.12113",
      "View PDF": "https://arxiv.org/pdf/2506.12113"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 13 Jun 2025 13:39:00 UTC (484 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 09:55:01 UTC (566 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/13",
    "title": "Semantic Preprocessing for LLM-based Malware Analysis",
    "tasks": [
      "Language Modeling",
      "Language Modelling",
      "Large Language Model",
      "Malware Analysis",
      "Malware Classification"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16251",
    "abstract": "The scarcity of high-quality annotated data presents a significant challenge in developing effective end-to-end speech-to-text translation (ST) systems, particularly for low-resource languages. This paper explores the hypothesis that weakly labeled data can be used to build ST models for low-resource language pairs. We constructed speech-to-text translation datasets with the help of bitext mining using state-of-the-art sentence encoders. We mined the multilingual Shrutilipi corpus to build Shrutilipi-anuvaad, a dataset comprising ST data for language pairs Bengali-Hindi, Malayalam-Hindi, Odia-Hindi, and Telugu-Hindi. We created multiple versions of training data with varying degrees of quality and quantity to investigate the effect of quality versus quantity of weakly labeled data on ST model performance. Results demonstrate that ST systems can be built using weakly labeled data, with performance comparable to massive multi-modal multilingual baselines such as SONAR and SeamlessM4T.",
    "authors": [
      "Pothula, Aishwarya",
      "Akkiraju, Bhavana",
      "Bandarupalli, Srihari",
      "D, Charan",
      "Kesiraju, Santosh",
      "Vuppala, Anil Kumar"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16251v1",
      "Other Formats": "https://arxiv.org/format/2506.16251",
      "TeX Source": "https://arxiv.org/src/2506.16251",
      "View PDF": "https://arxiv.org/pdf/2506.16251"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 12:11:01 UTC (225 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "End-to-End Speech Translation for Low-Resource Languages Using Weakly Labeled Data",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16151",
    "abstract": "Language is not only a tool for communication but also a medium for human cognition and reasoning. If, as linguistic relativity suggests, the structure of language shapes cognitive patterns, then large language models (LLMs) trained on human language may also internalize the habitual logical structures embedded in different languages. To examine this hypothesis, we introduce BICAUSE, a structured bilingual dataset for causal reasoning, which includes semantically aligned Chinese and English samples in both forward and reversed causal forms. Our study reveals three key findings: (1) LLMs exhibit typologically aligned attention patterns, focusing more on causes and sentence-initial connectives in Chinese, while showing a more balanced distribution in English. (2) Models internalize language-specific preferences for causal word order and often rigidly apply them to atypical inputs, leading to degraded performance, especially in Chinese. (3) When causal reasoning succeeds, model representations converge toward semantically aligned abstractions across languages, indicating a shared understanding beyond surface form. Overall, these results suggest that LLMs not only mimic surface linguistic forms but also internalize the reasoning biases shaped by language. Rooted in cognitive linguistic theory, this phenomenon is for the first time empirically verified through structural analysis of model internals.",
    "authors": [
      "Wang, Chenxi",
      "Zhang, Yixuan",
      "Gao, Lang",
      "Xu, Zixiang",
      "Song, Zirui",
      "Wang, Yanbo",
      "Chen, Xiuying"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16151v1",
      "Other Formats": "https://arxiv.org/format/2506.16151",
      "TeX Source": "https://arxiv.org/src/2506.16151",
      "View PDF": "https://arxiv.org/pdf/2506.16151"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 09:06:38 UTC (776 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Under the Shadow of Babel: How Language Shapes Reasoning in LLMs",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16388",
    "abstract": "This paper presents our approach to multi-label emotion detection in Hausa, a low-resource African language, as part of SemEval Track A. We fine-tuned AfriBERTa, a transformer-based model pre-trained on African languages, to classify Hausa text into six emotions: anger, disgust, fear, joy, sadness, and surprise. Our methodology involved data preprocessing, tokenization, and model fine-tuning using the Hugging Face Trainer API. The system achieved a validation accuracy of 74.00%, with an F1-score of 73.50%, demonstrating the effectiveness of transformer-based models for emotion detection in low-resource languages.",
    "authors": [
      "Sani, Sani Abdullahi",
      "Abubakar, Salim",
      "Lawan, Falalu Ibrahim",
      "Abubakar, Abdulhamid",
      "Bala, Maryam"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16388v1",
      "Other Formats": "https://arxiv.org/format/2506.16388",
      "TeX Source": "https://arxiv.org/src/2506.16388",
      "View PDF": "https://arxiv.org/pdf/2506.16388"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 15:19:35 UTC (388 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16418",
    "abstract": "This study investigates the integration of signal processing transformations -- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete Cosine Transform (DCT) -- within the ResNet50 convolutional neural network (CNN) model for image classification. The primary objective is to assess the trade-offs between computational efficiency, energy consumption, and classification accuracy during training and inference. Using the CIFAR-100 dataset (100 classes, 60,000 images), experiments demonstrated that incorporating WHT significantly reduced energy consumption while improving accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified ResNet50 incorporating WHT in the early convolutional layers achieved 74% accuracy, and an enhanced version with WHT applied to both early and late layers achieved 79% accuracy, with an average energy consumption of only 39 kJ per model. These results demonstrate the potential of WHT as a highly efficient and effective approach for energy-constrained CNN applications.",
    "authors": [
      "Yilmaz, Berk",
      "Harvey, Daniel Fidel",
      "Dhuri, Prajit"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16418",
      "View PDF": "https://arxiv.org/pdf/2506.16418"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 15:54:59 UTC (9,430 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Efficient Transformations in Deep Learning Convolutional Neural Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16170",
    "abstract": "Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects memorization.In this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student variants.This study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.",
    "authors": [
      "Singh, Simardeep"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16170v1",
      "Other Formats": "https://arxiv.org/format/2506.16170",
      "TeX Source": "https://arxiv.org/src/2506.16170",
      "View PDF": "https://arxiv.org/pdf/2506.16170"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 09:44:25 UTC (26 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "From Teacher to Student: Tracking Memorization Through Model Distillation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.11140",
    "abstract": "Agentic Artificial Intelligence (AI) systems leveraging Large Language Models (LLMs) exhibit significant potential for complex reasoning, planning, and tool utilization. We demonstrate that a specialized computer vision system can be built autonomously from a natural language prompt using Agentic AI methods. This involved extending SimpleMind (SM), an open-source Cognitive AI environment with configurable tools for medical image analysis, with an LLM-based agent, implemented using OpenManus, to automate the planning (tool configuration) for a particular computer vision task. We provide a proof-of-concept demonstration that an agentic system can interpret a computer vision task prompt, plan a corresponding SimpleMind workflow by decomposing the task and configuring appropriate tools. From the user input prompt, \"provide sm (SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest x-ray)\"), the agent LLM was able to generate the plan (tool configuration file in YAML format), and execute SM-Learn (training) and SM-Think (inference) scripts autonomously. The computer vision agent automatically configured, trained, and tested itself on 50 chest x-ray images, achieving mean dice scores of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows the potential for autonomous planning and tool configuration that has traditionally been performed by a data scientist in the development of computer vision applications.",
    "authors": [
      "Kim, Jin",
      "Wahi-Anwa, Muhammad",
      "Park, Sangyun",
      "Shin, Shawn",
      "Hoffman, John M.",
      "Brown, Matthew S."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.11140",
      "TeX Source": "https://arxiv.org/src/2506.11140",
      "View PDF": "https://arxiv.org/pdf/2506.11140"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 11 Jun 2025 02:21:19 UTC (1,385 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 16 Jun 2025 03:18:56 UTC (1,385 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 21:19:13 UTC (1,385 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/06/11",
    "title": "Autonomous Computer Vision Development with Agentic AI",
    "repo_urls": [
      "https://github.com/jink-ucla/OpenManus-SimpleMind"
    ],
    "tasks": [
      "Medical Image Analysis"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.04524",
    "abstract": "Analog in-memory computing is an emerging paradigm designed to efficiently accelerate deep neural network workloads. Recent advancements have focused on either inference or training acceleration. However, a unified analog in-memory technology platform-capable of on-chip training, weight retention, and long-term inference acceleration-has yet to be reported. This work presents an all-in-one analog AI accelerator, combining these capabilities to enable energy-efficient, continuously adaptable AI systems. The platform leverages an array of analog filamentary conductive-metal-oxide (CMO)/HfOx resistive switching memory cells (ReRAM) integrated into the back-end-of-line (BEOL). The array demonstrates reliable resistive switching with voltage amplitudes below 1.5V, compatible with advanced technology nodes. The array multi-bit capability (over 32 stable states) and low programming noise (down to 10nS) enable a nearly ideal weight transfer process, more than an order of magnitude better than other memristive technologies. Inference performance is validated through matrix-vector multiplication simulations on a 64x64 array, achieving a root-mean-square error improvement by a factor of 20 at 1 second and 3 at 10 years after programming, compared to state-of-the-art. Training accuracy closely matching the software equivalent is achieved across different datasets. The CMO/HfOx ReRAM technology lays the foundation for efficient analog systems accelerating both inference and training in deep neural networks.",
    "authors": [
      "Falcone, Donato Francesco",
      "Clerico, Victoria",
      "Choi, Wooseok",
      "Stecconi, Tommaso",
      "Horst, Folkert",
      "Begon-Lours, Laura",
      "Galetta, Matteo",
      "La Porta, Antonio",
      "Garg, Nikhil",
      "Alibart, Fabien",
      "Offrein, Bert Jan",
      "Bragaglia, Valeria"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.04524v4",
      "Other Formats": "https://arxiv.org/format/2502.04524",
      "TeX Source": "https://arxiv.org/src/2502.04524",
      "View PDF": "https://arxiv.org/pdf/2502.04524"
    },
    "subjects": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 6 Feb 2025 21:52:09 UTC (27,414 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Tue, 11 Feb 2025 18:02:11 UTC (27,413 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Wed, 26 Feb 2025 09:39:50 UTC (27,395 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Thu, 19 Jun 2025 16:22:03 UTC (27,421 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2025/02/06",
    "title": "All-in-One Analog AI Hardware: On-Chip Training and Inference with Conductive-Metal-Oxide/HfOx ReRAM Devices",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2410.18077",
    "abstract": "We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework -- language specification, symbolic interpreter, and weight compiler -- available to the community to enable further applications and insights.",
    "authors": [
      "Shaw, Peter",
      "Cohan, James",
      "Eisenstein, Jacob",
      "Lee, Kenton",
      "Berant, Jonathan",
      "Toutanova, Kristina"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2410.18077",
      "TeX Source": "https://arxiv.org/src/2410.18077",
      "View PDF": "https://arxiv.org/pdf/2410.18077"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 23 Oct 2024 17:58:49 UTC (151 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 15:55:45 UTC (149 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/10/23",
    "title": "ALTA: Compiler-Based Analysis of Transformers",
    "repo_urls": [
      "https://github.com/google-deepmind/alta"
    ],
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.14806",
    "abstract": "LiDAR place recognition (LPR) plays a vital role in autonomous navigation. However, existing LPR methods struggle to maintain robustness under adverse weather conditions such as rain, snow, and fog, where weather-induced noise and point cloud degradation impair LiDAR reliability and perception accuracy. To tackle these challenges, we propose an Iterative Task-Driven Framework (ITDNet), which integrates a LiDAR Data Restoration (LDR) module and a LiDAR Place Recognition (LPR) module through an iterative learning strategy. These modules are jointly trained end-to-end, with alternating optimization to enhance performance. The core rationale of ITDNet is to leverage the LDR module to recover the corrupted point clouds while preserving structural consistency with clean data, thereby improving LPR accuracy in adverse weather. Simultaneously, the LPR task provides feature pseudo-labels to guide the LDR module's training, aligning it more effectively with the LPR task. To achieve this, we first design a task-driven LPR loss and a reconstruction loss to jointly supervise the optimization of the LDR module. Furthermore, for the LDR module, we propose a Dual-Domain Mixer (DDM) block for frequency-spatial feature fusion and a Semantic-Aware Generator (SAG) block for semantic-guided restoration. In addition, for the LPR module, we introduce a Multi-Frequency Transformer (MFT) block and a Wavelet Pyramid NetVLAD (WPN) block to aggregate multi-scale, robust global descriptors. Finally, extensive experiments on Weather-KITTI, Boreas, and our proposed Weather-Apollo datasets demonstrate that, ITDNet outperforms existing LPR methods, achieving state-of-the-art performance in adverse weather.",
    "authors": [
      "Zhao, Xiongwei",
      "Chen, Xieyuanli",
      "Zhu, Xu",
      "Xie, Xingxiang",
      "Bai, Haojie",
      "Wen, Congcong",
      "Zhou, Rundong",
      "Sun, Qihao"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.14806v2",
      "Other Formats": "https://arxiv.org/format/2504.14806",
      "TeX Source": "https://arxiv.org/src/2504.14806",
      "View PDF": "https://arxiv.org/pdf/2504.14806"
    },
    "subjects": [
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 21 Apr 2025 02:15:27 UTC (15,028 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 14:04:39 UTC (12,715 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/04/21",
    "title": "An Iterative Task-Driven Framework for Resilient LiDAR Place Recognition in Adverse Weather",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15976",
    "abstract": "Mamba, a State Space Model (SSM) that accelerates training by recasting recurrence as a parallel selective scan, has recently emerged as a linearly-scaling, efficient alternative to self-attention. Because of its unidirectional nature, each state in Mamba only has information of its previous states and is blind to states after. Current Mamba-based computer-vision methods typically overcome this limitation by augmenting Mamba's global forward scan with a global backward scan, forming a bi-directional scan that restores a full receptive field. However, this operation doubles the computational load, eroding much of the efficiency advantage that originally Mamba have. To eliminate this extra scans, we introduce LBMamba, a locally bi-directional SSM block that embeds a lightweight locally backward scan inside the forward selective scan and executes it entirely in per-thread registers. Building on LBMamba, we present LBVim, a scalable vision backbone that alternates scan directions every two layers to recover a global receptive field without extra backward sweeps. We validate the versatility of our approach on both natural images and whole slide images (WSIs). We show that our LBVim constantly offers a superior performance-throughput trade-off. That is under the same throughput, LBVim achieves 0.8% to 1.6% higher top-1 accuracy on the ImageNet-1K classification dataset, 0.6% to 2.7% higher mIoU on the ADE20K semantic segmentation dataset, 0.9% higher APb and 1.1% higher APm on the COCO detection dataset. We also integrate LBMamba into the SOTA pathology multiple instance learning (MIL) approach, MambaMIL, which uses single directional scan. Experiments on 3 public WSI classification datasets for show that our method achieves a relative improvement of up to 3.06% better AUC, 3.39% better F1, 1.67% better accuracy.",
    "authors": [
      "Zhang, Jingwei",
      "Han, Xi",
      "Qin, Hong",
      "Hosseini, Mahdi S.",
      "Samaras, Dimitris"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15976v1",
      "Other Formats": "https://arxiv.org/format/2506.15976",
      "TeX Source": "https://arxiv.org/src/2506.15976",
      "View PDF": "https://arxiv.org/pdf/2506.15976"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 02:44:47 UTC (838 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "LBMamba: Locally Bi-directional Mamba",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16255",
    "abstract": "Conventional galaxy generation methods rely on semi-analytical models and hydrodynamic simulations, which are highly dependent on physical assumptions and parameter tuning. In contrast, data-driven generative models do not have explicit physical parameters pre-determined, and instead learn them efficiently from observational data, making them alternative solutions to galaxy generation. Among these, diffusion models outperform Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) in quality and diversity. Leveraging physical prior knowledge to these models can further enhance their capabilities. In this work, we present GalCatDiff, the first framework in astronomy to leverage both galaxy image features and astrophysical properties in the network design of diffusion models. GalCatDiff incorporates an enhanced U-Net and a novel block entitled Astro-RAB (Residual Attention Block), which dynamically combines attention mechanisms with convolution operations to ensure global consistency and local feature fidelity. Moreover, GalCatDiff uses category embeddings for class-specific galaxy generation, avoiding the high computational costs of training separate models for each category. Our experimental results demonstrate that GalCatDiff significantly outperforms existing methods in terms of the consistency of sample color and size distributions, and the generated galaxies are both visually realistic and physically consistent. This framework will enhance the reliability of galaxy simulations and can potentially serve as a data augmentor to support future galaxy classification algorithm development.",
    "authors": [
      "Fan, Xingzhong",
      "Tang, Hongming",
      "Zeng, Yue",
      "Kouwenhoven, M. B. N.",
      "Zeng, Guangquan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16255v1",
      "Other Formats": "https://arxiv.org/format/2506.16255",
      "TeX Source": "https://arxiv.org/src/2506.16255",
      "View PDF": "https://arxiv.org/pdf/2506.16255"
    },
    "subjects": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 12:14:33 UTC (3,075 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Category-based Galaxy Image Generation via Diffusion Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16475",
    "abstract": "Quadrupedal robots have demonstrated impressive locomotion capabilities in complex environments, but equipping them with autonomous versatile manipulation skills in a scalable way remains a significant challenge. In this work, we introduce a cross-embodiment imitation learning system for quadrupedal manipulation, leveraging data collected from both humans and LocoMan, a quadruped equipped with multiple manipulation modes. Specifically, we develop a teleoperation and data collection pipeline, which unifies and modularizes the observation and action spaces of the human and the robot. To effectively leverage the collected data, we propose an efficient modularized architecture that supports co-training and pretraining on structured modality-aligned data across different embodiments. Additionally, we construct the first manipulation dataset for the LocoMan robot, covering various household tasks in both unimanual and bimanual modes, supplemented by a corresponding human dataset. We validate our system on six real-world manipulation tasks, where it achieves an average success rate improvement of 41.9% overall and 79.7% under out-of-distribution (OOD) settings compared to the baseline. Pretraining with human data contributes a 38.6% success rate improvement overall and 82.7% under OOD settings, enabling consistently better performance with only half the amount of robot data. Our code, hardware, and data are open-sourced at: https://human2bots.github.io.",
    "authors": [
      "Niu, Yaru",
      "Zhang, Yunzhe",
      "Yu, Mingyang",
      "Lin, Changyi",
      "Li, Chenhao",
      "Wang, Yikai",
      "Yang, Yuxiang",
      "Yu, Wenhao",
      "Zhang, Tingnan",
      "Chen, Bingqing",
      "Francis, Jonathan",
      "Li, Zhenzhen",
      "Tan, Jie",
      "Zhao, Ding"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16475v1",
      "Other Formats": "https://arxiv.org/format/2506.16475",
      "TeX Source": "https://arxiv.org/src/2506.16475",
      "View PDF": "https://arxiv.org/pdf/2506.16475"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:22:52 UTC (13,757 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2408.08095",
    "abstract": "Background. Code Technical Debt (Code TD) prediction has gained significant attention in recent software engineering research. However, no standardized approach to Code TD prediction fully captures the factors influencing its evolution. Objective. Our study aims to assess the impact of time-dependent models and seasonal effects on Code TD prediction. It evaluates such models against widely used Machine Learning models, also considering the influence of seasonality on prediction performance. Methods. We trained 11 prediction models with 31 Java open-source projects. To assess their performance, we predicted future observations of the SQALE index. To evaluate the practical usability of our TD forecasting model and its impact on practitioners, we surveyed 23 software engineering professionals. Results. Our study confirms the benefits of time-dependent techniques, with the ARIMAX model outperforming the others. Seasonal effects improved predictive performance, though the impact remained modest. \\ReviewerA{ARIMAX/SARIMAX models demonstrated to provide well-balanced long-term forecasts. The survey highlighted strong industry interest in short- to medium-term TD forecasts. Conclusions. Our findings support using techniques that capture time dependence in historical software metric data, particularly for Code TD. Effectively addressing this evidence requires adopting methods that account for temporal patterns.",
    "authors": [
      "Robredo, Mikel",
      "Saarimaki, Nyyti",
      "Esposito, Matteo",
      "Taibi, Davide",
      "Penaloza, Rafael",
      "Lenarduzzi, Valentina"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2408.08095v2",
      "Other Formats": "https://arxiv.org/format/2408.08095",
      "TeX Source": "https://arxiv.org/src/2408.08095",
      "View PDF": "https://arxiv.org/pdf/2408.08095"
    },
    "subjects": [
      "Software Engineering (cs.SE)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 15 Aug 2024 11:39:58 UTC (1,005 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 11:21:02 UTC (1,267 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/08/15",
    "title": "Evaluating Time-Dependent Methods and Seasonal Effects in Code Technical Debt Prediction",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2411.19930",
    "abstract": "Adapting general multimodal large language models (MLLMs) to specific domains, such as scientific and industrial fields, is highly significant in promoting their practical applications. This paper systematically investigates domain adaptation of MLLMs via post-training, focusing on data synthesis, training pipeline, and task evaluation. (1) Data Synthesis: Using only open-source models, we develop a generate-then-filter pipeline that curates diverse visual instruction tasks based on domain-specific image-caption pairs. The resulting data surpass the data synthesized by manual rules or strong closed-source models in enhancing domain-specific performance. (2) Training Pipeline: Unlike general MLLMs that typically adopt a two-stage training paradigm, we find that a single-stage approach is more effective for domain adaptation. (3) Task Evaluation: We conduct extensive experiments in high-impact domains such as biomedicine, food, and remote sensing, by post-training a variety of MLLMs and then evaluating MLLM performance on various domain-specific tasks. Finally, we fully open-source our models, code, and data to encourage future research in this area.",
    "authors": [
      "Cheng, Daixuan",
      "Huang, Shaohan",
      "Zhu, Ziyu",
      "Zhang, Xintong",
      "Zhao, Wayne Xin",
      "Luan, Zhongzhi",
      "Dai, Bo",
      "Zhang, Zhenliang"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2411.19930v3",
      "Other Formats": "https://arxiv.org/format/2411.19930",
      "TeX Source": "https://arxiv.org/src/2411.19930",
      "View PDF": "https://arxiv.org/pdf/2411.19930"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 29 Nov 2024 18:42:28 UTC (1,189 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 20 Mar 2025 06:35:22 UTC (1,180 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 03:55:02 UTC (1,192 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/11/29",
    "title": "On Domain-Adaptive Post-Training for Multimodal Large Language Models",
    "tasks": [
      "Diversity",
      "Domain Adaptation"
    ],
    "datasets": [
      {
        "dataset_name": "AdaptLLM/law-tasks",
        "downloads": "260",
        "likes": "30",
        "link": "https://huggingface.co/datasets/AdaptLLM/law-tasks"
      },
      {
        "dataset_name": "AdaptLLM/medicine-tasks",
        "downloads": "388",
        "likes": "31",
        "link": "https://huggingface.co/datasets/AdaptLLM/medicine-tasks"
      },
      {
        "dataset_name": "AdaptLLM/med_knowledge_prob",
        "downloads": "267",
        "likes": "12",
        "link": "https://huggingface.co/datasets/AdaptLLM/med_knowledge_prob"
      },
      {
        "dataset_name": "AdaptLLM/biomed-VQA-benchmark",
        "downloads": "356",
        "likes": "6",
        "link": "https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark"
      },
      {
        "dataset_name": "AdaptLLM/food-VQA-benchmark",
        "downloads": "486",
        "likes": "5",
        "link": "https://huggingface.co/datasets/AdaptLLM/food-VQA-benchmark"
      },
      {
        "dataset_name": "AdaptLLM/food-visual-instructions",
        "downloads": "566",
        "likes": "2",
        "link": "https://huggingface.co/datasets/AdaptLLM/food-visual-instructions"
      },
      {
        "dataset_name": "AdaptLLM/biomed-visual-instructions",
        "downloads": "75",
        "likes": "3",
        "link": "https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions"
      },
      {
        "dataset_name": "AdaptLLM/remote-sensing-visual-instructions",
        "downloads": "77",
        "likes": "2",
        "link": "https://huggingface.co/datasets/AdaptLLM/remote-sensing-visual-instructions"
      },
      {
        "dataset_name": "AdaptLLM/remote-sensing-VQA-benchmark",
        "downloads": "448",
        "likes": "1",
        "link": "https://huggingface.co/datasets/AdaptLLM/remote-sensing-VQA-benchmark"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16288",
    "abstract": "The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.",
    "authors": [
      "Gagnon, Leo",
      "Elmoznino, Eric",
      "Mittal, Sarthak",
      "Marty, Tom",
      "Kasetty, Tejas",
      "Sridhar, Dhanya",
      "Lajoie, Guillaume"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16288v1",
      "Other Formats": "https://arxiv.org/format/2506.16288",
      "TeX Source": "https://arxiv.org/src/2506.16288",
      "View PDF": "https://arxiv.org/pdf/2506.16288"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 13:05:12 UTC (1,740 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16502",
    "abstract": "Reward models are essential for aligning large language models (LLMs) with human preferences. However, most open-source multilingual reward models are primarily trained on preference datasets in high-resource languages, resulting in unreliable reward signals for low-resource Indic languages. Collecting large-scale, high-quality preference data for these languages is prohibitively expensive, making preference-based training approaches impractical. To address this challenge, we propose RELIC, a novel in-context learning framework for reward modeling in low-resource Indic languages. RELIC trains a retriever with a pairwise ranking objective to select in-context examples from auxiliary high-resource languages that most effectively highlight the distinction between preferred and less-preferred responses. Extensive experiments on three preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art open-source reward models demonstrate that RELIC significantly improves reward model accuracy for low-resource Indic languages, consistently outperforming existing example selection methods. For example, on Bodo-a low-resource Indic language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13% improvement in accuracy over zero-shot prompting and state-of-the-art example selection method, respectively.",
    "authors": [
      "Ghosal, Soumya Suvra",
      "Singh, Vaibhav",
      "Ghosh, Akash",
      "Pal, Soumyabrata",
      "Baidya, Subhadip",
      "Saha, Sriparna",
      "Manocha, Dinesh"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16502v1",
      "Other Formats": "https://arxiv.org/format/2506.16502",
      "TeX Source": "https://arxiv.org/src/2506.16502",
      "View PDF": "https://arxiv.org/pdf/2506.16502"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:56:16 UTC (3,440 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16443",
    "abstract": "Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.",
    "authors": [
      "Naujoks, Jonas R.",
      "Krasowski, Aleksander",
      "Weckbecker, Moritz",
      "Yolcu, Galip \u00dcmit",
      "Wiegand, Thomas",
      "Lapuschkin, Sebastian",
      "Samek, Wojciech",
      "Klausen, Ren\u00e9 P."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16443v1",
      "Other Formats": "https://arxiv.org/format/2506.16443",
      "TeX Source": "https://arxiv.org/src/2506.16443",
      "View PDF": "https://arxiv.org/pdf/2506.16443"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 16:21:14 UTC (7,500 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2503.19740",
    "abstract": "Advancements in computer-assisted surgical procedures heavily rely on accurate visual data interpretation from camera systems used during surgeries. Traditional open-access datasets focusing on surgical procedures are often limited by their small size, typically consisting of fewer than 100 videos with less than 100K images. To address these constraints, a new dataset called Surg-3M has been compiled using a novel aggregation pipeline that collects high-resolution videos from online sources. Featuring an extensive collection of over 4K surgical videos totaling 938 hours of high-quality footage across multiple procedure types, Surg-3M offers a comprehensive resource surpassing existing alternatives in size and scope, including two novel tasks. To demonstrate the effectiveness of this dataset, we present SurgFM, a self-supervised foundation model pretrained on Surg-3M that achieves impressive results in downstream tasks such as surgical phase recognition, action recognition, and tool presence detection. Combining key components from ConvNeXt, DINO, and an innovative augmented distillation method, SurgFM exhibits exceptional performance compared to specialist architectures across various benchmarks. Our experimental results show that SurgFM outperforms state-of-the-art models in multiple downstream tasks, including significant gains in surgical phase recognition (+8.9pp, +4.7pp, and +3.9pp of Jaccard in AutoLaparo, M2CAI16, and Cholec80), action recognition (+3.1pp of mAP in CholecT50) and tool presence detection (+4.6pp of mAP in Cholec80). Moreover, even when using only half of the data, SurgFM outperforms state-of-the-art models in AutoLaparo and achieves state-of-the-art performance in Cholec80. Both Surg-3M and SurgFM have significant potential to accelerate progress towards developing autonomous robotic surgery systems.",
    "authors": [
      "Che, Chengan",
      "Wang, Chao",
      "Vercauteren, Tom",
      "Tsoka, Sophia",
      "Garcia-Peraza-Herrera, Luis C."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.19740v2",
      "Other Formats": "https://arxiv.org/format/2503.19740",
      "TeX Source": "https://arxiv.org/src/2503.19740",
      "View PDF": "https://arxiv.org/pdf/2503.19740"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 25 Mar 2025 15:05:00 UTC (1,644 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 22:55:49 UTC (1,658 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/03/25",
    "title": "Surg-3M: A Dataset and Foundation Model for Perception in Surgical Settings",
    "repo_urls": [
      "https://github.com/visurg-ai/surg-3m"
    ],
    "tasks": [
      "4k",
      "Action Recognition",
      "Surgical phase recognition"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16254",
    "abstract": "Enhancing the sustainability and efficiency of wireless sensor networks (WSN) in dynamic and unpredictable environments requires adaptive communication and energy harvesting strategies. We propose a novel adaptive control strategy for WSNs that optimizes data transmission and EH to minimize overall energy consumption while ensuring queue stability and energy storing constraints under dynamic environmental conditions. The notion of adaptability therein is achieved by transferring the known environment-specific knowledge to new conditions resorting to the lifelong reinforcement learning concepts. We evaluate our proposed method against two baseline frameworks: Lyapunov-based optimization, and policy-gradient reinforcement learning (RL). Simulation results demonstrate that our approach rapidly adapts to changing environmental conditions by leveraging transferable knowledge, achieving near-optimal performance approximately $30\\%$ faster than the RL method and $60\\%$ faster than the Lyapunov-based approach.",
    "authors": [
      "Firouzjaei, Hossein Mohammadi",
      "Scaciota, Rafaela",
      "Samarakoon, Sumudu"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16254v1",
      "Other Formats": "https://arxiv.org/format/2506.16254",
      "TeX Source": "https://arxiv.org/src/2506.16254",
      "View PDF": "https://arxiv.org/pdf/2506.16254"
    },
    "subjects": [
      "Systems and Control (eess.SY)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 12:13:30 UTC (293 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Multi-Task Lifelong Reinforcement Learning for Wireless Sensor Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16061",
    "abstract": "Human pose estimation in low-resolution videos presents a fundamental challenge in computer vision. Conventional methods either assume high-quality inputs or employ computationally expensive cascaded processing, which limits their deployment in resource-constrained environments. We propose STAR-Pose, a spatial-temporal adaptive super-resolution framework specifically designed for video-based human pose estimation. Our method features a novel spatial-temporal Transformer with LeakyReLU-modified linear attention, which efficiently captures long-range temporal dependencies. Moreover, it is complemented by an adaptive fusion module that integrates parallel CNN branch for local texture enhancement. We also design a pose-aware compound loss to achieve task-oriented super-resolution. This loss guides the network to reconstruct structural features that are most beneficial for keypoint localization, rather than optimizing purely for visual quality. Extensive experiments on several mainstream video HPE datasets demonstrate that STAR-Pose outperforms existing approaches. It achieves up to 5.2% mAP improvement under extremely low-resolution (64x48) conditions while delivering 2.8x to 4.4x faster inference than cascaded approaches.",
    "authors": [
      "Jin, Yucheng",
      "Chen, Jinyan",
      "He, Ziyue",
      "Han, Baojun",
      "An, Furan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16061",
      "TeX Source": "https://arxiv.org/src/2506.16061",
      "View PDF": "https://arxiv.org/pdf/2506.16061"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 06:38:49 UTC (1,392 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2408.14831",
    "abstract": "Intelligent Transportation Systems (ITS) leverage Integrated Sensing and Communications (ISAC) to enhance data exchange between vehicles and infrastructure in the Internet of Vehicles (IoV). This integration inevitably increases computing demands, risking real-time system stability. Vehicle Edge Computing (VEC) addresses this by offloading tasks to Road Side Unit (RSU), ensuring timely services. Our previous work FLSimCo algorithm, which uses local resources for Federated Self-Supervised Learning (SSL), though vehicles often can't complete all iterations task. Our improved algorithm offloads partial task to RSU and optimizes energy consumption by adjusting transmission power, CPU frequency, and task assignment ratios, balancing local and RSU-based training. Meanwhile, setting an offloading threshold further prevents inefficiencies. Simulation results show that the enhanced algorithm reduces energy consumption, improves offloading efficiency and the accuracy of Federated SSL.",
    "authors": [
      "Gu, Xueying",
      "Wu, Qiong",
      "Fan, Pingyi",
      "Cheng, Nan",
      "Chen, Wen",
      "Letaief, Khaled B."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2408.14831v2",
      "Other Formats": "https://arxiv.org/format/2408.14831",
      "TeX Source": "https://arxiv.org/src/2408.14831",
      "View PDF": "https://arxiv.org/pdf/2408.14831"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 27 Aug 2024 07:28:05 UTC (2,507 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 06:46:58 UTC (2,434 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/08/27",
    "title": "DRL-Based Federated Self-Supervised Learning for Task Offloading and Resource Allocation in ISAC-Enabled Vehicle Edge Computing",
    "repo_urls": [
      "https://github.com/qiongwu86/federated-ssl-task-offloading-and-resource-allocation"
    ],
    "tasks": [
      "Edge-computing",
      "ISAC",
      "Self-Supervised Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16444",
    "abstract": "Large Language Models (LLMs) face an inherent challenge: their knowledge is confined to the data that they have been trained on. To overcome this issue, Retrieval-Augmented Generation (RAG) complements the static training-derived knowledge of LLMs with an external knowledge repository. RAG consists of three stages: indexing, retrieval, and generation. The retrieval stage of RAG becomes a significant bottleneck in inference pipelines. In this stage, a user query is mapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS) algorithm searches for similar vectors in the database to identify relevant items. Due to the large database sizes, ANNS incurs significant data movement overheads between the host and the storage system. To alleviate these overheads, prior works propose In-Storage Processing (ISP) techniques that accelerate ANNS by performing computations inside storage. However, existing works that leverage ISP for ANNS (i) employ algorithms that are not tailored to ISP systems, (ii) do not accelerate data retrieval operations for data selected by ANNS, and (iii) introduce significant hardware modifications, limiting performance and hindering their adoption. We propose REIS, the first ISP system tailored for RAG that addresses these limitations with three key mechanisms. First, REIS employs a database layout that links database embedding vectors to their associated documents, enabling efficient retrieval. Second, it enables efficient ANNS by introducing an ISP-tailored data placement technique that distributes embeddings across the planes of the storage system and employs a lightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that uses the existing computational resources inside the storage system. Compared to a server-grade system, REIS improves the performance (energy efficiency) of retrieval by an average of 13x (55x).",
    "authors": [
      "Chen, Kangqi",
      "Kakolyris, Andreas Kosmas",
      "Nadig, Rakesh",
      "Frouzakis, Manos",
      "Ghiasi, Nika Mansouri",
      "Liang, Yu",
      "Mao, Haiyu",
      "Park, Jisung",
      "Sadrosadati, Mohammad",
      "Mutlu, Onur"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16444v1",
      "Other Formats": "https://arxiv.org/format/2506.16444",
      "TeX Source": "https://arxiv.org/src/2506.16444",
      "View PDF": "https://arxiv.org/pdf/2506.16444"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Hardware Architecture (cs.AR)",
      "Databases (cs.DB)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 16:26:51 UTC (273 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15954",
    "abstract": "Critical Learning Periods comprehend an important phenomenon involving deep learning, where early epochs play a decisive role in the success of many training recipes, such as data augmentation. Existing works confirm the existence of this phenomenon and provide useful insights. However, the literature lacks efforts to precisely identify when critical periods occur. In this work, we fill this gap by introducing a systematic approach for identifying critical periods during the training of deep neural networks, focusing on eliminating computationally intensive regularization techniques and effectively applying mechanisms for reducing computational costs, such as data pruning. Our method leverages generalization prediction mechanisms to pinpoint critical phases where training recipes yield maximum benefits to the predictive ability of models. By halting resource-intensive recipes beyond these periods, we significantly accelerate the learning phase and achieve reductions in training time, energy consumption, and CO$_2$ emissions. Experiments on standard architectures and benchmarks confirm the effectiveness of our method. Specifically, we achieve significant milestones by reducing the training time of popular architectures by up to 59.67%, leading to a 59.47% decrease in CO$_2$ emissions and a 60% reduction in financial costs, without compromising performance. Our work enhances understanding of training dynamics and paves the way for more sustainable and efficient deep learning practices, particularly in resource-constrained environments. In the era of the race for foundation models, we believe our method emerges as a valuable framework. The repository is available at https://github.com/baunilhamarga/critical-periods",
    "authors": [
      "Fukase, Vinicius Yuiti",
      "Gama, Heitor",
      "Bueno, Barbara",
      "Libanio, Lucas",
      "Costa, Anna Helena Reali",
      "Jordao, Artur"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15954v1",
      "Other Formats": "https://arxiv.org/format/2506.15954",
      "TeX Source": "https://arxiv.org/src/2506.15954",
      "View PDF": "https://arxiv.org/pdf/2506.15954"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 01:45:21 UTC (82 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "One Period to Rule Them All: Identifying Critical Learning Periods in Deep Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.02970",
    "abstract": "To detect unauthorized data usage in training large-scale generative models (e.g., ChatGPT or Midjourney), membership inference attacks (MIA) have proven effective in distinguishing a single training instance (a member) from a single non-training instance (a non-member). This success is mainly credited to a memorization effect: models tend to perform better on a member than a non-member. However, we find that standard MIAs fail against distilled generative models (i.e., student models) that are increasingly deployed in practice for efficiency (e.g., ChatGPT 4o-mini). Trained exclusively on data generated from a large-scale model (a teacher model), the student model lacks direct exposure to any members (teacher's training data), nullifying the memorization effect that standard MIAs rely on. This finding reveals a serious privacy loophole, where generation-service providers could deploy a student model whose teacher was potentially trained on unauthorized data, yet claim the deployed model is clean because it was not directly trained on such data. Hence, are distilled models inherently unauditable for upstream privacy violations, and should we discard them when we care about privacy? We contend no, as we uncover a memory chain connecting the student and teacher's member data: the distribution of student-generated data aligns more closely with the distribution of the teacher's members than with non-members, thus we can detect unauthorized data usage even when direct instance-level memorization is absent. This leads us to posit that MIAs on distilled generative models should shift from instance-level scores to distribution-level statistics. We further propose three principles of distribution-based MIAs for detecting unauthorized training data through distilled generative models, and validate our position through an exemplar framework. We lastly discuss the implications of our position.",
    "authors": [
      "Li, Muxing",
      "Ye, Zesheng",
      "Li, Yixuan",
      "Song, Andy",
      "Zhang, Guangquan",
      "Liu, Feng"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.02970v3",
      "Other Formats": "https://arxiv.org/format/2502.02970",
      "TeX Source": "https://arxiv.org/src/2502.02970",
      "View PDF": "https://arxiv.org/pdf/2502.02970"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 5 Feb 2025 08:11:23 UTC (6,283 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 9 Jun 2025 01:14:48 UTC (4,872 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 06:33:05 UTC (4,872 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/02/05",
    "title": "Membership Inference Attack Should Move On to Distributional Statistics for Distilled Generative Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.08884",
    "abstract": "We present ShapeLib, the first method that leverages the priors of LLMs to design libraries of programmatic 3D shape abstractions. Our system accepts two forms of design intent: text descriptions of functions to include in the library and a seed set of exemplar shapes. We discover abstractions that match this design intent with a guided LLM workflow that first proposes, and then validates, different ways of applying and implementing functions. We learn recognition networks that map shapes to programs with these newly discovered abstractions by training on data produced by LLM authored synthetic data generation procedures. Across modeling domains (split by shape category), we find that LLMs, when thoughtfully combined with geometric reasoning, can be guided to author a library of abstraction functions that generalize to shapes outside of the seed set. This framework addresses a long-standing shape analysis problem of how to discover reusable abstraction functions while exposing interpretable, semantically aligned interfaces. We find that ShapeLib provides distinct advantages over prior alternative abstraction discovery works in terms of generalization, usability, and maintaining plausibility under manipulation. Finally, we demonstrate that ShapeLib's abstraction functions unlock a number of downstream applications, combining LLM reasoning over shape programs with geometry processing to support shape editing and generation.",
    "authors": [
      "Jones, R. Kenny",
      "Guerrero, Paul",
      "Mitra, Niloy J.",
      "Ritchie, Daniel"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.08884v2",
      "Other Formats": "https://arxiv.org/format/2502.08884",
      "TeX Source": "https://arxiv.org/src/2502.08884",
      "View PDF": "https://arxiv.org/pdf/2502.08884"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 13 Feb 2025 01:52:02 UTC (20,820 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 03:48:04 UTC (30,524 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/13",
    "title": "ShapeLib: Designing a library of programmatic 3D shape abstractions with Large Language Models",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.13563",
    "abstract": "With the rise of the fine-tuned--pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base) with up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and (d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression.",
    "authors": [
      "Wang, Xiaohui",
      "Ye, Peng",
      "Huang, Chenyu",
      "Zheng, Shenghe",
      "Zhang, Bo",
      "Bai, Lei",
      "Ouyang, Wanli",
      "Chen, Tao"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.13563v2",
      "Other Formats": "https://arxiv.org/format/2505.13563",
      "TeX Source": "https://arxiv.org/src/2505.13563",
      "View PDF": "https://arxiv.org/pdf/2505.13563"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 19 May 2025 10:37:22 UTC (2,742 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 15:45:16 UTC (2,742 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/19",
    "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16216",
    "abstract": "In this work, we aim to optimize the radio resource management of a communication system between a remote controller and its device, whose state is represented through image frames, without compromising the performance of the control task. We propose a novel machine learning (ML) technique to jointly model and predict the dynamics of the control system as well as the wireless propagation environment in latent space. Our method leverages two coupled joint-embedding predictive architectures (JEPAs): a control JEPA models the control dynamics and guides the predictions of a wireless JEPA, which captures the dynamics of the device's channel state information (CSI) through cross-modal conditioning. We then train a deep reinforcement learning (RL) algorithm to derive a control policy from latent control dynamics and a power predictor to estimate scheduling intervals with favorable channel conditions based on latent CSI representations. As such, the controller minimizes the usage of radio resources by utilizing the coupled JEPA networks to imagine the device's trajectory in latent space. We present simulation results on synthetic multimodal data and show that our proposed approach reduces transmit power by over 50% while maintaining control performance comparable to baseline methods that do not account for wireless optimization.",
    "authors": [
      "Chaaya, Charbel Bou",
      "Girgis, Abanoub M.",
      "Bennis, Mehdi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16216",
      "TeX Source": "https://arxiv.org/src/2506.16216",
      "View PDF": "https://arxiv.org/pdf/2506.16216"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 11:08:20 UTC (2,332 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "From Pixels to CSI: Distilling Latent Dynamics For Efficient Wireless Resource Management",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.06316",
    "abstract": "In genome-scale constraint-based metabolic models, gene deletion strategies are crucial for achieving growth-coupled production, where cell growth and target metabolite production are simultaneously achieved. While computational methods for calculating gene deletions have been widely explored and contribute to developing gene deletion strategy databases, current approaches are limited in leveraging new data-driven paradigms, such as machine learning, for more efficient strain design. Therefore, it is necessary to propose a fundamental framework for this objective. In this study, we first formulate the problem of gene deletion strategy prediction and then propose a framework for predicting gene deletion strategies for growth-coupled production in genome-scale metabolic models. The proposed framework leverages deep learning algorithms to learn and integrate sequential gene and metabolite data representation, enabling the automatic gene deletion strategy prediction. Computational experiment results demonstrate the feasibility of the proposed framework, showing substantial improvements over baseline methods. Specifically, the proposed framework achieves a 14.69%, 22.52%, and 13.03% increase in overall accuracy across three metabolic models of different scales under study, while maintaining balanced precision and recall in predicting gene deletion statuses. The source code and examples for the framework are publicly available at https://github.com/MetNetComp/DeepGDel.",
    "authors": [
      "Yang, Ziwei",
      "Tamura, Takeyuki"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.06316v4",
      "Other Formats": "https://arxiv.org/format/2504.06316",
      "TeX Source": "https://arxiv.org/src/2504.06316",
      "View PDF": "https://arxiv.org/pdf/2504.06316"
    },
    "subjects": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 8 Apr 2025 08:07:59 UTC (298 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 12 Jun 2025 07:02:42 UTC (301 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Fri, 13 Jun 2025 03:21:23 UTC (301 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Thu, 19 Jun 2025 05:07:51 UTC (301 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2025/04/08",
    "title": "DeepGDel: Deep Learning-based Gene Deletion Prediction Framework for Growth-Coupled Production in Genome-Scale Metabolic Models",
    "repo_urls": [
      "https://github.com/metnetcomp/deepgdel"
    ],
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16024",
    "abstract": "Current research on long-form context in Large Language Models (LLMs) primarily focuses on the understanding of long-contexts, the Open-ended Long Text Generation (Open-LTG) remains insufficiently explored. Training a long-context generation model requires curation of gold standard reference data, which is typically nonexistent for informative Open-LTG tasks. However, previous methods only utilize general assessments as reward signals, which limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative reinforcement learning (RL) based framework, which includes a dataset and a reward signal computation method. Firstly, ProxyReward Dataset generation is accomplished through simple prompts that enables the model to create automatically, obviating extensive labeled data or significant manual effort. Secondly, ProxyReward Signal offers a targeted evaluation of information comprehensiveness and accuracy for specific questions. The experimental results indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can significantly enhance performance by 20% on the Open-LTG task when training widely used open-source models, while also surpassing the LLM-as-a-Judge approach. Our work presents effective methods to enhance the ability of LLMs to address complex open-ended questions posed by human.",
    "authors": [
      "Guo, Zhihan",
      "Wu, Jiele",
      "Cui, Wenqian",
      "Zhang, Yifei",
      "Hu, Minda",
      "Wang, Yufei",
      "King, Irwin"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16024v1",
      "Other Formats": "https://arxiv.org/format/2506.16024",
      "TeX Source": "https://arxiv.org/src/2506.16024",
      "View PDF": "https://arxiv.org/pdf/2506.16024"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 04:44:34 UTC (858 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16602",
    "abstract": "Graph neural networks have been useful in machine learning on graph-structured data, particularly for node classification and some types of graph classification tasks. However, they have had limited use in representing patterning of signals over graphs. Patterning of signals over graphs and in subgraphs carries important information in many domains including neuroscience. Neural signals are spatiotemporally patterned, high dimensional and difficult to decode. Graph signal processing and associated GCN models utilize the graph Fourier transform and are unable to efficiently represent spatially or spectrally localized signal patterning on graphs. Wavelet transforms have shown promise here, but offer non-canonical representations and cannot be tightly confined to subgraphs. Here we propose SlepNet, a novel GCN architecture that uses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepian harmonics optimally concentrate signal energy on specifically relevant subgraphs that are automatically learned with a mask. Thus, they can produce canonical and highly resolved representations of neural activity, focusing energy of harmonics on areas of the brain which are activated. We evaluated SlepNet across three fMRI datasets, spanning cognitive and visual tasks, and two traffic dynamics datasets, comparing its performance against conventional GNNs and graph signal processing constructs. SlepNet outperforms the baselines in all datasets. Moreover, the extracted representations of signal patterns from SlepNet offers more resolution in distinguishing between similar patterns, and thus represent brain signaling transients as informative trajectories. Here we have shown that these extracted trajectory representations can be used for other downstream untrained tasks. Thus we establish that SlepNet is useful both for prediction and representation learning in spatiotemporal data.",
    "authors": [
      "Viswanath, Siddharth",
      "Singh, Rahul",
      "Zhang, Yanlei",
      "Noah, J. Adam",
      "Hirsch, Joy",
      "Krishnaswamy, Smita"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16602v1",
      "Other Formats": "https://arxiv.org/format/2506.16602",
      "TeX Source": "https://arxiv.org/src/2506.16602",
      "View PDF": "https://arxiv.org/pdf/2506.16602"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 21:03:52 UTC (17,832 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "SlepNet: Spectral Subgraph Representation Learning for Neural Dynamics",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.05142",
    "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data, and lack generalizability to out-of-distribution datasets. To address these challenges, we introduce CheXFound, a self-supervised vision foundation model that learns robust CXR representations and generalizes effectively across a wide range of downstream tasks. We pretrain CheXFound on a curated CXR-1M dataset, comprising over one million unique CXRs from publicly available sources. We propose a Global and Local Representations Integration (GLoRI) module for downstream adaptations, by incorporating disease-specific local features with global image features for enhanced performance in multilabel classification. Our experimental results show that CheXFound outperforms state-of-the-art models in classifying 40 disease findings across different prevalence levels on the CXR-LT 24 dataset and exhibits superior label efficiency on downstream tasks with limited training data. Additionally, CheXFound achieved significant improvements on new tasks with out-of-distribution datasets, including opportunistic cardiovascular disease risk estimation and mortality prediction. These results highlight CheXFound's strong generalization capabilities, enabling diverse adaptations with improved label efficiency. The project source code is publicly available at https://github.com/RPIDIAL/CheXFound.",
    "authors": [
      "Yang, Zefan",
      "Xu, Xuanang",
      "Zhang, Jiajin",
      "Wang, Ge",
      "Kalra, Mannudeep K.",
      "Yan, Pingkun"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.05142v2",
      "Other Formats": "https://arxiv.org/format/2502.05142",
      "TeX Source": "https://arxiv.org/src/2502.05142",
      "View PDF": "https://arxiv.org/pdf/2502.05142"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 7 Feb 2025 18:16:15 UTC (9,449 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 14:25:55 UTC (1,274 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/07",
    "title": "Chest X-ray Foundation Model with Global and Local Representations Integration",
    "repo_urls": [
      "https://github.com/rpidial/chexfound"
    ],
    "tasks": [
      "Mortality Prediction"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.13180",
    "abstract": "Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about \"what\", \"where\", \"when\", and \"how\" of a video. We make our work fully reproducible by providing data, training recipes, code & models. https://github.com/facebookresearch/perception_models",
    "authors": [
      "Cho, Jang Hyun",
      "Madotto, Andrea",
      "Mavroudi, Effrosyni",
      "Afouras, Triantafyllos",
      "Nagarajan, Tushar",
      "Maaz, Muhammad",
      "Song, Yale",
      "Ma, Tengyu",
      "Hu, Shuming",
      "Jain, Suyog",
      "Martin, Miguel",
      "Wang, Huiyu",
      "Rasheed, Hanoona",
      "Sun, Peize",
      "Huang, Po-Yao",
      "Bolya, Daniel",
      "Ravi, Nikhila",
      "Jain, Shashank",
      "Stark, Tammy",
      "Moon, Shane",
      "Damavandi, Babak",
      "Lee, Vivian",
      "Westbury, Andrew",
      "Khan, Salman",
      "Kr\u00e4henb\u00fchl, Philipp",
      "Doll\u00e1r, Piotr",
      "Torresani, Lorenzo",
      "Grauman, Kristen",
      "Feichtenhofer, Christoph"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2504.13180",
      "TeX Source": "https://arxiv.org/src/2504.13180",
      "View PDF": "https://arxiv.org/pdf/2504.13180"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 17 Apr 2025 17:59:56 UTC (41,409 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 16:16:57 UTC (13,281 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/04/17",
    "title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding",
    "repo_urls": [
      "https://github.com/facebookresearch/perception_models"
    ],
    "tasks": [
      "Video Question Answering",
      "Video Understanding"
    ],
    "datasets": [
      {
        "dataset_name": "facebook/PLM-Video-Human",
        "downloads": "1077",
        "likes": "23",
        "link": "https://huggingface.co/datasets/facebook/PLM-Video-Human"
      },
      {
        "dataset_name": "facebook/PLM-Video-Auto",
        "downloads": "299",
        "likes": "14",
        "link": "https://huggingface.co/datasets/facebook/PLM-Video-Auto"
      },
      {
        "dataset_name": "facebook/PLM-Image-Auto",
        "downloads": "731",
        "likes": "14",
        "link": "https://huggingface.co/datasets/facebook/PLM-Image-Auto"
      },
      {
        "dataset_name": "facebook/PLM-VideoBench",
        "downloads": "851",
        "likes": "9",
        "link": "https://huggingface.co/datasets/facebook/PLM-VideoBench"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16655",
    "abstract": "With the rapid proliferation of large language models (LLMs) -- each optimized for different strengths, style, or latency/cost profile -- routing has become an essential technique to operationalize the use of different models. However, existing LLM routing approaches are limited in two key ways: they evaluate performance using benchmarks that often fail to capture human preferences driven by subjective evaluation criteria, and they typically select from a limited pool of models. In this work, we propose a preference-aligned routing framework that guides model selection by matching queries to user-defined domains (e.g., travel) or action types (e.g., image editing) -- offering a practical mechanism to encode preferences in routing decisions. Specifically, we introduce \\textbf{Arch-Router}, a compact 1.5B model that learns to map queries to domain-action preferences for model routing decisions. Our approach also supports seamlessly adding new models for routing without requiring retraining or architectural modifications. Experiments on conversational datasets demonstrate that our approach achieves state-of-the-art (SOTA) results in matching queries with human preferences, outperforming top proprietary models. Our approach captures subjective evaluation criteria and makes routing decisions more transparent and flexible. Our model is available at: \\texttt{https://huggingface.co/katanemo/Arch-Router-1.5B}.",
    "authors": [
      "Tran, Co",
      "Paracha, Salman",
      "Hafeez, Adil",
      "Chen, Shuguang"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16655v1",
      "Other Formats": "https://arxiv.org/format/2506.16655",
      "TeX Source": "https://arxiv.org/src/2506.16655",
      "View PDF": "https://arxiv.org/pdf/2506.16655"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 23:57:41 UTC (6,543 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Arch-Router: Aligning LLM Routing with Human Preferences",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2408.08872",
    "abstract": "This paper introduces BLIP-3, an open framework for developing Large Multimodal Models (LMMs). The framework comprises meticulously curated datasets, a training recipe, model architectures, and a resulting suite of LMMs. We release 4B and 14B models, including both the pre-trained base model and the instruction fine-tuned ones. Our models undergo rigorous evaluation across a range of tasks, including both single and multi-image benchmarks. Our models demonstrate competitive performance among open-source LMMs with similar model sizes. Our resulting LMMs demonstrate competitive performance among open-source LMMs with similar model sizes, with the ability to comprehend interleaved image-text inputs. Our training code, models, and all datasets used in this work, including the three largescale datasets we create and the preprocessed ones, will be open-sourced to better support the research community.",
    "authors": [
      "Xue, Le",
      "Shu, Manli",
      "Awadalla, Anas",
      "Wang, Jun",
      "Yan, An",
      "Purushwalkam, Senthil",
      "Zhou, Honglu",
      "Prabhu, Viraj",
      "Dai, Yutong",
      "Ryoo, Michael S",
      "Kendre, Shrikant",
      "Zhang, Jieyu",
      "Tseng, Shaoyen",
      "Lujan-Moreno, Gustavo A",
      "Olson, Matthew L",
      "Hinck, Musashi",
      "Cobbley, David",
      "Lal, Vasudev",
      "Qin, Can",
      "Zhang, Shu",
      "Chen, Chia-Chih",
      "Yu, Ning",
      "Tan, Juntao",
      "Awalgaonkar, Tulika Manoj",
      "Heinecke, Shelby",
      "Wang, Huan",
      "Choi, Yejin",
      "Schmidt, Ludwig",
      "Chen, Zeyuan",
      "Savarese, Silvio",
      "Niebles, Juan Carlos",
      "Xiong, Caiming",
      "Xu, Ran"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2408.08872v3",
      "Other Formats": "https://arxiv.org/format/2408.08872",
      "TeX Source": "https://arxiv.org/src/2408.08872",
      "View PDF": "https://arxiv.org/pdf/2408.08872"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 16 Aug 2024 17:57:01 UTC (12,671 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 28 Aug 2024 05:03:34 UTC (12,671 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 18:29:26 UTC (2,681 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/08/16",
    "title": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models",
    "repo_urls": [
      "https://github.com/zzxslp/som-llava"
    ],
    "tasks": [
      "In-Context Learning"
    ],
    "datasets": [
      {
        "dataset_name": "Salesforce/blip3-kale",
        "downloads": "159436",
        "likes": "35",
        "link": "https://huggingface.co/datasets/Salesforce/blip3-kale"
      },
      {
        "dataset_name": "Salesforce/blip3-ocr-200m",
        "downloads": "923",
        "likes": "31",
        "link": "https://huggingface.co/datasets/Salesforce/blip3-ocr-200m"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2503.01058",
    "abstract": "Robotic tactile sensors, including vision-based and taxel-based sensors, enable agile manipulation and safe human-robot interaction through force sensation. However, variations in structural configurations, measured signals, and material properties create domain gaps that limit the transferability of learned force sensation across different tactile sensors. Here, we introduce GenForce, a general framework for achieving transferable force sensation across both homogeneous and heterogeneous tactile sensors in robotic systems. By unifying tactile signals into marker-based binary tactile images, GenForce enables the transfer of existing force labels to arbitrary target sensors using a marker-to-marker translation technique with a few paired data. This process equips uncalibrated tactile sensors with force prediction capabilities through spatiotemporal force prediction models trained on the transferred data. Extensive experimental results validate GenForce's generalizability, accuracy, and robustness across sensors with diverse marker patterns, structural designs, material properties, and sensing principles. The framework significantly reduces the need for costly and labor-intensive labeled data collection, enabling the rapid deployment of multiple tactile sensors on robotic hands requiring force sensing capabilities.",
    "authors": [
      "Chen, Zhuo",
      "Ou, Ni",
      "Zhang, Xuyang",
      "Wu, Zhiyuan",
      "Zhao, Yongqiang",
      "Wang, Yupeng",
      "Lepora, Nathan",
      "Jamone, Lorenzo",
      "Deng, Jiankang",
      "Luo, Shan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.01058v2",
      "Other Formats": "https://arxiv.org/format/2503.01058",
      "TeX Source": "https://arxiv.org/src/2503.01058",
      "View PDF": "https://arxiv.org/pdf/2503.01058"
    },
    "subjects": [
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 2 Mar 2025 23:36:21 UTC (24,964 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 09:03:08 UTC (24,566 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/03/02",
    "title": "General Force Sensation for Tactile Robot",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15947",
    "abstract": "Low-Altitude Economy Networks (LAENets) are emerging as a promising paradigm to support various low-altitude services through integrated air-ground infrastructure. To satisfy low-latency and high-computation demands, the integration of Unmanned Aerial Vehicles (UAVs) with Mobile Edge Computing (MEC) systems plays a vital role, which offloads computing tasks from terminal devices to nearby UAVs, enabling flexible and resilient service provisions for ground users. To promote the development of LAENets, it is significant to achieve low-carbon multi-UAV-assisted MEC networks. However, several challenges hinder this implementation, including the complexity of multi-dimensional UAV modeling and the difficulty of multi-objective coupled optimization. To this end, this paper proposes a novel Retrieval Augmented Generation (RAG)-based Large Language Model (LLM) agent framework for model formulation. Specifically, we develop HybridRAG by combining KeywordRAG, VectorRAG, and GraphRAG, empowering LLM agents to efficiently retrieve structural information from expert databases and generate more accurate optimization problems compared with traditional RAG-based LLM agents. After customizing carbon emission optimization problems for multi-UAV-assisted MEC networks, we propose a Double Regularization Diffusion-enhanced Soft Actor-Critic (R\\textsuperscript{2}DSAC) algorithm to solve the formulated multi-objective optimization problem. The R\\textsuperscript{2}DSAC algorithm incorporates diffusion entropy regularization and action entropy regularization to improve the performance of the diffusion policy. Furthermore, we dynamically mask unimportant neurons in the actor network to reduce the carbon emissions associated with model training. Simulation results demonstrate the effectiveness and reliability of the proposed HybridRAG-based LLM agent framework and the R\\textsuperscript{2}DSAC algorithm.",
    "authors": [
      "Wen, Jinbo",
      "Su, Cheng",
      "Kang, Jiawen",
      "Nie, Jiangtian",
      "Zhang, Yang",
      "Tang, Jianhang",
      "Niyato, Dusit",
      "Yuen, Chau"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15947v1",
      "Other Formats": "https://arxiv.org/format/2506.15947",
      "TeX Source": "https://arxiv.org/src/2506.15947",
      "View PDF": "https://arxiv.org/pdf/2506.15947"
    },
    "subjects": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 01:11:35 UTC (2,282 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "HybridRAG-based LLM Agents for Low-Carbon Optimization in Low-Altitude Economy Networks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12779",
    "abstract": "Achieving general agile whole-body control on humanoid robots remains a major challenge due to diverse motion demands and data conflicts. While existing frameworks excel in training single motion-specific policies, they struggle to generalize across highly varied behaviors due to conflicting control requirements and mismatched data distributions. In this work, we propose BumbleBee (BB), an expert-generalist learning framework that combines motion clustering and sim-to-real adaptation to overcome these challenges. BB first leverages an autoencoder-based clustering method to group behaviorally similar motions using motion features and motion descriptions. Expert policies are then trained within each cluster and refined with real-world data through iterative delta action modeling to bridge the sim-to-real gap. Finally, these experts are distilled into a unified generalist controller that preserves agility and robustness across all motion types. Experiments on two simulations and a real humanoid robot demonstrate that BB achieves state-of-the-art general whole-body control, setting a new benchmark for agile, robust, and generalizable humanoid performance in the real world.",
    "authors": [
      "Wang, Yuxuan",
      "Yang, Ming",
      "Zeng, Weishuai",
      "Zhang, Yu",
      "Xu, Xinrun",
      "Jiang, Haobin",
      "Ding, Ziluo",
      "Lu, Zongqing"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12779v2",
      "Other Formats": "https://arxiv.org/format/2506.12779",
      "TeX Source": "https://arxiv.org/src/2506.12779",
      "View PDF": "https://arxiv.org/pdf/2506.12779"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 15 Jun 2025 09:09:34 UTC (3,154 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 06:15:49 UTC (7,754 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/15",
    "title": "From Experts to a Generalist: Toward General Whole-Body Control for Humanoid Robots",
    "tasks": [
      "Clustering"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16017",
    "abstract": "Monocular depth estimation and ego-motion estimation are significant tasks for scene perception and navigation in stable, accurate and efficient robot-assisted endoscopy. To tackle lighting variations and sparse textures in endoscopic scenes, multiple techniques including optical flow, appearance flow and intrinsic image decomposition have been introduced into the existing methods. However, the effective training strategy for multiple modules are still critical to deal with both illumination issues and information interference for self-supervised depth estimation in endoscopy. Therefore, a novel framework with multistep efficient finetuning is proposed in this work. In each epoch of end-to-end training, the process is divided into three steps, including optical flow registration, multiscale image decomposition and multiple transformation alignments. At each step, only the related networks are trained without interference of irrelevant information. Based on parameter-efficient finetuning on the foundation model, the proposed method achieves state-of-the-art performance on self-supervised depth estimation on SCARED dataset and zero-shot depth estimation on Hamlyn dataset, with 4\\%$\\sim$10\\% lower error. The evaluation code of this work has been published on https://github.com/BaymaxShao/EndoMUST.",
    "authors": [
      "Shao, Liangjing",
      "Bai, Linxin",
      "Du, Chenkang",
      "Chen, Xinrong"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16017v1",
      "Other Formats": "https://arxiv.org/format/2506.16017",
      "TeX Source": "https://arxiv.org/src/2506.16017",
      "View PDF": "https://arxiv.org/pdf/2506.16017"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 04:31:59 UTC (1,300 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16460",
    "abstract": "Multitask learning (MTL) has emerged as a powerful paradigm that leverages similarities among multiple learning tasks, each with insufficient samples to train a standalone model, to solve them simultaneously while minimizing data sharing across users and organizations. MTL typically accomplishes this goal by learning a shared representation that captures common structure among the tasks by embedding data from all tasks into a common feature space. Despite being designed to be the smallest unit of shared information necessary to effectively learn patterns across multiple tasks, these shared representations can inadvertently leak sensitive information about the particular tasks they were trained on. In this work, we investigate what information is revealed by the shared representations through the lens of inference attacks. Towards this, we propose a novel, black-box task-inference threat model where the adversary, given the embedding vectors produced by querying the shared representation on samples from a particular task, aims to determine whether that task was present when training the shared representation. We develop efficient, purely black-box attacks on machine learning models that exploit the dependencies between embeddings from the same task without requiring shadow models or labeled reference data. We evaluate our attacks across vision and language domains for multiple use cases of MTL and demonstrate that even with access only to fresh task samples rather than training data, a black-box adversary can successfully infer a task's inclusion in training. To complement our experiments, we provide theoretical analysis of a simplified learning setting and show a strict separation between adversaries with training samples and fresh samples from the target task's distribution.",
    "authors": [
      "Abascal, John",
      "Berrios, Nicol\u00e1s",
      "Oprea, Alina",
      "Ullman, Jonathan",
      "Smith, Adam",
      "Jagielski, Matthew"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16460v1",
      "Other Formats": "https://arxiv.org/format/2506.16460",
      "TeX Source": "https://arxiv.org/src/2506.16460",
      "View PDF": "https://arxiv.org/pdf/2506.16460"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 16:56:41 UTC (672 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Black-Box Privacy Attacks on Shared Representations in Multitask Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16228",
    "abstract": "We propose a spatio-spectral, combined model-based and data-driven diarization pipeline consisting of TDOA-based segmentation followed by embedding-based clustering. The proposed system requires neither access to multi-channel training data nor prior knowledge about the number or placement of microphones. It works for both a compact microphone array and distributed microphones, with minor adjustments. Due to its superior handling of overlapping speech during segmentation, the proposed pipeline significantly outperforms the single-channel pyannote approach, both in a scenario with a compact microphone array and in a setup with distributed microphones. Additionally, we show that, unlike fully spatial diarization pipelines, the proposed system can correctly track speakers when they change positions.",
    "authors": [
      "Cord-Landwehr, Tobias",
      "Gburrek, Tobias",
      "Deegen, Marc",
      "Haeb-Umbach, Reinhold"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16228v1",
      "Other Formats": "https://arxiv.org/format/2506.16228",
      "TeX Source": "https://arxiv.org/src/2506.16228",
      "View PDF": "https://arxiv.org/pdf/2506.16228"
    },
    "subjects": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 11:37:35 UTC (1,206 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Spatio-spectral diarization of meetings by combining TDOA-based segmentation and speaker embedding-based clustering",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12699",
    "abstract": "Large language models (LLMs) are sophisticated artificial intelligence systems that enable machines to generate human-like text with remarkable precision. While LLMs offer significant technological progress, their development using vast amounts of user data scraped from the web and collected from extensive user interactions poses risks of sensitive information leakage. Most existing surveys focus on the privacy implications of the training data but tend to overlook privacy risks from user interactions and advanced LLM capabilities. This paper aims to fill that gap by providing a comprehensive analysis of privacy in LLMs, categorizing the challenges into four main areas: (i) privacy issues in LLM training data, (ii) privacy challenges associated with user prompts, (iii) privacy vulnerabilities in LLM-generated outputs, and (iv) privacy challenges involving LLM agents. We evaluate the effectiveness and limitations of existing mitigation mechanisms targeting these proposed privacy challenges and identify areas for further research.",
    "authors": [
      "Shanmugarasa, Yashothara",
      "Ding, Ming",
      "Chamikara, M. A. P",
      "Rakotoarivelo, Thierry"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12699v2",
      "Other Formats": "https://arxiv.org/format/2506.12699",
      "TeX Source": "https://arxiv.org/src/2506.12699",
      "View PDF": "https://arxiv.org/pdf/2506.12699"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 15 Jun 2025 03:14:03 UTC (971 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 06:30:24 UTC (970 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/15",
    "title": "SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.05253",
    "abstract": "Despite the tremendous success of deep learning in computer vision, models still fall behind humans in generalizing to new input distributions. Existing benchmarks do not investigate the specific failure points of models by analyzing performance under many controlled conditions. Our study systematically dissects where and why models struggle with contour integration -- a hallmark of human vision -- by designing an experiment that tests object recognition under various levels of object fragmentation. Humans (n=50) perform at high accuracy, even with few object contours present. This is in contrast to models which exhibit substantially lower sensitivity to increasing object contours, with most of the over 1,000 models we tested barely performing above chance. Only at very large scales ($\\sim5B$ training dataset size) do models begin to approach human performance. Importantly, humans exhibit an integration bias -- a preference towards recognizing objects made up of directional fragments over directionless fragments. We find that not only do models that share this property perform better at our task, but that this bias also increases with model training dataset size, and training models to exhibit contour integration leads to high shape bias. Taken together, our results suggest that contour integration is a hallmark of object vision that underlies object recognition performance, and may be a mechanism learned from data at scale.",
    "authors": [
      "Lonnqvist, Ben",
      "Scialom, Elsa",
      "Gokce, Abdulkadir",
      "Merchant, Zehra",
      "Herzog, Michael H.",
      "Schrimpf, Martin"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.05253v2",
      "Other Formats": "https://arxiv.org/format/2504.05253",
      "TeX Source": "https://arxiv.org/src/2504.05253",
      "View PDF": "https://arxiv.org/pdf/2504.05253"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 7 Apr 2025 16:45:06 UTC (5,396 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 08:43:44 UTC (5,389 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/04/07",
    "title": "Contour Integration Underlies Human-Like Vision",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.10545",
    "abstract": "Recent advances in recommender systems have underscored the complementary strengths of generative modeling and pretrained language models. We propose HSTU-BLaIR, a hybrid framework that augments the Hierarchical Sequential Transduction Unit (HSTU)-based generative recommender with BLaIR, a lightweight contrastive text embedding model. This integration enriches item representations with semantic signals from textual metadata while preserving HSTU's powerful sequence modeling capabilities. We evaluate HSTU-BLaIR on two e-commerce datasets: three subsets from the Amazon Reviews 2023 dataset and the Steam dataset. We compare its performance against both the original HSTU-based recommender and a variant augmented with embeddings from OpenAI's state-of-the-art \\texttt{text-embedding-3-large} model. Despite the latter being trained on a substantially larger corpus with significantly more parameters, our lightweight BLaIR-enhanced approach -- pretrained on domain-specific data -- achieves better performance in nearly all cases. Specifically, HSTU-BLaIR outperforms the OpenAI embedding-based variant on all but one metric, where it is marginally lower, and matches it on another. These findings highlight the effectiveness of contrastive text embeddings in compute-efficient recommendation settings.",
    "authors": [
      "Liu, Yijun"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.10545v3",
      "Other Formats": "https://arxiv.org/format/2504.10545",
      "TeX Source": "https://arxiv.org/src/2504.10545",
      "View PDF": "https://arxiv.org/pdf/2504.10545"
    },
    "subjects": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 13 Apr 2025 15:23:00 UTC (57 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 30 May 2025 02:22:12 UTC (112 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 07:04:38 UTC (112 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/04/13",
    "title": "HSTU-BLaIR: Lightweight Contrastive Text Embedding for Generative Recommender",
    "repo_urls": [
      "https://github.com/snapfinger/hstu-blair"
    ],
    "tasks": [
      "Contrastive Learning",
      "Recommendation Systems"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16322",
    "abstract": "Despite increasing efforts to ensure the safety of large language models (LLMs), most existing safety assessments and moderation tools remain heavily biased toward English and other high-resource languages, leaving majority of global languages underexamined. To address this gap, we introduce a manually annotated benchmark dataset for language model safety classification in Polish. We also create adversarially perturbed variants of these samples designed to challenge model robustness. We conduct a series of experiments to evaluate LLM-based and classifier-based models of varying sizes and architectures. Specifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based classifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B model. We train these models using different combinations of annotated data and evaluate their performance, comparing it against publicly available guard models. Results demonstrate that the HerBERT-based classifier achieves the highest overall performance, particularly under adversarial conditions.",
    "authors": [
      "Krasnod\u0119bska, Aleksandra",
      "Seweryn, Karolina",
      "\u0141ukasik, Szymon",
      "Kusa, Wojciech"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16322v1",
      "Other Formats": "https://arxiv.org/format/2506.16322",
      "TeX Source": "https://arxiv.org/src/2506.16322",
      "View PDF": "https://arxiv.org/pdf/2506.16322"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 13:56:41 UTC (60 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "PL-Guard: Benchmarking Language Model Safety for Polish",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15929",
    "abstract": "This paper introduces a novel framework for image and video demoir\\'eing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. Demoir\\'eing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods. Traditional supervised learning approaches either fail to remove moir\\'e patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoir\\'eing and often introduce artifacts. To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoir\\'eing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.",
    "authors": [
      "Li, Liangyan",
      "Ning, Yimo",
      "Le, Kevin",
      "Dong, Wei",
      "Li, Yunzhe",
      "Chen, Jun",
      "Liu, Xiaohong"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15929v1",
      "Other Formats": "https://arxiv.org/format/2506.15929",
      "TeX Source": "https://arxiv.org/src/2506.15929",
      "View PDF": "https://arxiv.org/pdf/2506.15929"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 00:15:07 UTC (4,533 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Moir\\'eXNet: Adaptive Multi-Scale Demoir\\'eing with Linear Attention Test-Time Training and Truncated Flow Matching Prior",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16006",
    "abstract": "Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.",
    "authors": [
      "Duan, Weiwei",
      "Gerlek, Michael P.",
      "Minton, Steven N.",
      "Knoblock, Craig A.",
      "Lin, Fandel",
      "Chen, Theresa",
      "Jang, Leeje",
      "Kirsanova, Sofia",
      "Li, Zekun",
      "Lin, Yijun",
      "Chiang, Yao-Yi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16006v1",
      "Other Formats": "https://arxiv.org/format/2506.16006",
      "TeX Source": "https://arxiv.org/src/2506.16006",
      "View PDF": "https://arxiv.org/pdf/2506.16006"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 03:51:47 UTC (15,489 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "DIGMAPPER: A Modular System for Automated Geologic Map Digitization",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16458",
    "abstract": "Federated Learning (FL) protects data privacy while providing a decentralized method for training models. However, because of the distributed schema, it is susceptible to adversarial clients that could alter results or sabotage model performance. This study presents SecureFed, a two-phase FL framework for identifying and reducing the impact of such attackers. Phase 1 involves collecting model updates from participating clients and applying a dimensionality reduction approach to identify outlier patterns frequently associated with malicious behavior. Temporary models constructed from the client updates are evaluated on synthetic datasets to compute validation losses and support anomaly scoring. The idea of learning zones is presented in Phase 2, where weights are dynamically routed according to their contribution scores and gradient magnitudes. High-value gradient zones are given greater weight in aggregation and contribute more significantly to the global model, while lower-value gradient zones, which may indicate possible adversarial activity, are gradually removed from training. Until the model converges and a strong defense against poisoning attacks is possible, this training cycle continues Based on the experimental findings, SecureFed considerably improves model resilience without compromising model performance.",
    "authors": [
      "Kavuri, Likhitha Annapurna",
      "Mhatre, Akshay",
      "Nair, Akarsh K",
      "Gupta, Deepti"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16458v1",
      "Other Formats": "https://arxiv.org/format/2506.16458",
      "TeX Source": "https://arxiv.org/src/2506.16458",
      "View PDF": "https://arxiv.org/pdf/2506.16458"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 16:52:48 UTC (1,878 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "SecureFed: A Two-Phase Framework for Detecting Malicious Clients in Federated Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.20007",
    "abstract": "This paper proposes a novel interdisciplinary framework for analyzing police body-worn camera (BWC) footage from the Rochester Police Department (RPD) using advanced artificial intelligence (AI) and statistical machine learning (ML) techniques. Our goal is to detect, classify, and analyze patterns of interaction between police officers and civilians to identify key behavioral dynamics, such as respect, disrespect, escalation, and de-escalation. We apply multimodal data analysis by integrating image, audio, and natural language processing (NLP) techniques to extract meaningful insights from BWC footage. The framework incorporates speaker separation, transcription, and large language models (LLMs) to produce structured, interpretable summaries of police-civilian encounters. We also employ a custom evaluation pipeline to assess transcription quality and behavior detection accuracy in high-stakes, real-world policing scenarios. Our methodology, computational techniques, and findings outline a practical approach for law enforcement review, training, and accountability processes while advancing the frontiers of knowledge discovery from complex police BWC data.",
    "authors": [
      "Srbinovska, Anita",
      "Srbinovska, Angela",
      "Senthil, Vivek",
      "Martin, Adrian",
      "McCluskey, John",
      "Bateman, Jonathan",
      "Fokou\u00e9, Ernest"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.20007v3",
      "Other Formats": "https://arxiv.org/format/2504.20007",
      "TeX Source": "https://arxiv.org/src/2504.20007",
      "View PDF": "https://arxiv.org/pdf/2504.20007"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 28 Apr 2025 17:25:23 UTC (308 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 9 May 2025 14:29:05 UTC (309 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 01:59:33 UTC (510 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/04/28",
    "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16548",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, their tendency to memorize training data raises concerns regarding privacy, copyright compliance, and security, particularly in cases involving Personally Identifiable Information (PII). Effective machine unlearning techniques are essential to mitigate these risks, yet existing methods remain underdeveloped for LLMs due to their open-ended output space. In this work, we apply the Adaptive Representation Misdirection Unlearning (RMU) technique to unlearn sensitive information from LLMs. Through extensive experiments, we analyze the effects of unlearning across different decoder layers to determine the most effective regions for sensitive information removal. Our technique ranked 4th on the official leaderboard of both 1B parameter and 7B parameter models.",
    "authors": [
      "Dosajh, Arjun",
      "Sanghi, Mihika"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16548v1",
      "Other Formats": "https://arxiv.org/format/2506.16548",
      "TeX Source": "https://arxiv.org/src/2506.16548",
      "View PDF": "https://arxiv.org/pdf/2506.16548"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 19:06:44 UTC (595 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Mr. Snuffleupagus at SemEval-2025 Task 4: Unlearning Factual Knowledge from LLMs Using Adaptive RMU",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2409.10819",
    "abstract": "We introduce EzAudio, a text-to-audio (T2A) generation framework designed to produce high-quality, natural-sounding sound effects. Core designs include: (1) We propose EzAudio-DiT, an optimized Diffusion Transformer (DiT) designed for audio latent representations, improving convergence speed, as well as parameter and memory efficiency. (2) We apply a classifier-free guidance (CFG) rescaling technique to mitigate fidelity loss at higher CFG scores and enhancing prompt adherence without compromising audio quality. (3) We propose a synthetic caption generation strategy leveraging recent advances in audio understanding and LLMs to enhance T2A pretraining. We show that EzAudio, with its computationally efficient architecture and fast convergence, is a competitive open-source model that excels in both objective and subjective evaluations by delivering highly realistic listening experiences. Code, data, and pre-trained models are released at: https://haidog-yaqub.github.io/EzAudio-Page/.",
    "authors": [
      "Hai, Jiarui",
      "Xu, Yong",
      "Zhang, Hao",
      "Li, Chenxing",
      "Wang, Helin",
      "Elhilali, Mounya",
      "Yu, Dong"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2409.10819v2",
      "Other Formats": "https://arxiv.org/format/2409.10819",
      "TeX Source": "https://arxiv.org/src/2409.10819",
      "View PDF": "https://arxiv.org/pdf/2409.10819"
    },
    "subjects": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 17 Sep 2024 01:27:28 UTC (10,939 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 04:44:02 UTC (803 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/09/17",
    "title": "EzAudio: Enhancing Text-to-Audio Generation with Efficient Diffusion Transformer",
    "tasks": [
      "Audio Generation"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16116",
    "abstract": "Teledermatology has become a widely accepted communication method in daily clinical practice, enabling remote care while showing strong agreement with in-person visits. Poor image quality remains an unsolved problem in teledermatology and is a major concern to practitioners, as bad-quality images reduce the usefulness of the remote consultation process. However, research on Image Quality Assessment (IQA) in dermatology is sparse, and does not leverage the latest advances in non-dermatology IQA, such as using larger image databases with ratings from large groups of human observers. In this work, we propose cross-domain training of IQA models, combining dermatology and non-dermatology IQA datasets. For this purpose, we created a novel dermatology IQA database, Legit.Health-DIQA-Artificial, using dermatology images from several sources and having them annotated by a group of human observers. We demonstrate that cross-domain training yields optimal performance across domains and overcomes one of the biggest limitations in dermatology IQA, which is the small scale of data, and leads to models trained on a larger pool of image distortions, resulting in a better management of image quality in the teledermatology process.",
    "authors": [
      "Montilla, Ignacio Hern\u00e1ndez",
      "Medela, Alfonso",
      "Pasquali, Paola",
      "Aguilar, Andy",
      "Mac Carthy, Taig",
      "Fern\u00e1ndez, Gerardo",
      "Martorell, Antonio",
      "Onieva, Enrique"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16116v1",
      "Other Formats": "https://arxiv.org/format/2506.16116",
      "TeX Source": "https://arxiv.org/src/2506.16116",
      "View PDF": "https://arxiv.org/pdf/2506.16116"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 08:07:06 UTC (4,499 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Enhanced Dermatology Image Quality Assessment via Cross-Domain Training",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16211",
    "abstract": "Learning real-world robotic manipulation is challenging, particularly when limited demonstrations are available. Existing methods for few-shot manipulation often rely on simulation-augmented data or pre-built modules like grasping and pose estimation, which struggle with sim-to-real gaps and lack extensibility. While large-scale imitation pre-training shows promise, adapting these general-purpose policies to specific tasks in data-scarce settings remains unexplored. To achieve this, we propose ControlVLA, a novel framework that bridges pre-trained VLA models with object-centric representations via a ControlNet-style architecture for efficient fine-tuning. Specifically, to introduce object-centric conditions without overwriting prior knowledge, ControlVLA zero-initializes a set of projection layers, allowing them to gradually adapt the pre-trained manipulation policies. In real-world experiments across 6 diverse tasks, including pouring cubes and folding clothes, our method achieves a 76.7% success rate while requiring only 10-20 demonstrations -- a significant improvement over traditional approaches that require more than 100 demonstrations to achieve comparable success. Additional experiments highlight ControlVLA's extensibility to long-horizon tasks and robustness to unseen objects and backgrounds.",
    "authors": [
      "Li, Puhao",
      "Wu, Yingying",
      "Xi, Ziheng",
      "Li, Wanlin",
      "Huang, Yuzhe",
      "Zhang, Zhiyuan",
      "Chen, Yinghan",
      "Wang, Jianan",
      "Zhu, Song-Chun",
      "Liu, Tengyu",
      "Huang, Siyuan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16211v1",
      "Other Formats": "https://arxiv.org/format/2506.16211",
      "TeX Source": "https://arxiv.org/src/2506.16211",
      "View PDF": "https://arxiv.org/pdf/2506.16211"
    },
    "subjects": [
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 10:59:53 UTC (21,003 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16082",
    "abstract": "Dense video captioning is a challenging task that aims to localize and caption multiple events in an untrimmed video. Recent studies mainly follow the transformer-based architecture to jointly perform the two sub-tasks, i.e., event localization and caption generation, in an end-to-end manner. Based on the general philosophy of detection transformer, these methods implicitly learn the event locations and event semantics, which requires a large amount of training data and limits the model's performance in practice. In this paper, we propose a novel dense video captioning framework, named PR-DETR, which injects the explicit position and relation prior into the detection transformer to improve the localization accuracy and caption quality, simultaneously. On the one hand, we first generate a set of position-anchored queries to provide the scene-specific position and semantic information about potential events as position prior, which serves as the initial event search regions to eliminate the implausible event proposals. On the other hand, we further design an event relation encoder to explicitly calculate the relationship between event boundaries as relation prior to guide the event interaction to improve the semantic coherence of the captions. Extensive ablation studies are conducted to verify the effectiveness of the position and relation prior. Experimental results also show the competitive performance of our method on ActivityNet Captions and YouCook2 datasets.",
    "authors": [
      "Li, Yizhe",
      "Zhou, Sanping",
      "Qin, Zheng",
      "Wang, Le"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16082v1",
      "Other Formats": "https://arxiv.org/format/2506.16082",
      "TeX Source": "https://arxiv.org/src/2506.16082",
      "View PDF": "https://arxiv.org/pdf/2506.16082"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 07:07:42 UTC (1,096 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16196",
    "abstract": "Prompting has become a dominant paradigm for adapting large language models (LLMs). While discrete (textual) prompts are widely used for their interpretability, soft (parameter) prompts have recently gained traction in APIs. This is because they can encode information from more training samples while minimizing the user's token usage, leaving more space in the context window for task-specific input. However, soft prompts are tightly coupled to the LLM they are tuned on, limiting their generalization to other LLMs. This constraint is particularly problematic for efficiency and privacy: (1) tuning prompts on each LLM incurs high computational costs, especially as LLMs continue to grow in size. Additionally, (2) when the LLM is hosted externally, soft prompt tuning often requires sharing private data with the LLM provider. For instance, this is the case with the NVIDIA NeMo API. To address these issues, we propose POST (Privacy Of Soft prompt Transfer), a framework that enables private tuning of soft prompts on a small model and subsequently transfers these prompts to a larger LLM. POST uses knowledge distillation to derive a small model directly from the large LLM to improve prompt transferability, tunes the soft prompt locally, optionally with differential privacy guarantees, and transfers it back to the larger LLM using a small public dataset. Our experiments show that POST reduces computational costs, preserves privacy, and effectively transfers high-utility soft prompts.",
    "authors": [
      "Wang, Xun",
      "Xu, Jing",
      "Boenisch, Franziska",
      "Backes, Michael",
      "Choquette-Choo, Christopher A.",
      "Dziedzic, Adam"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16196v1",
      "Other Formats": "https://arxiv.org/format/2506.16196",
      "TeX Source": "https://arxiv.org/src/2506.16196",
      "View PDF": "https://arxiv.org/pdf/2506.16196"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 10:25:16 UTC (554 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Efficient and Privacy-Preserving Soft Prompt Transfer for LLMs",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16639",
    "abstract": "Requirements over strings, commonly represented using natural language (NL), are particularly relevant for software systems due to their heavy reliance on string data manipulation. While individual requirements can usually be analyzed manually, verifying properties (e.g., satisfiability) over sets of NL requirements is particularly challenging. Formal approaches (e.g., SMT solvers) may efficiently verify such properties, but are known to have theoretical limitations. Additionally, the translation of NL requirements into formal constraints typically requires significant manual effort. Recently, large language models (LLMs) have emerged as an alternative approach for formal reasoning tasks, but their effectiveness in verifying requirements over strings is less studied. In this paper, we introduce a hybrid approach that verifies the satisfiability of NL requirements over strings by using LLMs (1) to derive a satisfiability outcome (and a consistent string, if possible), and (2) to generate declarative (i.e., SMT) and imperative (i.e., Python) checkers, used to validate the correctness of (1). In our experiments, we assess the performance of four LLMs. Results show that LLMs effectively translate natural language into checkers, even achieving perfect testing accuracy for Python-based checkers. These checkers substantially help LLMs in generating a consistent string and accurately identifying unsatisfiable requirements, leading to more than doubled generation success rate and F1-score in certain cases compared to baselines without generated checkers.",
    "authors": [
      "Chen, Boqi",
      "Babikian, Aren A.",
      "Feng, Shuzhao",
      "Varr\u00f3, D\u00e1niel",
      "Mussbacher, Gunter"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16639v1",
      "Other Formats": "https://arxiv.org/format/2506.16639",
      "TeX Source": "https://arxiv.org/src/2506.16639",
      "View PDF": "https://arxiv.org/pdf/2506.16639"
    },
    "subjects": [
      "Software Engineering (cs.SE)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 22:41:43 UTC (306 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "LLM-based Satisfiability Checking of String Requirements by Consistent Data and Checker Generation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16056",
    "abstract": "The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.",
    "authors": [
      "Liu, Puchun",
      "Chen, C. L. Philip",
      "He, Yubin",
      "Zhang, Tong"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16056v1",
      "Other Formats": "https://arxiv.org/format/2506.16056",
      "TeX Source": "https://arxiv.org/src/2506.16056",
      "View PDF": "https://arxiv.org/pdf/2506.16056"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 06:31:08 UTC (1,073 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15948",
    "abstract": "In this work, we explore the interplay between information and computation in non-linear transform-based compression for broad classes of modern information-processing tasks. We first investigate two emerging nonlinear data transformation frameworks for image compression: Implicit Neural Representations (INRs) and 2D Gaussian Splatting (GS). We analyze their representational properties, behavior under lossy compression, and convergence dynamics. Our results highlight key trade-offs between INR's compact, resolution-flexible neural field representations and GS's highly parallelizable, spatially interpretable fitting, providing insights for future hybrid and compression-aware frameworks. Next, we introduce the textual transform that enables efficient compression at ultra-low bitrate regimes and simultaneously enhances human perceptual satisfaction. When combined with the concept of denoising via lossy compression, the textual transform becomes a powerful tool for denoising tasks. Finally, we present a Lempel-Ziv (LZ78) \"transform\", a universal method that, when applied to any member of a broad compressor family, produces new compressors that retain the asymptotic universality guarantees of the LZ78 algorithm. Collectively, these three transforms illuminate the fundamental trade-offs between coding efficiency and computational cost. We discuss how these insights extend beyond compression to tasks such as classification, denoising, and generative AI, suggesting new pathways for using non-linear transformations to balance resource constraints and performance.",
    "authors": [
      "Ding, Connor",
      "Gorle, Abhiram Rao",
      "Jeong, Jiwon",
      "Sagan, Naomi",
      "Weissman, Tsachy"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15948v1",
      "Other Formats": "https://arxiv.org/format/2506.15948",
      "TeX Source": "https://arxiv.org/src/2506.15948",
      "View PDF": "https://arxiv.org/pdf/2506.15948"
    },
    "subjects": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 01:13:04 UTC (44,402 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Information-computation trade-offs in non-linear transforms",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16343",
    "abstract": "We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.",
    "authors": [
      "M\u00f6ller, Cedric",
      "Usbeck, Ricardo"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16343v1",
      "Other Formats": "https://arxiv.org/format/2506.16343",
      "TeX Source": "https://arxiv.org/src/2506.16343",
      "View PDF": "https://arxiv.org/pdf/2506.16343"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 14:21:08 UTC (182 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Analyzing the Influence of Knowledge Graph Information on Relation Extraction",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2411.13057",
    "abstract": "Existing click-through rate (CTR) prediction works have studied the role of feature interaction through a variety of techniques. Each interaction technique exhibits its own strength, and solely using one type usually constrains the model's capability to capture the complex feature relationships, especially for industrial data with enormous input feature fields. Recent research shows that effective CTR models often combine an MLP network with a dedicated feature interaction network in a two-parallel structure. However, the interplay and cooperative dynamics between different streams or branches remain under-researched. In this work, we introduce a novel Multi-Branch Cooperation Network (MBCnet) which enables multiple branch networks to collaborate with each other for better complex feature interaction modeling. Specifically, MBCnet consists of three branches: the Extensible Feature Grouping and Crossing (EFGC) branch that promotes the model's memorization ability of specific feature fields, the low rank Cross Net branch and Deep branch to enhance explicit and implicit feature crossing for improved generalization. Among these branches, a novel cooperation scheme is proposed based on two principles: Branch co-teaching and moderate differentiation. Branch co-teaching encourages well-learned branches to support poorly-learned ones on specific training samples. Moderate differentiation advocates branches to maintain a reasonable level of difference in their feature representations on the same inputs. This cooperation strategy improves learning through mutual knowledge sharing and boosts the discovery of diverse feature interactions across branches. Experiments on large-scale industrial datasets and online A/B test at Taobao app demonstrate MBCnet's superior performance, delivering a 0.09 point increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes are available online.",
    "authors": [
      "Chen, Xu",
      "Cheng, Zida",
      "Pan, Yuangang",
      "Xiao, Shuai",
      "Liu, Xiaoming",
      "Lan, Jinsong",
      "Zhu, Xiaoyong",
      "Zheng, Bo",
      "Tsang, Ivor W."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2411.13057v2",
      "Other Formats": "https://arxiv.org/format/2411.13057",
      "TeX Source": "https://arxiv.org/src/2411.13057",
      "View PDF": "https://arxiv.org/pdf/2411.13057"
    },
    "subjects": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 20 Nov 2024 06:10:06 UTC (6,155 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 12:53:17 UTC (3,655 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/11/20",
    "title": "Learning Multi-Branch Cooperation for Enhanced Click-Through Rate Prediction at Taobao",
    "tasks": [
      "Click-Through Rate Prediction",
      "Memorization"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16592",
    "abstract": "Breast ultrasound imaging is a valuable tool for early breast cancer detection, but automated tumor segmentation is challenging due to inherent noise, variations in scale of lesions, and fuzzy boundaries. To address these challenges, we propose a novel hybrid attention-based network for lesion segmentation. Our proposed architecture integrates a pre-trained DenseNet121 in the encoder part for robust feature extraction with a multi-branch attention-enhanced decoder tailored for breast ultrasound images. The bottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE), and Scaled Dot-Product Attention (SDPA) to learn global context, spatial relationships, and relative positional features. The Spatial Feature Enhancement Block (SFEB) is embedded at skip connections to refine and enhance spatial features, enabling the network to focus more effectively on tumor regions. A hybrid loss function combining Binary Cross-Entropy (BCE) and Jaccard Index loss optimizes both pixel-level accuracy and region-level overlap metrics, enhancing robustness to class imbalance and irregular tumor shapes. Experiments on public datasets demonstrate that our method outperforms existing approaches, highlighting its potential to assist radiologists in early and accurate breast cancer diagnosis.",
    "authors": [
      "Aslam, Muhammad Azeem",
      "Naveed, Asim",
      "Ahmed, Nisar"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16592v1",
      "Other Formats": "https://arxiv.org/format/2506.16592",
      "TeX Source": "https://arxiv.org/src/2506.16592",
      "View PDF": "https://arxiv.org/pdf/2506.16592"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 20:32:54 UTC (1,555 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16058",
    "abstract": "Open-vocabulary segmentation aims to achieve segmentation of arbitrary categories given unlimited text inputs as guidance. To achieve this, recent works have focused on developing various technical routes to exploit the potential of large-scale pre-trained vision-language models and have made significant progress on existing benchmarks. However, we find that existing test sets are limited in measuring the models' comprehension of ``open-vocabulary\" concepts, as their semantic space closely resembles the training space, even with many overlapping categories. To this end, we present a new benchmark named OpenBench that differs significantly from the training semantics. It is designed to better assess the model's ability to understand and segment a wide range of real-world concepts. When testing existing methods on OpenBench, we find that their performance diverges from the conclusions drawn on existing test sets. In addition, we propose a method named OVSNet to improve the segmentation performance for diverse and open scenarios. Through elaborate fusion of heterogeneous features and cost-free expansion of the training space, OVSNet achieves state-of-the-art results on both existing datasets and our proposed OpenBench. Corresponding analysis demonstrate the soundness and effectiveness of our proposed benchmark and method.",
    "authors": [
      "Liu, Yong",
      "Wu, SongLi",
      "Bai, Sule",
      "Wang, Jiahao",
      "Wang, Yitong",
      "Tang, Yansong"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16058v1",
      "Other Formats": "https://arxiv.org/format/2506.16058",
      "TeX Source": "https://arxiv.org/src/2506.16058",
      "View PDF": "https://arxiv.org/pdf/2506.16058"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 06:32:53 UTC (2,585 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.10954",
    "abstract": "Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the traditional process for creating such benchmarks is notoriously challenging and labor-intensive, particularly in the stages of setting up evaluation environments, grading test outcomes, and validating task instances. In this paper, we propose SWE-Factory, an automated pipeline designed to address these challenges. To tackle these issues, our pipeline integrates three core automated components. First, we introduce SWE-Builder, a multi-agent system that automates evaluation environment construction, which employs four specialized agents that work in a collaborative, iterative loop and leverages an environment memory pool to enhance efficiency. Second, we introduce a standardized, exit-code-based grading method that eliminates the need for manually writing custom parsers. Finally, we automate the fail2pass validation process using these reliable exit code signals. Experiments on 671 issues across four programming languages show that our pipeline can effectively construct valid task instances; for example, with GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per instance, while with Gemini-2.5-flash, it achieves comparable performance at the lowest cost of $0.024 per instance. We also demonstrate that our exit-code-based grading achieves 100% accuracy compared to manual inspection, and our automated fail2pass validation reaches a precision of 0.92 and a recall of 1.00. We hope our automated pipeline will accelerate the collection of large-scale, high-quality GitHub issue resolution datasets for both training and evaluation. Our code and datasets are released at https://github.com/DeepSoftwareAnalytics/swe-factory.",
    "authors": [
      "Guo, Lianghong",
      "Wang, Yanlin",
      "Li, Caihua",
      "Yang, Pengyu",
      "Chen, Jiachi",
      "Tao, Wei",
      "Zou, Yingtian",
      "Tang, Duyu",
      "Zheng, Zibin"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.10954v2",
      "Other Formats": "https://arxiv.org/format/2506.10954",
      "TeX Source": "https://arxiv.org/src/2506.10954",
      "View PDF": "https://arxiv.org/pdf/2506.10954"
    },
    "subjects": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 12 Jun 2025 17:54:17 UTC (2,868 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 15:54:48 UTC (2,868 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/12",
    "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks",
    "repo_urls": [
      "https://github.com/deepsoftwareanalytics/swe-factory"
    ],
    "tasks": [
      "GitHub issue resolution",
      "valid"
    ],
    "datasets": [
      {
        "dataset_name": "Deep-Software-Analytics/SweSetupBench-lite",
        "downloads": "48",
        "likes": "0",
        "link": "https://huggingface.co/datasets/Deep-Software-Analytics/SweSetupBench-lite"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.16039",
    "abstract": "The brain is a highly complex organ that manages many important tasks, including movement, memory and thinking. Brain-related conditions, like tumors and degenerative disorders, can be hard to diagnose and treat. Magnetic Resonance Imaging (MRI) serves as a key tool for identifying these conditions, offering high-resolution images of brain structures. Despite this, interpreting MRI scans can be complicated. This study tackles this challenge by conducting a comparative analysis of Vision Transformer (ViT) and Transfer Learning (TL) models such as VGG16, VGG19, Resnet50V2, MobilenetV2 for classifying brain diseases using MRI data from Bangladesh based dataset. ViT, known for their ability to capture global relationships in images, are particularly effective for medical imaging tasks. Transfer learning helps to mitigate data constraints by fine-tuning pre-trained models. Furthermore, Explainable AI (XAI) methods such as GradCAM, GradCAM++, LayerCAM, ScoreCAM, and Faster-ScoreCAM are employed to interpret model predictions. The results demonstrate that ViT surpasses transfer learning models, achieving a classification accuracy of 94.39%. The integration of XAI methods enhances model transparency, offering crucial insights to aid medical professionals in diagnosing brain diseases with greater precision.",
    "authors": [
      "Sarker, Shuvashis",
      "Refat, Shamim Rahim",
      "Preotee, Faika Fairuj",
      "Islam, Shifat",
      "Muhammad, Tashreef",
      "Hoque, Mohammad Ashraful"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.16039v2",
      "Other Formats": "https://arxiv.org/format/2505.16039",
      "TeX Source": "https://arxiv.org/src/2505.16039",
      "View PDF": "https://arxiv.org/pdf/2505.16039"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 21 May 2025 21:38:22 UTC (1,865 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 19:22:10 UTC (1,755 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/21",
    "title": "An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection",
    "tasks": [
      "Transfer Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16407",
    "abstract": "Visual Document Understanding (VDU) systems have achieved strong performance in information extraction by integrating textual, layout, and visual signals. However, their robustness under realistic adversarial perturbations remains insufficiently explored. We introduce the first unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models. Our method covers six gradient-based layout attack scenarios, incorporating manipulations of OCR bounding boxes, pixels, and texts across both word and line granularities, with constraints on layout perturbation budget (e.g., IoU >= 0.6) to preserve plausibility. Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and six model families demonstrate that line-level attacks and compound perturbations (BBox + Pixel + Text) yield the most severe performance degradation. Projected Gradient Descent (PGD)-based BBox perturbations outperform random-shift baselines in all investigated models. Ablation studies further validate the impact of layout budget, text modification, and adversarial transferability.",
    "authors": [
      "Tien, Dong Nguyen",
      "Le, Dung D."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16407v1",
      "Other Formats": "https://arxiv.org/format/2506.16407",
      "TeX Source": "https://arxiv.org/src/2506.16407",
      "View PDF": "https://arxiv.org/pdf/2506.16407"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 15:38:31 UTC (343 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16578",
    "abstract": "Effective stroke triage in emergency settings often relies on clinicians' ability to identify subtle abnormalities in facial muscle coordination. While recent AI models have shown promise in detecting such patterns from patient facial videos, their reliance on real patient data raises significant ethical and privacy challenges -- especially when training robust and generalizable models across institutions. To address these concerns, we propose SafeTriage, a novel method designed to de-identify patient facial videos while preserving essential motion cues crucial for stroke diagnosis. SafeTriage leverages a pretrained video motion transfer (VMT) model to map the motion characteristics of real patient faces onto synthetic identities. This approach retains diagnostically relevant facial dynamics without revealing the patients' identities. To mitigate the distribution shift between normal population pre-training videos and patient population test videos, we introduce a conditional generative model for visual prompt tuning, which adapts the input space of the VMT model to ensure accurate motion transfer without needing to fine-tune the VMT model backbone. Comprehensive evaluation, including quantitative metrics and clinical expert assessments, demonstrates that SafeTriage-produced synthetic videos effectively preserve stroke-relevant facial patterns, enabling reliable AI-based triage. Our evaluations also show that SafeTriage provides robust privacy protection while maintaining diagnostic accuracy, offering a secure and ethically sound foundation for data sharing and AI-driven clinical analysis in neurological disorders.",
    "authors": [
      "Cai, Tongan",
      "Ni, Haomiao",
      "Ma, Wenchao",
      "Xue, Yuan",
      "Ma, Qian",
      "Leicht, Rachel",
      "Wong, Kelvin",
      "Volpi, John",
      "Wong, Stephen T. C.",
      "Wang, James Z.",
      "Huang, Sharon X."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16578v1",
      "Other Formats": "https://arxiv.org/format/2506.16578",
      "TeX Source": "https://arxiv.org/src/2506.16578",
      "View PDF": "https://arxiv.org/pdf/2506.16578"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 20:02:47 UTC (583 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.01816",
    "abstract": "The tradeoff between reconstruction quality and compute required for video super-resolution (VSR) remains a formidable challenge in its adoption for deployment on resource-constrained edge devices. While transformer-based VSR models have set new benchmarks for reconstruction quality in recent years, these require substantial computational resources. On the other hand, lightweight models that have been introduced even recently struggle to deliver state-of-the-art reconstruction. We propose a novel lightweight and parameter-efficient neural architecture for VSR that achieves state-of-the-art reconstruction accuracy with just 2.3 million parameters. Our model enhances information utilization based on several architectural attributes. Firstly, it uses 2D wavelet decompositions strategically interlayered with learnable convolutional layers to utilize the inductive prior of spatial sparsity of edges in visual data. Secondly, it uses a single memory tensor to capture inter-frame temporal information while avoiding the computational cost of previous memory-based schemes. Thirdly, it uses residual deformable convolutions for implicit inter-frame object alignment that improve upon deformable convolutions by enhancing spatial information in inter-frame feature differences. Architectural insights from our model can pave the way for real-time VSR on the edge, such as display devices for streaming data.",
    "authors": [
      "Viswanathan, Kavitha",
      "Pathak, Shashwat",
      "Bharambe, Piyush",
      "Choudhary, Harsh",
      "Sethi, Amit"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.01816v3",
      "Other Formats": "https://arxiv.org/format/2502.01816",
      "TeX Source": "https://arxiv.org/src/2502.01816",
      "View PDF": "https://arxiv.org/pdf/2502.01816"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 3 Feb 2025 20:46:15 UTC (2,855 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sun, 16 Mar 2025 20:16:00 UTC (12,277 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 22:49:16 UTC (6,924 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/02/03",
    "title": "Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions",
    "repo_urls": [
      "https://github.com/kavi1388/RCDM"
    ],
    "tasks": [
      "SSIM",
      "Super-Resolution",
      "Video Super-Resolution"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16112",
    "abstract": "Inspired by text prompts in large language models (LLMs), visual prompts have been explored to enhance the reasoning capabilities of large vision-language models (LVLMs). Current methods design heuristic visual prompts, such as overlaying a text-query-guided attention heatmap on the original input image. However, designing effective prompts manually is challenging and time-consuming, and it often fails to explore the benefits of different visual prompts, leading to sub-optimal performance. To this end, we propose \\textbf{AutoV} that learns to automatically select the optimal visual prompt from various candidates based on given textual queries and the input image. To train AutoV, we developed an automatic data collection and labeling pipeline that evaluates various visual prompts with a pre-trained LVLM. We input a set of visual prompts into the LVLM and rank them according to the prediction losses generated by the model. Using the ranking as a supervision signal, we train AutoV to automatically choose the optimal visual prompt from various visual prompts for LVLMs. Experimental results indicate that AutoV enhances the performance of various LVLMs across multiple popular image understanding tasks. For instance, LLaVA-OV with AutoV achieves $\\textbf{1.7}\\%$ accuracy gain on LLaVA$^{\\text{Wild}}$, and AutoV boosts Qwen2.5-VL by $\\textbf{1.9}\\%$ on MMMU, highlighting its potential as an optimal visual prompting method for LVLMs.",
    "authors": [
      "Zhang, Yuan",
      "Fan, Chun-Kai",
      "Huang, Tao",
      "Lu, Ming",
      "Yu, Sicheng",
      "Pan, Junwen",
      "Cheng, Kuan",
      "She, Qi",
      "Zhang, Shanghang"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16112v1",
      "Other Formats": "https://arxiv.org/format/2506.16112",
      "TeX Source": "https://arxiv.org/src/2506.16112",
      "View PDF": "https://arxiv.org/pdf/2506.16112"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 08:02:53 UTC (13,942 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16406",
    "abstract": "Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce \\textbf{Drag-and-Drop LLMs (\\textit{DnD})}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to \\textbf{12,000$\\times$} lower overhead than full fine-tuning, ii) average gains up to \\textbf{30\\%} in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at \\href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.",
    "authors": [
      "Liang, Zhiyuan",
      "Tang, Dongwen",
      "Zhou, Yuhao",
      "Zhao, Xuanlei",
      "Shi, Mingjia",
      "Zhao, Wangbo",
      "Li, Zekai",
      "Wang, Peihao",
      "Sch\u00fcrholt, Konstantin",
      "Borth, Damian",
      "Bronstein, Michael M.",
      "You, Yang",
      "Wang, Zhangyang",
      "Wang, Kai"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16406v1",
      "Other Formats": "https://arxiv.org/format/2506.16406",
      "TeX Source": "https://arxiv.org/src/2506.16406",
      "View PDF": "https://arxiv.org/pdf/2506.16406"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 15:38:21 UTC (341 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16396",
    "abstract": "Natural language can offer a concise and human-interpretable means of specifying reinforcement learning (RL) tasks. The ability to extract rewards from a language instruction can enable the development of robotic systems that can learn from human guidance; however, it remains a challenging problem, especially in visual environments. Existing approaches that employ large, pretrained language models either rely on non-visual environment representations, require prohibitively large amounts of feedback, or generate noisy, ill-shaped reward functions. In this paper, we propose a novel method, $\\textbf{GoalLadder}$, that leverages vision-language models (VLMs) to train RL agents from a single language instruction in visual environments. GoalLadder works by incrementally discovering states that bring the agent closer to completing a task specified in natural language. To do so, it queries a VLM to identify states that represent an improvement in agent's task progress and to rank them using pairwise comparisons. Unlike prior work, GoalLadder does not trust VLM's feedback completely; instead, it uses it to rank potential goal states using an ELO-based rating system, thus reducing the detrimental effects of noisy VLM feedback. Over the course of training, the agent is tasked with minimising the distance to the top-ranked goal in a learned embedding space, which is trained on unlabelled visual data. This key feature allows us to bypass the need for abundant and accurate feedback typically required to train a well-shaped reward function. We demonstrate that GoalLadder outperforms existing related methods on classic control and robotic manipulation environments with the average final success rate of $\\sim$95% compared to only $\\sim$45% of the best competitor.",
    "authors": [
      "Zakharov, Alexey",
      "Whiteson, Shimon"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16396v1",
      "Other Formats": "https://arxiv.org/format/2506.16396",
      "TeX Source": "https://arxiv.org/src/2506.16396",
      "View PDF": "https://arxiv.org/pdf/2506.16396"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 15:28:27 UTC (3,953 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "GoalLadder: Incremental Goal Discovery with Vision-Language Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16273",
    "abstract": "Fine-Grained Image Retrieval~(FGIR) faces challenges in learning discriminative visual representations to retrieve images with similar fine-grained features. Current leading FGIR solutions typically follow two regimes: enforce pairwise similarity constraints in the semantic embedding space, or incorporate a localization sub-network to fine-tune the entire model. However, such two regimes tend to overfit the training data while forgetting the knowledge gained from large-scale pre-training, thus reducing their generalization ability. In this paper, we propose a Dual-Vision Adaptation (DVA) approach for FGIR, which guides the frozen pre-trained model to perform FGIR through collaborative sample and feature adaptation. Specifically, we design Object-Perceptual Adaptation, which modifies input samples to help the pre-trained model perceive critical objects and elements within objects that are helpful for category prediction. Meanwhile, we propose In-Context Adaptation, which introduces a small set of parameters for feature adaptation without modifying the pre-trained parameters. This makes the FGIR task using these adjusted features closer to the task solved during the pre-training. Additionally, to balance retrieval efficiency and performance, we propose Discrimination Perception Transfer to transfer the discriminative knowledge in the object-perceptual adaptation to the image encoder using the knowledge distillation mechanism. Extensive experiments show that DVA has fewer learnable parameters and performs well on three in-distribution and three out-of-distribution fine-grained datasets.",
    "authors": [
      "Jiang, Xin",
      "Cao, Meiqi",
      "Tang, Hao",
      "Shen, Fei",
      "Li, Zechao"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16273v1",
      "Other Formats": "https://arxiv.org/format/2506.16273",
      "TeX Source": "https://arxiv.org/src/2506.16273",
      "View PDF": "https://arxiv.org/pdf/2506.16273"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 12:46:55 UTC (1,943 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Fine-grained Image Retrieval via Dual-Vision Adaptation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.07245",
    "abstract": "Recent advancements in large language models (LLMs) have significantly improved performance on the Text-to-SQL task. However, prior approaches typically rely on static, pre-processed database information provided at inference time, which limits the model's ability to fully understand the database contents. Without dynamic interaction, LLMs are constrained to fixed, human-provided context and cannot autonomously explore the underlying data. To address this limitation, we propose SDE-SQL, a framework that enables large language models to perform self-driven exploration of databases during inference. This is accomplished by generating and executing SQL probes, which allow the model to actively retrieve information from the database and iteratively update its understanding of the data. Unlike prior methods, SDE-SQL operates in a zero-shot setting, without relying on any question-SQL pairs as in-context demonstrations. When evaluated on the BIRD benchmark with Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing a new state-of-the-art among methods based on open-source models without supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the performance of SDE-SQL can be further enhanced, yielding an additional 0.52% improvement.",
    "authors": [
      "Xie, Wenxuan",
      "Dai, Yaxun",
      "Jiang, Wenhao"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.07245v2",
      "Other Formats": "https://arxiv.org/format/2506.07245",
      "TeX Source": "https://arxiv.org/src/2506.07245",
      "View PDF": "https://arxiv.org/pdf/2506.07245"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 8 Jun 2025 18:01:26 UTC (358 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 04:10:10 UTC (354 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/08",
    "title": "SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes",
    "tasks": [
      "Text to SQL",
      "Text-To-SQL"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16370",
    "abstract": "Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.",
    "authors": [
      "Williams, Iwan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16370",
      "View PDF": "https://arxiv.org/pdf/2506.16370"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 14:48:40 UTC (421 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Can structural correspondences ground real world representational content in Large Language Models?",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16186",
    "abstract": "Accident detection using Closed Circuit Television (CCTV) footage is one of the most imperative features for enhancing transport safety and efficient traffic control. To this end, this research addresses the issues of supervised monitoring and data deficiency in accident detection systems by adapting excellent deep learning technologies. The motivation arises from rising statistics in the number of car accidents worldwide; this calls for innovation and the establishment of a smart, efficient and automated way of identifying accidents and calling for help to save lives. Addressing the problem of the scarcity of data, the presented framework joins Generative Adversarial Networks (GANs) for synthesizing data and Convolutional Neural Networks (CNN) for model training. Video frames for accidents and non-accidents are collected from YouTube videos, and we perform resizing, image enhancement and image normalisation pixel range adjustments. Three models are used: CNN, Fine-tuned Convolutional Neural Network (FTCNN) and Vision Transformer (VIT) worked best for detecting accidents from CCTV, obtaining an accuracy rate of 94% and 95%, while the CNN model obtained 88%. Such results show that the proposed framework suits traffic safety applications due to its high real-time accident detection capabilities and broad-scale applicability. This work lays the foundation for intelligent surveillance systems in the future for real-time traffic monitoring, smart city framework, and integration of intelligent surveillance systems into emergency management systems.",
    "authors": [
      "Xi, Zhenghao",
      "Liu, Xiang",
      "Liu, Yaqi",
      "Cai, Yitong",
      "Zheng, Yangyu"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16186",
      "View PDF": "https://arxiv.org/pdf/2506.16186"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 10:06:20 UTC (2,238 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16504",
    "abstract": "In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.",
    "authors": [
      "Lai, Zeqiang",
      "Zhao, Yunfei",
      "Liu, Haolin",
      "Zhao, Zibo",
      "Lin, Qingxiang",
      "Shi, Huiwen",
      "Yang, Xianghui",
      "Yang, Mingxin",
      "Yang, Shuhui",
      "Feng, Yifei",
      "Zhang, Sheng",
      "Huang, Xin",
      "Luo, Di",
      "Yang, Fan",
      "Yang, Fang",
      "Wang, Lifu",
      "Liu, Sicong",
      "Tang, Yixuan",
      "Cai, Yulin",
      "He, Zebin",
      "Liu, Tian",
      "Liu, Yuhong",
      "Jiang, Jie",
      "Linus",
      "Huang, Jingwei",
      "Guo, Chunchao"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16504",
      "TeX Source": "https://arxiv.org/src/2506.16504",
      "View PDF": "https://arxiv.org/pdf/2506.16504"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:57:40 UTC (27,955 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16369",
    "abstract": "The high computational demands of Vision Transformers (ViTs), in processing a huge number of tokens, often constrain their practical application in analyzing medical images. This research proposes an adaptive prompt-guided pruning method to selectively reduce the processing of irrelevant tokens in the segmentation pipeline. The prompt-based spatial prior helps to rank the tokens according to their relevance. Tokens with low-relevance scores are down-weighted, ensuring that only the relevant ones are propagated for processing across subsequent stages. This data-driven pruning strategy facilitates end-to-end training, maintains gradient flow, and improves segmentation accuracy by focusing computational resources on essential regions. The proposed framework is integrated with several state-of-the-art models to facilitate the elimination of irrelevant tokens; thereby, enhancing computational efficiency while preserving segmentation accuracy. The experimental results show a reduction of $\\sim$ 35-55\\% tokens; thus reducing the computational costs relative to the baselines. Cost-effective medical image processing, using our framework, facilitates real-time diagnosis by expanding its applicability in resource-constrained environments.",
    "authors": [
      "Dutta, Pallabi",
      "Maity, Anubhab",
      "Mitra, Sushmita"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16369v1",
      "Other Formats": "https://arxiv.org/format/2506.16369",
      "TeX Source": "https://arxiv.org/src/2506.16369",
      "View PDF": "https://arxiv.org/pdf/2506.16369"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 14:45:46 UTC (8,174 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2406.04220",
    "abstract": "Recent advancements in large language models (LLMs) have significantly improved natural language processing (NLP) applications. However, these models often inherit biases from their training data. While several datasets exist for bias detection, most are limited to one or two NLP tasks, typically classification or evaluation, and lack comprehensive coverage across a broader range of tasks. To address this gap, we introduce the Bias Evaluations Across Domains (BEADs) dataset, designed to support a wide range of NLP tasks, including text classification, token classification, bias quantification, and benign language generation. A key contribution of this work is the gold-standard annotation provided by GPT-4 for scalability, with expert verification to ensure high reliability. BEADs can be used for both fine-tuning models (for classification and generation tasks) and evaluating LLM behavior. Our findings show that BEADs effectively surfaces various biases during model fine-tuning and helps reduce biases in language generation tasks while maintaining output quality. The dataset also highlights prevalent demographic biases in LLMs during evaluation. We release BEADs as a practical resource for detecting and mitigating bias across domains, supporting the development of responsible AI systems. Project: https://vectorinstitute.github.io/BEAD/ Data: https://huggingface.co/datasets/shainar/BEAD",
    "authors": [
      "Raza, Shaina",
      "Rahman, Mizanur",
      "Zhang, Michael R."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2406.04220v5",
      "Other Formats": "https://arxiv.org/format/2406.04220",
      "TeX Source": "https://arxiv.org/src/2406.04220",
      "View PDF": "https://arxiv.org/pdf/2406.04220"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 6 Jun 2024 16:18:30 UTC (32,227 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 7 Jun 2024 12:29:48 UTC (32,223 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Sun, 1 Sep 2024 01:17:21 UTC (32,251 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Tue, 24 Dec 2024 15:08:40 UTC (2,473 KB)",
        "link": "/",
        "version": "[v4]"
      },
      {
        "details": "Thu, 19 Jun 2025 11:43:07 UTC (4,084 KB)",
        "version": "[v5]"
      }
    ],
    "submitted_date": "2024/06/06",
    "title": "BEADs: Bias Evaluation Across Domains",
    "tasks": [
      "Benchmarking",
      "Bias Detection",
      "Classification",
      "text-classification",
      "Text Classification",
      "Text Generation",
      "token-classification",
      "Token Classification"
    ],
    "datasets": [
      {
        "dataset_name": "newsmediabias/news-bias-full-data",
        "downloads": "44",
        "likes": "14",
        "link": "https://huggingface.co/datasets/newsmediabias/news-bias-full-data"
      },
      {
        "dataset_name": "shainar/BEAD",
        "downloads": "105",
        "likes": "10",
        "link": "https://huggingface.co/datasets/shainar/BEAD"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.13205",
    "abstract": "With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
    "authors": [
      "Wang, Xuan",
      "Liang, Siyuan",
      "Liu, Zhe",
      "Yu, Yi",
      "Lu, Yuliang",
      "Cao, Xiaochun",
      "Chang, Ee-Chien"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.13205v2",
      "Other Formats": "https://arxiv.org/format/2506.13205",
      "TeX Source": "https://arxiv.org/src/2506.13205",
      "View PDF": "https://arxiv.org/pdf/2506.13205"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 16 Jun 2025 08:09:32 UTC (639 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 05:46:05 UTC (639 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/16",
    "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments",
    "tasks": [
      "Backdoor Attack"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16029",
    "abstract": "Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage. We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",
    "authors": [
      "Qi, Zhenting",
      "Nie, Fan",
      "Alahi, Alexandre",
      "Zou, James",
      "Lakkaraju, Himabindu",
      "Du, Yilun",
      "Xing, Eric",
      "Kakade, Sham",
      "Zhang, Hanlin"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16029",
      "TeX Source": "https://arxiv.org/src/2506.16029",
      "View PDF": "https://arxiv.org/pdf/2506.16029"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 04:58:47 UTC (418 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "EvoLM: In Search of Lost Language Model Training Dynamics",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16572",
    "abstract": "Although image compression is fundamental to visual data processing and has inspired numerous standard and learned codecs, these methods still suffer severe quality degradation at extremely low bits per pixel. While recent diffusion based models provided enhanced generative performance at low bitrates, they still yields limited perceptual quality and prohibitive decoding latency due to multiple denoising steps. In this paper, we propose the first single step diffusion model for image compression (DiffO) that delivers high perceptual quality and fast decoding at ultra low bitrates. DiffO achieves these goals by coupling two key innovations: (i) VQ Residual training, which factorizes a structural base code and a learned residual in latent space, capturing both global geometry and high frequency details; and (ii) rate adaptive noise modulation, which tunes denoising strength on the fly to match the desired bitrate. Extensive experiments show that DiffO surpasses state of the art compression performance while improving decoding speed by about 50x compared to prior diffusion-based methods, greatly improving the practicality of generative codecs. The code will be available at https://github.com/Freemasti/DiffO.",
    "authors": [
      "Park, Chanung",
      "Lee, Joo Chan",
      "Ko, Jong Hwan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16572v1",
      "Other Formats": "https://arxiv.org/format/2506.16572",
      "TeX Source": "https://arxiv.org/src/2506.16572",
      "View PDF": "https://arxiv.org/pdf/2506.16572"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 19:53:27 UTC (6,112 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16574",
    "abstract": "Modern neural network based speech recognition models are required to continually absorb new data without re-training the whole system, especially in downstream applications using foundation models, having no access to the original training data. Continually training the models in a rehearsal-free, multilingual, and language agnostic condition, likely leads to catastrophic forgetting, when a seemingly insignificant disruption to the weights can destructively harm the quality of the models. Inspired by the ability of human brains to learn and consolidate knowledge through the waking-sleeping cycle, we propose a continual learning approach with two distinct phases: factorization and centralization, learning and merging knowledge accordingly. Our experiments on a sequence of varied code-switching datasets showed that the centralization stage can effectively prevent catastrophic forgetting by accumulating the knowledge in multiple scattering low-rank adapters.",
    "authors": [
      "Ugan, Enes Yavuz",
      "Pham, Ngoc-Quan",
      "Waibel, Alexander"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16574v1",
      "Other Formats": "https://arxiv.org/format/2506.16574",
      "TeX Source": "https://arxiv.org/src/2506.16574",
      "View PDF": "https://arxiv.org/pdf/2506.16574"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 19:59:24 UTC (163 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Weight Factorization and Centralization for Continual Learning in Speech Recognition",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.14911",
    "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable capabilities on widely benchmarked high-resource languages. However, linguistic nuances of under-resourced languages remain unexplored. We introduce Batayan, a holistic Filipino benchmark that systematically evaluates LLMs across three key natural language processing (NLP) competencies: understanding, reasoning, and generation. Batayan consolidates eight tasks, three of which have not existed prior for Filipino corpora, covering both Tagalog and code-switched Taglish utterances. Our rigorous, native-speaker-driven adaptation and validation processes ensures fluency and authenticity to the complex morphological and syntactic structures of Filipino, alleviating the pervasive translationese bias in existing Filipino corpora. We report empirical results on a variety of open-source and commercial LLMs, highlighting significant performance gaps that signal the under-representation of Filipino in pre-training corpora, the unique hurdles in modeling Filipino's rich morphology and construction, and the importance of explicit Filipino language support. Moreover, we discuss the practical challenges encountered in dataset construction and propose principled solutions for building culturally and linguistically-faithful resources in under-represented languages. We also provide a public evaluation suite as a clear foundation for iterative, community-driven progress in Filipino NLP.",
    "authors": [
      "Montalan, Jann Railey",
      "Layacan, Jimson Paulo",
      "Africa, David Demitri",
      "Flores, Richell Isaiah",
      "Lopez II, Michael T.",
      "Magsajo, Theresa Denise",
      "Cayabyab, Anjanette",
      "Tjhi, William Chandra"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.14911v2",
      "Other Formats": "https://arxiv.org/format/2502.14911",
      "TeX Source": "https://arxiv.org/src/2502.14911",
      "View PDF": "https://arxiv.org/pdf/2502.14911"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 19 Feb 2025 07:03:15 UTC (305 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 08:30:50 UTC (956 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/19",
    "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.08584",
    "abstract": "Reliable artificial intelligence (AI) models for medical image analysis often depend on large and diverse labeled datasets. Federated learning (FL) offers a decentralized and privacy-preserving approach to training but struggles in highly non-independent and identically distributed (non-IID) settings, where institutions with more representative data may experience degraded performance. Moreover, existing large-scale FL studies have been limited to adult datasets, neglecting the unique challenges posed by pediatric data, which introduces additional non-IID variability. To address these limitations, we analyzed n=398,523 adult chest radiographs from diverse institutions across multiple countries and n=9,125 pediatric images, leveraging transfer learning from general-purpose self-supervised image representations to classify pneumonia and cases with no abnormality. Using state-of-the-art vision transformers, we found that FL improved performance only for smaller adult datasets (P<0.001) but degraded performance for larger datasets (P<0.064) and pediatric cases (P=0.242). However, equipping FL with self-supervised weights significantly enhanced outcomes across pediatric cases (P=0.031) and most adult datasets (P<0.008), except the largest dataset (P=0.052). These findings underscore the potential of easily deployable general-purpose self-supervised image representations to address non-IID challenges in clinical FL applications and highlight their promise for enhancing patient outcomes and advancing pediatric healthcare, where data scarcity and variability remain persistent obstacles.",
    "authors": [
      "Lotfinia, Mahshad",
      "Tayebiarasteh, Arash",
      "Samiei, Samaneh",
      "Joodaki, Mehdi",
      "Arasteh, Soroosh Tayebi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2504.08584",
      "View PDF": "https://arxiv.org/pdf/2504.08584"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 11 Apr 2025 14:38:09 UTC (1,118 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 17:21:48 UTC (1,188 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/04/11",
    "title": "Boosting multi-demographic federated learning for chest radiograph analysis using general-purpose self-supervised representations",
    "tasks": [
      "Federated Learning",
      "Medical Image Analysis",
      "Privacy Preserving",
      "Transfer Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2408.00256",
    "abstract": "Federated Learning (FL) is an advanced distributed machine learning approach, that protects the privacy of each vehicle by allowing the model to be trained on multiple devices simultaneously without the need to upload all data to a road side unit (RSU). This enables FL to handle scenarios with sensitive or widely distributed data. However, in these fields, it is well known that the labeling costs can be a significant expense, and models relying on labels are not suitable for these rapidly evolving fields especially in vehicular networks, or mobile internet of things (MIoT), where new data emerges constantly. To handle this issue, the self-supervised learning paves the way for training without labels. Additionally, for vehicles with high velocity, owing to blurred images, simple aggregation not only impacts the accuracy of the aggregated model but also reduces the convergence speed of FL. This paper proposes a FL algorithm based on image blur level to aggregation, called FLSimCo, which does not require labels and serves as a pre-training stage for self-supervised learning in the vehicular environment. Simulation results demonstrate that the proposed algorithm exhibits fast and stable convergence.",
    "authors": [
      "Gu, Xueying",
      "Wu, Qiong",
      "Fan, Pingyi",
      "Fan, Qiang"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2408.00256v2",
      "Other Formats": "https://arxiv.org/format/2408.00256",
      "TeX Source": "https://arxiv.org/src/2408.00256",
      "View PDF": "https://arxiv.org/pdf/2408.00256"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 1 Aug 2024 03:28:10 UTC (958 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 07:23:51 UTC (1,027 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/08/01",
    "title": "Mobility-Aware Federated Self-supervised Learning in Vehicular Network",
    "tasks": [
      "Federated Learning",
      "Self-Supervised Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2501.09481",
    "abstract": "Inferring object 3D position and orientation from a single RGB camera is a foundational task in computer vision with many important applications. Traditionally, 3D object detection methods are trained in a fully-supervised setup, requiring LiDAR and vast amounts of human annotations, which are laborious, costly, and do not scale well with the ever-increasing amounts of data being captured. We present a novel method to train a 3D object detector from a single RGB camera without domain-specific human annotations, making orders of magnitude more data available for training. The method uses newly proposed Local Object Motion Model to disentangle object movement source between subsequent frames, is approximately 700 times faster than previous work and compensates camera focal length differences to aggregate multiple datasets. The method is evaluated on three public datasets, where despite using no human labels, it outperforms prior work by a significant margin. It also shows its versatility as a pre-training tool for fully-supervised training and shows that combining pseudo-labels from multiple datasets can achieve comparable accuracy to using human labels from a single dataset. The source code and model are available at https://github.com/jskvrna/MonoSOWA.",
    "authors": [
      "Skvrna, Jan",
      "Neumann, Lukas"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2501.09481v3",
      "Other Formats": "https://arxiv.org/format/2501.09481",
      "TeX Source": "https://arxiv.org/src/2501.09481",
      "View PDF": "https://arxiv.org/pdf/2501.09481"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 16 Jan 2025 11:35:22 UTC (13,543 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Mon, 10 Mar 2025 12:27:10 UTC (46,739 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 21:30:04 UTC (45,052 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/01/16",
    "title": "MonoSOWA: Scalable monocular 3D Object detector Without human Annotations",
    "tasks": [
      "3D Object Detection",
      "Autonomous Driving",
      "Object",
      "object-detection",
      "Object Detection"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2410.18973",
    "abstract": "A Bayesian coreset is a small, weighted subset of a data set that replaces the full data during inference to reduce computational cost. The state-of-the-art coreset construction algorithm, Coreset Markov chain Monte Carlo (Coreset MCMC), uses draws from an adaptive Markov chain targeting the coreset posterior to train the coreset weights via stochastic gradient optimization. However, the quality of the constructed coreset, and thus the quality of its posterior approximation, is sensitive to the stochastic optimization learning rate. In this work, we propose a learning-rate-free stochastic gradient optimization procedure, Hot-start Distance over Gradient (Hot DoG), for training coreset weights in Coreset MCMC without user tuning effort. We provide a theoretical analysis of the convergence of the coreset weights produced by Hot DoG. We also provide empirical results demonstrate that Hot DoG provides higher quality posterior approximations than other learning-rate-free stochastic gradient methods, and performs competitively to optimally-tuned ADAM.",
    "authors": [
      "Chen, Naitong",
      "Huggins, Jonathan H.",
      "Campbell, Trevor"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2410.18973v2",
      "Other Formats": "https://arxiv.org/format/2410.18973",
      "TeX Source": "https://arxiv.org/src/2410.18973",
      "View PDF": "https://arxiv.org/pdf/2410.18973"
    },
    "subjects": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 24 Oct 2024 17:59:23 UTC (3,327 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 03:15:03 UTC (3,336 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2024/10/24",
    "title": "Tuning-Free Coreset Markov Chain Monte Carlo via Hot DoG",
    "repo_urls": [
      "https://github.com/NaitongChen/automated-coreset-mcmc-experiments"
    ],
    "tasks": [
      "Stochastic Optimization"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16235",
    "abstract": "Training large-scale distributed machine learning models imposes considerable demands on network infrastructure, often resulting in sudden traffic spikes that lead to congestion, increased latency, and reduced throughput, which would ultimately affect convergence times and overall training performance. While gradient compression techniques are commonly employed to alleviate network load, they frequently compromise model accuracy due to the loss of gradient information. This paper introduces NetSenseML, a novel network adaptive distributed deep learning framework that dynamically adjusts quantization, pruning, and compression strategies in response to real-time network conditions. By actively monitoring network conditions, NetSenseML applies gradient compression only when network congestion negatively impacts convergence speed, thus effectively balancing data payload reduction and model accuracy preservation. Our approach ensures efficient resource usage by adapting reduction techniques based on current network conditions, leading to shorter convergence times and improved training efficiency. We present the design of the NetSenseML adaptive data reduction function and experimental evaluations show that NetSenseML can improve training throughput by a factor of 1.55 to 9.84 times compared to state-of-the-art compression-enabled systems for representative DDL training jobs in bandwidth-constrained conditions.",
    "authors": [
      "Wang, Yisu",
      "Li, Xinjiao",
      "Wu, Ruilong",
      "Chen, Huangxun",
      "Kutscher, Dirk"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16235v1",
      "Other Formats": "https://arxiv.org/format/2506.16235",
      "TeX Source": "https://arxiv.org/src/2506.16235",
      "View PDF": "https://arxiv.org/pdf/2506.16235"
    },
    "subjects": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 11:45:09 UTC (271 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "NetSenseML: Network-Adaptive Compression for Efficient Distributed Machine Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16494",
    "abstract": "Electrocardiograms (ECGs) provide direct, non-invasive measurements of heart activity and are well-established tools for detecting and monitoring cardiovascular disease. However, manual ECG analysis can be time-consuming and prone to errors. Machine learning has emerged as a promising approach for automated heartbeat recognition and classification, but substantial variations in ECG signals make it challenging to develop generalizable models. ECG signals can vary widely across individuals and leads, while datasets often follow different labeling standards and may be biased, all of which greatly hinder supervised methods. Conventional unsupervised methods, e.g. principal component analysis, prioritize large (and often obvious) variances in the data and typically overlook subtle yet clinically relevant patterns. If labels are missing and/or variations are significant but small, both approaches fail. Here, we show that nonlinear dimensionality reduction (NLDR) can accommodate these issues and identify medically relevant features in ECG signals, with no need for training or prior information. Using the MLII and V1 leads of the MIT-BIH dataset, we demonstrate that t-distributed stochastic neighbor embedding and uniform manifold approximation and projection can discriminate individual recordings in mixed populations with >= 90% accuracy and distinguish different arrhythmias in individual patients with a median accuracy of 98.96% and a median F1-score of 91.02%. The results show that NLDR holds much promise for cardiac monitoring, including the limiting cases of single-lead ECG and the current 12-lead standard of care, and for personalized health care beyond cardiology.",
    "authors": [
      "Vazifeh, Amir Reza",
      "Fleischer, Jason W."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16494v1",
      "Other Formats": "https://arxiv.org/format/2506.16494",
      "TeX Source": "https://arxiv.org/src/2506.16494",
      "View PDF": "https://arxiv.org/pdf/2506.16494"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:39:57 UTC (32,118 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Manifold Learning for Personalized and Label-Free Detection of Cardiac Arrhythmias",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16580",
    "abstract": "We propose a first streaming accent conversion (AC) model that transforms non-native speech into a native-like accent while preserving speaker identity, prosody and improving pronunciation. Our approach enables stream processing by modifying a previous AC architecture with an Emformer encoder and an optimized inference mechanism. Additionally, we integrate a native text-to-speech (TTS) model to generate ideal ground-truth data for efficient training. Our streaming AC model achieves comparable performance to the top AC models while maintaining stable latency, making it the first AC system capable of streaming.",
    "authors": [
      "Nguyen, Tuan-Nam",
      "Pham, Ngoc-Quan",
      "Akti, Seymanur",
      "Waibel, Alexander"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16580v1",
      "Other Formats": "https://arxiv.org/format/2506.16580",
      "TeX Source": "https://arxiv.org/src/2506.16580",
      "View PDF": "https://arxiv.org/pdf/2506.16580"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 20:05:29 UTC (135 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Streaming Non-Autoregressive Model for Accent Conversion and Pronunciation Improvement",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.07796",
    "abstract": "Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.",
    "authors": [
      "Wang, Xingjin",
      "Tissue, Howe",
      "Wang, Lu",
      "Li, Linjing",
      "Zeng, Daniel Dajun"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.07796v2",
      "Other Formats": "https://arxiv.org/format/2505.07796",
      "TeX Source": "https://arxiv.org/src/2505.07796",
      "View PDF": "https://arxiv.org/pdf/2505.07796"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 12 May 2025 17:47:32 UTC (2,407 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 10:38:17 UTC (729 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/12",
    "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16445",
    "abstract": "Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation.",
    "authors": [
      "Xia, Haotian",
      "Peng, Hao",
      "Qi, Yunjia",
      "Wang, Xiaozhi",
      "Xu, Bin",
      "Hou, Lei",
      "Li, Juanzi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16445",
      "TeX Source": "https://arxiv.org/src/2506.16445",
      "View PDF": "https://arxiv.org/pdf/2506.16445"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 16:26:58 UTC (476 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "StoryWriter: A Multi-Agent Framework for Long Story Generation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16495",
    "abstract": "Like image coding in visual data transmission, feature coding is essential for the distributed deployment of large models by significantly reducing transmission and storage overhead. However, prior studies have mostly targeted task- or model-specific scenarios, leaving the challenge of universal feature coding across diverse large models largely unaddressed. In this paper, we present the first systematic study on universal feature coding for large models. The key challenge lies in the inherently diverse and distributionally incompatible nature of features extracted from different models. For example, features from DINOv2 exhibit highly peaky, concentrated distributions, while those from Stable Diffusion 3 (SD3) are more dispersed and uniform. This distributional heterogeneity severely hampers both compression efficiency and cross-model generalization. To address this, we propose a learned peaky-to-balanced distribution transformation, which reshapes highly skewed feature distributions into a common, balanced target space. This transformation is non-uniform, data-driven, and plug-and-play, enabling effective alignment of heterogeneous distributions without modifying downstream codecs. With this alignment, a universal codec trained on the balanced target distribution can effectively generalize to features from different models and tasks. We validate our approach on three representative large models-LLaMA3, DINOv2, and SD3-across multiple tasks and modalities. Extensive experiments show that our method achieves notable improvements in both compression efficiency and cross-model generalization over task-specific baselines. All source code will be released for future research.",
    "authors": [
      "Gao, Changsheng",
      "Liu, Zijie",
      "Li, Li",
      "Liu, Dong",
      "Sun, Xiaoyan",
      "Lin, Weisi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16495v1",
      "Other Formats": "https://arxiv.org/format/2506.16495",
      "TeX Source": "https://arxiv.org/src/2506.16495",
      "View PDF": "https://arxiv.org/pdf/2506.16495"
    },
    "subjects": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 17:43:32 UTC (1,141 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16380",
    "abstract": "This paper presents a novel system for monitoring cattle behavior and detecting estrus (heat) periods using sensor data and machine learning. We designed and deployed a low-cost Bluetooth-based neck collar equipped with accelerometer and gyroscope sensors to capture real-time behavioral data from real cows, which was synced to the cloud. A labeled dataset was created using synchronized CCTV footage to annotate behaviors such as feeding, rumination, lying, and others. We evaluated multiple machine learning models -- Support Vector Machines (SVM), Random Forests (RF), and Convolutional Neural Networks (CNN) -- for behavior classification. Additionally, we implemented a Long Short-Term Memory (LSTM) model for estrus detection using behavioral patterns and anomaly detection. Our system achieved over 93% behavior classification accuracy and 96% estrus detection accuracy on a limited test set. The approach offers a scalable and accessible solution for precision livestock monitoring, especially in resource-constrained environments.",
    "authors": [
      "Dhakshinamoorthy, Druva",
      "Jha, Avikshit",
      "Majumdar, Sabyasachi",
      "Ghosh, Devdulal",
      "Chakraborty, Ranjita",
      "Ray, Hena"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16380v1",
      "Other Formats": "https://arxiv.org/format/2506.16380",
      "TeX Source": "https://arxiv.org/src/2506.16380",
      "View PDF": "https://arxiv.org/pdf/2506.16380"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 15:00:23 UTC (155 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Classification of Cattle Behavior and Detection of Heat (Estrus) using Sensor Data",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.18108",
    "abstract": "Retrieval augmented Question Answering (QA) helps QA models overcome knowledge gaps by incorporating retrieved evidence, typically a set of passages, alongside the question at test time. Previous studies show that this approach improves QA performance and reduces hallucinations, without, however, assessing whether the retrieved passages are indeed useful at answering correctly. In this work, we propose to quantify the uncertainty of a QA model via estimating the utility of the passages it is provided with. We train a lightweight neural model to predict passage utility for a target QA model and show that while simple information theoretic metrics can predict answer correctness up to a certain extent, our approach efficiently approximates or outperforms more expensive sampling-based methods. Code and data are available at https://github.com/lauhaide/ragu.",
    "authors": [
      "Perez-Beltrachini, Laura",
      "Lapata, Mirella"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.18108v2",
      "Other Formats": "https://arxiv.org/format/2502.18108",
      "TeX Source": "https://arxiv.org/src/2502.18108",
      "View PDF": "https://arxiv.org/pdf/2502.18108"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 25 Feb 2025 11:24:52 UTC (69 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 12:51:02 UTC (79 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/25",
    "title": "Uncertainty Quantification in Retrieval Augmented Question Answering",
    "repo_urls": [
      "https://github.com/lauhaide/ragu"
    ],
    "tasks": [
      "Question Answering",
      "Retrieval",
      "Uncertainty Quantification"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16352",
    "abstract": "Increasing global energy demand and renewable integration complexity have placed buildings at the center of sustainable energy management. We present a three-step reinforcement learning(RL)-based Building Energy Management System (BEMS) that combines clustering, forecasting, and constrained policy learning to address scalability, adaptability, and safety challenges. First, we cluster non-shiftable load profiles to identify common consumption patterns, enabling policy generalization and transfer without retraining for each new building. Next, we integrate an LSTM based forecasting module to anticipate future states, improving the RL agents' responsiveness to dynamic conditions. Lastly, domain-informed action masking ensures safe exploration and operation, preventing harmful decisions. Evaluated on real-world data, our approach reduces operating costs by up to 15% for certain building types, maintains stable environmental performance, and quickly classifies and optimizes new buildings with limited data. It also adapts to stochastic tariff changes without retraining. Overall, this framework delivers scalable, robust, and cost-effective building energy management.",
    "authors": [
      "Zangato, Theo",
      "Osmani, Aomar",
      "Alizadeh, Pegah"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16352v1",
      "Other Formats": "https://arxiv.org/format/2506.16352",
      "TeX Source": "https://arxiv.org/src/2506.16352",
      "View PDF": "https://arxiv.org/pdf/2506.16352"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 14:29:48 UTC (3,798 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Data-Driven Policy Mapping for Safe RL-based Energy Management Systems",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16073",
    "abstract": "The word-level lipreading approach typically employs a two-stage framework with separate frontend and backend architectures to model dynamic lip movements. Each component has been extensively studied, and in the backend architecture, temporal convolutional networks (TCNs) have been widely adopted in state-of-the-art methods. Recently, dense skip connections have been introduced in TCNs to mitigate the limited density of the receptive field, thereby improving the modeling of complex temporal representations. However, their performance remains constrained owing to potential information loss regarding the continuous nature of lip movements, caused by blind spots in the receptive field. To address this limitation, we propose TD3Net, a temporal densely connected multi-dilated convolutional network that combines dense skip connections and multi-dilated temporal convolutions as the backend architecture. TD3Net covers a wide and dense receptive field without blind spots by applying different dilation factors to skip-connected features. Experimental results on a word-level lipreading task using two large publicly available datasets, Lip Reading in the Wild (LRW) and LRW-1000, indicate that the proposed method achieves performance comparable to state-of-the-art methods. It achieved higher accuracy with fewer parameters and lower floating-point operations compared to existing TCN-based backend architectures. Moreover, visualization results suggest that our approach effectively utilizes diverse temporal features while preserving temporal continuity, presenting notable advantages in lipreading systems. The code is available at our GitHub repository: https://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading",
    "authors": [
      "Lee, Byung Hoon",
      "Shin, Wooseok",
      "Han, Sung Won"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16073v1",
      "Other Formats": "https://arxiv.org/format/2506.16073",
      "TeX Source": "https://arxiv.org/src/2506.16073",
      "View PDF": "https://arxiv.org/pdf/2506.16073"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 06:55:03 UTC (14,033 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16636",
    "abstract": "Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/\\sqrt{n}$ rate when approximating the true data distribution. To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles. Our procedure satisfies local $(\\epsilon, \\delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.",
    "authors": [
      "Shen, Rex",
      "Tian, Lu"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16636v1",
      "Other Formats": "https://arxiv.org/format/2506.16636",
      "TeX Source": "https://arxiv.org/src/2506.16636",
      "View PDF": "https://arxiv.org/pdf/2506.16636"
    },
    "subjects": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 22:22:57 UTC (17,557 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2501.11260",
    "abstract": "Recent breakthroughs in autonomous driving have been propelled by advances in robust world modeling, fundamentally transforming how vehicles interpret dynamic scenes and execute safe decision-making. World models have emerged as a linchpin technology, offering high-fidelity representations of the driving environment that integrate multi-sensor data, semantic cues, and temporal dynamics. This paper systematically reviews recent advances in world models for autonomous driving, proposing a three-tiered taxonomy: (i) Generation of Future Physical World, covering Image-, BEV-, OG-, and PC-based generation methods that enhance scene evolution modeling through diffusion models and 4D occupancy forecasting; (ii) Behavior Planning for Intelligent Agents, combining rule-driven and learning-based paradigms with cost map optimization and reinforcement learning for trajectory generation in complex traffic conditions; (ii) Interaction between Prediction and Planning, achieving multi-agent collaborative decision-making through latent space diffusion and memory-augmented architectures. The study further analyzes training paradigms, including self-supervised learning, multimodal pretraining, and generative data augmentation, while evaluating world models' performance in scene understanding and motion prediction tasks. Future research must address key challenges in self-supervised representation learning, long-tail scenario generation, and multimodal fusion to advance the practical deployment of world models in complex urban environments. Overall, the comprehensive analysis provides a technical roadmap for harnessing the transformative potential of world models in advancing safe and reliable autonomous driving solutions.",
    "authors": [
      "Feng, Tuo",
      "Wang, Wenguan",
      "Yang, Yi"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2501.11260v3",
      "Other Formats": "https://arxiv.org/format/2501.11260",
      "TeX Source": "https://arxiv.org/src/2501.11260",
      "View PDF": "https://arxiv.org/pdf/2501.11260"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 20 Jan 2025 04:00:02 UTC (856 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sun, 16 Feb 2025 03:38:23 UTC (856 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 17:19:49 UTC (2,727 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2025/01/20",
    "title": "A Survey of World Models for Autonomous Driving",
    "tasks": [
      "Anomaly Detection",
      "Autonomous Driving",
      "Computational Efficiency",
      "Data Augmentation",
      "Decision Making",
      "Domain Adaptation",
      "Future prediction",
      "motion prediction",
      "Representation Learning",
      "Scene Understanding",
      "Self-Supervised Learning",
      "Survey",
      "Trajectory Forecasting"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2409.11884",
    "abstract": "Out-of-distribution (OOD) detection aims to detect test samples outside the training category space, which is an essential component in building reliable machine learning systems. Existing reviews on OOD detection primarily focus on method taxonomy, surveying the field by categorizing various approaches. However, many recent works concentrate on non-traditional OOD detection scenarios, such as test-time adaptation, multi-modal data sources and other novel contexts. In this survey, we uniquely review recent advances in OOD detection from the task-oriented perspective for the first time. According to the user's access to the model, that is, whether the OOD detection method is allowed to modify or retrain the model, we classify the methods as training-driven or training-agnostic. Besides, considering the rapid development of pre-trained models, large pre-trained model-based OOD detection is also regarded as an important category and discussed separately. Furthermore, we provide a discussion of the evaluation scenarios, a variety of applications, and several future research directions. We believe this survey with new taxonomy will benefit the proposal of new methods and the expansion of more practical scenarios. A curated list of related papers is provided in the Github repository: https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection.",
    "authors": [
      "Lu, Shuo",
      "Wang, Yingsheng",
      "Sheng, Lijun",
      "He, Lingxiao",
      "Zheng, Aihua",
      "Liang, Jian"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2409.11884v3",
      "Other Formats": "https://arxiv.org/format/2409.11884",
      "TeX Source": "https://arxiv.org/src/2409.11884",
      "View PDF": "https://arxiv.org/pdf/2409.11884"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Sep 2024 11:30:30 UTC (9,770 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Sat, 21 Sep 2024 06:36:21 UTC (11,192 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 19 Jun 2025 03:58:59 UTC (13,752 KB)",
        "version": "[v3]"
      }
    ],
    "submitted_date": "2024/09/18",
    "title": "Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances",
    "repo_urls": [
      "https://github.com/shuolucs/awesome-out-of-distribution-detection"
    ],
    "tasks": [
      "Out-of-Distribution Detection",
      "Out of Distribution (OOD) Detection",
      "Survey",
      "Test-time Adaptation"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15933",
    "abstract": "Diffusion models have achieved impressive performance in generating high-quality and diverse synthetic data. However, their success typically assumes a class-balanced training distribution. In real-world settings, multi-class data often follow a long-tailed distribution, where standard diffusion models struggle -- producing low-diversity and lower-quality samples for tail classes. While this degradation is well-documented, its underlying cause remains poorly understood. In this work, we investigate the behavior of diffusion models trained on long-tailed datasets and identify a key issue: the latent representations (from the bottleneck layer of the U-Net) for tail class subspaces exhibit significant overlap with those of head classes, leading to feature borrowing and poor generation quality. Importantly, we show that this is not merely due to limited data per class, but that the relative class imbalance significantly contributes to this phenomenon. To address this, we propose COntrastive Regularization for Aligning Latents (CORAL), a contrastive latent alignment framework that leverages supervised contrastive losses to encourage well-separated latent class representations. Experiments demonstrate that CORAL significantly improves both the diversity and visual quality of samples generated for tail classes relative to state-of-the-art methods.",
    "authors": [
      "Rodriguez, Esther",
      "Welfert, Monica",
      "McDowell, Samuel",
      "Stromberg, Nathan",
      "Camarena, Julian Antolin",
      "Sankar, Lalitha"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.15933",
      "TeX Source": "https://arxiv.org/src/2506.15933",
      "View PDF": "https://arxiv.org/pdf/2506.15933"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 00:23:44 UTC (22,548 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "CORAL: Disentangling Latent Representations in Long-Tailed Diffusion",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.13487",
    "abstract": "Reinforcement Learning with Human Feedback (RLHF) has emerged as a key paradigm for task-specific fine-tuning of language models using human preference data. While numerous publicly available preference datasets provide pairwise comparisons of responses, the potential for biases in the resulting reward models remains underexplored. In this work, we introduce novel methods to detect and evaluate prefix bias -- a systematic shift in model preferences triggered by minor variations in query prefixes -- in LLM-based reward models trained on such datasets. We leverage these metrics to reveal significant biases in preference models across racial and gender dimensions. Our comprehensive evaluation spans diverse open-source preference datasets and reward model architectures, demonstrating susceptibility to this kind of bias regardless of the underlying model architecture. Furthermore, we propose a data augmentation strategy to mitigate these biases, showing its effectiveness in reducing the impact of prefix bias. Our findings highlight the critical need for bias-aware dataset design and evaluation in developing fair and reliable reward models, contributing to the broader discourse on fairness in AI.",
    "authors": [
      "Kumar, Ashwin",
      "He, Yuzi",
      "Markosyan, Aram H.",
      "Chern, Bobbie",
      "Arrieta-Ibarra, Imanol"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.13487v2",
      "Other Formats": "https://arxiv.org/format/2505.13487",
      "TeX Source": "https://arxiv.org/src/2505.13487",
      "View PDF": "https://arxiv.org/pdf/2505.13487"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 13 May 2025 21:50:03 UTC (1,226 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Thu, 19 Jun 2025 04:38:26 UTC (1,227 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/13",
    "title": "Detecting Prefix Bias in LLM-based Reward Models",
    "tasks": [
      "Data Augmentation",
      "Fairness"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16428",
    "abstract": "Recent neural heuristics for the Vehicle Routing Problem (VRP) primarily rely on node coordinates as input, which may be less effective in practical scenarios where real cost metrics-such as edge-based distances-are more relevant. To address this limitation, we introduce EFormer, an Edge-based Transformer model that uses edge as the sole input for VRPs. Our approach employs a precoder module with a mixed-score attention mechanism to convert edge information into temporary node embeddings. We also present a parallel encoding strategy characterized by a graph encoder and a node encoder, each responsible for processing graph and node embeddings in distinct feature spaces, respectively. This design yields a more comprehensive representation of the global relationships among edges. In the decoding phase, parallel context embedding and multi-query integration are used to compute separate attention mechanisms over the two encoded embeddings, facilitating efficient path construction. We train EFormer using reinforcement learning in an autoregressive manner. Extensive experiments on the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) reveal that EFormer outperforms established baselines on synthetic datasets, including large-scale and diverse distributions. Moreover, EFormer demonstrates strong generalization on real-world instances from TSPLib and CVRPLib. These findings confirm the effectiveness of EFormer's core design in solving VRPs.",
    "authors": [
      "Meng, Dian",
      "Cao, Zhiguang",
      "Wu, Yaoxin",
      "Hou, Yaqing",
      "Ge, Hongwei",
      "Zhang, Qiang"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16428v1",
      "Other Formats": "https://arxiv.org/format/2506.16428",
      "TeX Source": "https://arxiv.org/src/2506.16428",
      "View PDF": "https://arxiv.org/pdf/2506.16428"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 16:07:11 UTC (559 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "EFormer: An Effective Edge-based Transformer for Vehicle Routing Problems",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16247",
    "abstract": "The findings section of a radiology report is often detailed and lengthy, whereas the impression section is comparatively more compact and captures key diagnostic conclusions. This research explores the use of advanced abstractive summarization models to generate the concise impression from the findings section of a radiology report. We have used the publicly available MIMIC-CXR dataset. A comparative analysis is conducted on leading pre-trained and open-source large language models, including T5-base, BART-base, PEGASUS-x-base, ChatGPT-4, LLaMA-3-8B, and a custom Pointer Generator Network with a coverage mechanism. To ensure a thorough assessment, multiple evaluation metrics are employed, including ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and BERTScore. By analyzing the performance of these models, this study identifies their respective strengths and limitations in the summarization of medical text. The findings of this paper provide helpful information for medical professionals who need automated summarization solutions in the healthcare sector.",
    "authors": [
      "Bhattacharya, Anindita",
      "Rehman, Tohida",
      "Sanyal, Debarshi Kumar",
      "Chattopadhyay, Samiran"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16247v1",
      "Other Formats": "https://arxiv.org/format/2506.16247",
      "TeX Source": "https://arxiv.org/src/2506.16247",
      "View PDF": "https://arxiv.org/pdf/2506.16247"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 12:07:17 UTC (199 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16457",
    "abstract": "This report showcases the role of, and future directions for, the field of Randomized Numerical Linear Algebra (RNLA) in a selection of scientific applications. These applications span the domains of imaging, genomics and time-varying systems, and are thematically connected by needing to perform linear algebra routines on large-scale matrices (with up to quantillions of entries). At such scales, the linear algebra routines face typical bottlenecks: memory constraints, data access latencies, and substantial floating-point operation costs. RNLA routines are discussed at a high level to demonstrate how RNLA is able to solve the challenges faced by traditional linear algebra routines, and, consequently, address the computational problem posed in the underlying application. For each application, RNLA's open challenges and possible future directions are also presented, which broadly fall into the categories: creating structure-aware RNLA algorithms; co-designing RNLA algorithms with hardware and mixed-precision considerations; and advancing modular, composable software infrastructure. Ultimately, this report serves two purposes: it invites domain scientists to engage with RNLA; and it offers a guide for future RNLA research grounded in real applications.",
    "authors": [
      "Patel, Vivak",
      "Maldonado, D. Adrian",
      "Melnichenko, Maksim",
      "Pritchard, Nathaniel",
      "Rao, Vishwas",
      "Rebrova, Elizaveta",
      "Sankararaman, Sriram"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16457v1",
      "Other Formats": "https://arxiv.org/format/2506.16457",
      "TeX Source": "https://arxiv.org/src/2506.16457",
      "View PDF": "https://arxiv.org/pdf/2506.16457"
    },
    "subjects": [
      "Numerical Analysis (math.NA)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 16:50:56 UTC (2,003 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Scientific Applications Leveraging Randomized Linear Algebra",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16243",
    "abstract": "Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.",
    "authors": [
      "Mutlu, Abdulvahap",
      "Do\u011fan, \u015eeng\u00fcl",
      "Tuncer, T\u00fcrker"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.16243",
      "View PDF": "https://arxiv.org/pdf/2506.16243"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 11:57:23 UTC (702 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16007",
    "abstract": "Cardinality estimation (CardEst) is a critical aspect of query optimization. Traditionally, it leverages statistics built directly over the data. However, organizational policies (e.g., regulatory compliance) may restrict global data access. Fortunately, query-driven cardinality estimation can learn CardEst models using query workloads. However, existing query-driven models often require access to data or summaries for best performance, and they assume perfect training workloads with complete and balanced join templates (or join graphs). Such assumptions rarely hold in real-world scenarios, in which join templates are incomplete and imbalanced. We present GRASP, a data-agnostic cardinality learning system designed to work under these real-world constraints. GRASP's compositional design generalizes to unseen join templates and is robust to join template imbalance. It also introduces a new per-table CardEst model that handles value distribution shifts for range predicates, and a novel learned count sketch model that captures join correlations across base relations. Across three database instances, we demonstrate that GRASP consistently outperforms existing query-driven models on imperfect workloads, both in terms of estimation accuracy and query latency. Remarkably, GRASP achieves performance comparable to, or even surpassing, traditional approaches built over the underlying data on the complex CEB-IMDb-full benchmark -- despite operating without any data access and using only 10% of all possible join templates.",
    "authors": [
      "Wu, Peizhi",
      "Kang, Rong",
      "Zhang, Tieying",
      "Chen, Jianjun",
      "Marcus, Ryan",
      "Ives, Zachary G."
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16007v1",
      "Other Formats": "https://arxiv.org/format/2506.16007",
      "TeX Source": "https://arxiv.org/src/2506.16007",
      "View PDF": "https://arxiv.org/pdf/2506.16007"
    },
    "subjects": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 03:58:31 UTC (1,805 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Data-Agnostic Cardinality Learning from Imperfect Workloads",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16233",
    "abstract": "Observational astronomy relies on visual feature identification to detect critical astrophysical phenomena. While machine learning (ML) increasingly automates this process, models often struggle with generalization in large-scale surveys due to the limited representativeness of labeled datasets -- whether from simulations or human annotation -- a challenge pronounced for rare yet scientifically valuable objects. To address this, we propose a conditional diffusion model to synthesize realistic galaxy images for augmenting ML training data. Leveraging the Galaxy Zoo 2 dataset which contains visual feature -- galaxy image pairs from volunteer annotation, we demonstrate that our model generates diverse, high-fidelity galaxy images closely adhere to the specified morphological feature conditions. Moreover, this model enables generative extrapolation to project well-annotated data into unseen domains and advancing rare object detection. Integrating synthesized images into ML pipelines improves performance in standard morphology classification, boosting completeness and purity by up to 30\\% across key metrics. For rare object detection, using early-type galaxies with prominent dust lane features ( $\\sim$0.1\\% in GZ2 dataset) as a test case, our approach doubled the number of detected instances from 352 to 872, compared to previous studies based on visual inspection. This study highlights the power of generative models to bridge gaps between scarce labeled data and the vast, uncharted parameter space of observational astronomy and sheds insight for future astrophysical foundation model developments. Our project homepage is available at https://galaxysd-webpage.streamlit.app/.",
    "authors": [
      "Ma, Chenrui",
      "Sun, Zechang",
      "Jing, Tao",
      "Cai, Zheng",
      "Ting, Yuan-Sen",
      "Huang, Song",
      "Li, Mingyu"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16233v1",
      "Other Formats": "https://arxiv.org/format/2506.16233",
      "TeX Source": "https://arxiv.org/src/2506.16233",
      "View PDF": "https://arxiv.org/pdf/2506.16233"
    },
    "subjects": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 11:44:09 UTC (11,138 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy Morphology Augmentation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.16626",
    "abstract": "In recent years, the adoption of cloud services has been expanding at an unprecedented rate. As more and more organizations migrate or deploy their businesses to the cloud, a multitude of related cybersecurity incidents such as data breaches are on the rise. Many inherent attributes of cloud environments, for example, data sharing, remote access, dynamicity and scalability, pose significant challenges for the protection of cloud security. Even worse, cyber threats are becoming increasingly sophisticated and covert. Attack methods, such as Advanced Persistent Threats (APTs), are continually developed to bypass traditional security measures. Among the emerging technologies for robust threat detection, system provenance analysis is being considered as a promising mechanism, thus attracting widespread attention in the field of incident response. This paper proposes a new few-shot learning-based attack detection with improved data context intelligence. We collect operating system behavior data of cloud systems during realistic attacks and leverage an innovative semiotics extraction method to describe system events. Inspired by the advances in semantic analysis, which is a fruitful area focused on understanding natural languages in computational linguistics, we further convert the anomaly detection problem into a similarity comparison problem. Comprehensive experiments show that the proposed approach is able to generalize over unseen attacks and make accurate predictions, even if the incident detection models are trained with very limited samples.",
    "authors": [
      "Zuo, Fei",
      "Rhee, Junghwan",
      "Choe, Yung Ryn",
      "Fu, Chenglong",
      "Qu, Xianshan"
    ],
    "last_revised_date": "2025/06/19",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.16626v1",
      "Other Formats": "https://arxiv.org/format/2506.16626",
      "TeX Source": "https://arxiv.org/src/2506.16626",
      "View PDF": "https://arxiv.org/pdf/2506.16626"
    },
    "subjects": [
      "Cryptography and Security (cs.CR)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 19 Jun 2025 21:53:02 UTC (551 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/19",
    "title": "Few-Shot Learning-Based Cyber Incident Detection with Augmented Context Intelligence",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.11302",
    "abstract": "World models aim to simulate environments and enable effective agent behavior. However, modeling real-world environments presents unique challenges as they dynamically change across both space and, crucially, time. To capture these composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for Exploration (STRIDE) permuting 360-degree panoramic imagery into rich interconnected observation, state and action nodes. Leveraging this structure, we can simultaneously model the relationship between egocentric views, positional coordinates, and movement commands across both space and time. We benchmark this dataset via TARDIS, a transformer-based generative world model that integrates spatial and temporal dynamics through a unified autoregressive framework trained on STRIDE. We demonstrate robust performance across a range of agentic tasks such as controllable photorealistic image synthesis, instruction following, autonomous self-control, and state-of-the-art georeferencing. These results suggest a promising direction towards sophisticated generalist agents--capable of understanding and manipulating the spatial and temporal aspects of their material environments--with enhanced embodied reasoning capabilities. Training code, datasets, and model checkpoints are made available at https://huggingface.co/datasets/Tera-AI/STRIDE.",
    "authors": [
      "Carri\u00f3n, H\u00e9ctor",
      "Bai, Yutong",
      "Castro, V\u00edctor A. Hern\u00e1ndez",
      "Panaganti, Kishan",
      "Zenith, Ayush",
      "Trang, Matthew",
      "Zhang, Tony",
      "Perona, Pietro",
      "Malik, Jitendra"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.11302v2",
      "Other Formats": "https://arxiv.org/format/2506.11302",
      "TeX Source": "https://arxiv.org/src/2506.11302",
      "View PDF": "https://arxiv.org/pdf/2506.11302"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 12 Jun 2025 21:08:11 UTC (46,664 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 15:59:47 UTC (46,664 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/12",
    "title": "TARDIS STRIDE: A Spatio-Temporal Road Image Dataset and World Model for Autonomy",
    "tasks": [
      "Image Generation",
      "Instruction Following"
    ],
    "datasets": [
      {
        "dataset_name": "Tera-AI/STRIDE",
        "downloads": "110",
        "likes": "3",
        "link": "https://huggingface.co/datasets/Tera-AI/STRIDE"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15787",
    "abstract": "We introduce SLR, an end-to-end framework for systematic evaluation and training of Large Language Models (LLMs) via Scalable Logical Reasoning. Given a user's task specification, SLR enables scalable, automated synthesis of inductive reasoning tasks with precisely controlled difficulty. For each task, SLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation program used by a symbolic judge to deterministically verify model outputs, and (iii) an instruction prompt for the reasoning task. Using SLR, we create SLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum levels that progressively increase in relational, arithmetic, and recursive complexity. Large-scale evaluation reveals that contemporary LLMs readily produce syntactically valid rules, yet often fail at correct logical inference. Recent reasoning LLMs do somewhat better, but incur substantial increases in test-time compute, sometimes exceeding 15k completion tokens. Finally, logic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully automated, requires no human annotation, ensures dataset novelty, and offers a scalable environment for probing and advancing LLMs' reasoning capabilities.",
    "authors": [
      "Helff, Lukas",
      "Omar, Ahmad",
      "Friedrich, Felix",
      "Stammer, Wolfgang",
      "W\u00fcst, Antonia",
      "Woydt, Tim",
      "Mitchell, Rupert",
      "Schramowski, Patrick",
      "Kersting, Kristian"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15787v1",
      "Other Formats": "https://arxiv.org/format/2506.15787",
      "TeX Source": "https://arxiv.org/src/2506.15787",
      "View PDF": "https://arxiv.org/pdf/2506.15787"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 18:10:30 UTC (1,012 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "SLR: An Automated Synthesis Framework for Scalable Logical Reasoning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.09010",
    "abstract": "Training advanced machine learning models demands massive datasets, resulting in prohibitive computational costs. To address this challenge, data pruning techniques identify and remove redundant training samples while preserving model performance. Yet, existing pruning techniques predominantly require a full initial training pass to identify removable samples, negating any efficiency benefits for single training runs. To overcome this limitation, we introduce a novel importance score extrapolation framework that requires training on only a small subset of data. We present two initial approaches in this framework - k-nearest neighbors and graph neural networks - to accurately predict sample importance for the entire dataset using patterns learned from this minimal subset. We demonstrate the effectiveness of our approach for 2 state-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different datasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training paradigms (supervised, unsupervised, and adversarial). Our results indicate that score extrapolation is a promising direction to scale expensive score calculation methods, such as pruning, data attribution, or other tasks.",
    "authors": [
      "Schmidt, Sebastian",
      "Dhungel, Prasanga",
      "L\u00f6ffler, Christoffer",
      "Nieth, Bj\u00f6rn",
      "G\u00fcnnemann, Stephan",
      "Schwinn, Leo"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.09010v2",
      "Other Formats": "https://arxiv.org/format/2506.09010",
      "TeX Source": "https://arxiv.org/src/2506.09010",
      "View PDF": "https://arxiv.org/pdf/2506.09010"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 10 Jun 2025 17:38:49 UTC (2,350 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 20:58:25 UTC (2,350 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/10",
    "title": "Effective Data Pruning through Score Extrapolation",
    "repo_urls": [
      "https://github.com/prasangadhungel/Data-Pruning-with-Extrapolated-Scores"
    ],
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15815",
    "abstract": "Structural coloration is commonly modeled using wave optics for reliable and photorealistic rendering of natural, quasi-periodic and complex nanostructures. Such models often rely on dense, preliminary or preprocessed data to accurately capture the nuanced variations in diffractive surface reflectances. This heavy data dependency warrants implicit neural representation which has not been addressed comprehensively in the current literature. In this paper, we present a multi-layer perceptron (MLP) based method for data-driven rendering of diffractive surfaces with high accuracy and efficiency. We primarily approach this problem from a data compression perspective to devise a nuanced training and modeling method which is attuned to the domain and range characteristics of diffractive reflectance datasets. Importantly, our approach avoids over-fitting and has robust resampling behavior. Using Peak-Signal-to-Noise (PSNR), Structural Similarity Index Measure (SSIM) and a flipping difference evaluator (FLIP) as evaluation metrics, we demonstrate the high-quality reconstruction of the ground-truth. In comparison to a recent state-of-the-art offline, wave-optical, forward modeling approach, our method reproduces subjectively similar results with significant performance gains. We reduce the memory footprint of the raw datasets by two orders of magnitude in general. Lastly, we depict the working of our method with actual surface renderings.",
    "authors": [
      "Kandel, Narayan",
      "Dhillon, Daljit Singh J. S."
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15815v1",
      "Other Formats": "https://arxiv.org/format/2506.15815",
      "TeX Source": "https://arxiv.org/src/2506.15815",
      "View PDF": "https://arxiv.org/pdf/2506.15815"
    },
    "subjects": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 18:58:00 UTC (38,125 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "GratNet: A Photorealistic Neural Shader for Diffractive Surfaces",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.12708",
    "abstract": "The rapid evolution of large language models (LLMs), driven by growing parameter scales, adoption of mixture-of-experts (MoE) architectures, and expanding context lengths, imposes unprecedented demands on AI infrastructure. Traditional AI clusters face limitations in compute intensity, memory bandwidth, inter-chip communication, and latency, compounded by variable workloads and strict service-level objectives. Addressing these issues requires fundamentally redesigned hardware-software integration. This paper introduces Huawei CloudMatrix, a next-generation AI datacenter architecture, realized in the production-grade CloudMatrix384 supernode. It integrates 384 Ascend 910C NPUs and 192 Kunpeng CPUs interconnected via an ultra-high-bandwidth Unified Bus (UB) network, enabling direct all-to-all communication and dynamic pooling of resources. These features optimize performance for communication-intensive operations, such as large-scale MoE expert parallelism and distributed key-value cache access. To fully leverage CloudMatrix384, we propose CloudMatrix-Infer, an advanced LLM serving solution incorporating three core innovations: a peer-to-peer serving architecture that independently scales prefill, decode, and caching; a large-scale expert parallelism strategy supporting EP320 via efficient UB-based token dispatch; and hardware-aware optimizations including specialized operators, microbatch-based pipelining, and INT8 quantization. Evaluation with the DeepSeek-R1 model shows CloudMatrix-Infer achieves state-of-the-art efficiency: prefill throughput of 6,688 tokens/s per NPU and decode throughput of 1,943 tokens/s per NPU (<50 ms TPOT). It effectively balances throughput and latency, sustaining 538 tokens/s per NPU even under stringent 15 ms latency constraints, while INT8 quantization maintains model accuracy across benchmarks.",
    "authors": [
      "Zuo, Pengfei",
      "Lin, Huimin",
      "Deng, Junbo",
      "Zou, Nan",
      "Yang, Xingkun",
      "Diao, Yingyu",
      "Gao, Weifeng",
      "Xu, Ke",
      "Chen, Zhangyu",
      "Lu, Shirui",
      "Qiu, Zhao",
      "Li, Peiyang",
      "Chang, Xianyu",
      "Yu, Zhengzhong",
      "Miao, Fangzheng",
      "Zheng, Jia",
      "Li, Ying",
      "Feng, Yuan",
      "Wang, Bei",
      "Zong, Zaijian",
      "Zhou, Mosong",
      "Zhou, Wenli",
      "Chen, Houjiang",
      "Liao, Xingyu",
      "Li, Yipeng",
      "Zhang, Wenxiao",
      "Zhu, Ping",
      "Wang, Yinggang",
      "Xiao, Chuanjie",
      "Liang, Depeng",
      "Cao, Dong",
      "Liu, Juncheng",
      "Yang, Yongqiang",
      "Bai, Xiaolong",
      "Li, Yi",
      "Xie, Huaguo",
      "Wu, Huatao",
      "Yu, Zhibin",
      "Chen, Lv",
      "Liu, Hu",
      "Ding, Yujun",
      "Zhu, Haipei",
      "Xia, Jing",
      "Xiong, Yi",
      "Yu, Zhou",
      "Liao, Heng"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.12708v2",
      "Other Formats": "https://arxiv.org/format/2506.12708",
      "TeX Source": "https://arxiv.org/src/2506.12708",
      "View PDF": "https://arxiv.org/pdf/2506.12708"
    },
    "subjects": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 15 Jun 2025 03:41:34 UTC (1,018 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 10:04:59 UTC (1,018 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/15",
    "title": "Serving Large Language Models on Huawei CloudMatrix384",
    "tasks": [
      "Mixture-of-Experts",
      "Quantization"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15748",
    "abstract": "Automated grading of Knee Osteoarthritis (KOA) from radiographs is challenged by significant inter-observer variability and the limited robustness of deep learning models, particularly near critical decision boundaries. To address these limitations, this paper proposes a novel framework, Diffusion-based Counterfactual Augmentation (DCA), which enhances model robustness and interpretability by generating targeted counterfactual examples. The method navigates the latent space of a diffusion model using a Stochastic Differential Equation (SDE), governed by balancing a classifier-informed boundary drive with a manifold constraint. The resulting counterfactuals are then used within a self-corrective learning strategy to improve the classifier by focusing on its specific areas of uncertainty. Extensive experiments on the public Osteoarthritis Initiative (OAI) and Multicenter Osteoarthritis Study (MOST) datasets demonstrate that this approach significantly improves classification accuracy across multiple model architectures. Furthermore, the method provides interpretability by visualizing minimal pathological changes and revealing that the learned latent space topology aligns with clinical knowledge of KOA progression. The DCA framework effectively converts model uncertainty into a robust training signal, offering a promising pathway to developing more accurate and trustworthy automated diagnostic systems. Our code is available at https://github.com/ZWang78/DCA.",
    "authors": [
      "Wang, Zhe",
      "Ru, Yuhua",
      "Chetouani, Aladine",
      "Shiang, Tina",
      "Chen, Fang",
      "Bauer, Fabian",
      "Zhang, Liping",
      "Hans, Didier",
      "Jennane, Rachid",
      "Palmer, William Ewing",
      "Jarraya, Mohamed",
      "Chen, Yung Hsin"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15748v1",
      "Other Formats": "https://arxiv.org/format/2506.15748",
      "TeX Source": "https://arxiv.org/src/2506.15748",
      "View PDF": "https://arxiv.org/pdf/2506.15748"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 04:16:28 UTC (4,062 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Diffusion-based Counterfactual Augmentation: Towards Robust and Interpretable Knee Osteoarthritis Grading",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15872",
    "abstract": "Loss curves are smooth during most of model training, so visible discontinuities stand out as possible conceptual breakthroughs. Studying these breakthroughs enables a deeper understanding of learning dynamics, but only when they are properly identified. This paper argues that similar breakthroughs occur frequently throughout training but they are obscured by a loss metric that collapses all variation into a single scalar. To find these hidden transitions, we introduce POLCA, a method for decomposing changes in loss along arbitrary bases of the low-rank training subspace. We use our method to identify clusters of samples that share similar changes in loss during training, disaggregating the overall loss into that of smaller groups of conceptually similar data. We validate our method on synthetic arithmetic and natural language tasks, showing that POLCA recovers clusters that represent interpretable breakthroughs in the model's capabilities. We demonstrate the promise of these hidden phase transitions as a tool for unsupervised interpretability.",
    "authors": [
      "Kangaslahti, Sara",
      "Rosenfeld, Elan",
      "Saphra, Naomi"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15872v1",
      "Other Formats": "https://arxiv.org/format/2506.15872",
      "TeX Source": "https://arxiv.org/src/2506.15872",
      "View PDF": "https://arxiv.org/pdf/2506.15872"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 20:40:16 UTC (3,106 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Hidden Breakthroughs in Language Model Training",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15675",
    "abstract": "Video generation techniques have made remarkable progress, promising to be the foundation of interactive world exploration. However, existing video generation datasets are not well-suited for world exploration training as they suffer from some limitations: limited locations, short duration, static scenes, and a lack of annotations about exploration and the world. In this paper, we introduce Sekai (meaning ``world'' in Japanese), a high-quality first-person view worldwide video dataset with rich annotations for world exploration. It consists of over 5,000 hours of walking or drone view (FPV and UVA) videos from over 100 countries and regions across 750 cities. We develop an efficient and effective toolbox to collect, pre-process and annotate videos with location, scene, weather, crowd density, captions, and camera trajectories. Experiments demonstrate the quality of the dataset. And, we use a subset to train an interactive video world exploration model, named YUME (meaning ``dream'' in Japanese). We believe Sekai will benefit the area of video generation and world exploration, and motivate valuable applications.",
    "authors": [
      "Li, Zhen",
      "Li, Chuanhao",
      "Mao, Xiaofeng",
      "Lin, Shaoheng",
      "Li, Ming",
      "Zhao, Shitian",
      "Xu, Zhaopan",
      "Li, Xinyue",
      "Feng, Yukang",
      "Sun, Jianwen",
      "Li, Zizhen",
      "Zhang, Fanrui",
      "Ai, Jiaxin",
      "Wang, Zhixiang",
      "Wu, Yuwei",
      "He, Tong",
      "Pang, Jiangmiao",
      "Qiao, Yu",
      "Jia, Yunde",
      "Zhang, Kaipeng"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15675v1",
      "Other Formats": "https://arxiv.org/format/2506.15675",
      "TeX Source": "https://arxiv.org/src/2506.15675",
      "View PDF": "https://arxiv.org/pdf/2506.15675"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 17:57:06 UTC (5,503 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Sekai: A Video Dataset towards World Exploration",
    "tasks": [
      "Video Generation"
    ],
    "datasets": [
      {
        "dataset_name": "Lixsp11/Sekai-Project",
        "downloads": "464",
        "likes": "12",
        "link": "https://huggingface.co/datasets/Lixsp11/Sekai-Project"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15881",
    "abstract": "SHallow REcurrent Decoders (SHRED) are effective for system identification and forecasting from sparse sensor measurements. Such models are light-weight and computationally efficient, allowing them to be trained on consumer laptops. SHRED-based models rely on Recurrent Neural Networks (RNNs) and a simple Multi-Layer Perceptron (MLP) for the temporal encoding and spatial decoding respectively. Despite the relatively simple structure of SHRED, they are able to predict chaotic dynamical systems on different physical, spatial, and temporal scales directly from a sparse set of sensor measurements. In this work, we improve SHRED by leveraging transformers (T-SHRED) for the temporal encoding which improves performance on next-step state prediction on large datasets. We also introduce a sparse identification of nonlinear dynamics (SINDy) attention mechanism into T-SHRED to perform symbolic regression directly on the latent space as part of the model regularization architecture. Symbolic regression improves model interpretability by learning and regularizing the dynamics of the latent space during training. We analyze the performance of T-SHRED on three different dynamical systems ranging from low-data to high-data regimes. We observe that SINDy attention T-SHRED accurately predicts future frames based on an interpretable symbolic model across all tested datasets.",
    "authors": [
      "Yermakov, Alexey",
      "Zoro, David",
      "Gao, Mars Liyao",
      "Kutz, J. Nathan"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15881v1",
      "Other Formats": "https://arxiv.org/format/2506.15881",
      "TeX Source": "https://arxiv.org/src/2506.15881",
      "View PDF": "https://arxiv.org/pdf/2506.15881"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 21:14:38 UTC (11,255 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "T-SHRED: Symbolic Regression for Regularization and Model Discovery with Transformer Shallow Recurrent Decoders",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15868",
    "abstract": "Risk quantification is a critical component of safe autonomous driving, however, constrained by the limited perception range and occlusion of single-vehicle systems in complex and dense scenarios. Vehicle-to-everything (V2X) paradigm has been a promising solution to sharing complementary perception information, nevertheless, how to ensure the risk interpretability while understanding multi-agent interaction with V2X remains an open question. In this paper, we introduce the first V2X-enabled risk quantification pipeline, CooperRisk, to fuse perception information from multiple agents and quantify the scenario driving risk in future multiple timestamps. The risk is represented as a scenario risk map to ensure interpretability based on risk severity and exposure, and the multi-agent interaction is captured by the learning-based cooperative prediction model. We carefully design a risk-oriented transformer-based prediction model with multi-modality and multi-agent considerations. It aims to ensure scene-consistent future behaviors of multiple agents and avoid conflicting predictions that could lead to overly conservative risk quantification and cause the ego vehicle to become overly hesitant to drive. Then, the temporal risk maps could serve to guide a model predictive control planner. We evaluate the CooperRisk pipeline in a real-world V2X dataset V2XPnP, and the experiments demonstrate its superior performance in risk quantification, showing a 44.35% decrease in conflict rate between the ego vehicle and background traffic participants.",
    "authors": [
      "Lei, Mingyue",
      "Zhou, Zewei",
      "Li, Hongchen",
      "Hu, Jia",
      "Ma, Jiaqi"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15868v1",
      "Other Formats": "https://arxiv.org/format/2506.15868",
      "TeX Source": "https://arxiv.org/src/2506.15868",
      "View PDF": "https://arxiv.org/pdf/2506.15868"
    },
    "subjects": [
      "Robotics (cs.RO)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 20:31:34 UTC (2,119 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "CooperRisk: A Driving Risk Quantification Pipeline with Multi-Agent Cooperative Perception and Prediction",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15907",
    "abstract": "Accurate graph similarity is critical for knowledge transfer in VLSI design, enabling the reuse of prior solutions to reduce engineering effort and turnaround time. We propose Pieceformer, a scalable, self-supervised similarity assessment framework, equipped with a hybrid message-passing and graph transformer encoder. To address transformer scalability, we incorporate a linear transformer backbone and introduce a partitioned training pipeline for efficient memory and parallelism management. Evaluations on synthetic and real-world CircuitNet datasets show that Pieceformer reduces mean absolute error (MAE) by 24.9% over the baseline and is the only method to correctly cluster all real-world design groups. We further demonstrate the practical usage of our model through a case study on a partitioning task, achieving up to 89% runtime reduction. These results validate the framework's effectiveness for scalable, unbiased design reuse in modern VLSI systems.",
    "authors": [
      "Yang, Hang",
      "Hu, Yusheng",
      "Liu, Yong",
      "Cong",
      "Hao"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15907v1",
      "Other Formats": "https://arxiv.org/format/2506.15907",
      "TeX Source": "https://arxiv.org/src/2506.15907",
      "View PDF": "https://arxiv.org/pdf/2506.15907"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 22:47:09 UTC (1,232 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Pieceformer: Similarity-Driven Knowledge Transfer via Scalable Graph Transformer in VLSI",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15337",
    "abstract": "Neural network potentials (NNPs) offer a powerful alternative to traditional force fields for molecular dynamics (MD) simulations. Accurate and stable MD simulations, crucial for evaluating material properties, require training data encompassing both low-energy stable structures and high-energy structures. Conventional knowledge distillation (KD) methods fine-tune a pre-trained NNP as a teacher model to generate training data for a student model. However, in material-specific models, this fine-tuning process increases energy barriers, making it difficult to create training data containing high-energy structures. To address this, we propose a novel KD framework that leverages a non-fine-tuned, off-the-shelf pre-trained NNP as a teacher. Its gentler energy landscape facilitates the exploration of a wider range of structures, including the high-energy structures crucial for stable MD simulations. Our framework employs a two-stage training process: first, the student NNP is trained with a dataset generated by the off-the-shelf teacher; then, it is fine-tuned with a smaller, high-accuracy density functional theory (DFT) dataset. We demonstrate the effectiveness of our framework by applying it to both organic (polyethylene glycol) and inorganic (L$_{10}$GeP$_{2}$S$_{12}$) materials, achieving comparable or superior accuracy in reproducing physical properties compared to existing methods. Importantly, our method reduces the number of expensive DFT calculations by 10x compared to existing NNP generation methods, without sacrificing accuracy.",
    "authors": [
      "Matsumura, Naoki",
      "Yoshimoto, Yuta",
      "Iwasaki, Yuto",
      "Yamazaki, Meguru",
      "Sakai, Yasufumi"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15337v1",
      "Other Formats": "https://arxiv.org/format/2506.15337",
      "TeX Source": "https://arxiv.org/src/2506.15337",
      "View PDF": "https://arxiv.org/pdf/2506.15337"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Physics (physics.comp-ph)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 10:32:26 UTC (4,592 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Knowledge Distillation Framework for Accelerating High-Accuracy Neural Network-Based Molecular Dynamics Simulations",
    "tasks": [
      "Knowledge Distillation"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.03147",
    "abstract": "Although existing unified models achieve strong performance in vision-language understanding and text-to-image generation, they remain limited in addressing image perception and manipulation -- capabilities increasingly demanded in practical applications. Recently, OpenAI introduced the powerful GPT-4o-Image model, which showcases advanced capabilities in comprehensive image perception and manipulation, sparking widespread interest. Through carefully designed experiments, we observe that GPT-4o-Image likely relies on semantic encoders rather than VAEs for feature extraction, despite VAEs being commonly regarded as crucial for image manipulation tasks. Inspired by this insight, we propose UniWorld-V1, a unified generative framework built upon semantic features extracted from powerful multimodal large language models and contrastive semantic encoders. Using only 2.7M training data, UniWorld-V1 achieves impressive performance across diverse tasks, including image understanding, generation, manipulation, and perception. We fully open-source the UniWorld-V1 framework, including model weights, training and evaluation scripts, and datasets to promote reproducibility and further research.",
    "authors": [
      "Lin, Bin",
      "Li, Zongjian",
      "Cheng, Xinhua",
      "Niu, Yuwei",
      "Ye, Yang",
      "He, Xianyi",
      "Yuan, Shenghai",
      "Yu, Wangbo",
      "Wang, Shaodong",
      "Ge, Yunyang",
      "Pang, Yatian",
      "Yuan, Li"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.03147v4",
      "Other Formats": "https://arxiv.org/format/2506.03147",
      "TeX Source": "https://arxiv.org/src/2506.03147",
      "View PDF": "https://arxiv.org/pdf/2506.03147"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 3 Jun 2025 17:59:33 UTC (3,621 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 4 Jun 2025 14:45:58 UTC (3,623 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Thu, 5 Jun 2025 16:41:40 UTC (3,623 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Wed, 18 Jun 2025 18:00:05 UTC (3,624 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2025/06/03",
    "title": "UniWorld-V1: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation",
    "repo_urls": [
      "https://github.com/PKU-YuanGroup/UniWorld-V1",
      "https://github.com/pku-yuangroup/imgedit"
    ],
    "tasks": [
      "",
      "Image Editing",
      "Image Generation",
      "Image Manipulation",
      "Text to Image Generation",
      "Text-to-Image Generation"
    ],
    "datasets": [
      {
        "dataset_name": "LanguageBind/UniWorld-V1",
        "downloads": "21777",
        "likes": "10",
        "link": "https://huggingface.co/datasets/LanguageBind/UniWorld-V1"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15833",
    "abstract": "In recent years, there has been an explosion of interest in the applications of large pre-trained language models (PLMs) to recommender systems, with many studies showing strong performance of PLMs on common benchmark datasets. PLM-based recommender models benefit from flexible and customizable prompting, an unlimited vocabulary of recommendable items, and general ``world knowledge'' acquired through pre-training on massive text corpora. While PLM-based recommenders show promise in settings where data is limited, they are hard to implement in practice due to their large size and computational cost. Additionally, fine-tuning PLMs to improve performance on collaborative signals may degrade the model's capacity for world knowledge and generalizability. We propose a recommender model that uses the architecture of large language models (LLMs) while reducing layer count and dimensions and replacing the text-based subword tokenization of a typical LLM with discrete tokens that uniquely represent individual content items. We find that this simplified approach substantially outperforms both traditional sequential recommender models and PLM-based recommender models at a tiny fraction of the size and computational complexity of PLM-based models. Our results suggest that the principal benefit of LLMs in recommender systems is their architecture, rather than the world knowledge acquired during extensive pre-training.",
    "authors": [
      "Foley, Kevin",
      "Agah, Shaghayegh",
      "Kakinada, Kavya Priyanka"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15833v1",
      "Other Formats": "https://arxiv.org/format/2506.15833",
      "TeX Source": "https://arxiv.org/src/2506.15833",
      "View PDF": "https://arxiv.org/pdf/2506.15833"
    },
    "subjects": [
      "Information Retrieval (cs.IR)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 19:18:49 UTC (32 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Architecture is All You Need: Improving LLM Recommenders by Dropping the Text",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15901",
    "abstract": "Background: Patients with both diabetes mellitus (DM) and atrial fibrillation (AF) face elevated mortality in intensive care units (ICUs), yet models targeting this high-risk group remain limited. Objective: To develop an interpretable machine learning (ML) model predicting 28-day mortality in ICU patients with concurrent DM and AF using early-phase clinical data. Methods: A retrospective cohort of 1,535 adult ICU patients with DM and AF was extracted from the MIMIC-IV database. Data preprocessing involved median/mode imputation, z-score normalization, and early temporal feature engineering. A two-step feature selection pipeline-univariate filtering (ANOVA F-test) and Random Forest-based multivariate ranking-yielded 19 interpretable features. Seven ML models were trained with stratified 5-fold cross-validation and SMOTE oversampling. Interpretability was assessed via ablation and Accumulated Local Effects (ALE) analysis. Results: Logistic regression achieved the best performance (AUROC: 0.825; 95% CI: 0.779-0.867), surpassing more complex models. Key predictors included RAS, age, bilirubin, and extubation. ALE plots showed intuitive, non-linear effects such as age-related risk acceleration and bilirubin thresholds. Conclusion: This interpretable ML model offers accurate risk prediction and clinical insights for early ICU triage in patients with DM and AF.",
    "authors": [
      "Sun, Li",
      "Chen, Shuheng",
      "Si, Yong",
      "Fan, Junyi",
      "Pishgar, Maryam",
      "Pishgar, Elham",
      "Alaei, Kamiar",
      "Placencia, Greg"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15901v1",
      "Other Formats": "https://arxiv.org/format/2506.15901",
      "TeX Source": "https://arxiv.org/src/2506.15901",
      "View PDF": "https://arxiv.org/pdf/2506.15901"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 22:04:12 UTC (2,329 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Clinically Interpretable Mortality Prediction for ICU Patients with Diabetes and Atrial Fibrillation: A Machine Learning Approach",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.08134",
    "abstract": "Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "authors": [
      "Wei, Qiyao",
      "Holt, Samuel",
      "Yang, Jing",
      "Wulfmeier, Markus",
      "van der Schaar, Mihaela"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.08134v2",
      "Other Formats": "https://arxiv.org/format/2506.08134",
      "TeX Source": "https://arxiv.org/src/2506.08134",
      "View PDF": "https://arxiv.org/pdf/2506.08134"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 9 Jun 2025 18:37:14 UTC (1,123 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 23:48:35 UTC (1,124 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/09",
    "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning",
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.18452",
    "abstract": "During Human Robot Interactions in disaster relief scenarios, Large Language Models (LLMs) have the potential for substantial physical reasoning to assist in mission objectives. However, these capabilities are often found only in larger models, which are frequently not reasonable to deploy on robotic systems. To meet our problem space requirements, we introduce a dataset and pipeline to create Field Reasoning and Instruction Decoding Agent (FRIDA) models. In our pipeline, domain experts and linguists combine their knowledge to make high-quality few-shot prompts used to generate synthetic data for fine-tuning. We hand-curate datasets for this few-shot prompting and for evaluation to improve LLM reasoning on both general and disaster-specific objects. We concurrently run an ablation study to understand which kinds of synthetic data most affect performance. We fine-tune several small instruction-tuned models and find that ablated FRIDA models only trained on objects' physical state and function data outperformed both the FRIDA models trained on all synthetic data and the base models in our customized evaluation. We demonstrate that the FRIDA pipeline is capable of instilling physical common sense with minimal data.",
    "authors": [
      "Shichman, Mollie",
      "Bonial, Claire",
      "Blodgett, Austin",
      "Hudson, Taylor",
      "Ferraro, Francis",
      "Rudinger, Rachel"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.18452v2",
      "Other Formats": "https://arxiv.org/format/2502.18452",
      "TeX Source": "https://arxiv.org/src/2502.18452",
      "View PDF": "https://arxiv.org/pdf/2502.18452"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 25 Feb 2025 18:51:06 UTC (2,164 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 19:43:12 UTC (2,651 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/25",
    "title": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response",
    "tasks": [
      "Common Sense Reasoning",
      "Disaster Response",
      "Information Retrieval"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2502.18443",
    "abstract": "PDF documents have the potential to provide trillions of novel, high-quality tokens for training language models. However, these documents come in a diversity of types with differing formats and visual layouts that pose a challenge when attempting to extract and faithfully represent the underlying content for language model use. Traditional open source tools often produce lower quality extractions compared to vision language models (VLMs), but reliance on the best VLMs can be prohibitively costly (e.g., over $6,240 USD per million PDF pages for GPT-4o) or infeasible if the PDFs cannot be sent to proprietary APIs. We present olmOCR, an open-source toolkit for processing PDFs into clean, linearized plain text in natural reading order while preserving structured content like sections, tables, lists, equations, and more. Our toolkit runs a fine-tuned 7B vision language model (VLM) trained on olmOCR-mix-0225, a sample of 260,000 pages from over 100,000 crawled PDFs with diverse properties, including graphics, handwritten text and poor quality scans. olmOCR is optimized for large-scale batch processing, able to scale flexibly to different hardware setups and can convert a million PDF pages for only $176 USD. To aid comparison with existing systems, we also introduce olmOCR-Bench, a curated set of 1,400 PDFs capturing many content types that remain challenging even for the best tools and VLMs, including formulas, tables, tiny fonts, old scans, and more. We find olmOCR outperforms even top VLMs including GPT-4o, Gemini Flash 2 and Qwen-2.5-VL. We openly release all components of olmOCR: our fine-tuned VLM model, training code and data, an efficient inference pipeline that supports vLLM and SGLang backends, and benchmark olmOCR-Bench.",
    "authors": [
      "Poznanski, Jake",
      "Rangapur, Aman",
      "Borchardt, Jon",
      "Dunkelberger, Jason",
      "Huff, Regan",
      "Lin, Daniel",
      "Rangapur, Aman",
      "Wilhelm, Christopher",
      "Lo, Kyle",
      "Soldaini, Luca"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2502.18443v2",
      "Other Formats": "https://arxiv.org/format/2502.18443",
      "TeX Source": "https://arxiv.org/src/2502.18443",
      "View PDF": "https://arxiv.org/pdf/2502.18443"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 25 Feb 2025 18:38:38 UTC (3,128 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 18:32:05 UTC (10,790 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/02/25",
    "title": "olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models",
    "repo_urls": [
      "https://github.com/allenai/olmocr"
    ],
    "tasks": [
      "Diversity",
      "Language Modeling",
      "Language Modelling"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.15517",
    "abstract": "Vision-Language Models (VLMs) acquire real-world knowledge and general reasoning ability through Internet-scale image-text corpora. They can augment robotic systems with scene understanding and task planning, and assist visuomotor policies that are trained on robot trajectory data. We explore the reverse paradigm - using rich, real, multi-modal robot trajectory data to enhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual Question Answering (VQA) dataset generation framework for VLMs. Given a human tele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual and non-descriptive sensory modalities, such as end-effector pose, gripper aperture, and force sensing. Based on these modalities, it segments the robot trajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses scene and interaction understanding to identify 3D properties of the robot, task goal, and the target object. The properties are used to generate representative VQA queries - images with textural multiple-choice questions - based on spatial, goal-conditioned, and interaction reasoning question templates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710 questions covering 463 distinct scenes and 3,396 robotic manipulation tasks from 176k real robot trajectories. Results suggest that Robo2VLM-1 can benchmark and improve VLM capabilities in spatial and interaction reasoning.",
    "authors": [
      "Chen, Kaiyuan",
      "Xie, Shuangyu",
      "Ma, Zehan",
      "Sanketi, Pannag R",
      "Goldberg, Ken"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "Other Formats": "https://arxiv.org/format/2505.15517",
      "TeX Source": "https://arxiv.org/src/2505.15517",
      "View PDF": "https://arxiv.org/pdf/2505.15517"
    },
    "subjects": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 21 May 2025 13:42:52 UTC (2,189 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 21:24:31 UTC (44,830 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/21",
    "title": "Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets",
    "tasks": [
      "Dataset Generation",
      "Descriptive",
      "Multiple-choice",
      "Question Answering",
      "Robot Manipulation",
      "Scene Understanding",
      "Task Planning",
      "Visual Question Answering",
      "Visual Question Answering (VQA)",
      "World Knowledge"
    ],
    "datasets": [
      {
        "dataset_name": "keplerccc/ManipulationVQA-60k",
        "downloads": "199",
        "likes": "0",
        "link": "https://huggingface.co/datasets/keplerccc/ManipulationVQA-60k"
      },
      {
        "dataset_name": "keplerccc/Robo2VLM-1",
        "downloads": "2705",
        "likes": "5",
        "link": "https://huggingface.co/datasets/keplerccc/Robo2VLM-1"
      },
      {
        "dataset_name": "remyxai/Robo2VLM-Reasoning",
        "downloads": "42",
        "likes": "1",
        "link": "https://huggingface.co/datasets/remyxai/Robo2VLM-Reasoning"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.08013",
    "abstract": "As a core step in structure-from-motion and SLAM, robust feature detection and description under challenging scenarios such as significant viewpoint changes remain unresolved despite their ubiquity. While recent works have identified the importance of local features in modeling geometric transformations, these methods fail to learn the visual cues present in long-range relationships. We present Robust Deformable Detector (RDD), a novel and robust keypoint detector/descriptor leveraging the deformable transformer, which captures global context and geometric invariance through deformable self-attention mechanisms. Specifically, we observed that deformable attention focuses on key locations, effectively reducing the search space complexity and modeling the geometric invariance. Furthermore, we collected an Air-to-Ground dataset for training in addition to the standard MegaDepth dataset. Our proposed method outperforms all state-of-the-art keypoint detection/description methods in sparse matching tasks and is also capable of semi-dense matching. To ensure comprehensive evaluation, we introduce two challenging benchmarks: one emphasizing large viewpoint and scale variations, and the other being an Air-to-Ground benchmark -- an evaluation setting that has recently gaining popularity for 3D reconstruction across different altitudes.",
    "authors": [
      "Chen, Gonglin",
      "Fu, Tianwen",
      "Chen, Haiwei",
      "Teng, Wenbin",
      "Xiao, Hanyuan",
      "Zhao, Yajie"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.08013v2",
      "Other Formats": "https://arxiv.org/format/2505.08013",
      "TeX Source": "https://arxiv.org/src/2505.08013",
      "View PDF": "https://arxiv.org/pdf/2505.08013"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 12 May 2025 19:24:45 UTC (2,597 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 16:02:35 UTC (2,254 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/12",
    "title": "RDD: Robust Feature Detector and Descriptor using Deformable Transformer",
    "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Chen_RDD_Robust_Feature_Detector_and_Descriptor_using_Deformable_Transformer_CVPR_2025_paper.html",
    "tasks": [
      "3D Reconstruction",
      "Keypoint Detection"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2505.05625",
    "abstract": "Estimating rate coefficients from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence that hinder effective rate coefficient estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a latent neural ODE learns the continuous and differentiable trajectory between chemical concentrations and their time derivatives; second, an explicit Chemical Reaction Neural Network (CRNN) extracts the underlying rate coefficients based on the learned dynamics; and third, fine-tune CRNN using a neural ODE solver to further improve rate coefficient estimation. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work on stiff Neural ODEs for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.",
    "authors": [
      "Peng, Wenqing",
      "Liu, Zhi-Song",
      "Boy, Michael"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2505.05625v2",
      "Other Formats": "https://arxiv.org/format/2505.05625",
      "TeX Source": "https://arxiv.org/src/2505.05625",
      "View PDF": "https://arxiv.org/pdf/2505.05625"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Thu, 8 May 2025 20:03:30 UTC (3,891 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 18:09:35 UTC (3,901 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/05/08",
    "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation",
    "repo_urls": [
      "https://github.com/pvvq/spin-ode"
    ],
    "tasks": [],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15626",
    "abstract": "$\\textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a neuroimaging biomarker reflecting brain health. However, training robust BrainAGE models requires large datasets, often restricted by privacy concerns. This study evaluates the performance of federated learning (FL) for BrainAGE estimation in ischemic stroke patients treated with mechanical thrombectomy, and investigates its association with clinical phenotypes and functional outcomes. $\\textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients across 16 hospital centers. We implemented standard machine learning and deep learning models for BrainAGE estimates under three data management strategies: centralized learning (pooled data), FL (local training at each site), and single-site learning. We reported prediction errors and examined associations between BrainAGE and vascular risk factors (e.g., diabetes mellitus, hypertension, smoking), as well as functional outcomes at three months post-stroke. Logistic regression evaluated BrainAGE's predictive value for these outcomes, adjusting for age, sex, vascular risk factors, stroke severity, time between MRI and arterial puncture, prior intravenous thrombolysis, and recanalisation outcome. $\\textbf{Results:}$ While centralized learning yielded the most accurate predictions, FL consistently outperformed single-site models. BrainAGE was significantly higher in patients with diabetes mellitus across all models. Comparisons between patients with good and poor functional outcomes, and multivariate predictions of these outcomes showed the significance of the association between BrainAGE and post-stroke recovery. $\\textbf{Conclusion:}$ FL enables accurate age predictions without data centralization. The strong association between BrainAGE, vascular risk factors, and post-stroke recovery highlights its potential for prognostic modeling in stroke care.",
    "authors": [
      "Roca, Vincent",
      "Tommasi, Marc",
      "Andrey, Paul",
      "Bellet, Aur\u00e9lien",
      "Schirmer, Markus D.",
      "Henon, Hilde",
      "Puy, Laurent",
      "Ramon, Julien",
      "Kuchcinski, Gr\u00e9gory",
      "Bretzner, Martin",
      "Lopes, Renaud"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15626v1",
      "Other Formats": "https://arxiv.org/format/2506.15626",
      "TeX Source": "https://arxiv.org/src/2506.15626",
      "View PDF": "https://arxiv.org/pdf/2506.15626"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 16:56:44 UTC (154 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction",
    "tasks": [
      "Federated Learning"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2407.09879",
    "abstract": "Despite the remarkable success of large language models (LLMs) in English, a significant performance gap remains in non-English languages. To address this, we introduce a novel approach for strategically constructing a multilingual synthetic instruction tuning dataset, sPhinX. Unlike prior methods that directly translate fixed instruction-response pairs, sPhinX enhances diversity by selectively augmenting English instruction-response pairs with multilingual translations. Additionally, we propose LANGIT, a novel N-shot guided fine-tuning strategy, which further enhances model performance by incorporating contextually relevant examples in each training sample. Our ablation study shows that our approach enhances the multilingual capabilities of Mistral-7B and Phi-3-Small improving performance by an average of 39.8% and 11.2%, respectively, across multilingual benchmarks in reasoning, question answering, reading comprehension, and machine translation. Moreover, sPhinX maintains strong performance on English LLM benchmarks while exhibiting minimal to no catastrophic forgetting, even when trained on 51 languages.",
    "authors": [
      "Ahuja, Sanchit",
      "Tanmay, Kumar",
      "Chauhan, Hardik Hansrajbhai",
      "Patra, Barun",
      "Aggarwal, Kriti",
      "Del Corro, Luciano",
      "Mitra, Arindam",
      "Dhamecha, Tejas Indulal",
      "Awadallah, Ahmed",
      "Choudhary, Monojit",
      "Chaudhary, Vishrav",
      "Sitaram, Sunayana"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2407.09879v4",
      "Other Formats": "https://arxiv.org/format/2407.09879",
      "TeX Source": "https://arxiv.org/src/2407.09879",
      "View PDF": "https://arxiv.org/pdf/2407.09879"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 13 Jul 2024 13:03:45 UTC (3,039 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Tue, 16 Jul 2024 17:23:18 UTC (3,039 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Wed, 16 Oct 2024 12:57:56 UTC (3,046 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Wed, 18 Jun 2025 19:19:17 UTC (1,180 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2024/07/13",
    "title": "sPhinX: Sample Efficient Multilingual Instruction Fine-Tuning Through N-shot Guided Prompting",
    "tasks": [
      "Machine Translation",
      "Question Answering",
      "Reading Comprehension"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15803",
    "abstract": "Objective. Proton arc therapy (PAT) is an emerging and promising modality in radiotherapy, offering several advantages over conventional intensitymodulated proton therapy (IMPT). However, identifying the optimal energy layer (EL) sequence remains computationally intensive due to the large number of possible energy layer transitions. This study proposes an unsupervised deep learning framework for fast and effective EL pre-selection, aiming to minimize energy layer switch time while preserving high plan quality. Approach. We introduce a novel data representation method, spot-count representation, which encodes the number of proton spots intersecting the target and organs at risk (OARs) in a matrix structured by sorted gantry angles and energy layers. This representation is the input of a UNet-based architecture, SPArcdl, which is trained to optimize a tri-objective function: maximizing target coverage, minimizing OAR exposure, and reducing energy switching time. The model is evaluated on 54 nasopharyngeal cancer cases, and its performance is benchmarked against plans generated by SPArcparticle swarm. Main results. SPArcdl produces EL pre-selection that significantly improves both plan quality and delivery efficiency. Compared to SPArc particle swarm, it enhances the conformity index by 0.16 (p < 0.01), reduces the homogeneity index by 0.71 (p < 0.01), shortens the energy switching time by 38.4% (p < 0.01), and lowers the mean dose to brainstem by 0.21 (p < 0.01). The results unintentionally reveal employing unchanged ELS is more time-wise efficient than descended ELS. SPArcdl's inference time is within 1 second. Significance. SPArcdl is a fast and effective tool for generating high-quality PAT plans by strategically pre-selecting energy layers to reduce delivery time while maintaining excellent dosimetric performance.",
    "authors": [
      "Yang, Bohan",
      "Liu, Gang",
      "Dao, Rirao",
      "Qian, Yujia",
      "Shi, Ke",
      "Tang, Anke",
      "Luo, Yong",
      "Liu, Jingnan"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15803v1",
      "Other Formats": "https://arxiv.org/format/2506.15803",
      "TeX Source": "https://arxiv.org/src/2506.15803",
      "View PDF": "https://arxiv.org/pdf/2506.15803"
    },
    "subjects": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 18:40:10 UTC (2,192 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Unsupervised deep learning model for fast energy layer pre-selection of delivery-efficient proton arc therapy plan optimization of nasopharyngeal carcinoma",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15762",
    "abstract": "Diffusion magnetic resonance imaging (dMRI) enables non-invasive investigation of tissue microstructure. The Standard Model (SM) of white matter aims to disentangle dMRI signal contributions from intra- and extra-axonal water compartments. However, due to the model its high-dimensional nature, extensive acquisition protocols with multiple b-values and diffusion tensor shapes are typically required to mitigate parameter degeneracies. Even then, accurate estimation remains challenging due to noise. This work introduces a novel estimation framework based on implicit neural representations (INRs), which incorporate spatial regularization through the sinusoidal encoding of the input coordinates. The INR method is evaluated on both synthetic and in vivo datasets and compared to parameter estimates using cubic polynomials, supervised neural networks, and nonlinear least squares. Results demonstrate superior accuracy of the INR method in estimating SM parameters, particularly in low signal-to-noise conditions. Additionally, spatial upsampling of the INR can represent the underlying dataset anatomically plausibly in a continuous way, which is unattainable with linear or cubic interpolation. The INR is fully unsupervised, eliminating the need for labeled training data. It achieves fast inference ($\\sim$6 minutes), is robust to both Gaussian and Rician noise, supports joint estimation of SM kernel parameters and the fiber orientation distribution function with spherical harmonics orders up to at least 8 and non-negativity constraints, and accommodates spatially varying acquisition protocols caused by magnetic gradient non-uniformities. The combination of these properties along with the possibility to easily adapt the framework to other dMRI models, positions INRs as a potentially important tool for analyzing and interpreting diffusion MRI data.",
    "authors": [
      "Hendriks, Tom",
      "Arends, Gerrit",
      "Versteeg, Edwin",
      "Vilanova, Anna",
      "Chamberland, Maxime",
      "Tax, Chantal M. W."
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15762v1",
      "Other Formats": "https://arxiv.org/format/2506.15762",
      "TeX Source": "https://arxiv.org/src/2506.15762",
      "View PDF": "https://arxiv.org/pdf/2506.15762"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 15:40:42 UTC (21,374 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Implicit neural representations for accurate estimation of the standard model of white matter",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.11903",
    "abstract": "Advances in transformer-based language models have highlighted the benefits of language-specific pre-training on high-quality corpora. In this context, German NLP stands to gain from updated architectures and modern datasets tailored to the linguistic characteristics of the German language. GeistBERT seeks to improve German language processing by incrementally training on a diverse corpus and optimizing model performance across various NLP tasks. It was pre-trained using fairseq with standard hyperparameters, initialized from GottBERT weights, and trained on a large-scale German corpus using Whole Word Masking (WWM). Based on the pre-trained model, we derived extended-input variants using Nystr\\\"omformer and Longformer architectures with support for sequences up to 8k tokens. While these long-context models were not evaluated on dedicated long-context benchmarks, they are included in our release. We assessed all models on NER (CoNLL 2003, GermEval 2014) and text classification (GermEval 2018 fine/coarse, 10kGNAD) using $F_1$ score and accuracy. The GeistBERT models achieved strong performance, leading all tasks among the base models and setting a new state-of-the-art (SOTA). Notably, the base models outperformed larger models in several tasks. To support the German NLP research community, we are releasing GeistBERT under the MIT license.",
    "authors": [
      "Scheible-Schmitt, Raphael",
      "Frei, Johann"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.11903v2",
      "Other Formats": "https://arxiv.org/format/2506.11903",
      "TeX Source": "https://arxiv.org/src/2506.11903",
      "View PDF": "https://arxiv.org/pdf/2506.11903"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 13 Jun 2025 15:53:17 UTC (131 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 23:06:09 UTC (131 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/06/13",
    "title": "GeistBERT: Breathing Life into German NLP",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15848",
    "abstract": "Query optimizer is a crucial module for database management systems. Existing optimizers exhibit two flawed paradigms: (1) cost-based optimizers use dynamic programming with cost models but face search space explosion and heuristic pruning constraints; (2) value-based ones train value networks to enable efficient beam search, but incur higher training costs and lower accuracy. They also lack mechanisms to detect queries where they may perform poorly. To determine more efficient plans, we propose Delta, a mixed cost-based query optimization framework that consists of a compatible query detector and a two-stage planner. Delta first employs a Mahalanobis distancebased detector to preemptively filter out incompatible queries where the planner might perform poorly. For compatible queries, Delta activates its two-stage mixed cost-based planner. Stage I serves as a coarse-grained filter to generate high-quality candidate plans based on the value network via beam search, relaxing precision requirements and narrowing the search space. Stage II employs a fine-grained ranker to determine the best plan from the candidate plans based on a learned cost model. Moreover, to reduce training costs, we reuse and augment the training data from stage I to train the model in stage II. Experimental results on three workloads demonstrate that Delta identifies higher-quality plans, achieving an average 2.34x speedup over PostgreSQL and outperforming the state-of-the-art learned methods by 2.21x.",
    "authors": [
      "Peng, Jiazhen",
      "Qu, Zheng",
      "Miao, Xiaoye",
      "Zhu, Rong"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15848v1",
      "Other Formats": "https://arxiv.org/format/2506.15848",
      "TeX Source": "https://arxiv.org/src/2506.15848",
      "View PDF": "https://arxiv.org/pdf/2506.15848"
    },
    "subjects": [
      "Databases (cs.DB)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 19:55:59 UTC (434 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Delta: A Learned Mixed Cost-based Query Optimization Framework",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15318",
    "abstract": "Pathology image classification plays a crucial role in accurate medical diagnosis and treatment planning. Training high-performance models for this task typically requires large-scale annotated datasets, which are both expensive and time-consuming to acquire. Active Learning (AL) offers a solution by iteratively selecting the most informative samples for annotation, thereby reducing the labeling effort. However, most AL methods are designed under the assumption of a closed-set scenario, where all the unannotated images belong to target classes. In real-world clinical environments, the unlabeled pool often contains a substantial amount of Out-Of-Distribution (OOD) data, leading to low efficiency of annotation in traditional AL methods. Furthermore, most existing AL methods start with random selection in the first query round, leading to a significant waste of labeling costs in open-set scenarios. To address these challenges, we propose OpenPath, a novel open-set active learning approach for pathological image classification leveraging a pre-trained Vision-Language Model (VLM). In the first query, we propose task-specific prompts that combine target and relevant non-target class prompts to effectively select In-Distribution (ID) and informative samples from the unlabeled pool. In subsequent queries, Diverse Informative ID Sampling (DIS) that includes Prototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic Sampling (EGSS) is proposed to ensure both purity and informativeness in a query, avoiding the selection of OOD samples. Experiments on two public pathology image datasets show that OpenPath significantly enhances the model's performance due to its high purity of selected samples, and outperforms several state-of-the-art open-set AL methods. The code is available at \\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}..",
    "authors": [
      "Zhong, Lanfeng",
      "Liao, Xin",
      "Zhang, Shichuan",
      "Zhang, Shaoting",
      "Wang, Guotai"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15318v1",
      "Other Formats": "https://arxiv.org/format/2506.15318",
      "TeX Source": "https://arxiv.org/src/2506.15318",
      "View PDF": "https://arxiv.org/pdf/2506.15318"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 09:47:45 UTC (3,534 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models",
    "tasks": [
      "Active Learning",
      "image-classification",
      "Image Classification",
      "Informativeness",
      "Medical Diagnosis"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15898",
    "abstract": "With the proliferation of location-tracking technologies, massive volumes of trajectory data are continuously being collected. As a fundamental task in trajectory data mining, trajectory similarity computation plays a critical role in a wide range of real-world applications. However, existing learning-based methods face three challenges: First, they ignore the semantic gap between GPS and grid features in trajectories, making it difficult to obtain meaningful trajectory embeddings. Second, the noise inherent in the trajectories, as well as the noise introduced during grid discretization, obscures the true motion patterns of the trajectories. Third, existing methods focus solely on point-wise and pair-wise losses, without utilizing the global ranking information obtained by sorting all trajectories according to their similarity to a given trajectory. To address the aforementioned challenges, we propose a novel trajectory similarity computation framework, named TrajDiff. Specifically, the semantic alignment module relies on cross-attention and an attention score mask mechanism with adaptive fusion, effectively eliminating semantic discrepancies between data at two scales and generating a unified representation. Additionally, the DDBM-based Noise-robust Pre-Training introduces the transfer patterns between any two trajectories into the model training process, enhancing the model's noise robustness. Finally, the overall ranking-aware regularization shifts the model's focus from a local to a global perspective, enabling it to capture the holistic ordering information among trajectories. Extensive experiments on three publicly available datasets show that TrajDiff consistently outperforms state-of-the-art baselines. In particular, it achieves an average HR@1 gain of 33.38% across all three evaluation metrics and datasets.",
    "authors": [
      "Zhang, Xiao",
      "Zhao, Xingyu",
      "Xia, Hong",
      "Cao, Yuan",
      "Jiang, Guiyuan",
      "Dong, Junyu",
      "Yu, Yanwei"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15898v1",
      "Other Formats": "https://arxiv.org/format/2506.15898",
      "TeX Source": "https://arxiv.org/src/2506.15898",
      "View PDF": "https://arxiv.org/pdf/2506.15898"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 21:52:07 UTC (2,670 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "TrajDiff: Diffusion Bridge Network with Semantic Alignment for Trajectory Similarity Computation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15860",
    "abstract": "Visual analysis of relational data is essential for many real-world analytics tasks, with layout quality being key to interpretability. However, existing layout algorithms often require users to navigate complex parameters to express their intent. We present a user-guided force-directed layout approach that enables intuitive control through freehand sketching. Our method uses classical image analysis techniques to extract structural information from sketches, which is then used to generate positional constraints that guide the layout process. We evaluate the approach on various real and synthetic graphs ranging from small to medium scale, demonstrating its ability to produce layouts aligned with user expectations. An implementation of our method along with documentation and a demo page is freely available on GitHub at https://github.com/sciluna/uggly.",
    "authors": [
      "Balci, Hasan",
      "Luna, Augustin"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15860v1",
      "Other Formats": "https://arxiv.org/format/2506.15860",
      "TeX Source": "https://arxiv.org/src/2506.15860",
      "View PDF": "https://arxiv.org/pdf/2506.15860"
    },
    "subjects": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 20:11:46 UTC (8,283 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "User-Guided Force-Directed Graph Layout",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15903",
    "abstract": "We introduce a large-scale dataset for instruction-guided vector image editing, consisting of over 270,000 pairs of SVG images paired with natural language edit instructions. Our dataset enables training and evaluation of models that modify vector graphics based on textual commands. We describe the data collection process, including image pairing via CLIP similarity and instruction generation with vision-language models. Initial experiments with state-of-the-art large language models reveal that current methods struggle to produce accurate and valid edits, underscoring the challenge of this task. To foster research in natural language-driven vector graphic generation and editing, we make our resources created within this work publicly available.",
    "authors": [
      "Kucha\u0159, Josef",
      "Kadl\u010d\u00edk, Marek",
      "Spiegel, Michal",
      "\u0160tef\u00e1nik, Michal"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15903v1",
      "Other Formats": "https://arxiv.org/format/2506.15903",
      "TeX Source": "https://arxiv.org/src/2506.15903",
      "View PDF": "https://arxiv.org/pdf/2506.15903"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 22:17:30 UTC (217 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15852",
    "abstract": "This paper tackles the task of writer identification for Greek papyri. A common preprocessing step in writer identification pipelines is image binarization, which prevents the model from learning background features. This is challenging in historical documents, in our case Greek papyri, as background is often non-uniform, fragmented, and discolored with visible fiber structures. We compare traditional binarization methods to state-of-the-art Deep Learning (DL) models, evaluating the impact of binarization quality on subsequent writer identification performance. DL models are trained with and without a custom data augmentation technique, as well as different model selection criteria are applied. The performance of these binarization methods, is then systematically evaluated on the DIBCO 2019 dataset. The impact of binarization on writer identification is subsequently evaluated using a state-of-the-art approach for writer identification. The results of this analysis highlight the influence of data augmentation for DL methods. Furthermore, findings indicate a strong correlation between binarization effectiveness on papyri documents of DIBCO 2019 and downstream writer identification performance.",
    "authors": [
      "Akt, Dominic",
      "Peer, Marco",
      "Kleber, Florian"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15852v1",
      "Other Formats": "https://arxiv.org/format/2506.15852",
      "TeX Source": "https://arxiv.org/src/2506.15852",
      "View PDF": "https://arxiv.org/pdf/2506.15852"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 20:00:57 UTC (762 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Assessing the impact of Binarization for Writer Identification in Greek Papyrus",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2504.05154",
    "abstract": "Language Models (LMs) are typically tuned with human preferences to produce helpful responses, but the impact of preference tuning on the ability to handle culturally diverse queries remains understudied. In this paper, we systematically analyze how native human cultural preferences can be incorporated into the preference learning process to train more culturally aware LMs. We introduce CARE, a multilingual resource containing 3,490 culturally specific questions and 31.7k responses with native judgments. We demonstrate how a modest amount of high-quality native preferences improves cultural awareness across various LMs, outperforming larger generic preference data. Our analyses reveal that models with stronger initial cultural performance benefit more from alignment, leading to gaps among models developed in different regions with varying access to culturally relevant data. CARE will be made publicly available at https://github.com/Guochry/CARE.",
    "authors": [
      "Guo, Geyang",
      "Naous, Tarek",
      "Wakaki, Hiromi",
      "Nishimura, Yukiko",
      "Mitsufuji, Yuki",
      "Ritter, Alan",
      "Xu, Wei"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2504.05154v4",
      "Other Formats": "https://arxiv.org/format/2504.05154",
      "TeX Source": "https://arxiv.org/src/2504.05154",
      "View PDF": "https://arxiv.org/pdf/2504.05154"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 7 Apr 2025 14:57:06 UTC (3,803 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Tue, 15 Apr 2025 05:34:48 UTC (3,804 KB)",
        "link": "/",
        "version": "[v2]"
      },
      {
        "details": "Wed, 4 Jun 2025 05:22:27 UTC (2,926 KB)",
        "link": "/",
        "version": "[v3]"
      },
      {
        "details": "Wed, 18 Jun 2025 23:44:50 UTC (2,932 KB)",
        "version": "[v4]"
      }
    ],
    "submitted_date": "2025/04/07",
    "title": "CARE: Assessing the Impact of Multilingual Human Preference Learning on Cultural Awareness",
    "repo_urls": [
      "https://github.com/guochry/care"
    ],
    "tasks": [],
    "datasets": [
      {
        "dataset_name": "geyang627/CARE",
        "downloads": "46",
        "likes": "1",
        "link": "https://huggingface.co/datasets/geyang627/CARE"
      },
      {
        "dataset_name": "geyang627/CARE-eval",
        "downloads": "42",
        "likes": "1",
        "link": "https://huggingface.co/datasets/geyang627/CARE-eval"
      }
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15841",
    "abstract": "Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.",
    "authors": [
      "Zhou, Zijian",
      "Qu, Ao",
      "Wu, Zhaoxuan",
      "Kim, Sunghwan",
      "Prakash, Alok",
      "Rus, Daniela",
      "Zhao, Jinhua",
      "Low, Bryan Kian Hsiang",
      "Liang, Paul Pu"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15841v1",
      "Other Formats": "https://arxiv.org/format/2506.15841",
      "TeX Source": "https://arxiv.org/src/2506.15841",
      "View PDF": "https://arxiv.org/pdf/2506.15841"
    },
    "subjects": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 19:44:46 UTC (5,049 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2503.19549",
    "abstract": "In 6G wireless networks, Artificial Intelligence (AI)-driven applications demand the adoption of Federated Learning (FL) to enable efficient and privacy-preserving model training across distributed devices. Over-The-Air Federated Learning (OTA-FL) exploits the superposition property of multiple access channels, allowing edge users in 6G networks to efficiently share spectral resources and perform low-latency global model aggregation. However, these advantages come with challenges, as traditional OTA-FL techniques suffer due to the joint effects of Additive White Gaussian Noise (AWGN) at the server, fading, and both data and system heterogeneity at the participating edge devices. In this work, we propose the novel Noise Resilient Over-the-Air Federated Learning (NoROTA-FL) framework to jointly tackle these challenges in federated wireless networks. In NoROTA-FL, the local optimization problems find controlled inexact solutions, which manifests as an additional proximal constraint at the clients. This approach provides robustness against straggler-induced partial work, heterogeneity, noise, and fading. From a theoretical perspective, we leverage the zeroth- and first-order inexactness and establish convergence guarantees for non-convex optimization problems in the presence of heterogeneous data and varying system capabilities. Experimentally, we validate NoROTA-FL on real-world datasets, including FEMNIST, CIFAR10, and CIFAR100, demonstrating its robustness in noisy and heterogeneous environments. Compared to state-of-the-art baselines such as COTAF and FedProx, NoROTA-FL achieves significantly more stable convergence and higher accuracy, particularly in the presence of stragglers.",
    "authors": [
      "Shaban, Zubair",
      "Shah, Nazreen",
      "Prasad, Ranjitha"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2503.19549v2",
      "Other Formats": "https://arxiv.org/format/2503.19549",
      "TeX Source": "https://arxiv.org/src/2503.19549",
      "View PDF": "https://arxiv.org/pdf/2503.19549"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 25 Mar 2025 11:04:00 UTC (2,635 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Wed, 18 Jun 2025 18:01:32 UTC (2,311 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2025/03/25",
    "title": "Noise Resilient Over-The-Air Federated Learning In Heterogeneous Wireless Networks",
    "tasks": [
      "Federated Learning",
      "Privacy Preserving"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15825",
    "abstract": "In this paper, we first propose a novel algorithm for model fusion that leverages Wasserstein barycenters in training a global Deep Neural Network (DNN) in a distributed architecture. To this end, we divide the dataset into equal parts that are fed to \"agents\" who have identical deep neural networks and train only over the dataset fed to them (known as the local dataset). After some training iterations, we perform an aggregation step where we combine the weight parameters of all neural networks using Wasserstein barycenters. These steps form the proposed algorithm referred to as FedWB. Moreover, we leverage the processes created in the first part of the paper to develop an algorithm to tackle Heterogeneous Federated Reinforcement Learning (HFRL). Our test experiment is the CartPole toy problem, where we vary the lengths of the poles to create heterogeneous environments. We train a deep Q-Network (DQN) in each environment to learn to control each cart, while occasionally performing a global aggregation step to generalize the local models; the end outcome is a global DQN that functions across all environments.",
    "authors": [
      "Pereira, Luiz",
      "Amini, M. Hadi"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15825v1",
      "Other Formats": "https://arxiv.org/format/2506.15825",
      "TeX Source": "https://arxiv.org/src/2506.15825",
      "View PDF": "https://arxiv.org/pdf/2506.15825"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 19:09:57 UTC (226 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Heterogeneous Federated Reinforcement Learning Using Wasserstein Barycenters",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15792",
    "abstract": "Fast and accurate prediction of molecular properties with machine learning is pivotal to scientific advancements across myriad domains. Foundation models in particular have proven especially effective, enabling accurate training on small, real-world datasets. This study introduces CheMeleon, a novel molecular foundation model pre-trained on deterministic molecular descriptors from the Mordred package, leveraging a Directed Message-Passing Neural Network to predict these descriptors in a noise-free setting. Unlike conventional approaches relying on noisy experimental data or biased quantum mechanical simulations, CheMeleon uses low-noise molecular descriptors to learn rich molecular representations. Evaluated on 58 benchmark datasets from Polaris and MoleculeACE, CheMeleon achieves a win rate of 79% on Polaris tasks, outperforming baselines like Random Forest (46%), fastprop (39%), and Chemprop (36%), and a 97% win rate on MoleculeACE assays, surpassing Random Forest (63%) and other foundation models. However, it struggles to distinguish activity cliffs like many of the tested models. The t-SNE projection of CheMeleon's learned representations demonstrates effective separation of chemical series, highlighting its ability to capture structural nuances. These results underscore the potential of descriptor-based pre-training for scalable and effective molecular property prediction, opening avenues for further exploration of descriptor sets and unlabeled datasets.",
    "authors": [
      "Burns, Jackson",
      "Zalte, Akshat",
      "Green, William"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15792v1",
      "Other Formats": "https://arxiv.org/format/2506.15792",
      "TeX Source": "https://arxiv.org/src/2506.15792",
      "View PDF": "https://arxiv.org/pdf/2506.15792"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 18:21:50 UTC (1,129 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Descriptor-based Foundation Models for Molecular Property Prediction",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15889",
    "abstract": "Byte-Pair Encoding (BPE) has become a widely adopted subword tokenization method in modern language models due to its simplicity and strong empirical performance across downstream tasks. However, applying BPE to unsegmented languages such as Chinese presents significant challenges, as its frequency-driven merge operation is agnostic to linguistic boundaries. To address this, we propose two entropy-informed pre-tokenization strategies that guide BPE segmentation using unsupervised information-theoretic cues. The first approach uses pointwise mutual information and left/right entropy to identify coherent character spans, while the second leverages predictive entropy derived from a pretrained GPT-2 model to detect boundary uncertainty. We evaluate both methods on a subset of the PKU dataset and demonstrate substantial improvements in segmentation precision, recall, and F1 score compared to standard BPE. Our results suggest that entropy-guided pre-tokenization not only enhances alignment with gold-standard linguistic units but also offers a promising direction for improving tokenization quality in low-resource and multilingual settings.",
    "authors": [
      "Hu, Yifan",
      "Liang, Frank",
      "Zhao, Dachuan",
      "Geuter, Jonathan",
      "Reddy, Varshini",
      "Schmidt, Craig W.",
      "Tanner, Chris"
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15889v1",
      "Other Formats": "https://arxiv.org/format/2506.15889",
      "TeX Source": "https://arxiv.org/src/2506.15889",
      "View PDF": "https://arxiv.org/pdf/2506.15889"
    },
    "subjects": [
      "Computation and Language (cs.CL)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 21:25:55 UTC (934 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Entropy-Driven Pre-Tokenization for Byte-Pair Encoding",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15771",
    "abstract": "Quantum processors require rapid and high-fidelity simultaneous measurements of many qubits. While superconducting qubits are among the leading modalities toward a useful quantum processor, their readout remains a bottleneck. Traditional approaches to processing measurement data often struggle to account for crosstalk present in frequency-multiplexed readout, the preferred method to reduce the resource overhead. Recent approaches to address this challenge use neural networks to improve the state-discrimination fidelity. However, they are computationally expensive to train and evaluate, resulting in increased latency and poor scalability as the number of qubits increases. We present an alternative machine learning approach based on next-generation reservoir computing that constructs polynomial features from the measurement signals and maps them to the corresponding qubit states. This method is highly parallelizable, avoids the costly nonlinear activation functions common in neural networks, and supports real-time training, enabling fast evaluation, adaptability, and scalability. Despite its lower computational complexity, our reservoir approach is able to maintain high qubit-state-discrimination fidelity. Relative to traditional methods, our approach achieves error reductions of up to 50% and 11% on single- and five-qubit datasets, respectively, and delivers up to 2.5x crosstalk reduction on the five-qubit dataset. Compared with recent machine-learning methods, evaluating our model requires 100x fewer multiplications for single-qubit and 2.5x fewer for five-qubit models. This work demonstrates that reservoir computing can enhance qubit-state discrimination while maintaining scalability for future quantum processors.",
    "authors": [
      "Kent, Robert",
      "Lienhard, Benjamin",
      "Lafyatis, Gregory",
      "Gauthier, Daniel J."
    ],
    "last_revised_date": "2025/06/18",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15771v1",
      "Other Formats": "https://arxiv.org/format/2506.15771",
      "TeX Source": "https://arxiv.org/src/2506.15771",
      "View PDF": "https://arxiv.org/pdf/2506.15771"
    },
    "subjects": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 18 Jun 2025 18:00:01 UTC (376 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/18",
    "title": "Superconducting Qubit Readout Using Next-Generation Reservoir Computing",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15744",
    "abstract": "Class imbalance and the difficulty imbalance are the two types of data imbalance that affect the performance of neural networks in medical segmentation tasks. In class imbalance the loss is dominated by the majority classes and in difficulty imbalance the loss is dominated by easy to classify pixels. This leads to an ineffective training. Dice loss, which is based on a geometrical metric, is very effective in addressing the class imbalance compared to the cross entropy (CE) loss, which is adopted directly from classification tasks. To address the difficulty imbalance, the common approach is employing a re-weighted CE loss or a modified Dice loss to focus the training on difficult to classify areas. The existing modification methods are computationally costly and with limited success. In this study we propose a simple modification to the Dice loss with minimal computational cost. With a pixel level modulating term, we take advantage of the effectiveness of Dice loss in handling the class imbalance to also handle the difficulty imbalance. Results on three commonly used medical segmentation tasks show that the proposed Pixel-wise Modulated Dice loss (PM Dice loss) outperforms other methods, which are designed to tackle the difficulty imbalance problem.",
    "authors": [
      "Hosseini, Seyed Mohsen"
    ],
    "last_revised_date": "2025/06/17",
    "links": {
      "Other Formats": "https://arxiv.org/format/2506.15744",
      "View PDF": "https://arxiv.org/pdf/2506.15744"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 17 Jun 2025 23:09:41 UTC (1,254 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/17",
    "title": "Pixel-wise Modulated Dice Loss for Medical Image Segmentation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15838",
    "abstract": "Video diffusion models substantially boost the productivity of artistic workflows with high-quality portrait video generative capacity. However, prevailing pipelines are primarily constrained to single-shot creation, while real-world applications urge for multiple shots with identity consistency and flexible content controllability. In this work, we propose EchoShot, a native and scalable multi-shot framework for portrait customization built upon a foundation video diffusion model. To start with, we propose shot-aware position embedding mechanisms within video diffusion transformer architecture to model inter-shot variations and establish intricate correspondence between multi-shot visual content and their textual descriptions. This simple yet effective design enables direct training on multi-shot video data without introducing additional computational overhead. To facilitate model training within multi-shot scenario, we construct PortraitGala, a large-scale and high-fidelity human-centric video dataset featuring cross-shot identity consistency and fine-grained captions such as facial attributes, outfits, and dynamic motions. To further enhance applicability, we extend EchoShot to perform reference image-based personalized multi-shot generation and long video synthesis with infinite shot counts. Extensive evaluations demonstrate that EchoShot achieves superior identity consistency as well as attribute-level controllability in multi-shot portrait video generation. Notably, the proposed framework demonstrates potential as a foundational paradigm for general multi-shot video modeling.",
    "authors": [
      "Wang, Jiahao",
      "Sheng, Hualian",
      "Cai, Sijia",
      "Zhang, Weizhan",
      "Yan, Caixia",
      "Feng, Yachuang",
      "Deng, Bing",
      "Ye, Jieping"
    ],
    "last_revised_date": "2025/06/16",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15838v1",
      "Other Formats": "https://arxiv.org/format/2506.15838",
      "TeX Source": "https://arxiv.org/src/2506.15838",
      "View PDF": "https://arxiv.org/pdf/2506.15838"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 16 Jun 2025 11:00:16 UTC (57,028 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/16",
    "title": "EchoShot: Multi-Shot Portrait Video Generation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15835",
    "abstract": "Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the spatial relationships of anatomical structures, playing a crucial role in clinical diagnosis. Recently, deep-learning-based freehand 3D US has made significant advancements. It reconstructs volumes by estimating transformations between images without external tracking. However, image-only reconstruction poses difficulties in reducing cumulative drift and further improving reconstruction accuracy, particularly in scenarios involving complex motion trajectories. In this context, we propose an enhanced motion network (MoNetV2) to enhance the accuracy and generalizability of reconstruction under diverse scanning velocities and tactics. First, we propose a sensor-based temporal and multi-branch structure that fuses image and motion information from a velocity perspective to improve image-only reconstruction accuracy. Second, we devise an online multi-level consistency constraint that exploits the inherent consistency of scans to handle various scanning velocities and tactics. This constraint exploits both scan-level velocity consistency, path-level appearance consistency, and patch-level motion consistency to supervise inter-frame transformation estimation. Third, we distill an online multi-modal self-supervised strategy that leverages the correlation between network estimation and motion information to further reduce cumulative errors. Extensive experiments clearly demonstrate that MoNetV2 surpasses existing methods in both reconstruction quality and generalizability performance across three large datasets.",
    "authors": [
      "Luo, Mingyuan",
      "Yang, Xin",
      "Yan, Zhongnuo",
      "Cao, Yan",
      "Zhang, Yuanji",
      "Hu, Xindi",
      "Wang, Jin",
      "Ding, Haoxuan",
      "Han, Wei",
      "Sun, Litao",
      "Ni, Dong"
    ],
    "last_revised_date": "2025/06/16",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15835v1",
      "Other Formats": "https://arxiv.org/format/2506.15835",
      "TeX Source": "https://arxiv.org/src/2506.15835",
      "View PDF": "https://arxiv.org/pdf/2506.15835"
    },
    "subjects": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 16 Jun 2025 04:57:34 UTC (14,694 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/16",
    "title": "MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15733",
    "abstract": "Scaling test-time compute has driven the recent advances in the reasoning capabilities of large language models (LLMs), typically by allocating additional computation for more thorough exploration. However, increased compute often comes at the expense of higher user-facing latency, directly impacting user experience. Current test-time scaling methods primarily optimize for accuracy based on total compute resources (FLOPS), often overlooking latency constraints. To address this gap, we propose $\\texttt{SPECS}$, a latency-aware test-time scaling method inspired by speculative decoding. $\\texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences efficiently, and evaluates these candidates using signals from both a larger target model and a dedicated reward model. We introduce new integration strategies, including reward-guided soft verification and a reward-based deferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench datasets show that $\\texttt{SPECS}$~matches or surpasses beam search accuracy while reducing latency by up to $\\sim$19.1\\%. Our theoretical analysis shows that our algorithm converges to the solution of a KL-regularized reinforcement learning objective with increasing beam width.",
    "authors": [
      "Cemri, Mert",
      "Rajaraman, Nived",
      "Tiwari, Rishabh",
      "Liu, Xiaoxuan",
      "Keutzer, Kurt",
      "Stoica, Ion",
      "Ramchandran, Kannan",
      "Beirami, Ahmad",
      "Sun, Ziteng"
    ],
    "last_revised_date": "2025/06/15",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15733v1",
      "Other Formats": "https://arxiv.org/format/2506.15733",
      "TeX Source": "https://arxiv.org/src/2506.15733",
      "View PDF": "https://arxiv.org/pdf/2506.15733"
    },
    "subjects": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 15 Jun 2025 05:50:05 UTC (607 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/15",
    "title": "$\\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2312.06799",
    "abstract": "We propose a weakly supervised semantic segmentation method for point clouds that predicts \"per-point\" labels from just \"whole-scene\" annotations. The key challenge here is the discrepancy between the target of dense per-point semantic prediction and training losses derived from only scene-level labels. To address this, in addition to the typical weakly-supervised setup that supervises all points with the scene label, we propose to conservatively propagate the scene-level labels to points selectively. Specifically, we over-segment point cloud features via unsupervised clustering in the entire dataset and form primitives. We then associate scene-level labels with primitives through bipartite matching. Then, we allow labels to pass through this primitive-label relationship, while further encouraging features to form narrow clusters around the primitives. Importantly, through bipartite matching, this additional pathway through which labels flow, only propagates scene labels to the most relevant points, reducing the potential negative impact caused by the global approach that existing methods take. We evaluate our method on ScanNet and S3DIS datasets, outperforming the state of the art by a large margin.",
    "authors": [
      "Xia, Shaobo",
      "Yue, Jun",
      "Kania, Kacper",
      "Fang, Leyuan",
      "Tagliasacchi, Andrea",
      "Yi, Kwang Moo",
      "Sun, Weiwei"
    ],
    "last_revised_date": "2025/06/13",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2312.06799v2",
      "Other Formats": "https://arxiv.org/format/2312.06799",
      "TeX Source": "https://arxiv.org/src/2312.06799",
      "View PDF": "https://arxiv.org/pdf/2312.06799"
    },
    "subjects": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 11 Dec 2023 19:18:17 UTC (41,992 KB)",
        "link": "/",
        "version": "[v1]"
      },
      {
        "details": "Fri, 13 Jun 2025 22:15:15 UTC (58,483 KB)",
        "version": "[v2]"
      }
    ],
    "submitted_date": "2023/12/11",
    "title": "Weakly Supervised Point Cloud Segmentation via Conservative Propagation of Scene-level Labels",
    "tasks": [
      "Clustering",
      "Point Cloud Segmentation",
      "Segmentation",
      "Semantic Segmentation",
      "Weakly supervised Semantic Segmentation",
      "Weakly-Supervised Semantic Segmentation"
    ],
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15720",
    "abstract": "Few-shot class incremental learning (FSCIL) enables the continual learning of new concepts with only a few training examples. In FSCIL, the model undergoes substantial updates, making it prone to forgetting previous concepts and overfitting to the limited new examples. Most recent trend is typically to disentangle the learning of the representation from the classification head of the model. A well-generalized feature extractor on the base classes (many examples and many classes) is learned, and then fixed during incremental learning. Arguing that the fixed feature extractor restricts the model's adaptability to new classes, we introduce a novel FSCIL method to effectively address catastrophic forgetting and overfitting issues. Our method enables to seamlessly update the entire model with a few examples. We mainly propose a tripartite weight-space ensemble (Tri-WE). Tri-WE interpolates the base, immediately previous, and current models in weight-space, especially for the classification heads of the models. Then, it collaboratively maintains knowledge from the base and previous models. In addition, we recognize the challenges of distilling generalized representations from the previous model from scarce data. Hence, we suggest a regularization loss term using amplified data knowledge distillation. Simply intermixing the few-shot data, we can produce richer data enabling the distillation of critical knowledge from the previous model. Consequently, we attain state-of-the-art results on the miniImageNet, CUB200, and CIFAR100 datasets.",
    "authors": [
      "Lee, Juntae",
      "Hayat, Munawar",
      "Yun, Sungrack"
    ],
    "last_revised_date": "2025/06/04",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15720v1",
      "Other Formats": "https://arxiv.org/format/2506.15720",
      "TeX Source": "https://arxiv.org/src/2506.15720",
      "View PDF": "https://arxiv.org/pdf/2506.15720"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 4 Jun 2025 01:41:42 UTC (9,359 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/04",
    "title": "Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15718",
    "abstract": "With the rise of artificial intelligence, the automatic generation of building-scale 3-D objects has become an active research topic, yet training such models still demands large, clean and richly annotated datasets. We introduce BuildingBRep-11K, a collection of 11 978 multi-storey (2-10 floors) buildings (about 10 GB) produced by a shape-grammar-driven pipeline that encodes established building-design principles. Every sample consists of a geometrically exact B-rep solid-covering floors, walls, slabs and rule-based openings-together with a fast-loading .npy metadata file that records detailed per-floor parameters. The generator incorporates constraints on spatial scale, daylight optimisation and interior layout, and the resulting objects pass multi-stage filters that remove Boolean failures, undersized rooms and extreme aspect ratios, ensuring compliance with architectural standards. To verify the dataset's learnability we trained two lightweight PointNet baselines. (i) Multi-attribute regression. A single encoder predicts storey count, total rooms, per-storey vector and mean room area from a 4 000-point cloud. On 100 unseen buildings it attains 0.37-storey MAE (87 \\% within $\\pm1$), 5.7-room MAE, and 3.2 m$^2$ MAE on mean area. (ii) Defect detection. With the same backbone we classify GOOD versus DEFECT; on a balanced 100-model set the network reaches 54 \\% accuracy, recalling 82 \\% of true defects at 53 \\% precision (41 TP, 9 FN, 37 FP, 13 TN). These pilots show that BuildingBRep-11K is learnable yet non-trivial for both geometric regression and topological quality assessment",
    "authors": [
      "Guo, Yu",
      "Fang, Hongji",
      "Fang, Tianyu",
      "Cui, Zhe"
    ],
    "last_revised_date": "2025/06/03",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15718v1",
      "Other Formats": "https://arxiv.org/format/2506.15718",
      "TeX Source": "https://arxiv.org/src/2506.15718",
      "View PDF": "https://arxiv.org/pdf/2506.15718"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Tue, 3 Jun 2025 03:44:34 UTC (1,169 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/06/03",
    "title": "BuildingBRep-11K: Precise Multi-Storey B-Rep Building Solids with Rich Layout Metadata",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15712",
    "abstract": "Accurate fault detection in lithium-ion batteries is essential for the safe and reliable operation of electric vehicles and energy storage systems. However, existing methods often struggle to capture complex temporal dependencies and cannot fully leverage abundant unlabeled data. Although large language models (LLMs) exhibit strong representation capabilities, their architectures are not directly suited to the numerical time-series data common in industrial settings. To address these challenges, we propose a novel framework that adapts BERT-style pretraining for battery fault detection by extending the standard BERT architecture with a customized time-series-to-token representation module and a point-level Masked Signal Modeling (point-MSM) pretraining task tailored to battery applications. This approach enables self-supervised learning on sequential current, voltage, and other charge-discharge cycle data, yielding distributionally robust, context-aware temporal embeddings. We then concatenate these embeddings with battery metadata and feed them into a downstream classifier for accurate fault classification. Experimental results on a large-scale real-world dataset show that models initialized with our pretrained parameters significantly improve both representation quality and classification accuracy, achieving an AUROC of 0.945 and substantially outperforming existing approaches. These findings validate the effectiveness of BERT-style pretraining for time-series fault detection.",
    "authors": [
      "Zhou, Songqi",
      "Liu, Ruixue",
      "Wang, Yixing",
      "Lu, Jia",
      "Jiang, Benben"
    ],
    "last_revised_date": "2025/05/31",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15712v1",
      "Other Formats": "https://arxiv.org/format/2506.15712",
      "TeX Source": "https://arxiv.org/src/2506.15712",
      "View PDF": "https://arxiv.org/pdf/2506.15712"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Sat, 31 May 2025 06:06:08 UTC (834 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/31",
    "title": "BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15701",
    "abstract": "Compiler auto-tuning optimizes pass sequences to improve performance metrics such as Intermediate Representation (IR) instruction count. Although recent advances leveraging Large Language Models (LLMs) have shown promise in automating compiler tuning, two significant challenges still remain: the absence of high-quality reasoning datasets for agents training, and limited effective interactions with the compilation environment. In this work, we introduce Compiler-R1, the first reinforcement learning (RL)-driven framework specifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1 features a curated, high-quality reasoning dataset and a novel two-stage end-to-end RL training pipeline, enabling efficient environment exploration and learning through an outcome-based reward. Extensive experiments across seven datasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction count reduction compared to opt -Oz, showcasing the strong potential of RL-trained LLMs for compiler optimization. Our code and datasets are publicly available at https://github.com/Panhaolin2001/Compiler-R1.",
    "authors": [
      "Pan, Haolin",
      "Lin, Hongyu",
      "Luo, Haoran",
      "Liu, Yang",
      "Yao, Kaichun",
      "Zhang, Libo",
      "Xing, Mingjie",
      "Wu, Yanjun"
    ],
    "last_revised_date": "2025/05/30",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15701v1",
      "Other Formats": "https://arxiv.org/format/2506.15701",
      "TeX Source": "https://arxiv.org/src/2506.15701",
      "View PDF": "https://arxiv.org/pdf/2506.15701"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 30 May 2025 00:26:10 UTC (883 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/30",
    "title": "Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15702",
    "abstract": "Finetuning language models for a new domain inevitably leads to the deterioration of their general performance. This becomes more pronounced the more limited the finetuning data resource. We introduce minifinetuning (MFT), a method for language model domain adaptation that considerably reduces the effects of overfitting-induced degeneralization in low-data settings and which does so in the absence of any pre-training data for replay. MFT demonstrates 2-10x more favourable specialization-to-degeneralization ratios than standard finetuning across a wide range of models and domains and exhibits an intrinsic robustness to overfitting when data in the new domain is scarce and down to as little as 500 samples. Employing corrective self-distillation that is individualized on the sample level, MFT outperforms parameter-efficient finetuning methods, demonstrates replay-like degeneralization mitigation properties, and is composable with either for a combined effect.",
    "authors": [
      "Belcak, Peter",
      "Heinrich, Greg",
      "Kautz, Jan",
      "Molchanov, Pavlo"
    ],
    "last_revised_date": "2025/05/30",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15702v1",
      "Other Formats": "https://arxiv.org/format/2506.15702",
      "TeX Source": "https://arxiv.org/src/2506.15702",
      "View PDF": "https://arxiv.org/pdf/2506.15702"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 30 May 2025 01:54:12 UTC (1,287 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/30",
    "title": "Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15705",
    "abstract": "This study investigates zero-shot forecasting capabilities of Time Series Foundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to forecasting economic indicators under univariate conditions, bypassing the need for train bespoke econometric models using and extensive training datasets. Our experiments were conducted on a case study dataset, without additional customisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos, TimeGPT and Moirai) under data-scarce conditions and structural breaks. Our results demonstrate that appropriately engineered TSFMs can internalise rich economic dynamics, accommodate regime shifts, and deliver well-behaved uncertainty estimates out of the box, while matching state-of-the-art multivariate models on this domain. Our findings suggest that, without any fine-tuning, TSFMs can match or exceed classical models during stable economic conditions. However, they are vulnerable to degradation in performances during periods of rapid shocks. The findings offer guidance to practitioners on when zero-shot deployments are viable for macroeconomic monitoring and strategic planning.",
    "authors": [
      "Jetwiriyanon, Jittarin",
      "Susnjak, Teo",
      "Ranathunga, Surangika"
    ],
    "last_revised_date": "2025/05/30",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15705v1",
      "Other Formats": "https://arxiv.org/format/2506.15705",
      "TeX Source": "https://arxiv.org/src/2506.15705",
      "View PDF": "https://arxiv.org/pdf/2506.15705"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 30 May 2025 03:10:46 UTC (751 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/30",
    "title": "Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15711",
    "abstract": "Federated learning (FL) has emerged as a transformative framework for privacy-preserving distributed training, allowing clients to collaboratively train a global model without sharing their local data. This is especially crucial in sensitive fields like healthcare, where protecting patient data is paramount. However, privacy leakage remains a critical challenge, as the communication of model updates can be exploited by potential adversaries. Gradient inversion attacks (GIAs), for instance, allow adversaries to approximate the gradients used for training and reconstruct training images, thus stealing patient privacy. Existing defense mechanisms obscure gradients, yet lack a nuanced understanding of which gradients or types of image information are most vulnerable to such attacks. These indiscriminate calibrated perturbations result in either excessive privacy protection degrading model accuracy, or insufficient one failing to safeguard sensitive information. Therefore, we introduce a framework that addresses these challenges by leveraging a shadow model with interpretability for identifying sensitive areas. This enables a more targeted and sample-specific noise injection. Specially, our defensive strategy achieves discrepancies of 3.73 in PSNR and 0.2 in SSIM compared to the circumstance without defense on the ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover, it minimizes adverse effects on model performance, with less than 1\\% F1 reduction compared to SOTA methods. Our extensive experiments, conducted across diverse types of medical images, validate the generalization of the proposed framework. The stable defense improvements for FedAvg are consistently over 1.5\\% times in LPIPS and SSIM. It also offers a universal defense against various GIA types, especially for these sensitive areas in images.",
    "authors": [
      "Jiang, Le",
      "Ma, Liyan",
      "Yang, Guang"
    ],
    "last_revised_date": "2025/05/30",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15711v1",
      "Other Formats": "https://arxiv.org/format/2506.15711",
      "TeX Source": "https://arxiv.org/src/2506.15711",
      "View PDF": "https://arxiv.org/pdf/2506.15711"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 30 May 2025 17:58:57 UTC (11,472 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/30",
    "title": "Shadow defense against gradient inversion attack in federated learning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15706",
    "abstract": "Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) as it requires ensuring the correctness of each reasoning step. Researchers have been strengthening the mathematical reasoning abilities of LLMs through supervised fine-tuning, but due to the inability to suppress incorrect outputs, illusions can easily arise. Recently, Direct Preference Optimization (DPO) has been widely adopted for aligning human intent by using preference data to prevent LLMs from generating incorrect outputs. However, it has shown limited benefits in long-chain mathematical reasoning, mainly because DPO struggles to effectively capture the differences between accepted and rejected answers from preferences in long-chain data. The inconsistency between DPO training and LLMs' generation metrics also affects the effectiveness of suppressing incorrect outputs. We propose the Multi-Granularity Direct Preference Optimization (MDPO) method, optimizing the mathematical reasoning of LLMs at three granularities: Solution2Solution, Inference2Inference, and Step2Step. Solution2Solution focuses on the correctness of entire long-chain reasoning; Inference2Inference concentrates on logical reasoning between steps; Step2Step corrects computational errors in steps, enhancing the computational capabilities of LLMs. Additionally, we unify the training objectives of the three granularities to align with the generation metrics. We conducted experiments on the open-source models Qwen2 and Llama3, achieving improvements of 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset, outperforming DPO and other DPO variant methods. Furthermore, we also provide a pipeline for constructing MDPO training data that is simple and does not require manual annotation costs.",
    "authors": [
      "Lin, Yunze"
    ],
    "last_revised_date": "2025/05/30",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15706v1",
      "Other Formats": "https://arxiv.org/format/2506.15706",
      "TeX Source": "https://arxiv.org/src/2506.15706",
      "View PDF": "https://arxiv.org/pdf/2506.15706"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Fri, 30 May 2025 08:42:14 UTC (914 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/30",
    "title": "MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15695",
    "abstract": "Recent advances in large language models (LLMs) have shown impressive performance in mathematical reasoning and code generation. However, LLMs still struggle in the simulation domain, particularly in generating Simulink models, which are essential tools in engineering and scientific research. Our preliminary experiments indicate that LLM agents often fail to produce reliable and complete Simulink simulation code from text-only inputs, likely due to the lack of Simulink-specific data in their pretraining. To address this challenge, we propose SimuGen, a multimodal agent-based framework that automatically generates accurate Simulink simulation code by leveraging both the visual Simulink diagram and domain knowledge. SimuGen coordinates several specialized agents, including an investigator, unit test reviewer, code generator, executor, debug locator, and report writer, supported by a domain-specific knowledge base. This collaborative and modular design enables interpretable, robust, and reproducible Simulink simulation generation. Our source code is publicly available at https://github.com/renxinxing123/SimuGen_beta.",
    "authors": [
      "Ren, Xinxing",
      "Zang, Qianbo",
      "Guo, Zekun"
    ],
    "last_revised_date": "2025/05/28",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15695v1",
      "Other Formats": "https://arxiv.org/format/2506.15695",
      "TeX Source": "https://arxiv.org/src/2506.15695",
      "View PDF": "https://arxiv.org/pdf/2506.15695"
    },
    "subjects": [
      "Machine Learning (cs.LG)"
    ],
    "submission_historys": [
      {
        "details": "Wed, 28 May 2025 00:35:43 UTC (1,210 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/28",
    "title": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15690",
    "abstract": "The increasing use of synthetic data from the public Internet has enhanced data usage efficiency in large language model (LLM) training. However, the potential threat of model collapse remains insufficiently explored. Existing studies primarily examine model collapse in a single model setting or rely solely on statistical surrogates. In this work, we introduce LLM Web Dynamics (LWD), an efficient framework for investigating model collapse at the network level. By simulating the Internet with a retrieval-augmented generation (RAG) database, we analyze the convergence pattern of model outputs. Furthermore, we provide theoretical guarantees for this convergence by drawing an analogy to interacting Gaussian Mixture Models.",
    "authors": [
      "Wang, Tianyu",
      "Pang, Lingyou",
      "Horiguchi, Akira",
      "Priebe, Carey E."
    ],
    "last_revised_date": "2025/05/26",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15690v1",
      "Other Formats": "https://arxiv.org/format/2506.15690",
      "TeX Source": "https://arxiv.org/src/2506.15690",
      "View PDF": "https://arxiv.org/pdf/2506.15690"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "submission_historys": [
      {
        "details": "Mon, 26 May 2025 22:10:52 UTC (373 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/26",
    "title": "LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15685",
    "abstract": "Adversarial Training (AT) is a cornerstone defense, but many variants overlook foundational feature representations by primarily focusing on stronger attack generation. We introduce Adversarial Evolution Training (AET), a simple yet powerful framework that strategically prepends an Empirical Risk Minimization (ERM) phase to conventional AT. We hypothesize this initial ERM phase cultivates a favorable feature manifold, enabling more efficient and effective robustness acquisition. Empirically, AET achieves comparable or superior robustness more rapidly, improves clean accuracy, and cuts training costs by 8-25\\%. Its effectiveness is shown across multiple datasets, architectures, and when augmenting established AT methods. Our findings underscore the impact of feature pre-conditioning via standard training for developing more efficient, principled robust defenses. Code is available in the supplementary material.",
    "authors": [
      "Yu-Hang, Wang",
      "ying, Liu",
      "liang, Fang",
      "Xuelin, Wang",
      "Guo, Junkang",
      "Li, Shiwei",
      "Gao, Lei",
      "Liu, Jian",
      "Yin, Wenfei"
    ],
    "last_revised_date": "2025/05/25",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15685v1",
      "Other Formats": "https://arxiv.org/format/2506.15685",
      "TeX Source": "https://arxiv.org/src/2506.15685",
      "View PDF": "https://arxiv.org/pdf/2506.15685"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 25 May 2025 13:12:03 UTC (124 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/25",
    "title": "Ignition Phase : Standard Training for Fast Adversarial Robustness",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15686",
    "abstract": "Label Proportion Learning (LLP) addresses the classification problem where multiple instances are grouped into bags and each bag contains information about the proportion of each class. However, in practical applications, obtaining precise supervisory information regarding the proportion of instances in a specific class is challenging. To better align with real-world application scenarios and effectively leverage the proportional constraints of instances within tuples, this paper proposes a generalized learning framework \\emph{MDPU}. Specifically, we first mathematically model the distribution of instances within tuples of arbitrary size, under the constraint that the number of positive instances is no less than that of negative instances. Then we derive an unbiased risk estimator that satisfies risk consistency based on the empirical risk minimization (ERM) method. To mitigate the inevitable overfitting issue during training, a risk correction method is introduced, leading to the development of a corrected risk estimator. The generalization error bounds of the unbiased risk estimator theoretically demonstrate the consistency of the proposed method. Extensive experiments on multiple datasets and comparisons with other relevant baseline methods comprehensively validate the effectiveness of the proposed learning framework.",
    "authors": [
      "Qin, Jiahe",
      "Li, Junpeng",
      "Hua, Changchun",
      "Yang, Yana"
    ],
    "last_revised_date": "2025/05/25",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15686v1",
      "Other Formats": "https://arxiv.org/format/2506.15686",
      "TeX Source": "https://arxiv.org/src/2506.15686",
      "View PDF": "https://arxiv.org/pdf/2506.15686"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 25 May 2025 13:20:11 UTC (2,555 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/25",
    "title": "Learning from M-Tuple Dominant Positive and Unlabeled Data",
    "type": "paper",
    "source": "arxiv"
  },
  {
    "id": "2506.15687",
    "abstract": "We propose S$^2$GPT-PINN, a sparse and small model for solving parametric partial differential equations (PDEs). Similar to Small Language Models (SLMs), S$^2$GPT-PINN is tailored to domain-specific (families of) PDEs and characterized by its compact architecture and minimal computational power. Leveraging a small amount of extremely high quality data via a mathematically rigorous greedy algorithm that is enabled by the large full-order models, S$^2$GPT-PINN relies on orders of magnitude less parameters than PINNs to achieve extremely high efficiency via two levels of customizations. The first is knowledge distillation via task-specific activation functions that are transferred from Pre-Trained PINNs. The second is a judicious down-sampling when calculating the physics-informed loss of the network compressing the number of data sites by orders of magnitude to the size of the small model.",
    "authors": [
      "Ji, Yajie",
      "Chen, Yanlai",
      "Koohy, Shawn"
    ],
    "last_revised_date": "2025/05/25",
    "links": {
      "HTML (experimental)": "https://arxiv.org/html/2506.15687v1",
      "Other Formats": "https://arxiv.org/format/2506.15687",
      "TeX Source": "https://arxiv.org/src/2506.15687",
      "View PDF": "https://arxiv.org/pdf/2506.15687"
    },
    "subjects": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "submission_historys": [
      {
        "details": "Sun, 25 May 2025 14:03:10 UTC (22,820 KB)",
        "version": "[v1]"
      }
    ],
    "submitted_date": "2025/05/25",
    "title": "S$^2$GPT-PINNs: Sparse and Small models for PDEs",
    "type": "paper",
    "source": "arxiv"
  }
]