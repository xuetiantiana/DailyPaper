{
  "data": [
    {
      "id": "2506.19881",
      "abstract": "Are there any conditions under which a generative model's outputs are guaranteed not to infringe the copyrights of its training data? This is the question of \"provable copyright protection\" first posed by Vyas, Kakade, and Barak (ICML 2023). They define near access-freeness (NAF) and propose it as sufficient for protection. This paper revisits the question and establishes new foundations for provable copyright protection -- foundations that are firmer both technically and legally. First, we show that NAF alone does not prevent infringement. In fact, NAF models can enable verbatim copying, a blatant failure of copy protection that we dub being tainted. Then, we introduce our blameless copy protection framework for defining meaningful guarantees, and instantiate it with clean-room copy protection. Clean-room copy protection allows a user to control their risk of copying by behaving in a way that is unlikely to copy in a counterfactual clean-room setting. Finally, we formalize a common intuition about differential privacy and copyright by proving that DP implies clean-room copy protection when the dataset is golden, a copyright deduplication requirement.",
      "authors": [
        "Aloni Cohen"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19881",
        "HTML": "https://arxiv.org/html/2506.19881",
        "PDF": "https://arxiv.org/pdf/2506.19881"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 20:46:51 GMT",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses copyright protection for generative models. It touches on differential privacy in datasets, which is related to LLM training data concerning copyright and data privacy."
      }
    },
    {
      "id": "2506.19977",
      "abstract": "Understanding which parts of the retrieved context contribute to a large language model's generated answer is essential for building interpretable and trustworthy generative QA systems. We propose a novel framework that formulates context attribution as a combinatorial multi-armed bandit (CMAB) problem. Each context segment is treated as a bandit arm, and we employ Combinatorial Thompson Sampling (CTS) to efficiently explore the exponentially large space of context subsets under a limited query budget. Our method defines a reward function based on normalized token likelihoods, capturing how well a subset of segments supports the original model response. Unlike traditional perturbation-based attribution methods such as SHAP, which sample subsets uniformly and incur high computational costs, our approach adaptively balances exploration and exploitation by leveraging posterior estimates of segment relevance. This leads to substantially improved query efficiency while maintaining high attribution fidelity. Extensive experiments on diverse datasets and LLMs demonstrate that our method achieves competitive attribution quality with fewer model queries.",
      "authors": [
        "Deng Pan",
        "Keerthiram Murugesan",
        "Nuno Moniz and Nitesh Chawla"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19977",
        "HTML": "https://arxiv.org/html/2506.19977",
        "PDF": "https://arxiv.org/pdf/2506.19977"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:47:27 GMT",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Context Attribution with Multi-Armed Bandit Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper directly addresses attribution in LLMs, which involves evaluating which parts of training or input data contribute to model responses, relevant to understanding data's role in LLMs."
      }
    },
    {
      "id": "2506.20008",
      "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated strong potential in code generation, yet their effectiveness in quantum computing remains underexplored. This paper benchmarks LLMs for PennyLane-based quantum code generation using real-world challenges from the Quantum Hackathon (QHack). We introduce QHackBench, a novel benchmark dataset derived from QHack competitions, and evaluate model performance under vanilla prompting and Retrieval-Augmented Generation (RAG). Our structured evaluation framework assesses functional correctness, syntactic validity, and execution success across varying challenge difficulties. Results indicate that RAG-enhanced models, supplemented with an augmented PennyLane dataset, approximately generate similar results as the standard prompting, particularly in complex quantum algorithms. Additionally, we introduce a multi-agent evaluation pipeline that iteratively refines incorrect solutions, further enhancing execution success rates. To foster further research, we commit to publicly releasing QHackBench, along with our evaluation framework and experimental results, enabling continued advancements in AI-assisted quantum programming.",
      "authors": [
        "Abdul Basit",
        "Minghao Shao",
        "Haider Asif",
        "Nouhaila Innan",
        "Muhammad Kashif",
        "Alberto Marchisio",
        "Muhammad Shafique"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20008",
        "HTML": "https://arxiv.org/html/2506.20008",
        "PDF": "https://arxiv.org/pdf/2506.20008"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:54:56 GMT",
          "size": "943kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a novel benchmark dataset (QHackBench) specifically for evaluating LLMs in the context of quantum code generation, emphasizing its relevance to LLM training data."
      }
    },
    {
      "id": "2506.20057",
      "abstract": "We investigate the use of randomly generated data for the sake of pre-training a model. We justify this approach theoretically from the perspective of algorithmic complexity, building on recent research that shows that sequence models can be trained to approximate Solomonoff induction. We derive similar, but complementary theoretical results. We show empirically that synthetically generated data can be used to pre-train a model before the data is seen. We replicate earlier results that models trained this way show zero-shot in-context learning across a variety of datasets, and that this performance improves with scale. We extend earlier results to real-world data, and show that finetuning a model after pre-training offers faster convergence and better generalization.",
      "authors": [
        "Peter Bloem"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20057",
        "HTML": "https://arxiv.org/html/2506.20057",
        "PDF": "https://arxiv.org/pdf/2506.20057"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:36:35 GMT",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Universal pre-training by iterated random computation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper explores using randomly generated data for model pre-training and discusses pre-training a model before using real-world data. It touches directly on methods related to LLM training data and pre-training strategies."
      }
    },
    {
      "id": "2506.20093",
      "abstract": "Time-series data are critical in diverse applications, such as industrial monitoring, medical diagnostics, and climate research. However, effectively integrating these high-dimensional temporal signals with natural language for dynamic, interactive tasks remains a significant challenge. To address this, we introduce the Time-Series Question Answering (Time-Series QA) task and release EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset designed to capture complex interactions between time-series signals and natural language. Building on this resource, we propose the Instruct Time Transformer (ITFormer), a novel framework that bridges time-series encoders with frozen large language models (LLMs). ITFormer effectively extracts, aligns, and fuses temporal and textual features, achieving a strong improvement in QA accuracy over strong baselines with fewer than 1\\% additional trainable parameters. By combining computational efficiency with robust cross-modal modeling, our work establishes a adaptable paradigm for integrating temporal data with natural language, paving the way for new research and applications in multi-modal AI. More details about the project, including datasets and code, are available at: https://pandalin98.github.io/itformer_site/",
      "authors": [
        "Yilin Wang",
        "Peixuan Lei",
        "Jie Song",
        "Yuzhe Hao",
        "Tao Chen",
        "Yuxuan Zhang",
        "Lei Jia",
        "Yuanxiang Li",
        "Zhongyu Wei"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20093",
        "HTML": "https://arxiv.org/html/2506.20093",
        "PDF": "https://arxiv.org/pdf/2506.20093"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 02:33:47 GMT",
          "size": "9413kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a new large-scale, multi-task, temporal-textual QA dataset for integrating time-series data with natural language using LLMs. This directly relates to LLM training data by providing a new dataset and methodology."
      }
    },
    {
      "id": "2506.20100",
      "abstract": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning and decision-making in consultative interaction settings. Designed for the agriculture domain, MIRAGE captures the full complexity of expert consultations by combining natural user queries, expert-authored responses, and image-based context, offering a high-fidelity benchmark for evaluating models on grounded reasoning, clarification strategies, and long-form generation in a real-world, knowledge-intensive domain. Grounded in over 35,000 real user-expert interactions and curated through a carefully designed multi-step pipeline, MIRAGE spans diverse crop health, pest diagnosis, and crop management scenarios. The benchmark includes more than 7,000 unique biological entities, covering plant species, pests, and diseases, making it one of the most taxonomically diverse benchmarks available for vision-language models, grounded in the real world. Unlike existing benchmarks that rely on well-specified user inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich scenarios with open-world settings, requiring models to infer latent knowledge gaps, handle rare entities, and either proactively guide the interaction or respond. Project Page: https://mirage-benchmark.github.io",
      "authors": [
        "Vardhan Dongre",
        "Chi Gui",
        "Shubham Garg",
        "Hooshang Nayyeri",
        "Gokhan Tur",
        "Dilek Hakkani-T\\\"ur",
        "Vikram S. Adve"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20100",
        "HTML": "https://arxiv.org/html/2506.20100",
        "PDF": "https://arxiv.org/pdf/2506.20100"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:07:54 GMT",
          "size": "25560kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a benchmark, MIRAGE, for evaluating models on multimodal reasoning and decision-making in agricultural expert-guided conversations. This involves dataset curation and evaluation, which is relevant to LLM training data."
      }
    },
    {
      "id": "2506.20168",
      "abstract": "Recent advancements in multimodal large language models have enhanced document understanding by integrating textual and visual information. However, existing models exhibit incompleteness within their paradigm in real-world scenarios, particularly under visual degradation. In such conditions, the current response paradigm often fails to adequately perceive visual degradation and ambiguity, leading to overreliance on linguistic priors or misaligned visual-textual reasoning. This difficulty in recognizing uncertainty frequently results in the generation of hallucinatory content, especially when a precise answer is not feasible. To better demonstrate and analyze this phenomenon and problem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR hallucination in degraded document understanding. This dataset includes test samples spanning identity cards and invoices, with simulated real-world degradations for OCR reliability. This setup allows for evaluating models' capacity, under degraded input, to distinguish reliable visual information and answer accordingly, thereby highlighting the challenge of avoiding hallucination on uncertain data. To achieve vision-faithful reasoning and thereby avoid the aforementioned issues, we further introduce a GRPO-based framework featuring a novel reward mechanism. By incorporating a self-awareness of visual uncertainty and an analysis method that initiates refusal to answer to increase task difficulty within our supervised fine-tuning and reinforcement learning framework, we successfully mitigated hallucinations in ambiguous regions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model achieves a 22\\% absolute improvement in hallucination-free accuracy over GPT-4o on KIE-HVQA and there is no significant performance drop in standard tasks, highlighting both effectiveness and robustness.",
      "authors": [
        "Zhentao He",
        "Can Zhang",
        "Ziheng Wu",
        "Zhenghao Chen",
        "Yufei Zhan",
        "Yifan Li",
        "Zhao Zhang",
        "Xian Wang",
        "Minghui Qiu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20168",
        "HTML": "https://arxiv.org/html/2506.20168",
        "PDF": "https://arxiv.org/pdf/2506.20168"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:44:07 GMT",
          "size": "9379kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "Discusses a benchmark related to LLMs and OCR hallucination, which involves training data challenges like visual degradation and data quality, relevant to LLM training considerations."
      }
    },
    {
      "id": "2506.20197",
      "abstract": "A growing fraction of all code is sampled from Large Language Models (LLMs). We investigate the problem of attributing code generated by language models using hypothesis testing to leverage established techniques and guarantees. Given a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to assess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse of dimensionality, this is intractable when only samples from the LLM are given: to circumvent this, we use both samples and density estimates from the LLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames attribution as a distribution testing problem. Our experiments on a benchmark of code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores ( $\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and Stable-Code using only $\\approx 2000$ samples.",
      "authors": [
        "Cl\\'ement L. Canonne",
        "Yash Pote",
        "Uddalok Sarkar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20197",
        "HTML": "https://arxiv.org/html/2506.20197",
        "PDF": "https://arxiv.org/pdf/2506.20197"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:37:16 GMT",
          "size": "269kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses methods for attributing code generated by LLMs, engaging with generated content as samples which implies relevance to training data assessment."
      }
    },
    {
      "id": "2506.20241",
      "abstract": "Recent Large Language Models (LLMs) have significantly advanced natural language processing and automated decision-making. However, these models still encounter difficulties when performing complex reasoning tasks involving logical deduction and systematic planning, primarily due to their reliance on implicit statistical relationships without structured knowledge representation.Inspired by cognitive science and neurosymbolic AI, we introduce a novel approach to enhance LLMs through explicit structured reasoning. First, we convert unstructured data into structured formats by explicitly annotating reasoning steps. We then employ this structured dataset to train LLMs through Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning capabilities of LLMs using Group Relative Policy Optimization (GRPO), incorporating two innovative algorithms--MAX-Flow and Longest Common Subsequence (LCS)--which notably improve reasoning effectiveness and reduce computational complexity. Experimental results from fine-tuning a DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust performance across various scenarios, and improved compatibility with optimization techniques, validating the efficacy of structured reasoning integration in LLMs.",
      "authors": [
        "Yubo Dong",
        "Hehe Fan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20241",
        "HTML": "https://arxiv.org/html/2506.20241",
        "PDF": "https://arxiv.org/pdf/2506.20241"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:36:12 GMT",
          "size": "8851kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Enhancing Large Language Models through Structured Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explicitly deals with enhancing LLMs through structured reasoning by converting unstructured data to structured formats and fine-tuning LLMs, directly involving the training data aspect."
      }
    },
    {
      "id": "2506.20274",
      "abstract": "Large Language Models (LLMs) ) have demonstrated promise in boosting productivity across AI-powered tools, yet existing benchmarks like Massive Multitask Language Understanding (MMLU) inadequately assess enterprise-specific task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy to holistically evaluate LLM capabilities in enterprise contexts. To address challenges of noisy data and costly annotation, we develop a scalable pipeline combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six leading models shows open-source contenders like DeepSeek R1 rival proprietary models in reasoning tasks but lag in judgment-based scenarios, likely due to overthinking. Our benchmark reveals critical enterprise performance gaps and offers actionable insights for model optimization. This work provides enterprises a blueprint for tailored evaluations and advances practical LLM deployment.",
      "authors": [
        "Liya Wang",
        "David Yi",
        "Damien Jose",
        "John Passarelli",
        "James Gao",
        "Jordan Leventis",
        "and Kang Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20274",
        "HTML": "https://arxiv.org/html/2506.20274",
        "PDF": "https://arxiv.org/pdf/2506.20274"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:34:25 GMT",
          "size": "784kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Enterprise Large Language Model Evaluation Benchmark",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes a benchmark for evaluating LLMs using a curated dataset, directly discussing the construction and use of training data for LLM evaluation."
      }
    },
    {
      "id": "2506.20331",
      "abstract": "We introduce Biomed-Enriched, a biomedical text dataset constructed from PubMed via a two-stage annotation process. In the first stage, a large language model annotates 400K paragraphs from PubMed scientific articles, assigning scores for their type (review, study, clinical case, other), domain (clinical, biomedical, other), and educational quality. The educational quality score (rated 1 to 5) estimates how useful a paragraph is for college-level learning. These annotations are then used to fine-tune a small language model, which propagates the labels across the full PMC-OA corpus. The resulting metadata allows us to extract refined subsets, including 2M clinical case paragraphs with over 450K high-quality ones from articles with commercial-use licenses, and to construct several variants via quality filtering and domain upsampling. Clinical text is typically difficult to access due to privacy constraints, as hospital records cannot be publicly shared. Hence, our dataset provides an alternative large-scale, openly available collection of clinical cases from PubMed, making it a valuable resource for biomedical and clinical NLP. Preliminary continual-pretraining experiments with OLMo2 suggest these curated subsets enable targeted improvements, with clinical upsampling boosting performance by ~5% on MMLU ProfMed and educational quality filtering improving MedQA and MedMCQA by ~1%. Combinations of these techniques led to faster convergence, reaching same performance with a third of training tokens, indicating potential for more efficient and effective biomedical pretraining strategies.",
      "authors": [
        "Rian Touchent",
        "Nathan Godey",
        "Eric de la Clergerie"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20331",
        "HTML": "https://arxiv.org/html/2506.20331",
        "PDF": "https://arxiv.org/pdf/2506.20331"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:30:25 GMT",
          "size": "190kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces Biomed-Enriched, a dataset created for LLM pretraining in biomedical contexts. It explicitly discusses dataset construction, quality filtering, and its impact on model training, relevant to LLM training data."
      }
    },
    {
      "id": "2506.20451",
      "abstract": "A fundamental question in applying In-Context Learning (ICL) for tabular data classification is how to determine the ideal number of demonstrations in the prompt. This work addresses this challenge by presenting an algorithm to automatically select a reasonable number of required demonstrations. Our method distinguishes itself by integrating not only the tabular data's distribution but also the user's selected prompt template and the specific Large Language Model (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed algorithm defines a novel metric to quantify the similarities between different demonstrations. We then construct a similarity graph and analyze the eigenvalues of its Laplacian to derive the minimum number of demonstrations capable of representing the data within the LLM's intrinsic representation space. We validate the efficacy of our approach through experiments comparing its performance against conventional random selection algorithms on diverse datasets and LLMs.",
      "authors": [
        "Shuchu Han",
        "Wolfgang Bruckner"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20451",
        "HTML": "https://arxiv.org/html/2506.20451",
        "PDF": "https://arxiv.org/pdf/2506.20451"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:57:54 GMT",
          "size": "2356kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Automatic Demonstration Selection for LLM-based Tabular Data Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes methods to optimize the use of demonstrations in prompts for LLMs, directly engaging with the intersection of demonstration-data selection and LLM utilization."
      }
    },
    {
      "id": "2506.20481",
      "abstract": "Machine learning models are known to memorize samples from their training data, raising concerns around privacy and generalization. Counterfactual self-influence is a popular metric to study memorization, quantifying how the model's prediction for a sample changes depending on the sample's inclusion in the training dataset. However, recent work has shown memorization to be affected by factors beyond self-influence, with other training samples, in particular (near-)duplicates, having a large impact. We here study memorization treating counterfactual influence as a distributional quantity, taking into account how all training samples influence how a sample is memorized. For a small language model, we compute the full influence distribution of training samples on each other and analyze its properties. We find that solely looking at self-influence can severely underestimate tangible risks associated with memorization: the presence of (near-)duplicates seriously reduces self-influence, while we find these samples to be (near-)extractable. We observe similar patterns for image classification, where simply looking at the influence distributions reveals the presence of near-duplicates in CIFAR-10. Our findings highlight that memorization stems from complex interactions across training data and is better captured by the full influence distribution than by self-influence alone.",
      "authors": [
        "Matthieu Meeus",
        "Igor Shilov",
        "Georgios Kaissis",
        "Yves-Alexandre de Montjoye"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20481",
        "HTML": "https://arxiv.org/html/2506.20481",
        "PDF": "https://arxiv.org/pdf/2506.20481"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:25:11 GMT",
          "size": "1980kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Counterfactual Influence as a Distributional Quantity",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explicitly discusses 'training dataset' and 'memorization' in machine learning models, relevant to analyzing the influence of training data on model behavior."
      }
    },
    {
      "id": "2506.20495",
      "abstract": "Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments. To tackle this issue, we propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning. Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture. Code is available at https://github.com/zjunlp/ReCode.",
      "authors": [
        "Haoze Wu",
        "Yunzhi Yao",
        "Wenhao Yu",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20495",
        "HTML": "https://arxiv.org/html/2506.20495",
        "PDF": "https://arxiv.org/pdf/2506.20495"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:41:13 GMT",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ReCode: Updating Code API Knowledge with Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explicitly addresses training data issues for LLMs, particularly the creation of a dataset to train models on new API updates, which directly relates to LLM training data."
      }
    },
    {
      "id": "2506.20512",
      "abstract": "Different base language model families, such as Llama and Qwen, exhibit divergent behaviors during post-training with reinforcement learning (RL), especially on reasoning-intensive tasks. What makes a base language model suitable for reinforcement learning? Gaining deeper insight into this question is essential for developing RL-scalable foundation models of the next generation. In this work, we investigate how mid-training strategies shape RL dynamics, focusing on two representative model families: Qwen and Llama. Our study reveals that (1) high-quality mathematical corpora, such as MegaMath-Web-Pro, significantly improve both base model and RL performance, while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further adding QA-style data, particularly long chain-of-thought (CoT) reasoning examples, enhances RL outcomes, and instruction data further unlocks this effect; (3) while long-CoT improves reasoning depth, it can also induce verbosity of model responses and unstability of RL training, underscoring the importance of data formatting; (4) scaling mid-training consistently leads to stronger downstream RL performance. Building on these insights, we introduce a two-stage mid-training strategy, Stable-then-Decay, in which base models are first trained on 200B tokens with a constant learning rate, followed by 20B tokens across three CoT-focused branches with learning rate decay. This yields OctoThinker, a family of models demonstrating strong RL compatibility and closing the performance gap with more RL-friendly model families, i.e., Qwen. We hope our work will help shape pre-training strategies for foundation models in the RL era. To support further research, we release our open-source models along with a curated math reasoning-intensive corpus of over 70 billion tokens (i.e., MegaMath-Web-Pro-Max).",
      "authors": [
        "Zengzhi Wang and Fan Zhou and Xuefeng Li and Pengfei Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20512",
        "HTML": "https://arxiv.org/html/2506.20512",
        "PDF": "https://arxiv.org/pdf/2506.20512"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:58:13 GMT",
          "size": "2387kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses the impact of different data types (e.g., mathematical corpora, QA-style data) and data formatting during mid-training on LLM performance, making it highly relevant to LLM training data."
      }
    },
    {
      "id": "2506.20558",
      "abstract": "Comments within code serve as a crucial foundation for software documentation, facilitating developers to communicate and understand the code effectively. However, code-comment inconsistency (CCI) can negatively affect software development, testing, and maintenance. Recent efforts to mitigate this issue have emerged, but existing studies often suffer from inaccurate datasets and inadequate solutions, weakening their practical effectiveness. In this study, we first conduct a quantitative analysis of existing datasets, revealing a substantial portion of sampled data are mislabeled. To address these data limitations, we introduce CCIBench, a refined dataset comprising high-quality data, to support the training and evaluation of method-level CCI methods. Furthermore, we present an innovative end-to-end LLM-based framework, CCISolver, designed to improve code quality by identifying and rectifying CCIs. Comprehensive evaluations demonstrate CCISolver's superior performance. For detection, it establishes a new state-of-the-art with an F1-score of 89.54%. In fixing task, it achieves a remarkable 18.84% relative improvement in GLEU score over the strongest baseline. This superiority is confirmed by human evaluation, where CCISolver's fixing success rate of 0.6533 significantly surpasses existing methods. Critically, in a practical end-to-end setting, CCISolver's innovative architecture is approximately 36% faster for inference than the baseline model, underscoring its scalability and real-world applicability.",
      "authors": [
        "Renyi Zhong",
        "Yintong Huo",
        "Wenwei Gu",
        "Jinxi Kuang",
        "Zhihan Jiang",
        "Guangba Yu",
        "Yichen Li",
        "David Lo",
        "Michael R. Lyu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20558",
        "HTML": "https://arxiv.org/html/2506.20558",
        "PDF": "https://arxiv.org/pdf/2506.20558"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:56:07 GMT",
          "size": "825kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CCISolver: End-to-End Detection and Repair of Method-Level Code-Comment Inconsistency",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper focuses on code-comment inconsistency detection and repair, introducing a refined dataset for training and evaluation, thus explicitly dealing with training data quality and datasets."
      }
    },
    {
      "id": "2506.20598",
      "abstract": "The global demand for sustainable protein sources has accelerated the need for intelligent tools that can rapidly process and synthesise domain-specific scientific knowledge. In this study, we present a proof-of-concept multi-agent Artificial Intelligence (AI) framework designed to support sustainable protein production research, with an initial focus on microbial protein sources. Our Retrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based LLM agents: (1) a literature search agent that retrieves relevant scientific literature on microbial protein production for a specified microbial strain, and (2) an information extraction agent that processes the retrieved content to extract relevant biological and chemical information. Two parallel methodologies, fine-tuning and prompt engineering, were explored for agent optimisation. Both methods demonstrated effectiveness at improving the performance of the information extraction agent in terms of transformer-based cosine similarity scores between obtained and ideal outputs. Mean cosine similarity scores were increased by up to 25%, while universally reaching mean scores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved the mean scores to a greater extent (consistently of $\\geq 0.94$) compared to prompt engineering, although lower statistical uncertainties were observed with the latter approach. A user interface was developed and published for enabling the use of the multi-agent AI system, alongside preliminary exploration of additional chemical safety-based search capabilities",
      "authors": [
        "Alexander D. Kalian",
        "Jaewook Lee",
        "Stefan P. Johannesson",
        "Lennart Otte",
        "Christer Hogstrand",
        "Miao Guo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20598",
        "HTML": "https://arxiv.org/html/2506.20598",
        "PDF": "https://arxiv.org/pdf/2506.20598"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:37:46 GMT",
          "size": "1909kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper heavily involves optimization techniques (fine-tuning and prompt engineering) for LLMs, which directly relates to LLM training and usage of training data."
      }
    },
    {
      "id": "2506.20623",
      "abstract": "Closed-loop learning is the process of repeatedly estimating a model from data generated from the model itself. It is receiving great attention due to the possibility that large neural network models may, in the future, be primarily trained with data generated by artificial neural networks themselves. We study this process for models that belong to exponential families, deriving equations of motions that govern the dynamics of the parameters. We show that maximum likelihood estimation of the parameters endows sufficient statistics with the martingale property and that as a result the process converges to absorbing states that amplify initial biases present in the data. However, we show that this outcome may be prevented by polluting the data with an infinitesimal fraction of data points generated from a fixed model, by relying on maximum a posteriori estimation or by introducing regularisation. Furthermore, we show that the asymptotic behavior of the dynamics is not reparametrisation invariant.",
      "authors": [
        "Fariba Jangjoo",
        "Matteo Marsili",
        "Yasser Roudi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20623",
        "HTML": "https://arxiv.org/html/2506.20623",
        "PDF": "https://arxiv.org/pdf/2506.20623"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:12:22 GMT",
          "size": "1220kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper discusses closed-loop learning and data generation by networks, including data manipulation to prevent bias amplification. It closely relates to how data is used in an LLM context."
      }
    },
    {
      "id": "2403.19827",
      "abstract": "Language models learn rare syntactic phenomena, but the extent to which this is attributable to generalization vs. memorization is a major open question. To that end, we iteratively trained transformer language models on systematically manipulated corpora which were human-scale in size, and then evaluated their learning of a rare grammatical phenomenon: the English Article+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days''). We compared how well this construction was learned on the default corpus relative to a counterfactual corpus in which AANN sentences were removed. We found that AANNs were still learned better than systematically perturbed variants of the construction. Using additional counterfactual corpora, we suggest that this learning occurs through generalization from related constructions (e.g., ``a few days''). An additional experiment showed that this learning is enhanced when there is more variability in the input. Taken together, our results provide an existence proof that LMs can learn rare grammatical phenomena by generalization from less rare phenomena. Data and code: https://github.com/kanishkamisra/aannalysis.",
      "authors": [
        "Kanishka Misra",
        "Kyle Mahowald"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.19827",
        "HTML": "https://arxiv.org/html/2403.19827",
        "PDF": "https://arxiv.org/pdf/2403.19827"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 28 Mar 2024 20:35:10 GMT",
          "size": "934kb",
          "version": "v1"
        },
        {
          "date": "Sat, 10 Aug 2024 19:45:30 GMT",
          "size": "1734kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 21:39:54 GMT",
          "size": "708kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses the learning process of language models using manipulated corpora to evaluate training data's impact, directly addressing LLM training data and its influence on language model performance."
      },
      "tasks": [
        "counterfactual",
        "Memorization"
      ]
    },
    {
      "id": "2410.18362",
      "abstract": "Web development involves turning UI designs into functional webpages, which can be difficult for both beginners and experienced developers due to the complexity of HTML's hierarchical structures and styles. While Large Language Models (LLMs) have shown promise in generating source code, two major challenges persist in UI-to-HTML code generation: (1) effectively representing HTML's hierarchical structure for LLMs, and (2) bridging the gap between the visual nature of UI designs and the text-based format of HTML code. To tackle these challenges, we introduce Waffle, a new fine-tuning strategy that uses a structure-aware attention mechanism to improve LLMs' understanding of HTML's structure and a contrastive fine-tuning approach to align LLMs' understanding of UI images and HTML code. Models fine-tuned with Waffle show up to 9.00 pp (percentage point) higher HTML match, 0.0982 higher CW-SSIM, 32.99 higher CLIP, and 27.12 pp higher LLEM on our new benchmark WebSight-Test and an existing benchmark Design2Code, outperforming current fine-tuning methods.",
      "authors": [
        "Shanchao Liang",
        "Nan Jiang",
        "Shangshu Qian",
        "Lin Tan"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18362",
        "HTML": "https://arxiv.org/html/2410.18362",
        "PDF": "https://arxiv.org/pdf/2410.18362"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 24 Oct 2024 01:49:49 GMT",
          "size": "5906kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:35:02 GMT",
          "size": "5316kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "WAFFLE: Finetuning Multi-Modal Model for Automated Front-End Development",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses a fine-tuning strategy for LLMs in the context of UI-to-HTML code generation, which involves aspects of adapting models through specific datasets, making it strongly related to LLM training data."
      },
      "models": [
        {
          "model_path": "lt-asset/Waffle_VLM_WebSight",
          "downloads": "32",
          "likes": "12",
          "trending_score": "0.0",
          "link": "https://huggingface.co/lt-asset/Waffle_VLM_WebSight"
        }
      ],
      "tasks": [
        "Code Generation",
        "SSIM"
      ],
      "repo_urls": [
        "https://github.com/lt-asset/Waffle"
      ]
    },
    {
      "id": "2412.06413",
      "abstract": "Vision-and-Language Navigation (VLN) is a challenging task that requires an agent to navigate through photorealistic environments following natural-language instructions. One main obstacle existing in VLN is data scarcity, leading to poor generalization performance over unseen environments. Though data argumentation is a promising way for scaling up the dataset, how to generate VLN data both diverse and world-consistent remains problematic. To cope with this issue, we propose the world-consistent data generation (WCGEN), an efficacious data-augmentation framework satisfying both diversity and world-consistency, aimed at enhancing the generalization of agents to novel environments. Roughly, our framework consists of two stages, the trajectory stage which leverages a point-cloud based technique to ensure spatial coherency among viewpoints, and the viewpoint stage which adopts a novel angle synthesis method to guarantee spatial and wraparound consistency within the entire observation. By accurately predicting viewpoint changes with 3D knowledge, our approach maintains the world-consistency during the generation procedure. Experiments on a wide range of datasets verify the effectiveness of our method, demonstrating that our data augmentation strategy enables agents to achieve new state-of-the-art results on all navigation tasks, and is capable of enhancing the VLN agents' generalization ability to unseen environments.",
      "authors": [
        "Yu Zhong",
        "Rui Zhang",
        "Zihao Zhang",
        "Shuo Wang",
        "Chuan Fang",
        "Xishan Zhang",
        "Jiaming Guo",
        "Shaohui Peng",
        "Di Huang",
        "Yanyang Yan",
        "Xing Hu",
        "Qi Guo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06413",
        "HTML": "https://arxiv.org/html/2412.06413",
        "PDF": "https://arxiv.org/pdf/2412.06413"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Dec 2024 11:40:54 GMT",
          "size": "3216kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:03:04 GMT",
          "size": "2467kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "World-Consistent Data Generation for Vision-and-Language Navigation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses data generation and augmentation specifically for enhancing generalization in vision-and-language navigation tasks, emphasizing world-consistent data generation methods. This is directly relevant to LLM training data as it addresses how data can be curated and augmented to improve model generalization."
      },
      "tasks": [
        "Data Augmentation",
        "Navigate",
        "Vision and Language Navigation"
      ]
    },
    {
      "id": "2502.11962",
      "abstract": "Instruction fine-tuning (IFT) can increase the informativeness of large language models (LLMs), but may reduce their truthfulness. This trade-off arises because IFT steers LLMs to generate responses containing long-tail knowledge that was not well covered during pre-training. As a result, models become more informative but less accurate when generalizing to unseen tasks. In this paper, we empirically demonstrate how unfamiliar knowledge in IFT datasets can negatively affect the truthfulness of LLMs, and we introduce two new IFT paradigms, $UNIT_{cut}$ and $UNIT_{ref}$, to address this issue. $UNIT_{cut}$ identifies and removes unfamiliar knowledge from IFT datasets to mitigate its impact on model truthfulness, whereas $UNIT_{ref}$ trains LLMs to recognize their uncertainty and explicitly indicate it at the end of their responses. Our experiments show that $UNIT_{cut}$ substantially improves LLM truthfulness, while $UNIT_{ref}$ maintains high informativeness and reduces hallucinations by distinguishing between confident and uncertain statements.",
      "authors": [
        "Tianyi Wu",
        "Jingwei Ni",
        "Bryan Hooi",
        "Jiaheng Zhang",
        "Elliott Ash",
        "See-Kiong Ng",
        "Mrinmaya Sachan",
        "Markus Leippold"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11962",
        "HTML": "https://arxiv.org/html/2502.11962",
        "PDF": "https://arxiv.org/pdf/2502.11962"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Feb 2025 16:10:30 GMT",
          "size": "9302kb",
          "version": "v1"
        },
        {
          "date": "Sun, 25 May 2025 19:39:50 GMT",
          "size": "9951kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 09:51:33 GMT",
          "size": "9951kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Balancing Truthfulness and Informativeness with Uncertainty-Aware Instruction Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper is directly related to LLM training data as it addresses issues with instruction fine-tuning datasets affecting LLM truthfulness, proposing methods for dataset modification to improve model performance."
      },
      "tasks": []
    },
    {
      "id": "2503.02502",
      "abstract": "Long-context modeling has drawn more and more attention in the area of Large Language Models (LLMs). Continual training with long-context data becomes the de-facto method to equip LLMs with the ability to process long inputs. However, it still remains an open challenge to measure the quality of long-context training data. To address this issue, we propose a Long-context data selection framework with Attention-based Dependency Measurement (LADM), which can efficiently identify high-quality long-context data from a large-scale, multi-domain pre-training corpus. LADM leverages the retrieval capabilities of the attention mechanism to capture contextual dependencies, ensuring a comprehensive quality measurement of long-context data. Experimental results show that our LADM framework significantly boosts the performance of LLMs on multiple long-context tasks with only 1B tokens for continual training.",
      "authors": [
        "Jianghao Chen",
        "Junhong Wu",
        "Yangyifan Xu",
        "Jiajun Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02502",
        "HTML": "https://arxiv.org/html/2503.02502",
        "PDF": "https://arxiv.org/pdf/2503.02502"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Mar 2025 11:10:13 GMT",
          "size": "7065kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:27:33 GMT",
          "size": "3354kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper directly discusses selection and quality measurement of training data for LLMs, presenting a framework for high-quality long-context data selection, clearly focusing on LLM training data."
      },
      "models": [
        {
          "model_path": "UltraRonin/Long-Attn-Calculator",
          "downloads": "43",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/UltraRonin/Long-Attn-Calculator"
        }
      ],
      "datasets": [
        {
          "dataset_name": "UltraRonin/pile-LlamaTokenizerFast-32k-truncated-toy",
          "downloads": "102",
          "likes": "0",
          "link": "https://huggingface.co/datasets/UltraRonin/pile-LlamaTokenizerFast-32k-truncated-toy"
        }
      ],
      "tasks": []
    },
    {
      "id": "2503.16789",
      "abstract": "Human-LLM conversations are increasingly becoming more pervasive in peoples' professional and personal lives, yet many users still struggle to elicit helpful responses from LLM Chatbots. One of the reasons for this issue is users' lack of understanding in crafting effective prompts that accurately convey their information needs. Meanwhile, the existence of real-world conversational datasets on the one hand, and the text understanding faculties of LLMs on the other, present a unique opportunity to study this problem, and its potential solutions at scale. Thus, in this paper we present the first LLM-centric study of real human-AI chatbot conversations, focused on investigating aspects in which user queries fall short of expressing information needs, and the potential of using LLMs to rewrite suboptimal user prompts. Our findings demonstrate that rephrasing ineffective prompts can elicit better responses from a conversational system, while preserving the user's original intent. Notably, the performance of rewrites improves in longer conversations, where contextual inferences about user needs can be made more accurately. Additionally, we observe that LLMs often need to -- and inherently do -- make \\emph{plausible} assumptions about a user's intentions and goals when interpreting prompts. Our findings largely hold true across conversational domains, user intents, and LLMs of varying sizes and families, indicating the promise of using prompt rewriting as a solution for better human-AI interactions.",
      "authors": [
        "Rupak Sarkar",
        "Bahareh Sarrafzadeh",
        "Nirupama Chandrasekaran",
        "Nagu Rangan",
        "Philip Resnik",
        "Longqi Yang",
        "Sujay Kumar Jauhar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16789",
        "HTML": "https://arxiv.org/html/2503.16789",
        "PDF": "https://arxiv.org/pdf/2503.16789"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 21 Mar 2025 02:01:02 GMT",
          "size": "9434kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:44:58 GMT",
          "size": "9678kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Conversational User-AI Intervention: A Study on Prompt Rewriting for Improved LLM Response Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper focuses on improving LLM responses through prompt rewriting, indicating a reliance on conversational datasets for analysis. This shows an explicit focus on LLM training data, especially in terms of understanding user prompts and data representing human-AI interactions."
      },
      "tasks": [
        "Chatbot",
        "Response Generation"
      ]
    },
    {
      "id": "2504.08377",
      "abstract": "We consider a model for explainable AI in which an explanation for a prediction $h(x)=y$ consists of a subset $S'$ of the training data (if it exists) such that all classifiers $h' \\in H$ that make at most $b$ mistakes on $S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has label $y$ under the assumption that (1) the target function $h^\\star$ belongs to $H$, and (2) the set $S$ contains at most $b$ corrupted points. For example, if $b=0$ and $H$ is the family of linear classifiers in $\\mathbb{R}^d$, and if $x$ lies inside the convex hull of the positive data points in $S$ (and hence every consistent linear classifier labels $x$ as positive), then Carath\\'eodory's theorem states that $x$ lies inside the convex hull of $d+1$ of those points. So, a set $S'$ of size $d+1$ could be released as an explanation for a positive prediction, and would serve as a short proof of correctness of the prediction under the assumption of realizability.\n  In this work, we consider this problem more generally, for general hypothesis classes $H$ and general values $b\\geq 0$. We define the notion of the robust hollow star number of $H$ (which generalizes the standard hollow star number), and show that it precisely characterizes the worst-case size of the smallest certificate achievable, and analyze its size for natural classes. We also consider worst-case distributional bounds on certificate size, as well as distribution-dependent bounds that we show tightly control the sample size needed to get a certificate for any given test example. In particular, we define a notion of the certificate coefficient $\\varepsilon_x$ of an example $x$ with respect to a data distribution $D$ and target function $h^\\star$, and prove matching upper and lower bounds on sample size as a function of $\\varepsilon_x$, $b$, and the VC dimension $d$ of $H$.",
      "authors": [
        "Avrim Blum",
        "Steve Hanneke",
        "Chirag Pabbaraju",
        "Donya Saless"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08377",
        "HTML": "https://arxiv.org/html/2504.08377",
        "PDF": "https://arxiv.org/pdf/2504.08377"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 11 Apr 2025 09:26:37 GMT",
          "size": "35kb",
          "version": "v1"
        },
        {
          "date": "Fri, 09 May 2025 23:30:17 GMT",
          "size": "37kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 19:55:51 GMT",
          "size": "38kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Proofs as Explanations: Short Certificates for Reliable Predictions",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses using subsets of the training data to provide explanations for predictions, which is directly connected to the use and properties of training datasets in models."
      },
      "tasks": []
    },
    {
      "id": "2505.12434",
      "abstract": "Reinforcement fine-tuning (RFT) has shown great promise in achieving humanlevel reasoning capabilities of Large Language Models (LLMs), and has recently been extended to MLLMs. Nevertheless, reasoning about videos, which is a fundamental aspect of human intelligence, remains a persistent challenge due to the complex logic, temporal and causal structures inherent in video data. To fill this gap, we propose VIDEORFT, a novel approach that extends the RFT paradigm to cultivate human-like video reasoning capabilities in MLLMs. VIDEORFT follows the standard two-stage scheme in RFT: supervised fine-tuning (SFT) with chain-of-thought (CoT) annotations, followed by reinforcement learning (RL) to improve generalization. A central challenge to achieve this in the video domain lies in the scarcity of large-scale, high-quality video CoT datasets. We address this by building a fully automatic CoT curation pipeline. First, we devise a cognitioninspired prompting strategy to elicit a reasoning LLM to generate preliminary CoTs based solely on rich, structured, and literal representations of video content. Subsequently, these CoTs are revised by a visual-language model conditioned on the actual video, ensuring visual consistency and reducing visual hallucinations. This pipeline results in two new datasets - VideoRFT-CoT-102K for SFT and VideoRFT-RL-310K for RL. To further strengthen the RL phase, we introduce a novel semantic-consistency reward that explicitly promotes the alignment between textual reasoning and visual evidence. This reward encourages the model to produce coherent, context-aware reasoning outputs grounded in visual input. Extensive experiments show that VIDEORFT achieves state-of-the-art performance on six video reasoning benchmarks.",
      "authors": [
        "Qi Wang",
        "Yanrui Yu",
        "Ye Yuan",
        "Rui Mao",
        "Tianfei Zhou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12434",
        "HTML": "https://arxiv.org/html/2505.12434",
        "PDF": "https://arxiv.org/pdf/2505.12434"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 18 May 2025 14:14:35 GMT",
          "size": "10463kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:35:51 GMT",
          "size": "10987kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper is explicitly focused on LLM training data as it discusses creating new datasets (VideoRFT-CoT-102K and VideoRFT-RL-310K) for training MLLMs and outlines methods for dataset curation and annotation pertinent to enhancing LLMs' video reasoning capabilities."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/qiwang98/videorft"
      ]
    },
    {
      "id": "2505.16065",
      "abstract": "Embedding-Based Retrieval (EBR) is an important technique in modern search engines, enabling semantic match between search queries and relevant results. However, search logging data on platforms like Facebook Marketplace lacks the diversity and details needed for effective EBR model training, limiting the models' ability to capture nuanced search patterns. To address this challenge, we propose Aug2Search, an EBR-based framework leveraging synthetic data generated by Generative AI (GenAI) models, in a multimodal and multitask approach to optimize query-product relevance. This paper investigates the capabilities of GenAI, particularly Large Language Models (LLMs), in generating high-quality synthetic data, and analyzing its impact on enhancing EBR models. We conducted experiments using eight Llama models and 100 million data points from Facebook Marketplace logs. Our synthetic data generation follows three strategies: (1) generate queries, (2) enhance product listings, and (3) generate queries from enhanced listings. We train EBR models on three different datasets: sampled engagement data or original data ((e.g., \"Click\" and \"Listing Interactions\")), synthetic data, and a mixture of both engagement and synthetic data to assess their performance across various training sets. Our findings underscore the robustness of Llama models in producing synthetic queries and listings with high coherence, relevance, and diversity, while maintaining low levels of hallucination. Aug2Search achieves an improvement of up to 4% in ROC_AUC with 100 million synthetic data samples, demonstrating the effectiveness of our approach. Moreover, our experiments reveal that with the same volume of training data, models trained exclusively on synthetic data often outperform those trained on original data only or a mixture of original and synthetic data.",
      "authors": [
        "Ruijie Xi",
        "He Ba",
        "Hao Yuan",
        "Rishu Agrawal",
        "Yuxin Tian",
        "Ruoyan Kong",
        "Arul Prakash"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16065",
        "HTML": "https://arxiv.org/html/2505.16065",
        "PDF": "https://arxiv.org/pdf/2505.16065"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 21 May 2025 22:33:40 GMT",
          "size": "558kb",
          "version": "v1"
        },
        {
          "date": "Wed, 18 Jun 2025 17:04:04 GMT",
          "size": "558kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 18:46:45 GMT",
          "size": "558kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper focuses on using LLMs to generate synthetic training data to improve search models, highlighting the impact and quality of LLM-generated data."
      },
      "tasks": [
        "Data Augmentation",
        "Diversity",
        "Hallucination",
        "Synthetic Data Generation"
      ]
    },
    {
      "id": "2505.20767",
      "abstract": "Faithfulness hallucinations are claims generated by a Large Language Model (LLM) not supported by contexts provided to the LLM. Lacking assessment standards, existing benchmarks focus on \"factual statements\" that rephrase source materials while overlooking \"cognitive statements\" that involve making inferences from the given context. Consequently, evaluating and detecting the hallucination of cognitive statements remains challenging. Inspired by how evidence is assessed in the legal domain, we design a rigorous framework to assess different levels of faithfulness of cognitive statements and introduce the CogniBench dataset where we reveal insightful statistics. To keep pace with rapidly evolving LLMs, we further develop an automatic annotation pipeline that scales easily across different models. This results in a large-scale CogniBench-L dataset, which facilitates training accurate detectors for both factual and cognitive hallucinations. We release our model and datasets at: https://github.com/FUTUREEEEEE/CogniBench",
      "authors": [
        "Xiaqiang Tang",
        "Jian Li",
        "Keyu Hu",
        "Du Nan",
        "Xiaolong Li",
        "Xi Zhang",
        "Weigao Sun",
        "Sihong Xie"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20767",
        "HTML": "https://arxiv.org/html/2505.20767",
        "PDF": "https://arxiv.org/pdf/2505.20767"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 27 May 2025 06:16:27 GMT",
          "size": "8274kb",
          "version": "v1"
        },
        {
          "date": "Wed, 28 May 2025 06:17:19 GMT",
          "size": "8492kb",
          "version": "v2"
        },
        {
          "date": "Fri, 30 May 2025 08:16:51 GMT",
          "size": "3733kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 14:02:19 GMT",
          "size": "3825kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a dataset, CogniBench, which is relevant for assessing the faithfulness of LLMs, directly involving training data aspects."
      },
      "models": [
        {
          "model_path": "future7/CogniDet",
          "downloads": "95",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/future7/CogniDet"
        }
      ],
      "tasks": [
        "Hallucination",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/futureeeeee/cognibench"
      ]
    },
    {
      "id": "2506.04689",
      "abstract": "Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet so far. However, this pool of natural data does not grow at the same rate as the compute supply. Furthermore, the availability of high-quality texts is even more limited: data filtering pipelines often remove up to 99% of the initial web scrapes to achieve state-of-the-art. To address the \"data wall\" of pre-training scaling, our work explores ways to transform and recycle data discarded in existing filtering processes. We propose REWIRE, REcycling the Web with guIded REwrite, a method to enrich low-quality documents so that they could become useful for training. This in turn allows us to increase the representation of synthetic data in the final pre-training set. Experiments at 1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw texts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points improvement respectively across 22 diverse tasks, compared to training on only filtered web data. Training on the raw-synthetic data mix is also more effective than having access to 2x web data. Through further analysis, we demonstrate that about 82% of the mixed in texts come from transforming lower-quality documents that would otherwise be discarded. REWIRE also outperforms related approaches of generating synthetic data, including Wikipedia-style paraphrasing, question-answer synthesizing and knowledge extraction. These results suggest that recycling web texts holds the potential for being a simple and effective approach for scaling pre-training data.",
      "authors": [
        "Thao Nguyen",
        "Yang Li",
        "Olga Golovneva",
        "Luke Zettlemoyer",
        "Sewoong Oh",
        "Ludwig Schmidt",
        "Xian Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04689",
        "HTML": "https://arxiv.org/html/2506.04689",
        "PDF": "https://arxiv.org/pdf/2506.04689"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Jun 2025 07:12:12 GMT",
          "size": "1252kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:12:12 GMT",
          "size": "1252kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes a method to enhance pre-training data quality and quantity by recycling web data, directly addressing LLM training data concerns such as data filtering and enrichment."
      },
      "tasks": []
    },
    {
      "id": "2506.08400",
      "abstract": "Large Language models (LLMs) have demonstrated impressive performance on a wide range of tasks, including in multimodal settings such as speech. However, their evaluation is often limited to English and a few high-resource languages. For low-resource languages, there is no standardized evaluation benchmark. In this paper, we address this gap by introducing mSTEB, a new benchmark to evaluate the performance of LLMs on a wide range of tasks covering language identification, text classification, question answering, and translation tasks on both speech and text modalities. We evaluated the performance of leading LLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open models such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in performance between high-resource and low-resource languages, especially for languages spoken in Africa and Americas/Oceania. Our findings show that more investment is needed to address their under-representation in LLMs coverage.",
      "authors": [
        "Luel Hagos Beyene",
        "Vivek Verma",
        "Min Ma",
        "Jesujoba O. Alabi",
        "Fabian David Schmidt",
        "Joyce Nakatumba-Nabende",
        "David Ifeoluwa Adelani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08400",
        "HTML": "https://arxiv.org/html/2506.08400",
        "PDF": "https://arxiv.org/pdf/2506.08400"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Jun 2025 03:15:08 GMT",
          "size": "347kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 00:58:19 GMT",
          "size": "347kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a multilingual evaluation benchmark for LLMs, focusing on testing performance across different languages. This involves considerations of dataset and language representativeness for LLMs, hence strongly related to LLM training data."
      },
      "tasks": [
        "Language Identification",
        "Question Answering",
        "text-classification",
        "Text Classification"
      ]
    },
    {
      "id": "2506.14293",
      "abstract": "We present Sleeping-DISCO 9M, a large-scale pre-training dataset for music and song. To the best of our knowledge, there are no open-source high-quality dataset representing popular and well-known songs for generative music modeling tasks such as text-music, music-captioning, singing-voice synthesis, melody reconstruction and cross-model retrieval. Past contributions focused on isolated and constrained factors whose core perspective was to create synthetic or re-recorded music corpus (e.g. GTSinger, M4Singer) and arbitrarily large-scale audio datasets (e.g. DISCO-10M and LAIONDISCO-12M) had been another focus for the community. Unfortunately, adoption of these datasets has been below substantial in the generative music community as these datasets fail to reflect real-world music and its flavour. Our dataset changes this narrative and provides a dataset that is constructed using actual popular music and world-renowned artists.",
      "authors": [
        "Tawsif Ahmed",
        "Andrej Radonjic",
        "Gollam Rabby"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14293",
        "HTML": "https://arxiv.org/html/2506.14293",
        "PDF": "https://arxiv.org/pdf/2506.14293"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 08:08:08 GMT",
          "size": "380kb",
          "version": "v1"
        },
        {
          "date": "Mon, 23 Jun 2025 18:39:59 GMT",
          "size": "380kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 08:18:37 GMT",
          "size": "380kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents a large-scale pre-training dataset for music modeling, explicitly discussing data collection and quality, which are directly relevant to the creation and use of LLM training datasets."
      },
      "datasets": [
        {
          "dataset_name": "sleeping-ai/Sleeping-DISCO-9M",
          "downloads": "707",
          "likes": "7",
          "link": "https://huggingface.co/datasets/sleeping-ai/Sleeping-DISCO-9M"
        }
      ],
      "tasks": [
        "Music Captioning",
        "Music Modeling",
        "Singing Voice Synthesis"
      ]
    },
    {
      "id": "2506.18023",
      "abstract": "This report introduces PP-DocBee2, an advanced version of the PP-DocBee, designed to enhance multimodal document understanding. Built on a large multimodal model architecture, PP-DocBee2 addresses the limitations of its predecessor through key technological improvements, including enhanced synthetic data quality, improved visual feature fusion strategy, and optimized inference methodologies. These enhancements yield an $11.4\\%$ performance boost on internal benchmarks for Chinese business documents, and reduce inference latency by $73.0\\%$ to the vanilla version. A key innovation of our work is a data quality optimization strategy for multimodal document tasks. By employing a large-scale multimodal pre-trained model to evaluate data, we apply a novel statistical criterion to filter outliers, ensuring high-quality training data. Inspired by insights into underutilized intermediate features in multimodal models, we enhance the ViT representational capacity by decomposing it into layers and applying a novel feature fusion strategy to improve complex reasoning. The source code and pre-trained model are available at \\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.",
      "authors": [
        "Kui Huang",
        "Xinrong Chen",
        "Wenyu Lv",
        "Jincheng Liao",
        "Guanzhong Wang",
        "Yi Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18023",
        "HTML": "https://arxiv.org/html/2506.18023",
        "PDF": "https://arxiv.org/pdf/2506.18023"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 13:06:13 GMT",
          "size": "132kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:40:39 GMT",
          "size": "132kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper is concerned with datasets for multimodal document understanding, specifically improving data quality and employing a pre-trained model to evaluate data, directly related to LLM training data quality."
      }
    },
    {
      "id": "2506.18871",
      "abstract": "In this work, we introduce OmniGen2, a versatile and open-source generative model designed to provide a unified solution for diverse generation tasks, including text-to-image, image editing, and in-context generation. Unlike OmniGen v1, OmniGen2 features two distinct decoding pathways for text and image modalities, utilizing unshared parameters and a decoupled image tokenizer. This design enables OmniGen2 to build upon existing multimodal understanding models without the need to re-adapt VAE inputs, thereby preserving the original text generation capabilities. To facilitate the training of OmniGen2, we developed comprehensive data construction pipelines, encompassing image editing and in-context generation data. Additionally, we introduce a reflection mechanism tailored for image generation tasks and curate a dedicated reflection dataset based on OmniGen2. Despite its relatively modest parameter size, OmniGen2 achieves competitive results on multiple task benchmarks, including text-to-image and image editing. To further evaluate in-context generation, also referred to as subject-driven tasks, we introduce a new benchmark named OmniContext. OmniGen2 achieves state-of-the-art performance among open-source models in terms of consistency. We will release our models, training code, datasets, and data construction pipeline to support future research in this field. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link: https://github.com/VectorSpaceLab/OmniGen2",
      "authors": [
        "Chenyuan Wu",
        "Pengfei Zheng",
        "Ruiran Yan",
        "Shitao Xiao",
        "Xin Luo",
        "Yueze Wang",
        "Wanli Li",
        "Xiyan Jiang",
        "Yexin Liu",
        "Junjie Zhou",
        "Ze Liu",
        "Ziyi Xia",
        "Chaofan Li",
        "Haoge Deng",
        "Jiahao Wang",
        "Kun Luo",
        "Bo Zhang",
        "Defu Lian",
        "Xinlong Wang",
        "Zhongyuan Wang",
        "Tiejun Huang",
        "Zheng Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18871",
        "HTML": "https://arxiv.org/html/2506.18871",
        "PDF": "https://arxiv.org/pdf/2506.18871"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 17:38:54 GMT",
          "size": "13203kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:54:25 GMT",
          "size": "13203kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "OmniGen2: Exploration to Advanced Multimodal Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explicitly mentions the development of data construction pipelines and datasets for training a generative model. This is closely related to LLM training data as it involves the processes of collecting and curating datasets used for model training."
      },
      "models": [
        {
          "model_path": "OmniGen2/OmniGen2",
          "downloads": "1150",
          "likes": "144",
          "trending_score": "137.0",
          "link": "https://huggingface.co/OmniGen2/OmniGen2"
        },
        {
          "model_path": "jobs-git/OmniGen2",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/jobs-git/OmniGen2"
        }
      ]
    },
    {
      "id": "2506.19262",
      "abstract": "With the remarkable generative capabilities of large language models (LLMs), using LLM-generated data to train downstream models has emerged as a promising approach to mitigate data scarcity in specific domains and reduce time-consuming annotations. However, recent studies have highlighted a critical issue: iterative training on self-generated data results in model collapse, where model performance degrades over time. Despite extensive research on the implications of LLM-generated data, these works often neglect the importance of data diversity, a key factor in data quality. In this work, we aim to understand the implications of the diversity of LLM-generated data on downstream model performance. Specifically, we explore how varying levels of diversity in LLM-generated data affect downstream model performance. Additionally, we investigate the performance of models trained on data that mixes different proportions of LLM-generated data, which we refer to as synthetic data. Our experimental results show that, with minimal distribution shift, moderately diverse LLM-generated data can enhance model performance in scenarios with insufficient labeled data, whereas highly diverse generated data has a negative impact. We hope our empirical findings will offer valuable guidance for future studies on LLMs as data generators.",
      "authors": [
        "Yuchang Zhu",
        "Huazhen Zhong",
        "Qunshu Lin",
        "Haotong Wei",
        "Xiaolong Sun",
        "Zixuan Yu",
        "Minghao Liu",
        "Zibin Zheng",
        "Liang Chen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19262",
        "HTML": "https://arxiv.org/html/2506.19262",
        "PDF": "https://arxiv.org/pdf/2506.19262"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 02:44:58 GMT",
          "size": "625kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:25:04 GMT",
          "size": "625kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "What Matters in LLM-generated Data: Diversity and Its Effect on Model Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explicitly focuses on the diversity of LLM-generated data and its impact on model fine-tuning, directly relating to training data quality and content."
      }
    }
  ],
  "subjects": [
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Computation and Language (cs.CL)",
    "Sound (cs.SD)",
    "Systems and Control (eess.SY)",
    "Cryptography and Security (cs.CR)",
    "Information Retrieval (cs.IR)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Systems and Control (cs.SY)",
    "Audio and Speech Processing (eess.AS)",
    "Machine Learning (stat.ML)",
    "Computers and Society (cs.CY)",
    "Software Engineering (cs.SE)",
    "Machine Learning (cs.LG)"
  ],
  "prompt": {
    "train_data": "\nYou are an expert in information retrieval. I will provide you with a list of research papers from arXiv, specifically in the *cs* (Computer Science) category.\n\nYour task is to analyze each paper and determine its relevance to the topic of **LLM training data** \u2014 that is, any content, methodology, or discussion related to data used in training large language models (LLMs), such as data collection, curation, filtering, privacy, quality, or representativeness.\n\nClassify each paper into one of the following relevance levels:\n\n* `\"strong\"`: The paper is explicitly focused on LLM training data (e.g., it proposes a dataset, evaluates dataset quality, or discusses training data's impact on LLMs).\n* `\"weak\"`: The paper touches on topics indirectly related to LLM training data (e.g., discusses user-generated content, data annotation, or ethics in data use) but it's not the main focus.\n* `\"none\"`: The paper is not related to LLM training data.\n\nReturn your results in the following JSON format:\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"paper id\",\n      \"level\": \"strong | weak | none\",\n      \"reason\": \"Brief justification based on the paper content\"\n    },\n    {\n      \"id\": \"paper id\",\n      \"level\": \"strong | weak | none\",\n      \"reason\": \"Brief justification based on the paper content\"\n    }\n  ]\n}\n```\n\nBe concise but specific in your reasoning. Mention key terms (e.g., \u201ctraining data\u201d, \u201cdataset\u201d, \u201ccorpus\u201d, \u201cdata collection\u201d) or specific sections (e.g., abstract, methodology) that informed your decision when applicable.\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new"
}