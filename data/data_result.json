{
  "data": [
    {
      "id": "1906.06141",
      "abstract": "Following the widespread digitalization of scholarship, software has become essential for research, but the current sociotechnical system of citation does not reflect this sufficiently. Citation provides context for research, but the current model for the respective research citation graphs does not integrate software. In this paper, I develop a directed graph model to alleviate this, describe challenges for its instantiation, and give an outlook of useful applications of research citation graphs, including transitive credit.",
      "authors": [
        "Stephan Druskat"
      ],
      "last_revised_date": "2019/12/19",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/1906.06141",
        "HTML": "https://arxiv.org/html/1906.06141",
        "PDF": "https://arxiv.org/pdf/1906.06141"
      },
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 14 Jun 2019 11:50:16 GMT",
          "size": "2993kb",
          "version": "v1"
        },
        {
          "date": "Thu, 12 Sep 2019 08:08:13 GMT",
          "size": "3065kb",
          "version": "v2"
        },
        {
          "date": "Thu, 19 Dec 2019 09:45:27 GMT",
          "size": "2999kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2019/12/19",
      "title": "Software and Dependencies in Research Citation Graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper examines research citation graphs with a focus on integrating software citations. It does not involve any aspect of LLM training data processing or engineering."
      }
    },
    {
      "id": "2302.14325",
      "abstract": "Place recognition is a key module for long-term SLAM systems. Current LiDAR-based place recognition methods usually use representations of point clouds such as unordered points or range images. These methods achieve high recall rates of retrieval, but their performance may degrade in the case of view variation or scene changes. In this work, we explore the potential of a different representation in place recognition, i.e. bird's eye view (BEV) images. We observe that the structural contents of BEV images are less influenced by rotations and translations of point clouds. We validate that, without any delicate design, a simple VGGNet trained on BEV images achieves comparable performance with the state-of-the-art place recognition methods in scenes of slight viewpoint changes. For more robust place recognition, we design a rotation-invariant network called BEVPlace. We use group convolution to extract rotation-equivariant local features from the images and NetVLAD for global feature aggregation. In addition, we observe that the distance between BEV features is correlated with the geometry distance of point clouds. Based on the observation, we develop a method to estimate the position of the query cloud, extending the usage of place recognition. The experiments conducted on large-scale public datasets show that our method 1) achieves state-of-the-art performance in terms of recall rates, 2) is robust to view changes, 3) shows strong generalization ability, and 4) can estimate the positions of query point clouds. Source codes are publicly available at https://github.com/zjuluolun/BEVPlace.",
      "authors": [
        "Lun Luo",
        "Shuhang Zheng",
        "Yixuan Li",
        "Yongzhi Fan",
        "Beinan Yu",
        "Siyuan Cao",
        "Huiliang Shen"
      ],
      "last_revised_date": "2023/08/15",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.14325",
        "HTML": "https://arxiv.org/html/2302.14325",
        "PDF": "https://arxiv.org/pdf/2302.14325"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 28 Feb 2023 05:37:45 GMT",
          "size": "3445kb",
          "version": "v1"
        },
        {
          "date": "Wed, 15 Mar 2023 02:38:54 GMT",
          "size": "3362kb",
          "version": "v2"
        },
        {
          "date": "Tue, 15 Aug 2023 03:44:00 GMT",
          "size": "6332kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2023/08/15",
      "title": "BEVPlace: Learning LiDAR-based Place Recognition using Bird's Eye View Images",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses place recognition using LiDAR data and BEV images, and does not address training data collection or processing for LLMs."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/ICCV2023/html/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.html",
      "tasks": [
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/zjuluolun/bevplace"
      ]
    },
    {
      "id": "2410.00659",
      "abstract": "The explainability of a robot's actions is crucial to its acceptance in social spaces. Explaining why a robot fails to complete a given task is particularly important for non-expert users to be aware of the robot's capabilities and limitations. So far, research on explaining robot failures has only considered generating textual explanations, even though several studies have shown the benefits of multimodal ones. However, a simple combination of multiple modalities may lead to semantic incoherence between the information across different modalities - a problem that is not well-studied. An incoherent multimodal explanation can be difficult to understand, and it may even become inconsistent with what the robot and the human observe and how they perform reasoning with the observations. Such inconsistencies may lead to wrong conclusions about the robot's capabilities. In this paper, we introduce an approach to generate coherent multimodal explanations by checking the logical coherence of explanations from different modalities, followed by refinements as required. We propose a classification approach for coherence assessment, where we evaluate if an explanation logically follows another. Our experiments suggest that fine-tuning a neural network that was pre-trained to recognize textual entailment, performs well for coherence assessment of multimodal explanations. Code & data: https://pradippramanick.github.io/coherent-explain/.",
      "authors": [
        "Pradip Pramanick",
        "Silvia Rossi"
      ],
      "last_revised_date": "2024/10/01",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00659",
        "HTML": "https://arxiv.org/html/2410.00659",
        "PDF": "https://arxiv.org/pdf/2410.00659"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 01 Oct 2024 13:15:38 GMT",
          "size": "417kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/10/01",
      "title": "Multimodal Coherent Explanation Generation of Robot Failures",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with generating multimodal explanations for robot failures, focusing on logical coherence, with no mention of LLM training data processing or data-related techniques specific to LLMs."
      },
      "tasks": [
        "Explanation Generation",
        "Natural Language Inference"
      ],
      "repo_urls": [
        "https://github.com/pradippramanick/coexp-iros24"
      ]
    },
    {
      "id": "2305.12967",
      "abstract": "This paper proposes a safe reinforcement learning (RL) algorithm that approximately solves the state-constrained optimal control problem for continuous-time uncertain nonlinear systems. We formulate the safe RL problem as the minimization of a Lagrangian that includes the cost functional and a user-defined barrier Lyapunov function (BLF) encoding the state constraints. We show that the analytical solution obtained by the application of Karush-Kuhn-Tucker (KKT) conditions contains a state-dependent expression for the Lagrange multiplier, which is a function of uncertain terms in the system dynamics. We argue that a naive estimation of the Lagrange multiplier may lead to safety constraint violations. To obviate this challenge, we propose an Actor-Critic-Identifier-Lagrangian (ACIL) algorithm that learns optimal control policies from online data without compromising safety. We provide safety and boundedness guarantees with the proposed algorithm and compare its performance with existing offline/online RL methods via a simulation study.",
      "authors": [
        "Soutrik Bandyopadhyay and Shubhendu Bhasin"
      ],
      "last_revised_date": "2024/06/27",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.12967",
        "HTML": "https://arxiv.org/html/2305.12967",
        "PDF": "https://arxiv.org/pdf/2305.12967"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 22 May 2023 12:22:49 GMT",
          "size": "1019kb",
          "version": "v1"
        },
        {
          "date": "Thu, 27 Jun 2024 11:43:37 GMT",
          "size": "1168kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2024/06/27",
      "title": "Lagrangian-based online safe reinforcement learning for state-constrained systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces an RL algorithm for state-constrained systems, which is not related to LLM training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)",
        "Safe Reinforcement Learning"
      ]
    },
    {
      "id": "2109.00317",
      "abstract": "Recognizing places using Lidar in large-scale environments is challenging due to the sparse nature of point cloud data. In this paper we present BVMatch, a Lidar-based frame-to-frame place recognition framework, that is capable of estimating 2D relative poses. Based on the assumption that the ground area can be approximated as a plane, we uniformly discretize the ground area into grids and project 3D Lidar scans to bird's-eye view (BV) images. We further use a bank of Log-Gabor filters to build a maximum index map (MIM) that encodes the orientation information of the structures in the images. We analyze the orientation characteristics of MIM theoretically and introduce a novel descriptor called bird's-eye view feature transform (BVFT). The proposed BVFT is insensitive to rotation and intensity variations of BV images. Leveraging the BVFT descriptors, we unify the Lidar place recognition and pose estimation tasks into the BVMatch framework. The experiments conducted on three large-scale datasets show that BVMatch outperforms the state-of-the-art methods in terms of both recall rate of place recognition and pose estimation accuracy. The source code of our method is publicly available at https://github.com/zjuluolun/BVMatch.",
      "authors": [
        "Lun Luo",
        "Si-Yuan Cao",
        "Bin Han",
        "Hui-Liang Shen",
        "and Junwei Li"
      ],
      "last_revised_date": "2022/01/16",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.00317",
        "HTML": "https://arxiv.org/html/2109.00317",
        "PDF": "https://arxiv.org/pdf/2109.00317"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 01 Sep 2021 11:52:05 GMT",
          "size": "1914kb",
          "version": "v1"
        },
        {
          "date": "Sun, 16 Jan 2022 15:33:00 GMT",
          "size": "1915kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2022/01/16",
      "title": "BVMatch: Lidar-based Place Recognition Using Bird's-eye View Images",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work presents a Lidar-based place recognition framework and does not involve LLM training data processing or engineering."
      },
      "tasks": [
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/zjuluolun/bvmatch"
      ]
    },
    {
      "id": "2501.18224",
      "abstract": "Ambisonics rendering has become an integral part of 3D audio for headphones. It works well with existing recording hardware, the processing cost is mostly independent of the number of sound sources, and it elegantly allows for rotating the scene and listener. One challenge in Ambisonics headphone rendering is to find a perceptually well behaved low-order representation of the Head-Related Transfer Functions (HRTFs) that are contained in the rendering pipe-line. Low-order rendering is of interest, when working with microphone arrays containing only a few sensors, or for reducing the bandwidth for signal transmission. Magnitude Least Squares rendering became the de facto standard for this, which discards high-frequency interaural phase information in favor of reducing magnitude errors. Building upon this idea, we suggest Masked Magnitude Least Squares, which optimized the Ambisonics coefficients with a neural network and employs a spatio-spectral weighting mask to control the accuracy of the magnitude reconstruction. In the tested case, the weighting mask helped to maintain high-frequency notches in the low-order HRTFs and improved the modeled median plane localization performance in comparison to MagLS, while only marginally affecting the overall accuracy of the magnitude reconstruction.",
      "authors": [
        "Or Berebi",
        "Fabian Brinkmann",
        "Stefan Weinzierl and Boaz Rafaely"
      ],
      "last_revised_date": "2025/01/30",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18224",
        "HTML": "https://arxiv.org/html/2501.18224",
        "PDF": "https://arxiv.org/pdf/2501.18224"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 30 Jan 2025 09:26:49 GMT",
          "size": "1877kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/01/30",
      "title": "Ambisonics Binaural Rendering via Masked Magnitude Least Squares",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses Ambisonics binaural rendering, which is outside the scope of LLM training data processing."
      },
      "tasks": []
    },
    {
      "id": "2405.11977",
      "abstract": "We introduce a novel unsupervised approach to reconstructing a 3D volume from only two planar projections that exploits a previous\\-ly-captured 3D volume of the patient. Such volume is readily available in many important medical procedures and previous methods already used such a volume. Earlier methods that work by deforming this volume to match the projections typically fail when the number of projections is very low as the alignment becomes underconstrained. We show how to use a generative model of the volume structures to constrain the deformation and obtain a correct estimate. Moreover, our method is not bounded to a specific sensor calibration and can be applied to new calibrations without retraining. We evaluate our approach on a challenging dataset and show it outperforms state-of-the-art methods. As a result, our method could be used in treatment scenarios such as surgery and radiotherapy while drastically reducing patient radiation exposure.",
      "authors": [
        "Alexandre Cafaro",
        "Amaury Leroy",
        "Guillaume Beldjoudi",
        "Pauline Maury",
        "Charlotte Robert",
        "Eric Deutsch",
        "Vincent Gr\\'egoire",
        "Vincent Lepetit and Nikos Paragios"
      ],
      "last_revised_date": "2024/05/20",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.11977",
        "HTML": "https://arxiv.org/html/2405.11977",
        "PDF": "https://arxiv.org/pdf/2405.11977"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 20 May 2024 12:13:22 GMT",
          "size": "4720kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/05/20",
      "title": "GuidedRec: Guiding Ill-Posed Unsupervised Volumetric Recovery",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for 3D volume reconstruction in medical imaging using generative models. It doesn't focus on LLM training data processing or data engineering."
      },
      "tasks": []
    },
    {
      "id": "2502.06674",
      "abstract": "The emergence of the fifth generation (5G) technology has transformed mobile networks into multi-service environments, necessitating efficient network slicing to meet diverse Service Level Agreements (SLAs). SLA decomposition across multiple network domains, each potentially managed by different service providers, poses a significant challenge due to limited visibility into real-time underlying domain conditions. This paper introduces Risk-Aware Iterated Local Search (RAILS), a novel risk model-driven meta-heuristic framework designed to jointly address SLA decomposition and service provider selection in multi-domain networks. By integrating online risk modeling with iterated local search principles, RAILS effectively navigates the complex optimization landscape, utilizing historical feedback from domain controllers. We formulate the joint problem as a Mixed-Integer Nonlinear Programming (MINLP) problem and prove its NP-hardness. Extensive simulations demonstrate that RAILS achieves near-optimal performance, offering an efficient, real-time solution for adaptive SLA management in modern multi-domain networks.",
      "authors": [
        "Cyril Shih-Huan Hsu",
        "Chrysa Papagianni",
        "Paola Grosso"
      ],
      "last_revised_date": "2025/04/11",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06674",
        "HTML": "https://arxiv.org/html/2502.06674",
        "PDF": "https://arxiv.org/pdf/2502.06674"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 10 Feb 2025 17:00:32 GMT",
          "size": "342kb",
          "version": "v1"
        },
        {
          "date": "Fri, 11 Apr 2025 14:48:32 GMT",
          "size": "365kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/04/11",
      "title": "RAILS: Risk-Aware Iterated Local Search for Joint SLA Decomposition and Service Provider Management in Multi-Domain Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses SLA decomposition and provider management in networks, unrelated to LLM training data processing or data engineering."
      },
      "tasks": [
        "Management"
      ]
    },
    {
      "id": "2107.01791",
      "abstract": "Pretrained language models (PLM) achieve surprising performance on the Choice of Plausible Alternatives (COPA) task. However, whether PLMs have truly acquired the ability of causal reasoning remains a question. In this paper, we investigate the problem of semantic similarity bias and reveal the vulnerability of current COPA models by certain attacks. Previous solutions that tackle the superficial cues of unbalanced token distribution still encounter the same problem of semantic bias, even more seriously due to the utilization of more training data. We mitigate this problem by simply adding a regularization loss and experimental results show that this solution not only improves the model's generalization ability, but also assists the models to perform more robustly on a challenging dataset, BCOPA-CE, which has unbiased token distribution and is more difficult for models to distinguish cause and effect.",
      "authors": [
        "Mingyue Han and Yinglin Wang"
      ],
      "last_revised_date": "2021/07/05",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2107.01791",
        "HTML": "https://arxiv.org/html/2107.01791",
        "PDF": "https://arxiv.org/pdf/2107.01791"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 05 Jul 2021 05:08:30 GMT",
          "size": "1274kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2021/07/05",
      "title": "Doing Good or Doing Right? Exploring the Weakness of Commonsense Causal Reasoning Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates commonsense causal reasoning in language models, focusing on bias in model reasoning. It does not address the processing or engineering of LLM training data."
      },
      "conference_url_abs": "https://aclanthology.org/2021.acl-short.20",
      "tasks": [
        "Commonsense Causal Reasoning",
        "Semantic Similarity",
        "Semantic Textual Similarity"
      ],
      "repo_urls": [
        "https://github.com/badbadcode/weakCOPA"
      ]
    },
    {
      "id": "2501.17754",
      "abstract": "Local administration of thrombolytics in ischemic stroke could accelerate clot lysis and the ensuing reperfusion while minimizing the side effects of systemic administration. Medical microrobots could be injected into the bloodstream and magnetically navigated to the clot for administering the drugs directly to the target. The magnetic manipulation required to navigate medical microrobots will depend on various parameters such as the microrobots size, the blood velocity, and the imposed magnetic field gradients. Numerical simulation was used to study the motion of magnetically controlled microrobots flowing through representative cerebral bifurcations, for predicting the magnetic gradients required to navigate the microrobots from the injection point until the target location. Upon thorough validation of the model against several independent analytical and experimental results, the model was used to generate maps and a predictive equation providing quantitative information on the required magnetic gradients, for different scenarios. The developed maps and predictive equation are crucial to inform the design, operation and optimization of magnetic navigation systems for healthcare applications.",
      "authors": [
        "Pedro G. Alves",
        "Maria Pinto",
        "Rosa Moreira",
        "Derick Sivakumaran",
        "Fabian C. Landers",
        "Maria Guix",
        "Bradley J. Nelson",
        "Andreas D. Flouris",
        "Salvador Pan\\'e",
        "Josep Puigmart\\'i-Luis",
        "Tiago Sotto Mayor"
      ],
      "last_revised_date": "2025/01/29",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17754",
        "HTML": "https://arxiv.org/html/2501.17754",
        "PDF": "https://arxiv.org/pdf/2501.17754"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 29 Jan 2025 16:47:59 GMT",
          "size": "16267kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/01/29",
      "title": "Analysis of the navigation of magnetic microrobots through cerebral bifurcations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on navigation of magnetic microrobots for medical applications and does not address any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2203.01987",
      "abstract": "Acoustic levitation has recently demonstrated the ability to create volumetric content by trapping and quickly moving particles along reference paths to reveal shapes in mid-air. However, the problem of specifying physically feasible trap trajectories to display desired shapes remains unsolved. Even if only the final shape is of interest to the content creator, the trap trajectories need to determine where and when the traps need to be, for the particle to reveal the intended shape. We propose OptiTrap, the first structured numerical approach to compute trap trajectories for acoustic levitation displays. Our approach generates trap trajectories that are physically feasible and nearly time-optimal, and reveal generic mid-air shapes, given only a reference path (i.e., a shape with no time information). We provide a multi-dimensional model of the acoustic forces around a trap to model the trap-particle system dynamics and compute optimal trap trajectories by formulating and solving a non-linear path following problem. We formulate our approach and evaluate it, demonstrating how OptiTrap consistently produces feasible and nearly optimal paths, with increases in size, frequency, and accuracy of the shapes rendered, allowing us to demonstrate larger and more complex shapes than ever shown to date.",
      "authors": [
        "Viktorija Paneva",
        "Arthur Fleig",
        "Diego Mart\\'inez Plasencia",
        "Timm Faulwasser",
        "and J\\\"org M\\\"uller"
      ],
      "last_revised_date": "2022/03/03",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.01987",
        "HTML": "https://arxiv.org/html/2203.01987",
        "PDF": "https://arxiv.org/pdf/2203.01987"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Dynamical Systems (math.DS)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 03 Mar 2022 20:01:52 GMT",
          "size": "24493kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2022/03/03",
      "title": "OptiTrap: Optimal Trap Trajectories for Acoustic Levitation Displays",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a numerical approach for computing optimal trap trajectories for acoustic levitation displays. This work is unrelated to the processing of training data for LLMs."
      }
    },
    {
      "id": "2403.10447",
      "abstract": "We investigate categories in which products distribute over coproducts, a structure we call doubly-infinitary distributive categories. Through a range of examples, we explore how this notion relates to established concepts such as extensivity, infinitary distributivity, and cartesian closedness. We show that doubly-infinitary distributivity strictly strengthens the classical notion of infinitary distributivity. Moreover, we prove that free doubly-infinitary distributive categories are cartesian closed, unlike free distributive categories. The paper concludes with observations on non-canonical isomorphisms, alongside open questions and directions for future research.",
      "authors": [
        "Fernando Lucatelli Nunes and Matthijs V\\'ak\\'ar"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.10447",
        "HTML": "https://arxiv.org/html/2403.10447",
        "PDF": "https://arxiv.org/pdf/2403.10447"
      },
      "subjects": [
        "Category Theory (math.CT)",
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 15 Mar 2024 16:30:41 GMT",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "Fri, 22 Mar 2024 13:49:21 GMT",
          "size": "30kb",
          "version": "v2"
        },
        {
          "date": "Mon, 25 Mar 2024 17:40:21 GMT",
          "size": "26kb",
          "version": "v3"
        },
        {
          "date": "Sat, 30 Mar 2024 17:34:00 GMT",
          "size": "31kb",
          "version": "v4"
        },
        {
          "date": "Sat, 14 Jun 2025 22:05:05 GMT",
          "size": "53kb",
          "version": "v5"
        },
        {
          "date": "Tue, 24 Jun 2025 18:28:52 GMT",
          "size": "53kb",
          "version": "v6"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Free Doubly-Infinitary Distributive Categories are Cartesian Closed",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on mathematical concepts related to category theory, specifically doubly-infinitary distributive categories and their properties, without any mention of LLM training data or data processing methodologies."
      }
    },
    {
      "id": "2409.10803",
      "abstract": "Modeling complex semiconductor fabrication processes such as Ohmic contact formation remains challenging due to high-dimensional parameter spaces and limited experimental data. While classical machine learning (CML) approaches have been successful in many domains, their performance degrades in small-sample, nonlinear scenarios. In this work, we investigate quantum machine learning (QML) as an alternative, exploiting quantum kernels to capture intricate correlations from compact datasets. Using only 159 experimental GaN HEMT samples, we develop a quantum kernel-aligned regressor (QKAR) combining a shallow Pauli-Z feature map with a trainable quantum kernel alignment (QKA) layer. All models, including seven baseline CML regressors, are evaluated under a unified PCA-based preprocessing pipeline to ensure a fair comparison. QKAR consistently outperforms classical baselines across multiple metrics (MAE, MSE, RMSE), achieving a mean absolute error of 0.338 Omega mm when validated on experimental data. We further assess noise robustness and generalization through cross-validation and new device fabrication. These findings suggest that carefully constructed QML models could provide predictive advantages in data-constrained semiconductor modeling, offering a foundation for practical deployment on near-term quantum hardware. While challenges remain for both QML and CML, this study demonstrates QML's potential as a complementary approach in complex process modeling tasks.",
      "authors": [
        "Zeheng Wang",
        "Fangzhou Wang",
        "Liang Li",
        "Zirui Wang",
        "Timothy van der Laan",
        "Ross C. C. Leon",
        "Jing-Kai Huang",
        "Muhammad Usman"
      ],
      "last_revised_date": "2025/05/28",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10803",
        "HTML": "https://arxiv.org/html/2409.10803",
        "PDF": "https://arxiv.org/pdf/2409.10803"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Emerging Technologies (cs.ET)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Sep 2024 00:44:49 GMT",
          "size": "1665kb",
          "version": "v1"
        },
        {
          "date": "Mon, 07 Apr 2025 02:57:39 GMT",
          "size": "1533kb",
          "version": "v2"
        },
        {
          "date": "Wed, 28 May 2025 07:40:06 GMT",
          "size": "2621kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/05/28",
      "title": "Quantum Kernel Learning for Small Dataset Modeling in Semiconductor Fabrication: Application to Ohmic Contact",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on quantum machine learning for semiconductor modeling using limited datasets, but it does not discuss processing of training data for large language models."
      },
      "tasks": [
        "Benchmarking",
        "Quantum Machine Learning"
      ]
    },
    {
      "id": "2410.17960",
      "abstract": "From a monarchy to a democracy, to a dictatorship and back to a democracy -- the German political landscape has been constantly changing ever since the first German national state was formed in 1871. After World War II, the Federal Republic of Germany was formed in 1949. Since then every plenary session of the German Bundestag was logged and even has been digitized over the course of the last few years. We analyze these texts using a time series variant of the topic model LDA to investigate which events had a lasting effect on the political discourse and how the political topics changed over time. This allows us to detect changes in word frequency (and thus key discussion points) in political discourse.",
      "authors": [
        "Kai-Robin Lange and Jonas Rieger and Niklas Benner and Carsten Jentsch"
      ],
      "last_revised_date": "2024/10/23",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17960",
        "HTML": "https://arxiv.org/html/2410.17960",
        "PDF": "https://arxiv.org/pdf/2410.17960"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 23 Oct 2024 15:28:53 GMT",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/10/23",
      "title": "Zeitenwenden: Detecting changes in the German political discourse",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work analyzes historical political discourse using a time series variant of LDA, with no direct relation to LLM training data processing or construction."
      },
      "tasks": [
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/JonasRieger/topicalchanges"
      ]
    },
    {
      "id": "2502.01573",
      "abstract": "Recent work has shown that Large Language Models (LLMs) are not only a suitable tool for code generation but also capable of generating annotation-based code specifications. Scaling these methodologies may allow us to deduce provable correctness guarantees for large-scale software systems. In comparison to other LLM tasks, the application field of deductive verification has the notable advantage of providing a rigorous toolset to check LLM-generated solutions. This short paper provides early results on how this rigorous toolset can be used to reliably elicit correct specification annotations from an unreliable LLM oracle.",
      "authors": [
        "Samuel Teuber and Bernhard Beckert"
      ],
      "last_revised_date": "2025/02/03",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01573",
        "HTML": "https://arxiv.org/html/2502.01573",
        "PDF": "https://arxiv.org/pdf/2502.01573"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 03 Feb 2025 17:55:50 GMT",
          "size": "216kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/02/03",
      "title": "Next Steps in LLM-Supported Java Verification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates LLM capabilities in code verification, with no focus on training data processing or engineering for LLMs."
      },
      "tasks": [
        "Code Generation"
      ]
    },
    {
      "id": "2506.11039",
      "abstract": "Classifier-free guidance (CFG) has emerged as a pivotal advancement in text-to-image latent diffusion models, establishing itself as a cornerstone technique for achieving high-quality image synthesis. However, under high guidance weights, where text-image alignment is significantly enhanced, CFG also leads to pronounced color distortions in the generated images. We identify that these distortions stem from the amplification of sample norms in the latent space. We present a theoretical framework that elucidates the mechanisms of norm amplification and anomalous diffusion phenomena induced by classifier-free guidance. Leveraging our theoretical insights and the latent space structure, we propose an Angle Domain Guidance (ADG) algorithm. ADG constrains magnitude variations while optimizing angular alignment, thereby mitigating color distortions while preserving the enhanced text-image alignment achieved at higher guidance weights. Experimental results demonstrate that ADG significantly outperforms existing methods, generating images that not only maintain superior text alignment but also exhibit improved color fidelity and better alignment with human perceptual preferences.",
      "authors": [
        "Cheng Jin",
        "Zhenyu Xiao",
        "Chutao Liu",
        "Yuantao Gu"
      ],
      "last_revised_date": "2025/05/21",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11039",
        "HTML": "https://arxiv.org/html/2506.11039",
        "PDF": "https://arxiv.org/pdf/2506.11039"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 21 May 2025 03:36:56 GMT",
          "size": "23482kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/05/21",
      "title": "Angle Domain Guidance: Latent Diffusion Requires Rotation Rather Than Extrapolation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a new algorithm for latent diffusion models in image synthesis, not related to LLM training data processing."
      },
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/jinc7461/ADG"
      ]
    },
    {
      "id": "2405.08460",
      "abstract": "The rapid advancement of Large Language Models (LLMs) has led to the development of benchmarks that consider temporal dynamics, however, there remains a gap in understanding how well these models can generalize across temporal contexts due to the inherent dynamic nature of language and information. This paper introduces the concept of temporal generalization in LLMs, including bias in past and future generalizations. Then we introduce FreshBench, a new evaluation framework that employs fresh text and event prediction for assessing LLMs' temporal adaptability, ensuring the evaluation process free from data leakage and subjective bias. The experiment shows significant temporal biases and a decline in performance over time. Our findings reveal that powerful models, while initially superior, tend to decline more rapidly in future generalization. Additionally, powerful open-source models demonstrate better long-term adaptability compared to their closed-source counterparts. Our code is available at https://github.com/FreedomIntelligence/FreshBench.",
      "authors": [
        "Chenghao Zhu and Nuo Chen and Yufei Gao and Yunyi Zhang and Prayag Tiwari and Benyou Wang"
      ],
      "last_revised_date": "2025/04/02",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.08460",
        "HTML": "https://arxiv.org/html/2405.08460",
        "PDF": "https://arxiv.org/pdf/2405.08460"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 14 May 2024 09:31:31 GMT",
          "size": "13098kb",
          "version": "v1"
        },
        {
          "date": "Wed, 10 Jul 2024 17:57:01 GMT",
          "size": "11202kb",
          "version": "v2"
        },
        {
          "date": "Wed, 02 Apr 2025 07:20:24 GMT",
          "size": "13247kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/04/02",
      "title": "Is Your LLM Outdated? A Deep Look at Temporal Generalization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the concept of temporal generalization in LLMs and introduces FreshBench for evaluation. It does not discuss any aspects of data engineering or training-stage data processing for LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/freedomintelligence/freshbench"
      ]
    },
    {
      "id": "2111.06224",
      "abstract": "Income inequality is an important issue that has to be solved in order to make progress in our society. The study of income inequality is well received through the Gini coefficient, which is used to measure degrees of inequality in general. While this method is effective in several aspects, the Gini coefficient alone inevitably overlooks minority subpopulations (e.g. occupations) which results in missing undetected patterns of inequality in minority.\n  In this study, the surveys of incomes and occupations from more than 12 millions households across Thailand have been analyzed by using both Gini coefficient and network densities of income domination networks to get insight regarding the degrees of general and occupational income inequality issues. The results show that, in agricultural provinces, there are less issues in both types of inequality (low Gini coefficients and network densities), while some non-agricultural provinces face an issue of occupational income inequality (high network densities) without any symptom of general income inequality (low Gini coefficients). Moreover, the results also illustrate the gaps of income inequality using estimation statistics, which not only support whether income inequality exists, but that we are also able to tell the magnitudes of income gaps among occupations. These results cannot be obtained via Gini coefficients alone. This work serves as a use case of analyzing income inequality from both general population and subpopulations perspectives that can be utilized in studies of other countries.",
      "authors": [
        "Wanetha Sudswong",
        "Anon Plangprasopchok",
        "and Chainarong Amornbunchornvej"
      ],
      "last_revised_date": "2021/11/05",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.06224",
        "HTML": "https://arxiv.org/html/2111.06224",
        "PDF": "https://arxiv.org/pdf/2111.06224"
      },
      "subjects": [
        "General Economics (econ.GN)",
        "Computers and Society (cs.CY)",
        "Economics (q-fin.EC)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 05 Nov 2021 10:01:19 GMT",
          "size": "1227kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2021/11/05",
      "title": "Occupational Income Inequality of Thailand: A Case Study of Exploratory Data Analysis beyond Gini Coefficient",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on analyzing occupational income inequality in Thailand using exploratory data analysis techniques, such as Gini coefficients and network densities. It does not address any aspect of LLM training data processing."
      },
      "tasks": []
    },
    {
      "id": "2406.03260",
      "abstract": "Deep linear networks have been extensively studied, as they provide simplified models of deep learning. However, little is known in the case of finite-width architectures with multiple outputs and convolutional layers. In this manuscript, we provide rigorous results for the statistics of functions implemented by the aforementioned class of networks, thus moving closer to a complete characterization of feature learning in the Bayesian setting. Our results include: (i) an exact and elementary non-asymptotic integral representation for the joint prior distribution over the outputs, given in terms of a mixture of Gaussians; (ii) an analytical formula for the posterior distribution in the case of squared error loss function (Gaussian likelihood); (iii) a quantitative description of the feature learning infinite-width regime, using large deviation theory. From a physical perspective, deep architectures with multiple outputs or convolutional layers represent different manifestations of kernel shape renormalization, and our work provides a dictionary that translates this physics intuition and terminology into rigorous Bayesian statistics.",
      "authors": [
        "Federico Bassetti",
        "Marco Gherardi",
        "Alessandro Ingrosso",
        "Mauro Pastore",
        "Pietro Rotondo"
      ],
      "last_revised_date": "2025/06/16",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03260",
        "HTML": "https://arxiv.org/html/2406.03260",
        "PDF": "https://arxiv.org/pdf/2406.03260"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 05 Jun 2024 13:37:42 GMT",
          "size": "66kb",
          "version": "v1"
        },
        {
          "date": "Thu, 17 Oct 2024 08:15:09 GMT",
          "size": "37kb",
          "version": "v2"
        },
        {
          "date": "Mon, 16 Jun 2025 11:42:27 GMT",
          "size": "76kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/16",
      "title": "Feature learning in finite-width Bayesian deep linear networks with multiple outputs and convolutional layers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on Bayesian deep linear networks and the statistical characterization of these models. There is no mention of large language models (LLMs) or processing of data associated specifically with LLMs."
      },
      "tasks": []
    },
    {
      "id": "2406.04993",
      "abstract": "INTRODUCTION: The pharmacological treatment of Major Depressive Disorder (MDD) relies on a trial-and-error approach. We introduce an artificial intelligence (AI) model aiming to personalize treatment and improve outcomes, which was deployed in the Artificial Intelligence in Depression Medication Enhancement (AIDME) Study. OBJECTIVES: 1) Develop a model capable of predicting probabilities of remission across multiple pharmacological treatments for adults with at least moderate major depression. 2) Validate model predictions and examine them for amplification of harmful biases. METHODS: Data from previous clinical trials of antidepressant medications were standardized into a common framework and included 9,042 adults with moderate to severe major depression. Feature selection retained 25 clinical and demographic variables. Using Bayesian optimization, a deep learning model was trained on the training set, refined using the validation set, and tested once on the held-out test set. RESULTS: In the evaluation on the held-out test set, the model demonstrated achieved an AUC of 0.65. The model outperformed a null model on the test set (p = 0.01). The model demonstrated clinical utility, achieving an absolute improvement in population remission rate in hypothetical and actual improvement testing. While the model did identify one drug (escitalopram) as generally outperforming the other drugs (consistent with the input data), there was otherwise significant variation in drug rankings. On bias testing, the model did not amplify potentially harmful biases. CONCLUSIONS: We demonstrate the first model capable of predicting outcomes for 10 different treatment options for patients with MDD, intended to be used at or near the start of treatment to personalize treatment. The model was put into clinical practice during the AIDME randomized controlled trial whose results are reported separately.",
      "authors": [
        "David Benrimoh",
        "Caitrin Armstrong",
        "Joseph Mehltretter",
        "Robert Fratila",
        "Kelly Perlman",
        "Sonia Israel",
        "Adam Kapelner",
        "Sagar V. Parikh",
        "Jordan F. Karp",
        "Katherine Heller",
        "Gustavo Turecki"
      ],
      "last_revised_date": "2025/03/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.04993",
        "HTML": "https://arxiv.org/html/2406.04993",
        "PDF": "https://arxiv.org/pdf/2406.04993"
      },
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 07 Jun 2024 15:04:59 GMT",
          "size": "2004kb",
          "version": "v1"
        },
        {
          "date": "Wed, 26 Mar 2025 12:29:31 GMT",
          "size": "1518kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/03/26",
      "title": "Development and Validation of a Deep-Learning Model for Differential Treatment Benefit Prediction for Adults with Major Depressive Disorder Deployed in the Artificial Intelligence in Depression Medication Enhancement (AIDME) Study",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The primary focus is on a deep-learning model for treatment prediction in adults with major depressive disorder. It does not discuss data processing techniques for LLM training data."
      },
      "tasks": [
        "Bayesian Optimization",
        "feature selection"
      ]
    },
    {
      "id": "2502.17419",
      "abstract": "Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases. Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 thinking. Recently, reasoning LLMs like OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level performance in fields such as mathematics and coding, closely mimicking the deliberate reasoning of System 2 and showcasing human-like cognitive abilities. This survey begins with a brief overview of the progress in foundational LLMs and the early development of System 2 technologies, exploring how their combination has paved the way for reasoning LLMs. Next, we discuss how to construct reasoning LLMs, analyzing their features, the core methods enabling advanced reasoning, and the evolution of various reasoning LLMs. Additionally, we provide an overview of reasoning benchmarks, offering an in-depth comparison of the performance of representative reasoning LLMs. Finally, we explore promising directions for advancing reasoning LLMs and maintain a real-time \\href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub Repository} to track the latest developments. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this rapidly evolving field.",
      "authors": [
        "Zhong-Zhi Li",
        "Duzhen Zhang",
        "Ming-Liang Zhang",
        "Jiaxin Zhang",
        "Zengyan Liu",
        "Yuxuan Yao",
        "Haotian Xu",
        "Junhao Zheng",
        "Pei-Jie Wang",
        "Xiuyi Chen",
        "Yingying Zhang",
        "Fei Yin",
        "Jiahua Dong",
        "Zhiwei Li",
        "Bao-Long Bi",
        "Ling-Rui Mei",
        "Junfeng Fang",
        "Xiao Liang",
        "Zhijiang Guo",
        "Le Song",
        "Cheng-Lin Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17419",
        "HTML": "https://arxiv.org/html/2502.17419",
        "PDF": "https://arxiv.org/pdf/2502.17419"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 24 Feb 2025 18:50:52 GMT",
          "size": "19587kb",
          "version": "v1"
        },
        {
          "date": "Tue, 25 Feb 2025 17:15:00 GMT",
          "size": "18289kb",
          "version": "v2"
        },
        {
          "date": "Fri, 25 Apr 2025 08:15:51 GMT",
          "size": "19197kb",
          "version": "v3"
        },
        {
          "date": "Thu, 05 Jun 2025 03:18:45 GMT",
          "size": "19201kb",
          "version": "v4"
        },
        {
          "date": "Sun, 15 Jun 2025 07:06:53 GMT",
          "size": "19203kb",
          "version": "v5"
        },
        {
          "date": "Wed, 25 Jun 2025 02:24:46 GMT",
          "size": "19204kb",
          "version": "v6"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "From System 1 to System 2: A Survey of Reasoning Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This survey paper covers reasoning in LLMs and their evolution, but it does not focus on the data engineering or training-stage data processing tasks related to LLMs."
      },
      "tasks": [
        "Logical Reasoning"
      ],
      "repo_urls": [
        "https://github.com/zzli2022/awesome-slow-reason-system"
      ]
    },
    {
      "id": "2504.07609",
      "abstract": "This invited paper presents an overview of an ongoing research program aimed at extending the Curry-Howard-Lambek correspondence to quantum computation. We explore two key frameworks that provide both logical and computational foundations for quantum programming languages. The first framework, the Lambda-$S$ calculus, extends the lambda calculus by incorporating quantum superposition, enforcing linearity, and ensuring unitarity, to model quantum control. Its categorical semantics establishes a structured connection between classical and quantum computation through an adjunction between Cartesian closed categiries and additive symmetric monoidal closed categories. The second framework, the $\\mathcal L^{\\mathbb C}$ calculus, introduces a proof language for intuitionistic linear logic augmented with sum and scalar operations. This enables the formal encoding of quantum superpositions and measurements, leading to a computational model grounded in categorical structures with biproducts. These approaches suggest a fundamental duality between quantum computation and linear logic, highlighting structural correspondences between logical proofs and quantum programs. We discuss ongoing developments, including extensions to polymorphism, categorical and realizability models, as well as the integration of the modality !, which further solidify the connection between logic and quantum programming languages.",
      "authors": [
        "Alejandro D\\'iaz-Caro"
      ],
      "last_revised_date": "2025/04/10",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07609",
        "HTML": "https://arxiv.org/html/2504.07609",
        "PDF": "https://arxiv.org/pdf/2504.07609"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 10 Apr 2025 10:00:16 GMT",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/04/10",
      "title": "Towards a Computational Quantum Logic: An Overview of an Ongoing Research Program",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores quantum computation frameworks and logic, without any reference to LLM training data processing or related stages."
      }
    },
    {
      "id": "2505.14881",
      "abstract": "Autonomous driving systems (ADS) require extensive testing and validation before deployment. However, it is tedious and time-consuming to construct traffic scenarios for ADS testing. In this paper, we propose TrafficComposer, a multi-modal traffic scenario construction approach for ADS testing. TrafficComposer takes as input a natural language (NL) description of a desired traffic scenario and a complementary traffic scene image. Then, it generates the corresponding traffic scenario in a simulator, such as CARLA and LGSVL. Specifically, TrafficComposer integrates high-level dynamic information about the traffic scenario from the NL description and intricate details about the surrounding vehicles, pedestrians, and the road network from the image. The information from the two modalities is complementary to each other and helps generate high-quality traffic scenarios for ADS testing. On a benchmark of 120 traffic scenarios, TrafficComposer achieves 97.0% accuracy, outperforming the best-performing baseline by 7.3%. Both direct testing and fuzz testing experiments on six ADSs prove the bug detection capabilities of the traffic scenarios generated by TrafficComposer. These scenarios can directly discover 37 bugs and help two fuzzing methods find 33%--124% more bugs serving as initial seeds.",
      "authors": [
        "Zhi Tu",
        "Liangkun Niu",
        "Wei Fan",
        "Tianyi Zhang"
      ],
      "last_revised_date": "2025/06/14",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14881",
        "HTML": "https://arxiv.org/html/2505.14881",
        "PDF": "https://arxiv.org/pdf/2505.14881"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 20 May 2025 20:12:08 GMT",
          "size": "13531kb",
          "version": "v1"
        },
        {
          "date": "Sat, 14 Jun 2025 22:53:15 GMT",
          "size": "13525kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/14",
      "title": "Multi-modal Traffic Scenario Generation for Autonomous Driving System Testing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about traffic scenario generation for autonomous driving systems and does not involve LLM training data processing or engineering."
      },
      "repo_urls": [
        "https://github.com/TrafficComposer/TrafficComposer"
      ]
    },
    {
      "id": "2308.07129",
      "abstract": "This research explores how different virtual work environments, differing in the type and amount of elements they include, impact users' flow, performance, emotional state, and preferences. Pre-study interviews were conducted to inform the design of three VR work environments: the Dark Room, the Empty Room, and the Furnished Room. Fifteen participants took part in a user study where they engaged in a logic-based task simulating deep work while experiencing each environment. The findings suggest that while objective performance measures did not differ significantly, subjective experiences and perceptions varied across the environments. Participants reported feeling less distracted and more focused in the Dark Room and the Empty Room compared to the Furnished Room. The Empty Room was associated with the highest levels of relaxation and calmness, while the Furnished Room was perceived as visually appealing yet more distracting. These findings highlight the variability of user preferences and emphasise the importance of considering user comfort and well-being in the design of virtual work environments. The study contributes to the better understanding of virtual workspaces and provides insights for designing environments that promote flow, productivity, and user well-being.",
      "authors": [
        "Alicja Kiluk",
        "Viktorija Paneva",
        "Sofia Seinfeld",
        "J\\\"org M\\\"uller"
      ],
      "last_revised_date": "2023/08/14",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.07129",
        "HTML": "https://arxiv.org/html/2308.07129",
        "PDF": "https://arxiv.org/pdf/2308.07129"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 14 Aug 2023 13:29:29 GMT",
          "size": "9351kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2023/08/14",
      "title": "The Impact of Different Virtual Work Environments on Flow, Performance, User Emotions, and Preferences",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "It examines virtual work environments' impact on user experience, without any context related to LLM training data or data engineering processes."
      }
    },
    {
      "id": "2404.06435",
      "abstract": "With the proliferation of Internet of Things (IoT) devices, ensuring secure communications has become imperative. Due to their low cost and embedded nature, many of these devices operate with computational and energy constraints, neglecting the potential security vulnerabilities that they may bring. This work-in-progress is focused on designing secure communication among remote servers and embedded IoT devices to balance security robustness and energy efficiency. The proposed approach uses lightweight cryptography, optimizing device performance and security without overburdening their limited resources. Our architecture stands out for integrating Edge servers and a central Name Server, allowing secure and decentralized authentication and efficient connection transitions between different Edge servers. This architecture enhances the scalability of the IoT network and reduces the load on each server, distributing the responsibility for authentication and key management.",
      "authors": [
        "Jos\\'e Cec\\'ilio and Alan Oliveira de S\\'a and Andr\\'e Souto"
      ],
      "last_revised_date": "2024/04/09",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.06435",
        "HTML": "https://arxiv.org/html/2404.06435",
        "PDF": "https://arxiv.org/pdf/2404.06435"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 09 Apr 2024 16:25:13 GMT",
          "size": "317kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/04/09",
      "title": "Software-based Security Framework for Edge and Mobile IoT",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on secure communication protocols for IoT devices, without addressing LLM training data collection or processing."
      }
    },
    {
      "id": "2308.02572",
      "abstract": "Railway networks have become increasingly important in recent times, especially in moving freight and public transportation from road traffic and planes to more environmentally friendly trains. Since expanding the global railway network is time- and resource-consuming, maximizing the rail capacity of the existing infrastructure is desirable. However, simply running more trains is infeasible as certain constraints enforced by the train control system must be satisfied. The capacity of a network depends (amongst others) on the distance between trains allowed by this safety system. While most signaling systems rely on fixed blocks defined by costly hardware, new specifications provided by Level 2 with Hybrid Train Detection of the European Train Control System (ETCS L2 HTD), formerly known as ETCS Hybrid Level 3, allow the usage of virtual subsections. This additional degree of freedom allows for shorter train following times and, thus, more trains on existing railway tracks. On the other hand, new design tasks arise on which automated methods might be helpful for designers of modern railway networks. However, although first approaches exist that solve design problems arising within ETCS L2 HTD, neither formal descriptions nor results on the computational complexity of the corresponding design tasks exist. In this paper, we fill this gap by providing a formal description of design tasks for ETCS L2 HTD and proof that these tasks are NP-complete or NP-hard, respectively. By that, we are providing a solid basis for the future development of methods to solve those tasks, which will be integrated into the Munich Train Control Toolkit available open-source on GitHub at https://github.com/cda-tum/mtct.",
      "authors": [
        "Stefan Engels",
        "Tom Peham",
        "Judith Przigoda",
        "Nils Przigoda",
        "and Robert Wille"
      ],
      "last_revised_date": "2025/06/06",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.02572",
        "HTML": "https://arxiv.org/html/2308.02572",
        "PDF": "https://arxiv.org/pdf/2308.02572"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 03 Aug 2023 11:44:23 GMT",
          "size": "723kb",
          "version": "v1"
        },
        {
          "date": "Thu, 04 Jul 2024 16:20:04 GMT",
          "size": "2339kb",
          "version": "v2"
        },
        {
          "date": "Fri, 02 Aug 2024 14:51:34 GMT",
          "size": "2343kb",
          "version": "v3"
        },
        {
          "date": "Fri, 06 Jun 2025 08:35:20 GMT",
          "size": "2356kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/06",
      "title": "Design Tasks and Their Complexity for the European Train Control System with Hybrid Train Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with design tasks and computational complexity associated with train control systems, rather than any data processing methods related to LLM training."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/cda-tum/mtct"
      ]
    },
    {
      "id": "2410.19027",
      "abstract": "A novel physics-informed operator learning technique based on spectral methods is introduced to model the complex behavior of heterogeneous materials. The Lippmann-Schwinger operator in Fourier space is employed to construct physical constraints with minimal computational overhead, effectively eliminating the need for automatic differentiation. The introduced methodology accelerates the training process by enabling gradient construction on a fixed, finite discretization in Fourier space. Later, the spectral physics-informed finite operator learning (SPiFOL) framework is built based on this discretization and trained to map the arbitrary shape of microstructures to their mechanical responses (strain fields) without relying on labeled data. The training is done by minimizing equilibrium in Fourier space concerning the macroscopic loading condition, which also guarantees the periodicity. SPiFOL, as a physics-informed operator learning method, enables rapid predictions through forward inference after training. To ensure accuracy, we incorporate physical constraints and diversify the training data. However, performance may still degrade for out-of-distribution microstructures. SPiFOL is further enhanced by integrating a Fourier Neural Operator (FNO). Compared to the standard data-driven FNO, SPiFOL shows higher accuracy in predicting stress fields and provides nearly resolution-independent results. Additionally, its zero-shot super-resolution capabilities are explored in heterogeneous domains. Finally, SPiFOL is extended to handle 3D problems and further adapted to finite elasticity, demonstrating the robustness of the framework in handling nonlinear mechanical behavior. The framework shows great potential for efficient and scalable prediction of mechanical responses in complex material systems while also reducing the training time required for training physics-informed neural operators.",
      "authors": [
        "Ali Harandi",
        "Hooman Danesh",
        "Kevin Linka",
        "Stefanie Reese",
        "Shahed Rezaei"
      ],
      "last_revised_date": "2025/05/04",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19027",
        "HTML": "https://arxiv.org/html/2410.19027",
        "PDF": "https://arxiv.org/pdf/2410.19027"
      },
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 24 Oct 2024 14:43:43 GMT",
          "size": "15835kb",
          "version": "v1"
        },
        {
          "date": "Mon, 17 Feb 2025 11:07:19 GMT",
          "size": "42573kb",
          "version": "v2"
        },
        {
          "date": "Sun, 04 May 2025 07:51:57 GMT",
          "size": "46931kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/05/04",
      "title": "A Spectral-based Physics-informed Finite Operator Learning for Prediction of Mechanical Behavior of Microstructures",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on a physics-informed operator learning framework and does not relate to the processing or engineering of LLM training data."
      },
      "repo_urls": [
        "https://github.com/Harandi-Ali/SPiFOL"
      ]
    },
    {
      "id": "2501.06205",
      "abstract": "The evolution of Artificial Intelligence (AI) and its subset Deep Learning (DL), has profoundly impacted numerous domains, including autonomous driving. The integration of autonomous driving in military settings reduces human casualties and enables precise and safe execution of missions in hazardous environments while allowing for reliable logistics support without the risks associated with fatigue-related errors. However, relying on autonomous driving solely requires an advanced decision-making model that is adaptable and optimum in any situation. Considering the presence of numerous interconnected autonomous vehicles in mission-critical scenarios, Ultra-Reliable Low Latency Communication (URLLC) is vital for ensuring seamless coordination, real-time data exchange, and instantaneous response to dynamic driving environments. The advent of 6G strengthens the Internet of Automated Defense Vehicles (IoADV) concept within the realm of Internet of Military Defense Things (IoMDT) by enabling robust connectivity, crucial for real-time data exchange, advanced navigation, and enhanced safety features through IoADV interactions. On the other hand, a critical advancement in this space is using pre-trained Generative Large Language Models (LLMs) for decision-making and communication optimization for autonomous driving. Hence, this work presents opportunities and challenges with a vision of realizing the full potential of these technologies in critical defense applications, especially through the advancement of IoADV and its role in enhancing autonomous military operations.",
      "authors": [
        "Murat Arda Onsu",
        "Poonam Lohan",
        "Burak Kantarci"
      ],
      "last_revised_date": "2025/02/23",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06205",
        "HTML": "https://arxiv.org/html/2501.06205",
        "PDF": "https://arxiv.org/pdf/2501.06205"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 28 Dec 2024 23:07:25 GMT",
          "size": "2545kb",
          "version": "v1"
        },
        {
          "date": "Sun, 23 Feb 2025 02:37:15 GMT",
          "size": "2420kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/02/23",
      "title": "Leveraging Edge Intelligence and LLMs to Advance 6G-Enabled Internet of Automated Defense Vehicles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the application of LLMs in military autonomous driving and edge intelligence without focusing on the processing of LLM training data."
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Decision Making"
      ]
    },
    {
      "id": "2502.12185",
      "abstract": "Conventional predictive modeling of parametric relationships in manufacturing processes is limited by the subjectivity of human expertise and intuition on the one hand and by the cost and time of experimental data generation on the other hand. This work addresses this issue by establishing a new Large Language Model (LLM) framework. The novelty lies in combining automatic extraction of process-relevant knowledge embedded in the literature with iterative model refinement based on a small amount of experimental data. This approach is evaluated on three distinct manufacturing processes that are based on machining, deformation, and additive principles. The results show that for the same small experimental data budget the models derived by our framework have unexpectedly high extrapolative performance, often surpassing the capabilities of conventional Machine Learning. Further, our approach eliminates manual generation of initial models or expertise-dependent interpretation of the literature. The results also reveal the importance of the nature of the knowledge extracted from the literature and the significance of both the knowledge extraction and model refinement components.",
      "authors": [
        "Kiarash Naghavi Khanghah",
        "Anandkumar Patel",
        "Rajiv Malhotra",
        "Hongyi Xu"
      ],
      "last_revised_date": "2025/02/15",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12185",
        "HTML": "https://arxiv.org/html/2502.12185",
        "PDF": "https://arxiv.org/pdf/2502.12185"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 15 Feb 2025 02:43:22 GMT",
          "size": "3494kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/02/15",
      "title": "Large Language Models for Extrapolative Modeling of Manufacturing Processes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a framework for predictive modeling in manufacturing using LLMs, focusing on knowledge extraction and model refinement rather than on LLM training data processing tasks."
      }
    },
    {
      "id": "2505.21291",
      "abstract": "In this paper, we present a novel diagnostic framework that integrates Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system diagnostics in high-reliability systems such as nuclear power plants. Traditional diagnostic modeling struggles when systems become too complex, making functional modeling a more attractive approach. Our approach introduces a diagnostic framework grounded in the functional modeling principles of the Dynamic Master Logic (DML) model. It incorporates two coordinated LLM components, including an LLM-based workflow for automated construction of DML logic from system documentation and an LLM agent that facilitates interactive diagnostics. The generated logic is encoded into a structured KG, referred to as KG-DML, which supports hierarchical fault reasoning. Expert knowledge or operational data can also be incorporated to refine the model's precision and diagnostic depth. In the interaction phase, users submit natural language queries, which are interpreted by the LLM agent. The agent selects appropriate tools for structured reasoning, including upward and downward propagation across the KG-DML. Rather than embedding KG content into every prompt, the LLM agent distinguishes between diagnostic and interpretive tasks. For diagnostics, the agent selects and executes external tools that perform structured KG reasoning. For general queries, a Graph-based Retrieval-Augmented Generation (Graph-RAG) approach is used, retrieving relevant KG segments and embedding them into the prompt to generate natural explanations. A case study on an auxiliary feedwater system demonstrated the framework's effectiveness, with over 90% accuracy in key elements and consistent tool and argument extraction, supporting its use in safety-critical diagnostics.",
      "authors": [
        "Saman Marandi",
        "Yu-Shu Hu",
        "Mohammad Modarres"
      ],
      "last_revised_date": "2025/05/27",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21291",
        "HTML": "https://arxiv.org/html/2505.21291",
        "PDF": "https://arxiv.org/pdf/2505.21291"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 27 May 2025 14:54:49 GMT",
          "size": "1159kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/05/27",
      "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a framework integrating knowledge graphs and LLMs for diagnostics but does not address LLM training data processing."
      },
      "tasks": [
        "Diagnostic",
        "Knowledge Graphs",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Natural Language Queries",
        "RAG",
        "Retrieval-augmented Generation"
      ]
    },
    {
      "id": "2506.01492",
      "abstract": "This study investigates the challenges in designing research infrastructure software for automated software publication in multi-stakeholder environments, focusing specifically on the HERMES system. Through two quantitative surveys of research software engineers (RSEs) and infrastructure facility staff (IFs), it examines technical, organizational, and social requirements across these stakeholder groups. The study reveals significant differences in how RSEs and IFs prioritize various system features. While RSEs highly value compatibility with existing infrastructure, IFs prioritize user-focused aspects like system usability and documentation. The research identifies two main challenges in designing research infrastructure software: (1) the existence of multiple stakeholder groups with differing requirements, and (2) the internal heterogeneity within each stakeholder group across dimensions such as technical experience. The study also highlights that only half of RSE respondents actively practice software publication, pointing to potential cultural or technical barriers. Additionally, the research reveals discrepancies in how stakeholders view organizational aspects, with IFs consistently rating factors like responsibility structures and quality assurance as more important than RSEs do. These findings contribute to a better understanding of the complexities involved in designing research infrastructure software and emphasize the need for systems that can accommodate diverse user groups while maintaining usability across different technical expertise levels.",
      "authors": [
        "Stephan Druskat and Sabine Theis"
      ],
      "last_revised_date": "2025/06/02",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01492",
        "HTML": "https://arxiv.org/html/2506.01492",
        "PDF": "https://arxiv.org/pdf/2506.01492"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 09:50:30 GMT",
          "size": "310kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/02",
      "title": "Challenges in designing research infrastructure software in multi-stakeholder contexts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses challenges in designing research infrastructure software, which is not related to LLM training data processing."
      }
    },
    {
      "id": "2506.19478",
      "abstract": "Bias problems in the estimation of $Q$-values are a well-known obstacle that slows down convergence of $Q$-learning and actor-critic methods. One of the reasons of the success of modern RL algorithms is partially a direct or indirect overestimation reduction mechanism. We propose an easy to implement method built on top of distributional reinforcement learning (DRL) algorithms to deal with the overestimation in a locally adaptive way. Our framework is simple to implement, existing distributional algorithms can be improved with a few lines of code. We provide theoretical evidence and use double $Q$-learning to show how to include locally adaptive overestimation control in existing algorithms. Experiments are provided for tabular, Atari, and MuJoCo environments.",
      "authors": [
        "Leif D\\\"oring",
        "Benedikt Wille",
        "Maximilian Birr",
        "Mihail B\\^irsan",
        "Martin Slowik"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19478",
        "HTML": "https://arxiv.org/html/2506.19478",
        "PDF": "https://arxiv.org/pdf/2506.19478"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 10:09:26 GMT",
          "size": "12315kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "ADDQ: Adaptive Distributional Double Q-Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes enhancements to reinforcement learning algorithms for bias reduction in Q-learning, without connection to LLM training data processing."
      }
    },
    {
      "id": "2506.19746",
      "abstract": "The notion of homomorphism indistinguishability offers a combinatorial framework for characterizing equivalence relations of graphs, in particular equivalences in counting logics within finite model theory. That is, for certain graph classes, two structures agree on all homomorphism counts from the class if and only if they satisfy the same sentences in a corresponding logic. This perspective often reveals connections between the combinatorial properties of graph classes and the syntactic structure of logical fragments. In this work, we extend this perspective to logics with restricted requantification, refining the stratification of logical resources in finite-variable counting logics. Specifically, we generalize Lov\\'asz-type theorems for these logics with either restricted conjunction or bounded quantifier-rank and present new combinatorial proofs of existing results. To this end, we introduce novel path and tree decompositions that incorporate the concept of reusability and develop characterizations based on pursuit-evasion games. Leveraging this framework, we establish that classes of bounded pathwidth and treewidth with reusability constraints are homomorphism distinguishing closed. Finally, we develop a comonadic perspective on requantification by constructing new comonads that encapsulate restricted-reusability pebble games. We show a tight correspondence between their coalgebras and path/tree decompositions, yielding categorical characterizations of reusability in graph decompositions. This unifies logical, combinatorial, and categorical perspectives on the notion of reusability.",
      "authors": [
        "Georg Schindling"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19746",
        "HTML": "https://arxiv.org/html/2506.19746",
        "PDF": "https://arxiv.org/pdf/2506.19746"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 16:05:31 GMT",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Homomorphism Indistinguishability and Game Comonads for Restricted Conjunction and Requantification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work focuses on graph theory, logics, and combinatorial frameworks, with no connection to the processing or engineering of LLM training data."
      }
    },
    {
      "id": "2209.13023",
      "abstract": "Unsupervised text classification, with its most common form being sentiment analysis, used to be performed by counting words in a text that were stored in a lexicon, which assigns each word to one class or as a neutral word. In recent years, these lexicon-based methods fell out of favor and were replaced by computationally demanding fine-tuning techniques for encoder-only models such as BERT and zero-shot classification using decoder-only models such as GPT-4. In this paper, we propose an alternative approach: Lex2Sent, which provides improvement over classic lexicon methods but does not require any GPU or external hardware. To classify texts, we train embedding models to determine the distances between document embeddings and the embeddings of the parts of a suitable lexicon. We employ resampling, which results in a bagging effect, boosting the performance of the classification. We show that our model outperforms lexica and provides a basis for a high performing few-shot fine-tuning approach in the task of binary sentiment analysis.",
      "authors": [
        "Kai-Robin Lange",
        "Jonas Rieger",
        "Carsten Jentsch"
      ],
      "last_revised_date": "2024/10/22",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2209.13023",
        "HTML": "https://arxiv.org/html/2209.13023",
        "PDF": "https://arxiv.org/pdf/2209.13023"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 26 Sep 2022 20:49:18 GMT",
          "size": "60kb",
          "version": "v1"
        },
        {
          "date": "Tue, 22 Oct 2024 15:18:55 GMT",
          "size": "70kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2024/10/22",
      "title": "Lex2Sent: A bagging approach to unsupervised sentiment analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper proposes a method for unsupervised sentiment analysis using a bagging approach, it does not relate to the processing of training data for LLMs, focusing instead on text classification without fine-tuning or other LLM-specific data processing tasks."
      },
      "tasks": [
        "Classification",
        "Decoder",
        "Sentiment Analysis",
        "text-classification",
        "Text Classification",
        "Unsupervised Text Classification",
        "Zero-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/k-rlange/lex2sent"
      ]
    },
    {
      "id": "2502.02879",
      "abstract": "Maven Central is a large popular repository of Java components that has evolved over the last 20 years. The distribution of dependencies indicates that the repository is dominated by a relatively small number of components other components depend on. The question is whether those elites are static, or change over time, and how this relates to innovation in the Maven ecosystem. We study those questions using several metrics. We find that elites are dynamic, and that the rate of innovation is slowing as the repository ages but remains healthy.",
      "authors": [
        "Nkiru Ede",
        "Jens Dietrich",
        "Ulrich Z\\\"ulicke"
      ],
      "last_revised_date": "2025/02/05",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02879",
        "HTML": "https://arxiv.org/html/2502.02879",
        "PDF": "https://arxiv.org/pdf/2502.02879"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 05 Feb 2025 04:38:20 GMT",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/02/05",
      "title": "Popularity and Innovation in Maven Central",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper analyses the dynamics and innovation of the Maven Central repository and does not discuss any aspects of training data processing for LLMs."
      },
      "repo_urls": [
        "https://github.com/nkiru-ede/Popularity_and_Innovation_in_Maven_Central"
      ]
    },
    {
      "id": "2505.02195",
      "abstract": "GCsnap2 Cluster is a scalable, high performance tool for genomic context analysis, developed to overcome the limitations of its predecessor, GCsnap1 Desktop. Leveraging distributed computing with mpi4py[.]futures, GCsnap2 Cluster achieved a 22x improvement in execution time and can now perform genomic context analysis for hundreds of thousands of input sequences in HPC clusters. Its modular architecture enables the creation of task-specific workflows and flexible deployment in various computational environments, making it well suited for bioinformatics studies of large-scale datasets. This work highlights the potential for applying similar approaches to solve scalability challenges in other scientific domains that rely on large-scale data analysis pipelines.",
      "authors": [
        "Reto Krummenacher",
        "Osman Seckin Simsek",
        "Mich\\`ele Leemann",
        "Leila T. Alexander",
        "Torsten Schwede",
        "Florina M. Ciorba and Joana Pereira"
      ],
      "last_revised_date": "2025/05/13",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02195",
        "HTML": "https://arxiv.org/html/2505.02195",
        "PDF": "https://arxiv.org/pdf/2505.02195"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 04 May 2025 17:30:44 GMT",
          "size": "1184kb",
          "version": "v1"
        },
        {
          "date": "Tue, 13 May 2025 08:41:49 GMT",
          "size": "1184kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/05/13",
      "title": "Scalable Genomic Context Analysis with GCsnap2 on HPC Clusters",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research highlights improvements in genomic context analysis tools for bioinformatics and does not relate to LLM training data processing or engineering."
      }
    },
    {
      "id": "2204.13571",
      "abstract": "Automated laboratory experiments have the potential to propel new discoveries, while increasing reproducibility and improving scientists' safety when handling dangerous materials. However, many automated laboratory workflows have not fully leveraged the remarkable advancements in robotics and digital lab equipment. As a result, most robotic systems used in the labs are programmed specifically for a single experiment, often relying on proprietary architectures or using unconventional hardware. In this work, we tackle this problem by proposing a novel robotic system architecture specifically designed with and for chemists, which allows the scientist to easily reconfigure their setup for new experiments. Specifically, the system's strength is its ability to combine together heterogeneous robotic platforms with standard laboratory equipment to create different experimental setups. Finally, we show how the architecture can be used for specific laboratory experiments through case studies such as solubility screening and crystallisation.",
      "authors": [
        "Hatem Fakhruldeen",
        "Gabriella Pizzuto",
        "Jakub Glowacki and Andrew Ian Cooper"
      ],
      "last_revised_date": "2022/04/28",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2204.13571",
        "HTML": "https://arxiv.org/html/2204.13571",
        "PDF": "https://arxiv.org/pdf/2204.13571"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 28 Apr 2022 15:34:09 GMT",
          "size": "13542kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2022/04/28",
      "title": "ARChemist: Autonomous Robotic Chemistry System Architecture",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a robotic system architecture for conducting laboratory experiments, emphasizing flexibility and integration with standard lab equipment. It does not involve LLM training data processing."
      }
    },
    {
      "id": "2411.01218",
      "abstract": "Dynamic scene reconstruction is essential in robotic minimally invasive surgery, providing crucial spatial information that enhances surgical precision and outcomes. However, existing methods struggle to address the complex, temporally dynamic nature of endoscopic scenes. This paper presents ST-Endo4DGS, a novel framework that models the spatio-temporal volume of dynamic endoscopic scenes using unbiased 4D Gaussian Splatting (4DGS) primitives, parameterized by anisotropic ellipses with flexible 4D rotations. This approach enables precise representation of deformable tissue dynamics, capturing intricate spatial and temporal correlations in real time. Additionally, we extend spherindrical harmonics to represent time-evolving appearance, achieving realistic adaptations to lighting and view changes. A new endoscopic normal alignment constraint (ENAC) further enhances geometric fidelity by aligning rendered normals with depth-derived geometry. Extensive evaluations show that ST-Endo4DGS outperforms existing methods in both visual quality and real-time performance, establishing a new state-of-the-art in dynamic scene reconstruction for endoscopic surgery.",
      "authors": [
        "Fengze Li",
        "Jishuai He",
        "Jieming Ma",
        "Zhijing Wu"
      ],
      "last_revised_date": "2024/11/02",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01218",
        "HTML": "https://arxiv.org/html/2411.01218",
        "PDF": "https://arxiv.org/pdf/2411.01218"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 02 Nov 2024 11:24:27 GMT",
          "size": "13946kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/11/02",
      "title": "Real-Time Spatio-Temporal Reconstruction of Dynamic Endoscopic Scenes with 4D Gaussian Splatting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While discussing a novel framework for dynamic scene reconstruction, the paper does not address training data processing for large language models."
      },
      "tasks": []
    },
    {
      "id": "2506.19870",
      "abstract": "Peer-to-peer trading and the move to decentralized grids have reshaped the energy markets in the United States. Notwithstanding, such developments lead to new challenges, mainly regarding the safety and authenticity of energy trade. This study aimed to develop and build a secure, intelligent, and efficient energy transaction system for the decentralized US energy market. This research interlinks the technological prowess of blockchain and artificial intelligence (AI) in a novel way to solve long-standing challenges in the distributed energy market, specifically those of security, fraudulent behavior detection, and market reliability. The dataset for this research is comprised of more than 1.2 million anonymized energy transaction records from a simulated peer-to-peer (P2P) energy exchange network emulating real-life blockchain-based American microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record contains detailed fields of transaction identifier, timestamp, energy volume (kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier (hashed for privacy), smart meter readings, geolocation regions, and settlement confirmation status. The dataset also includes system-calculated behavior metrics of transaction rate, variability of energy production, and historical pricing patterns. The system architecture proposed involves the integration of two layers, namely a blockchain layer and artificial intelligence (AI) layer, each playing a unique but complementary function in energy transaction securing and market intelligence improvement. The machine learning models used in this research were specifically chosen for their established high performance in classification tasks, specifically in the identification of energy transaction fraud in decentralized markets.",
      "authors": [
        "Md Asif Ul Hoq Khan",
        "MD Zahedul Islam",
        "Istiaq Ahmed",
        "Md Masud Karim Rabbi",
        "Farhana Rahman Anonna",
        "MD Abdul Fahim Zeeshan",
        "Mehedi Hasan Ridoy",
        "Bivash Ranjan Chowdhury",
        "Md Nazmul Shakir Rabbi and GM Alamin Sadnan"
      ],
      "last_revised_date": "2025/06/21",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19870",
        "HTML": "https://arxiv.org/html/2506.19870",
        "PDF": "https://arxiv.org/pdf/2506.19870"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 21:09:29 GMT",
          "size": "861kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/21",
      "title": "Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with secure energy transactions using blockchain and AI, without addressing any LLM training data-related processes or enhancements."
      }
    },
    {
      "id": "2506.19871",
      "abstract": "Insurance fraud detection represents a pivotal advancement in modern insurance service, providing intelligent and digitalized monitoring to enhance management and prevent fraud. It is crucial for ensuring the security and efficiency of insurance systems. Although AI and machine learning algorithms have demonstrated strong performance in detecting fraudulent claims, the absence of standardized defense mechanisms renders current systems vulnerable to emerging adversarial threats. In this paper, we propose a GAN-based approach to conduct adversarial attacks on fraud detection systems. Our results indicate that an attacker, without knowledge of the training data or internal model details, can generate fraudulent cases that are classified as legitimate with a 99\\% attack success rate (ASR). By subtly modifying real insurance records and claims, adversaries can significantly increase the fraud risk, potentially bypassing compromised detection systems. These findings underscore the urgent need to enhance the robustness of insurance fraud detection models against adversarial manipulation, thereby ensuring the stability and reliability of different insurance systems.",
      "authors": [
        "Yining Pang and Chenghan Li"
      ],
      "last_revised_date": "2025/06/22",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19871",
        "HTML": "https://arxiv.org/html/2506.19871",
        "PDF": "https://arxiv.org/pdf/2506.19871"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 05:02:45 GMT",
          "size": "332kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/22",
      "title": "An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study focuses on insurance fraud detection using GANs but does not involve LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.19874",
      "abstract": "Recent secure weight release schemes claim to enable open-source model distribution while protecting model ownership and preventing misuse. However, these approaches lack rigorous security foundations and provide only informal security guarantees. Inspired by established works in cryptography, we formalize the security of weight release schemes by introducing several concrete security definitions. We then demonstrate our definition's utility through a case study of TaylorMLP, a prominent secure weight release scheme. Our analysis reveals vulnerabilities that allow parameter extraction thus showing that TaylorMLP fails to achieve its informal security goals. We hope this work will advocate for rigorous research at the intersection of machine learning and security communities and provide a blueprint for how future weight release schemes should be designed and evaluated.",
      "authors": [
        "Xing Yang",
        "Bingtao Wang",
        "Yuhao Wang",
        "Zimo Ji",
        "Terry Jingchen Zhang",
        "Wenyuan Jiang"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19874",
        "HTML": "https://arxiv.org/html/2506.19874",
        "PDF": "https://arxiv.org/pdf/2506.19874"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 11:57:41 GMT",
          "size": "244kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Towards Provable (In)Secure Model Weight Release Schemes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates security in model weight release schemes, without any mention of LLM training data processing."
      }
    },
    {
      "id": "2506.19877",
      "abstract": "Identifying suitable machine learning paradigms for intrusion detection remains critical for building effective and generalizable security solutions. In this study, we present a controlled comparison of four representative models - Multi-Layer Perceptron (MLP), 1D Convolutional Neural Network (CNN), One-Class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF) - on the CICIDS2017 dataset under two scenarios: detecting known attack types and generalizing to previously unseen threats. Our results show that supervised MLP and CNN achieve near-perfect accuracy on familiar attacks but suffer drastic recall drops on novel attacks. Unsupervised LOF attains moderate overall accuracy and high recall on unknown threats at the cost of elevated false alarms, while boundary-based OCSVM balances precision and recall best, demonstrating robust detection across both scenarios. These findings offer practical guidance for selecting IDS models in dynamic network environments.",
      "authors": [
        "Zhaoyang Xu",
        "Yunbo Liu"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19877",
        "HTML": "https://arxiv.org/html/2506.19877",
        "PDF": "https://arxiv.org/pdf/2506.19877"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 15:31:10 GMT",
          "size": "447kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study is about evaluating machine learning models for anomaly detection in network traffic and does not pertain to LLM training data processing."
      }
    },
    {
      "id": "2506.19881",
      "abstract": "Are there any conditions under which a generative model's outputs are guaranteed not to infringe the copyrights of its training data? This is the question of \"provable copyright protection\" first posed by Vyas, Kakade, and Barak (ICML 2023). They define near access-freeness (NAF) and propose it as sufficient for protection. This paper revisits the question and establishes new foundations for provable copyright protection -- foundations that are firmer both technically and legally. First, we show that NAF alone does not prevent infringement. In fact, NAF models can enable verbatim copying, a blatant failure of copy protection that we dub being tainted. Then, we introduce our blameless copy protection framework for defining meaningful guarantees, and instantiate it with clean-room copy protection. Clean-room copy protection allows a user to control their risk of copying by behaving in a way that is unlikely to copy in a counterfactual clean-room setting. Finally, we formalize a common intuition about differential privacy and copyright by proving that DP implies clean-room copy protection when the dataset is golden, a copyright deduplication requirement.",
      "authors": [
        "Aloni Cohen"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19881",
        "HTML": "https://arxiv.org/html/2506.19881",
        "PDF": "https://arxiv.org/pdf/2506.19881"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 20:46:51 GMT",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on copyright protection frameworks for generative models, lacking content on LLM training data processing methodologies."
      }
    },
    {
      "id": "2506.19882",
      "abstract": "Science progresses by iteratively advancing and correcting humanity's understanding of the world. In machine learning (ML) research, rapid advancements have led to an explosion of publications, but have also led to misleading, incorrect, flawed or perhaps even fraudulent studies being accepted and sometimes highlighted at ML conferences due to the fallibility of peer review. While such mistakes are understandable, ML conferences do not offer robust processes to help the field systematically correct when such errors are made.This position paper argues that ML conferences should establish a dedicated \"Refutations and Critiques\" (R & C) Track. This R & C Track would provide a high-profile, reputable platform to support vital research that critically challenges prior research, thereby fostering a dynamic self-correcting research ecosystem. We discuss key considerations including track design, review principles, potential pitfalls, and provide an illustrative example submission concerning a recent ICLR 2025 Oral. We conclude that ML conferences should create official, reputable mechanisms to help ML research self-correct.",
      "authors": [
        "Rylan Schaeffer",
        "Joshua Kazdan",
        "Yegor Denisov-Blanch",
        "Brando Miranda",
        "Matthias Gerstgrasser",
        "Susan Zhang",
        "Andreas Haupt",
        "Isha Gupta",
        "Elyas Obbad",
        "Jesse Dodge",
        "Jessica Zosa Forde",
        "Koustuv Sinha",
        "Francesco Orabona",
        "Sanmi Koyejo",
        "David Donoho"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19882",
        "HTML": "https://arxiv.org/html/2506.19882",
        "PDF": "https://arxiv.org/pdf/2506.19882"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 02:19:30 GMT",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This is a position paper proposing a new track for ML conferences, with no content on LLM training data processing."
      }
    },
    {
      "id": "2506.19883",
      "abstract": "Recently, multi-objective optimization (MOO) has gained attention for its broad applications in ML, operations research, and engineering. However, MOO algorithm design remains in its infancy and many existing MOO methods suffer from unsatisfactory convergence rate and sample complexity performance. To address this challenge, in this paper, we propose an algorithm called STIMULUS( stochastic path-integrated multi-gradient recursive e\\ulstimator), a new and robust approach for solving MOO problems. Different from the traditional methods, STIMULUS introduces a simple yet powerful recursive framework for updating stochastic gradient estimates to improve convergence performance with low sample complexity. In addition, we introduce an enhanced version of STIMULUS, termed STIMULUS-M, which incorporates a momentum term to further expedite convergence. We establish $O(1/T)$ convergence rates of the proposed methods for non-convex settings and $O (\\exp{-\\mu T})$ for strongly convex settings, where $T$ is the total number of iteration rounds. Additionally, we achieve the state-of-the-art $O \\left(n+\\sqrt{n}\\epsilon^{-1}\\right)$ sample complexities for non-convex settings and $O\\left(n+ \\sqrt{n} \\ln ({\\mu/\\epsilon})\\right)$ for strongly convex settings, where $\\epsilon>0$ is a desired stationarity error. Moreover, to alleviate the periodic full gradient evaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced versions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their theoretical analysis.",
      "authors": [
        "Zhuqing Liu",
        "Chaosheng Dong",
        "Michinari Momma",
        "Simone Shao",
        "Shaoyuan Xu",
        "Yan Gao",
        "Haibo Yang",
        "Jia Liu"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19883",
        "HTML": "https://arxiv.org/html/2506.19883",
        "PDF": "https://arxiv.org/pdf/2506.19883"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 03:31:25 GMT",
          "size": "1236kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on multi-objective optimization algorithms and their convergence and sample complexity improvements, with no emphasis on the design, collection, or processing of training data for LLMs."
      }
    },
    {
      "id": "2506.19884",
      "abstract": "As the demand for on-device Large Language Model (LLM) inference grows, energy efficiency has become a major concern, especially for battery-limited mobile devices. Our analysis shows that the memory-bound LLM decode phase dominates energy use, and yet most existing works focus on accelerating the prefill phase, neglecting energy concerns. We introduce Adaptive Energy-Centric Core Selection (AECS) and integrate it into MNN to create the energy-efficient version, MNN-AECS, the first engine-level system solution without requiring root access or OS modifications for energy-efficient LLM decoding. MNN-AECS is designed to reduce LLM decoding energy while keeping decode speed within an acceptable slowdown threshold by dynamically selecting low-power CPU cores. MNN-AECS is evaluated across 5 Android and 2 iOS devices on 5 popular LLMs of various sizes. Compared to original MNN, MNN-AECS cuts down energy use by 23% without slowdown averaged over all 7 devices and 4 datasets. Against other engines, including llama.cpp, executorch, mllm, and MediaPipe, MNN-AECS delivers 39% to 78% energy saving and 12% to 363% speedup on average.",
      "authors": [
        "Zhengxiang Huang",
        "Chaoyue Niu",
        "Zhaode Wang",
        "Jiarui Xue",
        "Hanming Zhang",
        "Yugang Wang",
        "Zewei Xin",
        "Xiaotang Jiang",
        "Chengfei Lv",
        "Fan Wu",
        "Guihai Chen"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19884",
        "HTML": "https://arxiv.org/html/2506.19884",
        "PDF": "https://arxiv.org/pdf/2506.19884"
      },
      "subjects": [
        "Operating Systems (cs.OS)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 04:50:28 GMT",
          "size": "14003kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "MNN-AECS: Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses energy optimization for LLM decoding on mobile devices, and while it concerns LLM inference, it does not address training data processing for LLMs."
      }
    },
    {
      "id": "2506.19885",
      "abstract": "The Koopman theory is a powerful and effective modeling tool for converting nonlinear systems into linear representations, and flight trajectory prediction (FTP) is a complex nonlinear system. However, current models applying the Koopman theory to FTP tasks are not very effective, model interpretability is indeed an issue, and the Koopman operators are computationally intensive, resulting in long training times. To address this issue, this paper proposes a new modeling and control framework based on the HIPPO method, the Koopman theory, and state space equations from cybernetics: FlightKooba. Inspired by the idea of structural state space equations, FlightKooba directly constructs the Koopman operators from data. This makes the framework highly interpretable and significantly reduces the number of trainable parameters in the module, thereby greatly reducing training time. Experiments have demonstrated the superiority of the FlightKooba modeling method in terms of time and memory consumption (training time comparable to the Mamba module without using CUDA-level acceleration; memory reduced by more than 50% on most datasets, with a tenfold reduction in the number of parameters), essentially completing the FTP task. It provides a new method for the fast computation of the Koopman operators, opening up new possibilities for the combination of time series forecasting and control.",
      "authors": [
        "Jing Lu",
        "Xuan Wu",
        "Yizhun Tian",
        "Songhan Fan",
        "Yali Fang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19885",
        "HTML": "https://arxiv.org/html/2506.19885",
        "PDF": "https://arxiv.org/pdf/2506.19885"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 04:53:49 GMT",
          "size": "1360kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "FlightKooba: A Fast Interpretable FTP Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a model for flight trajectory prediction using Koopman theory. It does not discuss LLM training data or its processing."
      }
    },
    {
      "id": "2506.19886",
      "abstract": "Semantic communication has emerged as a promising neural network-based system design for 6G networks. Task-oriented semantic communication is a novel paradigm whose core goal is to efficiently complete specific tasks by transmitting semantic information, optimizing communication efficiency and task performance. The key challenge lies in preserving privacy while maintaining task accuracy, as this scenario is susceptible to model inversion attacks. In such attacks, adversaries can restore or even reconstruct input data by analyzing and processing model outputs, owing to the neural network-based nature of the systems. In addition, traditional systems use image quality indicators (such as PSNR or SSIM) to assess attack severity, which may be inadequate for task-oriented semantic communication, since visual differences do not necessarily ensure semantic divergence. In this paper, we propose a diffusion-based semantic communication framework, named DiffSem, that optimizes semantic information reconstruction through a diffusion mechanism with self-referential label embedding to significantly improve task performance. Our model also compensates channel noise and adopt semantic information distortion to ensure the robustness of the system in various signal-to-noise ratio environments. To evaluate the attacker's effectiveness, we propose a new metric that better quantifies the semantic fidelity of estimations from the adversary. Experimental results based on this criterion show that on the MNIST dataset, DiffSem improves the classification accuracy by 10.03%, and maintain stable performance under dynamic channels. Our results further demonstrate that significant deviation exists between traditional image quality indicators and the leakage of task-relevant semantic information.",
      "authors": [
        "Xuesong Wang",
        "Mo Li",
        "Xingyan Shi",
        "Zhaoqian Liu",
        "Shenghao Yang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19886",
        "HTML": "https://arxiv.org/html/2506.19886",
        "PDF": "https://arxiv.org/pdf/2506.19886"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 05:21:27 GMT",
          "size": "5774kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Diffusion-based Task-oriented Semantic Communications with Model Inversion Attack",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about semantic communication in the context of 6G networks and does not focus on LLM training data processing."
      }
    },
    {
      "id": "2506.19889",
      "abstract": "Recent advances in large language models (LLMs) have made a profound impact on our society and also raised new security concerns. Particularly, due to the remarkable inference ability of LLMs, the privacy violation attack (PVA), revealed by Staab et al., introduces serious personal privacy issues. Existing defense methods mainly leverage LLMs to anonymize the input query, which requires costly inference time and cannot gain satisfactory defense performance. Moreover, directly rejecting the PVA query seems like an effective defense method, while the defense method is exposed, promoting the evolution of PVA. In this paper, we propose a novel defense paradigm based on retrieval-confused generation (RCG) of LLMs, which can efficiently and covertly defend the PVA. We first design a paraphrasing prompt to induce the LLM to rewrite the \"user comments\" of the attack query to construct a disturbed database. Then, we propose the most irrelevant retrieval strategy to retrieve the desired user data from the disturbed database. Finally, the \"data comments\" are replaced with the retrieved user data to form a defended query, leading to responding to the adversary with some wrong personal attributes, i.e., the attack fails. Extensive experiments are conducted on two datasets and eight popular LLMs to comprehensively evaluate the feasibility and the superiority of the proposed defense method.",
      "authors": [
        "Wanli Peng",
        "Xin Chen",
        "Hang Fu",
        "XinYu He",
        "Xue Yiming",
        "Juan Wen"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19889",
        "HTML": "https://arxiv.org/html/2506.19889",
        "PDF": "https://arxiv.org/pdf/2506.19889"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 07:28:29 GMT",
          "size": "475kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily discusses a defense mechanism against privacy violation attacks on LLMs, focusing on the retrieval-confused generation approach rather than LLM training data processing or collection."
      }
    },
    {
      "id": "2506.19890",
      "abstract": "The optimization of quality of experience (QoE) in multi-user virtual reality (VR) interactions demands a delicate balance between ultra-low latency, high-fidelity motion synchronization, and equitable resource allocation. While adaptive keyframe extraction mitigates transmission overhead, existing approaches often overlook the causal relationships among allocated bandwidth, CPU frequency, and user perception, limiting QoE gains. This paper proposes an intelligent framework to maximize QoE by integrating adaptive keyframe extraction with causal-aware reinforcement learning (RL). First, a novel QoE metric is formulated using the Weber-Fechner Law, combining perceptual sensitivity, attention-driven priorities, and motion reconstruction accuracy. The QoE optimization problem is then modeled as a mixed integer programming (MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational resources under horizon-fairness constraints. We propose Partial State Causal Deep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep Deterministic Policy Gradient (DDPG) method with causal influence detection. By leveraging causal information regarding how QoE is influenced and determined by various actions, we explore actions guided by weights calculated from causal inference (CI), which in turn improves training efficiency. Experiments conducted with the CMU Motion Capture Database demonstrate that our framework significantly reduces interactive latency, enhances QoE, and maintains fairness, achieving superior performance compared to benchmark methods.",
      "authors": [
        "Ziru Zhang",
        "Jiadong Yu",
        "and Danny H.K. Tsang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19890",
        "HTML": "https://arxiv.org/html/2506.19890",
        "PDF": "https://arxiv.org/pdf/2506.19890"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 07:32:34 GMT",
          "size": "2561kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on optimizing quality of experience in virtual reality interactions and does not address LLM training data collection or processing."
      }
    },
    {
      "id": "2506.19891",
      "abstract": "Machine unlearning aims to selectively remove class-specific knowledge from pretrained neural networks to satisfy privacy regulations such as the GDPR. Existing methods typically face a trade-off between unlearning speed and preservation of predictive accuracy, often incurring either high computational overhead or significant performance degradation on retained classes. In this paper, we propose a novel class-aware soft pruning framework leveraging orthogonal convolutional kernel regularization to achieve rapid and precise forgetting with millisecond-level response times. By enforcing orthogonality constraints during training, our method decorrelates convolutional filters and disentangles feature representations, while efficiently identifying class-specific channels through activation difference analysis. Extensive evaluations across multiple architectures and datasets demonstrate stable pruning with near-instant execution, complete forgetting of targeted classes, and minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100, and TinyImageNet confirm that our approach substantially reduces membership inference attack risks and accelerates unlearning by orders of magnitude compared to state-of-the-art baselines. This framework provides an efficient, practical solution for real-time machine unlearning in Machine Learning as a Service (MLaaS) scenarios.",
      "authors": [
        "Qinghui Gong",
        "Xue Yang",
        "Xiaohu Tang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19891",
        "HTML": "https://arxiv.org/html/2506.19891",
        "PDF": "https://arxiv.org/pdf/2506.19891"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 09:52:04 GMT",
          "size": "1246kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Orthogonal Soft Pruning for Efficient Class Unlearning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses class-specific unlearning in neural networks and does not cover any aspects of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.19892",
      "abstract": "Decentralized Federated Learning (DFL) enables nodes to collaboratively train models without a central server, introducing new vulnerabilities since each node independently selects peers for model aggregation. Malicious nodes may exploit this autonomy by sending corrupted models (model poisoning), delaying model submissions (delay attack), or flooding the network with excessive messages, negatively affecting system performance. Existing solutions often depend on rigid configurations or additional infrastructures such as blockchain, leading to computational overhead, scalability issues, or limited adaptability. To overcome these limitations, this paper proposes RepuNet, a decentralized reputation system that categorizes threats in DFL and dynamically evaluates node behavior using metrics like model similarity, parameter changes, message latency, and communication volume. Nodes' influence in model aggregation is adjusted based on their reputation scores. RepuNet was integrated into the Nebula DFL platform and experimentally evaluated with MNIST and CIFAR-10 datasets under non-IID distributions, using federations of up to 25 nodes in both fully connected and random topologies. Different attack intensities, frequencies, and activation intervals were tested. Results demonstrated that RepuNet effectively detects and mitigates malicious behavior, achieving F1 scores above 95% for MNIST scenarios and approximately 76% for CIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness, and practical potential for mitigating threats in decentralized federated learning environments.",
      "authors": [
        "Isaac Marroqui Penalva and Enrique Tom\\'as Mart\\'inez Beltr\\'an and Manuel Gil P\\'erez and Alberto Huertas Celdr\\'an"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19892",
        "HTML": "https://arxiv.org/html/2506.19892",
        "PDF": "https://arxiv.org/pdf/2506.19892"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 10:46:48 GMT",
          "size": "719kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "RepuNet: A Reputation System for Mitigating Malicious Clients in DFL",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "RepuNet is focused on mitigating malicious clients in decentralized federated learning environments, and does not engage with LLM training data processes."
      }
    },
    {
      "id": "2506.19893",
      "abstract": "Due to the surging amount of AI-generated content (AIGC), its provisioning to edges and mobile users from the cloud incurs substantial traffic on networks. Generative semantic communication (GSC) offers a promising solution by transmitting highly compact information, i.e., prompt text and latent representations, instead of high-dimensional AIGC data. However, GSC relies on the alignment between the knowledge in the cloud generative AI (GAI) and that possessed by the edges and users, and between the knowledge for wireless transmission and that of actual channels, which remains challenging. In this paper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm for GSC systems. The core idea is to distill the generation knowledge from the cloud-GAI into low-rank matrices, which can be incorporated by the edge and used to adapt the transmission knowledge to diverse wireless channel conditions. DeKA-g comprises two novel methods: metaword-aided knowledge distillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD, an optimized metaword is employed to enhance the efficiency of knowledge distillation, while VGSA enables efficient adaptation to diverse compression rates and SNR ranges. From simulation results, DeKA-g improves the alignment between the edge-generated images and the cloud-generated ones by 44%. Moreover, it adapts to compression rates with 116% higher efficiency than the baseline and enhances the performance in low-SNR conditions by 28%.",
      "authors": [
        "Jingzhi Hu and Geoffrey Ye Li"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19893",
        "HTML": "https://arxiv.org/html/2506.19893",
        "PDF": "https://arxiv.org/pdf/2506.19893"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 10:50:14 GMT",
          "size": "2181kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research concerns generative semantic communications and knowledge alignment in AI-generated content networks, not involving LLM training data engineering or processing."
      }
    },
    {
      "id": "2506.19894",
      "abstract": "Electricity markets are highly complex, involving lots of interactions and complex dependencies that make it hard to understand the inner workings of the market and what is driving prices. Econometric methods have been developed for this, white-box models, however, they are not as powerful as deep neural network models (DNN). In this paper, we use a DNN to forecast the price and then use XAI methods to understand the factors driving the price dynamics in the market. The objective is to increase our understanding of how different electricity markets work. To do that, we apply explainable methods such as SHAP and Gradient, combined with visual techniques like heatmaps (saliency maps) to analyse the behaviour and contributions of various features across five electricity markets. We introduce the novel concepts of SSHAP values and SSHAP lines to enhance the complex representation of high-dimensional tabular models.",
      "authors": [
        "Antoine Pesenti",
        "Aidan OSullivan"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19894",
        "HTML": "https://arxiv.org/html/2506.19894",
        "PDF": "https://arxiv.org/pdf/2506.19894"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 11:07:19 GMT",
          "size": "7039kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Explaining deep neural network models for electricity price forecasting with XAI",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on using deep neural networks (DNN) and explainable AI (XAI) methods for understanding electricity price dynamics, not on LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.19895",
      "abstract": "Neural Networks have high accuracy in solving problems where it is difficult to detect patterns or create a logical model. However, these algorithms sometimes return wrong solutions, which become problematic in high-risk domains like medical diagnosis or autonomous driving. One strategy to detect and mitigate these errors is the measurement of the uncertainty over neural network decisions. In this paper, we present a novel post-hoc framework for measuring the uncertainty of a decision based on retrieved training cases that have a similar activation vector to the query for each layer. Based on these retrieved cases, we propose two new metrics: Decision Change and Layer Uncertainty, which capture changes in nearest-neighbor class distributions across layers. We evaluated our approach in a classification model for two datasets: CIFAR-10 and MNIST. The results show that these metrics enhance uncertainty estimation, especially in challenging classification tasks, outperforming softmax-based confidence.",
      "authors": [
        "Miguel N. Font and Jos\\'e L. Jorro-Aragoneses and Carlos M. Ala\\'iz"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19895",
        "HTML": "https://arxiv.org/html/2506.19895",
        "PDF": "https://arxiv.org/pdf/2506.19895"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 11:10:41 GMT",
          "size": "144kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a framework for uncertainty quantification in neural networks, focusing on post-hoc metrics rather than any data processing related to LLM training."
      }
    },
    {
      "id": "2506.19899",
      "abstract": "Social engineering attacks using email, commonly known as phishing, are a critical cybersecurity threat. Phishing attacks often lead to operational incidents and data breaches. As a result, many organizations allocate a substantial portion of their cybersecurity budgets to phishing awareness training, driven in part by compliance requirements. However, the effectiveness of this training remains in dispute. Empirical evidence of training (in)effectiveness is essential for evidence-based cybersecurity investment and policy development. Despite recent measurement studies, two critical gaps remain in the literature:\n  (1) we lack a validated measure of phishing lure difficulty, and\n  (2) there are few comparisons of different types of training in real-world business settings.\n  To fill these gaps, we conducted a large-scale study ($N = 12{,}511$) of phishing effectiveness at a US-based financial technology (``fintech'') firm. Our two-factor design compared the effect of treatments (lecture-based, interactive, and control groups) on subjects' susceptibility to phishing lures of varying complexity (using the NIST Phish Scale). The NIST Phish Scale successfully predicted behavior (click rates: 7.0\\% easy to 15.0\\% hard emails, p $<$ 0.001), but training showed no significant main effects on clicks (p = 0.450) or reporting (p = 0.417). Effect sizes remained below 0.01, indicating little practical value in any of the phishing trainings we deployed. Our results add to the growing evidence that phishing training is ineffective, reinforcing the importance of phishing defense-in-depth and the merit of changes to processes and technology to reduce reliance on humans, as well as rebuking the training costs necessitated by regulatory requirements.",
      "authors": [
        "Andrew T. Rozema",
        "James C. Davis"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19899",
        "HTML": "https://arxiv.org/html/2506.19899",
        "PDF": "https://arxiv.org/pdf/2506.19899"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 17:57:10 GMT",
          "size": "706kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper studies the effectiveness of phishing awareness training and does not involve any aspect of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.19923",
      "abstract": "We present Prover Agent, a novel AI agent for automated theorem proving that integrates large language models (LLMs) with a formal proof assistant, Lean. Prover Agent coordinates an informal reasoning LLM, a formal prover model, and feedback from Lean while also generating auxiliary lemmas to assist in discovering the overall proof strategy. It achieves an 86.1% success rate on the MiniF2F benchmark, establishing a new state-of-the-art among methods using small language models (SLMs) with a much lower sample budget than previous approaches. We also present case studies illustrating how these generated lemmas contribute to solving challenging problems.",
      "authors": [
        "Kaito Baba",
        "Chaoran Liu",
        "Shuhei Kurita",
        "Akiyoshi Sannai"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19923",
        "HTML": "https://arxiv.org/html/2506.19923",
        "PDF": "https://arxiv.org/pdf/2506.19923"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:01:52 GMT",
          "size": "91kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Prover Agent: An Agent-based Framework for Formal Mathematical Proofs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes an AI framework for theorem proving using LLMs but does not mention any contributions related to LLM training data construction or processing."
      }
    },
    {
      "id": "2506.19929",
      "abstract": "Bearing faults in rotating machinery can lead to significant operational disruptions and maintenance costs. Modern methods for bearing fault diagnosis rely heavily on vibration analysis and machine learning techniques, which often require extensive labeled data and may not adapt well to dynamic environments. This study explores the feasibility of reinforcement learning (RL), specifically Deep Q-Networks (DQNs), for bearing fault classification tasks in machine condition monitoring to enhance the accuracy and adaptability of bearing fault diagnosis. The results demonstrate that while RL models developed in this study can match the performance of traditional supervised learning models under controlled conditions, they excel in adaptability when equipped with optimized reward structures. However, their computational demands highlight areas for further improvement. These findings demonstrate RL's potential to complement traditional methods, paving the way for adaptive diagnostic frameworks.",
      "authors": [
        "Efe \\c{C}ak{\\i}r and Patrick Dumond"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19929",
        "HTML": "https://arxiv.org/html/2506.19929",
        "PDF": "https://arxiv.org/pdf/2506.19929"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:06:57 GMT",
          "size": "536kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A Comparative Analysis of Reinforcement Learning and Conventional Deep Learning Approaches for Bearing Fault Diagnosis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on applying reinforcement learning for bearing fault diagnosis and does not address the processing or construction of LLM training data."
      }
    },
    {
      "id": "2506.19934",
      "abstract": "Cybersecurity is one of the foremost challenges facing the world of cloud computing. Recently, the widespread adoption of smart devices in cloud computing environments that provide Internet-based services has become prevalent. Therefore, it is essential to consider the security threats in these environments. The use of intrusion detection systems can mitigate the vulnerabilities of these systems. Furthermore, hybrid intrusion detection systems can provide better protection compared to conventional intrusion detection systems. These systems manage issues related to complexity, dimensionality, and performance. This research aims to propose a Hybrid Intrusion Detection System (HyIDS) that identifies and mitigates initial threats. The main innovation of this research is the introduction of a new method for hybrid intrusion detection systems (HyIDS). For this purpose, an Energy-Valley Optimizer (EVO) is used to select an optimal feature set, which is then classified using supervised machine learning models. The proposed approach is evaluated using the CIC_DDoS2019, CSE_CIC_DDoS2018, and NSL-KDD datasets. For evaluation and testing, the proposed system has been run for a total of 32 times. The results of the proposed approach are compared with the Grey Wolf Optimizer (GWO). With the CIC_DDoS2019 dataset, the D_TreeEVO model achieves an accuracy of 99.13% and a detection rate of 98.941%. Furthermore, this result reaches 99.78% for the CSE_CIC_DDoS2018 dataset. In comparison to NSL-KDD, it has an accuracy of 99.50% and a detection rate (DT) of 99.48%. For feature selection, EVO outperforms GWO. The results of this research indicate that EVO yields better results as an optimizer for HyIDS performance.",
      "authors": [
        "Maryam Mahdi Al-Husseini"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19934",
        "HTML": "https://arxiv.org/html/2506.19934",
        "PDF": "https://arxiv.org/pdf/2506.19934"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:19:02 GMT",
          "size": "4436kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A Hybrid Intrusion Detection System with a New Approach to Protect the Cybersecurity of Cloud Computing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on a hybrid intrusion detection system using machine learning models for cybersecurity in cloud computing, not on LLM training data processing."
      }
    },
    {
      "id": "2506.19937",
      "abstract": "While analyzing the importance of features has become ubiquitous in interpretable machine learning, the joint signal from a group of related features is sometimes overlooked or inadvertently excluded. Neglecting the joint signal could bypass a critical insight: in many instances, the most significant predictors are not isolated features, but rather the combined effect of groups of features. This can be especially problematic for datasets that contain natural groupings of features, including multimodal datasets. This paper introduces a novel approach to determine the importance of a group of features for Generalized Additive Models (GAMs) that is efficient, requires no model retraining, allows defining groups posthoc, permits overlapping groups, and remains meaningful in high-dimensional settings. Moreover, this definition offers a parallel with explained variation in statistics. We showcase properties of our method on three synthetic experiments that illustrate the behavior of group importance across various data regimes. We then demonstrate the importance of groups of features in identifying depressive symptoms from a multimodal neuroscience dataset, and study the importance of social determinants of health after total hip arthroplasty. These two case studies reveal that analyzing group importance offers a more accurate, holistic view of the medical issues compared to a single-feature analysis.",
      "authors": [
        "Tomas M. Bosschieter",
        "Luis Franca",
        "Jessica Wolk",
        "Yiyuan Wu",
        "Bella Mehta",
        "Joseph Dehoney",
        "Orsolya Kiss",
        "Fiona C. Baker",
        "Qingyu Zhao",
        "Rich Caruana",
        "Kilian M. Pohl"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19937",
        "HTML": "https://arxiv.org/html/2506.19937",
        "PDF": "https://arxiv.org/pdf/2506.19937"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:25:24 GMT",
          "size": "986kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "The Most Important Features in Generalized Additive Models Might Be Groups of Features",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research talks about feature group importance in Generalized Additive Models, which is not related to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.19939",
      "abstract": "Application rate errors when using self-propelled agricultural sprayers for agricultural production remain a concern. Among other factors, spray boom instability is one of the major contributors to application errors. Spray booms' width of 38m, combined with 30 kph driving speeds, varying terrain, and machine dynamics when maneuvering complex field boundaries, make controls of these booms very complex. However, there is no quantitative knowledge on the extent of boom movement to systematically develop a solution that might include boom designs and responsive boom control systems. Therefore, this study was conducted to develop an automated computer vision system to quantify the boom movement of various agricultural sprayers. A computer vision system was developed to track a target on the edge of the sprayer boom in real time. YOLO V7, V8, and V11 neural network models were trained to track the boom's movements in field operations to quantify effective displacement in the vertical and transverse directions. An inclinometer sensor was mounted on the boom to capture boom angles and validate the neural network model output. The results showed that the model could detect the target with more than 90 percent accuracy, and distance estimates of the target on the boom were within 0.026 m of the inclinometer sensor data. This system can quantify the boom movement on the current sprayer and potentially on any other sprayer with minor modifications. The data can be used to make design improvements to make sprayer booms more stable and achieve greater application accuracy.",
      "authors": [
        "Aryan Singh Dalal",
        "Sidharth Rai",
        "Rahul Singh",
        "Treman Singh Kaloya",
        "Rahul Harsha Cheppally",
        "and Ajay Sharda"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19939",
        "HTML": "https://arxiv.org/html/2506.19939",
        "PDF": "https://arxiv.org/pdf/2506.19939"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:30:18 GMT",
          "size": "1055kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Computer Vision based Automated Quantification of Agricultural Sprayers Boom Displacement",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about developing a computer vision system for agricultural sprayer boom displacement, not related to LLM training data engineering or processing."
      }
    },
    {
      "id": "2506.19943",
      "abstract": "The Domain Name System (DNS) plays a foundational role in Internet infrastructure, yet its core protocols remain vulnerable to compromise by quantum adversaries. As cryptographically relevant quantum computers become a realistic threat, ensuring DNS confidentiality, authenticity, and integrity in the post-quantum era is imperative. In this paper, we present a comprehensive system-level study of post-quantum DNS security across three widely deployed mechanisms: DNSSEC, DNS-over-TLS (DoT), and DNS-over-HTTPS (DoH). We propose Post-Quantum Cryptographic (PQC)-DNS, a unified framework for benchmarking DNS security under legacy, post-quantum, and hybrid cryptographic configurations. Our implementation leverages the Open Quantum Safe (OQS) libraries and integrates lattice- and hash-based primitives into BIND9 and TLS 1.3 stacks. We formalize performance and threat models and analyze the impact of post-quantum key encapsulation and digital signatures on end-to-end DNS resolution. Experimental results on a containerized testbed reveal that lattice-based primitives such as Module-Lattice-Based Key-Encapsulation Mechanism (MLKEM) and Falcon offer practical latency and resource profiles, while hash-based schemes like SPHINCS+ significantly increase message sizes and processing overhead. We also examine security implications including downgrade risks, fragmentation vulnerabilities, and susceptibility to denial-of-service amplification. Our findings inform practical guidance for deploying quantum-resilient DNS and contribute to the broader effort of securing core Internet protocols for the post-quantum future.",
      "authors": [
        "Juyoul Lee",
        "Sanzida Hoque",
        "Abdullah Aydeger",
        "Engin Zeydan"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19943",
        "HTML": "https://arxiv.org/html/2506.19943",
        "PDF": "https://arxiv.org/pdf/2506.19943"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:35:24 GMT",
          "size": "1852kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Quantum-Resistant Domain Name System: A Comprehensive System-Level Study",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about enhancing the security of DNS using post-quantum cryptographic techniques and does not address any aspect of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.19944",
      "abstract": "We introduce a hybrid high-order method for approximating the ground state of the nonlinear Gross--Pitaevskii eigenvalue problem. Optimal convergence rates are proved for the ground state approximation, as well as for the associated eigenvalue and energy approximations. Unlike classical conforming methods, which inherently provide upper bounds on the ground state energy, the proposed approach gives rise to guaranteed and asymptotically exact lower energy bounds. Importantly, and in contrast to previous works, they are obtained directly without the need of post-processing, leading to more accurate guaranteed lower energy bounds in practice.",
      "authors": [
        "Moritz Hauck",
        "Yizhou Liang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19944",
        "HTML": "https://arxiv.org/html/2506.19944",
        "PDF": "https://arxiv.org/pdf/2506.19944"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:36:45 GMT",
          "size": "1307kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A Hybrid High-Order Method for the Gross--Pitaevskii Eigenvalue Problem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of this paper is on mathematical methods for solving the Gross-Pitaevskii eigenvalue problem, which is unrelated to training data processing for LLMs."
      }
    },
    {
      "id": "2506.19947",
      "abstract": "Channel hopping (CS) communication systems must adapt to interference changes in the wireless network and to node mobility for maintaining throughput efficiency. Optimal scheduling requires up-to-date network state information (i.e., of channel occupancy) to select non-overlapping channels for links in interference regions. However, state sharing among nodes introduces significant communication overhead, especially as network size or node mobility scale, thereby decreasing throughput efficiency of already capacity-limited networks. In this paper, we eschew state sharing while adapting the CS schedule based on a learning-based channel occupancy prediction. We propose the MiLAAP attention-based prediction framework for machine learning models of spectral, spatial, and temporal dependencies among network nodes. MiLAAP uses a self-attention mechanism that lets each node capture the temporospectral CS pattern in its interference region and accordingly predict the channel occupancy state within that region. Notably, the prediction relies only on locally and passively observed channel activities, and thus introduces no communication overhead. To deal with node mobility, MiLAAP also uses a multi-head self-attention mechanism that lets each node locally capture the spatiotemporal dependencies on other network nodes that can interfere with it and accordingly predict the motion trajectory of those nodes. Detecting nodes that enter or move outside the interference region is used to further improve the prediction accuracy of channel occupancy. We show that for dynamic networks that use local CS sequences to support relatively long-lived flow traffics, the channel state prediction accuracy of MiLAAP is remarkably ~100% across different node mobility patterns and it achieves zero-shot generalizability across different periods of CS sequences.",
      "authors": [
        "Yung-Fu Chen",
        "Anish Arora"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19947",
        "HTML": "https://arxiv.org/html/2506.19947",
        "PDF": "https://arxiv.org/pdf/2506.19947"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:45:51 GMT",
          "size": "1214kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "MILAAP: Mobile Link Allocation via Attention-based Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for predicting channel occupancy in wireless networks, which is not related to the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.19955",
      "abstract": "Density map estimation has become the mainstream paradigm in crowd counting. However, most existing methods overlook the extreme sparsity of ground-truth density maps. In real-world crowd scenes, the vast majority of spatial regions (often over 95%) contain no people, leading to heavily imbalanced count distributions. Ignoring this imbalance can bias models toward overestimating dense regions and underperforming in sparse areas. Furthermore, most loss functions used in density estimation are majorly based on MSE and implicitly assume Gaussian distributions, which are ill-suited for modeling discrete, non-negative count data. In this paper, we propose EBC-ZIP, a crowd counting framework that models the spatial distribution of counts using a Zero-Inflated Poisson (ZIP) regression formulation. Our approach replaces the traditional regression loss with the negative log-likelihood of the ZIP distribution, enabling better handling of zero-heavy distributions while preserving count accuracy. Built upon the recently proposed Enhanced Block Classification (EBC) framework, EBC-ZIP inherits EBC's advantages in preserving the discreteness of targets and ensuring training stability, while further improving performance through a more principled probabilistic loss. We also evaluate EBC-ZIP with backbones of varying computational complexity to assess its scalability. Extensive experiments on four crowd counting benchmarks demonstrate that EBC-ZIP consistently outperforms EBC and achieves state-of-the-art results.",
      "authors": [
        "Yiming Ma",
        "Victor Sanchez",
        "Tanaya Guha"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19955",
        "HTML": "https://arxiv.org/html/2506.19955",
        "PDF": "https://arxiv.org/pdf/2506.19955"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:06:22 GMT",
          "size": "25539kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "EBC-ZIP: Improving Blockwise Crowd Counting with Zero-Inflated Poisson Regression",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving crowd counting methods using Zero-Inflated Poisson regression but does not relate to LLM training data processing."
      }
    },
    {
      "id": "2506.19964",
      "abstract": "We report a higher-order neuromorphic Ising machine that exhibits superior scalability compared to architectures based on quadratization, while also achieving state-of-the-art quality and reliability in solutions with competitive time-to-solution metrics. At the core of the proposed machine is an asynchronous autoencoder architecture that captures higher-order interactions by directly manipulating Ising clauses instead of Ising spins, thereby maintaining resource complexity independent of interaction order. Asymptotic convergence to the Ising ground state is ensured by sampling the autoencoder latent space defined by the spins, based on the annealing dynamics of the Fowler-Nordheim quantum mechanical tunneling. To demonstrate the advantages of the proposed higher-order neuromorphic Ising machine, we systematically solved benchmark combinatorial optimization problems such as MAX-CUT and MAX-SAT, comparing the results to those obtained using a second-order Ising machine employing the same annealing process. Our findings indicate that the proposed architecture consistently provides higher quality solutions in shorter time frames compared to the second-order model across multiple runs. Additionally, we show that the techniques based on the sparsity of the interconnection matrix, such as graph coloring, can be effectively applied to higher-order neuromorphic Ising machines, enhancing the solution quality and the time-to-solution. The time-to-solution can be further improved through hardware co-design, as demonstrated in this paper using a field-programmable gate array (FPGA). The results presented in this paper provide further evidence that autoencoders and Fowler-Nordheim annealers are sufficient to achieve reliability and scaling of any-order neuromorphic Ising machines.",
      "authors": [
        "Faiek Ahsan",
        "Saptarshi Maiti",
        "Zihao Chen",
        "Jakob Kaiser",
        "Ankita Nandi",
        "Madhuvanthi Srivatsav",
        "Johannes Schemmel",
        "Andreas G. Andreou",
        "Jason Eshraghian",
        "Chetan Singh Thakur",
        "Shantanu Chakrabartty"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19964",
        "HTML": "https://arxiv.org/html/2506.19964",
        "PDF": "https://arxiv.org/pdf/2506.19964"
      },
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:17:02 GMT",
          "size": "5250kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Higher-Order Neuromorphic Ising Machines -- Autoencoders and Fowler-Nordheim Annealers are all you need for Scalability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper describes the development of a neuromorphic Ising machine for optimization problems, unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.19967",
      "abstract": "Large Language Models (LLMs) have achieved impressive capabilities in language understanding and generation, yet they continue to underperform on knowledge-intensive reasoning tasks due to limited access to structured context and multi-hop information. Retrieval-Augmented Generation (RAG) partially mitigates this by grounding generation in retrieved context, but conventional RAG and GraphRAG methods often fail to capture relational structure across nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel framework that enhances LLM-based graph reasoning by applying inference-time compute scaling. Our method combines sequential scaling with deep chain-of-thought graph traversal, and parallel scaling with majority voting over sampled trajectories within an interleaved reasoning-execution loop. Experiments on the GRBench benchmark demonstrate that our approach significantly improves multi-hop question answering performance, achieving substantial gains over both traditional GraphRAG and prior graph traversal baselines. These findings suggest that inference-time scaling is a practical and architecture-agnostic solution for structured knowledge reasoning with LLMs",
      "authors": [
        "Travis Thompson",
        "Seung-Hwan Lim",
        "Paul Liu",
        "Ruoying He",
        "Dongkuan Xu"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19967",
        "HTML": "https://arxiv.org/html/2506.19967",
        "PDF": "https://arxiv.org/pdf/2506.19967"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:31:03 GMT",
          "size": "4039kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for improving multi-hop question answering on knowledge graphs using LLMs but does not address LLM training data processing."
      }
    },
    {
      "id": "2506.19968",
      "abstract": "Multi-legged robots deployed in complex missions are susceptible to physical damage in their legs, impairing task performance and potentially compromising mission success. This letter presents a rapid, training-free damage recovery algorithm for legged robots subject to partial or complete loss of functional legs. The proposed method first stabilizes locomotion by generating a new gait sequence and subsequently optimally reconfigures leg gaits via a developed differential evolution algorithm to maximize forward progression while minimizing body rotation and lateral drift. The algorithm successfully restores locomotion in a 24-degree-of-freedom hexapod within one hour, demonstrating both high efficiency and robustness to structural damage.",
      "authors": [
        "Sahand Farghdani and Robin Chhabra"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19968",
        "HTML": "https://arxiv.org/html/2506.19968",
        "PDF": "https://arxiv.org/pdf/2506.19968"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:32:00 GMT",
          "size": "1188kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Evolutionary Gait Reconfiguration in Damaged Legged Robots",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with gait reconfiguration in legged robots and does not pertain to LLM training data processing."
      }
    },
    {
      "id": "2506.19972",
      "abstract": "Cloud computing drives innovation but also poses significant environmental challenges due to its high-energy consumption and carbon emissions. Data centers account for 2-4% of global energy usage, and the ICT sector's share of electricity consumption is projected to reach 40% by 2040. As the goal of achieving net-zero emissions by 2050 becomes increasingly urgent, there is a growing need for more efficient and transparent solutions, particularly for private cloud infrastructures, which are utilized by 87% of organizations, despite the dominance of public-cloud systems.\n  This study evaluates the MAIZX framework, designed to optimize cloud operations and reduce carbon footprint by dynamically ranking resources, including data centers, edge computing nodes, and multi-cloud environments, based on real-time and forecasted carbon intensity, Power Usage Effectiveness (PUE), and energy consumption. Leveraging a flexible ranking algorithm, MAIZX achieved an 85.68% reduction in CO2 emissions compared to baseline hypervisor operations. Tested across geographically distributed data centers, the framework demonstrates scalability and effectiveness, directly interfacing with hypervisors to optimize workloads in private, hybrid, and multi-cloud environments. MAIZX integrates real-time data on carbon intensity, power consumption, and carbon footprint, as well as forecasted values, into cloud management, providing a robust tool for enhancing climate performance potential while maintaining operational efficiency.",
      "authors": [
        "Federico Ruilova",
        "Ernst Gunnar Gran",
        "Sven-Arne Reinemo"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19972",
        "HTML": "https://arxiv.org/html/2506.19972",
        "PDF": "https://arxiv.org/pdf/2506.19972"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:40:09 GMT",
          "size": "244kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "MAIZX: A Carbon-Aware Framework for Optimizing Cloud Computing Emissions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on optimizing cloud computing emissions and does not involve any aspect of LLM training data processing."
      }
    },
    {
      "id": "2506.19974",
      "abstract": "Degeneracy is the ability of structurally different elements to perform the same function or yield the same output under certain constraints. In contrast to redundancy, which implies identical backups, degeneracy allows diverse components to step in and perform the same or similar role. Mathematically, it is about mapping multiple distinct elements into the same function. In a degenerate system, failure in one part can be compensated by others not structurally linked. System functions are distributed within the system itself or the entire network. This renders faster and more adaptive recovery. In this work, we define and formulate several novel metrics for resource fungibility to address robustness in networks (static/mobile/dynamic).",
      "authors": [
        "Indrakshi Dey and Nicola Marchetti"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19974",
        "HTML": "https://arxiv.org/html/2506.19974",
        "PDF": "https://arxiv.org/pdf/2506.19974"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:43:49 GMT",
          "size": "6kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Notes on Degeneracy and Robustness",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses metrics for resource fungibility and robustness in networks without any relation to LLM training data processing or data engineering for LLMs."
      }
    },
    {
      "id": "2506.19977",
      "abstract": "Understanding which parts of the retrieved context contribute to a large language model's generated answer is essential for building interpretable and trustworthy generative QA systems. We propose a novel framework that formulates context attribution as a combinatorial multi-armed bandit (CMAB) problem. Each context segment is treated as a bandit arm, and we employ Combinatorial Thompson Sampling (CTS) to efficiently explore the exponentially large space of context subsets under a limited query budget. Our method defines a reward function based on normalized token likelihoods, capturing how well a subset of segments supports the original model response. Unlike traditional perturbation-based attribution methods such as SHAP, which sample subsets uniformly and incur high computational costs, our approach adaptively balances exploration and exploitation by leveraging posterior estimates of segment relevance. This leads to substantially improved query efficiency while maintaining high attribution fidelity. Extensive experiments on diverse datasets and LLMs demonstrate that our method achieves competitive attribution quality with fewer model queries.",
      "authors": [
        "Deng Pan",
        "Keerthiram Murugesan",
        "Nuno Moniz and Nitesh Chawla"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19977",
        "HTML": "https://arxiv.org/html/2506.19977",
        "PDF": "https://arxiv.org/pdf/2506.19977"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:47:27 GMT",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Context Attribution with Multi-Armed Bandit Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a framework for context attribution in generative QA systems and does not pertain to LLM training data processing or engineering tasks."
      }
    },
    {
      "id": "2506.19984",
      "abstract": "Multi-legged robots (MLRs) are vulnerable to leg damage during complex missions, which can impair their performance. This paper presents a self-modeling and damage identification algorithm that enables autonomous adaptation to partial or complete leg loss using only data from a low-cost IMU. A novel FFT-based filter is introduced to address time-inconsistent signals, improving damage detection by comparing body orientation between the robot and its model. The proposed method identifies damaged legs and updates the robot's model for integration into its control system. Experiments on uneven terrain validate its robustness and computational efficiency.",
      "authors": [
        "Sahand Farghdani and Mili Patel and Robin Chhabra"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19984",
        "HTML": "https://arxiv.org/html/2506.19984",
        "PDF": "https://arxiv.org/pdf/2506.19984"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:57:46 GMT",
          "size": "828kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Robust Embodied Self-Identification of Morphology in Damaged Multi-Legged Robots",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a self-modeling and damage identification algorithm for multi-legged robots, which does not relate to LLM training data processing or any aspect of developing or processing large language models."
      }
    },
    {
      "id": "2506.19991",
      "abstract": "The Euler Characteristic Transform (ECT) is a robust method for shape classification. It takes an embedded shape and, for each direction, computes a piecewise constant function representing the Euler Characteristic of the shape's sublevel sets, which are defined by the height function in that direction. It has applications in TDA inverse problems, such as shape reconstruction, and is also employed with machine learning methodologies. In this paper, we define a distance between the ECTs of two distinct geometric embeddings of the same abstract simplicial complex and provide an upper bound for this distance. The Super Lifted Euler Characteristic Transform (SELECT), a related construction, extends the ECT to scalar fields defined on shapes. We establish a similar distance bound for SELECT, specifically when applied to fields defined on embedded simplicial complexes.",
      "authors": [
        "Jasmine George and Oscar Lledo Osborn and Elizabeth Munch and Messiah Ridgley II and Elena Xinyi Wang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19991",
        "HTML": "https://arxiv.org/html/2506.19991",
        "PDF": "https://arxiv.org/pdf/2506.19991"
      },
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:21:15 GMT",
          "size": "325kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "On the Stability of the Euler Characteristic Transform for a Perturbed Embedding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the Euler Characteristic Transform for shape classification within topological data analysis, which is unrelated to LLM training data engineering or processing."
      }
    },
    {
      "id": "2506.19995",
      "abstract": "Augmentative and alternative communication (AAC) is a field of research and practice that works with people who have a communication disability. One form AAC can take is a high-tech tool, such as a software-based communication system. Like all user interfaces, these systems must be designed and it is critical to include AAC users in the design process for their systems. A participatory design approach can include AAC users in the design process, but modifications may be necessary to make these methods more accessible. We present a two-part design process we are investigating for improving the participatory design for high-tech AAC systems. We discuss our plans to refine the accessibility of this process based on participant feedback.",
      "authors": [
        "Blade Frisch",
        "Keith Vertanen"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19995",
        "HTML": "https://arxiv.org/html/2506.19995",
        "PDF": "https://arxiv.org/pdf/2506.19995"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:28:27 GMT",
          "size": "148kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Refining Participatory Design for AAC Users",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses participatory design methods for AAC systems and does not pertain to LLM training data engineering, preparation, or processing."
      }
    },
    {
      "id": "2506.19997",
      "abstract": "Generalizing deep reinforcement learning agents to unseen environments remains a significant challenge. One promising solution is Unsupervised Environment Design (UED), a co-evolutionary framework in which a teacher adaptively generates tasks with high learning potential, while a student learns a robust policy from this evolving curriculum. Existing UED methods typically measure learning potential via regret, the gap between optimal and current performance, approximated solely by value-function loss. Building on these approaches, we introduce the transition prediction error as an additional term in our regret approximation. To capture how training on one task affects performance on others, we further propose a lightweight metric called co-learnability. By combining these two measures, we present Transition-aware Regret Approximation with Co-learnability for Environment Design (TRACED). Empirical evaluations show that TRACED yields curricula that improve zero-shot generalization across multiple benchmarks while requiring up to 2x fewer environment interactions than strong baselines. Ablation studies confirm that the transition prediction error drives rapid complexity ramp-up and that co-learnability delivers additional gains when paired with the transition prediction error. These results demonstrate how refined regret approximation and explicit modeling of task relationships can be leveraged for sample-efficient curriculum design in UED.",
      "authors": [
        "Geonwoo Cho",
        "Jaegyun Im",
        "Jihwan Lee",
        "Hojun Yi",
        "Sejin Kim",
        "Sundong Kim"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19997",
        "HTML": "https://arxiv.org/html/2506.19997",
        "PDF": "https://arxiv.org/pdf/2506.19997"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:29:24 GMT",
          "size": "1346kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on curriculum design for deep reinforcement learning using transition-aware regret approximation and co-learnability metrics, which are not related to LLM training data processing."
      }
    },
    {
      "id": "2506.19999",
      "abstract": "Reading is a process that unfolds across space and time, alternating between fixations where a reader focuses on a specific point in space, and saccades where a reader rapidly shifts their focus to a new point. An ansatz of psycholinguistics is that modeling a reader's fixations and saccades yields insight into their online sentence processing. However, standard approaches to such modeling rely on aggregated eye-tracking measurements and models that impose strong assumptions, ignoring much of the spatio-temporal dynamics that occur during reading. In this paper, we propose a more general probabilistic model of reading behavior, based on a marked spatio-temporal point process, that captures not only how long fixations last, but also where they land in space and when they take place in time. The saccades are modeled using a Hawkes process, which captures how each fixation excites the probability of a new fixation occurring near it in time and space. The duration time of fixation events is modeled as a function of fixation-specific predictors convolved across time, thus capturing spillover effects. Empirically, our Hawkes process model exhibits a better fit to human saccades than baselines. With respect to fixation durations, we observe that incorporating contextual surprisal as a predictor results in only a marginal improvement in the model's predictive accuracy. This finding suggests that surprisal theory struggles to explain fine-grained eye movements.",
      "authors": [
        "Francesco Ignazio Re",
        "Andreas Opedal",
        "Glib Manaiev",
        "Mario Giulianelli",
        "Ryan Cotterell"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19999",
        "HTML": "https://arxiv.org/html/2506.19999",
        "PDF": "https://arxiv.org/pdf/2506.19999"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:39:21 GMT",
          "size": "4497kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a model for reading behavior using spatio-temporal point processes. It does not relate to LLM training data processing but focuses on psycholinguistics and eye-tracking modeling."
      }
    },
    {
      "id": "2506.20000",
      "abstract": "We propose Guardian-FC, a novel two-layer framework for privacy preserving federated computing that unifies safety enforcement across diverse privacy preserving mechanisms, including cryptographic back-ends like fully homomorphic encryption (FHE) and multiparty computation (MPC), as well as statistical techniques such as differential privacy (DP). Guardian-FC decouples guard-rails from privacy mechanisms by executing plug-ins (modular computation units), written in a backend-neutral, domain-specific language (DSL) designed specifically for federated computing workflows and interchangeable Execution Providers (EPs), which implement DSL operations for various privacy back-ends. An Agentic-AI control plane enforces a finite-state safety loop through signed telemetry and commands, ensuring consistent risk management and auditability. The manifest-centric design supports fail-fast job admission and seamless extensibility to new privacy back-ends. We present qualitative scenarios illustrating backend-agnostic safety and a formal model foundation for verification. Finally, we outline a research agenda inviting the community to advance adaptive guard-rail tuning, multi-backend composition, DSL specification development, implementation, and compiler extensibility alongside human-override usability.",
      "authors": [
        "Narasimha Raghavan Veeraragavan",
        "Jan Franz Nyg{\\aa}rd"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20000",
        "HTML": "https://arxiv.org/html/2506.20000",
        "PDF": "https://arxiv.org/pdf/2506.20000"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:39:49 GMT",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research presents a privacy-preserving federated computing framework. It involves safety and privacy aspects of federated systems rather than any specific processing of LLM training data."
      }
    },
    {
      "id": "2506.20007",
      "abstract": "We develop a variant of a tensor reduced-order model (tROM) for the parameterized shallow-water dam-break problem. This hyperbolic system presents multiple challenges for model reduction, including a slow decay of the Kolmogorov $N$-width of the solution manifold, shock formation, and the loss of smooth solution dependence on parameters. These issues limit the performance of traditional Proper Orthogonal Decomposition based ROMs. Our tROM approach, based on a low-rank tensor decomposition, builds a parameter-to-solution map from high-fidelity snapshots and constructs localized reduced bases via a local POD procedure. We apply this method to both dry-bed and wet-bed problem setups, showing that the non-interpolatory variant of the tROM, combined with Chebyshev sampling near critical parameter values, effectively captures parameter-dependent behavior and significantly outperforms standard POD-ROMs. This is especially evident in the wet-bed case, where POD-ROMs exhibit poor resolution of shock waves and spurious oscillations.",
      "authors": [
        "Md Rezwan Bin Mizan",
        "Maxim Olshanskii",
        "Ilya Timofeyev"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20007",
        "HTML": "https://arxiv.org/html/2506.20007",
        "PDF": "https://arxiv.org/pdf/2506.20007"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:54:10 GMT",
          "size": "1365kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A parametric tensor ROM for the shallow water dam break problem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses a tensor reduced-order model for a dam-break problem, focusing on model reduction and parameter dependence, unrelated to LLM training data processing or LLM data engineering."
      }
    },
    {
      "id": "2506.20010",
      "abstract": "Huawei's cloud-native database system GaussDB for MySQL (also known as Taurus) stores data in a separate storage layer consisting of a pool of storage servers. Each server has considerable compute power making it possible to push data reduction operations (selection, projection, and aggregation) close to storage. This paper describes the design and implementation of near data processing (NDP) in Taurus. NDP has several benefits: it reduces the amount of data shipped over the network; frees up CPU capacity in the compute layer; and reduces query run time, thereby enabling higher system throughput. Experiments with the TPCH benchmark (100 GB) showed that 18 out of 22 queries benefited from NDP; data shipped was reduced by 63 percent; and CPU time by 50 percent. On Q15 the impact was even higher: data shipped was reduced by 98 percent; CPU time by 91 percent; and run time by 80 percent.",
      "authors": [
        "Shu Lin",
        "Arunprasad P. Marathe",
        "Per-\\.Ake Larson",
        "Chong Chen",
        "Calvin Sun",
        "Paul Lee",
        "Weidong Yu"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20010",
        "HTML": "https://arxiv.org/html/2506.20010",
        "PDF": "https://arxiv.org/pdf/2506.20010"
      },
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:57:32 GMT",
          "size": "394kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Near Data Processing in Taurus Database",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about near data processing in a database system and does not address any aspect of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20011",
      "abstract": "Future electrical grids will require new ways to identify faults as inverters are not capable of supplying large fault currents to support existing fault detection methods and because distributed resources may feed faults from the edge of the grid. This paper proposes the use of real-time system identification for online power-system fault detection. Specifically, we implement Recursive ARX (rARX) system identification on a grid-connected inverter. Experiments demonstrate that the proposed rARX method is able to both detect large faults quickly, and distinguish between high-impedance faults and large load increases. These results indicate that rARX grid-edge fault detection is a promising research direction for improving the reliability and safety of modern electric grids.",
      "authors": [
        "Soufiane El Yaagoubi",
        "Keith Moffat",
        "Eduardo Prieto Araujo",
        "Florian D\\\"orfler"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20011",
        "HTML": "https://arxiv.org/html/2506.20011",
        "PDF": "https://arxiv.org/pdf/2506.20011"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:03:56 GMT",
          "size": "2631kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Recursive-ARX for Grid-Edge Fault Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on fault detection in electrical grids using system identification, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20015",
      "abstract": "Neuromorphic computing offers an energy-efficient alternative to conventional deep learning accelerators for real-time time-series processing. However, many edge applications, such as wireless sensing and audio recognition, generate streaming signals with rich spectral features that are not effectively captured by conventional leaky integrate-and-fire (LIF) spiking neurons. This paper investigates a wireless split computing architecture that employs resonate-and-fire (RF) neurons with oscillatory dynamics to process time-domain signals directly, eliminating the need for costly spectral pre-processing. By resonating at tunable frequencies, RF neurons extract time-localized spectral features while maintaining low spiking activity. This temporal sparsity translates into significant savings in both computation and transmission energy. Assuming an OFDM-based analog wireless interface for spike transmission, we present a complete system design and evaluate its performance on audio classification and modulation classification tasks. Experimental results show that the proposed RF-SNN architecture achieves comparable accuracy to conventional LIF-SNNs and ANNs, while substantially reducing spike rates and total energy consumption during inference and communication.",
      "authors": [
        "Dengyu Wu",
        "Jiechen Chen",
        "H. Vincent Poor",
        "Bipin Rajendran",
        "Osvaldo Simeone"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20015",
        "HTML": "https://arxiv.org/html/2506.20015",
        "PDF": "https://arxiv.org/pdf/2506.20015"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:14:59 GMT",
          "size": "2071kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Neuromorphic Wireless Split Computing with Resonate-and-Fire Neurons",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a wireless split computing architecture for time-series data with neuromorphic computing, lacking discussions on large language model training data processing."
      }
    },
    {
      "id": "2506.20016",
      "abstract": "Client heterogeneity poses significant challenges to the performance of Quantum Federated Learning (QFL). To overcome these limitations, we propose a new approach leveraging deep unfolding, which enables clients to autonomously optimize hyperparameters, such as learning rates and regularization factors, based on their specific training behavior. This dynamic adaptation mitigates overfitting and ensures robust optimization in highly heterogeneous environments where standard aggregation methods often fail. Our framework achieves approximately 90% accuracy, significantly outperforming traditional methods, which typically yield around 55% accuracy, as demonstrated through real-time training on IBM quantum hardware and Qiskit Aer simulators. By developing self adaptive fine tuning, the proposed method proves particularly effective in critical applications such as gene expression analysis and cancer detection, enhancing diagnostic precision and predictive modeling within quantum systems. Our results are attributed to convergence-aware, learnable optimization steps intrinsic to the deep unfolded framework, which maintains the generalization. Hence, this study addresses the core limitations of conventional QFL, streamlining its applicability to any complex challenges such as healthcare and genomic research.",
      "authors": [
        "Shanika Iroshi Nanayakkara",
        "Shiva Raj Pokhrel"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20016",
        "HTML": "https://arxiv.org/html/2506.20016",
        "PDF": "https://arxiv.org/pdf/2506.20016"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:17:48 GMT",
          "size": "1226kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "New Insights on Unfolding and Fine-tuning Quantum Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses client heterogeneity challenges in Quantum Federated Learning and does not discuss LLM training data processing or any related engineering stages."
      }
    },
    {
      "id": "2506.20017",
      "abstract": "We study the central All-Pairs Shortest Paths (APSP) problem under the restriction that there are at most $d$ distinct weights on the outgoing edges from every node. For $d=n$ this is the classical (unrestricted) APSP problem that is hypothesized to require cubic time $n^{3-o(1)}$, and at the other extreme, for $d=1$, it is equivalent to the Node-Weighted APSP problem. We present new algorithms that achieve the following results:\n  1. Node-Weighted APSP can be solved in time $\\tilde{O}(n^{(3+\\omega)/2}) = \\tilde{O}(n^{2.686})$, improving on the 15-year-old subcubic bounds $\\tilde{O}(n^{(9+\\omega)/4}) = \\tilde{O}(n^{2.843})$ [Chan; STOC '07] and $\\tilde{O}(n^{2.830})$ [Yuster; SODA '09]. This positively resolves the question of whether Node-Weighted APSP is an ``intermediate'' problem in the sense of having complexity $n^{2.5+o(1)}$ if $\\omega=2$, in which case it also matches an $n^{2.5-o(1)}$ conditional lower bound.\n  2. For up to $d \\leq n^{3-\\omega-\\epsilon}$ distinct weights per node (where $\\epsilon > 0$), the problem can be solved in subcubic time $O(n^{3-f(\\epsilon)})$ (where $f(\\epsilon) > 0$). In particular, assuming that $\\omega = 2$, we can tolerate any sublinear number of distinct weights per node $d \\leq n^{1-\\epsilon}$, whereas previous work [Yuster; SODA '09] could only handle $d \\leq n^{1/2-\\epsilon}$ in subcubic time. This promotes our understanding of the APSP hypothesis showing that the hardest instances must exhaust a linear number of weights per node. Our result also applies to the All-Pairs Exact Triangle problem, thus generalizing a result of Chan and Lewenstein on \"Clustered 3SUM\" from arrays to matrices. Notably, our technique constitutes a rare application of additive combinatorics in graph algorithms.",
      "authors": [
        "Amir Abboud",
        "Nick Fischer",
        "Ce Jin",
        "Virginia Vassilevska Williams",
        "Zoe Xi"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20017",
        "HTML": "https://arxiv.org/html/2506.20017",
        "PDF": "https://arxiv.org/pdf/2506.20017"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:21:25 GMT",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "All-Pairs Shortest Paths with Few Weights per Node",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces algorithms for solving the All-Pairs Shortest Paths problem under certain constraints, with no relation to LLM training data or its processing."
      }
    },
    {
      "id": "2506.20018",
      "abstract": "This paper investigates real-time decision support systems that leverage low-latency AI models, bringing together recent progress in holistic AI-driven decision tools, integration with Edge-IoT technologies, and approaches for effective human-AI teamwork. It looks into how large language models can assist decision-making, especially when resources are limited. The research also examines the effects of technical developments such as DeLLMa, methods for compressing models, and improvements for analytics on edge devices, while also addressing issues like limited resources and the need for adaptable frameworks. Through a detailed review, the paper offers practical perspectives on development strategies and areas of application, adding to the field by pointing out opportunities for more efficient and flexible AI-supported systems. The conclusions set the stage for future breakthroughs in this fast-changing area, highlighting how AI can reshape real-time decision support.",
      "authors": [
        "Zechun Deng",
        "Ziwei Liu",
        "Ziqian Bi",
        "Junhao Song",
        "Chia Xin Liang",
        "Joe Yeong",
        "Junfeng Hao"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20018",
        "HTML": "https://arxiv.org/html/2506.20018",
        "PDF": "https://arxiv.org/pdf/2506.20018"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:22:25 GMT",
          "size": "899kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While examining AI models in decision support systems, it discusses model compression and Edge-IoT integration rather than LLM training data processing or enhancements."
      }
    },
    {
      "id": "2506.20020",
      "abstract": "Reasoning in humans is prone to biases due to underlying motivations like identity protection, that undermine rational decision-making and judgment. This motivated reasoning at a collective level can be detrimental to society when debating critical issues such as human-driven climate change or vaccine safety, and can further aggravate political polarization. Prior studies have reported that large language models (LLMs) are also susceptible to human-like cognitive biases, however, the extent to which LLMs selectively reason toward identity-congruent conclusions remains largely unexplored. Here, we investigate whether assigning 8 personas across 4 political and socio-demographic attributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and proprietary) across two reasoning tasks from human-subject studies -- veracity discernment of misinformation headlines and evaluation of numeric scientific evidence -- we find that persona-assigned LLMs have up to 9% reduced veracity discernment relative to models without personas. Political personas specifically, are up to 90% more likely to correctly evaluate scientific evidence on gun control when the ground truth is congruent with their induced political identity. Prompt-based debiasing methods are largely ineffective at mitigating these effects. Taken together, our empirical findings are the first to suggest that persona-assigned LLMs exhibit human-like motivated reasoning that is hard to mitigate through conventional debiasing prompts -- raising concerns of exacerbating identity-congruent reasoning in both LLMs and humans.",
      "authors": [
        "Saloni Dash",
        "Am\\'elie Reymond",
        "Emma S. Spiro",
        "Aylin Caliskan"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20020",
        "HTML": "https://arxiv.org/html/2506.20020",
        "PDF": "https://arxiv.org/pdf/2506.20020"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:35:17 GMT",
          "size": "1349kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research investigates the cognitive biases and motivated reasoning in LLMs with persona assignments, not focusing on the collection or processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20023",
      "abstract": "Time series imputation models have traditionally been developed using complete datasets with artificial masking patterns to simulate missing values. However, in real-world infrastructure monitoring, practitioners often encounter datasets where large amounts of data are missing and follow complex, heterogeneous patterns. We introduce DIM-SUM, a preprocessing framework for training robust imputation models that bridges the gap between artificially masked training data and real missing patterns. DIM-SUM combines pattern clustering and adaptive masking strategies with theoretical learning guarantees to handle diverse missing patterns actually observed in the data. Through extensive experiments on over 2 billion readings from California water districts, electricity datasets, and benchmarks, we demonstrate that DIM-SUM outperforms traditional methods by reaching similar accuracy with lower processing time and significantly less training data. When compared against a large pre-trained model, DIM-SUM averages 2x higher accuracy with significantly less inference time.",
      "authors": [
        "Ryan Hildebrant",
        "Rahul Bhope",
        "Sharad Mehrotra",
        "Christopher Tull",
        "Nalini Venkatasubramanian"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20023",
        "HTML": "https://arxiv.org/html/2506.20023",
        "PDF": "https://arxiv.org/pdf/2506.20023"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:38:06 GMT",
          "size": "3565kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "DIM-SUM: Dynamic IMputation for Smart Utility Management",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on time series imputation for infrastructure monitoring data with no direct connection to LLM training data processing."
      }
    },
    {
      "id": "2506.20024",
      "abstract": "Diffusion models are a powerful tool for probabilistic forecasting, yet most applications in high-dimensional chaotic systems predict future snapshots one-by-one. This common approach struggles to model complex temporal dependencies and fails to explicitly account for the progressive growth of uncertainty inherent to such systems. While rolling diffusion frameworks, which apply increasing noise to forecasts at longer lead times, have been proposed to address this, their integration with state-of-the-art, high-fidelity diffusion techniques remains a significant challenge. We tackle this problem by introducing Elucidated Rolling Diffusion Models (ERDM), the first framework to successfully unify a rolling forecast structure with the principled, performant design of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM components-its noise schedule, network preconditioning, and Heun sampler-to the rolling forecast setting. The success of this integration is driven by three key contributions: (i) a novel loss weighting scheme that focuses model capacity on the mid-range forecast horizons where determinism gives way to stochasticity; (ii) an efficient initialization strategy using a pre-trained EDM for the initial window; and (iii) a bespoke hybrid sequence architecture for robust spatiotemporal feature extraction under progressive denoising. On 2D Navier-Stokes simulations and ERA5 global weather forecasting at 1.5^\\circ resolution, ERDM consistently outperforms key diffusion-based baselines, including conditional autoregressive EDM. ERDM offers a flexible and powerful general framework for tackling diffusion-based sequence generation problems where modeling escalating uncertainty is paramount. Code is available at: https://github.com/salvaRC/erdm",
      "authors": [
        "Salva R\\\"uhling Cachay",
        "Miika Aittala",
        "Karsten Kreis",
        "Noah Brenowitz",
        "Arash Vahdat",
        "Morteza Mardani",
        "Rose Yu"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20024",
        "HTML": "https://arxiv.org/html/2506.20024",
        "PDF": "https://arxiv.org/pdf/2506.20024"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:44:31 GMT",
          "size": "13183kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses probabilistic weather forecasting using diffusion models and does not discuss LLM training data processing."
      }
    },
    {
      "id": "2506.20025",
      "abstract": "While machine learning models become more capable in discriminative tasks at scale, their ability to overcome biases introduced by training data has come under increasing scrutiny. Previous results suggest that there are two extremes of parameterization with very different behaviors: the population (underparameterized) setting where loss weighting is optimal and the separable overparameterized setting where loss weighting is ineffective at ensuring equal performance across classes. This work explores the regime of last layer retraining (LLR) in which the unseen limited (retraining) data is frequently inseparable and the model proportionately sized, falling between the two aforementioned extremes. We show, in theory and practice, that loss weighting is still effective in this regime, but that these weights \\emph{must} take into account the relative overparameterization of the model.",
      "authors": [
        "Nathan Stromberg",
        "Christos Thrampoulidis",
        "Lalitha Sankar"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20025",
        "HTML": "https://arxiv.org/html/2506.20025",
        "PDF": "https://arxiv.org/pdf/2506.20025"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:48:58 GMT",
          "size": "282kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Thumb on the Scale: Optimal Loss Weighting in Last Layer Retraining",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work explores loss weighting in last layer retraining, relevant to model retraining and optimization, but does not involve LLM training data processing."
      }
    },
    {
      "id": "2506.20030",
      "abstract": "This paper derives polynomial-time approximation schemes for several NP-hard stochastic optimization problems from the algorithmic mechanism design and operations research literatures. The problems we consider involve a principal or seller optimizing with respect to a subsequent choice by an agent or buyer. These include posted pricing for a unit-demand buyer with independent values (Chawla et al., 2007, Cai and Daskalakis, 2011), assortment optimization with independent utilities (Talluri and van Ryzin, 2004), and delegated choice (Khodabakhsh et al., 2024). Our results advance the state of the art for each of these problems. For unit-demand pricing with discrete distributions, our multiplicative PTAS improves on the additive PTAS of Cai and Daskalakis, and we additionally give a PTAS for the unbounded regular case, improving on the latter paper's QPTAS. For assortment optimization, no constant approximation was previously known. For delegated choice, we improve on both the $3$-approximation for the case with no outside option and the super-constant-approximation with an outside option.\n  A key technical insight driving our results is an economically meaningful property we term utility alignment. Informally, a problem is utility aligned if, at optimality, the principal derives most of their utility from realizations where the agent's utility is also high. Utility alignment allows the algorithm designer to focus on maximizing performance on realizations with high agent utility, which is often an algorithmically simpler task. We prove utility alignment results for all the problems mentioned above, including strong results for unit-demand pricing and delegation, as well as a weaker but very broad guarantee that holds for many other problems under very mild conditions.",
      "authors": [
        "Robin Bowers",
        "Marius Garbea",
        "Emmanouil Pountourakis",
        "Samuel Taggart"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20030",
        "HTML": "https://arxiv.org/html/2506.20030",
        "PDF": "https://arxiv.org/pdf/2506.20030"
      },
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:57:19 GMT",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Polynomial-Time Approximation Schemes via Utility Alignment: Unit-Demand Pricing and More",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper derives approximation schemes for NP-hard optimization problems, unrelated to any aspect of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20031",
      "abstract": "Operations in disaster response, search \\& rescue, and military missions that involve multiple agents demand automated processes to support the planning of the courses of action (COA). Moreover, traverse-affecting changes in the environment (rain, snow, blockades, etc.) may impact the expected performance of a COA, making it desirable to have a pool of COAs that are diverse in task distributions across agents. Further, variations in agent capabilities, which could be human crews and/or autonomous systems, present practical opportunities and computational challenges to the planning process. This paper presents a new theoretical formulation and computational framework to generate such diverse pools of COAs for operations with soft variations in agent-task compatibility. Key to the problem formulation is a graph abstraction of the task space and the pool of COAs itself to quantify its diversity. Formulating the COAs as a centralized multi-robot task allocation problem, a genetic algorithm is used for (order-ignoring) allocations of tasks to each agent that jointly maximize diversity within the COA pool and overall compatibility of the agent-task mappings. A graph neural network is trained using a policy gradient approach to then perform single agent task sequencing in each COA, which maximizes completion rates adaptive to task features. Our tests of the COA generation process in a simulated environment demonstrate significant performance gain over a random walk baseline, small optimality gap in task sequencing, and execution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 task operations.",
      "authors": [
        "Prithvi Poddar",
        "Ehsan Tarkesh Esfahani",
        "Karthik Dantu and Souma Chowdhury"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20031",
        "HTML": "https://arxiv.org/html/2506.20031",
        "PDF": "https://arxiv.org/pdf/2506.20031"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:58:30 GMT",
          "size": "4555kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a framework for generating courses of actions in multi-agent scenarios with no focus on processing LLM training data."
      }
    },
    {
      "id": "2506.20036",
      "abstract": "We propose a novel hierarchical reinforcement learning framework for quadruped locomotion over challenging terrain. Our approach incorporates a two-layer hierarchy in which a high-level policy (HLP) selects optimal goals for a low-level policy (LLP). The LLP is trained using an on-policy actor-critic RL algorithm and is given footstep placements as goals. We propose an HLP that does not require any additional training or environment samples and instead operates via an online optimization process over the learned value function of the LLP. We demonstrate the benefits of this framework by comparing it with an end-to-end reinforcement learning (RL) approach. We observe improvements in its ability to achieve higher rewards with fewer collisions across an array of different terrains, including terrains more difficult than any encountered during training.",
      "authors": [
        "Jeremiah Coholich",
        "Muhammad Ali Murtaza",
        "Seth Hutchinson",
        "Zsolt Kira"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20036",
        "HTML": "https://arxiv.org/html/2506.20036",
        "PDF": "https://arxiv.org/pdf/2506.20036"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:19:15 GMT",
          "size": "849kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on hierarchical reinforcement learning for quadruped locomotion and does not address any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.20037",
      "abstract": "Machine learning providers commonly distribute global models to edge devices, which subsequently personalize these models using local data. However, issues such as copyright infringements, biases, or regulatory requirements may require the verifiable removal of certain data samples across all edge devices. Ensuring that edge devices correctly execute such unlearning operations is critical to maintaining integrity.\n  In this work, we introduce a verification framework leveraging zero-knowledge proofs, specifically zk-SNARKs, to confirm data unlearning on personalized edge-device models without compromising privacy. We have developed algorithms explicitly designed to facilitate unlearning operations that are compatible with efficient zk-SNARK proof generation, ensuring minimal computational and memory overhead suitable for constrained edge environments. Furthermore, our approach carefully preserves personalized enhancements on edge devices, maintaining model performance post-unlearning.\n  Our results affirm the practicality and effectiveness of this verification framework, demonstrating verifiable unlearning with minimal degradation in personalization-induced performance improvements. Our methodology ensures verifiable, privacy-preserving, and effective machine unlearning across edge devices.",
      "authors": [
        "Mohammad M Maheri",
        "Alex Davidson",
        "Hamed Haddadi"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20037",
        "HTML": "https://arxiv.org/html/2506.20037",
        "PDF": "https://arxiv.org/pdf/2506.20037"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:24:47 GMT",
          "size": "861kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Verifiable Unlearning on Edge",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work is about machine unlearning on edge devices with privacy preservation and does not involve any contributions related to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20039",
      "abstract": "Team formation and the dynamics of team-based learning have drawn significant interest in the context of Multi-Agent Reinforcement Learning (MARL). However, existing studies primarily focus on unilateral groupings, predefined teams, or fixed-population settings, leaving the effects of algorithmic bilateral grouping choices in dynamic populations underexplored. To address this gap, we introduce a framework for learning two-sided team formation in dynamic multi-agent systems. Through this study, we gain insight into what algorithmic properties in bilateral team formation influence policy performance and generalization. We validate our approach using widely adopted multi-agent scenarios, demonstrating competitive performance and improved generalization in most scenarios.",
      "authors": [
        "Koorosh Moslemi",
        "Chi-Guhn Lee"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20039",
        "HTML": "https://arxiv.org/html/2506.20039",
        "PDF": "https://arxiv.org/pdf/2506.20039"
      },
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:40:05 GMT",
          "size": "278kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Learning Bilateral Team Formation in Cooperative Multi-Agent Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores multi-agent reinforcement learning and team formation, with no mention of LLM training data processing or the data engineering stage."
      }
    },
    {
      "id": "2506.20040",
      "abstract": "Uncovering emergent concepts across transformer layers remains a significant challenge because the residual stream linearly mixes and duplicates information, obscuring how features evolve within large language models. Current research efforts primarily inspect neural representations at single layers, thereby overlooking this cross-layer superposition and the redundancy it introduces. These representations are typically either analyzed directly for activation patterns or passed to probing classifiers that map them to a limited set of predefined concepts. To address these limitations, we propose \\gls{clvqvae}, a framework that uses vector quantization to map representations across layers and in the process collapse duplicated residual-stream features into compact, interpretable concept vectors. Our approach uniquely combines top-$k$ temperature-based sampling during quantization with EMA codebook updates, providing controlled exploration of the discrete latent space while maintaining code-book diversity. We further enhance the framework with scaled-spherical k-means++ for codebook initialization, which clusters by directional similarity rather than magnitude, better aligning with semantic structure in word embedding space.",
      "authors": [
        "Ankur Garg",
        "Xuemin Yu",
        "Hassan Sajjad",
        "Samira Ebrahimi Kahou"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20040",
        "HTML": "https://arxiv.org/html/2506.20040",
        "PDF": "https://arxiv.org/pdf/2506.20040"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:43:36 GMT",
          "size": "3261kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Cross-Layer Discrete Concept Discovery for Interpreting Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research tackles interpreting language models through a novel approach but does not contribute directly to the processing or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20041",
      "abstract": "The classification of imbalanced data streams, which have unequal class distributions, is a key difficulty in machine learning, especially when dealing with multiple classes. While binary imbalanced data stream classification tasks have received considerable attention, only a few studies have focused on multi-class imbalanced data streams. Effectively managing the dynamic imbalance ratio is a key challenge in this domain. This study introduces a novel, robust, and resilient approach to address these challenges by integrating Locality Sensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic Ensemble Diversification (DynED) framework. To the best of our knowledge, we present the first application of LSH-RHP for undersampling in the context of imbalanced non-stationary data streams. The proposed method undersamples the majority classes by utilizing LSH-RHP, provides a balanced training set, and improves the ensemble's prediction performance. We conduct comprehensive experiments on 23 real-world and ten semi-synthetic datasets and compare LSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED outperforms other approaches in terms of both Kappa and mG-Mean effectiveness measures, demonstrating its capability in dealing with multi-class imbalanced non-stationary data streams. Notably, LSH-DynED performs well in large-scale, high-dimensional datasets with considerable class imbalances and demonstrates adaptation and robustness in real-world circumstances. To motivate our design, we review existing methods for imbalanced data streams, outline key challenges, and offer guidance for future work. For the reproducibility of our results, we have made our implementation available on GitHub.",
      "authors": [
        "Soheil Abadifard and Fazli Can"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20041",
        "HTML": "https://arxiv.org/html/2506.20041",
        "PDF": "https://arxiv.org/pdf/2506.20041"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:46:47 GMT",
          "size": "4830kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a framework for classifying imbalanced data streams, which does not relate to the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20045",
      "abstract": "Deep object pose estimators are notoriously overconfident. A grasping agent that both estimates the 6-DoF pose of a target object and predicts the uncertainty of its own estimate could avoid task failure by choosing not to act under high uncertainty. Even though object pose estimation improves and uncertainty quantification research continues to make strides, few studies have connected them to the downstream task of robotic grasping. We propose a method for training lightweight, deep networks to predict whether a grasp guided by an image-based pose estimate will succeed before that grasp is attempted. We generate training data for our networks via object pose estimation on real images and simulated grasping. We also find that, despite high object variability in grasping trials, networks benefit from training on all objects jointly, suggesting that a diverse variety of objects can nevertheless contribute to the same goal.",
      "authors": [
        "Eric C. Joyce",
        "Qianwen Zhao",
        "Nathaniel Burgdorfer",
        "Long Wang",
        "Philippos Mordohai"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20045",
        "HTML": "https://arxiv.org/html/2506.20045",
        "PDF": "https://arxiv.org/pdf/2506.20045"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:53:54 GMT",
          "size": "2646kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research introduces a method for robotic grasping involving RGB perception and uncertainty prediction. It discusses training data for pose estimation, but not in the context of LLMs or relevant training data processing tasks."
      }
    },
    {
      "id": "2506.20046",
      "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance in the healthcare domain. However, what remained challenging is quantifying the predictive uncertainty of GNNs, which is an important aspect of trustworthiness in clinical settings. While Bayesian and ensemble methods can be used to quantify uncertainty, they are computationally expensive. Additionally, the disagreement metric used by ensemble methods to compute uncertainty cannot capture the diversity of models in an ensemble network. In this paper, we propose a novel method, based on knowledge distillation, to quantify GNNs' uncertainty more efficiently and with higher precision. We apply self-distillation, where the same network serves as both the teacher and student models, thereby avoiding the need to train several networks independently. To ensure the impact of self-distillation, we develop an uncertainty metric that captures the diverse nature of the network by assigning different weights to each GNN classifier. We experimentally evaluate the precision, performance, and ability of our approach in distinguishing out-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The evaluation results demonstrate that the proposed method can effectively capture the predictive uncertainty of the model while having performance similar to that of the MC Dropout and ensemble methods. The code is publicly available at https://github.com/tailabTMU/UQ_GNN.",
      "authors": [
        "Hirad Daneshvar",
        "Reza Samavi"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20046",
        "HTML": "https://arxiv.org/html/2506.20046",
        "PDF": "https://arxiv.org/pdf/2506.20046"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:08:31 GMT",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "GNN's Uncertainty Quantification using Self-Distillation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes a method for uncertainty quantification in GNNs using self-distillation, which is unrelated to LLM training data processing or engineering. It doesn't contribute new methods for LLM data preparation."
      }
    },
    {
      "id": "2506.20049",
      "abstract": "We present a novel approach for enhancing robotic exploration by using generative occupancy mapping. We introduce SceneSense, a diffusion model designed and trained for predicting 3D occupancy maps given partial observations. Our proposed approach probabilistically fuses these predictions into a running occupancy map in real-time, resulting in significant improvements in map quality and traversability. We implement SceneSense onboard a quadruped robot and validate its performance with real-world experiments to demonstrate the effectiveness of the model. In these experiments, we show that occupancy maps enhanced with SceneSense predictions better represent our fully observed ground truth data (24.44% FID improvement around the robot and 75.59% improvement at range). We additionally show that integrating SceneSense-enhanced maps into our robotic exploration stack as a \"drop-in\" map improvement, utilizing an existing off-the-shelf planner, results in improvements in robustness and traversability time. Finally we show results of full exploration evaluations with our proposed system in two dissimilar environments and find that locally enhanced maps provide more consistent exploration results than maps constructed only from direct sensor measurements.",
      "authors": [
        "Lorin Achey",
        "Alec Reed",
        "Brendan Crowe",
        "Bradley Hayes",
        "Christoffer Heckman"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20049",
        "HTML": "https://arxiv.org/html/2506.20049",
        "PDF": "https://arxiv.org/pdf/2506.20049"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:13:44 GMT",
          "size": "16703kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Robust Robotic Exploration and Mapping Using Generative Occupancy Map Synthesis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses robotic exploration and mapping with occupancy maps. It introduces a diffusion model for real-time mapping improvements, which is unrelated to any phase of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20051",
      "abstract": "Retrieval-augmented generation (RAG) enhances large language models by incorporating context retrieved from external knowledge sources. While the effectiveness of the retrieval module is typically evaluated with relevance-based ranking metrics, such metrics may be insufficient to reflect the retrieval's impact on the final RAG result, especially in long-form generation scenarios. We argue that providing a comprehensive retrieval-augmented context is important for long-form RAG tasks like report generation and propose metrics for assessing the context independent of generation. We introduce CRUX, a \\textbf{C}ontrolled \\textbf{R}etrieval-a\\textbf{U}gmented conte\\textbf{X}t evaluation framework designed to directly assess retrieval-augmented contexts. This framework uses human-written summaries to control the information scope of knowledge, enabling us to measure how well the context covers information essential for long-form generation. CRUX uses question-based evaluation to assess RAG's retrieval in a fine-grained manner. Empirical results show that CRUX offers more reflective and diagnostic evaluation. Our findings also reveal substantial room for improvement in current retrieval methods, pointing to promising directions for advancing RAG's retrieval. Our data and code are publicly available to support and advance future research on retrieval.",
      "authors": [
        "Jia-Huei Ju",
        "Suzan Verberne",
        "Maarten de Rijke and Andrew Yates"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20051",
        "HTML": "https://arxiv.org/html/2506.20051",
        "PDF": "https://arxiv.org/pdf/2506.20051"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:17:48 GMT",
          "size": "1885kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Controlled Retrieval-augmented Context Evaluation for Long-form RAG",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating retrieval-augmented contexts for long-form generation tasks, not on the data processing or engineering aspects related to LLM training data."
      }
    },
    {
      "id": "2506.20054",
      "abstract": "We investigate the stability of vector recovery from random linear measurements which have been either clipped or folded. This is motivated by applications where measurement devices detect inputs outside of their effective range.\n  As examples of our main results, we prove sharp lower bounds on the recovery constant for both the declipping and unfolding problems whenever samples are taken according to a uniform distribution on the sphere. Moreover, we show such estimates under (almost) the best possible conditions on both the number of samples and the distribution of the data. We then prove that all of the above results have suitable (effectively) sparse counterparts. In the special case that one restricts the stability analysis to vectors which belong to the unit sphere of $\\mathbb{R}^n$, we show that the problem of declipping directly extends the one-bit compressed sensing results of Oymak-Recht and Plan-Vershynin.",
      "authors": [
        "Pedro Abdalla",
        "Daniel Freeman",
        "Jo\\~ao P. G. Ramos",
        "Mitchell A. Taylor"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20054",
        "HTML": "https://arxiv.org/html/2506.20054",
        "PDF": "https://arxiv.org/pdf/2506.20054"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Metric Geometry (math.MG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:24:05 GMT",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "On sharp stable recovery from clipped and folded measurements",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered on theoretical aspects of vector recovery from modified measurements, unrelated to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20055",
      "abstract": "Online(-only) friendships have become increasingly common in daily lives post-COVID despite debates around their mental health benefits and equivalence to ''real'' relationships. Previous research has reflected a need to understand how online friends engage beyond individual platforms, and the lack of platform-agnostic inquiry limits our ability to fully understand the dynamics of online friendship. We employed an activity-grounded analysis of 25 interviews on lived experiences of close online friendship spanning multiple years. Our findings present unique challenges and strategies in online friendships, such as stigma from real-life circles, an ambivalent relationship with online communities, and counter-theoretical reappropriations of communication technology. This study contributes to HCI research in online communities and social interface design by refocusing prior impressions of strong vs. weak-ties in online social spaces and foregrounding time-stable interactions in design for relationship maintenance through technology. Our work also promotes critical reflection on biased perspectives towards technology-mediated practices and consideration of online friends as an invisible marginalized community.",
      "authors": [
        "Seraphina Yong",
        "Ashlee Milton",
        "Evan Suma Rosenberg",
        "Stevie Chancellor",
        "Svetlana Yarosh"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20055",
        "HTML": "https://arxiv.org/html/2506.20055",
        "PDF": "https://arxiv.org/pdf/2506.20055"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:30:49 GMT",
          "size": "2254kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "\"I'm Petting the Laptop, Which Has You Inside It\": Reflecting on Lived Experiences of Online Friendship",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper studies online friendship dynamics with no connection to LLM training data processing, data engineering, or related techniques."
      }
    },
    {
      "id": "2506.20062",
      "abstract": "AI-powered code assistants are widely used to generate code completions, significantly boosting developer productivity. However, these tools typically present suggestions without explaining their rationale, leaving their decision-making process inscrutable. This opacity hinders developers' ability to critically evaluate the output, form accurate mental models, and build calibrated trust in the system. To address this, we introduce CopilotLens, a novel interactive framework that reframes code completion from a simple suggestion into a transparent, explainable event. CopilotLens operates as an explanation layer that reveals the AI agent's \"thought process\" through a dynamic two-level interface, surfacing everything from its reconstructed high-level plans to the specific codebase context influencing the code. This paper presents the design and rationale of CopilotLens, offering a concrete framework for building future agentic code assistants that prioritize clarity of reasoning over speed of suggestion, thereby fostering deeper comprehension and more robust human-AI collaboration.",
      "authors": [
        "Runlong Ye",
        "Zeling Zhang",
        "Boushra Almazroua",
        "Michael Liut"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20062",
        "HTML": "https://arxiv.org/html/2506.20062",
        "PDF": "https://arxiv.org/pdf/2506.20062"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:50:03 GMT",
          "size": "3294kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Beyond Autocomplete: Designing CopilotLens Towards Transparent and Explainable AI Coding Agents",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses enhancing AI coding assistants with transparency and explainability and does not address LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.20063",
      "abstract": "Background: Software development teams are increasingly diverse, embedded, and cross-disciplinary. Domain experts (DEs) from different disciplines collaborate with professional software developers (SDEs), bringing complementary expertise in creating and maintaining complex production software. However, contested expectations, divergent problem-solving perspectives, and conflicting priorities lead to friction. Aims: This study aims to investigate the dynamics of emerging collaboration of cross-disciplinary software development (CDSD) by exploring the expectations held by DEs and SDEs and understanding how these frictions manifest in practice. Method: We utilize Activity Theory (AT), a well-established socio-technical framework, as an analytical lens in a grounded, empirical investigation, conducted through a mixed-method study involving 24 interviews (12 DEs and 12 SDEs) and a large-scale validation survey with 293 participants (161 DEs and 132 SDEs). Results: We conceptualize and empirically ground the CDSD dynamics. We identified eight expectations held by SDEs and six by DEs. By mapping these expectations to AT components, we revealed 21 frictions in CDSD and illustrated where and how they arise. Conclusions: This study offers a theoretical lens for understanding the dynamics and frictions in CDSD and provides actionable insights for future research, practitioners, and infrastructure design.",
      "authors": [
        "Zixuan Feng",
        "Thomas Zimmermann",
        "Lorenzo Pisani",
        "Christopher Gooley",
        "Jeremiah Wander",
        "Anita Sarma"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20063",
        "HTML": "https://arxiv.org/html/2506.20063",
        "PDF": "https://arxiv.org/pdf/2506.20063"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:51:35 GMT",
          "size": "306kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "When Domains Collide: An Activity Theory Exploration of Cross-Disciplinary Collaboration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores cross-disciplinary collaboration dynamics using Activity Theory, without discussing any aspect of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20066",
      "abstract": "Token merging has emerged as an effective strategy to accelerate Vision Transformers (ViT) by reducing computational costs. However, existing methods primarily rely on the visual token's feature similarity for token merging, overlooking the potential of integrating spatial information, which can serve as a reliable criterion for token merging in the early layers of ViT, where the visual tokens only possess weak visual information. In this paper, we propose ToSA, a novel token merging method that combines both semantic and spatial awareness to guide the token merging process. ToSA leverages the depth image as input to generate pseudo spatial tokens, which serve as auxiliary spatial information for the visual token merging process. With the introduced spatial awareness, ToSA achieves a more informed merging strategy that better preserves critical scene structure. Experimental results demonstrate that ToSA outperforms previous token merging methods across multiple benchmarks on visual and embodied question answering while largely reducing the runtime of the ViT, making it an efficient solution for ViT acceleration. The code will be available at: https://github.com/hsiangwei0903/ToSA",
      "authors": [
        "Hsiang-Wei Huang",
        "Wenhao Chai",
        "Kuang-Ming Chen",
        "Cheng-Yen Yang",
        "Jenq-Neng Hwang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20066",
        "HTML": "https://arxiv.org/html/2506.20066",
        "PDF": "https://arxiv.org/pdf/2506.20066"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:58:20 GMT",
          "size": "1526kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "ToSA: Token Merging with Spatial Awareness",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on accelerating Vision Transformers (ViT) through token merging, particularly with spatial awareness, and does not address any aspect of processing training data for large language models."
      }
    },
    {
      "id": "2506.20070",
      "abstract": "Existing multi-media retrieval models either rely on creating a common subspace with modality-specific representation models or require schema mapping among modalities to measure similarities among multi-media data. Our goal is to avoid the annotation overhead incurred from considering retrieval as a supervised classification task and re-use the pretrained encoders in large language models and vision tasks. We propose \"FemmIR\", a framework to retrieve multimodal results relevant to information needs expressed with multimodal queries by example without any similarity label. Such identification is necessary for real-world applications where data annotations are scarce and satisfactory performance is required without fine-tuning with a common framework across applications. We curate a new dataset called MuQNOL for benchmarking progress on this task. Our technique is based on weak supervision introduced through edit distance between samples: graph edit distance can be modified to consider the cost of replacing a data sample in terms of its properties, and relevance can be measured through the implicit signal from the amount of edit cost among the objects. Unlike metric learning or encoding networks, FemmIR re-uses the high-level properties and maintains the property value and relationship constraints with a multi-level interaction score between data samples and the query example provided by the user. We empirically evaluate FemmIR on a missing person use case with MuQNOL. FemmIR performs comparably to similar retrieval systems in delivering on-demand retrieval results with exact and approximate similarities while using the existing property identifiers in the system.",
      "authors": [
        "KMA Solaiman and Bharat Bhargava"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20070",
        "HTML": "https://arxiv.org/html/2506.20070",
        "PDF": "https://arxiv.org/pdf/2506.20070"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 00:25:08 GMT",
          "size": "888kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multimodal Information Retrieval for Open World with Edit Distance Weak Supervision",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a multimodal information retrieval framework that avoids supervised annotation and leverages pretrained encoders, without mentioning LLM training data processing or related tasks."
      }
    },
    {
      "id": "2506.20073",
      "abstract": "Spatio-temporal data mining plays a pivotal role in informed decision making across diverse domains. However, existing models are often restricted to narrow tasks, lacking the capacity for multi-task inference and complex long-form reasoning that require generation of in-depth, explanatory outputs. These limitations restrict their applicability to real-world, multi-faceted decision scenarios. In this work, we introduce STReason, a novel framework that integrates the reasoning strengths of large language models (LLMs) with the analytical capabilities of spatio-temporal models for multi-task inference and execution. Without requiring task-specific finetuning, STReason leverages in-context learning to decompose complex natural language queries into modular, interpretable programs, which are then systematically executed to generate both solutions and detailed rationales. To facilitate rigorous evaluation, we construct a new benchmark dataset and propose a unified evaluation framework with metrics specifically designed for long-form spatio-temporal reasoning. Experimental results show that STReason significantly outperforms advanced LLM baselines across all metrics, particularly excelling in complex, reasoning-intensive spatio-temporal scenarios. Human evaluations further validate STReason's credibility and practical utility, demonstrating its potential to reduce expert workload and broaden the applicability to real-world spatio-temporal tasks. We believe STReason provides a promising direction for developing more capable and generalizable spatio-temporal reasoning systems.",
      "authors": [
        "Kethmi Hirushini Hettige",
        "Jiahao Ji",
        "Cheng Long",
        "Shili Xiang",
        "Gao Cong",
        "Jingyuan Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20073",
        "HTML": "https://arxiv.org/html/2506.20073",
        "PDF": "https://arxiv.org/pdf/2506.20073"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 00:55:34 GMT",
          "size": "4489kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a multitask reasoning framework combining LLMs with spatio-temporal models, focusing on inference and execution rather than the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20081",
      "abstract": "Retrieval-Augmented Code Generation (RACG) is a critical technique for enhancing code generation by retrieving relevant information. In this work, we conduct an in-depth analysis of code retrieval by systematically masking specific features while preserving code functionality. Our discoveries include: (1) although trained on code, current retrievers heavily rely on surface-level textual features (e.g., docstrings, identifier names), and (2) they exhibit a strong bias towards well-documented code, even if the documentation is irrelevant.Based on our discoveries, we propose SACL, a framework that enriches textual information and reduces bias by augmenting code or structural knowledge with semantic information. Extensive experiments show that SACL substantially improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval / MBPP / SWE-Bench-Lite), which also leads to better code generation performance (e.g., by 4.88% Pass@1 on HumanEval).",
      "authors": [
        "Dhruv Gupta",
        "Gayathri Ganesh Lakshmy",
        "Yiqing Xie"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20081",
        "HTML": "https://arxiv.org/html/2506.20081",
        "PDF": "https://arxiv.org/pdf/2506.20081"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 01:44:28 GMT",
          "size": "3118kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates code retrieval and proposes SACL for enriching code with semantic information, which pertains to code processing rather than LLM training data processing."
      }
    },
    {
      "id": "2506.20082",
      "abstract": "Website Fingerprinting (WF) attacks aim to infer which websites a user is visiting by analyzing traffic patterns, thereby compromising user anonymity. Although this technique has been demonstrated to be effective in controlled experimental environments, it remains largely limited to small-scale scenarios, typically restricted to recognizing website homepages. In practical settings, however, users frequently access multiple subpages in rapid succession, often before previous content fully loads. WebPage Fingerprinting (WPF) generalizes the WF framework to large-scale environments by modeling subpages of the same site as distinct classes. These pages often share similar page elements, resulting in lower inter-class variance in traffic features. Furthermore, we consider multi-tab browsing scenarios, in which a single trace encompasses multiple categories of webpages. This leads to overlapping traffic segments, and similar features may appear in different positions within the traffic, thereby increasing the difficulty of classification. To address these challenges, we propose an attention-driven fine-grained WPF attack, named ADWPF. Specifically, during the training phase, we apply targeted augmentation to salient regions of the traffic based on attention maps, including attention cropping and attention masking. ADWPF then extracts low-dimensional features from both the original and augmented traffic and applies self-attention modules to capture the global contextual patterns of the trace. Finally, to handle the multi-tab scenario, we employ the residual attention to generate class-specific representations of webpages occurring at different temporal positions. Extensive experiments demonstrate that the proposed method consistently surpasses state-of-the-art baselines across datasets of different scales.",
      "authors": [
        "Yali Yuan",
        "Weiyi Zou",
        "Guang Cheng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20082",
        "HTML": "https://arxiv.org/html/2506.20082",
        "PDF": "https://arxiv.org/pdf/2506.20082"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 01:45:55 GMT",
          "size": "1177kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on webpage fingerprinting attacks through traffic analysis, unrelated to the processing of training data for large language models."
      }
    },
    {
      "id": "2506.20083",
      "abstract": "Integrating compositional and symbolic properties into current distributional semantic spaces can enhance the interpretability, controllability, compositionality, and generalisation capabilities of Transformer-based auto-regressive language models (LMs). In this survey, we offer a novel perspective on latent space geometry through the lens of compositional semantics, a direction we refer to as \\textit{semantic representation learning}. This direction enables a bridge between symbolic and distributional semantics, helping to mitigate the gap between them. We review and compare three mainstream autoencoder architectures-Variational AutoEncoder (VAE), Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the distinctive latent geometries they induce in relation to semantic structure and interpretability.",
      "authors": [
        "Yingji Zhang",
        "Danilo S. Carvalho",
        "Andr\\'e Freitas"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20083",
        "HTML": "https://arxiv.org/html/2506.20083",
        "PDF": "https://arxiv.org/pdf/2506.20083"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 01:48:18 GMT",
          "size": "1700kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the integration of compositional and symbolic semantics into distributional semantic spaces via autoencoder architectures, without addressing the processing or engineering of training data for LLMs."
      }
    },
    {
      "id": "2506.20090",
      "abstract": "Predictive maintenance (PdM) has become a crucial element of modern industrial practice. PdM plays a significant role in operational dependability and cost management by decreasing unforeseen downtime and optimizing asset life cycle management. Machine learning and deep learning have enabled more precise forecasts of equipment failure and remaining useful life (RUL). Although many studies have been conducted on PdM, there has not yet been a standalone comparative study between regression- and classification-based approaches. In this review, we look across a range of PdM methodologies, while focusing more strongly on the comparative use of classification and regression methods in prognostics. While regression-based methods typically provide estimates of RUL, classification-based methods present a forecast of the probability of failure across defined time intervals. Through a comprehensive analysis of recent literature, we highlight key advancements, challenges-such as data imbalance and high-dimensional feature spaces-and emerging trends, including hybrid approaches and AI-enabled prognostic systems. This review aims to provide researchers and practitioners with an awareness of the strengths and compromises of various PdM methods and to help identify future research and build more robust, directed adaptive maintenance systems. Future work may include a systematic review of practical aspects such as public datasets, benchmarking platforms, and open-source tools to support the advancement of PdM research.",
      "authors": [
        "Ainaz Jamshidi",
        "Dongchan Kim",
        "Muhammad Arif"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20090",
        "HTML": "https://arxiv.org/html/2506.20090",
        "PDF": "https://arxiv.org/pdf/2506.20090"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 02:22:23 GMT",
          "size": "1026kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper reviews predictive maintenance methods using classification and regression techniques. There is no mention or relevance to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20091",
      "abstract": "Recent advances in multi-agentic systems (e.g. AutoGen, OpenAI Swarm) allow users to interact with a group of specialised AI agents rather than a single general-purpose agent. Despite the promise of this new paradigm, the HCI community has yet to fully examine the opportunities, risks, and user-centred challenges it introduces. We contribute to research on multi-agentic systems by exploring their architectures and key features through a human-centred lens. While literature and use cases remain limited, we build on existing tools and frameworks available to developers to identify a set of overarching challenges, e.g. orchestration and conflict resolution, that can guide future research in HCI. We illustrate these challenges through examples, offer potential design considerations, and provide research opportunities to spark interdisciplinary conversation. Our work lays the groundwork for future exploration and offers a research agenda focused on user-centred design in multi-agentic systems.",
      "authors": [
        "Sarah Sch\\\"ombs",
        "Yan Zhang",
        "Jorge Goncalves",
        "Wafa Johal"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20091",
        "HTML": "https://arxiv.org/html/2506.20091",
        "PDF": "https://arxiv.org/pdf/2506.20091"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 02:28:39 GMT",
          "size": "610kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "From Conversation to Orchestration: HCI Challenges and Opportunities in Interactive Multi-Agentic Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses human-computer interaction challenges in multi-agentic systems, which is unrelated to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20094",
      "abstract": "AI inference at the edge is becoming increasingly common for low-latency services. However, edge environments are power- and resource-constrained, and susceptible to failures. Conventional failure resilience approaches, such as cloud failover or compressed backups, often compromise latency or accuracy, limiting their effectiveness for critical edge inference services. In this paper, we propose Multi-Level Ensemble Learning (MEL), a new framework for resilient edge inference that simultaneously trains multiple lightweight backup models capable of operating collaboratively, refining each other when multiple servers are available, and independently under failures while maintaining good accuracy. Specifically, we formulate our approach as a multi-objective optimization problem with a loss formulation that inherently encourages diversity among individual models to promote mutually refining representations, while ensuring each model maintains good standalone performance. Empirical evaluations across vision, language, and audio datasets show that MEL provides performance comparable to original architectures while also providing fault tolerance and deployment flexibility across edge platforms. Our results show that our ensemble model, sized at 40\\% of the original model, achieves similar performance, while preserving 95.6\\% of ensemble accuracy in the case of failures when trained using MEL.",
      "authors": [
        "Krishna Praneet Gudipaty",
        "Walid A. Hanafy",
        "Kaan Ozkara",
        "Qianlin Liang",
        "Jesse Milzman",
        "Prashant Shenoy",
        "Suhas Diggavi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20094",
        "HTML": "https://arxiv.org/html/2506.20094",
        "PDF": "https://arxiv.org/pdf/2506.20094"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 02:33:57 GMT",
          "size": "10723kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MEL: Multi-level Ensemble Learning for Resource-Constrained Environments",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a framework (MEL) for edge environment AI inference, focusing on resource constraints and fault tolerance without any connection to LLM training data processes."
      }
    },
    {
      "id": "2506.20100",
      "abstract": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning and decision-making in consultative interaction settings. Designed for the agriculture domain, MIRAGE captures the full complexity of expert consultations by combining natural user queries, expert-authored responses, and image-based context, offering a high-fidelity benchmark for evaluating models on grounded reasoning, clarification strategies, and long-form generation in a real-world, knowledge-intensive domain. Grounded in over 35,000 real user-expert interactions and curated through a carefully designed multi-step pipeline, MIRAGE spans diverse crop health, pest diagnosis, and crop management scenarios. The benchmark includes more than 7,000 unique biological entities, covering plant species, pests, and diseases, making it one of the most taxonomically diverse benchmarks available for vision-language models, grounded in the real world. Unlike existing benchmarks that rely on well-specified user inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich scenarios with open-world settings, requiring models to infer latent knowledge gaps, handle rare entities, and either proactively guide the interaction or respond. Project Page: https://mirage-benchmark.github.io",
      "authors": [
        "Vardhan Dongre",
        "Chi Gui",
        "Shubham Garg",
        "Hooshang Nayyeri",
        "Gokhan Tur",
        "Dilek Hakkani-T\\\"ur",
        "Vikram S. Adve"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20100",
        "HTML": "https://arxiv.org/html/2506.20100",
        "PDF": "https://arxiv.org/pdf/2506.20100"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:07:54 GMT",
          "size": "25560kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a multimodal benchmarking framework for agricultural consultations without focusing on training data processing for LLMs."
      }
    },
    {
      "id": "2506.20101",
      "abstract": "Multi-Key Homomorphic Encryption (MKHE), proposed by Lopez-Alt et al. (STOC 2012), allows for performing arithmetic computations directly on ciphertexts encrypted under distinct keys. Subsequent works by Chen and Dai et al. (CCS 2019) and Kim and Song et al. (CCS 2023) extended this concept by proposing multi-key BFV/CKKS variants, referred to as the CDKS scheme. These variants incorporate asymptotically optimal techniques to facilitate secure computation across multiple data providers. In this paper, we identify a critical security vulnerability in the CDKS scheme when applied to multiparty secure computation tasks, such as privacy-preserving federated learning (PPFL). In particular, we show that CDKS may inadvertently leak plaintext information from one party to others. To mitigate this issue, we propose a new scheme, SMHE (Secure Multi-Key Homomorphic Encryption), which incorporates a novel masking mechanism into the multi-key BFV and CKKS frameworks to ensure that plaintexts remain confidential throughout the computation. We implement a PPFL application using SMHE and demonstrate that it provides significantly improved security with only a modest overhead in homomorphic evaluation. For instance, our PPFL model based on multi-key CKKS incurs less than a 2\\times runtime and communication traffic increase compared to the CDKS-based PPFL model. The code is publicly available at https://github.com/JiahuiWu2022/SMHE.git.",
      "authors": [
        "Jiahui Wu",
        "Tiecheng Sun",
        "Fucai Luo",
        "Haiyan Wang",
        "Weizhe Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20101",
        "HTML": "https://arxiv.org/html/2506.20101",
        "PDF": "https://arxiv.org/pdf/2506.20101"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:28:25 GMT",
          "size": "429kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Secure Multi-Key Homomorphic Encryption with Application to Privacy-Preserving Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper details a secure multi-key homomorphic encryption scheme for federated learning, which does not address LLM training data processing."
      }
    },
    {
      "id": "2506.20102",
      "abstract": "The convergence of IT and OT has created hyper-connected ICS, exposing critical infrastructure to a new class of adaptive, intelligent adversaries that render static defenses obsolete. Existing security paradigms often fail to address a foundational \"Trinity of Trust,\" comprising the fidelity of the system model, the integrity of synchronizing data, and the resilience of the analytical engine against sophisticated evasion. This paper introduces the ARC framework, a method for achieving analytical resilience through an autonomous, closed-loop hardening process. ARC establishes a perpetual co-evolutionary arms race within the high-fidelity sandbox of a F-SCDT. A DRL agent, the \"Red Agent,\" is formalized and incentivized to autonomously discover stealthy, physically-plausible attack paths that maximize process disruption while evading detection. Concurrently, an ensemble-based \"Blue Agent\" defender is continuously hardened via adversarial training against the evolving threats discovered by its adversary. This co-evolutionary dynamic forces both agents to become progressively more sophisticated, enabling the system to autonomously probe and patch its own vulnerabilities. Experimental validation on both the TEP and the SWaT testbeds demonstrates the framework's superior performance. A comprehensive ablation study, supported by extensive visualizations including ROC curves and SHAP plots, reveals that the co-evolutionary process itself is responsible for a significant performance increase in detecting novel attacks. By integrating XAI to ensure operator trust and proposing a scalable F-ARC architecture, this work presents ARC not merely as an improvement, but as a necessary paradigm shift toward dynamic, self-improving security for the future of critical infrastructure.",
      "authors": [
        "Malikussaid",
        "Sutiyo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20102",
        "HTML": "https://arxiv.org/html/2506.20102",
        "PDF": "https://arxiv.org/pdf/2506.20102"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:28:48 GMT",
          "size": "605kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a framework for autonomous cyber resilience using a digital twin sandbox, which is unrelated to the processing of training data for large language models."
      }
    },
    {
      "id": "2506.20103",
      "abstract": "Recent advances in deep generative models have led to significant progress in video generation, yet the fidelity of AI-generated videos remains limited. Synthesized content often exhibits visual artifacts such as temporally inconsistent motion, physically implausible trajectories, unnatural object deformations, and local blurring that undermine realism and user trust. Accurate detection and spatial localization of these artifacts are crucial for both automated quality control and for guiding the development of improved generative models. However, the research community currently lacks a comprehensive benchmark specifically designed for artifact localization in AI generated videos. Existing datasets either restrict themselves to video or frame level detection or lack the fine-grained spatial annotations necessary for evaluating localization methods. To address this gap, we introduce BrokenVideos, a benchmark dataset of 3,254 AI-generated videos with meticulously annotated, pixel-level masks highlighting regions of visual corruption. Each annotation is validated through detailed human inspection to ensure high quality ground truth. Our experiments show that training state of the art artifact detection models and multi modal large language models (MLLMs) on BrokenVideos significantly improves their ability to localize corrupted regions. Through extensive evaluation, we demonstrate that BrokenVideos establishes a critical foundation for benchmarking and advancing research on artifact localization in generative video models. The dataset is available at: https://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.",
      "authors": [
        "Jiahao Lin",
        "Weixuan Peng",
        "Bojia Zi",
        "Yifeng Gao",
        "Xianbiao Qi",
        "Xingjun Ma",
        "Yu-Gang Jiang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20103",
        "HTML": "https://arxiv.org/html/2506.20103",
        "PDF": "https://arxiv.org/pdf/2506.20103"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:30:04 GMT",
          "size": "35594kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a benchmark dataset for detecting artifacts in AI-generated videos, which is not related to LLM training data or its processing."
      }
    },
    {
      "id": "2506.20104",
      "abstract": "The Russian invasion of Ukraine has fundamentally altered the information technology (IT) risk landscape, particularly in cloud computing environments. This paper examines how this geopolitical conflict has accelerated data sovereignty concerns, transformed cybersecurity paradigms, and reshaped cloud infrastructure strategies worldwide. Through an analysis of documented cyber operations, regulatory responses, and organizational adaptations between 2022 and early 2025, this research demonstrates how the conflict has served as a catalyst for a broader reassessment of IT risk. The research reveals that while traditional IT risk frameworks offer foundational guidance, their standard application may inadequately address the nuances of state-sponsored threats, conflicting data governance regimes, and the weaponization of digital dependencies without specific geopolitical augmentation. The contribution of this paper lies in its focused synthesis and strategic adaptation of existing best practices into a multi-layered approach. This approach uniquely synergizes resilient cloud architectures (including sovereign and hybrid models), enhanced data-centric security strategies (such as advanced encryption and privacy-enhancing technologies), and geopolitically-informed governance to build digital resilience. The interplay between these layers, emphasizing how geopolitical insights directly shape architectural and security choices beyond standard best practices-particularly by integrating the human element, including personnel vulnerabilities and expertise, as a core consideration in technical design and operational management-offers a more robust defense against the specific, multifaceted risks arising from geopolitical conflict in increasingly fractured digital territories.",
      "authors": [
        "Malikussaid",
        "Sutiyo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20104",
        "HTML": "https://arxiv.org/html/2506.20104",
        "PDF": "https://arxiv.org/pdf/2506.20104"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:32:36 GMT",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Impact of the Russia-Ukraine Conflict on the Cloud Computing Risk Landscape",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper analyzes IT risk landscapes influenced by geopolitical conflicts, which is not related to LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.20107",
      "abstract": "An LZ-like factorization of a string is a factorization in which each factor is either a single character or a copy of a substring that occurs earlier in the string. While grammar-based compression schemes support efficient random access with linear space in the size of the compressed representation, such methods are not known for general LZ-like factorizations. This has led to the development of restricted LZ-like schemes such as LZ-End [Kreft and Navarro, 2013] and height-bounded (LZHB) [Bannai et al., 2024], which trade off some compression efficiency for faster access. We introduce LZ-Start-End (LZSE), a new variant of LZ-like factorizations in which each copy factor refers to a contiguous sequence of preceding factors. By its nature, any context-free grammar can easily be converted into an LZSE factorization of equal size. Further, we study the greedy LZSE factorization, in which each copy factor is taken as long as possible. We show how the greedy LZSE factorization can be computed in linear time with respect to the input string length, and that there exists a family of strings for which the size of the greedy LZSE factorization is of strictly lower order than that of the smallest grammar. These imply that our LZSE scheme is stronger than grammar-based compressions in the context of repetitiveness measures. To support fast queries, we propose a data structure for LZSE-compressed strings that permits $O(\\log n)$-time random access within space linear in the compressed size, where $n$ is the length of the input string.",
      "authors": [
        "Hiroki Shibata",
        "Yuto Nakashima",
        "Yutaro Yamaguchi",
        "Shunsuke Inenaga"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20107",
        "HTML": "https://arxiv.org/html/2506.20107",
        "PDF": "https://arxiv.org/pdf/2506.20107"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:42:40 GMT",
          "size": "387kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LZSE: an LZ-style compressor supporting $O(\\log n)$-time random access",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a new LZ-style compression technique for random access in compressed strings, which does not relate to the processing of LLM training data."
      }
    },
    {
      "id": "2506.20109",
      "abstract": "Disassemblers are crucial in the analysis and modification of binaries. Existing works showing disassembler errors largely rely on practical implementation without specific guarantees and assume source code and compiler toolchains to evaluate ground truth. However, the assumption of source code is contrary to typical binary scenarios where only the binary is available. In this work, we investigate an approach with minimal assumptions and a sound approach to disassembly error evaluation that does not require source code. Any source code does not address the fundamental problem of binary disassembly and fails when only the binary exists. As far as we know, this is the first work to evaluate disassembly errors using only the binary. We propose TraceBin, which uses dynamic execution to find disassembly errors. TraceBin targets the use case where the disassembly is used in an automated fashion for security tasks on a target binary, such as static binary instrumentation, binary hardening, automated code repair, and so on, which may be affected by disassembly errors. Discovering disassembly errors in the target binary aids in reducing problems caused by such errors. Furthermore, we are not aware of existing approaches that can evaluate errors given only a target binary, as they require source code. Our evaluation shows TraceBin finds: (i) errors consistent with existing studies even without source; (ii) disassembly errors due to control flow; (iii) new interesting errors; (iv) errors in non-C/C++ binaries; (v) errors in closed-source binaries; and (vi) show that disassembly errors can have significant security implications. Overall, our experimental results show that TraceBin finds many errors in existing popular disassemblers. It is also helpful in automated security tasks on (closed source) binaries relying on disassemblers.",
      "authors": [
        "Lambang Akbar Wijayadi",
        "Yuancheng Jiang",
        "Roland H.C. Yap",
        "Zhenkai Liang",
        "Zhuohao Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20109",
        "HTML": "https://arxiv.org/html/2506.20109",
        "PDF": "https://arxiv.org/pdf/2506.20109"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:46:19 GMT",
          "size": "202kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Evaluating Disassembly Errors With Only Binaries",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a method for evaluating disassembly errors in binaries, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20111",
      "abstract": "In this article, we extend a statistical test of graph clusterability, the $\\delta$ test, to directed graphs with no self loops. The $\\delta$ test, originally designed for undirected graphs, is based on the premise that graphs with a clustered structure display a mean local density that is statistically higher than the graph's global density. We posit that graphs that do not meet this necessary (but not sufficient) condition for clusterability can be considered unsuited to clustering. In such cases, vertex clusters do not offer a meaningful summary of the broader graph. Additionally in this study, we aim to determine the optimal sample size (number of neighborhoods). Our test, designed for the analysis of large networks, is based on sampling subsets of neighborhoods/nodes. It is designed for cases where computing the density of every node's neighborhood is infeasible. Our results show that the $\\delta$ test performs very well, even with very small samples of neighborhoods ($1\\%$). It accurately detects unclusterable graphs and is also shown to be robust to departures from the underlying assumptions of the $t$ test.",
      "authors": [
        "Mario R. Guarracino and Pierre Miasnikof and Alexander Y. Shestopaloff and Houyem Demni and Cristi\\'an Bravo and Yuri Lawryshyn"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20111",
        "HTML": "https://arxiv.org/html/2506.20111",
        "PDF": "https://arxiv.org/pdf/2506.20111"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 03:52:44 GMT",
          "size": "136kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A clusterability test for directed graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study proposes a clusterability test for directed graphs and does not address any aspect of LLM training data processing."
      }
    },
    {
      "id": "2506.20112",
      "abstract": "Background: The positive predictive value (PPV) of large language model (LLM)-based proofreading for radiology reports is limited due to the low error prevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV and reduces operational costs compared with baseline approaches. Materials and Methods: A retrospective analysis was performed on 1,000 consecutive radiology reports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III database. Two external datasets (CheXpert and Open-i) were validation sets. Three LLM frameworks were tested: (1) single-prompt detector; (2) extractor plus detector; and (3) extractor, detector, and false-positive verifier. Precision was measured by PPV and absolute true positive rate (aTPR). Efficiency was calculated from model inference charges and reviewer remuneration. Statistical significance was tested using cluster bootstrap, exact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV increased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118, Framework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs. baselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per 1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and USD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively. Human-reviewed reports decreased from 192 to 88. External validation supported Framework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR (0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and reduced operational costs, maintaining detection performance, providing an effective strategy for AI-assisted radiology report quality assurance.",
      "authors": [
        "Songsoo Kim",
        "Seungtae Lee",
        "See Young Lee",
        "Joonho Kim",
        "Keechan Kan and Dukyong Yoon"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20112",
        "HTML": "https://arxiv.org/html/2506.20112",
        "PDF": "https://arxiv.org/pdf/2506.20112"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:02:29 GMT",
          "size": "1579kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a framework for radiology report error detection using large language models without addressing the collection, construction, processing, or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20119",
      "abstract": "Evaluating the abilities of learners is a fundamental objective in the field of education. In particular, there is an increasing need to assess higher-order abilities such as expressive skills and logical thinking. Constructed-response tests such as short-answer and essay-based questions have become widely used as a method to meet this demand. Although these tests are effective, they require substantial manual grading, making them both labor-intensive and costly. Item response theory (IRT) provides a promising solution by enabling the estimation of ability from incomplete score data, where human raters grade only a subset of answers provided by learners across multiple test items. However, the accuracy of ability estimation declines as the proportion of missing scores increases. Although data augmentation techniques for imputing missing scores have been explored in order to address this limitation, they often struggle with inaccuracy for sparse or heterogeneous data. To overcome these challenges, this study proposes a novel method for imputing missing scores by leveraging automated scoring technologies for accurate IRT-based ability estimation. The proposed method achieves high accuracy in ability estimation while markedly reducing manual grading workload.",
      "authors": [
        "Masaki Uto and Yuma Ito"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20119",
        "HTML": "https://arxiv.org/html/2506.20119",
        "PDF": "https://arxiv.org/pdf/2506.20119"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:17:57 GMT",
          "size": "1329kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research pertains to automated scoring and imputation for educational testing, without addressing LLM training data processing stages or data engineering."
      }
    },
    {
      "id": "2506.20123",
      "abstract": "The detection of malicious accounts on Ethereum - the preeminent DeFi platform - is critical for protecting digital assets and maintaining trust in decentralized finance. Recent advances highlight that temporal transaction evolution reveals more attack signatures than static graphs. However, current methods either fail to model continuous transaction dynamics or incur high computational costs that limit scalability to large-scale transaction networks. Furthermore, current methods fail to consider two higher-order behavioral fingerprints: (1) direction in temporal transaction flows, which encodes money movement trajectories, and (2) account clustering, which reveals coordinated behavior of organized malicious collectives. To address these challenges, we propose DiT-SGCR, an unsupervised graph encoder for malicious account detection. Specifically, DiT-SGCR employs directional temporal aggregation to capture dynamic account interactions, then coupled with differentiable clustering and graph Laplacian regularization to generate high-quality, low-dimensional embeddings. Our approach simultaneously encodes directional temporal dynamics, global topology, and cluster-specific behavioral patterns, thereby enhancing the discriminability and robustness of account representations. Furthermore, DiT-SGCR bypasses conventional graph propagation mechanisms, yielding significant scalability advantages. Extensive experiments on three datasets demonstrate that DiT-SGCR consistently outperforms state-of-the-art methods across all benchmarks, achieving F1-score improvements ranging from 3.62% to 10.83%.",
      "authors": [
        "Ye Tian",
        "Liangliang Song",
        "Peng Qian",
        "Yanbin Wang",
        "Jianguo Sun",
        "Yifan Jia"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20123",
        "HTML": "https://arxiv.org/html/2506.20123",
        "PDF": "https://arxiv.org/pdf/2506.20123"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:29:40 GMT",
          "size": "1964kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DiT-SGCR: Directed Temporal Structural Representation with Global-Cluster Awareness for Ethereum Malicious Account Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a method for malicious account detection in Ethereum, focusing on transactional dynamics and not on LLM training data or its processing."
      }
    },
    {
      "id": "2506.20127",
      "abstract": "Happens before-based dynamic analysis is the go-to technique for detecting data races in large scale software projects due to the absence of false positive reports. However, such analyses are expensive since they employ expensive vector clock updates at each event, rendering them usable only for in-house testing. In this paper, we present a sampling-based, randomized race detector that processes only constantly many events of the input trace even in the worst case. This is the first sub-linear time (i.e., running in o(n) time where n is the length of the trace) dynamic race detection algorithm; previous sampling based approaches like Pacer run in linear time (i.e., O(n)). Our algorithm is a property tester for HB-race detection -- it is sound in that it never reports any false positive, and on traces that are far, with respect to hamming distance, from any race-free trace, the algorithm detects an HB-race with high probability. Our experimental evaluation of the algorithm and its comparison with state-of-the-art deterministic and sampling based race detectors shows that the algorithm does indeed have significantly low running time, and detects races quite often.",
      "authors": [
        "Mosaad Al Thokair",
        "Minjian Zhang",
        "Umang Mathur",
        "Mahesh Viswanathan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20127",
        "HTML": "https://arxiv.org/html/2506.20127",
        "PDF": "https://arxiv.org/pdf/2506.20127"
      },
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:46:35 GMT",
          "size": "322kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Dynamic Race Detection With O(1) Samples",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on dynamic race detection in software and does not address any aspect of LLM training data processing."
      }
    },
    {
      "id": "2506.20130",
      "abstract": "Open science initiatives seek to make research outputs more transparent, accessible, and reusable, but ensuring that published findings can be independently reproduced remains a persistent challenge. This paper introduces OpenPub, an AI-powered platform that supports researchers, reviewers, and readers through a suite of modular copilots focused on key open science tasks. In this work, we present the Reproducibility Copilot, which analyzes manuscripts, code, and supplementary materials to generate structured Jupyter Notebooks and recommendations aimed at facilitating computational, or \"rote\", reproducibility. We conducted feasibility tests using previously studied research papers with known reproducibility benchmarks. Results indicate that OpenPub can substantially reduce reproduction time - from over 30 hours to about 1 hour - while achieving high coverage of figures, tables, and results suitable for computational reproduction. The system systematically detects barriers to reproducibility, including missing hyperparameters, undocumented preprocessing steps, and incomplete or inaccessible datasets. These findings suggest that AI-driven tools can meaningfully reduce the burden of reproducibility efforts and contribute to more transparent and verifiable scientific communication. The modular copilot architecture also provides a foundation for extending AI assistance to additional open science objectives beyond reproducibility.",
      "authors": [
        "Adrien Bibal and Steven N. Minton and Deborah Khider and Yolanda Gil"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20130",
        "HTML": "https://arxiv.org/html/2506.20130",
        "PDF": "https://arxiv.org/pdf/2506.20130"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:56:28 GMT",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AI Copilots for Reproducibility in Science: A Case Study",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a framework for improving reproducibility in scientific research using AI, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20132",
      "abstract": "Wildfires are increasing in intensity and severity at an alarming rate. Recent advances in AI and publicly available satellite data enable monitoring critical wildfire risk factors globally, at high resolution and low latency. Live Fuel Moisture Content (LFMC) is a critical wildfire risk factor and is valuable for both wildfire research and operational response. However, ground-based LFMC samples are both labor intensive and costly to acquire, resulting in sparse and infrequent updates. In this work, we explore the use of a pretrained, highly-multimodal earth-observation model for generating large-scale spatially complete (wall-to-wall) LFMC maps. Our approach achieves significant improvements over previous methods using randomly initialized models (20 reduction in RMSE). We provide an automated pipeline that enables rapid generation of these LFMC maps across the United States, and demonstrate its effectiveness in two regions recently impacted by wildfire (Eaton and Palisades).",
      "authors": [
        "Patrick Alan Johnson",
        "Gabriel Tseng",
        "Yawen Zhang",
        "Heather Heward",
        "Virginia Sjahli",
        "Favyen Bastani",
        "Joseph Redmon",
        "Patrick Beukema"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20132",
        "HTML": "https://arxiv.org/html/2506.20132",
        "PDF": "https://arxiv.org/pdf/2506.20132"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:59:10 GMT",
          "size": "4857kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "High-Resolution Live Fuel Moisture Content (LFMC) Maps for Wildfire Risk from Multimodal Earth Observation Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes generating LFMC maps using Earth observation data, focusing on wildfire risk assessment, not related to LLM training data."
      }
    },
    {
      "id": "2506.20134",
      "abstract": "World models have garnered increasing attention in the development of artificial general intelligence (AGI), serving as computational frameworks for learning representations of the external world and forecasting future states. While early efforts focused on 2D visual perception and simulation, recent 3D-aware generative world models have demonstrated the ability to synthesize geometrically consistent, interactive 3D environments, marking a shift toward 3D spatial cognition. Despite rapid progress, the field lacks systematic analysis to categorize emerging techniques and clarify their roles in advancing 3D cognitive world models. This survey addresses this need by introducing a conceptual framework, providing a structured and forward-looking review of world models transitioning from 2D perception to 3D cognition. Within this framework, we highlight two key technological drivers, particularly advances in 3D representations and the incorporation of world knowledge, as fundamental pillars. Building on these, we dissect three core cognitive capabilities that underpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning, and 3D spatial interaction. We further examine the deployment of these capabilities in real-world applications, including embodied AI, autonomous driving, digital twin, and gaming/VR. Finally, we identify challenges across data, modeling, and deployment, and outline future directions for advancing more robust and generalizable 3D world models.",
      "authors": [
        "Ningwei Xie and Zizi Tian and Lei Yang and Xiao-Ping Zhang and Meng Guo and Jie Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20134",
        "HTML": "https://arxiv.org/html/2506.20134",
        "PDF": "https://arxiv.org/pdf/2506.20134"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 05:05:09 GMT",
          "size": "1267kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "From 2D to 3D Cognition: A Brief Survey of General World Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This survey covers world models in AGI, specifically in transitioning from 2D to 3D cognition and does not discuss LLM training data processing."
      }
    },
    {
      "id": "2506.20139",
      "abstract": "A growing trend in the database and system communities is to augment conventional index structures, such as B+-trees, with machine learning (ML) models. Among these, error-bounded Piecewise Linear Approximation ($\\epsilon$-PLA) has emerged as a popular choice due to its simplicity and effectiveness. Despite its central role in many learned indexes, the design and analysis of $\\epsilon$-PLA fitting algorithms remain underexplored. In this paper, we revisit $\\epsilon$-PLA from both theoretical and empirical perspectives, with a focus on its application in learned index structures. We first establish a fundamentally improved lower bound of $\\Omega(\\kappa \\cdot \\epsilon^2)$ on the expected segment coverage for existing $\\epsilon$-PLA fitting algorithms, where $\\kappa$ is a data-dependent constant. We then present a comprehensive benchmark of state-of-the-art $\\epsilon$-PLA algorithms when used in different learned data structures. Our results highlight key trade-offs among model accuracy, model size, and query performance, providing actionable guidelines for the principled design of future learned data structures.",
      "authors": [
        "Jiayong Qin",
        "Xianyu Zhu",
        "Qiyu Liu",
        "Guangyi Zhang",
        "Zhigang Cai",
        "Jianwei Liao",
        "Sha Hu",
        "Jingshu Peng",
        "Yingxia Shao",
        "Lei Chen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20139",
        "HTML": "https://arxiv.org/html/2506.20139",
        "PDF": "https://arxiv.org/pdf/2506.20139"
      },
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 05:20:54 GMT",
          "size": "8833kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Piecewise Linear Approximation in Learned Index Structures: Theoretical and Empirical Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on augmenting index structures with machine learning models, specifically analyzing piecewise linear approximation in learned indexes. It does not address aspects of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20141",
      "abstract": "The explosive growth of AI research has driven paper submissions at flagship AI conferences to unprecedented levels, necessitating many venues in 2025 (e.g., CVPR, ICCV, KDD, AAAI, IJCAI, WSDM) to enforce strict per-author submission limits and to desk-reject any excess papers by simple ID order. While this policy helps reduce reviewer workload, it may unintentionally discard valuable papers and penalize authors' efforts. In this paper, we ask an essential research question on whether it is possible to follow submission limits while minimizing needless rejections. We first formalize the current desk-rejection policies as an optimization problem, and then develop a practical algorithm based on linear programming relaxation and a rounding scheme. Under extensive evaluation on 11 years of real-world ICLR (International Conference on Learning Representations) data, our method preserves up to $19.23\\%$ more papers without violating any author limits. Moreover, our algorithm is highly efficient in practice, with all results on ICLR data computed within at most 53.64 seconds. Our work provides a simple and practical desk-rejection strategy that significantly reduces unnecessary rejections, demonstrating strong potential to improve current CS conference submission policies.",
      "authors": [
        "Xiaoyu Li",
        "Zhao Song",
        "Jiahao Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20141",
        "HTML": "https://arxiv.org/html/2506.20141",
        "PDF": "https://arxiv.org/pdf/2506.20141"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 05:23:44 GMT",
          "size": "69kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research is about optimizing desk-rejection policies for paper submissions at conferences. It does not relate to the processing or engineering of training data for LLMs."
      }
    },
    {
      "id": "2506.20148",
      "abstract": "Humans can possess good mechanics intuitions by learning from a few examples, which leads to the question of how to develop artificial mechanics intuitions that can be learned from small data, as we are eagerly entering the era of artificial intelligence. We propose in this Letter the sample-switchable training method, which successfully develops highly-accurate artificial mechanics intuitions that can master brachistochrone problem, catenary problem, and large nonlinear deformation problem of elastic plate by learning from no more than three samples. The model's intuitive prediction ability increases nonlinearly with respect to the number of training samples, suggesting that superb mechanics intuitions can be in-principle achieved based on a finite number of samples, reflecting how human brains form good mechanics intuitions just by learning a few cases. Our current work presents an alternative perspective for educating artificial intelligence capable of intuitively understand and predict how materials deform and move, a scenario that has been frequently seen in Science-Fiction movies.",
      "authors": [
        "Jingruo Peng and Shuze Zhu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20148",
        "HTML": "https://arxiv.org/html/2506.20148",
        "PDF": "https://arxiv.org/pdf/2506.20148"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:07:41 GMT",
          "size": "1231kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Developing Artificial Mechanics Intuitions from Extremely Small Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered on developing artificial mechanics intuitions from small datasets. It does not deal with large language models or the data processing involved in their training."
      }
    },
    {
      "id": "2506.20152",
      "abstract": "Structured pruning is a well-established technique for compressing neural networks, making it suitable for deployment in resource-limited edge devices. This paper presents an efficient Loss-Aware Automatic Selection of Structured Pruning Criteria (LAASP) for slimming and accelerating deep neural networks. The majority of pruning methodologies employ a sequential process consisting of three stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed pruning technique adopts a pruning-while-training approach that eliminates the first stage and integrates the second and third stages into a single cycle. The automatic selection of magnitude or similarity-based filter pruning criteria from a specified pool of criteria and the specific pruning layer at each pruning iteration is guided by the network's overall loss on a small subset of the training data. To mitigate the abrupt accuracy drop due to pruning, the network is retrained briefly after each reduction of a predefined number of floating-point operations (FLOPs). The optimal pruning rates for each layer in the network are automatically determined, eliminating the need for manual allocation of fixed or variable pruning rates for each layer. Experiments on the VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets demonstrate the effectiveness of the proposed method. In particular, the ResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the top-1 accuracy compared to state-of-the-art methods while reducing the network FLOPs by 52\\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces FLOPs by more than 42\\% with a negligible 0.33\\% drop in top-5 accuracy. The source code of this paper is publicly available online - https://github.com/ghimiredhikura/laasp.",
      "authors": [
        "Deepak Ghimire",
        "Kilho Lee",
        "and Seong-heum Kim"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20152",
        "HTML": "https://arxiv.org/html/2506.20152",
        "PDF": "https://arxiv.org/pdf/2506.20152"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:18:46 GMT",
          "size": "737kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a pruning method for neural networks to enhance efficiency. It does not pertain to LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20155",
      "abstract": "Text-to-Image Diffusion models have enabled a wide array of image editing applications. However, capturing all types of edits through text alone can be challenging and cumbersome. The ambiguous nature of certain image edits is better expressed through an exemplar pair, i.e., a pair of images depicting an image before and after an edit respectively. In this work, we tackle exemplar-based image editing -- the task of transferring an edit from an exemplar pair to a content image(s), by leveraging pretrained text-to-image diffusion models and multimodal VLMs. Even though our end-to-end pipeline is optimization-free, our experiments demonstrate that it still outperforms baselines on multiple types of edits while being ~4x faster.",
      "authors": [
        "Avadhoot Jadhav",
        "Ashutosh Srivastava",
        "Abhinav Java",
        "Silky Singh",
        "Tarun Ram Menta",
        "Surgan Jandial",
        "Balaji Krishnamurthy"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20155",
        "HTML": "https://arxiv.org/html/2506.20155",
        "PDF": "https://arxiv.org/pdf/2506.20155"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:20:36 GMT",
          "size": "16568kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Towards Efficient Exemplar Based Image Editing with Multimodal VLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on image editing using text-to-image diffusion models and does not address any aspect of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20158",
      "abstract": "Rotatable antenna (RA) is a promising antenna architecture that exploits additional spatial degrees of freedom (DoFs) to enhance the communication performance. To fully obtain the performance gain provided by RAs, accurate channel state information (CSI) is essential for adjusting the orientation/boresight of each antenna. In this letter, we propose an efficient channel estimation scheme for RA communication systems, where the base station (BS) can sequentially and adaptively adjust the orientations of RAs to enrich the environmental observations from diverse angular perspectives, thereby enhancing the channel estimation accuracy. The proposed scheme includes two main procedures that are conducted alternately during each channel training period. Specifically, the first procedure is to estimate the CSI with given RAs' orientations, involving the angle-of-arrivals (AoAs) information and path gains. Then, based on the estimated CSI, the second procedure adjusts the RAs' orientations to maximize the effective channel gain. Simulation results demonstrate that the proposed channel estimation method outperforms other benchmark schemes.",
      "authors": [
        "Xue Xiong",
        "Beixiong Zheng",
        "Wen Wu",
        "Xiaodan Shao",
        "Liang Dai",
        "Ming-Min Zhao",
        "and Jie Tang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20158",
        "HTML": "https://arxiv.org/html/2506.20158",
        "PDF": "https://arxiv.org/pdf/2506.20158"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:28:49 GMT",
          "size": "371kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Efficient Channel Estimation for Rotatable Antenna-Enabled Wireless Communication",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a channel estimation scheme for wireless communication, which is outside the scope of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20159",
      "abstract": "The full-day workshop on AI and Agile at XP 2025 convened a diverse group of researchers and industry practitioners to address the practical challenges and opportunities of integrating Artificial Intelligence into Agile software development. Through interactive sessions, participants identified shared frustrations related to integrating AI into Agile Software Development practices, including challenges with tooling, governance, data quality, and critical skill gaps. These challenges were systematically prioritized and analyzed to uncover root causes. The workshop culminated in the collaborative development of a research roadmap that pinpoints actionable directions for future work, including both immediate solutions and ambitious long-term goals. The key outcome is a structured agenda designed to foster joint industry-academic efforts to move from identified frustrations to successful implementation.",
      "authors": [
        "Tomas Herda and Victoria Pichler and Zheying Zhang and Pekka Abrahamsson and Geir K. Hanssen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20159",
        "HTML": "https://arxiv.org/html/2506.20159",
        "PDF": "https://arxiv.org/pdf/2506.20159"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:29:03 GMT",
          "size": "270kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AI and Agile Software Development: From Frustration to Success -- XP2025 Workshop Summary",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The workshop summary mentions challenges and opportunities related to AI integration in Agile development but does not focus on the processing of training data specific to LLMs."
      }
    },
    {
      "id": "2506.20160",
      "abstract": "Large reasoning models (LRMs) achieve impressive reasoning capabilities by generating lengthy chain-of-thoughts, but this \"overthinking\" incurs high latency and cost without commensurate accuracy gains. In this work, we introduce AALC, a lightweight, accuracy-aware length reward integrated into reinforcement learning that dynamically balances correctness and brevity during training. By incorporating validation accuracy into the reward and employing a smooth, dynamically scheduled length penalty, AALC delays length penalty until target performance is met. Through extensive experiments across standard and out-of-distribution math benchmarks, we show that our approach reduces response length by over 50% while maintaining or even improving the original accuracy. Furthermore, qualitative analysis reveals that our method curbs redundant reasoning patterns such as excessive subgoal setting and verification, leading to structurally refined outputs rather than naive truncation. We also identify that efficiency gains are accompanied by reduced interpretability: models trained with AALC omit some narrative framing and explanatory context. These findings highlight the potential of reward-based strategies to guide LRMs toward more efficient, generalizable reasoning paths.",
      "authors": [
        "Ruosen Li",
        "Ziming Luo",
        "Quan Zhang",
        "Ruochen Li",
        "Ben Zhou",
        "Ali Payani",
        "Xinya Du"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20160",
        "HTML": "https://arxiv.org/html/2506.20160",
        "PDF": "https://arxiv.org/pdf/2506.20160"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:29:18 GMT",
          "size": "4219kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses efficiency in reasoning models by controlling reasoning length, and it focuses on reward strategies within reinforcement learning rather than LLM training data processing."
      }
    },
    {
      "id": "2506.20169",
      "abstract": "Discovering pure causes or driver variables in deterministic LTI systems is of vital importance in the data-driven reconstruction of causal networks. A recent work by Kathari and Tangirala, proposed in 2022, formulated the causal discovery method as a constraint identification problem. The constraints are identified using a dynamic iterative PCA (DIPCA)-based approach for dynamical systems corrupted with Gaussian measurement errors. The DIPCA-based method works efficiently for dynamical systems devoid of any algebraic relations. However, several dynamical systems operate under feedback control and/or are coupled with conservation laws, leading to differential-algebraic (DAE) or mixed causal systems. In this work, a method, namely the partition of variables (PoV), for causal discovery in LTI-DAE systems is proposed. This method is superior to the method that was presented by Kathari and Tangirala (2022), as PoV also works for pure dynamical systems, which are devoid of algebraic equations. The proposed method identifies the causal drivers up to a minimal subset. PoV deploys DIPCA to first determine the number of algebraic relations ($n_a$), the number of dynamical relations ($n_d$) and the constraint matrix. Subsequently, the subsets are identified through an admissible partitioning of the constraint matrix by finding the condition number of it. Case studies are presented to demonstrate the effectiveness of the proposed method.",
      "authors": [
        "Bala Rajesh Konkathi",
        "Arun K. Tangirala"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20169",
        "HTML": "https://arxiv.org/html/2506.20169",
        "PDF": "https://arxiv.org/pdf/2506.20169"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:47:22 GMT",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Causal discovery in deterministic discrete LTI-DAE systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a causal discovery method for deterministic discrete LTI-DAE systems, focusing on identifying causal systems and constraints. It does not address any aspect of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20174",
      "abstract": "Foundation models are rapidly transforming Earth Observation data mining by enabling generalizable and scalable solutions for key tasks such as scene classification and semantic segmentation. While most efforts in the geospatial domain have focused on developing large models trained from scratch using massive Earth Observation datasets, an alternative strategy that remains underexplored is the reuse and combination of existing pretrained models. In this study, we investigate whether foundation models pretrained on remote sensing and general vision datasets can be effectively combined to improve performance across a diverse set of key Earth Observation tasks. Using the GEO-Bench benchmark, we evaluate several prominent models, including Prithvi, Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions, sensor modalities, and task types. The results show that feature-level ensembling of smaller pretrained models can match or exceed the performance of much larger models, while requiring less training time and computational resources. Moreover, the study highlights the potential of applying knowledge distillation to transfer the strengths of ensembles into more compact models, offering a practical path for deploying foundation models in real-world Earth Observation applications.",
      "authors": [
        "Man Duc Chuc"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20174",
        "HTML": "https://arxiv.org/html/2506.20174",
        "PDF": "https://arxiv.org/pdf/2506.20174"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:02:42 GMT",
          "size": "4264kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates foundation models for Earth Observation data mining and pre-trained model composition, without contributions to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20176",
      "abstract": "This work explores the potential of spatial model checking of polyhedral models on a number of selected examples. In computer graphics polyhedral models can be found in the form of triangular surface meshes of tetrahedral volume meshes which are abundant. Spatial model checking is used to analyse spatial properties of interest of such models expressed in a suitable spatial logic. The original contributions of this paper are twofold. First we illustrate how a polyhedral model can be enriched by adding the outcome of one model checking session as an atomic proposition to the original model. This is useful as it provides a way to reduce the length of formulas to check on such models and to obtain more insightful results when these models are used for graphical visualisation. Second we show that this form of enrichment also enables practical model minimisation providing deeper insights in the basic spatial structure of the model in terms of the spatial logic properties it enjoys. This work is performed in the context of the geometric spatial model checker PolyLogicA, the visualizer PolyVisualizer and the polyhedral semantics of the Spatial Logic for Closure Spaces SLCS.",
      "authors": [
        "Yuri Andriaccio and Vincenzo Ciancia and Diego Latella and Mieke Massink"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20176",
        "HTML": "https://arxiv.org/html/2506.20176",
        "PDF": "https://arxiv.org/pdf/2506.20176"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:04:00 GMT",
          "size": "8499kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Practical Exploration of Polyhedral Model Checking",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work explores spatial model checking and polyhedral models, unrelated to training data processing for large language models."
      }
    },
    {
      "id": "2506.20178",
      "abstract": "Uncertainty quantification (UQ) for foundation models is essential to identify and mitigate potential hallucinations in automatically generated text. However, heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. Previous work adopts the split conformal prediction (SCP) framework to ensure desired coverage of admissible answers by constructing prediction sets, but these sets often contain incorrect candidates, limiting their practical utility. To address this, we propose COIN, an uncertainty-guarding selection framework that calibrates statistically valid thresholds to filter a single generated answer per question under user-specified FDR constraints. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). This enables the selection of the largest uncertainty threshold that ensures FDR control on test data while significantly increasing sample retention. We demonstrate COIN's robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, we show that employing alternative upper bound constructions and UQ strategies can further boost COIN's power performance, which underscores its extensibility and adaptability to diverse application scenarios.",
      "authors": [
        "Zhiyuan Wang and Jinhao Duan and Qingni Wang and Xiaofeng Zhu and Tianlong Chen and Xiaoshuang Shi and Kaidi Xu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20178",
        "HTML": "https://arxiv.org/html/2506.20178",
        "PDF": "https://arxiv.org/pdf/2506.20178"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:04:49 GMT",
          "size": "1702kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on uncertainty quantification for foundation models, without addressing training data processing or data engineering related to LLMs."
      }
    },
    {
      "id": "2506.20179",
      "abstract": "Deep learning-based pansharpening has been shown to effectively generate high-resolution multispectral (HRMS) images. To create supervised ground-truth HRMS images, synthetic data generated using the Wald protocol is commonly employed. This protocol assumes that networks trained on artificial low-resolution data will perform equally well on high-resolution data. However, well-trained models typically exhibit a trade-off in performance between reduced-resolution and full-resolution datasets. In this paper, we delve into the Wald protocol and find that its inaccurate approximation of real-world degradation patterns limits the generalization of deep pansharpening models. To address this issue, we propose the Progressive Alignment Degradation Module (PADM), which uses mutual iteration between two sub-networks, PAlignNet and PDegradeNet, to adaptively learn accurate degradation processes without relying on predefined operators. Building on this, we introduce HFreqdiff, which embeds high-frequency details into a diffusion framework and incorporates CFB and BACM modules for frequency-selective detail extraction and precise reverse process learning. These innovations enable effective integration of high-resolution panchromatic and multispectral images, significantly enhancing spatial sharpness and quality. Experiments and ablation studies demonstrate the proposed method's superior performance compared to state-of-the-art techniques.",
      "authors": [
        "Enzhe Zhao",
        "Zhichang Guo",
        "Yao Li",
        "Fanghui Song and Boying Wu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20179",
        "HTML": "https://arxiv.org/html/2506.20179",
        "PDF": "https://arxiv.org/pdf/2506.20179"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:07:32 GMT",
          "size": "9333kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Progressive Alignment Degradation Learning for Pansharpening",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses pansharpening and image processing techniques and does not involve any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.20181",
      "abstract": "We develop a principled framework for discovering causal structure in partial differential equations (PDEs) using physics-informed neural networks and counterfactual perturbations. Unlike classical residual minimization or sparse regression methods, our approach quantifies operator-level necessity through functional interventions on the governing dynamics. We introduce causal sensitivity indices and structural deviation metrics to assess the influence of candidate differential operators within neural surrogates. Theoretically, we prove exact recovery of the causal operator support under restricted isometry or mutual coherence conditions, with residual bounds guaranteeing identifiability. Empirically, we validate the framework on both synthetic and real-world datasets across climate dynamics, tumor diffusion, and ocean flows. Our method consistently recovers governing operators even under noise, redundancy, and data scarcity, outperforming standard PINNs and DeepONets in structural fidelity. This work positions causal PDE discovery as a tractable and interpretable inference task grounded in structural causal models and variational residual analysis.",
      "authors": [
        "Ronald Katende"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20181",
        "HTML": "https://arxiv.org/html/2506.20181",
        "PDF": "https://arxiv.org/pdf/2506.20181"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:15:42 GMT",
          "size": "1471kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on causal discovery in partial differential equations (PDEs) using physics-informed neural networks, which is unrelated to LLM training data processing or data engineering aspects."
      }
    },
    {
      "id": "2506.20187",
      "abstract": "Advanced Large Language Models (LLMs) have achieved impressive performance across a wide range of complex and long-context natural language tasks. However, performing long-context LLM inference locally on a commodity GPU (a PC) with privacy concerns remains challenging due to the increasing memory demands of the key-value (KV) cache. Existing systems typically identify important tokens and selectively offload their KV data to GPU and CPU memory. The KV data needs to be offloaded to disk due to the limited memory on a commodity GPU, but the process is bottlenecked by token importance evaluation overhead and the disk's low bandwidth. In this paper, we present LeoAM, the first efficient importance-aware long-context LLM inference system for a single commodity GPU with adaptive hierarchical GPU-CPU-Disk KV management. Our system employs an adaptive KV management strategy that partitions KV data into variable-sized chunks based on the skewed distribution of attention weights across different layers to reduce computational and additional transmission overheads. Moreover, we propose a lightweight KV abstract method, which minimizes transmission latency by storing and extracting the KV abstract of each chunk on disk instead of the full KV data. LeoAM also leverages the dynamic compression and pipeline techniques to further accelerate inference. Experimental results demonstrate that LongInfer achieves an average inference latency speedup of 3.46x, while maintaining comparable LLM response quality. In scenarios with larger batch sizes, it achieves up to a 5.47x speedup.",
      "authors": [
        "He Sun",
        "Li Li",
        "Mingjun Xiao",
        "Chengzhong Xu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20187",
        "HTML": "https://arxiv.org/html/2506.20187",
        "PDF": "https://arxiv.org/pdf/2506.20187"
      },
      "subjects": [
        "Operating Systems (cs.OS)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:26:42 GMT",
          "size": "989kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Breaking the Boundaries of Long-Context LLM Inference: Adaptive KV Management on a Single Commodity GPU",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses inference optimization for LLMs on commodity GPUs, involving KV cache management. It does not discuss training data processing or engineering for LLMs."
      }
    },
    {
      "id": "2506.20188",
      "abstract": "DefElement is an online encyclopedia of finite element definitions that was created and is maintained by the authors of this paper. DefElement aims to make information about elements defined in the literature easily available in a standard format. There are a number of open-source finite element libraries available, and it can be difficult to check that an implementation of an element in a library matches the element's definition in the literature or implementation in another library, especially when many libraries include variants of elements whose basis functions do not match exactly. In this paper, we carefully derive conditions under which elements can be considered equivalent and describe an algorithm that uses these conditions to verify that two implementations of a finite element are indeed variants of the same element. The results of scheduled runs of our implementation of this verification algorithm are included in the information available on DefElement.",
      "authors": [
        "Matthew W. Scroggs and Pablo D. Brubeck and Joseph P. Dean and J{\\o}rgen S. Dokken and India Marsden"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20188",
        "HTML": "https://arxiv.org/html/2506.20188",
        "PDF": "https://arxiv.org/pdf/2506.20188"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:29:35 GMT",
          "size": "1523kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DefElement: an encyclopedia of finite element definitions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "DefElement is about finite element definitions and their verification, with no indication of any relation to LLM training data engineering or processing."
      }
    },
    {
      "id": "2506.20194",
      "abstract": "Large language models (LLMs) deliver strong performance but are difficult to deploy due to high memory and compute costs. While pruning reduces these demands, most methods ignore activation sparsity observed at runtime. We reinterpret activation sparsity as dynamic structured weight sparsity and propose DuoGPT, a unified framework that constructs dual-sparse (spMspV) workloads by combining unstructured weight pruning with activation sparsity. To preserve accuracy, we extend the Optimal Brain Compression (OBC) framework with activation-aware calibration and introduce output residuals from the dense model as correction terms. We further optimize the solution for efficient GPU execution, enabling scalability to billion-parameter LLMs. Evaluations on LLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured pruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\\times$ compared to the baseline dense model.",
      "authors": [
        "Ruokai Yin",
        "Yuhang Li",
        "Donghyun Lee",
        "Priyadarshini Panda"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20194",
        "HTML": "https://arxiv.org/html/2506.20194",
        "PDF": "https://arxiv.org/pdf/2506.20194"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:35:12 GMT",
          "size": "1087kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on pruning methods for reducing memory and computational costs in large language models but does not address any aspect of training data processing or data engineering."
      }
    },
    {
      "id": "2506.20195",
      "abstract": "We propose a quasi-Grassmannian gradient flow model for eigenvalue problems of linear operators, aiming to efficiently address many eigenpairs. Our model inherently ensures asymptotic orthogonality: without the need for initial orthogonality, the solution naturally evolves toward being orthogonal over time. We establish the well-posedness of the model, and provide the analytical representation of solutions. Through asymptotic analysis, we show that the gradient converges exponentially to zero and that the energy decreases exponentially to its minimum. This implies that the solution of the quasi-Grassmannian gradient flow model converges to the solution of the eigenvalue problems as time progresses. These properties not only eliminate the need for explicit orthogonalization in numerical computation but also significantly enhance robustness of the model, rendering it far more resilient to numerical perturbations than conventional methods.",
      "authors": [
        "Shengyue Wang and Aihui Zhou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20195",
        "HTML": "https://arxiv.org/html/2506.20195",
        "PDF": "https://arxiv.org/pdf/2506.20195"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:36:39 GMT",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A quasi-Grassmannian gradient flow model for eigenvalue problems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is related to mathematical modeling for eigenvalue problems and does not involve any aspect of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20196",
      "abstract": "Parabolic Trough solar fields are among the most prominent methods for harnessing solar energy. However, continuous sun-tracking movements leads to wear and degradation of the tracking system, raising the question of whether the rotations can be minimized without compromising energy capture. In this paper, we address this question by exploring two problems: (1) minimizing the number of SCA rotational movements while maintaining energy production within a specified range, and (2) maximizing energy capture when the number of rotations is limited. Unlike prior work, we develop a general framework that considers variable conditions. By transforming the problem into grid-based path optimization, we design polynomial-time algorithms that can operate independently of the weather throughout the day. Through realistic simulations and experiments using real-world data, our methods show that rotational movements of solar trackers can be reduced by at least 10% while maintaining over 95% energy collection efficiency. These results offer a scalable solution for improving the operational lifespan of the solar field. Furthermore, our methods can be integrated with solar irradiance forecasting, enhancing their robustness and suitability for real-world deployment.",
      "authors": [
        "Jos\\'e-Miguel D\\'iaz-Ba\\~nez",
        "Jos\\'e-Manuel Higes-L\\'opez",
        "Miguel-Angel P\\'erez-Cuti\\~no and Tom Todtenhaupt"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20196",
        "HTML": "https://arxiv.org/html/2506.20196",
        "PDF": "https://arxiv.org/pdf/2506.20196"
      },
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:36:56 GMT",
          "size": "11106kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Modeling energy collection with shortest paths in rectangular grids: an efficient algorithm for energy harvesting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses energy collection optimization in solar fields, not related to any aspect of training data processing for large language models."
      }
    },
    {
      "id": "2506.20197",
      "abstract": "A growing fraction of all code is sampled from Large Language Models (LLMs). We investigate the problem of attributing code generated by language models using hypothesis testing to leverage established techniques and guarantees. Given a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to assess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse of dimensionality, this is intractable when only samples from the LLM are given: to circumvent this, we use both samples and density estimates from the LLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames attribution as a distribution testing problem. Our experiments on a benchmark of code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores ( $\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and Stable-Code using only $\\approx 2000$ samples.",
      "authors": [
        "Cl\\'ement L. Canonne",
        "Yash Pote",
        "Uddalok Sarkar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20197",
        "HTML": "https://arxiv.org/html/2506.20197",
        "PDF": "https://arxiv.org/pdf/2506.20197"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:37:16 GMT",
          "size": "269kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on attribution of code generated by LLMs using distribution testing, with no focus on LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20201",
      "abstract": "In order to numerically solve high-dimensional nonlinear PDEs and alleviate the curse of dimensionality, a stochastic particle method (SPM) has been proposed to capture the relevant feature of the solution through the adaptive evolution of particles [J. Comput. Phys. 527 (2025) 113818]. In this paper, we introduce an active birth-death dynamics of particles to improve the efficiency of SPM. The resulting method, dubbed SPM-birth-death, sample new particles according to the nonlinear term and execute the annihilation strategy when the number of particles exceeds a given threshold. Preliminary numerical experiments on the Allen-Cahn equation demonstrate that SPM-birth-death can achieve smaller errors at the same computational cost compared with the original SPM.",
      "authors": [
        "Zhengyang Lei and Sihong Shao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20201",
        "HTML": "https://arxiv.org/html/2506.20201",
        "PDF": "https://arxiv.org/pdf/2506.20201"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:41:40 GMT",
          "size": "252kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Stochastic particle method with birth-death dynamics",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a stochastic particle method with birth-death dynamics aimed at improving numerical solutions for high-dimensional PDEs. The content is unrelated to LLM training data or data processing tasks for language models."
      }
    },
    {
      "id": "2506.20202",
      "abstract": "With the advancement of Gaussian Splatting techniques, a growing number of datasets based on this representation have been developed. However, performing accurate and efficient clipping for Gaussian Splatting remains a challenging and unresolved problem, primarily due to the volumetric nature of Gaussian primitives, which makes hard clipping incapable of precisely localizing their pixel-level contributions. In this paper, we propose a hybrid rendering framework that combines rasterization and ray tracing to achieve efficient and high-fidelity clipping of Gaussian Splatting data. At the core of our method is the RaRa strategy, which first leverages rasterization to quickly identify Gaussians intersected by the clipping plane, followed by ray tracing to compute attenuation weights based on their partial occlusion. These weights are then used to accurately estimate each Gaussian's contribution to the final image, enabling smooth and continuous clipping effects. We validate our approach on diverse datasets, including general Gaussians, hair strand Gaussians, and multi-layer Gaussians, and conduct user studies to evaluate both perceptual quality and quantitative performance. Experimental results demonstrate that our method delivers visually superior results while maintaining real-time rendering performance and preserving high fidelity in the unclipped regions.",
      "authors": [
        "Da Li",
        "Donggang Jia",
        "Yousef Rajeh",
        "Dominik Engel and Ivan Viola"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20202",
        "HTML": "https://arxiv.org/html/2506.20202",
        "PDF": "https://arxiv.org/pdf/2506.20202"
      },
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:45:56 GMT",
          "size": "36599kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "RaRa Clipper: A Clipper for Gaussian Splatting Based on Ray Tracer and Rasterizer",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus here is on a new method for efficient clipping in Gaussian Splatting data using ray tracing and rasterization, mainly applied to rendering tasks. It does not pertain to LLM training data or its processing."
      }
    },
    {
      "id": "2506.20204",
      "abstract": "Affective priming exemplifies the challenge of ambiguity in affective computing. While the community has largely addressed this issue from a label-based perspective, identifying data points in the sequence affected by the priming effect, the impact of priming on data itself, particularly in physiological signals, remains underexplored. Data affected by priming can lead to misclassifications when used in learning models. This study proposes the Affective Priming Score (APS), a data-driven method to detect data points influenced by the priming effect. The APS assigns a score to each data point, quantifying the extent to which it is affected by priming. To validate this method, we apply it to the SEED and SEED-VII datasets, which contain sufficient transitions between emotional events to exhibit priming effects. We train models with the same configuration using both the original data and priming-free sequences. The misclassification rate is significantly reduced when using priming-free sequences compared to the original data. This work contributes to the broader challenge of ambiguity by identifying and mitigating priming effects at the data level, enhancing model robustness, and offering valuable insights for the design and collection of affective computing datasets.",
      "authors": [
        "Eduardo Gutierrez Maestro",
        "Hadi Banaee",
        "Amy Loutfi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20204",
        "HTML": "https://arxiv.org/html/2506.20204",
        "PDF": "https://arxiv.org/pdf/2506.20204"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:48:22 GMT",
          "size": "686kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study addresses the impact of affective priming on physiological data used in learning models, proposing a method to detect priming effects. It does not relate to LLM training data or data processing specifically for language models."
      }
    },
    {
      "id": "2506.20207",
      "abstract": "Mobile Augmented Reality (AR) applications leverage various sensors to provide immersive user experiences. However, their reliance on diverse data sources introduces significant privacy challenges. This paper investigates user perceptions and understanding of privacy permissions in mobile AR apps through an analysis of existing applications and an online survey of 120 participants. Findings reveal common misconceptions, including confusion about how permissions relate to specific AR functionalities (e.g., location and measurement of physical distances), and misinterpretations of permission labels (e.g., conflating camera and gallery access). We identify a set of actionable implications for designing more usable and transparent privacy mechanisms tailored to mobile AR technologies, including contextual explanations, modular permission requests, and clearer permission labels. These findings offer actionable guidance for developers, researchers, and policymakers working to enhance privacy frameworks in mobile AR.",
      "authors": [
        "Viktorija Paneva",
        "Verena Winterhalter",
        "Franziska Augustinowski",
        "Florian Alt"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20207",
        "HTML": "https://arxiv.org/html/2506.20207",
        "PDF": "https://arxiv.org/pdf/2506.20207"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:52:12 GMT",
          "size": "1060kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "User Understanding of Privacy Permissions in Mobile Augmented Reality: Perceptions and Misconceptions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on user understanding of privacy permissions in mobile AR applications, which does not directly relate to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20209",
      "abstract": "In the realm of Natural Language Processing (NLP), common approaches for handling human disagreement consist of aggregating annotators' viewpoints to establish a single ground truth. However, prior studies show that disregarding individual opinions can lead can lead to the side effect of underrepresenting minority perspectives, especially in subjective tasks, where annotators may systematically disagree because of their preferences. Recognizing that labels reflect the diverse backgrounds, life experiences, and values of individuals, this study proposes a new multi-perspective approach using soft labels to encourage the development of the next generation of perspective aware models, more inclusive and pluralistic. We conduct an extensive analysis across diverse subjective text classification tasks, including hate speech, irony, abusive language, and stance detection, to highlight the importance of capturing human disagreements, often overlooked by traditional aggregation methods. Results show that the multi-perspective approach not only better approximates human label distributions, as measured by Jensen-Shannon Divergence (JSD), but also achieves superior classification performance (higher F1 scores), outperforming traditional approaches. However, our approach exhibits lower confidence in tasks like irony and stance detection, likely due to the inherent subjectivity present in the texts. Lastly, leveraging Explainable AI (XAI), we explore model uncertainty and uncover meaningful insights into model predictions.",
      "authors": [
        "Benedetta Muscato",
        "Lucia Passaro",
        "Gizem Gezici",
        "Fosca Giannotti"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20209",
        "HTML": "https://arxiv.org/html/2506.20209",
        "PDF": "https://arxiv.org/pdf/2506.20209"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:53:36 GMT",
          "size": "2572kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses a multi-perspective approach for NLP systems, focusing on handling human disagreement in text classification, not on LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20212",
      "abstract": "With the advent of Industry 5.0, manufacturers are increasingly prioritizing worker well-being alongside mass customization. Stress-aware Human-Robot Collaboration (HRC) plays a crucial role in this paradigm, where robots must adapt their behavior to human mental states to improve collaboration fluency and safety. This paper presents a novel framework that integrates Federated Learning (FL) to enable personalized mental state evaluation while preserving user privacy. By leveraging physiological signals, including EEG, ECG, EDA, EMG, and respiration, a multimodal model predicts an operator's stress level, facilitating real-time robot adaptation. The FL-based approach allows distributed on-device training, ensuring data confidentiality while improving model generalization and individual customization. Results demonstrate that the deployment of an FL approach results in a global model with performance in stress prediction accuracy comparable to a centralized training approach. Moreover, FL allows for enhancing personalization, thereby optimizing human-robot interaction in industrial settings, while preserving data privacy. The proposed framework advances privacy-preserving, adaptive robotics to enhance workforce well-being in smart manufacturing.",
      "authors": [
        "Andrea Bussolan",
        "Oliver Avram",
        "Andrea Pignata",
        "Gianvito Urgese",
        "Stefano Baraldo",
        "Anna Valente"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20212",
        "HTML": "https://arxiv.org/html/2506.20212",
        "PDF": "https://arxiv.org/pdf/2506.20212"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:55:59 GMT",
          "size": "14314kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Personalized Mental State Evaluation in Human-Robot Interaction using Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research deals with personalized mental state evaluation using federated learning in human-robot interaction, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20214",
      "abstract": "Unified multimodal large language models (MLLMs) have shown promise in jointly advancing multimodal understanding and generation, with visual codebooks discretizing images into tokens for autoregressive modeling. Existing codebook-based methods either rely on small vocabularies (~16K entries) that lack fine-grained semantics or naively scale up, resulting in low token utilization and unstable training. We propose UniCode$^2$, a cascaded codebook framework enabling large-scale, semantically aligned, and stable visual tokenization. By clustering millions of SigLIP sequence embeddings, we build a 500K-entry codebook that preserves vision-language alignment while expanding capacity. Stability is ensured via a cascaded design: a frozen codebook anchors the embedding space, and a trainable codebook refines task-specific semantics. This decoupling promotes high utilization and robust learning. Moreover, the alignment of our visual tokens with textual semantics enables seamless integration with pretrained diffusion decoders, supporting high-quality visual synthesis with minimal adaptation. UniCode^2 delivers strong performance across diverse benchmarks, demonstrating the viability of scaling visual token spaces without sacrificing stability, semantics, or modularity.",
      "authors": [
        "Yanzhe Chen (Yen-chieh Chan)",
        "Huasong Zhong",
        "Yan Li",
        "Zhenheng Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20214",
        "HTML": "https://arxiv.org/html/2506.20214",
        "PDF": "https://arxiv.org/pdf/2506.20214"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:57:09 GMT",
          "size": "3747kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Although the paper discusses processing of visual tokens for multimodal models, it does not propose methods inherent to the data engineering or data processing stages for LLM training."
      }
    },
    {
      "id": "2506.20217",
      "abstract": "Research Software Engineering (RSEng) is a key success factor in producing high-quality research software, which in turn enables and improves research outcomes. However, as a principal investigator or leader of a research group you may not know what RSEng is, where to get started with it, or how to use it to maximize its benefit for your research. RSEng also often comes with technical complexity, and therefore reduced accessibility to some researchers. The ten simple rules presented in this paper aim to improve the accessibility of RSEng, and provide practical and actionable advice to PIs and leaders for integrating RSEng into their research group. By following these rules, readers can improve the quality, reproducibility, and trustworthiness of their research software, ultimately leading to better, more reproducible and more trustworthy research outcomes.",
      "authors": [
        "Stuart M. Allen and Neil Chue Hong and Stephan Druskat and Toby Hodges and Daniel S. Katz and Jan Linxweiler and Frank L\\\"offler and Lars Grunske and Heidi Seibold and Jan Philipp Thiele and Samantha Wittke"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20217",
        "HTML": "https://arxiv.org/html/2506.20217",
        "PDF": "https://arxiv.org/pdf/2506.20217"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:59:37 GMT",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Ten simple rules for PIs to integrate Research Software Engineering into their research group",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper provides guidelines for integrating Research Software Engineering into research groups, not focusing on LLM training data processing or related methods."
      }
    },
    {
      "id": "2506.20218",
      "abstract": "We present the first upper bound on the convergence time to consensus of the well-known $h$-majority dynamics with $k$ opinions, in the synchronous setting, for $h$ and $k$ that are both non-constant values.\n  We suppose that, at the beginning of the process, there is some initial additive bias towards some plurality opinion, that is, there is an opinion that is supported by $x$ nodes while any other opinion is supported by strictly fewer nodes.\n  We prove that, with high probability, if the bias is $\\omega(\\sqrt{x})$ and the initial plurality opinion is supported by at least $x = \\omega(\\log n)$ nodes, then the process converges to plurality consensus in $O(\\log n)$ rounds whenever $h = \\omega(n \\log n / x)$.\n  A main corollary is the following: if $k = o(n / \\log n)$ and the process starts from an almost-balanced configuration with an initial bias of magnitude $\\omega(\\sqrt{n/k})$ towards the initial plurality opinion, then any function $h = \\omega(k \\log n)$ suffices to guarantee convergence to consensus in $O(\\log n)$ rounds, with high probability.\n  Our upper bound shows that the lower bound of $\\Omega(k / h^2)$ rounds to reach consensus given by Becchetti et al.\\ (2017) cannot be pushed further than $\\widetilde{\\Omega}(k / h)$.\n  Moreover, the bias we require is asymptotically smaller than the $\\Omega(\\sqrt{n\\log n})$ bias that guarantees plurality consensus in the $3$-majority dynamics: in our case, the required bias is at most any (arbitrarily small) function in $\\omega(\\sqrt{x})$ for any value of $k \\ge 2$.",
      "authors": [
        "Francesco d'Amore",
        "Niccol\\`o D'Archivio",
        "George Giakkoupis and Emanuele Natale"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20218",
        "HTML": "https://arxiv.org/html/2506.20218",
        "PDF": "https://arxiv.org/pdf/2506.20218"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:01:58 GMT",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the $h$-majority dynamics with many opinions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the convergence time of the $h$-majority dynamics in opinion dynamics, which is not related to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20221",
      "abstract": "Motivated by the theory of proof complexity generators we consider the following $\\Sigma^p_2$ search problem $\\mbox{DD}_P$ determined by a propositional proof system $P$: given a $P$-proof $\\pi$ of a disjunction $\\bigvee_i \\alpha_i$, no two $\\alpha_i$ having an atom in common, find $i$ such that $\\alpha_i \\in \\mbox{TAUT}$.\n  We formulate a hypothesis (ST) that for some strong proof system $P$ the problem $\\mbox{DD}_P$ is not solvable in the student-teacher model with a p-time student and a constant number of rounds. The hypothesis follows from the existence of hard one-way permutations.\n  We prove, using a model-theoretic assumption, that (ST) implies $NP \\neq coNP$. The assumption concerns the existence of extensions of models of a bounded arithmetic theory and it is open at present if it holds.",
      "authors": [
        "Jan Krajicek"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20221",
        "HTML": "https://arxiv.org/html/2506.20221",
        "PDF": "https://arxiv.org/pdf/2506.20221"
      },
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:07:51 GMT",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On $NP \\cap coNP$ proof complexity generators",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is concerned with proof complexity and a hypothetical problem related to $NP \\cap coNP$, and does not discuss LLM training data or data processing."
      }
    },
    {
      "id": "2506.20222",
      "abstract": "Event cameras asynchronously capture pixel-level intensity changes with extremely low latency. They are increasingly used in conjunction with RGB cameras for a wide range of vision-related applications. However, a major challenge in these hybrid systems lies in the transmission of the large volume of triggered events and RGB images. To address this, we propose a transmission scheme that retains efficient reconstruction performance of both sources while accomplishing real-time deblurring in parallel. Conventional RGB cameras and event cameras typically capture the same scene in different ways, often resulting in significant redundant information across their outputs. To address this, we develop a joint event and image (E-I) transmission framework to eliminate redundancy and thereby optimize channel bandwidth utilization. Our approach employs Bayesian modeling and the information bottleneck method to disentangle the shared and domain-specific information within the E-I inputs. This disentangled information bottleneck framework ensures both the compactness and informativeness of extracted shared and domain-specific information. Moreover, it adaptively allocates transmission bandwidth based on scene dynamics, i.e., more symbols are allocated to events for dynamic details or to images for static information. Simulation results demonstrate that the proposed scheme not only achieves superior reconstruction quality compared to conventional systems but also delivers enhanced deblurring performance.",
      "authors": [
        "Pujing Yang",
        "Guangyi Zhang",
        "Yunlong Cai",
        "Lei Yu",
        "and Guanding Yu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20222",
        "HTML": "https://arxiv.org/html/2506.20222",
        "PDF": "https://arxiv.org/pdf/2506.20222"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:09:21 GMT",
          "size": "2243kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research proposes a transmission scheme for hybrid event-RGB systems and does not involve LLMs or the processing of training data specific to them."
      }
    },
    {
      "id": "2506.20225",
      "abstract": "Preprints have become increasingly essential in the landscape of open science, facilitating not only the exchange of knowledge within the scientific community but also bridging the gap between science and technology. However, the impact of preprints on technological innovation, given their unreviewed nature, remains unclear. This study fills this gap by conducting a comprehensive scientometric analysis of patent citations to bioRxiv preprints submitted between 2013 and 2021, measuring and accessing the contribution of preprints in accelerating knowledge transfer from science to technology. Our findings reveal a growing trend of patent citations to bioRxiv preprints, with a notable surge in 2020, primarily driven by the COVID-19 pandemic. Preprints play a critical role in accelerating innovation, not only expedite the dissemination of scientific knowledge into technological innovation but also enhance the visibility of early research results in the patenting process, while journals remain essential for academic rigor and reliability. The substantial number of post-online-publication patent citations highlights the critical role of the open science model-particularly the \"open access\" effect of preprints-in amplifying the impact of science on technological innovation. This study provides empirical evidence that open science policies encouraging the early sharing of research outputs, such as preprints, contribute to more efficient linkage between science and technology, suggesting an acceleration in the pace of innovation, higher innovation quality, and economic benefits.",
      "authors": [
        "Zhiqi Wang",
        "Yue Chen",
        "Chun Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20225",
        "HTML": "https://arxiv.org/html/2506.20225",
        "PDF": "https://arxiv.org/pdf/2506.20225"
      },
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:13:05 GMT",
          "size": "2031kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The role of preprints in open science: Accelerating knowledge transfer from science to technology",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study examines the role of preprints in open science and their impact on innovation, which is unrelated to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20228",
      "abstract": "Phishing attacks frequently use email body obfuscation to bypass detection filters, but quantitative insights into how techniques are combined and their impact on filter scores remain limited. This paper addresses this gap by empirically investigating the prevalence, co-occurrence patterns, and spam score associations of body obfuscation techniques. Analysing 386 verified phishing emails, we quantified ten techniques, identified significant pairwise co-occurrences revealing strategic layering like the presence of text in images with multipart abuse, and assessed associations with antispam scores using multilinear regression. Text in Image (47.0%), Base64 Encoding (31.2%), and Invalid HTML (28.8%) were highly prevalent. Regression (R${}^2$=0.486, p<0.001) linked Base64 Encoding and Text in Image with significant antispam evasion (p<0.05) in this configuration, suggesting potential bypass capabilities, while Invalid HTML correlated with higher scores. These findings establish a quantitative baseline for complex evasion strategies, underscoring the need for multi-modal defences against combined obfuscation tactics.",
      "authors": [
        "Antony Dalmiere (LAAS)",
        "Zheng Zhou (LAAS)",
        "Guillaume Auriol (LAAS-TRUST",
        "INSA Toulouse)",
        "Vincent Nicomette (LAAS-TSF",
        "LAAS-TRUST)",
        "Pascal Marchand (LERASS",
        "IUT Paul Sabatier)"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20228",
        "HTML": "https://arxiv.org/html/2506.20228",
        "PDF": "https://arxiv.org/pdf/2506.20228"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:20:38 GMT",
          "size": "874kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Measuring Modern Phishing Tactics: A Quantitative Study of Body Obfuscation Prevalence, Co-occurrence, and Filter Impact",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper analyzes phishing tactics and obfuscation in emails, which does not pertain to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20234",
      "abstract": "In this work, we propose a differentially private algorithm for publishing matrices aggregated from sparse vectors. These matrices include social network adjacency matrices, user-item interaction matrices in recommendation systems, and single nucleotide polymorphisms (SNPs) in DNA data. Traditionally, differential privacy in vector collection relies on randomized response, but this approach incurs high communication costs. Specifically, for a matrix with $N$ users, $n$ columns, and $m$ nonzero elements, conventional methods require $\\Omega(n \\times N)$ communication, making them impractical for large-scale data. Our algorithm significantly reduces this cost to $O(\\varepsilon m)$, where $\\varepsilon$ is the privacy budget. Notably, this is even lower than the non-private case, which requires $\\Omega(m \\log n)$ communication. Moreover, as the privacy budget decreases, communication cost further reduces, enabling better privacy with improved efficiency. We theoretically prove that our method yields results identical to those of randomized response, and experimental evaluations confirm its effectiveness in terms of accuracy, communication efficiency, and computational complexity.",
      "authors": [
        "Quentin Hillebrand",
        "Vorapong Suppakitpaisarn",
        "and Tetsuo Shibuya"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20234",
        "HTML": "https://arxiv.org/html/2506.20234",
        "PDF": "https://arxiv.org/pdf/2506.20234"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:25:46 GMT",
          "size": "2587kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Communication-Efficient Publication of Sparse Vectors under Differential Privacy",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a differentially private algorithm for publishing matrices, which is unrelated to the specific focus of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20235",
      "abstract": "Link prediction is a classical problem in graph analysis with many practical applications. For directed graphs, recently developed deep learning approaches typically analyze node similarities through contrastive learning and aggregate neighborhood information through graph convolutions. In this work, we propose a novel graph neural network (GNN) framework to fuse feature embedding with community information. We theoretically demonstrate that such hybrid features can improve the performance of directed link prediction. To utilize such features efficiently, we also propose an approach to transform input graphs into directed line graphs so that nodes in the transformed graph can aggregate more information during graph convolutions. Experiments on benchmark datasets show that our approach outperforms the state-of-the-art in most cases when 30%, 40%, 50%, and 60% of the connected links are used as training data, respectively.",
      "authors": [
        "Yuyang Zhang",
        "Xu Shen",
        "Yu Xie",
        "Ka-Chun Wong",
        "Weidun Xie",
        "and Chengbin Peng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20235",
        "HTML": "https://arxiv.org/html/2506.20235",
        "PDF": "https://arxiv.org/pdf/2506.20235"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:25:56 GMT",
          "size": "6057kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Directed Link Prediction using GNN with Local and Global Feature Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on improving link prediction in graph analysis using GNNs, without addressing any aspects of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20238",
      "abstract": "This paper introduces a data-driven topology identification and correction approach for low-voltage distribution networks (LVDNs) combined with a time-based smart meter data selection strategy, aiming to correct outdated recordings and identify the missed recordings. The proposed approach solely relies on voltage magnitude measurements, releasing privacy concerns and measurement burdens. It enables the distribution system operators to identify switch states through supervised learning algorithms, as well as determine user-feeder connections and phase labels of customers by a modified Hierarchical Clustering algorithm. To address the similarity among smart meter (SM) data caused by distributed photovoltaic (PV) systems, a time-based SM data selection strategy is combined with the proposed correlation analysis. The feasibility and robustness of the proposed approach are validated using modified real-world LVDNs and multiple incomplete SM datasets collected from customers in the Netherlands. The results demonstrate that the time-based SM data selection strategy effectively mitigates their impact on phase identification, and the corrected topology not only improves network observability but also supports network operators in load balancing and PV consumption.",
      "authors": [
        "Dong Liu",
        "Sander Timmerman",
        "Yu Xiang",
        "Peter Palensky",
        "and Pedro P. Vergara"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20238",
        "HTML": "https://arxiv.org/html/2506.20238",
        "PDF": "https://arxiv.org/pdf/2506.20238"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:31:42 GMT",
          "size": "4625kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Data-Driven Approach for Topology Correction in Low Voltage Networks with DERs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with topology correction in low-voltage networks using smart meter data, which does not pertain to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20240",
      "abstract": "A low-order nonconforming finite element discretization of a smooth de Rham complex starting from the $H^2$ space in three dimensions is proposed, involving an $H^2$-nonconforming finite element space, a new tangentially continuous $H^1$-nonconforming vector-valued finite element space, the lowest-order Raviart-Thomas space, and piecewise constant functions. While nonconforming for the smooth complex, the discretization conforms to the classical de Rham complex. It is applied to develop a decoupled mixed finite element method for a fourth-order elliptic singular perturbation problem, focusing on the discretization of a generalized singularly perturbed Stokes-type equation. In contrast to Nitsche's method, which requires additional stabilization to handle boundary layers, the nodal interpolation operator for the lowest-order N\\'{e}d\\'{e}lec element of the second kind is introduced into the discrete bilinear forms. This modification yields a decoupled mixed method that achieves optimal convergence rates uniformly with respect to the perturbation parameter, even in the presence of strong boundary layers, without requiring any additional stabilization.",
      "authors": [
        "Xuewei Cui and Xuehai Huang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20240",
        "HTML": "https://arxiv.org/html/2506.20240",
        "PDF": "https://arxiv.org/pdf/2506.20240"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:34:54 GMT",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Low-order finite element complex with application to a fourth-order elliptic singular perturbation problem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is concerned with finite element methods for elliptic singular perturbation problems, which are unrelated to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20243",
      "abstract": "Automatic fluency assessment (AFA) remains challenging, particularly in capturing speech rhythm, pauses, and disfluencies in non-native speakers. We introduce a chunk-based approach integrating self-supervised learning (SSL) models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths in phonetic, prosodic, and noisy speech modeling, with a hierarchical CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero voice activity detection (Silero-VAD), enabling fine-grained temporal analysis while mitigating over-segmentation artifacts. SSL embeddings are fused via a learnable weighted mechanism, balancing acoustic and linguistic features, and enriched with chunk-level fluency markers (e.g., speech rate, pause durations, n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on Avalinguo, surpassing Pyannote.audio-based segmentation baselines. These findings highlight chunk-based multi-SSL fusion for robust fluency evaluation, though future work should explore generalization to dialects with irregular prosody.",
      "authors": [
        "Papa S\\'ega Wade",
        "Mihai Andries",
        "Ioannis Kanellos and Thierry Moudenc"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20243",
        "HTML": "https://arxiv.org/html/2506.20243",
        "PDF": "https://arxiv.org/pdf/2506.20243"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:39:22 GMT",
          "size": "375kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on automatic fluency assessment of speech using a chunk-based approach and self-supervised learning models, which does not involve the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20244",
      "abstract": "To empower the low-altitude economy with high-accuracy sensing and high-rate communication, this paper proposes a cooperative integrated sensing and communication (ISAC) framework for aerial-ground networks. In the proposed system, the ground base stations (BSs) cooperatively serve the unmanned aerial vehicles (UAVs), which are equipped for either joint communication and sensing or sensing-only operations. The BSs employ coordinated beamforming to simultaneously transmit communication and sensing signals, while the UAVs execute their missions. To maximize the weighted sum rate under the sensing signal-to-interference-plus-noise ratio (SINR) constraints, we jointly optimize the transmit beamforming, receive filtering, and UAV trajectory. The resulting non-convex problem is solved using an alternating optimization framework incorporating semidefinite relaxation (SDR) and successive convex approximation (SCA). Simulation results demonstrate that the proposed joint design achieves higher communication throughput while ensuring required sensing robustness. Additionally, the sensing SINR threshold and the UAV altitude have a significant impact on the trajectory design, highlighting the necessity of adaptive deployment strategies in practical applications.",
      "authors": [
        "Fangzhi Li",
        "Zhichu Ren",
        "Cunhua Pan",
        "Hong Ren",
        "Jing Jin",
        "Qixing Wang",
        "and Jiangzhou Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20244",
        "HTML": "https://arxiv.org/html/2506.20244",
        "PDF": "https://arxiv.org/pdf/2506.20244"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:41:48 GMT",
          "size": "465kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Cooperative Sensing and Communication Beamforming Design for Low-Altitude Economy",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses cooperative sensing and communication beamforming design for aerial-ground networks, unrelated to the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20252",
      "abstract": "This paper describes a new algorithm called PAT, for Parallel Aggregated Trees, and which can be used to implement all-gather and reduce-scatter operations. This algorithm works on any number of ranks, has a logarithmic number of network transfers for small size operations, minimizes long-distance communication, and requires a logarithmic amount of internal buffers, independently from the total operation size. It is aimed at improving the performance of the NCCL library in cases where the ring algorithm would be inefficient, as its linear latency would show poor performance for small sizes and/or at scale.",
      "authors": [
        "Sylvain Jeaugey"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20252",
        "HTML": "https://arxiv.org/html/2506.20252",
        "PDF": "https://arxiv.org/pdf/2506.20252"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:54:42 GMT",
          "size": "884kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PAT: a new algorithm for all-gather and reduce-scatter operations at scale",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving algorithmic efficiency in communication operations like all-gather and reduce-scatter in networking, with no relation to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20253",
      "abstract": "Forecasting attracts a lot of research attention in the electricity value chain. However, most studies concentrate on short-term forecasting of generation or consumption with a focus on systems and less on individual consumers. Even more neglected is the topic of long-term forecasting of individual power consumption.\n  Here, we provide an in-depth comparative evaluation of data-driven methods for generating synthetic time series data tailored to energy consumption long-term forecasting. High-fidelity synthetic data is crucial for a wide range of applications, including state estimations in energy systems or power grid planning. In this study, we assess and compare the performance of multiple state-of-the-art but less common techniques: a hybrid Wasserstein Generative Adversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM), Hidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial normalizing Flows (MABF). We analyze the ability of each method to replicate the temporal dynamics, long-range dependencies, and probabilistic transitions characteristic of individual energy consumption profiles. Our comparative evaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and MABF aiding in selecting the most suitable approach for state estimations and other energy-related tasks. Our generation and analysis framework aims to enhance the accuracy and reliability of synthetic power consumption data while generating data that fulfills criteria like anonymisation - preserving privacy concerns mitigating risks of specific profiling of single customers. This study utilizes an open-source dataset from households in Germany with 15min time resolution. The generated synthetic power profiles can readily be used in applications like state estimations or consumption forecasting.",
      "authors": [
        "Ben Gerhards",
        "Nikita Popkov",
        "Annekatrin K\\\"onig",
        "Marcel Arpogaus",
        "Bastian Sch\\\"afermeier",
        "Leonie Riedl",
        "Stephan Vogt",
        "Philip Hehlert"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20253",
        "HTML": "https://arxiv.org/html/2506.20253",
        "PDF": "https://arxiv.org/pdf/2506.20253"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:54:47 GMT",
          "size": "15643kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper evaluates methods for generating synthetic time series for energy forecasting, which does not involve LLM training data processing or data engineering tasks related to LLMs."
      }
    },
    {
      "id": "2506.20255",
      "abstract": "We posit that handwriting recognition benefits from complementary cues carried by the rasterized complex glyph and the pen's trajectory, yet most systems exploit only one modality. We introduce an end-to-end network that performs early fusion of offline images and online stroke data within a shared latent space. A patch encoder converts the grayscale crop into fixed-length visual tokens, while a lightweight transformer embeds the $(x, y, \\text{pen})$ sequence. Learnable latent queries attend jointly to both token streams, yielding context-enhanced stroke embeddings that are pooled and decoded under a cross-entropy loss objective. Because integration occurs before any high-level classification, temporal cues reinforce each other during representation learning, producing stronger writer independence. Comprehensive experiments on IAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art accuracy, exceeding previous bests by up to 1\\%. Our study also shows adaptation of this pipeline with gesturification on the ISI-Air dataset. Our code can be found here.",
      "authors": [
        "Ayush Lodh",
        "Ritabrata Chakraborty",
        "Shivakumara Palaiahnakote",
        "Umapada Pal"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20255",
        "HTML": "https://arxiv.org/html/2506.20255",
        "PDF": "https://arxiv.org/pdf/2506.20255"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:58:47 GMT",
          "size": "646kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research addresses improving handwriting recognition through multimodal data processing, not related to LLM training data processing or data engineering for LLMs."
      }
    },
    {
      "id": "2506.20259",
      "abstract": "We introduce a neural network approach for generating and customizing the trajectory of a robotic arm, that guarantees precision and repeatability. To highlight the potential of this novel method, we describe the design and implementation of the technique and show its application in an experimental setting of cognitive robotics. In this scenario, the NICO robot was characterized by the ability to point to specific points in space with precise linear movements, increasing the predictability of the robotic action during its interaction with humans. To achieve this goal, the neural network computes the forward kinematics of the robot arm. By integrating it with a generator of joint angles, another neural network was developed and trained on an artificial dataset created from suitable start and end poses of the robotic arm. Through the computation of angular velocities, the robot was characterized by its ability to perform the movement, and the quality of its action was evaluated in terms of shape and accuracy. Thanks to its broad applicability, our approach successfully generates precise trajectories that could be customized in their shape and adapted to different settings.",
      "authors": [
        "Andrej L\\'u\\v{c}ny",
        "Matilde Antonj",
        "Carlo Mazzola",
        "Hana Horn\\'a\\v{c}kov\\'a",
        "Igor Farka\\v{s}"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20259",
        "HTML": "https://arxiv.org/html/2506.20259",
        "PDF": "https://arxiv.org/pdf/2506.20259"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:05:58 GMT",
          "size": "239kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Generating and Customizing Robotic Arm Trajectories using Neural Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for robotic arm trajectory planning using neural networks, without addressing LLM training data processing or enhancements to the data engineering process for LLMs."
      }
    },
    {
      "id": "2506.20260",
      "abstract": "In machine learning, it is common to obtain multiple equally performing models for the same prediction task, e.g., when training neural networks with different random seeds. Model multiplicity (MM) is the situation which arises when these competing models differ in their predictions for the same input, for which ensembling is often employed to determine an aggregation of the outputs. Providing recourse recommendations via counterfactual explanations (CEs) under MM thus becomes complex, since the CE may not be valid across all models, i.e., the CEs are not robust under MM. In this work, we formalise the problem of providing recourse under MM, which we name recourse-aware ensembling (RAE). We propose the idea that under MM, CEs for each individual model should be considered alongside their predictions so that the aggregated prediction and recourse are decided in tandem. Centred around this intuition, we introduce six desirable properties for solutions to this problem. For solving RAE, we propose a novel argumentative ensembling method which guarantees the robustness of CEs under MM. Specifically, our method leverages computational argumentation to explicitly represent the conflicts between models and counterfactuals regarding prediction results and CE validity. It then uses argumentation semantics to resolve the conflicts and obtain the final solution, in a manner which is parametric to the chosen semantics. Our method also allows for the specification of preferences over the models under MM, allowing further customisation of the ensemble. In a comprehensive theoretical analysis, we characterise the behaviour of argumentative ensembling with four different argumentation semantics. We then empirically demonstrate the effectiveness of our approach in satisfying desirable properties with eight instantiations of our method. (Abstract is shortened for arXiv.)",
      "authors": [
        "Junqi Jiang",
        "Antonio Rago",
        "Francesco Leofante",
        "Francesca Toni"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20260",
        "HTML": "https://arxiv.org/html/2506.20260",
        "PDF": "https://arxiv.org/pdf/2506.20260"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:07:00 GMT",
          "size": "2867kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Argumentative Ensembling for Robust Recourse under Model Multiplicity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on ensembling methods for counterfactual explanations in the context of model multiplicity, without contributions to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20261",
      "abstract": "Universal compression can learn the source and adapt to it either in a batch mode (forward adaptation), or in a sequential mode (backward adaptation). We recast the sequential mode as a multi-armed bandit problem, a fundamental model in reinforcement-learning, and study the trade-off between exploration and exploitation in the lossy compression case. We show that a previously proposed \"natural type selection\" scheme can be cast as a reconstruction-directed MAB algorithm, for sequential lossy compression, and explain its limitations in terms of robustness and short-block performance. We then derive and analyze robust cost-directed MAB algorithms, which work at any block length.",
      "authors": [
        "Nir Weinberger and Ram Zamir"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20261",
        "HTML": "https://arxiv.org/html/2506.20261",
        "PDF": "https://arxiv.org/pdf/2506.20261"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:08:29 GMT",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Exploration-Exploitation Tradeoff in Universal Lossy Compression",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses the exploration-exploitation tradeoff in universal lossy compression, with no discussion related to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20262",
      "abstract": "We consider an unsourced random access (URA) system enhanced with a feedback mechanism that serves both communication and sensing tasks. While traditional URA systems do not incorporate feedback, we propose a novel feedback signal design that announces the decoding status of users and simultaneously enables target sensing. To design this dual-purpose feedback, we introduce a modified projected gradient descent algorithm that minimizes a weighted combination of communication and sensing errors. Simulation results show that the proposed feedback design outperforms the state-of-the-art feedback design in the URA literature. Furthermore, we illustrate the trade-off between communication and sensing capabilities, offering valuable insight into balancing these two tasks.",
      "authors": [
        "Mohammad Javad Ahmadi",
        "Mohammad Kazemi",
        "and Rafael F. Schaefer"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20262",
        "HTML": "https://arxiv.org/html/2506.20262",
        "PDF": "https://arxiv.org/pdf/2506.20262"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:09:28 GMT",
          "size": "243kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Efficient Feedback Design for Unsourced Random Access with Integrated Sensing and Communication",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on feedback design in unsourced random access systems for communication and sensing tasks, which does not involve LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20263",
      "abstract": "Few-shot fine-grained image classification (FS-FGIC) presents a significant challenge, requiring models to distinguish visually similar subclasses with limited labeled examples. Existing methods have critical limitations: metric-based methods lose spatial information and misalign local features, while reconstruction-based methods fail to utilize hierarchical feature information and lack mechanisms to focus on discriminative regions. We propose the Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which integrates dual-layer feature reconstruction with mask-enhanced feature processing to improve fine-grained classification. HMDRN incorporates a dual-layer feature reconstruction and fusion module that leverages complementary visual information from different network hierarchies. Through learnable fusion weights, the model balances high-level semantic representations from the last layer with mid-level structural details from the penultimate layer. Additionally, we design a spatial binary mask-enhanced transformer self-reconstruction module that processes query features through adaptive thresholding while maintaining complete support features, enhancing focus on discriminative regions while filtering background noise. Extensive experiments on three challenging fine-grained datasets demonstrate that HMDRN consistently outperforms state-of-the-art methods across Conv-4 and ResNet-12 backbone architectures. Comprehensive ablation studies validate the effectiveness of each proposed component, revealing that dual-layer reconstruction enhances inter-class discrimination while mask-enhanced transformation reduces intra-class variations. Visualization results provide evidence of HMDRN's superior feature reconstruction capabilities.",
      "authors": [
        "Ning Luo",
        "Meiyin Hu",
        "Huan Wan",
        "Yanyan Yang",
        "Zhuohang Jiang and Xin Wei"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20263",
        "HTML": "https://arxiv.org/html/2506.20263",
        "PDF": "https://arxiv.org/pdf/2506.20263"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:15:59 GMT",
          "size": "1841kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a new method for few-shot fine-grained image classification, with no mention of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20267",
      "abstract": "Interpretable models are crucial for supporting clinical decision-making, driving advances in their development and application for medical images. However, the nature of 3D volumetric data makes it inherently challenging to visualize and interpret intricate and complex structures like the cerebral cortex. Cortical surface renderings, on the other hand, provide a more accessible and understandable 3D representation of brain anatomy, facilitating visualization and interactive exploration. Motivated by this advantage and the widespread use of surface data for studying neurological disorders, we present the eXplainable Surface Vision Transformer (X-SiT). This is the first inherently interpretable neural network that offers human-understandable predictions based on interpretable cortical features. As part of X-SiT, we introduce a prototypical surface patch decoder for classifying surface patch embeddings, incorporating case-based reasoning with spatially corresponding cortical prototypes. The results demonstrate state-of-the-art performance in detecting Alzheimer's disease and frontotemporal dementia while additionally providing informative prototypes that align with known disease patterns and reveal classification errors.",
      "authors": [
        "Fabian Bongratz",
        "Tom Nuno Wolf",
        "Jaume Gual Ramon",
        "Christian Wachinger"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20267",
        "HTML": "https://arxiv.org/html/2506.20267",
        "PDF": "https://arxiv.org/pdf/2506.20267"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:24:07 GMT",
          "size": "1102kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on interpretable neural networks for dementia diagnosis utilizing cortical surface data, unrelated to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20268",
      "abstract": "Detecting miscommunication in human-robot interaction is a critical function for maintaining user engagement and trust. While humans effortlessly detect communication errors in conversations through both verbal and non-verbal cues, robots face significant challenges in interpreting non-verbal feedback, despite advances in computer vision for recognizing affective expressions. This research evaluates the effectiveness of machine learning models in detecting miscommunications in robot dialogue. Using a multi-modal dataset of 240 human-robot conversations, where four distinct types of conversational failures were systematically introduced, we assess the performance of state-of-the-art computer vision models. After each conversational turn, users provided feedback on whether they perceived an error, enabling an analysis of the models' ability to accurately detect robot mistakes. Despite using state-of-the-art models, the performance barely exceeds random chance in identifying miscommunication, while on a dataset with more expressive emotional content, they successfully identified confused states. To explore the underlying cause, we asked human raters to do the same. They could also only identify around half of the induced miscommunications, similarly to our model. These results uncover a fundamental limitation in identifying robot miscommunications in dialogue: even when users perceive the induced miscommunication as such, they often do not communicate this to their robotic conversation partner. This knowledge can shape expectations of the performance of computer vision models and can help researchers to design better human-robot conversations by deliberately eliciting feedback where needed.",
      "authors": [
        "Ruben Janssens",
        "Jens De Bock",
        "Sofie Labat",
        "Eva Verhelst",
        "Veronique Hoste",
        "Tony Belpaeme"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20268",
        "HTML": "https://arxiv.org/html/2506.20268",
        "PDF": "https://arxiv.org/pdf/2506.20268"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:25:04 GMT",
          "size": "1151kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on detecting miscommunications in human-robot dialogue and does not address any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.20269",
      "abstract": "With rapidly evolving media narratives, it has become increasingly critical to not just extract narratives from a given corpus but rather investigate, how they develop over time. While popular narrative extraction methods such as Large Language Models do well in capturing typical narrative elements or even the complex structure of a narrative, applying them to an entire corpus comes with obstacles, such as a high financial or computational cost. We propose a combination of the language understanding capabilities of Large Language Models with the large scale applicability of topic models to dynamically model narrative shifts across time using the Narrative Policy Framework. We apply a topic model and a corresponding change point detection method to find changes that concern a specific topic of interest. Using this model, we filter our corpus for documents that are particularly representative of that change and feed them into a Large Language Model that interprets the change that happened in an automated fashion and distinguishes between content and narrative shifts. We employ our pipeline on a corpus of The Wall Street Journal news paper articles from 2009 to 2023. Our findings indicate that a Large Language Model can efficiently extract a narrative shift if one exists at a given point in time, but does not perform as well when having to decide whether a shift in content or a narrative shift took place.",
      "authors": [
        "Kai-Robin Lange",
        "Tobias Schmidt",
        "Matthias Reccius",
        "Henrik M\\\"uller",
        "Michael Roos",
        "Carsten Jentsch"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20269",
        "HTML": "https://arxiv.org/html/2506.20269",
        "PDF": "https://arxiv.org/pdf/2506.20269"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:25:15 GMT",
          "size": "929kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses narrative shift detection using a combination of topic models and LLMs but does not contribute to the processing or preparation of training data for LLMs."
      }
    },
    {
      "id": "2506.20272",
      "abstract": "The study of canvas fabrics in works of art is a crucial tool for authentication, attribution and conservation. Traditional methods are based on thread density map matching, which cannot be applied when canvases do not come from contiguous positions on a roll. This paper presents a novel approach based on deep learning to assess the similarity of textiles. We introduce an automatic tool that evaluates the similarity between canvases without relying on thread density maps. A Siamese deep learning model is designed and trained to compare pairs of images by exploiting the feature representations learned from the scans. In addition, a similarity estimation method is proposed, aggregating predictions from multiple pairs of cloth samples to provide a robust similarity score. Our approach is applied to canvases from the Museo Nacional del Prado, corroborating the hypothesis that plain weave canvases, widely used in painting, can be effectively compared even when their thread densities are similar. The results demonstrate the feasibility and accuracy of the proposed method, opening new avenues for the analysis of masterpieces.",
      "authors": [
        "Juan Jos\\'e Murillo-Fuentes",
        "Pablo M. Olmos",
        "Laura Alba-Carcel\\'en"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20272",
        "HTML": "https://arxiv.org/html/2506.20272",
        "PDF": "https://arxiv.org/pdf/2506.20272"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:34:10 GMT",
          "size": "1290kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Forensic Study of Paintings Through the Comparison of Fabrics",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research introduces a method for comparing fabrics using deep learning, unrelated to LLM training data requirements or processing."
      }
    },
    {
      "id": "2506.20279",
      "abstract": "Dense prediction tasks hold significant importance of computer vision, aiming to learn pixel-wise annotated label for an input image. Despite advances in this field, existing methods primarily focus on idealized conditions, with limited generalization to real-world scenarios and facing the challenging scarcity of real-world data. To systematically study this problem, we first introduce DenseWorld, a benchmark spanning a broad set of 25 dense prediction tasks that correspond to urgent real-world applications, featuring unified evaluation across tasks. Then, we propose DenseDiT, which maximally exploits generative models' visual priors to perform diverse real-world dense prediction tasks through a unified strategy. DenseDiT combines a parameter-reuse mechanism and two lightweight branches that adaptively integrate multi-scale context, working with less than 0.1% additional parameters. Evaluations on DenseWorld reveal significant performance drops in existing general and specialized baselines, highlighting their limited real-world generalization. In contrast, DenseDiT achieves superior results using less than 0.01% training data of baselines, underscoring its practical value for real-world deployment. Our data, and checkpoints and codes are available at https://xcltql666.github.io/DenseDiTProj",
      "authors": [
        "Changliang Xia and Chengyou Jia and Zhuohang Dang and Minnan Luo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20279",
        "HTML": "https://arxiv.org/html/2506.20279",
        "PDF": "https://arxiv.org/pdf/2506.20279"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:40:50 GMT",
          "size": "9894kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of this paper is on dense prediction in computer vision using a generative model, which is not related to LLM training data or processing."
      }
    },
    {
      "id": "2506.20285",
      "abstract": "Clustered Federated Learning (CFL) addresses the challenges posed by non-IID data by training multiple group- or cluster-specific expert models. However, existing methods often overlook the shared information across clusters, which represents the generalizable knowledge valuable to all participants in the Federated Learning (FL) system. To overcome this limitation, this paper introduces a novel FL framework that distills a universal expert model from the knowledge of multiple clusters. This universal expert captures globally shared information across all clients and is subsequently distributed to each client as the initialization for the next round of model training. The proposed FL framework operates in three iterative steps: (1) local model training at each client, (2) cluster-specific model aggregation, and (3) universal expert distillation. This three-step learning paradigm ensures the preservation of fine-grained non-IID characteristics while effectively incorporating shared knowledge across clusters. Compared to traditional gradient-based aggregation methods, the distillation-based model aggregation introduces greater flexibility in handling model heterogeneity and reduces conflicts among cluster-specific experts. Extensive experimental results demonstrate the superior performance of the proposed method across various scenarios, highlighting its potential to advance the state of CFL by balancing personalized and shared knowledge more effectively.",
      "authors": [
        "Zeqi Leng",
        "Chunxu Zhang",
        "Guodong Long",
        "Riting Xia and Bo Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20285",
        "HTML": "https://arxiv.org/html/2506.20285",
        "PDF": "https://arxiv.org/pdf/2506.20285"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:44:39 GMT",
          "size": "1578kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Distilling A Universal Expert from Clustered Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a Federated Learning framework for distilling expert models and does not address training data processing for LLMs."
      }
    },
    {
      "id": "2506.20290",
      "abstract": "Local differential privacy (LDP) has become a widely accepted framework for privacy-preserving data collection. In LDP, many protocols rely on hash functions to implement user-side encoding and perturbation. However, the security and privacy implications of hash function selection have not been previously investigated. In this paper, we expose that the hash functions may act as a source of unfairness in LDP protocols. We show that although users operate under the same protocol and privacy budget, differences in hash functions can lead to significant disparities in vulnerability to inference and poisoning attacks. To mitigate hash-induced unfairness, we propose Fair-OLH (F-OLH), a variant of OLH that enforces an entropy-based fairness constraint on hash function selection. Experiments show that F-OLH is effective in mitigating hash-induced unfairness under acceptable time overheads.",
      "authors": [
        "Berkay Kemal Balioglu",
        "Alireza Khodaie",
        "Mehmet Emre Gursoy"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20290",
        "HTML": "https://arxiv.org/html/2506.20290",
        "PDF": "https://arxiv.org/pdf/2506.20290"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:48:30 GMT",
          "size": "11011kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Don't Hash Me Like That: Exposing and Mitigating Hash-Induced Unfairness in Local Differential Privacy",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on hash function selection in local differential privacy protocols, unrelated to the processing or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20293",
      "abstract": "The blind fusion of unregistered hyperspectral images (HSIs) and multispectral images (MSIs) has attracted growing attention recently. To address the registration challenge, most existing methods employ spatial transformations on the HSI to achieve alignment with the MSI. However, due to the substantial differences in spatial resolution of the images, the performance of these methods is often unsatisfactory. Moreover, the registration process tends to be time-consuming when dealing with large-sized images in remote sensing. To address these issues, we propose tackling the registration problem from the spectral domain. Initially, a lightweight Spectral Prior Learning (SPL) network is developed to extract spectral features from the HSI and enhance the spectral resolution of the MSI. Following this, the obtained image undergoes spatial downsampling to produce the registered HSI. In this process, subspace representation and cyclic training strategy are employed to improve spectral accuracy of the registered HSI obtained. Next, we propose a blind sparse fusion (BSF) method, which utilizes group sparsity regularization to equivalently promote the low-rankness of the image. This approach not only circumvents the need for rank estimation, but also reduces computational complexity. Then, we employ the Proximal Alternating Optimization (PAO) algorithm to solve the BSF model, and present its convergence analysis. Finally, extensive numerical experiments on simulated and real datasets are conducted to verify the effectiveness of our method in registration and fusion. We also demonstrate its efficacy in enhancing classification performance.",
      "authors": [
        "Kunjing Yang",
        "Libin Zheng",
        "Minru Bai",
        "Ting Lu and Leyuan Fang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20293",
        "HTML": "https://arxiv.org/html/2506.20293",
        "PDF": "https://arxiv.org/pdf/2506.20293"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:00:51 GMT",
          "size": "27218kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on hyperspectral and multispectral image fusion and registration in the spectral domain, which does not relate to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20294",
      "abstract": "Diffusion models have shown strong performance in conditional generation by progressively denoising Gaussian noise toward a target data distribution. This denoising process can be interpreted as a form of hill climbing in a learned latent space, where the model iteratively refines the sample toward regions of higher probability. However, diffusion models often converge to local optima that are locally visually coherent yet globally inconsistent or conditionally misaligned, due to latent space complexity and suboptimal initialization. Prior efforts attempted to address this by strengthening guidance signals or manipulating the initial noise distribution. We introduce Controlled Random Zigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy designed to detect and escape such local maxima during conditional generation. The method first identifies potential local maxima using a reward model. Upon detection, it injects noise and reverts to a previous, noisier state to escape the current optimization plateau. The reward model then evaluates candidate trajectories, accepting only those that offer improvement, while progressively deeper retreat enables stronger escapes when nearby alternatives fail. This controlled random zigzag process allows dynamic alternation between forward refinement and backward exploration, enhancing both alignment and visual quality in the generated outputs. The proposed Ctrl-Z Sampling is model-agnostic and compatible with existing diffusion frameworks. Experimental results show that Ctrl-Z Sampling substantially improves generation quality with only around 7.6X increase in function evaluations.",
      "authors": [
        "Shunqi Mao",
        "Wei Guo",
        "Chaoyi Zhang",
        "Weidong Cai"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20294",
        "HTML": "https://arxiv.org/html/2506.20294",
        "PDF": "https://arxiv.org/pdf/2506.20294"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:01:00 GMT",
          "size": "8729kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a novel sampling strategy for diffusion models in the context of image generation, not pertaining to processing or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20299",
      "abstract": "This paper explores the pedagogical potential of \"teacher pre-prompting\" as a means of guiding student collaboration in programming education. In particular, we investigate how brief teacher-initiated questions posed before students engage in pair programming workshops can help shape problem interpretation and division of labor. Based on qualitative analysis of video data from a university course in systems development, we identify five distinct pre-prompting patterns. Our findings suggest that such prompts can foster structured discussions, clarify task requirements, and create opportunities for shared learning experiences.",
      "authors": [
        "Johan Petersson"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20299",
        "HTML": "https://arxiv.org/html/2506.20299",
        "PDF": "https://arxiv.org/pdf/2506.20299"
      },
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:22:43 GMT",
          "size": "980kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Enhancing Programming Pair Workshops: The Case of Teacher Pre-Prompting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research focuses on educational techniques like teacher pre-prompting in programming workshops, which is unrelated to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20302",
      "abstract": "Images captured in challenging environments often experience various forms of degradation, including noise, color cast, blur, and light scattering. These effects significantly reduce image quality, hindering their applicability in downstream tasks such as object detection, mapping, and classification. Our transformer-based diffusion model was developed to address image restoration tasks, aiming to improve the quality of degraded images. This model was evaluated against existing deep learning methodologies across multiple quality metrics for underwater image enhancement, denoising, and deraining on publicly available datasets. Our findings demonstrate that the diffusion model, combined with transformers, surpasses current methods in performance. The results of our model highlight the efficacy of diffusion models and transformers in improving the quality of degraded images, consequently expanding their utility in downstream tasks that require high-fidelity visual data.",
      "authors": [
        "Abbas Anwar",
        "Mohammad Shullar",
        "Ali Arshad Nasir",
        "Mudassir Masood",
        "Saeed Anwar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20302",
        "HTML": "https://arxiv.org/html/2506.20302",
        "PDF": "https://arxiv.org/pdf/2506.20302"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:28:13 GMT",
          "size": "5312kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TDiR: Transformer based Diffusion for Image Restoration Tasks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses image restoration tasks using transformer-based diffusion models for improved visual quality but does not relate to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20305",
      "abstract": "The hardness of learning a function that attains a target task relates to its input-sensitivity. For example, image classification tasks are input-insensitive as minor corruptions should not affect the classification results, whereas arithmetic and symbolic computation, which have been recently attracting interest, are highly input-sensitive as each input variable connects to the computation results. This study presents the first learning-based Quick Response (QR) code decoding and investigates learning functions of medium sensitivity. Our experiments reveal that Transformers can successfully decode QR codes, even beyond the theoretical error-correction limit, by learning the structure of embedded texts. They generalize from English-rich training data to other languages and even random strings. Moreover, we observe that the Transformer-based QR decoder focuses on data bits while ignoring error-correction bits, suggesting a decoding mechanism distinct from standard QR code readers.",
      "authors": [
        "Kazuki Yoda",
        "Kazuhiko Kawamoto",
        "Hiroshi Kera"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20305",
        "HTML": "https://arxiv.org/html/2506.20305",
        "PDF": "https://arxiv.org/pdf/2506.20305"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:37:39 GMT",
          "size": "2464kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study investigates learning functions for QR code decoding using Transformers, but it does not discuss any processes or methodologies related to the processing or engineering of training data for LLMs."
      }
    },
    {
      "id": "2506.20306",
      "abstract": "Accurate interpretation of knee MRI scans relies on expert clinical judgment, often with high variability and limited scalability. Existing radiomic approaches use a fixed set of radiomic features (the signature), selected at the population level and applied uniformly to all patients. While interpretable, these signatures are often too constrained to represent individual pathological variations. As a result, conventional radiomic-based approaches are found to be limited in performance, compared with recent end-to-end deep learning (DL) alternatives without using interpretable radiomic features. We argue that the individual-agnostic nature in current radiomic selection is not central to its intepretability, but is responsible for the poor generalization in our application. Here, we propose a novel radiomic fingerprint framework, in which a radiomic feature set (the fingerprint) is dynamically constructed for each patient, selected by a DL model. Unlike the existing radiomic signatures, our fingerprints are derived on a per-patient basis by predicting the feature relevance in a large radiomic feature pool, and selecting only those that are predictive of clinical conditions for individual patients. The radiomic-selecting model is trained simultaneously with a low-dimensional (considered relatively explainable) logistic regression for downstream classification. We validate our methods across multiple diagnostic tasks including general knee abnormalities, anterior cruciate ligament (ACL) tears, and meniscus tears, demonstrating comparable or superior diagnostic accuracy relative to state-of-the-art end-to-end DL models. More importantly, we show that the interpretability inherent in our approach facilitates meaningful clinical insights and potential biomarker discovery, with detailed discussion, quantitative and qualitative analysis of real-world clinical cases to evidence these advantages.",
      "authors": [
        "Yaxi Chen",
        "Simin Ni",
        "Shaheer U. Saeed",
        "Aleksandra Ivanova",
        "Rikin Hargunani",
        "Jie Huang",
        "Chaozong Liu",
        "Yipeng Hu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20306",
        "HTML": "https://arxiv.org/html/2506.20306",
        "PDF": "https://arxiv.org/pdf/2506.20306"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:39:22 GMT",
          "size": "898kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Radiomic fingerprints for knee MR images assessment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a framework for patient-specific radiomic fingerprints derived from MRI scans, focusing on medical diagnostics rather than any aspect of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20307",
      "abstract": "Imitation learning is a central problem in reinforcement learning where the goal is to learn a policy that mimics the expert's behavior. In practice, it is often challenging to learn the expert policy from a limited number of demonstrations accurately due to the complexity of the state space. Moreover, it is essential to explore the environment and collect data to achieve beyond-expert performance. To overcome these challenges, we propose a novel imitation learning algorithm called Imitation Learning with Double Exploration (ILDE), which implements exploration in two aspects: (1) optimistic policy optimization via an exploration bonus that rewards state-action pairs with high uncertainty to potentially improve the convergence to the expert policy, and (2) curiosity-driven exploration of the states that deviate from the demonstration trajectories to potentially yield beyond-expert performance. Empirically, we demonstrate that ILDE outperforms the state-of-the-art imitation learning algorithms in terms of sample efficiency and achieves beyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations than in previous work. We also provide a theoretical justification of ILDE as an uncertainty-regularized policy optimization method with optimistic exploration, leading to a regret growing sublinearly in the number of episodes.",
      "authors": [
        "Heyang Zhao",
        "Xingrui Yu",
        "David M. Bossens",
        "Ivor W. Tsang",
        "Quanquan Gu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20307",
        "HTML": "https://arxiv.org/html/2506.20307",
        "PDF": "https://arxiv.org/pdf/2506.20307"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:39:32 GMT",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work introduces a novel imitation learning algorithm for reinforcement learning tasks, which does not involve the data engineering or processing related to LLM training data."
      }
    },
    {
      "id": "2506.20308",
      "abstract": "Solving high-dimensional parabolic partial differential equations (PDEs) with deep learning methods is often computationally and memory intensive, primarily due to the need for automatic differentiation (AD) to compute large Hessian matrices in the PDE. In this work, we propose a deep random difference method (DRDM) that addresses these issues by approximating the convection-diffusion operator using only first-order differences and the solution by deep neural networks, thus, avoiding explicit Hessian computation. When incorporated into a Galerkin framework, the DRDM eliminates the need for pointwise evaluation of expectations, resulting in efficient implementation. We further extend the approach to Hamilton-Jacobi-Bellman (HJB) equations. Notably, the DRDM recovers existing martingale deep learning methods for PDEs (Cai et al., 2024, arXiv:2405.03169), without using the tools of stochastic calculus. The proposed method offers two main advantages: it removes the dependence on AD for PDE derivatives and enables parallel computation of the loss function in both time and space. We provide rigorous error estimates for the DRDM in the linear case, which shows a first order accuracy in $\\Delta t$ used in the sampling of the paths by the Euler-Maruyama scheme. Numerical experiments demonstrate that the method can efficiently and accurately solve quasilinear parabolic PDEs and HJB equations in dimensions up to $10^4$ and $10^5$, respectively.",
      "authors": [
        "Wei Cai",
        "Shuixin Fang",
        "Tao Zhou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20308",
        "HTML": "https://arxiv.org/html/2506.20308",
        "PDF": "https://arxiv.org/pdf/2506.20308"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:40:54 GMT",
          "size": "7050kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Deep random difference method for high dimensional quasilinear parabolic partial differential equations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research proposes a method for solving PDEs using neural networks, with no focus on the data collection, processing, or engineering stages related to LLM training datasets."
      }
    },
    {
      "id": "2506.20310",
      "abstract": "Albeit being a central notion of every programming language, formally and modularly reasoning about iteration proves itself to be a non-trivial feat, specially in the context of higher-order iteration. In this paper, we present a generic approach to the specification and deductive verification of higher-order iterators, written in the OCaml language. Our methodology follows two key principles: first, the usage of the Gospel specification language to describe the general behaviour of any iteration schema; second, the usage of the Cameleer framework to deductively verify that every iteration client is correct with respect to its logical specification. To validate our approach we develop a set of verified case studies, ranging from classic list iterators to graph algorithms implemented in the widely used OCamlGraph library.",
      "authors": [
        "Ion Chirica and M\\'ario Pereira"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20310",
        "HTML": "https://arxiv.org/html/2506.20310",
        "PDF": "https://arxiv.org/pdf/2506.20310"
      },
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:48:38 GMT",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Unfolding Iterators: Specification and Verification of Higher-Order Iterators, in OCaml",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the specification and verification of higher-order iterators in the OCaml programming language, without addressing aspects related to LLM training data processing."
      }
    },
    {
      "id": "2506.20311",
      "abstract": "The growing use of mobile robots in sectors such as automotive, agriculture, and rescue operations reflects progress in robotics and autonomy. In unmanned aerial vehicles (UAVs), most research emphasizes visual SLAM, sensor fusion, and path planning. However, applying UAVs to search and rescue missions in disaster zones remains underexplored, especially for autonomous navigation.\n  This report develops methods for real-time and secure UAV maneuvering in complex 3D environments, crucial during forest fires. Building upon past research, it focuses on designing navigation algorithms for unfamiliar and hazardous environments, aiming to improve rescue efficiency and safety through UAV-based early warning and rapid response.\n  The work unfolds in phases. First, a 2D fusion navigation strategy is explored, initially for mobile robots, enabling safe movement in dynamic settings. This sets the stage for advanced features such as adaptive obstacle handling and decision-making enhancements. Next, a novel 3D reactive navigation strategy is introduced for collision-free movement in forest fire simulations, addressing the unique challenges of UAV operations in such scenarios.\n  Finally, the report proposes a unified control approach that integrates UAVs and unmanned ground vehicles (UGVs) for coordinated rescue missions in forest environments. Each phase presents challenges, proposes control models, and validates them with mathematical and simulation-based evidence. The study offers practical value and academic insights for improving the role of UAVs in natural disaster rescue operations.",
      "authors": [
        "Jingwen Wei"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20311",
        "HTML": "https://arxiv.org/html/2506.20311",
        "PDF": "https://arxiv.org/pdf/2506.20311"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:49:17 GMT",
          "size": "10926kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses real-time obstacle avoidance algorithms for UAVs and UGVs and does not deal with LLM training data processing or any data-related issues relevant to LLMs."
      }
    },
    {
      "id": "2506.20314",
      "abstract": "Efficient, collision-free motion planning is essential for automating large-scale manipulators like timber cranes. They come with unique challenges such as hydraulic actuation constraints and passive joints-factors that are seldom addressed by current motion planning methods. This paper introduces a novel approach for time-optimal, collision-free hybrid motion planning for a hydraulically actuated timber crane with passive joints. We enhance the via-point-based stochastic trajectory optimization (VP-STO) algorithm to include pump flow rate constraints and develop a novel collision cost formulation to improve robustness. The effectiveness of the enhanced VP-STO as an optimal single-query global planner is validated by comparison with an informed RRT* algorithm using a time-optimal path parameterization (TOPP). The overall hybrid motion planning is formed by combination with a gradient-based local planner that is designed to follow the global planner's reference and to systematically consider the passive joint dynamics for both collision avoidance and sway damping.",
      "authors": [
        "Marc-Philip Ecker",
        "Bernhard Bischof",
        "Minh Nhat Vu",
        "Christoph Fr\\\"ohlich",
        "Tobias Gl\\\"uck",
        "Wolfgang Kemmetm\\\"uller"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20314",
        "HTML": "https://arxiv.org/html/2506.20314",
        "PDF": "https://arxiv.org/pdf/2506.20314"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:51:57 GMT",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Near Time-Optimal Hybrid Motion Planning for Timber Cranes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research introduces motion planning strategies for timber cranes with no mention of LLM training data processing or related methodologies."
      }
    },
    {
      "id": "2506.20315",
      "abstract": "Legged robots are increasingly being adopted in industries such as oil, gas, mining, nuclear, and agriculture. However, new challenges exist when moving into natural, less-structured environments, such as forestry applications. This paper presents a prototype system for autonomous, under-canopy forest inventory with legged platforms. Motivated by the robustness and mobility of modern legged robots, we introduce a system architecture which enabled a quadruped platform to autonomously navigate and map forest plots. Our solution involves a complete navigation stack for state estimation, mission planning, and tree detection and trait estimation. We report the performance of the system from trials executed over one and a half years in forests in three European countries. Our results with the ANYmal robot demonstrate that we can survey plots up to 1 ha plot under 30 min, while also identifying trees with typical DBH accuracy of 2cm. The findings of this project are presented as five lessons and challenges. Particularly, we discuss the maturity of hardware development, state estimation limitations, open problems in forest navigation, future avenues for robotic forest inventory, and more general challenges to assess autonomous systems. By sharing these lessons and challenges, we offer insight and new directions for future research on legged robots, navigation systems, and applications in natural environments. Additional videos can be found in https://dynamic.robots.ox.ac.uk/projects/legged-robots",
      "authors": [
        "Mat\\'ias Mattamala",
        "Nived Chebrolu",
        "Jonas Frey",
        "Leonard Frei{\\ss}muth",
        "Haedam Oh",
        "Benoit Casseau",
        "Marco Hutter",
        "Maurice Fallon"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20315",
        "HTML": "https://arxiv.org/html/2506.20315",
        "PDF": "https://arxiv.org/pdf/2506.20315"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:53:26 GMT",
          "size": "27588kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Building Forest Inventories with Autonomous Legged Robots -- System, Lessons, and Challenges Ahead",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a system for forestry inventory using legged robots, which involves navigation and mapping challenges but is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20317",
      "abstract": "We study the problem of (approximate) maximin share (MMS) allocation of indivisible items among a set of agents. We focus on the graphical valuation model, previously studied by Christodolou, Fiat, Koutsoupias, and Sgouritsa (\"Fair allocation in graphs\", EC 2023), where the input is given by a graph where edges correspond to items, and vertices correspond to agents. An edge may have non-zero marginal value only for its incident vertices. We study additive, XOS and subadditive valuations and we present positive and negative results for (approximate) MMS fairness, and also for (approximate) pair-wise maximin share (PMMS) fairness.",
      "authors": [
        "George Christodoulou",
        "Symeon Mastrakoulis"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20317",
        "HTML": "https://arxiv.org/html/2506.20317",
        "PDF": "https://arxiv.org/pdf/2506.20317"
      },
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:55:28 GMT",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Exact and approximate maximin share allocations in multi-graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on fair allocation in graphical models, which is unrelated to training data processing for LLMs or any aspect of LLM training data."
      }
    },
    {
      "id": "2506.20320",
      "abstract": "In Social Robot Navigation, autonomous agents need to resolve many sequential interactions with other agents. State-of-the art planners can efficiently resolve the next, imminent interaction cooperatively and do not focus on longer planning horizons. This makes it hard to maneuver scenarios where the agent needs to select a good strategy to find gaps or channels in the crowd. We propose to decompose trajectory planning into two separate steps: Conflict avoidance for finding good, macroscopic trajectories, and cooperative collision avoidance (CCA) for resolving the next interaction optimally. We propose the Probabilistic Gap Planner (PGP) as a conflict avoidance planner. PGP modifies an established probabilistic collision risk model to include a general assumption of cooperativity. PGP biases the short-term CCA planner to head towards gaps in the crowd. In extensive simulations with crowds of varying density, we show that using PGP in addition to state-of-the-art CCA planners improves the agents' performance: On average, agents keep more space to others, create less tension, and cause fewer collisions. This typically comes at the expense of slightly longer paths. PGP runs in real-time on WaPOCHI mobile robot by Honda R&D.",
      "authors": [
        "Malte Probst",
        "Raphael Wenzel",
        "Tim Puphal",
        "Monica Dasi",
        "Nico A. Steinhardt",
        "Sango Matsuzaki and Misa Komuro"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20320",
        "HTML": "https://arxiv.org/html/2506.20320",
        "PDF": "https://arxiv.org/pdf/2506.20320"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:01:51 GMT",
          "size": "4709kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses robot navigation using a probabilistic planner, which does not relate to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20323",
      "abstract": "This research presents the development of an Artificial Intelligence (AI) - driven crop disease detection system designed to assist farmers in rural areas with limited resources. We aim to compare different deep learning models for a comparative analysis, focusing on their efficacy in transfer learning. By leveraging deep learning models, including EfficientNet, ResNet101, MobileNetV2, and our custom CNN, which achieved a validation accuracy of 95.76%, the system effectively classifies plant diseases. This research demonstrates the potential of transfer learning in reshaping agricultural practices, improving crop health management, and supporting sustainable farming in rural environments.",
      "authors": [
        "Saundarya Subramaniam",
        "Shalini Majumdar",
        "Shantanu Nadar",
        "Kaustubh Kulkarni"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20323",
        "HTML": "https://arxiv.org/html/2506.20323",
        "PDF": "https://arxiv.org/pdf/2506.20323"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:04:33 GMT",
          "size": "723kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses crop disease detection using deep learning models, with no mention of LLM training data processing or data-centric techniques affecting LLMs."
      }
    },
    {
      "id": "2506.20324",
      "abstract": "Dynamic graphs exhibit complex temporal dynamics due to the interplay between evolving node features and changing network structures. Recently, Graph Neural Controlled Differential Equations (Graph Neural CDEs) successfully adapted Neural CDEs from paths on Euclidean domains to paths on graph domains. Building on this foundation, we introduce Permutation Equivariant Neural Graph CDEs, which project Graph Neural CDEs onto permutation equivariant function spaces. This significantly reduces the model's parameter count without compromising representational power, resulting in more efficient training and improved generalisation. We empirically demonstrate the advantages of our approach through experiments on simulated dynamical systems and real-world tasks, showing improved performance in both interpolation and extrapolation scenarios.",
      "authors": [
        "Torben Berndt",
        "Benjamin Walker",
        "Tiexin Qin",
        "Jan St\\\"uhmer",
        "Andrey Kormilitzin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20324",
        "HTML": "https://arxiv.org/html/2506.20324",
        "PDF": "https://arxiv.org/pdf/2506.20324"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:06:30 GMT",
          "size": "234kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work focuses on neural differential equations in dynamic graph learning, without addressing LLM training data processing or related data handling methods."
      }
    },
    {
      "id": "2506.20326",
      "abstract": "Robust Document Layout Analysis (DLA) is critical for the automated processing and understanding of historical documents with complex page organizations. This paper benchmarks five state-of-the-art object detection architectures on three annotated datasets representing a spectrum of codicological complexity: The e-NDP, a corpus of Parisian medieval registers (1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval and modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated books of hours (ca.13th-16th centuries). We evaluate two Transformer-based models (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and YOLO-World). Our findings reveal significant performance variations dependent on model architecture, data set characteristics, and bounding box representation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results (0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on the more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB significantly outperforms all other models (0.564 and 0.568, respectively). This study unequivocally demonstrates that using Oriented Bounding Boxes (OBB) is not a minor refinement but a fundamental requirement for accurately modeling the non-Cartesian nature of historical manuscripts. We conclude that a key trade-off exists between the global context awareness of Transformers, ideal for structured layouts, and the superior generalization of CNN-OBB models for visually diverse and complex documents.",
      "authors": [
        "Sergio Torres Aguilar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20326",
        "HTML": "https://arxiv.org/html/2506.20326",
        "PDF": "https://arxiv.org/pdf/2506.20326"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:14:04 GMT",
          "size": "9798kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper compares object detection models for document layout analysis, unrelated to the processes involved in LLM training data handling."
      }
    },
    {
      "id": "2506.20329",
      "abstract": "We address fairness in the context of sequential bundle recommendation, where users are served in turn with sets of relevant and compatible items. Motivated by real-world scenarios, we formalize producer-fairness, that seeks to achieve desired exposure of different item groups across users in a recommendation session. Our formulation combines naturally with building high quality bundles. Our problem is solved in real time as users arrive. We propose an exact solution that caters to small instances of our problem. We then examine two heuristics, quality-first and fairness-first, and an adaptive variant that determines on-the-fly the right balance between bundle fairness and quality. Our experiments on three real-world datasets underscore the strengths and limitations of each solution and demonstrate their efficacy in providing fair bundle recommendations without compromising bundle quality.",
      "authors": [
        "Alexandre Rio",
        "Marta Soare",
        "Sihem Amer-Yahia"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20329",
        "HTML": "https://arxiv.org/html/2506.20329",
        "PDF": "https://arxiv.org/pdf/2506.20329"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:24:52 GMT",
          "size": "4993kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Producer-Fairness in Sequential Bundle Recommendation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on fairness in bundle recommendations and does not address the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20330",
      "abstract": "Semantic retrieval, which retrieves semantically matched items given a textual query, has been an essential component to enhance system effectiveness in e-commerce search. In this paper, we study the multimodal retrieval problem, where the visual information (e.g, image) of item is leveraged as supplementary of textual information to enrich item representation and further improve retrieval performance. Though learning from cross-modality data has been studied extensively in tasks such as visual question answering or media summarization, multimodal retrieval remains a non-trivial and unsolved problem especially in the asymmetric scenario where the query is unimodal while the item is multimodal. In this paper, we propose a novel model named SMAR, which stands for Semantic-enhanced Modality-Asymmetric Retrieval, to tackle the problem of modality fusion and alignment in this kind of asymmetric scenario. Extensive experimental results on an industrial dataset show that the proposed model outperforms baseline models significantly in retrieval accuracy. We have open sourced our industrial dataset for the sake of reproducibility and future research works.",
      "authors": [
        "Zhigong Zhou",
        "Ning Ding",
        "Xiaochuan Fan",
        "Yue Shang",
        "Yiming Qiu",
        "Jingwei Zhuo",
        "Zhiwei Ge",
        "Songlin Wang",
        "Lin Liu",
        "Sulong Xu and Han Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20330",
        "HTML": "https://arxiv.org/html/2506.20330",
        "PDF": "https://arxiv.org/pdf/2506.20330"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:28:04 GMT",
          "size": "1326kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce Search",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses semantic-enhanced modality-asymmetric retrieval in e-commerce and does not deal with LLM training data processing."
      }
    },
    {
      "id": "2506.20334",
      "abstract": "This paper investigates the design of output-feedback schemes for systems described by a class of recurrent neural networks. We propose a procedure based on linear matrix inequalities for designing an observer and a static state-feedback controller. The algorithm leverages global and regional incremental input-to-state stability (incremental ISS) and enables the tracking of constant setpoints, ensuring robustness to disturbances and state estimation uncertainty. To address the potential limitations of regional incremental ISS, we introduce an alternative scheme in which the static law is replaced with a tube-based nonlinear model predictive controller (NMPC) that exploits regional incremental ISS properties. We show that these conditions enable the formulation of a robust NMPC law with guarantees of convergence and recursive feasibility, leading to an enlarged region of attraction. Theoretical results are validated through numerical simulations on the pH-neutralisation process benchmark, demonstrating the effectiveness of the proposed schemes.",
      "authors": [
        "Daniele Ravasio",
        "Marcello Farina",
        "Alessio La Bella",
        "Andrea Ballarino"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20334",
        "HTML": "https://arxiv.org/html/2506.20334",
        "PDF": "https://arxiv.org/pdf/2506.20334"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:44:28 GMT",
          "size": "285kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Recurrent neural network-based robust control systems with closed-loop regional incremental ISS and application to MPC design",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the design of robust control systems using recurrent neural networks for dynamic systems and does not address any aspects related to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20342",
      "abstract": "Understanding human actions in videos requires more than raw pixel analysis; it relies on high-level semantic reasoning and effective integration of multimodal features. We propose a deep translational action recognition framework that enhances recognition accuracy by jointly predicting action concepts and auxiliary features from RGB video frames. At test time, hallucination streams infer missing cues, enriching feature representations without increasing computational overhead. To focus on action-relevant regions beyond raw pixels, we introduce two novel domain-specific descriptors. Object Detection Features (ODF) aggregate outputs from multiple object detectors to capture contextual cues, while Saliency Detection Features (SDF) highlight spatial and intensity patterns crucial for action recognition. Our framework seamlessly integrates these descriptors with auxiliary modalities such as optical flow, Improved Dense Trajectories, skeleton data, and audio cues. It remains compatible with state-of-the-art architectures, including I3D, AssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE V2 and InternVideo2. To handle uncertainty in auxiliary features, we incorporate aleatoric uncertainty modeling in the hallucination step and introduce a robust loss function to mitigate feature noise. Our multimodal self-supervised action recognition framework achieves state-of-the-art performance on multiple benchmarks, including Kinetics-400, Kinetics-600, and Something-Something V2, demonstrating its effectiveness in capturing fine-grained action dynamics.",
      "authors": [
        "Lei Wang and Piotr Koniusz"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20342",
        "HTML": "https://arxiv.org/html/2506.20342",
        "PDF": "https://arxiv.org/pdf/2506.20342"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:50:23 GMT",
          "size": "1397kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Feature Hallucination for Self-supervised Action Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a self-supervised framework for action recognition in videos using auxiliary features and hallucination streams, which is unrelated to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20343",
      "abstract": "Musculoskeletal humanoids are robots that closely mimic the human musculoskeletal system, offering various advantages such as variable stiffness control, redundancy, and flexibility. However, their body structure is complex, and muscle paths often significantly deviate from geometric models. To address this, numerous studies have been conducted to learn body schema, particularly the relationships among joint angles, muscle tension, and muscle length. These studies typically rely solely on data collected from the actual robot, but this data collection process is labor-intensive, and learning becomes difficult when the amount of data is limited. Therefore, in this study, we propose a method that applies the concept of Physics-Informed Neural Networks (PINNs) to the learning of body schema in musculoskeletal humanoids, enabling high-accuracy learning even with a small amount of data. By utilizing not only data obtained from the actual robot but also the physical laws governing the relationship between torque and muscle tension under the assumption of correct joint structure, more efficient learning becomes possible. We apply the proposed method to both simulation and an actual musculoskeletal humanoid and discuss its effectiveness and characteristics.",
      "authors": [
        "Kento Kawaharazuka and Takahiro Hattori and Keita Yoneda and Kei Okada"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20343",
        "HTML": "https://arxiv.org/html/2506.20343",
        "PDF": "https://arxiv.org/pdf/2506.20343"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:51:01 GMT",
          "size": "6348kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study introduces a physics-informed method for efficient learning of musculoskeletal humanoids, and does not address the processing or engineering of training data for LLMs."
      }
    },
    {
      "id": "2506.20347",
      "abstract": "Granger Causality (GC) offers an elegant statistical framework to study the association between multivariate time series data. Linear Vector Autoregressive models (VAR) though have nice interpretation properties but have limited practical application due to underlying assumptions on the kind of associations that can be captured by these models. Numerous attempts have already been made in the literature that exploit the functional approximation power of Deep Neural Networks (DNNs) for the task of GC estimation. These methods however treat GC as a variable selection problem. We present a novel paradigm for approaching GC. We present this idea that GC is essentially linked with prediction and if a deep learning model is used to model the time series collectively or jointly, a well regularized model may learn the true granger causal structure from the data, given that there is enough training data. We propose to uncover the learned GC structure by comparing the model uncertainty or distribution of the residuals when the past of everything is used as compared to the one where a specific time series component is dropped from the model. We also compare the effect of input layer dropout on the ability of a neural network to learn granger causality from the data. We show that a well regularized model infact can learn the true GC structure from the data without explicitly adding terms in the loss function that guide the model to select variables or perform sparse regression.",
      "authors": [
        "Malik Shahid Sultan and Hernando Ombao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20347",
        "HTML": "https://arxiv.org/html/2506.20347",
        "PDF": "https://arxiv.org/pdf/2506.20347"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:57:24 GMT",
          "size": "469kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the ability of Deep Neural Networks to Learn Granger Causality in Multi-Variate Time Series Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research explores the learning of Granger causality in time series data through deep neural networks, which does not relate to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20350",
      "abstract": "Simulating and developing large rectangularly shaped arrays with equidistant interspacing is challenging as the computational complexity grows quickly with array size. However, the geometrical shape of the array, appropriately meshed, leads to a multilevel Toeplitz structure in the RWG-based Method of Moment impedance matrix representation that can be used to mitigate the increased complexity. This paper develops, presents and compares two different accelerated solvers that both utilize the matrix structure to determine antenna properties. Both methods use a novel mesh-partitioning algorithm and its associated data representation, reducing storage and computational costs. The first solver is an iterative method based on multilevel fast Fourier transform to accelerate matrix multiplications. The second solver approach is based on an extension of a fast direct Toeplitz solver, adapted to a block-matrix structure. This fast direct solver is demonstrated to have close to machine epsilon accuracy. Both accelerated methods are evaluated on two different array element types, for arrays with up to 900 elements. The results are compared with conventional direct and iterative matrix solvers. Improvements are seen in both the time and required storage to solve the problem. The choice of the most efficient method depends on the residual thresholds in the iterative method, geometry of the element and frequency. Two different preconditioners for the iterative method are investigated to evaluate their performance. The two accelerated methods vastly outperform regular matrix inversion methods.",
      "authors": [
        "Harald Hultin",
        "Lucas {\\AA}kerstedt",
        "and B.L.G. Jonsson"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20350",
        "HTML": "https://arxiv.org/html/2506.20350",
        "PDF": "https://arxiv.org/pdf/2506.20350"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:02:55 GMT",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Solver Performance of Accelerated MoM for Connected Arrays",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on developing accelerated solvers for simulating large arrays and does not relate to LLM training data processing. It is centered around computational methods for matrix multiplication in antenna design rather than data preparation for language models."
      }
    },
    {
      "id": "2506.20353",
      "abstract": "The ever-increasing computational demands and deployment costs of large language models (LLMs) have spurred numerous compressing methods. Compared to quantization and unstructured pruning, SVD compression offers superior hardware compatibility and theoretical guarantees. However, existing SVD-based methods focus on the overall discrepancy between the original and compressed matrices while overlooking the protection of critical components within the matrix, which leads to inferior performance in the compressed models. This paper proposes a dual-level importance protection mechanism to enhance SVD-based compression methods: (1) local importance protection: preserving the most critical singular vectors within each weight matrix through channel-weighted data whitening; and (2) global importance protection: enabling less important layers to bear a greater portion of the compression burden through either a heuristic or optimization-based approach, thereby minimizing the impact of compression on critical layers. Extensive experiments demonstrate that DipSVD outperforms existing SVD-based compression approaches across multiple benchmarks, achieving superior model performance especially at high model compression ratios.",
      "authors": [
        "Xuan Ding",
        "Rui Sun",
        "Yunjian Zhang",
        "Xiu Yan",
        "Yueqi Zhou",
        "Kaihao Huang",
        "Suzhong Fu",
        "Chuanlong Xie",
        "Yao Zhu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20353",
        "HTML": "https://arxiv.org/html/2506.20353",
        "PDF": "https://arxiv.org/pdf/2506.20353"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:04:53 GMT",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DipSVD: Dual-importance Protected SVD for Efficient LLM Compression",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses SVD-based compression methods to reduce the computational demands of LLMs, not the training data processing itself. It focuses on model compression techniques rather than the manipulation or preparation of training data."
      }
    },
    {
      "id": "2506.20354",
      "abstract": "Learning from multi-variate time-series with heterogeneous channel configurations remains a fundamental challenge for deep neural networks (DNNs), particularly in clinical domains such as intracranial electroencephalography (iEEG), where channel setups vary widely across subjects. In this work, we introduce multi-variate parallel attention (MVPA), a novel self-attention mechanism that disentangles content, temporal, and spatial attention, enabling flexible, generalizable, and efficient modeling of time-series data with varying channel counts and configurations. We use MVPA to build MVPFormer, a generative foundation model for human electrophysiology, trained to predict the evolution of iEEG signals across diverse subjects. To support this and future effort by the community, we release the SWEC iEEG dataset, the largest publicly available iEEG dataset to date, comprising nearly 10,000 hours of recordings from heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong generalization across subjects, demonstrating expert-level performance in seizure detection and outperforming state-of-the-art Transformer baselines on our SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard time-series forecasting and classification tasks, where it matches or exceeds existing attention-based models. Together, our contributions establish MVPA as a general-purpose attention mechanism for heterogeneous time-series and MVPFormer as the first open-source, open-weights, and open-data iEEG foundation model with state-of-the-art clinical performance. The code is available at https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG dataset is available at https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.",
      "authors": [
        "Francesco Carzaniga",
        "Michael Hersche",
        "Abu Sebastian",
        "Kaspar Schindler",
        "Abbas Rahimi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20354",
        "HTML": "https://arxiv.org/html/2506.20354",
        "PDF": "https://arxiv.org/pdf/2506.20354"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:07:10 GMT",
          "size": "2340kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A foundation model with multi-variate parallel attention to generate neuronal activity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study introduces a new attention mechanism for time-series data applied to clinical electrophysiology tasks and the release of an iEEG dataset. It does not pertain to the processing of LLM training data, focusing instead on clinical data and time-series modeling."
      }
    },
    {
      "id": "2506.20356",
      "abstract": "We consider the problem of statically ensuring that message-passing programs never run into deadlocks. We focus on concurrent functional programs governed by context-free session types, which can express rich tree-like structures not expressible in standard session types. Existing techniques based on context-free session types enforce protocol conformance but not deadlock freedom. We propose a type system that enhances context-free session types with a priority-based approach to deadlock freedom, considering polymorphic and recursive types. Interestingly, the notions needed for avoiding deadlocks fit nicely into this expressive setting. We prove that well-typed programs respect their protocols and never run into deadlocks at run-time; we also demonstrate the expressiveness gains with respect to prior work by means of examples.",
      "authors": [
        "Andreia Mordido and Jorge A. P\\'erez"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20356",
        "HTML": "https://arxiv.org/html/2506.20356",
        "PDF": "https://arxiv.org/pdf/2506.20356"
      },
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:11:47 GMT",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Deadlock-free Context-free Session Types",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses the problem of ensuring deadlock freedom in concurrent programs using context-free session types. This topic is unrelated to the data processing for training LLMs, focusing on type systems for concurrency control."
      }
    },
    {
      "id": "2506.20357",
      "abstract": "Feature engineering for tabular data remains a critical yet challenging step in machine learning. Recently, large language models (LLMs) have been used to automatically generate new features by leveraging their vast knowledge. However, existing LLM-based approaches often produce overly simple or repetitive features, partly due to inherent biases in the transformations the LLM chooses and the lack of structured reasoning guidance during generation. In this paper, we propose a novel method REFeat, which guides an LLM to discover diverse and informative features by leveraging multiple types of reasoning to steer the feature generation process. Experiments on 59 benchmark datasets demonstrate that our approach not only achieves higher predictive accuracy on average, but also discovers more diverse and meaningful features. These results highlight the promise of incorporating rich reasoning paradigms and adaptive strategy selection into LLM-driven feature discovery for tabular data.",
      "authors": [
        "Sungwon Han",
        "Sungkyu Park",
        "Seungeon Lee"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20357",
        "HTML": "https://arxiv.org/html/2506.20357",
        "PDF": "https://arxiv.org/pdf/2506.20357"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:18:34 GMT",
          "size": "423kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Tabular Feature Discovery With Reasoning Type Exploration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on feature engineering for tabular data using LLMs but does not address LLM training data processing or engineering tasks related to large language models."
      }
    },
    {
      "id": "2506.20359",
      "abstract": "Trajectory analysis is not only about obtaining movement data, but it is also of paramount importance in understanding the pattern in which an object moves through space and time, as well as in predicting its next move. Due to the significant interest in the area, data collection has improved substantially, resulting in a large number of features becoming available for training and predicting models. However, this introduces a high-dimensionality-induced feature explosion problem, which reduces the efficiency and interpretability of the data, thereby reducing the accuracy of machine learning models. To overcome this issue, feature selection has become one of the most prevalent tools. Thus, the objective of this paper was to introduce a taxonomy-based feature selection method that categorizes features based on their internal structure. This approach classifies the data into geometric and kinematic features, further categorizing them into curvature, indentation, speed, and acceleration. The comparative analysis indicated that a taxonomy-based approach consistently achieved comparable or superior predictive performance. Furthermore, due to the taxonomic grouping, which reduces combinatorial space, the time taken to select features was drastically reduced. The taxonomy was also used to gain insights into what feature sets each dataset was more sensitive to. Overall, this study provides robust evidence that a taxonomy-based feature selection method can add a layer of interpretability, reduce dimensionality and computational complexity, and contribute to high-level decision-making. It serves as a step toward providing a methodological framework for researchers and practitioners dealing with trajectory datasets and contributing to the broader field of explainable artificial intelligence.",
      "authors": [
        "Chanuka Don Samarasinghage and Dhruv Gulabani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20359",
        "HTML": "https://arxiv.org/html/2506.20359",
        "PDF": "https://arxiv.org/pdf/2506.20359"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:21:20 GMT",
          "size": "1870kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses feature selection in trajectory datasets and does not pertain to data processing aspects for LLM training data."
      }
    },
    {
      "id": "2506.20362",
      "abstract": "We present LaplaceGNN, a novel self-supervised graph learning framework that bypasses the need for negative sampling by leveraging spectral bootstrapping techniques. Our method integrates Laplacian-based signals into the learning process, allowing the model to effectively capture rich structural representations without relying on contrastive objectives or handcrafted augmentations. By focusing on positive alignment, LaplaceGNN achieves linear scaling while offering a simpler, more efficient, self-supervised alternative for graph neural networks, applicable across diverse domains. Our contributions are twofold: we precompute spectral augmentations through max-min centrality-guided optimization, enabling rich structural supervision without relying on handcrafted augmentations, then we integrate an adversarial bootstrapped training scheme that further strengthens feature learning and robustness. Our extensive experiments on different benchmark datasets show that LaplaceGNN achieves superior performance compared to state-of-the-art self-supervised graph methods, offering a promising direction for efficiently learning expressive graph representations.",
      "authors": [
        "Lorenzo Bini",
        "Stephane Marchand-Maillet"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20362",
        "HTML": "https://arxiv.org/html/2506.20362",
        "PDF": "https://arxiv.org/pdf/2506.20362"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:23:23 GMT",
          "size": "156kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a graph learning framework and does not involve any aspect of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20367",
      "abstract": "Recent advances in text-to-3D scene generation have demonstrated significant potential to transform content creation across multiple industries. Although the research community has made impressive progress in addressing the challenges of this complex task, existing methods often generate environments that are only front-facing, lack visual fidelity, exhibit limited scene understanding, and are typically fine-tuned for either indoor or outdoor settings. In this work, we address these issues and propose DreamAnywhere, a modular system for the fast generation and prototyping of 3D scenes. Our system synthesizes a 360{\\deg} panoramic image from text, decomposes it into background and objects, constructs a complete 3D representation through hybrid inpainting, and lifts object masks to detailed 3D objects that are placed in the virtual environment. DreamAnywhere supports immersive navigation and intuitive object-level editing, making it ideal for scene exploration, visual mock-ups, and rapid prototyping -- all with minimal manual modeling. These features make our system particularly suitable for low-budget movie production, enabling quick iteration on scene layout and visual tone without the overhead of traditional 3D workflows. Our modular pipeline is highly customizable as it allows components to be replaced independently. Compared to current state-of-the-art text and image-based 3D scene generation approaches, DreamAnywhere shows significant improvements in coherence in novel view synthesis and achieves competitive image quality, demonstrating its effectiveness across diverse and challenging scenarios. A comprehensive user study demonstrates a clear preference for our method over existing approaches, validating both its technical robustness and practical usefulness.",
      "authors": [
        "Edoardo Alberto Dominici",
        "Jozef Hladky",
        "Floor Verhoeven",
        "Lukas Radl",
        "Thomas Deixelberger",
        "Stefan Ainetter",
        "Philipp Drescher",
        "Stefan Hauswiesner",
        "Arno Coomans",
        "Giacomo Nazzaro",
        "Konstantinos Vardis",
        "Markus Steinberger"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20367",
        "HTML": "https://arxiv.org/html/2506.20367",
        "PDF": "https://arxiv.org/pdf/2506.20367"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:30:41 GMT",
          "size": "31905kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DreamAnywhere: Object-Centric Panoramic 3D Scene Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about 3D scene generation and involves text processing but does not focus on the preparation or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20370",
      "abstract": "This paper introduces a novel deep learning framework for robust image zero-watermarking based on distortion-invariant feature learning. As a zero-watermarking scheme, our method leaves the original image unaltered and learns a reference signature through optimization in the feature space. The proposed framework consists of two key modules. In the first module, a feature extractor is trained via noise-adversarial learning to generate representations that are both invariant to distortions and semantically expressive. This is achieved by combining adversarial supervision against a distortion discriminator and a reconstruction constraint to retain image content. In the second module, we design a learning-based multibit zero-watermarking scheme where the trained invariant features are projected onto a set of trainable reference codes optimized to match a target binary message. Extensive experiments on diverse image datasets and a wide range of distortions show that our method achieves state-of-the-art robustness in both feature stability and watermark recovery. Comparative evaluations against existing self-supervised and deep watermarking techniques further highlight the superiority of our framework in generalization and robustness.",
      "authors": [
        "Abdullah All Tanvir",
        "Xin Zhong"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20370",
        "HTML": "https://arxiv.org/html/2506.20370",
        "PDF": "https://arxiv.org/pdf/2506.20370"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:32:08 GMT",
          "size": "6265kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on image zero-watermarking using deep learning, involving feature extraction and watermarking techniques. It does not address LLM training data processing or data engineering related to language models."
      }
    },
    {
      "id": "2506.20372",
      "abstract": "In this work, the problem of optimizing damper positions in vibrational systems is investigated. The objective is to determine the positions of external dampers in such a way that the influence of the input on the output is minimized. The energy response serves as an optimization criterion, whose computation involves solving Lyapunov equations. Hence, in order to find the best positions, many of these equations need to be solved, and so the minimization process can have a high computational cost.\n  To accelerate the process of finding the optimal positions, we propose a new reduction method. Our algorithm generates a basis spanning an approximation to the solution space of the Lyapunov equations for all possible positions of the dampers. We derive an adaptive scheme that generates the reduced solution space by adding the subspaces of interest, and then we define the corresponding reduced optimization problem that is solvable in a reasonable amount of time. We decouple the solution spaces of the problem to obtain a space that corresponds to the system without external dampers and serves as a starting point for the reduction of the optimization problem. In addition, we derive spaces corresponding to the different damper positions that are used to expand the reduced basis if needed. To evaluate the quality of the basis, we introduce an error indicator based on the space decomposition. Our new technique produces a reduced optimization problem of significantly smaller dimension that is faster to solve than the original problem, which we illustrate with some numerical examples.",
      "authors": [
        "Jennifer Przybilla",
        "Matea Ugrica Vukojevi\\'c",
        "Ninolsav Truhar",
        "Peter Benner"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20372",
        "HTML": "https://arxiv.org/html/2506.20372",
        "PDF": "https://arxiv.org/pdf/2506.20372"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:36:45 GMT",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "An adaptive scheme for the optimization of damping positions by decoupling controllability spaces in vibrational systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with optimizing damper positions in vibrational systems and does not involve any aspect of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20373",
      "abstract": "We introduce CARMA, a system for situational grounding in human-robot group interactions. Effective collaboration in such group settings requires situational awareness based on a consistent representation of present persons and objects coupled with an episodic abstraction of events regarding actors and manipulated objects. This calls for a clear and consistent assignment of instances, ensuring that robots correctly recognize and track actors, objects, and their interactions over time. To achieve this, CARMA uniquely identifies physical instances of such entities in the real world and organizes them into grounded triplets of actors, objects, and actions.\n  To validate our approach, we conducted three experiments, where multiple humans and a robot interact: collaborative pouring, handovers, and sorting. These scenarios allow the assessment of the system's capabilities as to role distinction, multi-actor awareness, and consistent instance identification. Our experiments demonstrate that the system can reliably generate accurate actor-action-object triplets, providing a structured and robust foundation for applications requiring spatiotemporal reasoning and situated decision-making in collaborative settings.",
      "authors": [
        "Joerg Deigmoeller",
        "Stephan Hasler",
        "Nakul Agarwal",
        "Daniel Tanneberg",
        "Anna Belardinelli",
        "Reza Ghoddoosian",
        "Chao Wang",
        "Felix Ocker",
        "Fan Zhang",
        "Behzad Dariush",
        "Michael Gienger"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20373",
        "HTML": "https://arxiv.org/html/2506.20373",
        "PDF": "https://arxiv.org/pdf/2506.20373"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:36:49 GMT",
          "size": "1689kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a system for situational grounding in human-robot interactions, focusing on vision-language models, object and action recognition. It does not address LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20376",
      "abstract": "This paper presents a novel approach for robot navigation in environments containing deformable obstacles. By integrating Learning from Demonstration (LfD) with Dynamical Systems (DS), we enable adaptive and efficient navigation in complex environments where obstacles consist of both soft and hard regions. We introduce a dynamic modulation matrix within the DS framework, allowing the system to distinguish between traversable soft regions and impassable hard areas in real-time, ensuring safe and flexible trajectory planning. We validate our method through extensive simulations and robot experiments, demonstrating its ability to navigate deformable environments. Additionally, the approach provides control over both trajectory and velocity when interacting with deformable objects, including at intersections, while maintaining adherence to the original DS trajectory and dynamically adapting to obstacles for smooth and reliable navigation.",
      "authors": [
        "Lingyun Chen",
        "Xinrui Zhao",
        "Marcos P. S. Campanha",
        "Alexander Wegener",
        "Abdeldjallil Naceri",
        "Abdalla Swikir",
        "Sami Haddadin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20376",
        "HTML": "https://arxiv.org/html/2506.20376",
        "PDF": "https://arxiv.org/pdf/2506.20376"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:40:27 GMT",
          "size": "22688kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Enhanced Robotic Navigation in Deformable Environments using Learning from Demonstration and Dynamic Modulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on robotic navigation in environments with deformable obstacles using Learning from Demonstration and Dynamical Systems. It does not relate to LLM training data or processing stages."
      }
    },
    {
      "id": "2506.20380",
      "abstract": "Satellite remote sensing (RS) enables a wide array of downstream Earth observation (EO) applications, including climate modeling, carbon accounting, and strategies for conservation and sustainable land use. We present TESSERA, a novel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning (SSL) to generate global, robust representations at 10m scale from pixel-level satellite time series data. TESSERA combines information from only optical and SAR data streams using two parallel Transformer-based encoders: one dedicated to Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected spectral bands) to create representations that are then fused using a multilayer perceptron (MLP), resulting in a global representation map covering the years 2017 to 2024. Our precomputed representations set a new state-of-the-art performance benchmark and our open-source approach democratizes access to high-performance, high-resolution representations. We benchmark the performance of TESSERA in five diverse tasks, comparing our work with state-of-the-art task-specific models and other foundation models. Our results show that TESSERA outperforms both traditional RS baselines and the leading geospatial foundation models in these diverse downstream tasks.",
      "authors": [
        "Zhengpeng Feng",
        "Sadiq Jaffer",
        "Jovana Knezevic",
        "Silja Sormunen",
        "Robin Young",
        "Madeline Lisaius",
        "Markus Immitzer",
        "James Ball",
        "Clement Atzberger",
        "David A. Coomes",
        "Anil Madhavapeddy",
        "Andrew Blake and Srinivasan Keshav"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20380",
        "HTML": "https://arxiv.org/html/2506.20380",
        "PDF": "https://arxiv.org/pdf/2506.20380"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:46:26 GMT",
          "size": "17534kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces TESSERA, a Remote Sensing Foundation Model utilizing self-supervised learning for Earth observation tasks. It focuses on generating representations from satellite data, not on processing training data for LLMs."
      }
    },
    {
      "id": "2506.20381",
      "abstract": "Transformer-based visual trackers have demonstrated significant advancements due to their powerful modeling capabilities. However, their practicality is limited on resource-constrained devices because of their slow processing speeds. To address this challenge, we present HiT, a novel family of efficient tracking models that achieve high performance while maintaining fast operation across various devices. The core innovation of HiT lies in its Bridge Module, which connects lightweight transformers to the tracking framework, enhancing feature representation quality. Additionally, we introduce a dual-image position encoding approach to effectively encode spatial information. HiT achieves an impressive speed of 61 frames per second (fps) on the NVIDIA Jetson AGX platform, alongside a competitive AUC of 64.6% on the LaSOT benchmark, outperforming all previous efficient trackers.Building on HiT, we propose DyHiT, an efficient dynamic tracker that flexibly adapts to scene complexity by selecting routes with varying computational requirements. DyHiT uses search area features extracted by the backbone network and inputs them into an efficient dynamic router to classify tracking scenarios. Based on the classification, DyHiT applies a divide-and-conquer strategy, selecting appropriate routes to achieve a superior trade-off between accuracy and speed. The fastest version of DyHiT achieves 111 fps on NVIDIA Jetson AGX while maintaining an AUC of 62.4% on LaSOT.Furthermore, we introduce a training-free acceleration method based on the dynamic routing architecture of DyHiT. This method significantly improves the execution speed of various high-performance trackers without sacrificing accuracy. For instance, our acceleration method enables the state-of-the-art tracker SeqTrack-B256 to achieve a 2.68 times speedup on an NVIDIA GeForce RTX 2080 Ti GPU while maintaining the same AUC of 69.9% on the LaSOT.",
      "authors": [
        "Ben Kang",
        "Xin Chen",
        "Jie Zhao",
        "Chunjuan Bo",
        "Dong Wang",
        "Huchuan Lu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20381",
        "HTML": "https://arxiv.org/html/2506.20381",
        "PDF": "https://arxiv.org/pdf/2506.20381"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:46:46 GMT",
          "size": "3842kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses improving transformer-based visual trackers' efficiency and performance with innovative modules and dynamic frameworks. It does not cover the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20383",
      "abstract": "Scanners are daily visitors of public IPv4 hosts. Scanning IPv6 nodes successfully is still a challenge, which an increasing crowd of actors tries to master. In this paper, we analyze current IPv6 scanning under various network conditions. We observe scanner behavior during eleven months in four network telescopes, one of which is periodically reconfigured by changing BGP announcements. We analyze and classify the observed scanners w.r.t. their temporal behavior, their target, and network selection strategy, as well as their individual tools, fingerprints, and correlations across categories. We find that silent subnets of larger prefixes remain invisible, whereas BGP prefix announcements quickly attract attention by scanners. Based on our findings, we derive operational guidance on how to deploy network telescopes to increase visibility of IPv6 scanners.",
      "authors": [
        "Isabell Egloff",
        "Raphael Hiesgen",
        "Maynard Koch",
        "Thomas C. Schmidt",
        "Matthias W\\\"ahlisch"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20383",
        "HTML": "https://arxiv.org/html/2506.20383",
        "PDF": "https://arxiv.org/pdf/2506.20383"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:49:04 GMT",
          "size": "623kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Detailed Measurement View on IPv6 Scanners and Their Adaption to BGP Signals",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper analyzes IPv6 scanner behaviors and network conditions without contribution to LLM training data processes. It focuses on network measurements rather than data engineering for LLMs."
      }
    },
    {
      "id": "2506.20384",
      "abstract": "This paper introduces two significant contributions to address the issue of grounding claims in a given context. Grounding means that given a context (document) and a claim, there's at least one supportive evidence for the claim in the document. We will introduce Paladin-mini, a compact (3.8B parameters) open-source classifier model (used for labeling data as grounded or ungrounded) engineered for robust performance in real-world scenarios, and the grounding-benchmark, a new evaluation dataset designed to assess performance on critical reasoning tasks. We'll also demonstrate the results of Paladin-mini with benchmarks against the current State-of-the-art and share clear and reproducible results.",
      "authors": [
        "Dror Ivry",
        "Oran Nahum"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20384",
        "HTML": "https://arxiv.org/html/2506.20384",
        "PDF": "https://arxiv.org/pdf/2506.20384"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:50:28 GMT",
          "size": "11kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Paladin-mini addresses grounding claims within documents and evaluates a benchmarking dataset for reasoning tasks, with no focus on LLM training data processing."
      }
    },
    {
      "id": "2506.20388",
      "abstract": "Accurate, cost-effective monitoring of plantation aboveground biomass (AGB) is crucial for supporting local livelihoods and carbon sequestration initiatives like the China Certified Emission Reduction (CCER) program. High-resolution canopy height maps (CHMs) are essential for this, but standard lidar-based methods are expensive. While deep learning with RGB imagery offers an alternative, accurately extracting canopy height features remains challenging. To address this, we developed a novel model for high-resolution CHM generation using a Large Vision Foundation Model (LVFM). Our model integrates a feature extractor, a self-supervised feature enhancement module to preserve spatial details, and a height estimator. Tested in Beijing's Fangshan District using 1-meter Google Earth imagery, our model outperformed existing methods, including conventional CNNs. It achieved a mean absolute error of 0.09 m, a root mean square error of 0.24 m, and a correlation of 0.78 against lidar-based CHMs. The resulting CHMs enabled over 90% success in individual tree detection, high accuracy in AGB estimation, and effective tracking of plantation growth, demonstrating strong generalization to non-training areas. This approach presents a promising, scalable tool for evaluating carbon sequestration in both plantations and natural forests.",
      "authors": [
        "Shen Tan",
        "Xin Zhang",
        "Liangxiu Han",
        "Huaguo Huang",
        "Han Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20388",
        "HTML": "https://arxiv.org/html/2506.20388",
        "PDF": "https://arxiv.org/pdf/2506.20388"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:51:49 GMT",
          "size": "2695kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a model for generating canopy height maps for forestry management using visual data, focusing on vision models rather than LLM training data processing."
      }
    },
    {
      "id": "2506.20394",
      "abstract": "The ability to update information acquired through various means online during task execution is crucial for a general-purpose service robot. This information includes geometric and semantic data. While SLAM handles geometric updates on 2D maps or 3D point clouds, online updates of semantic information remain unexplored. We attribute the challenge to the online scene graph representation, for its utility and scalability. Building on previous works regarding offline scene graph representations, we study online graph representations of semantic information in this work. We introduce SPARK: Spatial Perception and Robot Knowledge Integration. This framework extracts semantic information from environment-embedded cues and updates the scene graph accordingly, which is then used for subsequent task planning. We demonstrate that graph representations of spatial relationships enhance the robot system's ability to perform tasks in dynamic environments and adapt to unconventional spatial cues, like gestures.",
      "authors": [
        "Mimo Shirasaka",
        "Yuya Ikeda",
        "Tatsuya Matsushima",
        "Yutaka Matsuo and Yusuke Iwasawa"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20394",
        "HTML": "https://arxiv.org/html/2506.20394",
        "PDF": "https://arxiv.org/pdf/2506.20394"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:02:59 GMT",
          "size": "6142kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on online semantic graph representation for robotics task planning, which is unrelated to LLM training data processing or data engineering aspects."
      }
    },
    {
      "id": "2506.20399",
      "abstract": "Laboratory robotics offer the capability to conduct experiments with a high degree of precision and reproducibility, with the potential to transform scientific research. Trivial and repeatable tasks; e.g., sample transportation for analysis and vial capping are well-suited for robots; if done successfully and reliably, chemists could contribute their efforts towards more critical research activities. Currently, robots can perform these tasks faster than chemists, but how reliable are they? Improper capping could result in human exposure to toxic chemicals which could be fatal. To ensure that robots perform these tasks as accurately as humans, sensory feedback is required to assess the progress of task execution. To address this, we propose a novel methodology based on behaviour trees with multimodal perception. Along with automating robotic tasks, this methodology also verifies the successful execution of the task, a fundamental requirement in safety-critical environments. The experimental evaluation was conducted on two lab tasks: sample vial capping and laboratory rack insertion. The results show high success rate, i.e., 88% for capping and 92% for insertion, along with strong error detection capabilities. This ultimately proves the robustness and reliability of our approach and that using multimodal behaviour trees should pave the way towards the next generation of robotic chemists.",
      "authors": [
        "Hatem Fakhruldeen",
        "Arvind Raveendran Nambiar",
        "Satheeshkumar Veeramani",
        "Bonilkumar Vijaykumar Tailor",
        "Hadi Beyzaee Juneghani",
        "Gabriella Pizzuto and Andrew Ian Cooper"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20399",
        "HTML": "https://arxiv.org/html/2506.20399",
        "PDF": "https://arxiv.org/pdf/2506.20399"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:13:46 GMT",
          "size": "1530kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multimodal Behaviour Trees for Robotic Laboratory Task Automation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses robotic laboratory task automation using multimodal behaviour trees and does not address LLM training data processing or related data engineering challenges."
      }
    },
    {
      "id": "2506.20400",
      "abstract": "Multi-agent-based simulations (MABS) of electric vehicle (EV) home charging ecosystems generate large, complex, and stochastic time-series datasets that capture interactions between households, grid infrastructure, and energy markets. These interactions can lead to unexpected system-level events, such as transformer overloads or consumer dissatisfaction, that are difficult to detect and explain through static post-processing. This paper presents a modular, Python-based dashboard framework, built using Dash by Plotly, that enables efficient, multi-level exploration and root-cause analysis of emergent behavior in MABS outputs. The system features three coordinated views (System Overview, System Analysis, and Consumer Analysis), each offering high-resolution visualizations such as time-series plots, spatial heatmaps, and agent-specific drill-down tools. A case study simulating full EV adoption with smart charging in a Danish residential network demonstrates how the dashboard supports rapid identification and contextual explanation of anomalies, including clustered transformer overloads and time-dependent charging failures. The framework facilitates actionable insight generation for researchers and distribution system operators, and its architecture is adaptable to other distributed energy resources and complex energy systems.",
      "authors": [
        "Kristoffer Christensen",
        "Bo N{\\o}rregaard J{\\o}rgensen and Zheng Grace Ma"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20400",
        "HTML": "https://arxiv.org/html/2506.20400",
        "PDF": "https://arxiv.org/pdf/2506.20400"
      },
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Human-Computer Interaction (cs.HC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:14:49 GMT",
          "size": "1161kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Visualization Framework for Exploring Multi-Agent-Based Simulations Case Study of an Electric Vehicle Home Charging Ecosystem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research centers on visualization tools for analyzing multi-agent-based simulations and does not deal with LLM training data processing or data-related methodologies."
      }
    },
    {
      "id": "2506.20401",
      "abstract": "With the rising popularity of electric vehicles (EVs), modern service systems, such as ride-hailing delivery services, are increasingly integrating EVs into their operations. Unlike conventional vehicles, EVs often have a shorter driving range, necessitating careful consideration of charging when fulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology - allowing EVs to also discharge energy back to the grid - new opportunities and complexities emerge. We introduce the Electric Vehicle Orienteering Problem with V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select customer requests or orders while managing when and where to charge or discharge. This involves navigating dynamic electricity prices, charging station selection, and route constraints. We formulate the problem as a Mixed Integer Programming (MIP) model and propose two near-optimal metaheuristic algorithms: one evolutionary (EA) and the other based on large neighborhood search (LNS). Experiments on real-world data show our methods can double driver profits compared to baselines, while maintaining near-optimal performance on small instances and excellent scalability on larger ones. Our work highlights a promising path toward smarter, more profitable EV-based mobility systems that actively support the energy grid.",
      "authors": [
        "Jinchun Du",
        "Bojie Shen",
        "Muhammad Aamir Cheema",
        "Adel N. Toosi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20401",
        "HTML": "https://arxiv.org/html/2506.20401",
        "PDF": "https://arxiv.org/pdf/2506.20401"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:15:52 GMT",
          "size": "629kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study introduces a problem-solving approach for electric vehicle logistics, focusing on optimization and not on any aspect of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20404",
      "abstract": "Process management systems support key decisions about the way work is allocated in organizations. This includes decisions on which task to perform next, when to execute the task, and who to assign the task to. Suitable software tools are required to support these decisions in a way that is optimal for the organization. This paper presents a software library, called GymPN, that supports optimal decision-making in business processes using Deep Reinforcement Learning. GymPN builds on previous work that supports task assignment in business processes, introducing two key novelties: support for partial process observability and the ability to model multiple decisions in a business process. These novel elements address fundamental limitations of previous work and thus enable the representation of more realistic process decisions. We evaluate the library on eight typical business process decision-making problem patterns, showing that GymPN allows for easy modeling of the desired problems, as well as learning optimal decision policies.",
      "authors": [
        "Riccardo Lo Bianco and Willem van Jaarsveld and Remco Dijkman"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20404",
        "HTML": "https://arxiv.org/html/2506.20404",
        "PDF": "https://arxiv.org/pdf/2506.20404"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:19:42 GMT",
          "size": "698kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "GymPN: A Library for Decision-Making in Process Management Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a library for decision-making in business processes using deep reinforcement learning, without relevance to LLM training data or its processing stage."
      }
    },
    {
      "id": "2506.20412",
      "abstract": "In the cut-query model, the algorithm can access the input graph $G=(V,E)$ only via cut queries that report, given a set $S\\subseteq V$, the total weight of edges crossing the cut between $S$ and $V\\setminus S$. This model was introduced by Rubinstein, Schramm and Weinberg [ITCS'18] and its investigation has so far focused on the number of queries needed to solve optimization problems, such as global minimum cut. We turn attention to the round complexity of cut-query algorithms, and show that several classical problems can be solved in this model with only a constant number of rounds.\n  Our main results are algorithms for finding a minimum cut in a graph, that offer different tradeoffs between round complexity and query complexity, where $n=|V|$ and $\\delta(G)$ denotes the minimum degree of $G$: (i) $\\tilde{O}(n^{4/3})$ cut queries in two rounds in unweighted graphs; (ii) $\\tilde{O}(rn^{1+1/r}/\\delta(G)^{1/r})$ queries in $2r+1$ rounds for any integer $r\\ge 1$ again in unweighted graphs; and (iii) $\\tilde{O}(rn^{1+(1+\\log_n W)/r})$ queries in $4r+3$ rounds for any $r\\ge1$ in weighted graphs. We also provide algorithms that find a minimum $(s,t)$-cut and approximate the maximum cut in a few rounds.",
      "authors": [
        "Yotam Kenneth-Mordoch and Robert Krauthgamer"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20412",
        "HTML": "https://arxiv.org/html/2506.20412",
        "PDF": "https://arxiv.org/pdf/2506.20412"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:27:07 GMT",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Cut-Query Algorithms with Few Rounds",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses algorithms for optimization problems in graphs within the cut-query model, not related to LLM training data processing."
      }
    },
    {
      "id": "2506.20413",
      "abstract": "The growing adoption of Artificial Intelligence (AI) in Internet of Things (IoT) ecosystems has intensified the need for personalized learning methods that can operate efficiently and privately across heterogeneous, resource-constrained devices. However, enabling effective personalized learning in decentralized settings introduces several challenges, including efficient knowledge transfer between clients, protection of data privacy, and resilience against poisoning attacks. In this paper, we address these challenges by developing P4 (Personalized, Private, Peer-to-Peer) -- a method designed to deliver personalized models for resource-constrained IoT devices while ensuring differential privacy and robustness against poisoning attacks. Our solution employs a lightweight, fully decentralized algorithm to privately detect client similarity and form collaborative groups. Within each group, clients leverage differentially private knowledge distillation to co-train their models, maintaining high accuracy while ensuring robustness to the presence of malicious clients. We evaluate P4 on popular benchmark datasets using both linear and CNN-based architectures across various heterogeneity settings and attack scenarios. Experimental results show that P4 achieves 5% to 30% higher accuracy than leading differentially private peer-to-peer approaches and maintains robustness with up to 30% malicious clients. Additionally, we demonstrate its practicality by deploying it on resource-constrained devices, where collaborative training between two clients adds only ~7 seconds of overhead.",
      "authors": [
        "Mohammad Mahdi Maheri",
        "Denys Herasymuk",
        "Hamed Haddadi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20413",
        "HTML": "https://arxiv.org/html/2506.20413",
        "PDF": "https://arxiv.org/pdf/2506.20413"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:27:36 GMT",
          "size": "3343kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on decentralized personalized learning in IoT ecosystems, emphasizing privacy and robustness rather than addressing processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20417",
      "abstract": "We study the novel problem of future off-policy evaluation (F-OPE) and learning (F-OPL) for estimating and optimizing the future value of policies in non-stationary environments, where distributions vary over time. In e-commerce recommendations, for instance, our goal is often to estimate and optimize the policy value for the upcoming month using data collected by an old policy in the previous month. A critical challenge is that data related to the future environment is not observed in the historical data. Existing methods assume stationarity or depend on restrictive reward-modeling assumptions, leading to significant bias. To address these limitations, we propose a novel estimator named \\textit{\\textbf{O}ff-\\textbf{P}olicy Estimator for the \\textbf{F}uture \\textbf{V}alue (\\textbf{\\textit{OPFV}})}, designed for accurately estimating policy values at any future time point. The key feature of OPFV is its ability to leverage the useful structure within time-series data. While future data might not be present in the historical log, we can leverage, for example, seasonal, weekly, or holiday effects that are consistent in both the historical and future data. Our estimator is the first to exploit these time-related structures via a new type of importance weighting, enabling effective F-OPE. Theoretical analysis identifies the conditions under which OPFV becomes low-bias. In addition, we extend our estimator to develop a new policy-gradient method to proactively learn a good future policy using only historical data. Empirical results show that our methods substantially outperform existing methods in estimating and optimizing the future policy value under non-stationarity for various experimental setups.",
      "authors": [
        "Tatsuhiro Shimizu",
        "Kazuki Kawamura",
        "Takanori Muroi",
        "Yusuke Narita",
        "Kei Tateno",
        "Takuma Udagawa",
        "Yuta Saito"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20417",
        "HTML": "https://arxiv.org/html/2506.20417",
        "PDF": "https://arxiv.org/pdf/2506.20417"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:31:46 GMT",
          "size": "2955kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Off-Policy Evaluation and Learning for the Future under Non-Stationarity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on policy value estimation and optimization in non-stationary environments with no emphasis on LLM training data processing."
      }
    },
    {
      "id": "2506.20419",
      "abstract": "Finite element approximation of the velocity-pressure formulation of the surfaces Stokes equations is challenging because it is typically not possible to enforce both tangentiality and $H^1$ conformity of the velocity field. Most previous works concerning finite element methods (FEMs) for these equations thus have weakly enforced one of these two constraints by penalization or a Lagrange multiplier formulation. Recently in [A tangential and penalty-free finite element method for the surface Stokes problem, SINUM 62(1):248-272, 2024], the authors constructed a surface Stokes FEM based on the MINI element which is tangentiality conforming and $H^1$ nonconforming, but possesses sufficient weak continuity properties to circumvent the need for penalization. The key to this method is construction of velocity degrees of freedom lying on element edges and vertices using an auxiliary Piola transform. In this work we extend this methodology to construct Taylor-Hood surface FEMs. The resulting method is shown to achieve optimal-order convergence when the edge degrees of freedom for the velocity spaced are placed at Gauss-Lobatto nodes. Numerical experiments confirm that this nonstandard placement of nodes is necessary to achieve optimal convergence orders.",
      "authors": [
        "Alan Demlow and Michael Neilan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20419",
        "HTML": "https://arxiv.org/html/2506.20419",
        "PDF": "https://arxiv.org/pdf/2506.20419"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:34:44 GMT",
          "size": "126kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Taylor-Hood finite element method for the surface Stokes problem without penalization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with finite element methods for the surface Stokes problem, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20421",
      "abstract": "A geometric graph is a drawing of a graph in the plane where the vertices are drawn as points in general position and the edges as straight-line segments connecting their endpoints. It is plane if it contains no crossing edges. We study plane cycles in geometric complete multipartite graphs. We prove that if a geometric complete multipartite graph contains a plane cycle of length $t$, with $t \\geq 6$, it also contains a smaller plane cycle of length at least $\\lfloor t/2\\rfloor + 1$. We further give a characterization of geometric complete multipartite graphs that contain plane cycles with a color class appearing at least twice. For geometric drawings of $K_{n,n}$, we give a sufficient condition under which they have, for each $s \\leq n$, a plane cycle of length 2s. We also provide an algorithm to decide whether a given geometric drawing of $K_{n,n}$ contains a plane Hamiltonian cycle in time $O(n \\log n + nk^2) + O(k^{5k})$, where k is the number of vertices inside the convex hull of all vertices. Finally, we prove that it is NP-complete to decide if a subset of edges of a geometric complete bipartite graph H is contained in a plane Hamiltonian cycle in H.",
      "authors": [
        "Marco Ricci",
        "Jonathan Rollin",
        "Andr\\'e Schulz",
        "Alexandra Weinberger"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20421",
        "HTML": "https://arxiv.org/html/2506.20421",
        "PDF": "https://arxiv.org/pdf/2506.20421"
      },
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:36:01 GMT",
          "size": "389kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On plane cycles in geometric multipartite graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on geometric graphs and plane cycles, which are unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20431",
      "abstract": "Federated learning aims to train a global model in a distributed environment that is close to the performance of centralized training. However, issues such as client label skew, data quantity skew, and other heterogeneity problems severely degrade the model's performance. Most existing methods overlook the scenario where only a small portion of clients participate in training within a large-scale client setting, whereas our experiments show that this scenario presents a more challenging federated learning task. Therefore, we propose a Knowledge Distillation with teacher-student Inequitable Aggregation (KDIA) strategy tailored to address the federated learning setting mentioned above, which can effectively leverage knowledge from all clients. In KDIA, the student model is the average aggregation of the participating clients, while the teacher model is formed by a weighted aggregation of all clients based on three frequencies: participation intervals, participation counts, and data volume proportions. During local training, self-knowledge distillation is performed. Additionally, we utilize a generator trained on the server to generate approximately independent and identically distributed (IID) data features locally for auxiliary training. We conduct extensive experiments on the CIFAR-10/100/CINIC-10 datasets and various heterogeneous settings to evaluate KDIA. The results show that KDIA can achieve better accuracy with fewer rounds of training, and the improvement is more significant under severe heterogeneity.",
      "authors": [
        "Xing Ma"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20431",
        "HTML": "https://arxiv.org/html/2506.20431",
        "PDF": "https://arxiv.org/pdf/2506.20431"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:42:30 GMT",
          "size": "1191kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper explores challenges in federated learning and knowledge distillation, unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20433",
      "abstract": "The potential of Generative AI (GenAI) for generating feedback in computing education has been the subject of numerous studies. However, there is still limited research on how computing students engage with this feedback and to what extent it supports their problem-solving. For this reason, we built a custom web application providing students with Python programming tasks, a code editor, GenAI feedback, and compiler feedback. Via a think-aloud protocol including eye-tracking and a post-interview with 11 undergraduate students, we investigate (1) how much attention the generated feedback received from learners and (2) to what extent the generated feedback is helpful (or not). In addition, students' attention to GenAI feedback is compared with that towards the compiler feedback. We further investigate differences between students with and without prior programming experience. The findings indicate that GenAI feedback generally receives a lot of visual attention, with inexperienced students spending twice as much fixation time. More experienced students requested GenAI less frequently, and could utilize it better to solve the given problem. It was more challenging for inexperienced students to do so, as they could not always comprehend the GenAI feedback. They often relied solely on the GenAI feedback, while compiler feedback was not read. Understanding students' attention and perception toward GenAI feedback is crucial for developing educational tools that support student learning.",
      "authors": [
        "Sven Jacobs",
        "Maurice Kempf",
        "Natalie Kiesler"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20433",
        "HTML": "https://arxiv.org/html/2506.20433",
        "PDF": "https://arxiv.org/pdf/2506.20433"
      },
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:43:23 GMT",
          "size": "540kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "That's Not the Feedback I Need! -- Student Engagement with GenAI Feedback in the Tutor Kai",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates student engagement with GenAI feedback in educational settings, not addressing LLM training data processing."
      }
    },
    {
      "id": "2506.20435",
      "abstract": "Digital Twins (DTs) are increasingly used to model complex systems, especially in Cyber-Physical Systems (CPS) and System-of-Systems (SoS), where effective integration is key. This systematic literature review investigates DT composition and verification and validation (V&V) methodologies. Analyzing 21 studies from 2022-2024, we examined composition mechanisms, SoS characteristics, and V&V formality, scope, and challenges. While composition is discussed, formalization is limited. V&V approaches vary, with semi-formal methods and simulations dominating; formal verification is underutilized. Key technical challenges include model uncertainty and integration complexity. Methodological challenges highlight the lack of standardized DT-specific V&V frameworks. There is a need to move beyond model validation to address integration and cyber-physical consistency. This review contributes a structured classification of V&V approaches and emphasizes the need for standardized, scalable V&V and rigorous composition methodologies for complex DT implementations.",
      "authors": [
        "Mennatullah T. Khedr",
        "John S. Fitzgerald"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20435",
        "HTML": "https://arxiv.org/html/2506.20435",
        "PDF": "https://arxiv.org/pdf/2506.20435"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:45:16 GMT",
          "size": "262kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Composition of Digital Twins for Systems-of-Systems: a Systematic Literature Review",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on Digital Twins in the context of systems-of-systems, primarily discussing composition and verification methodologies, without addressing LLM training data processing."
      }
    },
    {
      "id": "2506.20441",
      "abstract": "Physics-informed Neural Networks (PINNs) have emerged as an efficient way to learn surrogate neural solvers of PDEs by embedding the physical model in the loss function and minimizing its residuals using automatic differentiation at so-called collocation points. Originally uniformly sampled, the choice of the latter has been the subject of recent advances leading to adaptive sampling refinements. In this paper, we propose a new quadrature method for approximating definite integrals based on the hessian of the considered function, and that we leverage to guide the selection of the collocation points during the training process of PINNs.",
      "authors": [
        "Antoine Caradot",
        "R\\'emi Emonet",
        "Amaury Habrard",
        "Abdel-Rahim Mezidi",
        "Marc Sebban"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20441",
        "HTML": "https://arxiv.org/html/2506.20441",
        "PDF": "https://arxiv.org/pdf/2506.20441"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:49:53 GMT",
          "size": "1049kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "M\\'ethode de quadrature pour les PINNs fond\\'ee th\\'eoriquement sur la hessienne des r\\'esiduels",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is centered on a new quadrature method for Physics-Informed Neural Networks (PINNs) and does not address the processing of training data for large language models."
      }
    },
    {
      "id": "2506.20442",
      "abstract": "Biodiversity loss is a critical planetary boundary, yet its connection to computing remains largely unexamined. Prior sustainability efforts in computing have focused on carbon and water, overlooking biodiversity due to the lack of appropriate metrics and modeling frameworks. This paper presents the first end-to-end analysis of biodiversity impact from computing systems. We introduce two new metrics--Embodied Biodiversity Index (EBI) and Operational Biodiversity Index (OBI)--to quantify biodiversity impact across the lifecycle, and present FABRIC, a modeling framework that links computing workloads to biodiversity impacts. Our evaluation highlights the need to consider biodiversity alongside carbon and water in sustainable computing design and optimization. The code is available at https://github.com/TianyaoShi/FABRIC.",
      "authors": [
        "Tianyao Shi",
        "Ritbik Kumar",
        "Inez Hua",
        "Yi Ding"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20442",
        "HTML": "https://arxiv.org/html/2506.20442",
        "PDF": "https://arxiv.org/pdf/2506.20442"
      },
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:50:04 GMT",
          "size": "770kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper examines biodiversity impacts of computing systems and introduces new metrics for sustainability but does not discuss LLM training data processing."
      }
    },
    {
      "id": "2506.20445",
      "abstract": "Absolute positioning accuracy is a vital specification for robots. Achieving high position precision can be challenging due to the presence of various sources of errors. Meanwhile, accurately depicting these errors is difficult due to their stochastic nature. Vision-based methods are commonly integrated to guide robotic positioning, but their performance can be highly impacted by inevitable occlusions or adverse lighting conditions. Drawing on the aforementioned considerations, a vision-free, model-agnostic meta-method for compensating robotic position errors is proposed, which maximizes the probability of accurate robotic position via interactive feedback. Meanwhile, the proposed method endows the robot with the capability to learn and adapt to various position errors, which is inspired by the human's instinct for grasping under uncertainties. Furthermore, it is a self-learning and self-adaptive method able to accelerate the robotic positioning process as more examples are incorporated and learned. Empirical studies validate the effectiveness of the proposed method. As of the writing of this paper, the proposed meta search method has already been implemented in a robotic-based assembly line for odd-form electronic components.",
      "authors": [
        "Dongkun Wang",
        "Junkai Zhao",
        "Yunfei Teng",
        "Jieyang Peng",
        "Wenjing Xue",
        "Xiaoming Tao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20445",
        "HTML": "https://arxiv.org/html/2506.20445",
        "PDF": "https://arxiv.org/pdf/2506.20445"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:50:57 GMT",
          "size": "1491kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Learn to Position -- A Novel Meta Method for Robotic Positioning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study involves robotic positioning methods and error compensation and does not address any aspects of LLM training data processing."
      }
    },
    {
      "id": "2506.20447",
      "abstract": "The shift in research focus from Industry 4.0 to Industry 5.0 (I5.0) promises a human-centric workplace, with social and well-being values at the centre of technological implementation. Human-Robot Collaboration (HRC) is a core aspect of I5.0 development, with an increase in adaptive and personalised interactions and behaviours. This review investigates recent advancements towards personalised HRC, where user-centric adaption is key. There is a growing trend for adaptable HRC research, however there lacks a consistent and unified approach. The review highlights key research trends on which personal factors are considered, workcell and interaction design, and adaptive task completion. This raises various key considerations for future developments, particularly around the ethical and regulatory development of personalised systems, which are discussed in detail.",
      "authors": [
        "James Fant-Male and Roel Pieters"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20447",
        "HTML": "https://arxiv.org/html/2506.20447",
        "PDF": "https://arxiv.org/pdf/2506.20447"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:53:10 GMT",
          "size": "496kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Review of Personalisation in Human-Robot Collaboration and Future Perspectives Towards Industry 5.0",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on Human-Robot Collaboration in Industry 5.0, emphasizing personalization and human-centric interactions, with no mention of LLMs or training data processing."
      }
    },
    {
      "id": "2506.20452",
      "abstract": "Diffusion models have emerged as the leading approach for image synthesis, demonstrating exceptional photorealism and diversity. However, training diffusion models at high resolutions remains computationally prohibitive, and existing zero-shot generation techniques for synthesizing images beyond training resolutions often produce artifacts, including object duplication and spatial incoherence. In this paper, we introduce HiWave, a training-free, zero-shot approach that substantially enhances visual fidelity and structural coherence in ultra-high-resolution image synthesis using pretrained diffusion models. Our method employs a two-stage pipeline: generating a base image from the pretrained model followed by a patch-wise DDIM inversion step and a novel wavelet-based detail enhancer module. Specifically, we first utilize inversion methods to derive initial noise vectors that preserve global coherence from the base image. Subsequently, during sampling, our wavelet-domain detail enhancer retains low-frequency components from the base image to ensure structural consistency, while selectively guiding high-frequency components to enrich fine details and textures. Extensive evaluations using Stable Diffusion XL demonstrate that HiWave effectively mitigates common visual artifacts seen in prior methods, achieving superior perceptual quality. A user study confirmed HiWave's performance, where it was preferred over the state-of-the-art alternative in more than 80% of comparisons, highlighting its effectiveness for high-quality, ultra-high-resolution image synthesis without requiring retraining or architectural modifications.",
      "authors": [
        "Tobias Vontobel",
        "Seyedmorteza Sadat",
        "Farnood Salehi",
        "Romann M. Weber"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20452",
        "HTML": "https://arxiv.org/html/2506.20452",
        "PDF": "https://arxiv.org/pdf/2506.20452"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:58:37 GMT",
          "size": "44245kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about improving high-resolution image generation using diffusion models with wavelet-based techniques. There is no discussion of LLM training data processing."
      }
    },
    {
      "id": "2506.20457",
      "abstract": "This study introduces the Homotopy Perturbation Sumudu Transform Method (HPSTM), a novel hybrid approach combining the Sumudu transform with homotopy perturbation to solve nonlinear fractional partial differential equations (FPDEs), including fractional porous medium, heat transfer, and Fisher equations, using the Caputo fractional derivative. HPSTM leverages the linearity-preserving properties of the Sumudu transform and the flexibility of homotopy perturbation, achieving faster convergence than Laplace-HPM or Elzaki-HPM for strongly nonlinear FPDEs. Series solutions yield absolute errors as low as $3.12 \\times 10^{-3}$ for $\\alpha = 0.9$, with computational times averaging 0.5 seconds per example using 5 series terms on standard hardware. Solutions are validated against exact solutions, Adomian Decomposition Method (ADM), radial basis function (RBF) meshless method, Variational Iteration Method (VIM), Finite Difference Method (FDM), and a spectral method. Numerical examples, sensitivity analysis, and graphical representations for $\\alpha = 1.0, 0.9, 0.8, 0.7$ confirm HPSTM's accuracy, efficiency, and robustness. Limitations include challenges with high-order nonlinearities and multi-dimensional domains. HPSTM shows promise for applications in modeling fluid flow in porous media, heat conduction in complex materials, and biological population dynamics.",
      "authors": [
        "Maryam Jalili"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20457",
        "HTML": "https://arxiv.org/html/2506.20457",
        "PDF": "https://arxiv.org/pdf/2506.20457"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:08:08 GMT",
          "size": "188kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Novel Homotopy Perturbation Sumudu Transform Method for Nonlinear Fractional PDEs: Applications and Comparative Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a mathematical method for solving nonlinear fractional PDEs, with no relevance to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20463",
      "abstract": "Educators and learners worldwide are embracing the rise of Generative Artificial Intelligence (GenAI) as it reshapes higher education. However, GenAI also raises significant privacy and security concerns, as models and privacy-sensitive user data, such as student records, may be misused by service providers. Unfortunately, end-users often have little awareness of or control over how these models operate. To address these concerns, universities are developing institutional policies to guide GenAI use while safeguarding security and privacy. This work examines these emerging policies and guidelines, with a particular focus on the often-overlooked privacy and security dimensions of GenAI integration in higher education, alongside other academic values. Through a qualitative analysis of GenAI usage guidelines from universities across 12 countries, we identify key challenges and opportunities institutions face in providing effective privacy and security protections, including the need for GenAI safeguards tailored specifically to the academic context.",
      "authors": [
        "Bei Yi Ng",
        "Jiarui Li",
        "Xinyuan Tong",
        "Kevin Ye",
        "Gauthami Yenne",
        "Varun Chandrasekaran",
        "Jingjie Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20463",
        "HTML": "https://arxiv.org/html/2506.20463",
        "PDF": "https://arxiv.org/pdf/2506.20463"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:12:18 GMT",
          "size": "576kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Analyzing Security and Privacy Challenges in Generative AI Usage Guidelines for Higher Education",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on security and privacy challenges related to the use of Generative AI in higher education, specifically addressing policy guidelines but not the processing of LLM training data."
      }
    },
    {
      "id": "2506.20464",
      "abstract": "Rock bolts are crucial components of the subterranean support systems in underground mines that provide adequate structural reinforcement to the rock mass to prevent unforeseen hazards like rockfalls. This makes frequent assessments of such bolts critical for maintaining rock mass stability and minimising risks in underground mining operations. Where manual surveying of rock bolts is challenging due to the low light conditions in the underground mines and the time-intensive nature of the process, automated detection of rock bolts serves as a plausible solution. To that end, this study focuses on the automatic identification of rock bolts within medium to large-scale 3D point clouds obtained from underground mines using mobile laser scanners. Existing techniques for automated rock bolt identification primarily rely on feature engineering and traditional machine learning approaches. However, such techniques lack robustness as these point clouds present several challenges due to data noise, varying environments, and complex surrounding structures. Moreover, the target rock bolts are extremely small objects within large-scale point clouds and are often partially obscured due to the application of reinforcement shotcrete. Addressing these challenges, this paper proposes an approach termed DeepBolt, which employs a novel two-stage deep learning architecture specifically designed for handling severe class imbalance for the automatic and efficient identification of rock bolts in complex 3D point clouds. The proposed method surpasses state-of-the-art semantic segmentation models by up to 42.5% in Intersection over Union (IoU) for rock bolt points. Additionally, it outperforms existing rock bolt identification techniques, achieving a 96.41% precision and 96.96% recall in classifying rock bolts, demonstrating its robustness and effectiveness in complex underground environments.",
      "authors": [
        "Dibyayan Patra",
        "Pasindu Ranasinghe",
        "Bikram Banerjee",
        "Simit Raval"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20464",
        "HTML": "https://arxiv.org/html/2506.20464",
        "PDF": "https://arxiv.org/pdf/2506.20464"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:12:49 GMT",
          "size": "2009kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with the identification of rock bolts in 3D point clouds using deep learning techniques, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20469",
      "abstract": "State-of-the-art Deep Neural Networks (DNNs) often incorporate multi-branch connections, enabling multi-scale feature extraction and enhancing the capture of diverse features. This design improves network capacity and generalisation to unseen data. However, training such DNNs can be computationally expensive. The challenge is further exacerbated by the complexity of identifying optimal network architectures. To address this, we leverage Evolutionary Algorithms (EAs) to automatically discover high-performing architectures, a process commonly known as neuroevolution. We introduce a novel approach based on Linear Genetic Programming (LGP) to encode multi-branch (MB) connections within DNNs, referred to as NeuroLGP-MB. To efficiently design the DNNs, we use surrogate-assisted EAs. While their application in simple artificial neural networks has been influential, we scale their use from dozens or hundreds of sample points to thousands, aligning with the demands of complex DNNs by incorporating a semantic-based approach in our surrogate-assisted EA. Furthermore, we introduce a more advanced surrogate model that outperforms baseline, computationally expensive, and simpler surrogate models.",
      "authors": [
        "Fergal Stapleton",
        "Daniel Garc\\'ia N\\'u\\~nez",
        "Yanan Sun and Edgar Galv\\'an"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20469",
        "HTML": "https://arxiv.org/html/2506.20469",
        "PDF": "https://arxiv.org/pdf/2506.20469"
      },
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:18:17 GMT",
          "size": "417kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Surrogate-Assisted Evolution for Efficient Multi-branch Connection Design in Deep Neural Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the design of deep neural network architectures using evolutionary algorithms, with no connection to the processing of LLM training data."
      }
    },
    {
      "id": "2506.20472",
      "abstract": "Opinion Dynamics (OD) models are a particular case of Agent-Based Models in which the evolution of opinions within a population is studied. In most OD models, opinions evolve as a consequence of interactions between agents, and the opinion fusion rule defines how those opinions are updated. In consequence, despite being simplistic, OD models provide an explainable and interpretable mechanism for understanding the underlying dynamics of opinion evolution. Unfortunately, existing OD models mainly focus on explaining the evolution of (usually synthetic) opinions towards consensus, fragmentation, or polarization, but they usually fail to analyze scenarios of (real-world) highly oscillating opinions. This work overcomes this limitation by studying the ability of several OD models to reproduce highly oscillating dynamics. To this end, we formulate an optimization problem which is further solved using Evolutionary Algorithms, providing both quantitative results on the performance of the optimization and qualitative interpretations on the obtained results. Our experiments on a real-world opinion dataset about immigration from the monthly barometer of the Spanish Sociological Research Center show that the ATBCR, based on both rational and emotional mechanisms of opinion update, is the most accurate OD model for capturing highly oscillating opinions.",
      "authors": [
        "V\\'ictor A. Vargas-P\\'erez",
        "Jes\\'us Gir\\'aldez-Cru",
        "Oscar Cord\\'on"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20472",
        "HTML": "https://arxiv.org/html/2506.20472",
        "PDF": "https://arxiv.org/pdf/2506.20472"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computers and Society (cs.CY)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:22:13 GMT",
          "size": "317kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Opinion Dynamics with Highly Oscillating Opinions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores opinion dynamics models and their performance on highly oscillating opinions, with experiments conducted on a specific opinion dataset. It does not involve any processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20474",
      "abstract": "An intrinsic aspect of every conversation is the way talk-time is shared between multiple speakers. Conversations can be balanced, with each speaker claiming a similar amount of talk-time, or imbalanced when one talks disproportionately. Such overall distributions are the consequence of continuous negotiations between the speakers throughout the conversation: who should be talking at every point in time, and for how long?\n  In this work we introduce a computational framework for quantifying both the conversation-level distribution of talk-time between speakers, as well as the lower-level dynamics that lead to it. We derive a typology of talk-time sharing dynamics structured by several intuitive axes of variation. By applying this framework to a large dataset of video-chats between strangers, we confirm that, perhaps unsurprisingly, different conversation-level distributions of talk-time are perceived differently by speakers, with balanced conversations being preferred over imbalanced ones, especially by those who end up talking less. Then we reveal that -- even when they lead to the same level of overall balance -- different types of talk-time sharing dynamics are perceived differently by the participants, highlighting the relevance of our newly introduced typology. Finally, we discuss how our framework offers new tools to designers of computer-mediated communication platforms, for both human-human and human-AI communication.",
      "authors": [
        "Kaixiang Zhang",
        "Justine Zhang",
        "Cristian Danescu-Niculescu-Mizil"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20474",
        "HTML": "https://arxiv.org/html/2506.20474",
        "PDF": "https://arxiv.org/pdf/2506.20474"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:23:02 GMT",
          "size": "1762kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study is focused on conversational dynamics and talk-time sharing using a framework applied to a video-chat dataset. It does not address LLM training data processing."
      }
    },
    {
      "id": "2506.20475",
      "abstract": "Lifting on construction sites, as a frequent operation, works still with safety risks, especially for modular integrated construction (MiC) lifting due to its large weight and size, probably leading to accidents, causing damage to the modules, or more critically, posing safety hazards to on-site workers. Aiming to reduce the safety risks in lifting scenarios, we design an automated safe lifting monitoring algorithm pipeline based on learning-based methods, and deploy it on construction sites. This work is potentially to increase the safety and efficiency of MiC lifting process via automation technologies. A dataset is created consisting of 1007 image-point cloud pairs (37 MiC liftings). Advanced object detection models are trained for automated two-dimensional (2D) detection of MiCs and humans. Fusing the 2D detection results with the point cloud information allows accurate determination of the three-dimensional (3D) positions of MiCs and humans. The system is designed to automatically trigger alarms that notify individuals in the MiC lifting danger zone, while providing the crane operator with real-time lifting information and early warnings. The monitoring process minimizes the human intervention and no or less signal men are required on real sites assisted by our system. A quantitative analysis is conducted to evaluate the effectiveness of the algorithmic pipeline. The pipeline shows promising results in MiC and human perception with the mean distance error of 1.5640 m and 0.7824 m respectively. Furthermore, the developed system successfully executes safety risk monitoring and alarm functionalities during the MiC lifting process with limited manual work on real construction sites.",
      "authors": [
        "Hao Chen",
        "Yu Hin Ng",
        "Ching-Wei Chang",
        "Haobo Liang",
        "Yanke Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20475",
        "HTML": "https://arxiv.org/html/2506.20475",
        "PDF": "https://arxiv.org/pdf/2506.20475"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:23:16 GMT",
          "size": "7121kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Learning-based safety lifting monitoring system for cranes on construction sites",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a safety monitoring system for crane operations on construction sites, involving image and point cloud data processing, unrelated to any LLM training data tasks."
      }
    },
    {
      "id": "2506.20480",
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in deployment and inference. While structured pruning of model parameters offers a promising way to reduce computational costs at deployment time, current methods primarily focus on single model pruning. In this work, we develop a novel strategy to compress models by strategically combining or merging layers from finetuned model variants, which preserves the original model's abilities by aggregating capabilities accentuated in different finetunes. We pose the optimal tailoring of these LLMs as a zero-order optimization problem, adopting a search space that supports three different operations: (1) Layer removal, (2) Layer selection from different candidate models, and (3) Layer merging. Our experiments demonstrate that this approach leads to competitive model pruning, for example, for the Llama2-13B model families, our compressed models maintain approximately 97.3\\% of the original performance while removing $\\sim25\\%$ of parameters, significantly outperforming previous state-of-the-art methods. The code is available at https://github.com/Guinan-Su/auto-merge-llm.",
      "authors": [
        "Guinan Su",
        "Li Shen",
        "Lu Yin",
        "Shiwei Liu",
        "Yanwu Yang",
        "Jonas Geiping"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20480",
        "HTML": "https://arxiv.org/html/2506.20480",
        "PDF": "https://arxiv.org/pdf/2506.20480"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:24:59 GMT",
          "size": "1739kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on model compression techniques for LLMs through layer manipulation, involving pruning and optimization, rather than training data processing."
      }
    },
    {
      "id": "2506.20485",
      "abstract": "Unmanned Aerial Vehicles (UAVS) are limited by the onboard energy. Refinement of the navigation strategy directly affects both the flight velocity and the trajectory based on the adjustment of key parameters in the UAVS pipeline, thus reducing energy consumption. However, existing techniques tend to adopt static and conservative strategies in dynamic scenarios, leading to inefficient energy reduction. Dynamically adjusting the navigation strategy requires overcoming the challenges including the task pipeline interdependencies, the environmental-strategy correlations, and the selecting parameters. To solve the aforementioned problems, this paper proposes a method to dynamically adjust the navigation strategy of the UAVS by analyzing its dynamic characteristics and the temporal characteristics of the autonomous navigation pipeline, thereby reducing UAVS energy consumption in response to environmental changes. We compare our method with the baseline through hardware-in-the-loop (HIL) simulation and real-world experiments, showing our method 3.2X and 2.6X improvements in mission time, 2.4X and 1.6X improvements in energy, respectively.",
      "authors": [
        "Tian Liu",
        "Han Liu",
        "Boyang Li",
        "Long Chen",
        "Kai Huang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20485",
        "HTML": "https://arxiv.org/html/2506.20485",
        "PDF": "https://arxiv.org/pdf/2506.20485"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:32:45 GMT",
          "size": "4216kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "EANS: Reducing Energy Consumption for UAV with an Environmental Adaptive Navigation Strategy",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on energy reduction strategies for Unmanned Aerial Vehicles and does not address any aspect of LLM training data processing."
      }
    },
    {
      "id": "2506.20486",
      "abstract": "Neural Cellular Automata (NCAs) are a promising new approach to model self-organizing processes, with potential applications in life science. However, their deterministic nature limits their ability to capture the stochasticity of real-world biological and physical systems.\n  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework incorporating the idea of mixture models into the NCA paradigm. By combining probabilistic rule assignments with intrinsic noise, MNCAs can model diverse local behaviors and reproduce the stochastic dynamics observed in biological processes.\n  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic simulations of tissue growth and differentiation, (2) image morphogenesis robustness, and (3) microscopy image segmentation. Results show that MNCAs achieve superior robustness to perturbations, better recapitulate real biological growth patterns, and provide interpretable rule segmentation. These findings position MNCAs as a promising tool for modeling stochastic dynamical systems and studying self-growth processes.",
      "authors": [
        "Salvatore Milite",
        "Giulio Caravagna",
        "Andrea Sottoriva"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20486",
        "HTML": "https://arxiv.org/html/2506.20486",
        "PDF": "https://arxiv.org/pdf/2506.20486"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:33:35 GMT",
          "size": "12208kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is concerned with modeling stochastic dynamical systems and self-growth processes using Neural Cellular Automata, unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20487",
      "abstract": "Humanoid robots are drawing significant attention as versatile platforms for complex motor control, human-robot interaction, and general-purpose physical intelligence. However, achieving efficient whole-body control (WBC) in humanoids remains a fundamental challenge due to sophisticated dynamics, underactuation, and diverse task requirements. While learning-based controllers have shown promise for complex tasks, their reliance on labor-intensive and costly retraining for new scenarios limits real-world applicability. To address these limitations, behavior(al) foundation models (BFMs) have emerged as a new paradigm that leverages large-scale pretraining to learn reusable primitive skills and behavioral priors, enabling zero-shot or rapid adaptation to a wide range of downstream tasks. In this paper, we present a comprehensive overview of BFMs for humanoid WBC, tracing their development across diverse pre-training pipelines. Furthermore, we discuss real-world applications, current limitations, urgent challenges, and future opportunities, positioning BFMs as a key approach toward scalable and general-purpose humanoid intelligence. Finally, we provide a curated and long-term list of BFM papers and projects to facilitate more subsequent research, which is available at https://github.com/yuanmingqi/awesome-bfm-papers.",
      "authors": [
        "Mingqi Yuan",
        "Tao Yu",
        "Wenqi Ge",
        "Xiuyong Yao",
        "Dapeng Li",
        "Huijiang Wang",
        "Jiayu Chen",
        "Xin Jin",
        "Bo Li",
        "Hua Chen",
        "Wei Zhang",
        "Wenjun Zeng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20487",
        "HTML": "https://arxiv.org/html/2506.20487",
        "PDF": "https://arxiv.org/pdf/2506.20487"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:35:33 GMT",
          "size": "4847kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Behavior Foundation Model: Towards Next-Generation Whole-Body Control System of Humanoid Robots",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses whole-body control systems in humanoid robots using behavior foundation models and does not involve LLM training data or related data processing stages."
      }
    },
    {
      "id": "2506.20493",
      "abstract": "The growing integration of renewable energy sources necessitates adequate reserve capacity to maintain power balance. However, in market clearing, power companies with flexible resources may submit strategic bids to maximize profits, potentially compromising system reserves. This paper examines the effects of such strategic behavior by modeling the market as a bi-level problem. The upper level represents a strategic company aiming to maximize profit, while the lower level simulates the system operator clearing the market based on submitted offers. To enable duality-based solution methods, we approximate unit commitments with a continuous reserve capacity calculation. Case studies indicate that, in an imperfectly competitive market, more units are incentivized to operate,enhancing system reserves. However, some units go online mainly for profit, ultimately raising electricity costs for consumers. These findings highlight the importance of market design in managing the trade-off between reserve adequacy and economic efficiency in the presence of strategic bidding behavior.",
      "authors": [
        "Yun Xu",
        "Yunxiao Bai",
        "Yunyong Zhang",
        "Peng Wang",
        "Xuelin Wang",
        "Jiqun Guo",
        "Kaijun Xie",
        "Rusheng Zhao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20493",
        "HTML": "https://arxiv.org/html/2506.20493",
        "PDF": "https://arxiv.org/pdf/2506.20493"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Computer Science and Game Theory (cs.GT)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:40:01 GMT",
          "size": "444kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Analyzing the Impact of Strategic Bidding on the Reserve Capacity via a Bi-Level Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research addresses strategic bidding in energy markets and does not relate to any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.20496",
      "abstract": "Surgical training remains a crucial milestone in modern medicine, with procedures such as laminectomy exemplifying the high risks involved. Laminectomy drilling requires precise manual control to mill bony tissue while preserving spinal segment integrity and avoiding breaches in the dura: the protective membrane surrounding the spinal cord. Despite unintended tears occurring in up to 11.3% of cases, no assistive tools are currently utilized to reduce this risk. Variability in patient anatomy further complicates learning for novice surgeons. This study introduces CAPTAiN, a critical anatomy-preserving and terrain-augmenting navigation system that provides layered, color-coded voxel guidance to enhance anatomical awareness during spinal drilling. CAPTAiN was evaluated against a standard non-navigated approach through 110 virtual laminectomies performed by 11 orthopedic residents and medical students. CAPTAiN significantly improved surgical completion rates of target anatomy (87.99% vs. 74.42%) and reduced cognitive load across multiple NASA-TLX domains. It also minimized performance gaps across experience levels, enabling novices to perform on par with advanced trainees. These findings highlight CAPTAiN's potential to optimize surgical execution and support skill development across experience levels. Beyond laminectomy, it demonstrates potential for broader applications across various surgical and drilling procedures, including those in neurosurgery, otolaryngology, and other medical fields.",
      "authors": [
        "Jonathan Wang",
        "Hisashi Ishida",
        "David Usevitch",
        "Kesavan Venkatesh",
        "Yi Wang",
        "Mehran Armand",
        "Rachel Bronheim",
        "Amit Jain",
        "Adnan Munawar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20496",
        "HTML": "https://arxiv.org/html/2506.20496",
        "PDF": "https://arxiv.org/pdf/2506.20496"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:43:58 GMT",
          "size": "15166kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Critical Anatomy-Preserving & Terrain-Augmenting Navigation (CAPTAiN): Application to Laminectomy Surgical Education",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus here is on surgical navigation tools, not related to the collection, construction, or processing of LLM training data."
      }
    },
    {
      "id": "2506.20501",
      "abstract": "Additive two-tower models are popular learning-to-rank methods for handling biased user feedback in industry settings. Recent studies, however, report a concerning phenomenon: training two-tower models on clicks collected by well-performing production systems leads to decreased ranking performance. This paper investigates two recent explanations for this observation: confounding effects from logging policies and model identifiability issues. We theoretically analyze the identifiability conditions of two-tower models, showing that either document swaps across positions or overlapping feature distributions are required to recover model parameters from clicks. We also investigate the effect of logging policies on two-tower models, finding that they introduce no bias when models perfectly capture user behavior. However, logging policies can amplify biases when models imperfectly capture user behavior, particularly when prediction errors correlate with document placement across positions. We propose a sample weighting technique to mitigate these effects and provide actionable insights for researchers and practitioners using two-tower models.",
      "authors": [
        "Philipp Hager",
        "Onno Zoeter",
        "Maarten de Rijke"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20501",
        "HTML": "https://arxiv.org/html/2506.20501",
        "PDF": "https://arxiv.org/pdf/2506.20501"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:47:43 GMT",
          "size": "511kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Unidentified and Confounded? Understanding Two-Tower Models for Unbiased Learning to Rank",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on learning-to-rank methods and confounding effects in two-tower models, without discussing LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20503",
      "abstract": "Online Social Networks (OSNs) are a cornerstone in modern society, serving as platforms for diverse content consumption by millions of users each day. However, the challenge of ensuring the accuracy of information shared on these platforms remains significant, especially with the widespread dissemination of disinformation. Social bots -- automated accounts designed to mimic human behavior, frequently spreading misinformation -- represent one of the critical problems of OSNs. The advent of Large Language Models (LLMs) has further complicated bot behaviors, making detection increasingly difficult. This paper presents BotHash, an innovative, training-free approach to social bot detection. BotHash leverages a simplified user representation that enables approximate nearest-neighbor search to detect bots, avoiding the complexities of Deep-Learning model training and large dataset creation. We demonstrate that BotHash effectively differentiates between human and bot accounts, even when state-of-the-art LLMs are employed to generate posts' content. BotHash offers several advantages over existing methods, including its independence from a training phase, robust performance with minimal ground-truth data, and early detection capabilities, showing promising results across various datasets.",
      "authors": [
        "Edoardo Di Paolo",
        "Fabio De Gaspari",
        "Angelo Spognardi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20503",
        "HTML": "https://arxiv.org/html/2506.20503",
        "PDF": "https://arxiv.org/pdf/2506.20503"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:49:28 GMT",
          "size": "87kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "BotHash: Efficient and Training-Free Bot Detection Through Approximate Nearest Neighbor",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for bot detection without any focus on the processing or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20504",
      "abstract": "We spell out a definition of sentience that may be useful for designing and building it in machines. We propose that for sentience to be meaningful for AI, it must be fleshed out in functional, computational terms, in enough detail to allow for implementation. Yet, this notion of sentience must also reflect something essentially 'subjective', beyond just having the general capacity to encode perceptual content. For this specific functional notion of sentience to occur, we propose that certain sensory signals need to be both assertoric (persistent) and qualitative. To illustrate the definition in more concrete terms, we sketch out some ways for potential implementation, given current technology. Understanding what it takes for artificial agents to be functionally sentient can also help us avoid creating them inadvertently, or at least, realize that we have created them in a timely manner.",
      "authors": [
        "Konstantin Demin",
        "Taylor Webb",
        "Eric Elmoznino",
        "Hakwan Lau"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20504",
        "HTML": "https://arxiv.org/html/2506.20504",
        "PDF": "https://arxiv.org/pdf/2506.20504"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:49:50 GMT",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Engineering Sentience",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the definition and implementation of sentience in AI and does not address the processing or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20508",
      "abstract": "We address the problem of covering a target segment $\\overline{uv}$ using a finite set of guards $\\mathcal{S}$ placed on a source segment $\\overline{xy}$ within a simple polygon $\\mathcal{P}$, assuming weak visibility between the target and source. Without geometric constraints, $\\mathcal{S}$ may be infinite, as shown by prior hardness results. To overcome this, we introduce the {\\it line aspect ratio} (AR), defined as the ratio of the \\emph{long width} (LW) to the \\emph{short width} (SW) of $\\mathcal{P}$. These widths are determined by parallel lines tangent to convex vertices outside $\\mathcal{P}$ (LW) and reflex vertices inside $\\mathcal{P}$ (SW), respectively.\n  Under the assumption that AR is constant or polynomial in $n$ (the polygon's complexity), we prove that a finite guard set $\\mathcal{S}$ always exists, with size bounded by $\\mathcal{O}(\\text{AR})$. This AR-based framework generalizes some previous assumptions, encompassing a broader class of polygons.\n  Our result establishes a framework guaranteeing finite solutions for segment guarding under practical and intuitive geometric constraints.",
      "authors": [
        "Arash Vaezi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20508",
        "HTML": "https://arxiv.org/html/2506.20508",
        "PDF": "https://arxiv.org/pdf/2506.20508"
      },
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:53:51 GMT",
          "size": "390kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Line Aspect Ratio",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses geometric problems and polygon coverage without any reference to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20511",
      "abstract": "Federated Learning (FL) is a decentralized collaborative Machine Learning framework for training models without collecting data in a centralized location. It has seen application across various disciplines, from helping medical diagnoses in hospitals to detecting fraud in financial transactions. In this paper, we focus on improving the local training process through hardware usage optimization. While participants in a federation might share the hardware they are training on, since there is no information exchange between them, their training process can be hindered by an improper training configuration. Taking advantage of the parallel processing inherent to Federated Learning, we use a greedy randomized search to optimize local batch sizes for the best training settings across all participants. Our results show that against default parameter settings, our method improves convergence speed while staying nearly on par with the case where local parameters are optimized.",
      "authors": [
        "Arno Geimer",
        "Karthick Panner Selvam",
        "Beltran Fiz Pontiveros"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20511",
        "HTML": "https://arxiv.org/html/2506.20511",
        "PDF": "https://arxiv.org/pdf/2506.20511"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:57:23 GMT",
          "size": "117kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Collaborative Batch Size Optimization for Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores optimization in federated learning settings, focusing on batch size optimization and hardware usage, but does not relate to LLM training data."
      }
    },
    {
      "id": "2506.20518",
      "abstract": "Federated Learning (FL) is a collaborative machine learning paradigm which allows participants to collectively train a model while training data remains private. This paradigm is especially beneficial for sectors like finance, where data privacy, security and model performance are paramount. FL has been extensively studied in the years following its introduction, leading to, among others, better performing collaboration techniques, ways to defend against other clients trying to attack the model, and contribution assessment methods. An important element in for-profit Federated Learning is the development of incentive methods to determine the allocation and distribution of rewards for participants. While numerous methods for allocation have been proposed and thoroughly explored, distribution frameworks remain relatively understudied. In this paper, we propose a novel framework which introduces client-specific tokens as investment vehicles within the FL ecosystem. Our framework aims to address the limitations of existing incentive schemes by leveraging a decentralized finance (DeFi) platform and automated market makers (AMMs) to create a more flexible and scalable reward distribution system for participants, and a mechanism for third parties to invest in the federation learning process.",
      "authors": [
        "Arno Geimer",
        "Beltran Fiz Pontiveros",
        "Radu State"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20518",
        "HTML": "https://arxiv.org/html/2506.20518",
        "PDF": "https://arxiv.org/pdf/2506.20518"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:05:01 GMT",
          "size": "270kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses federated learning frameworks and incentives within FL systems, with no relevance to the training data processing or data engineering for LLMs."
      }
    },
    {
      "id": "2506.20522",
      "abstract": "Periodontitis, a chronic inflammatory disease causing alveolar bone loss, significantly affects oral health and quality of life. Accurate assessment of bone loss severity and pattern is critical for diagnosis and treatment planning. In this study, we propose a novel AI-based deep learning framework to automatically detect and quantify alveolar bone loss and its patterns using intraoral periapical (IOPA) radiographs. Our method combines YOLOv8 for tooth detection with Keypoint R-CNN models to identify anatomical landmarks, enabling precise calculation of bone loss severity. Additionally, YOLOv8x-seg models segment bone levels and tooth masks to determine bone loss patterns (horizontal vs. angular) via geometric analysis. Evaluated on a large, expertly annotated dataset of 1000 radiographs, our approach achieved high accuracy in detecting bone loss severity (intra-class correlation coefficient up to 0.80) and bone loss pattern classification (accuracy 87%). This automated system offers a rapid, objective, and reproducible tool for periodontal assessment, reducing reliance on subjective manual evaluation. By integrating AI into dental radiographic analysis, our framework has the potential to improve early diagnosis and personalized treatment planning for periodontitis, ultimately enhancing patient care and clinical outcomes.",
      "authors": [
        "Chathura Wimalasiri",
        "Piumal Rathnayake",
        "Shamod Wijerathne",
        "Sumudu Rasnayaka",
        "Dhanushka Leuke Bandara",
        "Roshan Ragel",
        "Vajira Thambawita",
        "Isuru Nawinne"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20522",
        "HTML": "https://arxiv.org/html/2506.20522",
        "PDF": "https://arxiv.org/pdf/2506.20522"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:08:52 GMT",
          "size": "7355kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper centers on an AI-based framework for analyzing medical radiographs, which is unrelated to the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20525",
      "abstract": "Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of high-quality datasets and the complex variability of industrial energy consumption patterns. To address data scarcity and privacy issues, we introduce the Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an open-source dataset generated using Digital Twin simulations. SIDED includes three types of industrial facilities across three different geographic locations, capturing diverse appliance behaviors, weather conditions, and load profiles. We also propose the Appliance-Modulated Data Augmentation (AMDA) method, a computationally efficient technique that enhances NILM model generalization by intelligently scaling appliance power contributions based on their relative impact. We show in experiments that NILM models trained with AMDA-augmented data significantly improve the disaggregation of energy consumption of complex industrial appliances like combined heat and power systems. Specifically, in our out-of-sample scenarios, models trained with AMDA achieved a Normalized Disaggregation Error of 0.093, outperforming models trained without data augmentation (0.451) and those trained with random data augmentation (0.290). Data distribution analyses confirm that AMDA effectively aligns training and test data distributions, enhancing model generalization.",
      "authors": [
        "Christian Intern\\`o",
        "Andrea Castellani",
        "Sebastian Schmitt",
        "Fabio Stella",
        "Barbara Hammer"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20525",
        "HTML": "https://arxiv.org/html/2506.20525",
        "PDF": "https://arxiv.org/pdf/2506.20525"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:10:43 GMT",
          "size": "1226kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the generation of an industrial energy dataset and data augmentation techniques for energy disaggregation models, which is unrelated to training data processing for LLMs."
      }
    },
    {
      "id": "2506.20530",
      "abstract": "As AI capabilities rapidly advance, the risk of catastrophic harm from large-scale training runs is growing. Yet the compute infrastructure that enables such development remains largely unregulated. This paper proposes a concrete framework for a global \"Compute Pause Button\": a governance system designed to prevent dangerously powerful AI systems from being trained by restricting access to computational resources. We identify three key intervention points -- technical, traceability, and regulatory -- and organize them within a Governance--Enforcement--Verification (GEV) framework to ensure rules are clear, violations are detectable, and compliance is independently verifiable. Technical mechanisms include tamper-proof FLOP caps, model locking, and offline licensing. Traceability tools track chips, components, and users across the compute supply chain. Regulatory mechanisms establish constraints through export controls, production caps, and licensing schemes. Unlike post-deployment oversight, this approach targets the material foundations of advanced AI development. Drawing from analogues ranging from nuclear non-proliferation to pandemic-era vaccine coordination, we demonstrate how compute can serve as a practical lever for global cooperation. While technical and political challenges remain, we argue that credible mechanisms already exist, and that the time to build this architecture is now, before the window for effective intervention closes.",
      "authors": [
        "Ananthi Al Ramiah",
        "Raymond Koopmanschap",
        "Josh Thorsteinson",
        "Sadruddin Khan",
        "Jim Zhou",
        "Shafira Noh",
        "Joep Meindertsma",
        "Farhan Shafiq"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20530",
        "HTML": "https://arxiv.org/html/2506.20530",
        "PDF": "https://arxiv.org/pdf/2506.20530"
      },
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:18:19 GMT",
          "size": "377kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Toward a Global Regime for Compute Governance: Building the Pause Button",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The main topic is governance of compute resources to prevent training of powerful AI systems. It does not involve LLM training data processing."
      }
    },
    {
      "id": "2506.20531",
      "abstract": "Driving in safety-critical scenarios requires quick, context-aware decision-making grounded in both situational understanding and experiential reasoning. Large Language Models (LLMs), with their powerful general-purpose reasoning capabilities, offer a promising foundation for such decision-making. However, their direct application to autonomous driving remains limited due to challenges in domain adaptation, contextual grounding, and the lack of experiential knowledge needed to make reliable and interpretable decisions in dynamic, high-risk environments. To address this gap, this paper presents a Case-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for evasive maneuver decision-making in complex risk scenarios. Our approach integrates semantic scene understanding from dashcam video inputs with the retrieval of relevant past driving cases, enabling LLMs to generate maneuver recommendations that are both context-sensitive and human-aligned. Experiments across multiple open-source LLMs show that our framework improves decision accuracy, justification quality, and alignment with human expert behavior. Risk-aware prompting strategies further enhance performance across diverse risk types, while similarity-based case retrieval consistently outperforms random sampling in guiding in-context learning. Case studies further demonstrate the framework's robustness in challenging real-world conditions, underscoring its potential as an adaptive and trustworthy decision-support tool for intelligent driving systems.",
      "authors": [
        "Wenbin Gan",
        "Minh-Son Dao",
        "Koji Zettsu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20531",
        "HTML": "https://arxiv.org/html/2506.20531",
        "PDF": "https://arxiv.org/pdf/2506.20531"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:19:25 GMT",
          "size": "6925kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a framework that uses LLMs in decision-making for autonomous driving scenarios, focusing on context-aware decision support rather than LLM training data processing."
      }
    },
    {
      "id": "2506.20535",
      "abstract": "The rapid advancement of AI, particularly large language models (LLMs), has raised significant concerns about the energy use and carbon emissions associated with model training and inference. However, existing tools for measuring and reporting such impacts are often fragmented, lacking systematic metric integration and offering limited support for correlation analysis among them. This paper presents WattsOnAI, a comprehensive software toolkit for the measurement, analysis, and visualization of energy use, power draw, hardware performance, and carbon emissions across AI workloads. By seamlessly integrating with existing AI frameworks, WattsOnAI offers standardized reports and exports fine-grained time-series data to support benchmarking and reproducibility in a lightweight manner. It further enables in-depth correlation analysis between hardware metrics and model performance and thus facilitates bottleneck identification and performance enhancement. By addressing critical limitations in existing tools, WattsOnAI encourages the research community to weigh environmental impact alongside raw performance of AI workloads and advances the shift toward more sustainable \"Green AI\" practices. The code is available at https://github.com/SusCom-Lab/WattsOnAI.",
      "authors": [
        "Hongzhen Huang",
        "Kunming Zhang",
        "Hanlong Liao",
        "Kui Wu and Guoming Tang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20535",
        "HTML": "https://arxiv.org/html/2506.20535",
        "PDF": "https://arxiv.org/pdf/2506.20535"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:24:45 GMT",
          "size": "2396kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "WattsOnAI: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on measuring energy consumption and carbon footprint of AI workloads, not on processing training data for LLMs."
      }
    },
    {
      "id": "2506.20537",
      "abstract": "Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process prediction due to the lasting issue of high computation cost using traditional numerical methods such as finite element analysis (FEA). This study presents an efficient modeling framework termed FEA-Regulated Physics-Informed Neural Network (FEA-PINN) to accelerate the thermal field prediction in a LPBF process while maintaining the FEA accuracy. A novel dynamic material updating strategy is developed to capture the dynamic phase change of powder-liquid-solid in the PINN model. The PINN model incorporates temperature-dependent material properties and phase change behavior using the apparent heat capacity method. While the PINN model demonstrates high accuracy with a small training data and enables generalization of new process parameters via transfer learning, it faces the challenge of high computation cost in time-dependent problems due to the residual accumulation. To overcome this issue, the FEA-PINN framework integrates corrective FEA simulations during inference to enforce physical consistency and reduce error drift. A comparative analysis shows that FEA-PINN achieves equivalent accuracy to FEA while significantly reducing computational cost. The framework has been validated using the benchmark FEA data and demonstrated through single-track scanning in LPBF.",
      "authors": [
        "R. Sharma",
        "M. Raissi",
        "Y.B. Guo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20537",
        "HTML": "https://arxiv.org/html/2506.20537",
        "PDF": "https://arxiv.org/pdf/2506.20537"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:25:01 GMT",
          "size": "1812kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a framework for improving simulation efficiency in laser fusion processes using neural networks and finite element analysis, unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20543",
      "abstract": "This paper is about optimally controlling skill-based queueing systems such as data centers, cloud computing networks, and service systems. By means of a case study using a real-world data set, we investigate the practical implementation of a recently developed reinforcement learning algorithm for optimal customer routing. Our experiments show that the algorithm efficiently learns and adapts to changing environments and outperforms static benchmark policies, indicating its potential for live implementation. We also augment the real-world applicability of this algorithm by introducing a new heuristic routing rule to reduce delays. Moreover, we show that the algorithm can optimize for multiple objectives: next to payoff maximization, secondary objectives such as server load fairness and customer waiting time reduction can be incorporated. Tuning parameters are used for balancing inherent performance trade--offs. Lastly, we investigate the sensitivity to estimation errors and parameter tuning, providing valuable insights for implementing adaptive routing algorithms in complex real-world queueing systems.",
      "authors": [
        "Sanne van Kempen",
        "Jaron Sanders",
        "Fiona Sloothaak",
        "Maarten G. Wolf"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20543",
        "HTML": "https://arxiv.org/html/2506.20543",
        "PDF": "https://arxiv.org/pdf/2506.20543"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:36:43 GMT",
          "size": "16370kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Demonstration of effective UCB-based routing in skill-based queues on real-world data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with skill-based queueing systems and routing algorithms in data centers, without addressing LLM training data processing."
      }
    },
    {
      "id": "2506.20544",
      "abstract": "Recent advancements in large language models (LLMs) have shifted focus toward scaling inference-time compute, improving performance without retraining the model. A common approach is to sample multiple outputs in parallel, and select one of these as the final output. However, work to date has focused on English and a handful of domains such as math and code. In contrast, we are most interested in techniques that generalize across open-ended tasks, formally verifiable tasks, and across languages. In this work, we study how to robustly scale inference-time compute for open-ended generative tasks in a multilingual, multi-task setting.\n  Our findings show that both sampling strategy based on temperature variation and selection strategy must be adapted to account for diverse domains and varied language settings. We evaluate existing selection methods, revealing that strategies effective in English often fail to generalize across languages. We propose novel sampling and selection strategies specifically adapted for multilingual and multi-task inference scenarios, and show they yield notable gains across languages and tasks. In particular, our combined sampling and selection methods lead to an average +6.8 jump in win-rates for our 8B models on m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At larger scale, Command-A (111B model) equipped with our methods, shows +9.0 improvement in win-rates on the same benchmark with just five samples against single-sample decoding, a substantial increase at minimal cost. Our results underscore the need for language- and task-aware approaches to inference-time compute, aiming to democratize performance improvements in underrepresented languages.",
      "authors": [
        "Ammar Khairi",
        "Daniel D'souza",
        "Ye Shen",
        "Julia Kreutzer",
        "Sara Hooker"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20544",
        "HTML": "https://arxiv.org/html/2506.20544",
        "PDF": "https://arxiv.org/pdf/2506.20544"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:37:53 GMT",
          "size": "196kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on scaling inference-time compute for multilingual LLMs, rather than on data engineering or training-stage data processing for LLMs."
      }
    },
    {
      "id": "2506.20548",
      "abstract": "With the rapid advancement of deep learning, particularly through generative adversarial networks (GANs) and diffusion models (DMs), AI-generated images, or ``deepfakes\", have become nearly indistinguishable from real ones. These images are widely shared across Online Social Networks (OSNs), raising concerns about their misuse. Existing deepfake detection methods overlook the ``block effects\" introduced by compression in OSNs, which obscure deepfake artifacts, and primarily focus on raw images, rarely encountered in real-world scenarios. To address these challenges, we propose PLADA (Pay Less Attention to Deceptive Artifacts), a novel framework designed to tackle the lack of paired data and the ineffective use of compressed images. PLADA consists of two core modules: Block Effect Eraser (B2E), which uses a dual-stage attention mechanism to handle block effects, and Open Data Aggregation (ODA), which processes both paired and unpaired data to improve detection. Extensive experiments across 26 datasets demonstrate that PLADA achieves a remarkable balance in deepfake detection, outperforming SoTA methods in detecting deepfakes on OSNs, even with limited paired data and compression. More importantly, this work introduces the ``block effect\" as a critical factor in deepfake detection, providing a robust solution for open-world scenarios. Our code is available at https://github.com/ManyiLee/PLADA.",
      "authors": [
        "Manyi Li",
        "Renshuai Tao",
        "Yufan Liu",
        "Chuangchuang Tan",
        "Haotong Qin",
        "Bing Li",
        "Yunchao Wei",
        "Yao Zhao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20548",
        "HTML": "https://arxiv.org/html/2506.20548",
        "PDF": "https://arxiv.org/pdf/2506.20548"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:46:41 GMT",
          "size": "1612kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes a framework for detecting deepfakes on social networks, which does not relate to LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20550",
      "abstract": "Modern image-based object detection models, such as YOLOv7, primarily process individual frames independently, thus ignoring valuable temporal context naturally present in videos. Meanwhile, existing video-based detection methods often introduce complex temporal modules, significantly increasing model size and computational complexity. In practical applications such as surveillance and autonomous driving, transient challenges including motion blur, occlusions, and abrupt appearance changes can severely degrade single-frame detection performance. To address these issues, we propose a straightforward yet highly effective strategy: stacking multiple consecutive frames as input to a YOLO-based detector while supervising only the output corresponding to a single target frame. This approach leverages temporal information with minimal modifications to existing architectures, preserving simplicity, computational efficiency, and real-time inference capability. Extensive experiments on the challenging MOT20Det and our BOAT360 datasets demonstrate that our method improves detection robustness, especially for lightweight models, effectively narrowing the gap between compact and heavy detection networks. Additionally, we contribute the BOAT360 benchmark dataset, comprising annotated fisheye video sequences captured from a boat, to support future research in multi-frame video object detection in challenging real-world scenarios.",
      "authors": [
        "Yitong Quan",
        "Benjamin Kiefer",
        "Martin Messmer",
        "Andreas Zell"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20550",
        "HTML": "https://arxiv.org/html/2506.20550",
        "PDF": "https://arxiv.org/pdf/2506.20550"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:49:07 GMT",
          "size": "18300kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on enhancing object detection in videos using a multi-frame input strategy for YOLO detectors, without mentioning any aspects of LLM training data processing or related data engineering tasks."
      }
    },
    {
      "id": "2506.20553",
      "abstract": "Learning-based robotic systems demand rigorous validation to assure reliable performance, but extensive real-world testing is often prohibitively expensive, and if conducted may still yield insufficient data for high-confidence guarantees. In this work, we introduce a general estimation framework that leverages paired data across test platforms, e.g., paired simulation and real-world observations, to achieve better estimates of real-world metrics via the method of control variates. By incorporating cheap and abundant auxiliary measurements (for example, simulator outputs) as control variates for costly real-world samples, our method provably reduces the variance of Monte Carlo estimates and thus requires significantly fewer real-world samples to attain a specified confidence bound on the mean performance. We provide theoretical analysis characterizing the variance and sample-efficiency improvement, and demonstrate empirically in autonomous driving and quadruped robotics settings that our approach achieves high-probability bounds with markedly improved sample efficiency. Our technique can lower the real-world testing burden for validating the performance of the stack, thereby enabling more efficient and cost-effective experimental evaluation of robotic systems.",
      "authors": [
        "Rachel Luo",
        "Heng Yang",
        "Michael Watson",
        "Apoorva Sharma",
        "Sushant Veer",
        "Edward Schmerling",
        "Marco Pavone"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20553",
        "HTML": "https://arxiv.org/html/2506.20553",
        "PDF": "https://arxiv.org/pdf/2506.20553"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:51:07 GMT",
          "size": "719kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Leveraging Correlation Across Test Platforms for Variance-Reduced Metric Estimation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work introduces a method for estimating real-world metrics in robotic systems using control variates, not involving any contributions to LLM training data engineering or processing."
      }
    },
    {
      "id": "2506.20563",
      "abstract": "Vision Transformer has recently gained tremendous popularity in medical image segmentation task due to its superior capability in capturing long-range dependencies. However, transformer requires a large amount of labeled data to be effective, which hinders its applicability in annotation scarce semi-supervised learning scenario where only limited labeled data is available. State-of-the-art semi-supervised learning methods propose combinatorial CNN-Transformer learning to cross teach a transformer with a convolutional neural network, which achieves promising results. However, it remains a challenging task to effectively train the transformer with limited labeled data. In this paper, we propose an adversarial masked image modeling method to fully unleash the potential of transformer for semi-supervised medical image segmentation. The key challenge in semi-supervised learning with transformer lies in the lack of sufficient supervision signal. To this end, we propose to construct an auxiliary masked domain from original domain with masked image modeling and train the transformer to predict the entire segmentation mask with masked inputs to increase supervision signal. We leverage the original labels from labeled data and pseudo-labels from unlabeled data to learn the masked domain. To further benefit the original domain from masked domain, we provide a theoretical analysis of our method from a multi-domain learning perspective and devise a novel adversarial training loss to reduce the domain gap between the original and masked domain, which boosts semi-supervised learning performance. We also extend adversarial masked image modeling to CNN network. Extensive experiments on three public medical image segmentation datasets demonstrate the effectiveness of our method, where our method outperforms existing methods significantly. Our code is publicly available at https://github.com/zlheui/AdvMIM.",
      "authors": [
        "Lei Zhu",
        "Jun Zhou",
        "Rick Siow Mong Goh",
        "Yong Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20563",
        "HTML": "https://arxiv.org/html/2506.20563",
        "PDF": "https://arxiv.org/pdf/2506.20563"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:00:18 GMT",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on an adversarial masked image modeling method for semi-supervised medical image segmentation without addressing LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20567",
      "abstract": "In this work, we propose a division-and-summarization (DaS) framework for dense video captioning. After partitioning each untrimmed long video as multiple event proposals, where each event proposal consists of a set of short video segments, we extract visual feature (e.g., C3D feature) from each segment and use the existing image/video captioning approach to generate one sentence description for this segment. Considering that the generated sentences contain rich semantic descriptions about the whole event proposal, we formulate the dense video captioning task as a visual cue aided sentence summarization problem and propose a new two stage Long Short Term Memory (LSTM) approach equipped with a new hierarchical attention mechanism to summarize all generated sentences as one descriptive sentence with the aid of visual features. Specifically, the first-stage LSTM network takes all semantic words from the generated sentences and the visual features from all segments within one event proposal as the input, and acts as the encoder to effectively summarize both semantic and visual information related to this event proposal. The second-stage LSTM network takes the output from the first-stage LSTM network and the visual features from all video segments within one event proposal as the input, and acts as the decoder to generate one descriptive sentence for this event proposal. Our comprehensive experiments on the ActivityNet Captions dataset demonstrate the effectiveness of our newly proposed DaS framework for dense video captioning.",
      "authors": [
        "Zhiwang Zhang",
        "Dong Xu",
        "Wanli Ouyang",
        "Chuanqi Tan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20567",
        "HTML": "https://arxiv.org/html/2506.20567",
        "PDF": "https://arxiv.org/pdf/2506.20567"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:02:04 GMT",
          "size": "11986kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a framework for dense video captioning using existing image/video captioning approaches, with no connection to LLM training data processing."
      }
    },
    {
      "id": "2506.20574",
      "abstract": "Anomaly detection in multivariate time series is an important problem across various fields such as healthcare, financial services, manufacturing or physics detector monitoring. Accurately identifying when unexpected errors or faults occur is essential, yet challenging, due to the unknown nature of anomalies and the complex interdependencies between time series dimensions. In this paper, we investigate transformer-based approaches for time series anomaly detection, focusing on the recently proposed iTransformer architecture. Our contributions are fourfold: (i) we explore the application of the iTransformer to time series anomaly detection, and analyse the influence of key parameters such as window size, step size, and model dimensions on performance; (ii) we examine methods for extracting anomaly labels from multidimensional anomaly scores and discuss appropriate evaluation metrics for such labels; (iii) we study the impact of anomalous data present during training and assess the effectiveness of alternative loss functions in mitigating their influence; and (iv) we present a comprehensive comparison of several transformer-based models across a diverse set of datasets for time series anomaly detection.",
      "authors": [
        "Laura Boggia",
        "Rafael Teixeira de Lima",
        "Bogdan Malaescu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20574",
        "HTML": "https://arxiv.org/html/2506.20574",
        "PDF": "https://arxiv.org/pdf/2506.20574"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:08:22 GMT",
          "size": "788kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on anomaly detection in multivariate time series using transformer-based approaches. There is no mention of training data processing for LLMs, nor contributions related to LLM training data engineering."
      }
    },
    {
      "id": "2506.20575",
      "abstract": "Deep learning on graphs has shown remarkable success across numerous applications, including social networks, bio-physics, traffic networks, and recommendation systems. Regardless of their successes, current methods frequently depend on the assumption that training and testing data share the same distribution, a condition rarely met in real-world scenarios. While graph-transformer (GT) backbones have recently outperformed traditional message-passing neural networks (MPNNs) in multiple in-distribution (ID) benchmarks, their effectiveness under distribution shifts remains largely unexplored.\n  In this work, we address the challenge of out-of-distribution (OOD) generalization for graph neural networks, with a special focus on the impact of backbone architecture. We systematically evaluate GT and hybrid backbones in OOD settings and compare them to MPNNs. To do so, we adapt several leading domain generalization (DG) algorithms to work with GTs and assess their performance on a benchmark designed to test a variety of distribution shifts. Our results reveal that GT and hybrid GT-MPNN backbones consistently demonstrate stronger generalization ability compared to MPNNs, even without specialized DG algorithms.\n  Additionally, we propose a novel post-training analysis approach that compares the clustering structure of the entire ID and OOD test datasets, specifically examining domain alignment and class separation. Demonstrating its model-agnostic design, this approach not only provided meaningful insights into GT and MPNN backbones. It also shows promise for broader applicability to DG problems beyond graph learning, offering a deeper perspective on generalization abilities that goes beyond standard accuracy metrics. Together, our findings highlight the promise of graph-transformers for robust, real-world graph learning and set a new direction for future research in OOD generalization.",
      "authors": [
        "Itay Niv and Neta Rabin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20575",
        "HTML": "https://arxiv.org/html/2506.20575",
        "PDF": "https://arxiv.org/pdf/2506.20575"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:09:24 GMT",
          "size": "9814kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Exploring Graph-Transformer Out-of-Distribution Generalization Abilities",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with out-of-distribution generalization for graph neural networks and graph-transformer models, not with LLM data processing or engineering. The focus is on generalization abilities rather than training data creation or processing for LLMs."
      }
    },
    {
      "id": "2506.20576",
      "abstract": "Adversarial attacks, wherein slight inputs are carefully crafted to mislead intelligent models, have attracted increasing attention. However, a critical gap persists between theoretical advancements and practical application, particularly in structured data like network traffic, where interdependent features complicate effective adversarial manipulations. Moreover, ambiguity in current approaches restricts reproducibility and limits progress in this field. Hence, existing defenses often fail to handle evolving adversarial attacks. This paper proposes a novel approach for black-box adversarial attacks, that addresses these limitations. Unlike prior work, which often assumes system access or relies on repeated probing, our method strictly respect black-box constraints, reducing interaction to avoid detection and better reflect real-world scenarios. We present an adaptive feature selection strategy using change-point detection and causality analysis to identify and target sensitive features to perturbations. This lightweight design ensures low computational cost and high deployability. Our comprehensive experiments show the attack's effectiveness in evading detection with minimal interaction, enhancing its adaptability and applicability in real-world scenarios. By advancing the understanding of adversarial attacks in network traffic, this work lays a foundation for developing robust defenses.",
      "authors": [
        "Sabrine Ennaji",
        "Elhadj Benkhelifa",
        "Luigi V. Mancini"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20576",
        "HTML": "https://arxiv.org/html/2506.20576",
        "PDF": "https://arxiv.org/pdf/2506.20576"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:10:20 GMT",
          "size": "2276kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates adversarial attacks on network intrusion detection systems (NIDS) and does not address training data processing or engineering for LLMs."
      }
    },
    {
      "id": "2506.20579",
      "abstract": "This paper addresses the problem of collaborative navigation in an unknown environment, where two robots, referred to in the sequel as the Seeker and the Supporter, traverse the space simultaneously. The Supporter assists the Seeker by transmitting a compressed representation of its local map under bandwidth constraints to support the Seeker's path-planning task. We introduce a bit-rate metric based on the expected binary codeword length to quantify communication cost. Using this metric, we formulate the compression design problem as a rate-distortion optimization problem that determines when to communicate, which regions of the map should be included in the compressed representation, and at what resolution (i.e., quantization level) they should be encoded. Our formulation allows different map regions to be encoded at varying quantization levels based on their relevance to the Seeker's path-planning task. We demonstrate that the resulting optimization problem is convex, and admits a closed-form solution known in the information theory literature as reverse water-filling, enabling efficient, low-computation, and real-time implementation. Additionally, we show that the Seeker can infer the compression decisions of the Supporter independently, requiring only the encoded map content and not the encoding policy itself to be transmitted, thereby reducing communication overhead. Simulation results indicate that our method effectively constructs compressed, task-relevant map representations, both in content and resolution, that guide the Seeker's planning decisions even under tight bandwidth limitations.",
      "authors": [
        "Ali Reza Pedram",
        "Evangelos Psomiadis",
        "Dipankar Maity",
        "Panagiotis Tsiotras"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20579",
        "HTML": "https://arxiv.org/html/2506.20579",
        "PDF": "https://arxiv.org/pdf/2506.20579"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:14:17 GMT",
          "size": "1332kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Communication-Aware Map Compression for Online Path-Planning: A Rate-Distortion Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research deals with map compression for robot navigation, which is unrelated to any aspect of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20582",
      "abstract": "Identifiable causal representation learning seeks to uncover the true causal relationships underlying a data generation process. In medical imaging, this presents opportunities to improve the generalisability and robustness of task-specific latent features. This work introduces the concept of grouping observations to learn identifiable representations for disease classification in chest X-rays via an end-to-end framework. Our experiments demonstrate that these causal representations improve generalisability and robustness across multiple classification tasks when grouping is used to enforce invariance w.r.t race, sex, and imaging views.",
      "authors": [
        "Rajat Rasal",
        "Avinash Kori",
        "Ben Glocker"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20582",
        "HTML": "https://arxiv.org/html/2506.20582",
        "PDF": "https://arxiv.org/pdf/2506.20582"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:17:36 GMT",
          "size": "559kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Causal Representation Learning with Observational Grouping for CXR Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of this paper is on causal representation learning in medical imaging for chest X-rays. It does not discuss LLM training data engineering or processing."
      }
    },
    {
      "id": "2506.20583",
      "abstract": "Recently, dense video captioning has made attractive progress in detecting and captioning all events in a long untrimmed video. Despite promising results were achieved, most existing methods do not sufficiently explore the scene evolution within an event temporal proposal for captioning, and therefore perform less satisfactorily when the scenes and objects change over a relatively long proposal. To address this problem, we propose a graph-based partition-and-summarization (GPaS) framework for dense video captioning within two stages. For the ``partition\" stage, a whole event proposal is split into short video segments for captioning at a finer level. For the ``summarization\" stage, the generated sentences carrying rich description information for each segment are summarized into one sentence to describe the whole event. We particularly focus on the ``summarization\" stage, and propose a framework that effectively exploits the relationship between semantic words for summarization. We achieve this goal by treating semantic words as nodes in a graph and learning their interactions by coupling Graph Convolutional Network (GCN) and Long Short Term Memory (LSTM), with the aid of visual cues. Two schemes of GCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN and LSTM. The effectiveness of our approach is demonstrated via an extensive comparison with the state-of-the-arts methods on the two benchmarks ActivityNet Captions dataset and YouCook II dataset.",
      "authors": [
        "Zhiwang Zhang",
        "Dong Xu",
        "Wanli Ouyang",
        "Luping Zhou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20583",
        "HTML": "https://arxiv.org/html/2506.20583",
        "PDF": "https://arxiv.org/pdf/2506.20583"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:23:43 GMT",
          "size": "13762kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Dense Video Captioning using Graph-based Sentence Summarization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on dense video captioning techniques using graph-based summarization methods and does not involve the processing of training data specifically for LLMs."
      }
    },
    {
      "id": "2506.20584",
      "abstract": "The most popular graph indices for vector search use principles from computational geometry to build the graph. Hence, their formal graph navigability guarantees are only valid in Euclidean space. In this work, we show that machine learning can be used to build graph indices for vector search in metric and non-metric vector spaces (e.g., for inner product similarity). From this novel perspective, we introduce the Support Vector Graph (SVG), a new type of graph index that leverages kernel methods to establish the graph connectivity and that comes with formal navigability guarantees valid in metric and non-metric vector spaces. In addition, we interpret the most popular graph indices, including HNSW and DiskANN, as particular specializations of SVG and show that new indices can be derived from the principles behind this specialization. Finally, we propose SVG-L0 that incorporates an $\\ell_0$ sparsity constraint into the SVG kernel method to build graphs with a bounded out-degree. This yields a principled way of implementing this practical requirement, in contrast to the traditional heuristic of simply truncating the out edges of each node. Additionally, we show that SVG-L0 has a self-tuning property that avoids the heuristic of using a set of candidates to find the out-edges of each node and that keeps its computational complexity in check.",
      "authors": [
        "Mariano Tepper and Ted Willke"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20584",
        "HTML": "https://arxiv.org/html/2506.20584",
        "PDF": "https://arxiv.org/pdf/2506.20584"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:24:55 GMT",
          "size": "9224kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The kernel of graph indices for vector search",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses using machine learning methods to build graph indices for vector search, with no mention of LLM training data processing or any related data engineering aspects."
      }
    },
    {
      "id": "2506.20585",
      "abstract": "Mobile Crowd-Sensing (MCS) enables users with personal mobile devices (PMDs) to gain information on their surroundings. Users collect and contribute data on different phenomena using their PMD sensors, and the MCS system processes this data to extract valuable information for end users. Navigation MCS-based applications (N-MCS) are prevalent and important for transportation: users share their location and speed while driving and, in return, find efficient routes to their destinations. However, N-MCS are currently vulnerable to malicious contributors, often termed Sybils: submitting falsified data, seemingly from many devices that are not truly present on target roads, falsely reporting congestion when there is none, thus changing the road status the N-MCS infers. The attack effect is that the N-MCS returns suboptimal routes to users, causing late arrival and, overall, deteriorating road traffic flow. We investigate exactly the impact of Sybil-based attacks on N-MCS: we design an N-MCS system that offers efficient routing on top of the vehicular simulator SUMO, using the InTAS road network as our scenario. We design experiments attacking an individual N-MCS user as well as a larger population of users, selecting the adversary targets based on graph-theoretical arguments. Our experiments show that the resources required for a successful attack depend on the location of the attack (i.e., the surrounding road network and traffic) and the extent of Sybil contributed data for the targeted road(s). We demonstrate that Sybil attacks can alter the route of N-MCS users, increasing average travel time by 20% with Sybils 3% of the N-MCS user population.",
      "authors": [
        "Alexander S\\\"oderh\\\"all and Zahra Alimadadi and Panos Papadimitratos"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20585",
        "HTML": "https://arxiv.org/html/2506.20585",
        "PDF": "https://arxiv.org/pdf/2506.20585"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:26:01 GMT",
          "size": "4796kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the Impact of Sybil-based Attacks on Mobile Crowdsensing for Transportation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on the impact of Sybil-based attacks on mobile crowdsensing systems for transportation, not on training data processing for LLMs."
      }
    },
    {
      "id": "2506.20586",
      "abstract": "Accurate distance estimation is a fundamental challenge in robotic perception, particularly in omnidirectional imaging, where traditional geometric methods struggle with lens distortions and environmental variability. In this work, we propose a neural network-based approach for monocular distance estimation using a single 360{\\deg} fisheye lens camera. Unlike classical trigonometric techniques that rely on precise lens calibration, our method directly learns and infers the distance of objects from raw omnidirectional inputs, offering greater robustness and adaptability across diverse conditions. We evaluate our approach on three 360{\\deg} datasets (LOAF, ULM360, and a newly captured dataset Boat360), each representing distinct environmental and sensor setups. Our experimental results demonstrate that the proposed learning-based model outperforms traditional geometry-based methods and other learning baselines in both accuracy and robustness. These findings highlight the potential of deep learning for real-time omnidirectional distance estimation, making our approach particularly well-suited for low-cost applications in robotics, autonomous navigation, and surveillance.",
      "authors": [
        "Yitong Quan",
        "Benjamin Kiefer",
        "Martin Messmer",
        "Andreas Zell"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20586",
        "HTML": "https://arxiv.org/html/2506.20586",
        "PDF": "https://arxiv.org/pdf/2506.20586"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:26:55 GMT",
          "size": "9377kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Learning-Based Distance Estimation for 360{\\deg} Single-Sensor Setups",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a neural network-based approach to distance estimation using 360\u00b0 fisheye camera data, unrelated to the collection or processing of LLM training data."
      }
    },
    {
      "id": "2506.20588",
      "abstract": "The increasing ubiquity of video content and the corresponding demand for efficient access to meaningful information have elevated video summarization and video highlights as a vital research area. However, many state-of-the-art methods depend heavily either on supervised annotations or on attention-based models, which are computationally expensive and brittle in the face of distribution shifts that hinder cross-domain applicability across datasets. We introduce a pioneering self-supervised video summarization model that captures both spatial and temporal dependencies without the overhead of attention, RNNs, or transformers. Our framework integrates a novel set of Markov process-driven loss metrics and a two-stage self supervised learning paradigm that ensures both performance and efficiency. Our approach achieves state-of-the-art performance on the SUMME and TVSUM datasets, outperforming all existing unsupervised methods. It also rivals the best supervised models, demonstrating the potential for efficient, annotation-free architectures. This paves the way for more generalizable video summarization techniques and challenges the prevailing reliance on complex architectures.",
      "authors": [
        "Pritam Mishra",
        "Coloma Ballester",
        "Dimosthenis Karatzas"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20588",
        "HTML": "https://arxiv.org/html/2506.20588",
        "PDF": "https://arxiv.org/pdf/2506.20588"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:27:38 GMT",
          "size": "2559kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a self-supervised video summarization framework and does not address LLM training data processing or any tasks directly related to LLM data engineering."
      }
    },
    {
      "id": "2506.20590",
      "abstract": "Interactive 3D scene generation from a single image has gained significant attention due to its potential to create immersive virtual worlds. However, a key challenge in current 3D generation methods is the limited explorability, which cannot render high-quality images during larger maneuvers beyond the original viewpoint, particularly when attempting to move forward into unseen areas. To address this challenge, we propose WonderFree, the first model that enables users to interactively generate 3D worlds with the freedom to explore from arbitrary angles and directions. Specifically, we decouple this challenge into two key subproblems: novel view quality, which addresses visual artifacts and floating issues in novel views, and cross-view consistency, which ensures spatial consistency across different viewpoints. To enhance rendering quality in novel views, we introduce WorldRestorer, a data-driven video restoration model designed to eliminate floaters and artifacts. In addition, a data collection pipeline is presented to automatically gather training data for WorldRestorer, ensuring it can handle scenes with varying styles needed for 3D scene generation. Furthermore, to improve cross-view consistency, we propose ConsistView, a multi-view joint restoration mechanism that simultaneously restores multiple perspectives while maintaining spatiotemporal coherence. Experimental results demonstrate that WonderFree not only enhances rendering quality across diverse viewpoints but also significantly improves global coherence and consistency. These improvements are confirmed by CLIP-based metrics and a user study showing a 77.20% preference for WonderFree over WonderWorld enabling a seamless and immersive 3D exploration experience. The code, model, and data will be publicly available.",
      "authors": [
        "Chaojun Ni",
        "Jie Li",
        "Haoyun Li",
        "Hengyu Liu",
        "Xiaofeng Wang",
        "Zheng Zhu",
        "Guosheng Zhao",
        "Boyuan Wang",
        "Chenxin Li",
        "Guan Huang",
        "Wenjun Mei"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20590",
        "HTML": "https://arxiv.org/html/2506.20590",
        "PDF": "https://arxiv.org/pdf/2506.20590"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:28:40 GMT",
          "size": "12314kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents WonderFree for 3D scene exploration, which involves rendering quality and cross-view consistency improvements, and does not address LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20599",
      "abstract": "The rapid advancement of generative artificial intelligence is producing fake remote sensing imagery (RSI) that is increasingly difficult to detect, potentially leading to erroneous intelligence, fake news, and even conspiracy theories. Existing forgery detection methods typically rely on single visual features to capture predefined artifacts, such as spatial-domain cues to detect forged objects like roads or buildings in RSI, or frequency-domain features to identify artifacts from up-sampling operations in adversarial generative networks (GANs). However, the nature of artifacts can significantly differ depending on geographic terrain, land cover types, or specific features within the RSI. Moreover, these complex artifacts evolve as generative models become more sophisticated. In short, over-reliance on a single visual cue makes existing forgery detectors struggle to generalize across diverse remote sensing data. This paper proposed a novel forgery detection framework called SFNet, designed to identify fake images in diverse remote sensing data by leveraging spatial and frequency domain features. Specifically, to obtain rich and comprehensive visual information, SFNet employs two independent feature extractors to capture spatial and frequency domain features from input RSIs. To fully utilize the complementary domain features, the domain feature mapping module and the hybrid domain feature refinement module(CBAM attention) of SFNet are designed to successively align and fuse the multi-domain features while suppressing redundant information. Experiments on three datasets show that SFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art RS forgery detection methods and exhibits robust generalization capabilities. The code is available at https://github.com/GeoX-Lab/RSTI/tree/main/SFNet.",
      "authors": [
        "Ji Qi",
        "Xinchang Zhang",
        "Dingqi Ye",
        "Yongjia Ruan",
        "Xin Guo",
        "Shaowen Wang",
        "Haifeng Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20599",
        "HTML": "https://arxiv.org/html/2506.20599",
        "PDF": "https://arxiv.org/pdf/2506.20599"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:38:37 GMT",
          "size": "5139kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "SFNet is focused on image forgery detection using spatial and frequency-domain features in remote sensing imagery, which is unrelated to the data engineering processes for LLM training data."
      }
    },
    {
      "id": "2506.20600",
      "abstract": "We introduce CogGen, a learner-centered AI architecture that transforms programming videos into interactive, adaptive learning experiences by integrating student modeling with generative AI tutoring based on the Cognitive Apprenticeship framework. The architecture consists of three components: (1) video segmentation by learning goals, (2) a conversational tutoring engine applying Cognitive Apprenticeship strategies, and (3) a student model using Bayesian Knowledge Tracing to adapt instruction. Our technical evaluation demonstrates effective video segmentation accuracy and strong pedagogical alignment across knowledge, method, action, and interaction layers. Ablation studies confirm the necessity of each component in generating effective guidance. This work advances AI-powered tutoring by bridging structured student modeling with interactive AI conversations, offering a scalable approach to enhancing video-based programming education.",
      "authors": [
        "Wengxi Li",
        "Roy Pea",
        "Nick Haber",
        "Hari Subramonyam"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20600",
        "HTML": "https://arxiv.org/html/2506.20600",
        "PDF": "https://arxiv.org/pdf/2506.20600"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:39:05 GMT",
          "size": "695kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a learner-centered AI architecture for transforming programming videos into interactive learning experiences, with no emphasis on LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20601",
      "abstract": "Traditionally, 3D scene synthesis requires expert knowledge and significant manual effort. Automating this process could greatly benefit fields such as architectural design, robotics simulation, virtual reality, and gaming. Recent approaches to 3D scene synthesis often rely on the commonsense reasoning of large language models (LLMs) or strong visual priors of modern image generation models. However, current LLMs demonstrate limited 3D spatial reasoning ability, which restricts their ability to generate realistic and coherent 3D scenes. Meanwhile, image generation-based methods often suffer from constraints in viewpoint selection and multi-view inconsistencies. In this work, we present Video Perception models for 3D Scene synthesis (VIPScene), a novel framework that exploits the encoded commonsense knowledge of the 3D physical world in video generation models to ensure coherent scene layouts and consistent object placements across views. VIPScene accepts both text and image prompts and seamlessly integrates video generation, feedforward 3D reconstruction, and open-vocabulary perception models to semantically and geometrically analyze each object in a scene. This enables flexible scene synthesis with high realism and structural consistency. For more precise analysis, we further introduce First-Person View Score (FPVScore) for coherence and plausibility evaluation, utilizing continuous first-person perspective to capitalize on the reasoning ability of multimodal large language models. Extensive experiments show that VIPScene significantly outperforms existing methods and generalizes well across diverse scenarios. The code will be released.",
      "authors": [
        "Rui Huang",
        "Guangyao Zhai",
        "Zuria Bauer",
        "Marc Pollefeys",
        "Federico Tombari",
        "Leonidas Guibas",
        "Gao Huang",
        "Francis Engelmann"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20601",
        "HTML": "https://arxiv.org/html/2506.20601",
        "PDF": "https://arxiv.org/pdf/2506.20601"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:40:17 GMT",
          "size": "12151kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Video Perception Models for 3D Scene Synthesis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses video perception models for 3D scene synthesis and does not address LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20606",
      "abstract": "Agents based on Large Language Models (LLMs) have demonstrated strong capabilities across a wide range of tasks. However, deploying LLM-based agents in high-stakes domains comes with significant safety and ethical risks. Unethical behavior by these agents can directly result in serious real-world consequences, including physical harm and financial loss. To efficiently steer the ethical behavior of agents, we frame agent behavior steering as a model editing task, which we term Behavior Editing. Model editing is an emerging area of research that enables precise and efficient modifications to LLMs while preserving their overall capabilities. To systematically study and evaluate this approach, we introduce BehaviorBench, a multi-tier benchmark grounded in psychological moral theories. This benchmark supports both the evaluation and editing of agent behaviors across a variety of scenarios, with each tier introducing more complex and ambiguous scenarios. We first demonstrate that Behavior Editing can dynamically steer agents toward the target behavior within specific scenarios. Moreover, Behavior Editing enables not only scenario-specific local adjustments but also more extensive shifts in an agent's global moral alignment. We demonstrate that Behavior Editing can be used to promote ethical and benevolent behavior or, conversely, to induce harmful or malicious behavior. Through comprehensive evaluations on agents based on frontier LLMs, BehaviorBench shows the effectiveness of Behavior Editing across different models and scenarios. Our findings offer key insights into a new paradigm for steering agent behavior, highlighting both the promise and perils of Behavior Editing.",
      "authors": [
        "Baixiang Huang",
        "Zhen Tan",
        "Haoran Wang",
        "Zijie Liu",
        "Dawei Li",
        "Ali Payani",
        "Huan Liu",
        "Tianlong Chen",
        "Kai Shu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20606",
        "HTML": "https://arxiv.org/html/2506.20606",
        "PDF": "https://arxiv.org/pdf/2506.20606"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:51:51 GMT",
          "size": "217kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses model editing for steering agent ethical behavior but lacks a focus on LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20607",
      "abstract": "Hamiltonian systems describe a broad class of dynamical systems governed by Hamiltonian functions, which encode the total energy and dictate the evolution of the system. Data-driven approaches, such as symbolic regression and neural network-based methods, provide a means to learn the governing equations of dynamical systems directly from observational data of Hamiltonian systems. However, these methods often struggle to accurately capture complex Hamiltonian functions while preserving energy conservation. To overcome this limitation, we propose the Finite Expression Method for learning Hamiltonian Systems (H-FEX), a symbolic learning method that introduces novel interaction nodes designed to capture intricate interaction terms effectively. Our experiments, including those on highly stiff dynamical systems, demonstrate that H-FEX can recover Hamiltonian functions of complex systems that accurately capture system dynamics and preserve energy over long time horizons. These findings highlight the potential of H-FEX as a powerful framework for discovering closed-form expressions of complex dynamical systems.",
      "authors": [
        "Jasen Lai",
        "Senwei Liang and Chunmei Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20607",
        "HTML": "https://arxiv.org/html/2506.20607",
        "PDF": "https://arxiv.org/pdf/2506.20607"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:53:01 GMT",
          "size": "436kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "H-FEX: A Symbolic Learning Method for Hamiltonian Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a symbolic learning method for Hamiltonian systems, without any mention of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20609",
      "abstract": "The escalating rates of gun-related violence and mass shootings represent a significant threat to public safety. Timely and accurate information for law enforcement agencies is crucial in mitigating these incidents. Current commercial gunshot detection systems, while effective, often come with prohibitive costs. This research explores a cost-effective alternative by leveraging acoustic analysis of gunshot recordings, potentially obtainable from ubiquitous devices like cell phones, to not only detect gunshots but also classify the type of firearm used. This paper details a study on deciphering gun type hierarchies using a curated dataset of 3459 recordings. We investigate the fundamental acoustic characteristics of gunshots, including muzzle blasts and shockwaves, which vary based on firearm type, ammunition, and shooting direction. We propose and evaluate machine learning frameworks, including Support Vector Machines (SVMs) as a baseline and a more advanced Convolutional Neural Network (CNN) architecture for joint gunshot detection and gun type classification. Results indicate that our deep learning approach achieves a mean average precision (mAP) of 0.58 on clean labeled data, outperforming the SVM baseline (mAP 0.39). Challenges related to data quality, environmental noise, and the generalization capabilities when using noisy web-sourced data (mAP 0.35) are also discussed. The long-term vision is to develop a highly accurate, real-time system deployable on common recording devices, significantly reducing detection costs and providing critical intelligence to first responders.",
      "authors": [
        "Ankit Shah",
        "Rita Singh",
        "Bhiksha Raj",
        "Alexander Hauptmann"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20609",
        "HTML": "https://arxiv.org/html/2506.20609",
        "PDF": "https://arxiv.org/pdf/2506.20609"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:00:21 GMT",
          "size": "638kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot Recordings",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on acoustic analysis and classification of gunshot recordings, using machine learning methods for gun type detection. It does not address any processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20616",
      "abstract": "Humans possess a unique ability to perceive meaningful patterns in ambiguous stimuli, a cognitive phenomenon known as pareidolia. This paper introduces Shape2Animal framework to mimics this imaginative capacity by reinterpreting natural object silhouettes, such as clouds, stones, or flames, as plausible animal forms. Our automated framework first performs open-vocabulary segmentation to extract object silhouette and interprets semantically appropriate animal concepts using vision-language models. It then synthesizes an animal image that conforms to the input shape, leveraging text-to-image diffusion model and seamlessly blends it into the original scene to generate visually coherent and spatially consistent compositions. We evaluated Shape2Animal on a diverse set of real-world inputs, demonstrating its robustness and creative potential. Our Shape2Animal can offer new opportunities for visual storytelling, educational content, digital art, and interactive media design. Our project page is here: https://shape2image.github.io",
      "authors": [
        "Quoc-Duy Tran",
        "Anh-Tuan Vo",
        "Dinh-Khoi Vo",
        "Tam V. Nguyen",
        "Minh-Triet Tran and Trung-Nghia Le"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20616",
        "HTML": "https://arxiv.org/html/2506.20616",
        "PDF": "https://arxiv.org/pdf/2506.20616"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:04:08 GMT",
          "size": "5304kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Shape2Animal: Creative Animal Generation from Natural Silhouettes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research presents a creative image generation framework for interpreting silhouettes as animal forms. The study is centered around vision-language models and image synthesis, not LLM training data aspects."
      }
    },
    {
      "id": "2506.20623",
      "abstract": "Closed-loop learning is the process of repeatedly estimating a model from data generated from the model itself. It is receiving great attention due to the possibility that large neural network models may, in the future, be primarily trained with data generated by artificial neural networks themselves. We study this process for models that belong to exponential families, deriving equations of motions that govern the dynamics of the parameters. We show that maximum likelihood estimation of the parameters endows sufficient statistics with the martingale property and that as a result the process converges to absorbing states that amplify initial biases present in the data. However, we show that this outcome may be prevented by polluting the data with an infinitesimal fraction of data points generated from a fixed model, by relying on maximum a posteriori estimation or by introducing regularisation. Furthermore, we show that the asymptotic behavior of the dynamics is not reparametrisation invariant.",
      "authors": [
        "Fariba Jangjoo",
        "Matteo Marsili",
        "Yasser Roudi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20623",
        "HTML": "https://arxiv.org/html/2506.20623",
        "PDF": "https://arxiv.org/pdf/2506.20623"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:12:22 GMT",
          "size": "1220kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study investigates closed-loop learning in the context of exponential families, focusing on parameter dynamics and estimation methods. There is no direct connection to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20624",
      "abstract": "Quantum computing has transformative computational power to make classically intractable computing feasible. As the algorithms that achieve practical quantum advantage are beyond manual tuning, quantum circuit optimization has become extremely important and integrated into today's quantum software stack. This paper focuses on a critical type of quantum circuit optimization -- phase-polynomial optimization. Phase polynomials represents a class of building-block circuits that appear frequently in quantum modular exponentials (the most time-consuming component in Shor's factoring algorithm), in quantum approximation optimization algorithms (QAOA), and in Hamiltonian simulations. Compared to prior work on phase polynomials, we focus more on the impact of phase polynomial synthesis in the context of whole-circuit optimization, from single-block phase polynomials to multiple block phase polynomials, from greedy equivalent sub-circuit replacement strategies to a systematic parity matrix optimization approach, and from hardware-oblivious logical circuit optimization to hardware-friendly logical circuit optimization. We also provide a utility of our phase polynomial optimization framework to generate hardware-friendly building blocks. Our experiments demonstrate improvements of up to 50%-with an average total gate reduction of 34.92%-and reductions in the CNOT gate count of up to 48.57%, averaging 28.53%, for logical circuits. Additionally, for physical circuits, we achieve up to 47.65% CNOT gate reduction with an average reduction of 25.47% across a representative set of important benchmarks.",
      "authors": [
        "Zihan Chen",
        "Henry Chen",
        "Yuwei Jin",
        "Minghao Guo",
        "Enhyeok Jang",
        "Jiakang Li",
        "Caitlin Chan",
        "Won Woo Ro",
        "Eddy Z. Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20624",
        "HTML": "https://arxiv.org/html/2506.20624",
        "PDF": "https://arxiv.org/pdf/2506.20624"
      },
      "subjects": [
        "Programming Languages (cs.PL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:13:16 GMT",
          "size": "6203kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PhasePoly: An Optimization Framework forPhase Polynomials in Quantum Circuits",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on quantum circuit optimization, specifically phase-polynomial optimization, which is unrelated to processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20626",
      "abstract": "This study addresses the optimisation of task allocation for Unmanned Aerial Vehicles (UAVs) within industrial monitoring missions. The proposed methodology integrates a Genetic Algorithms (GA) with a 2-Opt local search technique to obtain a high-quality solution. Our approach was experimentally validated in an industrial zone to demonstrate its efficacy in real-world scenarios. Also, a Hardware-in-the-loop (HIL) simulator for the UAVs team is introduced. Moreover, insights about the correlation between the theoretical cost function and the actual battery consumption and time of flight are deeply analysed. Results show that the considered costs for the optimisation part of the problem closely correlate with real-world data, confirming the practicality of the proposed approach.",
      "authors": [
        "Hamza Chakraa",
        "Fran\\c{c}ois Gu\\'erin",
        "Edouard Leclercq and Dimitri Lefebvre"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20626",
        "HTML": "https://arxiv.org/html/2506.20626",
        "PDF": "https://arxiv.org/pdf/2506.20626"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:18:41 GMT",
          "size": "553kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Task Allocation of UAVs for Monitoring Missions via Hardware-in-the-Loop Simulation and Experimental Validation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses the optimization of task allocation for UAVs, which is not related to the processing or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20628",
      "abstract": "In this paper we investigate identifiability and maximum likelihood estimation for direct system identification of networks of dynamical systems. We provide necessary and sufficient conditions for network identifiability in terms of Gr\\\"obner bases. We show that the maximum likelihood approach is both consistent and efficient, which is in contrast to existing prediction error approaches. Moreover, our approach has wider applicability, i.e., it is applicable whenever network identifiability holds. Finally, we show that we can formulate the maximum likelihood problem without the use of a predictor, which is the key to numerically being able to solve it efficiently.",
      "authors": [
        "Anders Hansson",
        "Jo\\~ao Victor Galv\\~ao da Mata",
        "Martin S. Andersen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20628",
        "HTML": "https://arxiv.org/html/2506.20628",
        "PDF": "https://arxiv.org/pdf/2506.20628"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:22:18 GMT",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Identifiability and Maximum Likelihood Estimation for System Identification of Networks of Dynamical Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with identifiability and maximum likelihood estimation for networks of dynamical systems, not involving LLM training data processing."
      }
    },
    {
      "id": "2506.20636",
      "abstract": "Accurate extrinsic calibration between LiDAR and camera sensors is important for reliable perception in autonomous systems. In this paper, we present a novel multi-objective optimization framework that jointly minimizes the geometric alignment error and computational cost associated with camera-LiDAR calibration. We optimize two objectives: (1) error between projected LiDAR points and ground-truth image edges, and (2) a composite metric for computational cost reflecting runtime and resource usage. Using the NSGA-II \\cite{deb2002nsga2} evolutionary algorithm, we explore the parameter space defined by 6-DoF transformations and point sampling rates, yielding a well-characterized Pareto frontier that exposes trade-offs between calibration fidelity and resource efficiency. Evaluations are conducted on the KITTI dataset using its ground-truth extrinsic parameters for validation, with results verified through both multi-objective and constrained single-objective baselines. Compared to existing gradient-based and learned calibration methods, our approach demonstrates interpretable, tunable performance with lower deployment overhead. Pareto-optimal configurations are further analyzed for parameter sensitivity and innovation insights. A preference-based decision-making strategy selects solutions from the Pareto knee region to suit the constraints of the embedded system. The robustness of calibration is tested across variable edge-intensity weighting schemes, highlighting optimal balance points. Although real-time deployment on embedded platforms is deferred to future work, this framework establishes a scalable and transparent method for calibration under realistic misalignment and resource-limited conditions, critical for long-term autonomy, particularly in SAE L3+ vehicles receiving OTA updates.",
      "authors": [
        "Venkat Karramreddy",
        "Rangarajan Ramanujam"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20636",
        "HTML": "https://arxiv.org/html/2506.20636",
        "PDF": "https://arxiv.org/pdf/2506.20636"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:31:15 GMT",
          "size": "6485kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Computationally Aware Multi Objective Framework for Camera LiDAR Calibration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on camera-LiDAR calibration for autonomous systems, which is unrelated to training data processing for large language models."
      }
    },
    {
      "id": "2506.20638",
      "abstract": "Obtaining a better knowledge of the current state and behavior of objects orbiting Earth has proven to be essential for a range of applications such as active debris removal, in-orbit maintenance, or anomaly detection. 3D models represent a valuable source of information in the field of Space Situational Awareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to perform 3D reconstruction of non-cooperative space objects from simulated images. This scenario is challenging for NeRF models due to unusual camera characteristics and environmental conditions : mono-chromatic images, unknown object orientation, limited viewing angles, absence of diffuse lighting etc. In this work we focus primarly on the joint optimization of camera poses alongside the NeRF. Our experimental results show that the most accurate 3D reconstruction is achieved when training with successive images one-by-one. We estimate camera poses by optimizing an uniform rotation and use regularization to prevent successive poses from being too far apart.",
      "authors": [
        "Cl\\'ement Forray and Pauline Delporte and Nicolas Delaygue and Florence Genin and Dawa Derksen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20638",
        "HTML": "https://arxiv.org/html/2506.20638",
        "PDF": "https://arxiv.org/pdf/2506.20638"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:33:49 GMT",
          "size": "3180kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses 3D neural reconstruction using neural radiance fields for space objects, without mentioning LLM training data processing tasks."
      }
    },
    {
      "id": "2506.20640",
      "abstract": "Large language model-based machine learning (ML) agents have shown great promise in automating ML research. However, existing agents typically operate in isolation on a given research problem, without engaging with the broader research community, where human researchers often gain insights and contribute by sharing knowledge. To bridge this gap, we introduce MLE-Live, a live evaluation framework designed to assess an agent's ability to communicate with and leverage collective knowledge from a simulated Kaggle research community. Building on this framework, we propose CoMind, a novel agent that excels at exchanging insights and developing novel solutions within a community context. CoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2% human competitors on average across four ongoing Kaggle competitions. Our code is released at https://github.com/comind-ml/CoMind.",
      "authors": [
        "Sijie Li",
        "Weiwei Sun",
        "Shanda Li",
        "Ameet Talwalkar",
        "Yiming Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20640",
        "HTML": "https://arxiv.org/html/2506.20640",
        "PDF": "https://arxiv.org/pdf/2506.20640"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:36:02 GMT",
          "size": "550kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Towards Community-Driven Agents for Machine Learning Engineering",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research introduces an agent for machine learning competitions and does not address any LLM training data processing techniques or methodologies."
      }
    },
    {
      "id": "2506.20642",
      "abstract": "Large language models (LLMs) excel at reasoning-only tasks, but struggle when reasoning must be tightly coupled with retrieval, as in multi-hop question answering. To overcome these limitations, we introduce a prompting strategy that first decomposes a complex question into smaller steps, then dynamically constructs a database of facts using LLMs, and finally pieces these facts together to solve the question. We show how this three-stage strategy, which we call Memento, can boost the performance of existing prompting strategies across diverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the performance of chain-of-thought (CoT) when all information is provided in context. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento improves over vanilla CoT-RAG by more than 20 F1 percentage points and over the multi-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the challenging MuSiQue dataset, Memento improves ReAct by more than 3 F1 percentage points, demonstrating its utility in agentic settings.",
      "authors": [
        "Chao Wan",
        "Albert Gong",
        "Mihir Mishra",
        "Carl-Leander Henneking",
        "Claas Beger",
        "Kilian Q. Weinberger"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20642",
        "HTML": "https://arxiv.org/html/2506.20642",
        "PDF": "https://arxiv.org/pdf/2506.20642"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:37:59 GMT",
          "size": "1748kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Memento: Note-Taking for Your Future Self",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Memento is a strategy for multi-hop question answering that enhances retrieval and reasoning, but it does not contribute to LLM training data processing."
      }
    },
    {
      "id": "2506.20644",
      "abstract": "As privacy protection gains increasing importance, more models are being trained on edge devices and subsequently merged into the central server through Federated Learning (FL). However, current research overlooks the impact of network topology, physical distance, and data heterogeneity on edge devices, leading to issues such as increased latency and degraded model performance. To address these issues, we propose a new federated learning scheme on edge devices that called Federated Learning with Encrypted Data Sharing(FedEDS). FedEDS uses the client model and the model's stochastic layer to train the data encryptor. The data encryptor generates encrypted data and shares it with other clients. The client uses the corresponding client's stochastic layer and encrypted data to train and adjust the local model. FedEDS uses the client's local private data and encrypted shared data from other clients to train the model. This approach accelerates the convergence speed of federated learning training and mitigates the negative impact of data heterogeneity, making it suitable for application services deployed on edge devices requiring rapid convergence. Experiments results show the efficacy of FedEDS in promoting model performance.",
      "authors": [
        "Hangyu Li and Hongyue Wu and Guodong Fan and Zhen Zhang and Shizhan Chen and Zhiyong Feng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20644",
        "HTML": "https://arxiv.org/html/2506.20644",
        "PDF": "https://arxiv.org/pdf/2506.20644"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:40:54 GMT",
          "size": "1352kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a federated learning approach using encrypted data sharing and does not discuss LLM training data processing or engineering tasks relevant to LLMs."
      }
    },
    {
      "id": "2506.20649",
      "abstract": "Microscopy image analysis is fundamental for different applications, from diagnosis to synthetic engineering and environmental monitoring. Modern acquisition systems have granted the possibility to acquire an escalating amount of images, requiring a consequent development of a large collection of deep learning-based automatic image analysis methods. Although deep neural networks have demonstrated great performance in this field, interpretability, an essential requirement for microscopy image analysis, remains an open challenge.\n  This work proposes a Disentangled Representation Learning (DRL) methodology to enhance model interpretability for microscopy image classification. Exploiting benchmark datasets from three different microscopic image domains (plankton, yeast vacuoles, and human cells), we show how a DRL framework, based on transferring a representation learnt from synthetic data, can provide a good trade-off between accuracy and interpretability in this domain.",
      "authors": [
        "Jacopo Dapueto",
        "Vito Paolo Pastore",
        "Nicoletta Noceti",
        "Francesca Odone"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20649",
        "HTML": "https://arxiv.org/html/2506.20649",
        "PDF": "https://arxiv.org/pdf/2506.20649"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:44:37 GMT",
          "size": "7503kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Disentangled representations of microscopy images",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses disentangled representation learning for microscopy images, with no relevance to LLM training data or related data processing methods."
      }
    },
    {
      "id": "2506.20650",
      "abstract": "The problem of learning to defer with multiple experts consists of optimally assigning input instances to experts, balancing the trade-off between their accuracy and computational cost. This is a critical challenge in natural language generation, but also in other fields such as image processing, and medical diagnostics. Recent studies have proposed surrogate loss functions to optimize deferral, but challenges remain in ensuring their consistency properties. This paper introduces novel surrogate loss functions and efficient algorithms with strong theoretical learning guarantees. We address open questions regarding realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for both single-stage (jointly learning predictor and deferral function) and two-stage (learning only the deferral function with a fixed expert) learning scenarios. For single-stage deferral, we introduce a family of new realizable $H$-consistent surrogate losses and further prove $H$-consistency for a selected member. For two-stage deferral, we derive new surrogate losses that achieve realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for the two-expert scenario and, under natural assumptions, multiple-expert scenario. Additionally, we provide enhanced theoretical guarantees under low-noise assumptions for both scenarios. Finally, we report the results of experiments using our proposed surrogate losses, comparing their performance against existing baselines.",
      "authors": [
        "Anqi Mao",
        "Mehryar Mohri",
        "Yutao Zhong"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20650",
        "HTML": "https://arxiv.org/html/2506.20650",
        "PDF": "https://arxiv.org/pdf/2506.20650"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:48:58 GMT",
          "size": "63kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study is about learning to defer with multiple experts and surrogate loss functions, without contributions to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20651",
      "abstract": "Recent work has shown that gradient updates in federated learning (FL) can unintentionally reveal sensitive information about a client's local data. This risk becomes significantly greater when a malicious server manipulates the global model to provoke information-rich updates from clients. In this paper, we adopt a defender's perspective to provide the first comprehensive analysis of malicious gradient leakage attacks and the model manipulation techniques that enable them. Our investigation reveals a core trade-off: these attacks cannot be both highly effective in reconstructing private data and sufficiently stealthy to evade detection -- especially in realistic FL settings that incorporate common normalization techniques and federated averaging.\n  Building on this insight, we argue that malicious gradient leakage attacks, while theoretically concerning, are inherently limited in practice and often detectable through basic monitoring. As a complementary contribution, we propose a simple, lightweight, and broadly applicable client-side detection mechanism that flags suspicious model updates before local training begins, despite the fact that such detection may not be strictly necessary in realistic FL settings. This mechanism further underscores the feasibility of defending against these attacks with minimal overhead, offering a deployable safeguard for privacy-conscious federated learning systems.",
      "authors": [
        "Fei Wang",
        "Baochun Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20651",
        "HTML": "https://arxiv.org/html/2506.20651",
        "PDF": "https://arxiv.org/pdf/2506.20651"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:49:26 GMT",
          "size": "3475kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses gradient leakage detection in federated learning scenarios, not focusing on LLM data collection or processing techniques."
      }
    },
    {
      "id": "2506.20652",
      "abstract": "We present EditP23, a method for mask-free 3D editing that propagates 2D image edits to multi-view representations in a 3D-consistent manner. In contrast to traditional approaches that rely on text-based prompting or explicit spatial masks, EditP23 enables intuitive edits by conditioning on a pair of images: an original view and its user-edited counterpart. These image prompts are used to guide an edit-aware flow in the latent space of a pre-trained multi-view diffusion model, allowing the edit to be coherently propagated across views. Our method operates in a feed-forward manner, without optimization, and preserves the identity of the original object, in both structure and appearance. We demonstrate its effectiveness across a range of object categories and editing scenarios, achieving high fidelity to the source while requiring no manual masks.",
      "authors": [
        "Roi Bar-On",
        "Dana Cohen-Bar",
        "Daniel Cohen-Or"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20652",
        "HTML": "https://arxiv.org/html/2506.20652",
        "PDF": "https://arxiv.org/pdf/2506.20652"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:50:20 GMT",
          "size": "23957kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "EditP23: 3D Editing via Propagation of Image Prompts to Multi-View",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for 3D editing with image prompts, unrelated to LLM training data processing or data engineering methodologies."
      }
    },
    {
      "id": "2506.20657",
      "abstract": "The increasing computational demand from growing data rates and complex machine learning (ML) algorithms in large-scale scientific experiments has driven the adoption of the Services for Optimized Network Inference on Coprocessors (SONIC) approach. SONIC accelerates ML inference by offloading it to local or remote coprocessors to optimize resource utilization. Leveraging its portability to different types of coprocessors, SONIC enhances data processing and model deployment efficiency for cutting-edge research in high energy physics (HEP) and multi-messenger astrophysics (MMA). We developed the SuperSONIC project, a scalable server infrastructure for SONIC, enabling the deployment of computationally intensive tasks to Kubernetes clusters equipped with graphics processing units (GPUs). Using NVIDIA Triton Inference Server, SuperSONIC decouples client workflows from server infrastructure, standardizing communication, optimizing throughput, load balancing, and monitoring. SuperSONIC has been successfully deployed for the CMS and ATLAS experiments at the CERN Large Hadron Collider (LHC), the IceCube Neutrino Observatory (IceCube), and the Laser Interferometer Gravitational-Wave Observatory (LIGO) and tested on Kubernetes clusters at Purdue University, the National Research Platform (NRP), and the University of Chicago. SuperSONIC addresses the challenges of the Cloud-native era by providing a reusable, configurable framework that enhances the efficiency of accelerator-based inference deployment across diverse scientific domains and industries.",
      "authors": [
        "Dmitry Kondratyev",
        "Benedikt Riedel",
        "Yuan-Tang Chou",
        "Miles Cochran-Branson",
        "Noah Paladino",
        "David Schultz",
        "Mia Liu",
        "Javier Duarte",
        "Philip Harris",
        "Shih-Chieh Hsu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20657",
        "HTML": "https://arxiv.org/html/2506.20657",
        "PDF": "https://arxiv.org/pdf/2506.20657"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "High Energy Physics - Experiment (hep-ex)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:52:26 GMT",
          "size": "1780kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SuperSONIC: Cloud-Native Infrastructure for ML Inferencing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on cloud-native infrastructure and ML inferencing optimization using server infrastructure and coprocessors. It does not discuss any topics related to data engineering or data processing for LLM training."
      }
    },
    {
      "id": "2506.20668",
      "abstract": "We propose DemoDiffusion, a simple and scalable method for enabling robots to perform manipulation tasks in natural environments by imitating a single human demonstration. Our approach is based on two key insights. First, the hand motion in a human demonstration provides a useful prior for the robot's end-effector trajectory, which we can convert into a rough open-loop robot motion trajectory via kinematic retargeting. Second, while this retargeted motion captures the overall structure of the task, it may not align well with plausible robot actions in-context. To address this, we leverage a pre-trained generalist diffusion policy to modify the trajectory, ensuring it both follows the human motion and remains within the distribution of plausible robot actions. Our approach avoids the need for online reinforcement learning or paired human-robot data, enabling robust adaptation to new tasks and scenes with minimal manual effort. Experiments in both simulation and real-world settings show that DemoDiffusion outperforms both the base policy and the retargeted trajectory, enabling the robot to succeed even on tasks where the pre-trained generalist policy fails entirely. Project page: https://demodiffusion.github.io/",
      "authors": [
        "Sungjae Park",
        "Homanga Bharadhwaj",
        "Shubham Tulsiani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20668",
        "HTML": "https://arxiv.org/html/2506.20668",
        "PDF": "https://arxiv.org/pdf/2506.20668"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:59:01 GMT",
          "size": "16510kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research paper discusses a method for robot motion trajectory generation from human demonstrations using a pre-trained diffusion policy. It does not involve LLMs or their training data processing."
      }
    },
    {
      "id": "2506.20671",
      "abstract": "Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointly learning scene geometry and semantics, enabling downstream applications such as navigation in mobile robotics. The recent generalization to Panoptic Scene Completion (PSC) advances the SSC domain by integrating instance-level information, thereby enhancing object-level sensitivity in scene understanding. While PSC was introduced using LiDAR modality, methods based on camera images remain largely unexplored. Moreover, recent Transformer-based SSC approaches utilize a fixed set of learned queries to reconstruct objects within the scene volume. Although these queries are typically updated with image context during training, they remain static at test time, limiting their ability to dynamically adapt specifically to the observed scene. To overcome these limitations, we propose IPFormer, the first approach that leverages context-adaptive instance proposals at train and test time to address vision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptively initializes these queries as panoptic instance proposals derived from image context and further refines them through attention-based encoding and decoding to reason about semantic instance-voxel relationships. Experimental results show that our approach surpasses state-of-the-art methods in overall panoptic metrics PQ$^\\dagger$ and PQ-All, matches performance in individual metrics, and achieves a runtime reduction exceeding 14$\\times$. Furthermore, our ablation studies reveal that dynamically deriving instance proposals from image context, as opposed to random initialization, leads to a 3.62% increase in PQ-All and a remarkable average improvement of 18.65% in combined Thing-metrics. These results highlight our introduction of context-adaptive instance proposals as a pioneering effort in addressing vision-based 3D Panoptic Scene Completion.",
      "authors": [
        "Markus Gross",
        "Aya Fahmy",
        "Danit Niwattananan",
        "Dominik Muhle",
        "Rui Song",
        "Daniel Cremers",
        "Henri Mee{\\ss}"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20671",
        "HTML": "https://arxiv.org/html/2506.20671",
        "PDF": "https://arxiv.org/pdf/2506.20671"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:59:45 GMT",
          "size": "37695kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on visual 3D panoptic scene completion using context-adaptive instance proposals, and while it deals with processing visual data, it does not address LLM training data processing or propose methods related to LLM data pipelines."
      }
    },
    {
      "id": "2506.18278",
      "abstract": "We establish the first finite-time information-theoretic lower bounds-and derive new policies that achieve them-for the total queue length in scheduling problems over stochastic processing networks with both adversarial and stochastic arrivals. Prior analyses of MaxWeight guarantee only stability and asymptotic optimality in heavy traffic; we prove that, at finite horizons, MaxWeight can incur strictly larger backlog by problem-dependent factors which we identify. Our main innovations are 1) a minimax framework that pinpoints the precise problem parameters governing any policy's finite-time performance; 2) an information-theoretic lower bound on total queue length; 3) fundamental limitation of MaxWeight that it is suboptimal in finite time; and 4) a new scheduling rule that minimizes the full Lyapunov drift-including its second-order term-thereby matching the lower bound under certain conditions, up to universal constants. These findings reveal a fundamental limitation on \"drift-only\" methods and points the way toward principled, non-asymptotic optimality in queueing control.",
      "authors": [
        "Yujie Liu",
        "Vincent Y. F. Tan",
        "Yunbei Xu"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18278",
        "HTML": "https://arxiv.org/html/2506.18278",
        "PDF": "https://arxiv.org/pdf/2506.18278"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 04:14:40 GMT",
          "size": "1010kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Finite-Time Information-Theoretic Bounds in Queueing Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research investigates queueing control in stochastic networks and does not relate to LLM training data processing or engineering in any way."
      }
    },
    {
      "id": "2506.19855",
      "abstract": "Studying the peeling behaviour of adhesives on skin is vital for advancing biomedical applications such as medical adhesives and transdermal patches. Traditional methods like experimental testing and finite element method (FEM), though considered gold standards, are resource-intensive, computationally expensive and time-consuming, particularly when analysing a wide material parameter space. In this study, we present a neural network-based approach to predict the minimum peel force (F_min) required for adhesive detachment from skin tissue, limiting the need for repeated FEM simulations and significantly reducing the computational cost. Leveraging a dataset generated from FEM simulations of 90 degree peel test with varying adhesive and fracture mechanics parameters, our neural network model achieved high accuracy, validated through rigorous 5-fold cross-validation. The final architecture was able to predict a wide variety of skin-adhesive peeling behaviour, exhibiting a mean squared error (MSE) of 3.66*10^-7 and a R^2 score of 0.94 on test set, demonstrating robust performance. This work introduces a reliable, computationally efficient method for predicting adhesive behaviour, significantly reducing simulation time while maintaining accuracy. This integration of machine learning with high-fidelity biomechanical simulations enables efficient design and optimization of skin-adhesive systems, providing a scalable framework for future research in computational dermato-mechanics and bio-adhesive material design.",
      "authors": [
        "Ashish Masarkar",
        "Rakesh Gupta",
        "Naga Neehar Dingari and Beena Rai"
      ],
      "last_revised_date": "2025/06/09",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19855",
        "HTML": "https://arxiv.org/html/2506.19855",
        "PDF": "https://arxiv.org/pdf/2506.19855"
      },
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 12:22:00 GMT",
          "size": "1507kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/09",
      "title": "Neural networks for the prediction of peel force for skin adhesive interface using FEM simulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on using neural networks to predict adhesive behavior, which does not involve the processing of LLM training data."
      }
    },
    {
      "id": "2506.19856",
      "abstract": "We introduce a novel proxy for firm linkages, Characteristic Vector Linkages (CVLs). We use this concept to estimate firm linkages, first through Euclidean similarity, and then by applying Quantum Cognition Machine Learning (QCML) to similarity learning. We demonstrate that both methods can be used to construct profitable momentum spillover trading strategies, but QCML similarity outperforms the simpler Euclidean similarity.",
      "authors": [
        "Ryan Samson",
        "Adrian Banner",
        "Luca Candelori",
        "Sebastien Cottrell",
        "Tiziana Di Matteo",
        "Paul Duchnowski",
        "Vahagn Kirakosyan",
        "Jose Marques",
        "Kharen Musaelian",
        "Stefano Pasquali",
        "Ryan Stever",
        "and Dario Villani"
      ],
      "last_revised_date": "2025/06/09",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19856",
        "HTML": "https://arxiv.org/html/2506.19856",
        "PDF": "https://arxiv.org/pdf/2506.19856"
      },
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 16:13:35 GMT",
          "size": "230kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/09",
      "title": "Supervised Similarity for Firm Linkages",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a method for estimating firm linkages and does not address any aspect of LLM training data processing."
      }
    },
    {
      "id": "2506.19857",
      "abstract": "In this survey, we explore recent literature on finding the cores of higher graphs using geometric and topological means. We study graphs, hypergraphs, and simplicial complexes, all of which are models of higher graphs. We study the notion of a core, which is a minimalist representation of a higher graph that retains its geometric or topological information. We focus on geometric and topological methods based on discrete curvatures, effective resistance, and persistent homology. We aim to connect tools from graph theory, discrete geometry, and computational topology to inspire new research on the simplification of higher graphs.",
      "authors": [
        "In\\'es Garc\\'ia-Redondo",
        "Claudia Landi",
        "Sarah Percival",
        "Anda Skeja",
        "Bei Wang",
        "Ling Zhou"
      ],
      "last_revised_date": "2025/06/09",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19857",
        "HTML": "https://arxiv.org/html/2506.19857",
        "PDF": "https://arxiv.org/pdf/2506.19857"
      },
      "subjects": [
        "History and Overview (math.HO)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 21:34:43 GMT",
          "size": "1976kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/09",
      "title": "Finding the Cores of Higher Graphs Using Geometric and Topological Means: A Survey",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This survey paper explores methods for finding graph cores and does not involve LLM training data processing."
      }
    },
    {
      "id": "2506.19860",
      "abstract": "Electric vehicle (EV) charging infrastructure is increasingly critical to sustainable transport systems, yet its resilience under environmental and infrastructural stress remains underexplored. In this paper, we introduce RSERI-EV, a spatially explicit and multi-modal risk assessment framework that combines remote sensing data, open infrastructure datasets, and spatial graph analytics to evaluate the vulnerability of EV charging stations. RSERI-EV integrates diverse data layers, including flood risk maps, land surface temperature (LST) extremes, vegetation indices (NDVI), land use/land cover (LULC), proximity to electrical substations, and road accessibility to generate a composite Resilience Score. We apply this framework to the country of Wales EV charger dataset to demonstrate its feasibility. A spatial $k$-nearest neighbours ($k$NN) graph is constructed over the charging network to enable neighbourhood-based comparisons and graph-aware diagnostics. Our prototype highlights the value of multi-source data fusion and interpretable spatial reasoning in supporting climate-resilient, infrastructure-aware EV deployment.",
      "authors": [
        "Oktay Karaku\\c{s}",
        "Padraig Corcoran"
      ],
      "last_revised_date": "2025/06/10",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19860",
        "HTML": "https://arxiv.org/html/2506.19860",
        "PDF": "https://arxiv.org/pdf/2506.19860"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Jun 2025 05:27:51 GMT",
          "size": "5477kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/10",
      "title": "A Multi-Modal Spatial Risk Framework for EV Charging Infrastructure Using Remote Sensing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a framework for EV charging infrastructure risk assessment using spatial data, unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.19862",
      "abstract": "Geometric graph neural networks (GNNs) that respect E(3) symmetries have achieved strong performance on small molecule modeling, but they face scalability and expressiveness challenges when applied to large biomolecules such as RNA and proteins. These systems require models that can simultaneously capture fine-grained atomic interactions, long-range dependencies across spatially distant components, and biologically relevant hierarchical structure, such as atoms forming residues, which in turn form higher-order domains. Existing geometric GNNs, which typically operate exclusively in either Euclidean or Spherical Harmonics space, are limited in their ability to capture both the fine-scale atomic details and the long-range, symmetry-aware dependencies required for modeling the multi-scale structure of large biomolecules. We introduce DualEquiNet, a Dual-Space Hierarchical Equivariant Network that constructs complementary representations in both Euclidean and Spherical Harmonics spaces to capture local geometry and global symmetry-aware features. DualEquiNet employs bidirectional cross-space message passing and a novel Cross-Space Interaction Pooling mechanism to hierarchically aggregate atomic features into biologically meaningful units, such as residues, enabling efficient and expressive multi-scale modeling for large biomolecular systems. DualEquiNet achieves state-of-the-art performance on multiple existing benchmarks for RNA property prediction and protein modeling, and outperforms prior methods on two newly introduced 3D structural benchmarks demonstrating its broad effectiveness across a range of large biomolecule modeling tasks.",
      "authors": [
        "Junjie Xu",
        "Jiahao Zhang",
        "Mangal Prakash",
        "Xiang Zhang",
        "Suhang Wang"
      ],
      "last_revised_date": "2025/06/10",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19862",
        "HTML": "https://arxiv.org/html/2506.19862",
        "PDF": "https://arxiv.org/pdf/2506.19862"
      },
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Jun 2025 07:43:50 GMT",
          "size": "1213kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/10",
      "title": "DualEquiNet: A Dual-Space Hierarchical Equivariant Network for Large Biomolecules",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a network model for biomolecular modeling, which does not involve LLM training data processing."
      }
    },
    {
      "id": "2506.19865",
      "abstract": "Template-based molecular generation offers a promising avenue for drug design by ensuring generated compounds are synthetically accessible through predefined reaction templates and building blocks. In this work, we tackle three core challenges in template-based GFlowNets: (1) minimizing synthesis cost, (2) scaling to large building block libraries, and (3) effectively utilizing small fragment sets. We propose \\textbf{Recursive Cost Guidance}, a backward policy framework that employs auxiliary machine learning models to approximate synthesis cost and viability. This guidance steers generation toward low-cost synthesis pathways, significantly enhancing cost-efficiency, molecular diversity, and quality, especially when paired with an \\textbf{Exploitation Penalty} that balances the trade-off between exploration and exploitation. To enhance performance in smaller building block libraries, we develop a \\textbf{Dynamic Library} mechanism that reuses intermediate high-reward states to construct full synthesis trees. Our approach establishes state-of-the-art results in template-based molecular generation.",
      "authors": [
        "Piotr Gai\\'nski",
        "Oussama Boussif",
        "Andrei Rekesh",
        "Dmytro Shevchuk",
        "Ali Parviz",
        "Mike Tyers",
        "Robert A. Batey",
        "Micha{\\l} Koziarski"
      ],
      "last_revised_date": "2025/06/10",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19865",
        "HTML": "https://arxiv.org/html/2506.19865",
        "PDF": "https://arxiv.org/pdf/2506.19865"
      },
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Jun 2025 15:16:09 GMT",
          "size": "1388kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/10",
      "title": "Scalable and Cost-Efficient de Novo Template-Based Molecular Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses molecular generation and synthesis cost optimization, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.19875",
      "abstract": "Speaker tracking methods often rely on spatial observations to assign coherent track identities over time. This raises limits in scenarios with intermittent and moving speakers, i.e., speakers that may change position when they are inactive, thus leading to discontinuous spatial trajectories. This paper proposes to investigate the use of speaker embeddings, in a simple solution to this issue. We propose to perform identity reassignment post-tracking, using speaker embeddings. We leverage trajectory-related information provided by an initial tracking step and multichannel audio signal. Beamforming is used to enhance the signal towards the speakers' positions in order to compute speaker embeddings. These are then used to assign new track identities based on an enrollment pool. We evaluate the performance of the proposed speaker embedding-based identity reassignment method on a dataset where speakers change position during inactivity periods. Results show that it consistently improves the identity assignment performance of neural and standard tracking systems. In particular, we study the impact of beamforming and input duration for embedding extraction.",
      "authors": [
        "Taous Iatariene (MULTISPEECH)",
        "Can Cui (MULTISPEECH)",
        "Alexandre Gu\\'erin",
        "Romain Serizel (MULTISPEECH)"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19875",
        "HTML": "https://arxiv.org/html/2506.19875",
        "PDF": "https://arxiv.org/pdf/2506.19875"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 13:02:20 GMT",
          "size": "1364kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Speaker Embeddings to Improve Tracking of Intermittent and Moving Speakers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on speaker tracking using embeddings and beamforming to improve speaker identity assignment, with no reference to LLM training data processing."
      }
    },
    {
      "id": "2506.19880",
      "abstract": "Radiotherapy (RT) is a critical cancer treatment, with volumetric modulated arc therapy (VMAT) being a commonly used technique that enhances dose conformity by dynamically adjusting multileaf collimator (MLC) positions and monitor units (MU) throughout gantry rotation. Adaptive radiotherapy requires frequent modifications to treatment plans to account for anatomical variations, necessitating time-efficient solutions. Deep learning offers a promising solution to automate this process. To this end, we propose a two-stage, physics-guided deep learning pipeline for radiotherapy planning. In the first stage, our network is trained with direct supervision on treatment plan parameters, consisting of MLC and MU values. In the second stage, we incorporate an additional supervision signal derived from the predicted 3D dose distribution, integrating physics-based guidance into the training process. We train and evaluate our approach on 133 prostate cancer patients treated with a uniform 2-arc VMAT protocol delivering a dose of 62 Gy to the planning target volume (PTV). Our results demonstrate that the proposed approach, implemented using both 3D U-Net and UNETR architectures, consistently produces treatment plans that closely match clinical ground truths. Our method achieves a mean difference of D95% = 0.42 +/- 1.83 Gy and V95% = -0.22 +/- 1.87% at the PTV while generating dose distributions that reduce radiation exposure to organs at risk. These findings highlight the potential of physics-guided deep learning in RT planning.",
      "authors": [
        "Stefanos Achlatis",
        "Efstratios Gavves and Jan-Jakob Sonke"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19880",
        "HTML": "https://arxiv.org/html/2506.19880",
        "PDF": "https://arxiv.org/pdf/2506.19880"
      },
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 19:44:56 GMT",
          "size": "5021kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Physics-Guided Radiotherapy Treatment Planning with Deep Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses deep learning for radiotherapy treatment planning, not involving any aspects of LLM training data processing."
      }
    },
    {
      "id": "2506.19887",
      "abstract": "This paper presents our contributions to the Speech Emotion Recognition in Naturalistic Conditions (SERNC) Challenge, where we address categorical emotion recognition and emotional attribute prediction. To handle the complexities of natural speech, including intra- and inter-subject variability, we propose Multi-level Acoustic-Textual Emotion Representation (MATER), a novel hierarchical framework that integrates acoustic and textual features at the word, utterance, and embedding levels. By fusing low-level lexical and acoustic cues with high-level contextualized representations, MATER effectively captures both fine-grained prosodic variations and semantic nuances. Additionally, we introduce an uncertainty-aware ensemble strategy to mitigate annotator inconsistencies, improving robustness in ambiguous emotional expressions. MATER ranks fourth in both tasks with a Macro-F1 of 41.01% and an average CCC of 0.5928, securing second place in valence prediction with an impressive CCC of 0.6941.",
      "authors": [
        "Hyo Jin Jon",
        "Longbin Jin",
        "Hyuntaek Jung",
        "Hyunseo Kim",
        "Donghun Min",
        "Eun Yi Kim"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19887",
        "HTML": "https://arxiv.org/html/2506.19887",
        "PDF": "https://arxiv.org/pdf/2506.19887"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 05:35:53 GMT",
          "size": "690kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on speech emotion recognition and does not address any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.19945",
      "abstract": "We propose a data-driven dynamic factor framework where a response variable depends on a high-dimensional set of covariates, without imposing any parametric model on the joint dynamics. Leveraging Anisotropic Diffusion Maps, a nonlinear manifold learning technique introduced by Singer and Coifman, our framework uncovers the joint dynamics of the covariates and responses in a purely data-driven way. We approximate the embedding dynamics using linear diffusions, and exploit Kalman filtering to predict the evolution of the covariates and response variables directly from the diffusion map embedding space. We generalize Singer's convergence rate analysis of the graph Laplacian from the case of independent uniform samples on a compact manifold to the case of time series arising from Langevin diffusions in Euclidean space. Furthermore, we provide rigorous justification for our procedure by showing the robustness of approximations of the diffusion map coordinates by linear diffusions, and the convergence of ergodic averages under standard spectral assumptions on the underlying dynamics. We apply our method to the stress testing of equity portfolios using a combination of financial and macroeconomic factors from the Federal Reserve's supervisory scenarios. We demonstrate that our data-driven stress testing method outperforms standard scenario analysis and Principal Component Analysis benchmarks through historical backtests spanning three major financial crises, achieving reductions in mean absolute error of up to 55% and 39% for scenario-based portfolio return prediction, respectively.",
      "authors": [
        "Graeme Baker",
        "Agostino Capponi",
        "J. Antonio Sidaoui"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19945",
        "HTML": "https://arxiv.org/html/2506.19945",
        "PDF": "https://arxiv.org/pdf/2506.19945"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:40:40 GMT",
          "size": "3217kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Data-Driven Dynamic Factor Modeling via Manifold Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a data-driven dynamic factor framework using manifold learning for financial time series analysis, with no relevance to LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.19960",
      "abstract": "Reliable description of bond breaking remains a major challenge for quantum chemistry due to the multireferential character of the electronic structure in dissociating species. Multireferential methods in particular suffer from large computational cost, which under the normal paradigm has to be paid anew for each system at a full price, ignoring commonalities in electronic structure across molecules. Quantum Monte Carlo with deep neural networks (deep QMC) uniquely offers to exploit such commonalities by pretraining transferable wavefunction models, but all such attempts were so far limited in scope. Here, we bring this new paradigm to fruition with Orbformer, a novel transferable wavefunction model pretrained on 22,000 equilibrium and dissociating structures that can be fine-tuned on unseen molecules reaching an accuracy-cost ratio rivalling classical multireferential methods. On established benchmarks as well as more challenging bond dissociations and Diels-Alder reactions, Orbformer is the only method that consistently converges to chemical accuracy (1 kcal/mol). This work turns the idea of amortizing the cost of solving the Schr\\\"odinger equation over many molecules into a practical approach in quantum chemistry.",
      "authors": [
        "Adam Foster",
        "Zeno Sch\\\"atzle",
        "P. Bern\\'at Szab\\'o",
        "Lixue Cheng",
        "Jonas K\\\"ohler",
        "Gino Cassella",
        "Nicholas Gao",
        "Jiawei Li",
        "Frank No\\'e",
        "Jan Hermann"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19960",
        "HTML": "https://arxiv.org/html/2506.19960",
        "PDF": "https://arxiv.org/pdf/2506.19960"
      },
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:12:45 GMT",
          "size": "3758kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "An ab initio foundation model of wavefunctions that accurately describes chemical bond breaking",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses quantum chemistry and wavefunction modeling with deep neural networks, which is not related to LLM training data processing."
      }
    },
    {
      "id": "2506.19973",
      "abstract": "This study investigates the application of quantum neural networks (QNNs) for propensity score estimation to address selection bias in comparing survival outcomes between laparoscopic and open surgical techniques in a cohort of 1177 colorectal carcinoma patients treated at University Hospital Ostrava (2001-2009). Using a dataset with 77 variables, including patient demographics and tumor characteristics, we developed QNN-based propensity score models focusing on four key covariates (Age, Sex, Stage, BMI). The QNN architecture employed a linear ZFeatureMap for data encoding, a SummedPaulis operator for predictions, and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for robust, gradient-free optimization in noisy quantum environments. Variance regularization was integrated to mitigate quantum measurement noise, with simulations conducted under exact, sampling (1024 shots), and noisy hardware (FakeManhattanV2) conditions. QNNs, particularly with simulated hardware noise, outperformed classical logistic regression and gradient boosted machines in small samples (AUC up to 0.750 for n=100), with noise modeling enhancing predictive stability. Propensity score matching and weighting, optimized via genetic matching and matching weights, achieved covariate balance with standardized mean differences of 0.0849 and 0.0869, respectively. Survival analyses using Kaplan-Meier estimation, Cox proportional hazards, and Aalen additive regression revealed no significant survival differences post-adjustment (p-values 0.287-0.851), indicating confounding bias in unadjusted outcomes. These results highlight QNNs' potential, enhanced by CMA-ES and noise-aware strategies, to improve causal inference in biomedical research, particularly for small-sample, high-dimensional datasets.",
      "authors": [
        "Vojt\\v{e}ch Nov\\'ak",
        "Ivan Zelinka",
        "Lenka P\\v{r}ibylov\\'a",
        "Lubom\\'ir Mart\\'inek"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19973",
        "HTML": "https://arxiv.org/html/2506.19973",
        "PDF": "https://arxiv.org/pdf/2506.19973"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:40:39 GMT",
          "size": "579kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Quantum Neural Networks for Propensity Score Estimation and Survival Analysis in Observational Biomedical Studies",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study applies quantum neural networks to biomedical data analysis but does not discuss LLM training data processing or relevant data engineering tasks."
      }
    },
    {
      "id": "2506.19975",
      "abstract": "Recent developments in neural networks have improved deformable image registration (DIR) by amortizing iterative optimization, enabling fast and accurate DIR results. However, learning-based methods often face challenges with limited training data, large deformations, and tend to underperform compared to iterative approaches when label supervision is unavailable. While iterative methods can achieve higher accuracy in such scenarios, they are considerably slower than learning-based methods. To address these limitations, we propose VoxelOpt, a discrete optimization-based DIR framework that combines the strengths of learning-based and iterative methods to achieve a better balance between registration accuracy and runtime. VoxelOpt uses displacement entropy from local cost volumes to measure displacement signal strength at each voxel, which differs from earlier approaches in three key aspects. First, it introduces voxel-wise adaptive message passing, where voxels with lower entropy receives less influence from their neighbors. Second, it employs a multi-level image pyramid with 27-neighbor cost volumes at each level, avoiding exponential complexity growth. Third, it replaces hand-crafted features or contrastive learning with a pretrained foundational segmentation model for feature extraction. In abdominal CT registration, these changes allow VoxelOpt to outperform leading iterative in both efficiency and accuracy, while matching state-of-the-art learning-based methods trained with label supervision. The source code will be available at https://github.com/tinymilky/VoxelOpt",
      "authors": [
        "Hang Zhang",
        "Yuxi Zhang",
        "Jiazheng Wang",
        "Xiang Chen",
        "Renjiu Hu",
        "Xin Tian",
        "Gaolei Li",
        "and Min Liu"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19975",
        "HTML": "https://arxiv.org/html/2506.19975",
        "PDF": "https://arxiv.org/pdf/2506.19975"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 19:44:04 GMT",
          "size": "976kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a method for deformable image registration and does not address LLM training data collection or processing tasks."
      }
    },
    {
      "id": "2506.20014",
      "abstract": "The undergraduate-led Polarization-modUlated Laser Satellite Experiment (PULSE-A) at the University of Chicago seeks to demonstrate the feasibility of circular polarization shift keyed satellite-to-ground laser communication. PULSE-A's low-cost open-source bus serves as the backbone of the mission and has been designed in tandem with the Payload, with design driven by strict requirements for pointing accuracy, component alignment, power demand, and thermal stability. This work presents the design and testing of the PULSE-A bus.\n  The spacecraft bus was designed to fill two major needs: (1) to meet the requirements of the PULSE-A mission, and (2) to be easily configurable for future missions that desire enhanced capabilities over other low-cost open-source designs. At its core, the bus features dual BeagleBone Black Industrial compute units, selected for their flight heritage, integrated via a PC/104 header standard. PULSE-A implements Goddard Space Flight Center's core Flight System (cFS), which takes a modular software architecture approach and is built in C. The use of C as the primary language aligns with the expertise of the University of Chicago's Computer Science department, allowing for ease of development by PULSE-A's undergraduate flight software team.\n  The CubeSat structure utilizes Gran Systems' 3U frame, modified to accommodate openings for various ports and deployable components. Inside, the avionics stack uses the PC/104 standard quad rails, which terminate in PULSE-A's custom-designed Payload Box that houses all of the Payload components and optical fiber runs. This work also covers the techniques and iterative engineering processes used to develop the thermal control and dissipation mechanisms for the specific requirements, under volume, mass, and temperature-range constraints.",
      "authors": [
        "Graydon Schulze-Kalt",
        "Robert Pitu",
        "Spencer Shelton",
        "Catherine Todd",
        "Zane Ebel",
        "Ian Goldberg",
        "Leon Gold",
        "Henry Czarnecki",
        "Mason McCormack",
        "Larry Li",
        "Zumi Riekse",
        "Brian Yu",
        "Akash Piya",
        "Vidya Suri",
        "Dylan Hu",
        "Colleen Kim",
        "John Baird",
        "Seth Knights",
        "Logan Hanssler",
        "Michael Lembeck",
        "and Tian Zhong"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20014",
        "HTML": "https://arxiv.org/html/2506.20014",
        "PDF": "https://arxiv.org/pdf/2506.20014"
      },
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Hardware Architecture (cs.AR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 21:06:49 GMT",
          "size": "6008kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Development of an Open-Source Spacecraft Bus for the PULSE-A CubeSat",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses the development of a spacecraft bus for a CubeSat mission, which does not involve processing or engineering of LLM training data."
      }
    },
    {
      "id": "2506.20043",
      "abstract": "Sampling physically valid ligand-binding poses remains a major challenge in molecular docking, particularly for unseen or structurally diverse targets. We introduce PocketVina, a fast and memory-efficient, search-based docking framework that combines pocket prediction with systematic multi-pocket exploration. We evaluate PocketVina across four established benchmarks--PDBbind2020 (timesplit and unseen), DockGen, Astex, and PoseBusters--and observe consistently strong performance in sampling physically valid docking poses. PocketVina achieves state-of-the-art performance when jointly considering ligand RMSD and physical validity (PB-valid), while remaining competitive with deep learning-based approaches in terms of RMSD alone, particularly on structurally diverse and previously unseen targets. PocketVina also maintains state-of-the-art physically valid docking accuracy across ligands with varying degrees of flexibility. We further introduce TargetDock-AI, a benchmarking dataset we curated, consisting of over 500000 protein-ligand pairs, and a partition of the dataset labeled with PubChem activity annotations. On this large-scale dataset, PocketVina successfully discriminates active from inactive targets, outperforming a deep learning baseline while requiring significantly less GPU memory and runtime. PocketVina offers a robust and scalable docking strategy that requires no task-specific training and runs efficiently on standard GPUs, making it well-suited for high-throughput virtual screening and structure-based drug discovery.",
      "authors": [
        "Ahmet Sarigun",
        "Bora Uyar",
        "Vedran Franke",
        "Altuna Akalin"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20043",
        "HTML": "https://arxiv.org/html/2506.20043",
        "PDF": "https://arxiv.org/pdf/2506.20043"
      },
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:50:30 GMT",
          "size": "8652kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "PocketVina Enables Scalable and Highly Accurate Physically Valid Docking through Multi-Pocket Conditioning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on molecular docking and proposes a docking framework, PocketVina, which enhances ligand-binding pose prediction accuracy. It does not address LLM training data processing or related data engineering tasks."
      }
    },
    {
      "id": "2506.20048",
      "abstract": "In reinforcement learning, distributional off-policy evaluation (OPE) focuses on estimating the return distribution of a target policy using offline data collected under a different policy. This work focuses on extending the widely used fitted-Q evaluation -- developed for expectation-based reinforcement learning -- to the distributional OPE setting. We refer to this extension as fitted distributional evaluation (FDE). While only a few related approaches exist, there remains no unified framework for designing FDE methods. To fill this gap, we present a set of guiding principles for constructing theoretically grounded FDE methods. Building on these principles, we develop several new FDE methods with convergence analysis and provide theoretical justification for existing methods, even in non-tabular environments. Extensive experiments, including simulations on linear quadratic regulators and Atari games, demonstrate the superior performance of the FDE methods.",
      "authors": [
        "Sungee Hong",
        "Jiayi Wang",
        "Zhengling Qi",
        "Raymond Ka Wai Wong"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20048",
        "HTML": "https://arxiv.org/html/2506.20048",
        "PDF": "https://arxiv.org/pdf/2506.20048"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:08:56 GMT",
          "size": "840kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A Principled Path to Fitted Distributional Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on reinforcement learning and specifically on distributional off-policy evaluation. It does not discuss any aspects related to LLM training data processes or improvements on data for such models."
      }
    },
    {
      "id": "2506.20056",
      "abstract": "Photonic device development (PDD) has achieved remarkable success in designing and implementing new devices for controlling light across various wavelengths, scales, and applications, including telecommunications, imaging, sensing, and quantum information processing. PDD is an iterative, five-step process that consists of: i) deriving device behavior from design parameters, ii) simulating device performance, iii) finding the optimal candidate designs from simulations, iv) fabricating the optimal device, and v) measuring device performance. Classically, all these steps involve Bayesian optimization, material science, control theory, and direct physics-driven numerical methods. However, many of these techniques are computationally intractable, monetarily costly, or difficult to implement at scale. In addition, PDD suffers from large optimization landscapes, uncertainties in structural or optical characterization, and difficulties in implementing robust fabrication processes. However, the advent of machine learning over the past decade has provided novel, data-driven strategies for tackling these challenges, including surrogate estimators for speeding up computations, generative modeling for noisy measurement modeling and data augmentation, reinforcement learning for fabrication, and active learning for experimental physical discovery. In this review, we present a comprehensive perspective on these methods to enable machine-learning-assisted PDD (ML-PDD) for efficient design optimization with powerful generative models, fast simulation and characterization modeling under noisy measurements, and reinforcement learning for fabrication. This review will provide researchers from diverse backgrounds with valuable insights into this emerging topic, fostering interdisciplinary efforts to accelerate the development of complex photonic devices and systems.",
      "authors": [
        "Yuheng Chen",
        "Alexander Montes McNeil",
        "Taehyuk Park",
        "Blake A. Wilson",
        "Vaishnavi Iyer",
        "Michael Bezick",
        "Jae-Ik Choi",
        "Rohan Ojha",
        "Pravin Mahendran",
        "Daksh Kumar Singh",
        "Geetika Chitturi",
        "Peigang Chen",
        "Trang Do",
        "Alexander V. Kildishev",
        "Vladimir M. Shalaev",
        "Michael Moebius",
        "Wenshan Cai",
        "Yongmin Liu",
        "Alexandra Boltasseva"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20056",
        "HTML": "https://arxiv.org/html/2506.20056",
        "PDF": "https://arxiv.org/pdf/2506.20056"
      },
      "subjects": [
        "Optics (physics.optics)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:32:54 GMT",
          "size": "10228kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Machine-Learning-Assisted Photonic Device Development: A Multiscale Approach from Theory to Characterization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work discusses photonic device development and machine learning techniques applied therein, not involving tasks related to training data for large language models."
      }
    },
    {
      "id": "2506.20096",
      "abstract": "In this work, a Model Predictive Controller (MPC) is proposed to control the plasma shape in the Tokamak \\`a Configuration Variable (TCV). The proposed controller relies on models obtained by coupling linearized plasma response models, derived from the \\texttt{fge} code of the Matlab EQuilibrium toolbox (MEQ) suite, with a state-space description of the core TCV magnetic control system. It optimizes the reference signals fed to this inner control loop in order to achieve the desired plasma shape while also enforcing constraints on the plant outputs. To this end, a suitable Quadratic Programming (QP) problem is formulated and solved in real-time. The effectiveness of the proposed controller is illustrated through a combination of simulations and experimental results. To the best of our knowledge, this is the first time that a plasma shape control solution based on MPC has been experimentally tested on a real tokamak.",
      "authors": [
        "Adriano Mele",
        "Maria A. Topalova",
        "Cristian Galperti",
        "Stefano Coda",
        "TCV team",
        "Eurofusion Tokamak Exploitation Team"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20096",
        "HTML": "https://arxiv.org/html/2506.20096",
        "PDF": "https://arxiv.org/pdf/2506.20096"
      },
      "subjects": [
        "Plasma Physics (physics.plasm-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 02:36:19 GMT",
          "size": "796kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "First experimental demonstration of plasma shape control in a tokamak through Model Predictive Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the design of a Model Predictive Controller for plasma shape control in a tokamak, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20114",
      "abstract": "Tree ensembles are non-parametric methods widely recognized for their accuracy and ability to capture complex interactions. While these models excel at prediction, they are difficult to interpret and may fail to uncover useful relationships in the data. We propose an estimator to extract compact sets of decision rules from tree ensembles. The extracted models are accurate and can be manually examined to reveal relationships between the predictors and the response. A key novelty of our estimator is the flexibility to jointly control the number of rules extracted and the interaction depth of each rule, which improves accuracy. We develop a tailored exact algorithm to efficiently solve optimization problems underlying our estimator and an approximate algorithm for computing regularization paths, sequences of solutions that correspond to varying model sizes. We also establish novel non-asymptotic prediction error bounds for our proposed approach, comparing it to an oracle that chooses the best data-dependent linear combination of the rules in the ensemble subject to the same complexity constraint as our estimator. The bounds illustrate that the large-sample predictive performance of our estimator is on par with that of the oracle. Through experiments, we demonstrate that our estimator outperforms existing algorithms for rule extraction.",
      "authors": [
        "Brian Liu",
        "Rahul Mazumder",
        "Peter Radchenko"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20114",
        "HTML": "https://arxiv.org/html/2506.20114",
        "PDF": "https://arxiv.org/pdf/2506.20114"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:06:37 GMT",
          "size": "1962kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study develops a method to extract decision rules from tree ensembles, focusing on interpretability and accuracy. It does not discuss LLM training data or related data processing stages."
      }
    },
    {
      "id": "2506.20118",
      "abstract": "Understanding the periodic and structural properties of permutation maps over residue rings such as $\\mathbb{Z}_{p^k}$ is a foundational challenge in algebraic dynamics and pseudorandom sequence analysis. Despite notable progress in characterizing global periods, a critical bottleneck remains: the lack of explicit tools to analyze local cycle structures and their evolution with increasing arithmetic precision. In this work, we propose a unified analytical framework to systematically derive the distribution of cycle lengths for a class of permutation maps over $\\mathbb{Z}_{p^k}$. The approach combines techniques from generating functions, minimal polynomials, and lifting theory to track how the cycle structure adapts as the modulus $p^k$ changes. To validate the generality and effectiveness of our method, we apply it to the well-known Cat map as a canonical example, revealing the exact patterns governing its cycle formation and transition. This analysis not only provides rigorous explanations for experimentally observed regularities in fixed-point implementations of such maps but also lays a theoretical foundation for evaluating the randomness and dynamical behavior of pseudorandom number sequences generated by other nonlinear maps. The results have broad implications for secure system design, computational number theory, and symbolic dynamics.",
      "authors": [
        "Kai Tan",
        "Chengqing Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20118",
        "HTML": "https://arxiv.org/html/2506.20118",
        "PDF": "https://arxiv.org/pdf/2506.20118"
      },
      "subjects": [
        "Number Theory (math.NT)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:15:33 GMT",
          "size": "143kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Graph Structure of a Class of Permutation Maps over Ring $\\mathbb{Z}_{p^k}$",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper analyzes permutation maps over mathematical rings, irrelevant to the processing of training data for large language models."
      }
    },
    {
      "id": "2506.20164",
      "abstract": "Technological advances in the past decades have begun to enable neuroscientists to address fundamental questions about consciousness in an unprecedented way. Here we review remarkable recent progress in our understanding of cellular-level mechanisms of conscious processing in the brain. Of particular interest are the cortical pyramidal neurons -- or \"psychic cells\" called by Ram\\'on y Cajal more than 100 years ago -- which have an intriguing cellular mechanism that accounts for selective disruption of feedback signaling in the brain upon anesthetic-induced loss of consciousness. Importantly, a particular class of metabotropic receptors distributed over the dendrites of pyramidal cells are highlighted as the key cellular mechanism. After all, Cajal's instinct over a century ago may turn out to be correct -- we may have just begun to understand whether and how psychic cells indeed generate and control our consciousness.",
      "authors": [
        "Mototaka Suzuki and Jaan Aru"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20164",
        "HTML": "https://arxiv.org/html/2506.20164",
        "PDF": "https://arxiv.org/pdf/2506.20164"
      },
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:38:13 GMT",
          "size": "651kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Do psychic cells generate consciousness?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses cellular mechanisms of consciousness, focusing on neuroscientific advances and pyramidal neurons. It does not address LLM training data processing or data engineering aspects."
      }
    },
    {
      "id": "2506.20173",
      "abstract": "Conformal prediction offers a distribution-free framework for constructing prediction sets with coverage guarantees. In practice, multiple valid conformal prediction sets may be available, arising from different models or methodologies. However, selecting the most desirable set, such as the smallest, can invalidate the coverage guarantees. To address this challenge, we propose a stability-based approach that ensures coverage for the selected prediction set. We extend our results to the online conformal setting, propose several refinements in settings where additional structure is available, and demonstrate its effectiveness through experiments.",
      "authors": [
        "Mahmoud Hegazy",
        "Liviu Aolaritei",
        "Michael I. Jordan",
        "Aymeric Dieuleveut"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20173",
        "HTML": "https://arxiv.org/html/2506.20173",
        "PDF": "https://arxiv.org/pdf/2506.20173"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Other Statistics (stat.OT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:59:55 GMT",
          "size": "1645kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Valid Selection among Conformal Sets",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on conformal prediction and selection of prediction sets, which are unrelated to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20190",
      "abstract": "Zero-shot multi-speaker text-to-speech (TTS) systems rely on speaker embeddings to synthesize speech in the voice of an unseen speaker, using only a short reference utterance. While many speaker embeddings have been developed for speaker recognition, their relative effectiveness in zero-shot TTS remains underexplored. In this work, we employ a YourTTS-based TTS system to compare three different speaker encoders - YourTTS's original H/ASP encoder, x-vector embeddings, and ECAPA-TDNN embeddings - within an otherwise fixed zero-shot TTS framework. All models were trained on the same dataset of Czech read speech and evaluated on 24 out-of-domain target speakers using both subjective and objective methods. The subjective evaluation was conducted via a listening test focused on speaker similarity, while the objective evaluation measured cosine distances between speaker embeddings extracted from synthesized and real utterances. Across both evaluations, the original H/ASP encoder consistently outperformed the alternatives, with ECAPA-TDNN showing better results than x-vectors. These findings suggest that, despite the popularity of ECAPA-TDNN in speaker recognition, it does not necessarily offer improvements for speaker similarity in zero-shot TTS in this configuration. Our study highlights the importance of empirical evaluation when reusing speaker recognition embeddings in TTS and provides a framework for additional future comparisons.",
      "authors": [
        "Marie Kune\\v{s}ov\\'a",
        "Zden\\v{e}k Hanzl\\'i\\v{c}ek",
        "Jind\\v{r}ich Matou\\v{s}ek"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20190",
        "HTML": "https://arxiv.org/html/2506.20190",
        "PDF": "https://arxiv.org/pdf/2506.20190"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:31:32 GMT",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "An Exploration of ECAPA-TDNN and x-vector Speaker Representations in Zero-shot Multi-speaker TTS",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores speaker embeddings in TTS systems, which does not involve LLM training data processing or data engineering tasks."
      }
    },
    {
      "id": "2506.20191",
      "abstract": "We introduce fast randomized algorithms for solving semidefinite programming (SDP) relaxations of the partial permutation synchronization (PPS) problem, a core task in multi-image matching with significant relevance to 3D reconstruction. Our methods build on recent advances in entropy-regularized semidefinite programming and are tailored to the unique structure of PPS, in which the unknowns are partial permutation matrices aligning sparse and noisy pairwise correspondences across images. We prove that entropy regularization resolves optimizer non-uniqueness in standard relaxations, and we develop a randomized solver with nearly optimal scaling in the number of observed correspondences. We also develop several rounding procedures for recovering combinatorial solutions from the implicitly represented primal solution variable, maintaining cycle consistency if desired without harming computational scaling. We demonstrate that our approach achieves state-of-the-art performance on synthetic and real-world datasets in terms of speed and accuracy. Our results highlight PPS as a paradigmatic setting in which entropy-regularized SDP admits both theoretical and practical advantages over traditional low-rank or spectral techniques.",
      "authors": [
        "Michael Lindsey",
        "Yunpeng Shi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20191",
        "HTML": "https://arxiv.org/html/2506.20191",
        "PDF": "https://arxiv.org/pdf/2506.20191"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:32:32 GMT",
          "size": "251kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fast entropy-regularized SDP relaxations for permutation synchronization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on permutation synchronization for multi-image matching via SDP relaxations, without addressing LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20200",
      "abstract": "Positron Emission Tomography / Computed Tomography (PET/CT) plays a critical role in medical imaging, combining functional and anatomical information to aid in accurate diagnosis. However, image quality degradation due to noise, compression and other factors could potentially lead to diagnostic uncertainty and increase the risk of misdiagnosis. When evaluating the quality of a PET/CT image, both low-level features like distortions and high-level features like organ anatomical structures affect the diagnostic value of the image. However, existing medical image quality assessment (IQA) methods are unable to account for both feature types simultaneously. In this work, we propose MS-IQA, a novel multi-scale feature fusion network for PET/CT IQA, which utilizes multi-scale features from various intermediate layers of ResNet and Swin Transformer, enhancing its ability of perceiving both local and global information. In addition, a multi-scale feature fusion module is also introduced to effectively combine high-level and low-level information through a dynamically weighted channel attention mechanism. Finally, to fill the blank of PET/CT IQA dataset, we construct PET-CT-IQA-DS, a dataset containing 2,700 varying-quality PET/CT images with quality scores assigned by radiologists. Experiments on our dataset and the publicly available LDCTIQAC2023 dataset demonstrate that our proposed model has achieved superior performance against existing state-of-the-art methods in various IQA metrics. This work provides an accurate and efficient IQA method for PET/CT. Our code and dataset are available at https://github.com/MS-IQA/MS-IQA/.",
      "authors": [
        "Siqiao Li",
        "Chen Hui",
        "Wei Zhang",
        "Rui Liang",
        "Chenyue Song",
        "Feng Jiang",
        "Haiqi Zhu",
        "Zhixuan Li",
        "Hong Huang",
        "Xiang Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20200",
        "HTML": "https://arxiv.org/html/2506.20200",
        "PDF": "https://arxiv.org/pdf/2506.20200"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:41:03 GMT",
          "size": "1741kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MS-IQA: A Multi-Scale Feature Fusion Network for PET/CT Image Quality Assessment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on medical imaging and proposes a model for assessing the quality of PET/CT images, as well as constructing a dedicated dataset for this purpose. It does not address LLM training data processing or data engineering for language models."
      }
    },
    {
      "id": "2506.20282",
      "abstract": "Osteoporosis, characterized by reduced bone mineral density (BMD) and compromised bone microstructure, increases fracture risk in aging populations. While dual-energy X-ray absorptiometry (DXA) is the clinical standard for BMD assessment, its limited accessibility hinders diagnosis in resource-limited regions. Opportunistic computed tomography (CT) analysis has emerged as a promising alternative for osteoporosis diagnosis using existing imaging data. Current approaches, however, face three limitations: (1) underutilization of unlabeled vertebral data, (2) systematic bias from device-specific DXA discrepancies, and (3) insufficient integration of clinical knowledge such as spatial BMD distribution patterns. To address these, we propose a unified deep learning framework with three innovations. First, a self-supervised learning method using radiomic representations to leverage unlabeled CT data and preserve bone texture. Second, a Mixture of Experts (MoE) architecture with learned gating mechanisms to enhance cross-device adaptability. Third, a multi-task learning framework integrating osteoporosis diagnosis, BMD regression, and vertebra location prediction. Validated across three clinical sites and an external hospital, our approach demonstrates superior generalizability and accuracy over existing methods for opportunistic osteoporosis screening and diagnosis.",
      "authors": [
        "Jiaxing Huang",
        "Heng Guo",
        "Le Lu",
        "Fan Yang",
        "Minfeng Xu",
        "Ge Yang",
        "Wei Luo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20282",
        "HTML": "https://arxiv.org/html/2506.20282",
        "PDF": "https://arxiv.org/pdf/2506.20282"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:43:09 GMT",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Opportunistic Osteoporosis Diagnosis via Texture-Preserving Self-Supervision, Mixture of Experts and Multi-Task Integration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a deep learning framework for medical image analysis to diagnose osteoporosis, with no mention of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20288",
      "abstract": "Overlapping speech remains a major challenge for automatic speech recognition (ASR) in real-world applications, particularly in broadcast media with dynamic, multi-speaker interactions. We propose a light-weight, target-speaker-based extension to an existing streaming ASR system to enable practical transcription of overlapping speech with minimal computational overhead. Our approach combines a speaker-independent (SI) model for standard operation with a speaker-conditioned (SC) model selectively applied in overlapping scenarios. Overlap detection is achieved using a compact binary classifier trained on frozen SI model output, offering accurate segmentation at negligible cost. The SC model employs Feature-wise Linear Modulation (FiLM) to incorporate speaker embeddings and is trained on synthetically mixed data to transcribe only the target speaker. Our method supports dynamic speaker tracking and reuses existing modules with minimal modifications. Evaluated on a challenging set of Czech television debates with 16% overlap, the system reduced WER on overlapping segments from 68.0% (baseline) to 35.78% while increasing total computational load by only 44%. The proposed system offers an effective and scalable solution for overlap transcription in continuous ASR services.",
      "authors": [
        "Ale\\v{s} Pra\\v{z}\\'ak and Marie Kune\\v{s}ov\\'a and Josef Psutka"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20288",
        "HTML": "https://arxiv.org/html/2506.20288",
        "PDF": "https://arxiv.org/pdf/2506.20288"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:46:56 GMT",
          "size": "849kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Lightweight Target-Speaker-Based Overlap Transcription for Practical Streaming ASR",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses speaker overlap in ASR systems and proposes a method for speech transcription, not related to LLM training data processing."
      }
    },
    {
      "id": "2506.20297",
      "abstract": "Federated learning (FL) enables collaborative training across distributed clients without sharing raw data, often at the cost of substantial communication overhead induced by transmitting high-dimensional model updates. This overhead can be alleviated by having the clients quantize their model updates, with dithered lattice quantizers identified as an attractive scheme due to its structural simplicity and convergence-preserving properties. However, existing lattice-based FL schemes typically rely on a fixed quantization rule, which is suboptimal in heterogeneous and dynamic environments where the model updates distribution varies across users and training rounds. In this work, we propose Online Learned Adaptive Lattices (OLALa), a heterogeneous FL framework where each client can adjust its quantizer online using lightweight local computations. We first derive convergence guarantees for FL with non-fixed lattice quantizers and show that proper lattice adaptation can tighten the convergence bound. Then, we design an online learning algorithm that enables clients to tune their quantizers throughout the FL process while exchanging only a compact set of quantization parameters. Numerical experiments demonstrate that OLALa consistently improves learning performance under various quantization rates, outperforming conventional fixed-codebook and non-adaptive schemes.",
      "authors": [
        "Natalie Lang",
        "Maya Simhi",
        "and Nir Shlezinger"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20297",
        "HTML": "https://arxiv.org/html/2506.20297",
        "PDF": "https://arxiv.org/pdf/2506.20297"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:18:34 GMT",
          "size": "2226kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "OLALa: Online Learned Adaptive Lattice Codes for Heterogeneous Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper addresses federated learning and quantization of model updates, it does not relate to any aspect of LLM training data collection or processing."
      }
    },
    {
      "id": "2506.20303",
      "abstract": "Automated fundus image quality assessment (FIQA) remains a challenge due to variations in image acquisition and subjective expert evaluations. We introduce FundaQ-8, a novel expert-validated framework for systematically assessing fundus image quality using eight critical parameters, including field coverage, anatomical visibility, illumination, and image artifacts. Using FundaQ-8 as a structured scoring reference, we develop a ResNet18-based regression model to predict continuous quality scores in the 0 to 1 range. The model is trained on 1800 fundus images from real-world clinical sources and Kaggle datasets, using transfer learning, mean squared error optimization, and standardized preprocessing. Validation against the EyeQ dataset and statistical analyses confirm the framework's reliability and clinical interpretability. Incorporating FundaQ-8 into deep learning models for diabetic retinopathy grading also improves diagnostic robustness, highlighting the value of quality-aware training in real-world screening applications.",
      "authors": [
        "Lee Qi Zun",
        "Oscar Wong Jin Hao",
        "Nor Anita Binti Che Omar",
        "Zalifa Zakiah Binti Asnir",
        "Mohamad Sabri bin Sinal Zainal",
        "Goh Man Fye"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20303",
        "HTML": "https://arxiv.org/html/2506.20303",
        "PDF": "https://arxiv.org/pdf/2506.20303"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:28:53 GMT",
          "size": "532kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a framework for assessing image quality in fundus images for medical applications, involving the training of models specifically for image quality assessment, not the data processing or engineering for LLMs."
      }
    },
    {
      "id": "2506.20333",
      "abstract": "Hepatic echinococcosis (HE) is a widespread parasitic disease in underdeveloped pastoral areas with limited medical resources. While CNN-based and Transformer-based models have been widely applied to medical image segmentation, CNNs lack global context modeling due to local receptive fields, and Transformers, though capable of capturing long-range dependencies, are computationally expensive. Recently, state space models (SSMs), such as Mamba, have gained attention for their ability to model long sequences with linear complexity. In this paper, we propose EAGLE, a U-shaped network composed of a Progressive Visual State Space (PVSS) encoder and a Hybrid Visual State Space (HVSS) decoder that work collaboratively to achieve efficient and accurate segmentation of hepatic echinococcosis (HE) lesions. The proposed Convolutional Vision State Space Block (CVSSB) module is designed to fuse local and global features, while the Haar Wavelet Transformation Block (HWTB) module compresses spatial information into the channel dimension to enable lossless downsampling. Due to the lack of publicly available HE datasets, we collected CT slices from 260 patients at a local hospital. Experimental results show that EAGLE achieves state-of-the-art performance with a Dice Similarity Coefficient (DSC) of 89.76%, surpassing MSVM-UNet by 1.61%.",
      "authors": [
        "Jiayan Chen",
        "Kai Li",
        "Yulu Zhao",
        "Jianqiang Huang",
        "Zhan Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20333",
        "HTML": "https://arxiv.org/html/2506.20333",
        "PDF": "https://arxiv.org/pdf/2506.20333"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:42:05 GMT",
          "size": "5433kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "EAGLE: An Efficient Global Attention Lesion Segmentation Model for Hepatic Echinococcosis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study focuses on a medical image segmentation model and dataset collection for hepatic echinococcosis, unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20344",
      "abstract": "Despite its wide range of applications across various domains, the optimization foundations of deep matrix factorization (DMF) remain largely open. In this work, we aim to fill this gap by conducting a comprehensive study of the loss landscape of the regularized DMF problem. Toward this goal, we first provide a closed-form expression of all critical points. Building on this, we establish precise conditions under which a critical point is a local minimizer, a global minimizer, a strict saddle point, or a non-strict saddle point. Leveraging these results, we derive a necessary and sufficient condition under which each critical point is either a local minimizer or a strict saddle point. This provides insights into why gradient-based methods almost always converge to a local minimizer of the regularized DMF problem. Finally, we conduct numerical experiments to visualize its loss landscape under different settings to support our theory.",
      "authors": [
        "Po Chen",
        "Rujun Jiang",
        "Peng Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20344",
        "HTML": "https://arxiv.org/html/2506.20344",
        "PDF": "https://arxiv.org/pdf/2506.20344"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:51:41 GMT",
          "size": "1722kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Complete Loss Landscape Analysis of Regularized Deep Matrix Factorization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of this paper is on the optimization of deep matrix factorization, analyzing its loss landscape, without discussion on aspects of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20355",
      "abstract": "This study investigates the design choices of parameterized quantum circuits (PQCs) within quantum and hybrid convolutional neural network (HQNN and QCNN) architectures, applied to the task of satellite image classification using the EuroSAT dataset. We systematically evaluate the performance implications of data encoding techniques, variational ans\\\"atze, and measurement in approx. 500 distinct model configurations. Our analysis reveals a clear hierarchy of influence on model performance. For hybrid architectures, which were benchmarked against their direct classical equivalents (e.g. the same architecture with the PQCs removed), the data encoding strategy is the dominant factor, with validation accuracy varying over 30% for distinct embeddings. In contrast, the selection of variational ans\\\"atze and measurement basis had a comparatively marginal effect, with validation accuracy variations remaining below 5%. For purely quantum models, restricted to amplitude encoding, performance was most dependent on the measurement protocol and the data-to-amplitude mapping. The measurement strategy varied the validation accuracy by up to 30% and the encoding mapping by around 8 percentage points.",
      "authors": [
        "Jes\\'us Lozano-Cruz",
        "Albert Nieto-Morales",
        "Oriol Ball\\'o-Gimbernat",
        "Adan Garriga",
        "Ant\\'on Rodr\\'iguez-Otero",
        "Alejandro Borrallo-Rentero"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20355",
        "HTML": "https://arxiv.org/html/2506.20355",
        "PDF": "https://arxiv.org/pdf/2506.20355"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:10:11 GMT",
          "size": "2739kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Practical insights on the effect of different encodings, ans\\\"atze and measurements in quantum and hybrid convolutional neural networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research explores quantum and hybrid convolutional neural networks for satellite image classification. It pertains to model architecture and quantum circuits rather than data preparation methodologies for LLM training."
      }
    },
    {
      "id": "2506.20361",
      "abstract": "Human speech perception is multimodal. In natural speech, lip movements can precede corresponding voicing by a non-negligible gap of 100-300 ms, especially for specific consonants, affecting the time course of neural phonetic encoding in human listeners. However, it remains unexplored whether self-supervised learning models, which have been used to simulate audio-visual integration in humans, can capture this asynchronicity between audio and visual cues. We compared AV-HuBERT, an audio-visual model, with audio-only HuBERT, by using linear classifiers to track their phonetic decodability over time. We found that phoneme information becomes available in AV-HuBERT embeddings only about 20 ms before HuBERT, likely due to AV-HuBERT's lower temporal resolution and feature concatenation process. It suggests AV-HuBERT does not adequately capture the temporal dynamics of multimodal speech perception, limiting its suitability for modeling the multimodal speech perception process.",
      "authors": [
        "Yi Wang",
        "Oli Danyi Liu",
        "Peter Bell"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20361",
        "HTML": "https://arxiv.org/html/2506.20361",
        "PDF": "https://arxiv.org/pdf/2506.20361"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:23:12 GMT",
          "size": "1178kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The role of audio-visual integration in the time course of phonetic encoding in self-supervised speech models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research investigates audio-visual integration in phonetic encoding within self-supervised speech models, without focusing on LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20406",
      "abstract": "Dynamic treatment regimes (DTRs) provide a principled framework for optimizing sequential decision-making in domains where decisions must adapt over time in response to individual trajectories, such as healthcare, education, and digital interventions. However, existing statistical methods often rely on strong positivity assumptions and lack robustness under partial data coverage, while offline reinforcement learning approaches typically focus on average training performance, lack statistical guarantees, and require solving complex optimization problems. To address these challenges, we propose POLAR, a novel pessimistic model-based policy learning algorithm for offline DTR optimization. POLAR estimates the transition dynamics from offline data and quantifies uncertainty for each history-action pair. A pessimistic penalty is then incorporated into the reward function to discourage actions with high uncertainty. Unlike many existing methods that focus on average training performance, POLAR directly targets the suboptimality of the final learned policy and offers theoretical guarantees, without relying on computationally intensive minimax or constrained optimization procedures. To the best of our knowledge, POLAR is the first model-based DTR method to provide both statistical and computational guarantees, including finite-sample bounds on policy suboptimality. Empirical results on both synthetic data and the MIMIC-III dataset demonstrate that POLAR outperforms state-of-the-art methods and yields near-optimal, history-aware treatment strategies.",
      "authors": [
        "Ruijia Zhang",
        "Zhengling Qi",
        "Yue Wu",
        "Xiangyu Zhang",
        "Yanxun Xu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20406",
        "HTML": "https://arxiv.org/html/2506.20406",
        "PDF": "https://arxiv.org/pdf/2506.20406"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:22:57 GMT",
          "size": "247kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "POLAR: A Pessimistic Model-based Policy Learning Algorithm for Dynamic Treatment Regimes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on proposing a policy learning algorithm (POLAR) for dynamic treatment regimes in offline reinforcement learning contexts, without addressing data collection or processing for LLMs."
      }
    },
    {
      "id": "2506.20407",
      "abstract": "Accurate gestational age (GA) estimation, ideally through fetal ultrasound measurement, is a crucial aspect of providing excellent antenatal care. However, deriving GA from manual fetal biometric measurements depends on the operator and is time-consuming. Hence, automatic computer-assisted methods are demanded in clinical practice. In this paper, we present a novel feature fusion framework to estimate GA using fetal ultrasound images without any measurement information. We adopt a deep learning model to extract deep representations from ultrasound images. We extract radiomic features to reveal patterns and characteristics of fetal brain growth. To harness the interpretability of radiomics in medical imaging analysis, we estimate GA by fusing radiomic features and deep representations. Our framework estimates GA with a mean absolute error of 8.0 days across three trimesters, outperforming current machine learning-based methods at these gestational ages. Experimental results demonstrate the robustness of our framework across different populations in diverse geographical regions. Our code is publicly available on \\href{https://github.com/13204942/RadiomicsImageFusion_FetalUS}{GitHub}.",
      "authors": [
        "Fangyijie Wang",
        "Yuan Liang",
        "Sourav Bhattacharjee",
        "Abey Campbell",
        "Kathleen M. Curran",
        "Gu\\'enol\\'e Silvestre"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20407",
        "HTML": "https://arxiv.org/html/2506.20407",
        "PDF": "https://arxiv.org/pdf/2506.20407"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:23:35 GMT",
          "size": "2122kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about gestational age estimation using a feature fusion framework that involves deep learning models applied to ultrasound images, without discussing data processing for LLM training."
      }
    },
    {
      "id": "2506.20411",
      "abstract": "We revisit a version of the classic occupancy scheme, where balls are thrown until almost all boxes receive a given number of balls. Special cases are widely known as coupon-collectors and dixie cup problems. We show that as the number of boxes tends to infinity, the distribution of the maximal occupancy count does not converge, but can be approximated by a convolution of two Gumbel distributions, with the approximating distribution having oscillations close to periodic on a logarithmic scale. We pursue two approaches: one relies on lattice point processes obtained by poissonisation of the number of balls and boxes, and the other employs interpolation of the multiset of occupancy counts to a point process on reals. This way we gain considerable insight in known asymptotics obtained previously by mostly analytic tools. Further results concern the moments of maximal occupancy counts and ties for the maximum.",
      "authors": [
        "Alexander Gnedin",
        "Svante Janson",
        "Yaakov Malinovsky"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20411",
        "HTML": "https://arxiv.org/html/2506.20411",
        "PDF": "https://arxiv.org/pdf/2506.20411"
      },
      "subjects": [
        "Probability (math.PR)",
        "Discrete Mathematics (cs.DM)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:25:03 GMT",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Maximal Counts in the Stopped Occupancy Problem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses a version of the classic occupancy scheme in probability theory, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2506.20425",
      "abstract": "Linear mixed models (LMMs), which incorporate fixed and random effects, are key tools for analyzing heterogeneous data, such as in personalized medicine or adaptive marketing. Nowadays, this type of data is increasingly wide, sometimes containing thousands of candidate predictors, necessitating sparsity for prediction and interpretation. However, existing sparse learning methods for LMMs do not scale well beyond tens or hundreds of predictors, leaving a large gap compared with sparse methods for linear models, which ignore random effects. This paper closes the gap with a new $\\ell_0$ regularized method for LMM subset selection that can run on datasets containing thousands of predictors in seconds to minutes. On the computational front, we develop a coordinate descent algorithm as our main workhorse and provide a guarantee of its convergence. We also develop a local search algorithm to help traverse the nonconvex optimization surface. Both algorithms readily extend to subset selection in generalized LMMs via a penalized quasi-likelihood approximation. On the statistical front, we provide a finite-sample bound on the Kullback-Leibler divergence of the new method. We then demonstrate its excellent performance in synthetic experiments and illustrate its utility on two datasets from biology and journalism.",
      "authors": [
        "Ryan Thompson",
        "Matt P. Wand",
        "Joanna J. J. Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20425",
        "HTML": "https://arxiv.org/html/2506.20425",
        "PDF": "https://arxiv.org/pdf/2506.20425"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:39:30 GMT",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Scalable Subset Selection in Linear Mixed Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study addresses scalable subset selection in linear mixed models, with no discussion of LLM training data processing."
      }
    },
    {
      "id": "2506.20470",
      "abstract": "We analyze pivot probabilities in Gaussian elimination with partial pivoting (GEPP) for $2 \\times 2$ random matrix ensembles. For GUE matrices, we resolve a previously reported discrepancy between theoretical predictions and empirical observations by deriving the exact pivot probability under standard LAPACK-style implementations. We further show that Dumitriu-Edelman tridiagonal $\\beta$-ensembles agree with the earlier theoretical expectations. Finally, we propose an open question on pivot behavior under alternative norm choices, supported by empirical evidence.",
      "authors": [
        "Kenji Gunawan",
        "John Peca-Medlin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20470",
        "HTML": "https://arxiv.org/html/2506.20470",
        "PDF": "https://arxiv.org/pdf/2506.20470"
      },
      "subjects": [
        "Probability (math.PR)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:19:35 GMT",
          "size": "1052kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Pivot probabilities and norm effects in Gaussian elimination for $\\beta$-ensembles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper analyzes mathematical properties of Gaussian elimination and does not pertain to the processing or engineering of training data for LLMs."
      }
    },
    {
      "id": "2506.20492",
      "abstract": "In this work, we address the problem of finite-time stabilization for a class of bilinear system. We propose a decomposition-based approach in which the nominal system is split into two subsystems, one of which is inherently finite-time stable without control. This allows the stabilization analysis to focus solely on the remaining subsystem. To ensure the well-posedness of the closed-loop system, we establish sufficient conditions on the system and control operators. The stabilization results are then derived using a suitable Lyapunov function and an observation condition. The effectiveness of the proposed approach is demonstrated through examples involving both parabolic and hyperbolic infinite-dimensional systems.",
      "authors": [
        "Kamal Fenza",
        "Moussa Labbadi and Mohamed Ouzahra"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20492",
        "HTML": "https://arxiv.org/html/2506.20492",
        "PDF": "https://arxiv.org/pdf/2506.20492"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:38:17 GMT",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Decomposition Method for Finite-Time Stabilization of Bilinear Systems with Applications to Parabolic and Hyperbolic Equations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on stabilization techniques for bilinear systems, without discussing or contributing to methods involving LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20513",
      "abstract": "This study proposes a high-performance dual-parameter full waveform inversion framework (FWI) for ground-penetrating radar (GPR), accelerated through the hybrid compilation of CUDA kernel functions and PyTorch. The method leverages the computational efficiency of GPU programming while preserving the flexibility and usability of Python-based deep learning frameworks. By integrating customized CUDA kernels into PyTorch's automatic differentiation mechanism, the framework enables accurate and efficient inversion of both dielectric permittivity and electrical conductivity. Experimental evaluations on synthetic data and real wavefield data demonstrate that the proposed method achieves dual-parameter FWI for GPR data while maintaining high accuracy. Moreover, the framework is flexible and extensible, supporting optional regularization strategies such as total variation and multi-scale inversion. These features make the proposed approach a practical and scalable framework for rapid GPR-based subsurface imaging in applications including civil engineering, environmental monitoring, and geophysical exploration.",
      "authors": [
        "Lei Liu",
        "Chao Song",
        "Liangsheng He",
        "Silin Wang",
        "Xuan Feng",
        "Cai Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20513",
        "HTML": "https://arxiv.org/html/2506.20513",
        "PDF": "https://arxiv.org/pdf/2506.20513"
      },
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:00:33 GMT",
          "size": "12771kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fast ground penetrating radar dual-parameter full waveform inversion method accelerated by hybrid compilation of CUDA kernel function and PyTorch",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on ground-penetrating radar data inversion using a hybrid compilation method, with no mention of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20527",
      "abstract": "Period finding and phase estimation are fundamental in quantum computing. Prior work has established lower bounds on their success probabilities. We improve these results by deriving tight upper and lower bounds on the success probability that converge to 1.",
      "authors": [
        "Malik Magdon-Ismail and Khai Dong"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20527",
        "HTML": "https://arxiv.org/html/2506.20527",
        "PDF": "https://arxiv.org/pdf/2506.20527"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:14:59 GMT",
          "size": "67kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Tight Success Probabilities for Quantum Period Finding and Phase Estimation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with theoretical aspects of quantum computing, discussing probabilities in quantum period finding and phase estimation. It is not related to LLM training data processing."
      }
    },
    {
      "id": "2506.20533",
      "abstract": "Robust subspace estimation is fundamental to many machine learning and data analysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and empirically effective approach to this problem, yet its theoretical properties remain poorly understood. This paper establishes that, under deterministic conditions, a variant of IRLS with dynamic smoothing regularization converges linearly to the underlying subspace from any initialization. We extend these guarantees to affine subspace estimation, a setting that lacks prior recovery theory. Additionally, we illustrate the practical benefits of IRLS through an application to low-dimensional neural network training. Our results provide the first global convergence guarantees for IRLS in robust subspace recovery and, more broadly, for nonconvex IRLS on a Riemannian manifold.",
      "authors": [
        "Gilad Lerman",
        "Kang Li",
        "Tyler Maunu",
        "Teng Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20533",
        "HTML": "https://arxiv.org/html/2506.20533",
        "PDF": "https://arxiv.org/pdf/2506.20533"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:23:32 GMT",
          "size": "5435kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research concerns robust subspace recovery and theoretical analysis of IRLS methods, not related to LLM training data."
      }
    },
    {
      "id": "2506.20554",
      "abstract": "Traditional wind farm control operates each turbine independently to maximize individual power output. However, coordinated wake steering across the entire farm can substantially increase the combined wind farm energy production. Although dynamic closed-loop control has proven effective in flow control applications, wind farm optimization has relied primarily on static, low-fidelity simulators that ignore critical turbulent flow dynamics. In this work, we present the first reinforcement learning (RL) controller integrated directly with high-fidelity large-eddy simulation (LES), enabling real-time response to atmospheric turbulence through collaborative, dynamic control strategies. Our RL controller achieves a 4.30% increase in wind farm power output compared to baseline operation, nearly doubling the 2.19% gain from static optimal yaw control obtained through Bayesian optimization. These results establish dynamic flow-responsive control as a transformative approach to wind farm optimization, with direct implications for accelerating renewable energy deployment to net-zero targets.",
      "authors": [
        "Andrew Mole",
        "Max Weissenbacher",
        "Georgios Rigas",
        "Sylvain Laizet"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20554",
        "HTML": "https://arxiv.org/html/2506.20554",
        "PDF": "https://arxiv.org/pdf/2506.20554"
      },
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:53:12 GMT",
          "size": "12924kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Reinforcement Learning Increases Wind Farm Power Production by Enabling Closed-Loop Collaborative Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research presents reinforcement learning applications to improve wind farm efficiency and does not engage with the topic of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.20555",
      "abstract": "For the first time, we implement the deep-neural-network-based variational Monte Carlo approach for the multiquark bound states, whose complexity surpasses that of electron or nucleon systems due to strong SU(3) color interactions. We design a novel and high-efficiency architecture, DeepQuark, to address the unique challenges in multiquark systems such as stronger correlations, extra discrete quantum numbers, and intractable confinement interaction. Our method demonstrates competitive performance with state-of-the-art approaches, including diffusion Monte Carlo and Gaussian expansion method, in the nucleon, doubly heavy tetraquark, and fully heavy tetraquark systems. Notably, it outperforms existing calculations for pentaquarks, exemplified by the triply heavy pentaquark. For the nucleon, we successfully incorporate three-body flux-tube confinement interactions without additional computational costs. In tetraquark systems, we consistently describe hadronic molecule $T_{cc}$ and compact tetraquark $T_{bb}$ with an unbiased form of wave function ansatz. In the pentaquark sector, we obtain weakly bound $\\bar D^*\\Xi_{cc}^*$ molecule $P_{cc\\bar c}(5715)$ with $S=\\frac{5}{2}$ and its bottom partner $P_{bb\\bar b}(15569)$. They can be viewed as the analogs of the molecular $T_{cc}$. We recommend experimental search of $P_{cc\\bar c}(5715)$ in the D-wave $J/\\psi \\Lambda_c$ channel. DeepQuark holds great promise for extension to larger multiquark systems, overcoming the computational barriers in conventional methods. It also serves as a powerful framework for exploring confining mechanism beyond two-body interactions in multiquark states, which may offer valuable insights into nonperturbative QCD and general many-body physics.",
      "authors": [
        "Wei-Lin Wu",
        "Lu Meng",
        "Shi-Lin Zhu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20555",
        "HTML": "https://arxiv.org/html/2506.20555",
        "PDF": "https://arxiv.org/pdf/2506.20555"
      },
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Artificial Intelligence (cs.AI)",
        "High Energy Physics - Experiment (hep-ex)",
        "High Energy Physics - Lattice (hep-lat)",
        "Nuclear Theory (nucl-th)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:53:18 GMT",
          "size": "900kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DeepQuark: deep-neural-network approach to multiquark bound states",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with applying deep neural networks to study multiquark bound states in physics, with no relevance to LLM training data processing or engineering tasks."
      }
    },
    {
      "id": "2506.20589",
      "abstract": "Recent developments in the Internet of Bio-Nano Things (IoBNT) are laying the groundwork for innovative applications across the healthcare sector. Nanodevices designed to operate within the body, managed remotely via the internet, are envisioned to promptly detect and actuate on potential diseases. In this vision, an inherent challenge arises due to the limited capabilities of individual nanosensors; specifically, nanosensors must communicate with one another to collaborate as a cluster. Aiming to research the boundaries of the clustering capabilities, this survey emphasizes data-driven communication strategies in molecular communication (MC) channels as a means of linking nanosensors. Relying on the flexibility and robustness of machine learning (ML) methods to tackle the dynamic nature of MC channels, the MC research community frequently refers to neural network (NN) architectures. This interdisciplinary research field encompasses various aspects, including the use of NNs to facilitate communication in MC environments, their implementation at the nanoscale, explainable approaches for NNs, and dataset generation for training. Within this survey, we provide a comprehensive analysis of fundamental perspectives on recent trends in NN architectures for MC, the feasibility of their implementation at the nanoscale, applied explainable artificial intelligence (XAI) techniques, and the accessibility of datasets along with best practices for their generation. Additionally, we offer open-source code repositories that illustrate NN-based methods to support reproducible research for key MC scenarios. Finally, we identify emerging research challenges, such as robust NN architectures, biologically integrated NN modules, and scalable training strategies.",
      "authors": [
        "Jorge Torres G\\'omez and Pit Hofmann and Lisa Y. Debus and Osman Tugay Ba\\c{s}aran and Sebastian Lotter and Roya Khanzadeh and Stefan Angerbauer and Bige Deniz Unluturk and Sergi Abadal and Werner Haselmayr and Frank H.P. Fitzek and Robert Schober and Falko Dressler"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20589",
        "HTML": "https://arxiv.org/html/2506.20589",
        "PDF": "https://arxiv.org/pdf/2506.20589"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Emerging Technologies (cs.ET)",
        "Other Quantitative Biology (q-bio.OT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:28:30 GMT",
          "size": "4111kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Communicating Smartly in Molecular Communication Environments: Neural Networks in the Internet of Bio-Nano Things",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on communication strategies and neural networks in molecular communication environments, particularly for nanosensors, and does not deal with the processing or engineering of training data for LLMs."
      }
    },
    {
      "id": "2506.20614",
      "abstract": "In recent decades, the use of 4D Flow MRI images has enabled the quantification of velocity fields within a volume of interest and along the cardiac cycle. However, the lack of resolution and the presence of noise in these biomarkers are significant issues. As indicated by recent studies, it appears that biomarkers such as wall shear stress are particularly impacted by the poor resolution of vessel segmentation. The Phase Contrast Magnetic Resonance Angiography (PC-MRA) is the state-of-the-art method to facilitate segmentation. The objective of this work is to introduce a new handcraft feature that provides a novel visualisation of 4D Flow MRI images, which is useful in the segmentation task. This feature, termed Weighted Mean Frequencies (WMF), is capable of revealing the region in three dimensions where a voxel has been passed by pulsatile flow. Indeed, this feature is representative of the hull of all pulsatile velocity voxels. The value of the feature under discussion is illustrated by two experiments. The experiments involved segmenting 4D Flow MRI images using optimal thresholding and deep learning methods. The results obtained demonstrate a substantial enhancement in terms of IoU and Dice, with a respective increase of 0.12 and 0.13 in comparison with the PC-MRA feature, as evidenced by the deep learning task. This feature has the potential to yield valuable insights that could inform future segmentation processes in other vascular regions, such as the heart or the brain.",
      "authors": [
        "Simon Perrin",
        "S\\'ebastien Levilly",
        "Huajun Sun",
        "Harold Mouch\\`ere",
        "Jean-Michel Serfaty"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20614",
        "HTML": "https://arxiv.org/html/2506.20614",
        "PDF": "https://arxiv.org/pdf/2506.20614"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:04:00 GMT",
          "size": "898kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a new feature for 4D Flow MRI segmentation and discusses its application in improving segmentation quality. It does not involve LLM training data engineering or processing."
      }
    },
    {
      "id": "2506.20630",
      "abstract": "In this paper, we study a class of stochastic and finite-sum convex optimization problems with deterministic constraints. Existing methods typically aim to find an $\\epsilon$-$expectedly\\ feasible\\ stochastic\\ optimal$ solution, in which the expected constraint violation and expected optimality gap are both within a prescribed tolerance $\\epsilon$. However, in many practical applications, constraints must be nearly satisfied with certainty, rendering such solutions potentially unsuitable due to the risk of substantial violations. To address this issue, we propose stochastic first-order methods for finding an $\\epsilon$-$surely\\ feasible\\ stochastic\\ optimal$ ($\\epsilon$-SFSO) solution, where the constraint violation is deterministically bounded by $\\epsilon$ and the expected optimality gap is at most $\\epsilon$. Our methods apply an accelerated stochastic gradient (ASG) scheme or a modified variance-reduced ASG scheme $only\\ once$ to a sequence of quadratic penalty subproblems with appropriately chosen penalty parameters. We establish first-order oracle complexity bounds for the proposed methods in computing an $\\epsilon$-SFSO solution. As a byproduct, we also derive first-order oracle complexity results for sample average approximation method in computing an $\\epsilon$-SFSO solution of the stochastic optimization problem using our proposed methods to solve the sample average problem.",
      "authors": [
        "Zhaosong Lu and Yifeng Xiao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20630",
        "HTML": "https://arxiv.org/html/2506.20630",
        "PDF": "https://arxiv.org/pdf/2506.20630"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:26:02 GMT",
          "size": "241kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "First-order methods for stochastic and finite-sum convex optimization with deterministic constraints",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on stochastic and convex optimization problems with deterministic constraints, without addressing any aspects of LLM training data processing."
      }
    },
    {
      "id": "1801.07029",
      "abstract": "Cloud-RAN (C-RAN) is a cellular network architecture where processing units, previously attached to antennas, are centralized in data centers. The main challenge in meeting protocol time constraints is minimizing the latency of periodic messages exchanged between antennas and processing units. We demonstrate that statistical multiplexing introduces significant logical latency due to buffering at network nodes to prevent collisions. To address this, we propose a deterministic scheme for periodic message transmission without collisions, eliminating latency caused by buffering.\n  We develop several algorithms to compute such schemes for star-routed networks, a common topology where all antennas share a single link. First, we show that deterministic transmission is possible without buffering when routes are short or network load is low. Under high load, we allow buffering at processing units and introduce the Periodic Minimal Latency Scheduling (PMLS) algorithm, adapted from classical scheduling methods. Experimental results indicate that even at full load, PMLS finds deterministic transmission schemes with negligible logical latency, whereas statistical multiplexing incurs substantial delays. Moreover, PMLS runs in polynomial time and scales efficiently to hundreds of antennas. Building on this approach, we also derive low-latency periodic transmission schemes that coexist with additional random network traffic. This article extends previous work presented at ICT.",
      "authors": [
        "Dominique Barth",
        "Ma\\\"el Guiraud",
        "Yann Strozecki"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/1801.07029",
        "HTML": "https://arxiv.org/html/1801.07029",
        "PDF": "https://arxiv.org/pdf/1801.07029"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 22 Jan 2018 10:24:48 GMT",
          "size": "139kb",
          "version": "v1"
        },
        {
          "date": "Tue, 19 Jun 2018 10:00:59 GMT",
          "size": "212kb",
          "version": "v2"
        },
        {
          "date": "Fri, 07 Jun 2019 11:50:51 GMT",
          "size": "212kb",
          "version": "v3"
        },
        {
          "date": "Thu, 08 Apr 2021 15:12:53 GMT",
          "size": "630kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 10:05:41 GMT",
          "size": "608kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Deterministic Scheduling of Periodic Messages for Low Latency in Cloud RAN",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses deterministic scheduling in Cloud-RAN networks to minimize message latency. It does not address LLM training data processing or engineering."
      }
    },
    {
      "id": "2103.15589",
      "abstract": "Backpropagation through time (BPTT) is a technique of updating tuned parameters within recurrent neural networks (RNNs). Several attempts at creating such an algorithm have been made including: Nth Ordered Approximations and Truncated-BPTT. These methods approximate the backpropagation gradients under the assumption that the RNN only utilises short-term dependencies. This is an acceptable assumption to make for the current state of artificial neural networks. As RNNs become more advanced, a shift towards influence by long-term dependencies is likely. Thus, a new method for backpropagation is required. We propose using the 'discrete forward sensitivity equation' and a variant of it for single and multiple interacting recurrent loops respectively. This solution is exact and also allows the network's parameters to vary between each subsequent step, however it does require the computation of a Jacobian.",
      "authors": [
        "George Bird",
        "Maxim E. Polivoda"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.15589",
        "HTML": "https://arxiv.org/html/2103.15589",
        "PDF": "https://arxiv.org/pdf/2103.15589"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 26 Mar 2021 15:55:54 GMT",
          "size": "11kb",
          "version": "v1"
        },
        {
          "date": "Sun, 18 Apr 2021 16:08:00 GMT",
          "size": "11kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 12:04:53 GMT",
          "size": "12kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Backpropagation Through Time For Networks With Long-Term Dependencies",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving backpropagation algorithms for RNNs, specifically addressing long-term dependencies. It does not relate to LLM training data processing or engineering."
      },
      "tasks": []
    },
    {
      "id": "2211.06665",
      "abstract": "Reinforcement Learning (RL) is a popular machine learning paradigm where intelligent agents interact with the environment to fulfill a long-term goal. Driven by the resurgence of deep learning, Deep RL (DRL) has witnessed great success over a wide spectrum of complex control tasks. Despite the encouraging results achieved, the deep neural network-based backbone is widely deemed as a black box that impedes practitioners to trust and employ trained agents in realistic scenarios where high security and reliability are essential. To alleviate this issue, a large volume of literature devoted to shedding light on the inner workings of the intelligent agents has been proposed, by constructing intrinsic interpretability or post-hoc explainability. In this survey, we provide a comprehensive review of existing works on eXplainable RL (XRL) and introduce a new taxonomy where prior works are clearly categorized into model-explaining, reward-explaining, state-explaining, and task-explaining methods. We also review and highlight RL methods that conversely leverage human knowledge to promote learning efficiency and performance of agents while this kind of method is often ignored in XRL field. Some challenges and opportunities in XRL are discussed. This survey intends to provide a high-level summarization of XRL and to motivate future research on more effective XRL solutions. Corresponding open source codes are collected and categorized at https://github.com/Plankson/awesome-explainable-reinforcement-learning.",
      "authors": [
        "Yunpeng Qing",
        "Shunyu Liu",
        "Jie Song",
        "Huiqiong Wang",
        "Mingli Song"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.06665",
        "HTML": "https://arxiv.org/html/2211.06665",
        "PDF": "https://arxiv.org/pdf/2211.06665"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 12 Nov 2022 13:52:06 GMT",
          "size": "727kb",
          "version": "v1"
        },
        {
          "date": "Tue, 15 Nov 2022 07:49:44 GMT",
          "size": "727kb",
          "version": "v2"
        },
        {
          "date": "Thu, 08 Dec 2022 04:39:24 GMT",
          "size": "740kb",
          "version": "v3"
        },
        {
          "date": "Wed, 01 Nov 2023 13:46:30 GMT",
          "size": "733kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 12:31:31 GMT",
          "size": "663kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Survey on Explainable Reinforcement Learning: Concepts, Algorithms, Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The survey paper discusses explainable reinforcement learning and categorizes XRL methods. It does not cover LLM training data processing topics."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/plankson/awesome-explainable-reinforcement-learning"
      ]
    },
    {
      "id": "2211.08071",
      "abstract": "DETR is a novel end-to-end transformer architecture object detector, which significantly outperforms classic detectors when scaling up. In this paper, we focus on the compression of DETR with knowledge distillation. While knowledge distillation has been well-studied in classic detectors, there is a lack of researches on how to make it work effectively on DETR. We first provide experimental and theoretical analysis to point out that the main challenge in DETR distillation is the lack of consistent distillation points. Distillation points refer to the corresponding inputs of the predictions for student to mimic, which have different formulations in CNN detector and DETR, and reliable distillation requires sufficient distillation points which are consistent between teacher and student.\n  Based on this observation, we propose the first general knowledge distillation paradigm for DETR (KD-DETR) with consistent distillation points sampling, for both homogeneous and heterogeneous distillation. Specifically, we decouple detection and distillation tasks by introducing a set of specialized object queries to construct distillation points for DETR. We further propose a general-to-specific distillation points sampling strategy to explore the extensibility of KD-DETR. Extensive experiments validate the effectiveness and generalization of KD-DETR. For both single-scale DAB-DETR and multis-scale Deformable DETR and DINO, KD-DETR boost the performance of student model with improvements of $2.6\\%-5.2\\%$. We further extend KD-DETR to heterogeneous distillation, and achieves $2.1\\%$ improvement by distilling the knowledge from DINO to Faster R-CNN with ResNet-50, which is comparable with homogeneous distillation methods.The code is available at https://github.com/wennyuhey/KD-DETR.",
      "authors": [
        "Yu Wang",
        "Xin Li",
        "Shengzhao Weng",
        "Gang Zhang",
        "Haixiao Yue",
        "Haocheng Feng",
        "Junyu Han",
        "Errui Ding"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.08071",
        "HTML": "https://arxiv.org/html/2211.08071",
        "PDF": "https://arxiv.org/pdf/2211.08071"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 15 Nov 2022 11:52:30 GMT",
          "size": "2140kb",
          "version": "v1"
        },
        {
          "date": "Wed, 16 Nov 2022 03:01:40 GMT",
          "size": "2140kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 08:20:33 GMT",
          "size": "2258kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "KD-DETR: Knowledge Distillation for Detection Transformer with Consistent Distillation Points Sampling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on knowledge distillation techniques for improving an object detection model (DETR) and does not mention or address training data processing for LLMs."
      },
      "tasks": [
        "General Knowledge",
        "Knowledge Distillation"
      ],
      "repo_urls": [
        "https://github.com/PaddlePaddle/PaddleDetection",
        "https://github.com/2023-MindSpore-4/Code10/tree/main/Focus-DETR"
      ]
    },
    {
      "id": "2304.04971",
      "abstract": "Generative models such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) are widely utilized to model the generative process of user interactions. However, these generative models suffer from intrinsic limitations such as the instability of GANs and the restricted representation ability of VAEs. Such limitations hinder the accurate modeling of the complex user interaction generation procedure, such as noisy interactions caused by various interference factors. In light of the impressive advantages of Diffusion Models (DMs) over traditional generative models in image synthesis, we propose a novel Diffusion Recommender Model (named DiffRec) to learn the generative process in a denoising manner. To retain personalized information in user interactions, DiffRec reduces the added noises and avoids corrupting users' interactions into pure noises like in image synthesis. In addition, we extend traditional DMs to tackle the unique challenges in practical recommender systems: high resource costs for large-scale item prediction and temporal shifts of user preference. To this end, we propose two extensions of DiffRec: L-DiffRec clusters items for dimension compression and conducts the diffusion processes in the latent space; and T-DiffRec reweights user interactions based on the interaction timestamps to encode temporal information. We conduct extensive experiments on three datasets under multiple settings (e.g. clean training, noisy training, and temporal training). The empirical results and in-depth analysis validate the superiority of DiffRec with two extensions over competitive baselines.",
      "authors": [
        "Wenjie Wang",
        "Yiyan Xu",
        "Fuli Feng",
        "Xinyu Lin",
        "Xiangnan He",
        "Tat-Seng Chua"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.04971",
        "HTML": "https://arxiv.org/html/2304.04971",
        "PDF": "https://arxiv.org/pdf/2304.04971"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 11 Apr 2023 04:31:00 GMT",
          "size": "3451kb",
          "version": "v1"
        },
        {
          "date": "Mon, 17 Apr 2023 13:20:22 GMT",
          "size": "3436kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 13:38:45 GMT",
          "size": "3335kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Diffusion Recommender Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a Diffusion Recommender Model for user interaction data in recommender systems, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Image Generation",
        "model",
        "Recommendation Systems"
      ],
      "repo_urls": [
        "https://github.com/yiyanxu/diffrec"
      ]
    },
    {
      "id": "2305.19928",
      "abstract": "Global sentence information is crucial for sequence labeling tasks, where each word in a sentence must be assigned a label. While BiLSTM models are widely used, they often fail to capture sufficient global context for inner words. Previous work has proposed various RNN variants to integrate global sentence information into word representations. However, these approaches suffer from three key limitations: (1) they are slower in both inference and training compared to the original BiLSTM, (2) they cannot effectively supplement global information for transformer-based models, and (3) the high time cost associated with reimplementing and integrating these customized RNNs into existing architectures. In this study, we introduce a simple yet effective mechanism that addresses these limitations. Our approach efficiently supplements global sentence information for both BiLSTM and transformer-based models, with minimal degradation in inference and training speed, and is easily pluggable into current architectures. We demonstrate significant improvements in F1 scores across seven popular benchmarks, including Named Entity Recognition (NER) tasks such as Conll2003, Wnut2017 , and the Chinese named-entity recognition task Weibo, as well as End-to-End Aspect-Based Sentiment Analysis (E2E-ABSA) benchmarks such as Laptop14, Restaurant14, Restaurant15, and Restaurant16. With out any extra strategy, we achieve third highest score on weibo NER benchmark. Compared to CRF, one of the most popular frameworks for sequence labeling, our mechanism achieves competitive F1 scores while offering superior inference and training speed. Code is available at: https://github.com/conglei2XU/Global-Context-Mechanism",
      "authors": [
        "Conglei Xu",
        "Kun Shen",
        "Hongguang Sun",
        "Yang Xu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.19928",
        "HTML": "https://arxiv.org/html/2305.19928",
        "PDF": "https://arxiv.org/pdf/2305.19928"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 31 May 2023 15:05:25 GMT",
          "size": "361kb",
          "version": "v1"
        },
        {
          "date": "Thu, 01 Jun 2023 06:35:18 GMT",
          "size": "362kb",
          "version": "v2"
        },
        {
          "date": "Thu, 08 Jun 2023 14:52:06 GMT",
          "size": "363kb",
          "version": "v3"
        },
        {
          "date": "Fri, 23 Jun 2023 13:47:17 GMT",
          "size": "363kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 03:52:41 GMT",
          "size": "369kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Global Context Mechanism for Sequence Labeling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on improving sequence labeling models by introducing a global context mechanism, with no mention of LLM training data processes or data engineering contributions."
      },
      "tasks": [
        "Aspect-Based Sentiment Analysis",
        "Chinese Named Entity Recognition",
        "named-entity-recognition",
        "Named Entity Recognition (NER)",
        "NER",
        "Part-Of-Speech Tagging",
        "POS",
        "POS Tagging",
        "Sentence",
        "Sentiment Analysis"
      ],
      "repo_urls": [
        "https://github.com/conglei2xu/global-context-mechanism"
      ]
    },
    {
      "id": "2309.05019",
      "abstract": "Diffusion Probabilistic Models (DPMs) have achieved considerable success in generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE or ODE which is time-consuming, numerous fast sampling methods built upon improved differential equation solvers are proposed. The majority of such techniques consider solving the diffusion ODE due to its superior efficiency. However, stochastic sampling could offer additional advantages in generating diverse and high-quality data. In this work, we engage in a comprehensive analysis of stochastic sampling from two aspects: variance-controlled diffusion SDE and linear multi-step SDE solver. Based on our analysis, we propose \\textit{SA-Solver}, which is an improved efficient stochastic Adams method for solving diffusion SDE to generate data with high quality. Our experiments show that \\textit{SA-Solver} achieves: 1) improved or comparable performance compared with the existing state-of-the-art (SOTA) sampling methods for few-step sampling; 2) SOTA FID on substantial benchmark datasets under a suitable number of function evaluations (NFEs). Code is available at https://github.com/scxue/SA-Solver.",
      "authors": [
        "Shuchen Xue",
        "Mingyang Yi",
        "Weijian Luo",
        "Shifeng Zhang",
        "Jiacheng Sun",
        "Zhenguo Li",
        "Zhi-Ming Ma"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.05019",
        "HTML": "https://arxiv.org/html/2309.05019",
        "PDF": "https://arxiv.org/pdf/2309.05019"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 10 Sep 2023 12:44:54 GMT",
          "size": "33768kb",
          "version": "v1"
        },
        {
          "date": "Mon, 04 Mar 2024 10:05:53 GMT",
          "size": "33768kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 18:47:02 GMT",
          "size": "27513kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving the sampling methods for diffusion probabilistic models, specifically through the development of the SA-Solver, but it does not address the processing of training data for large language models."
      },
      "models": [
        {
          "model_path": "PixArt-alpha/PixArt-XL-2-1024-MS",
          "downloads": "27176",
          "likes": "203",
          "trending_score": "2.0",
          "link": "https://huggingface.co/PixArt-alpha/PixArt-XL-2-1024-MS"
        },
        {
          "model_path": "PixArt-alpha/PixArt-XL-2-512x512",
          "downloads": "3083",
          "likes": "17",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PixArt-alpha/PixArt-XL-2-512x512"
        },
        {
          "model_path": "PixArt-alpha/PixArt-XL-2-256x256",
          "downloads": "0",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PixArt-alpha/PixArt-XL-2-256x256"
        },
        {
          "model_path": "PixArt-alpha/PixArt-Sigma-XL-2-1024-MS",
          "downloads": "6714",
          "likes": "90",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PixArt-alpha/PixArt-Sigma-XL-2-1024-MS"
        },
        {
          "model_path": "PixArt-alpha/PixArt-Sigma-XL-2-512-MS",
          "downloads": "0",
          "likes": "11",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PixArt-alpha/PixArt-Sigma-XL-2-512-MS"
        },
        {
          "model_path": "AlanB/SigmaJourney-1024ms",
          "downloads": "11",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/AlanB/SigmaJourney-1024ms"
        }
      ],
      "conference": "sa-solver-stochastic-adams-solver-for-fast",
      "conference_url_abs": "https://openreview.net/forum?id=f6a9XVFYIo",
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/scxue/SA-Solver"
      ]
    },
    {
      "id": "2309.05211",
      "abstract": "Higher-order singular value decomposition (HOSVD) is a celebrated tool for tensor data analysis. The sequential HOSVD was recently generalized to the quaternion domain, while a naive quaternion extension of the classical HOSVD% by De Lathauwer et al., which can be excecuted in parallel, incurs issues. To leverage the power of parallel computing, this work introduces a two-sided quaternion HOSVD (TS-QHOSVD) that can be parallelized on two processors. It is proved that TS-QHOSVD (i) preserves the HOSVD ordering property, (ii) inherits the orthogonality property at the first and the last modes, and (iii) satisfies the weak orthogonality at all modes. The truncated TS-QHOSVD is then developed, with its error bound being established. We apply the proposed model on color video denoising as well as scientific data compression arising from 3D Navier-Stokes equation and Lorentz system to demonstrate its efficacy.",
      "authors": [
        "Hanxin Ya",
        "Yuning Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.05211",
        "HTML": "https://arxiv.org/html/2309.05211",
        "PDF": "https://arxiv.org/pdf/2309.05211"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 11 Sep 2023 03:03:30 GMT",
          "size": "12877kb",
          "version": "v1"
        },
        {
          "date": "Sat, 23 Sep 2023 11:09:11 GMT",
          "size": "6300kb",
          "version": "v2"
        },
        {
          "date": "Tue, 17 Oct 2023 08:27:49 GMT",
          "size": "1784kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 00:46:35 GMT",
          "size": "816kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Parallelizable Quaternion Higher-Order Singular Value Decomposition with Applications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research addresses quaternion higher-order singular value decomposition with applications in data analysis, which is unrelated to the processing of training data for LLMs."
      }
    },
    {
      "id": "2311.08557",
      "abstract": "Pedestrian detection has become a cornerstone for several high-level tasks, including autonomous driving, intelligent transportation, and traffic surveillance. There are several works focussed on pedestrian detection using visible images, mainly in the daytime. However, this task is very intriguing when the environmental conditions change to poor lighting or nighttime. Recently, new ideas have been spurred to use alternative sources, such as Far InfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light conditions. This study reviews recent developments in low-light pedestrian detection approaches. It systematically categorizes and analyses various algorithms from region-based to non-region-based and graph-based learning methodologies by highlighting their methodologies, implementation issues, and challenges. It also outlines the key benchmark datasets that can be used for research and development of advanced pedestrian detection algorithms, particularly in low-light situations.",
      "authors": [
        "Thangarajah Akilan",
        "and Hrishikesh Vachhani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.08557",
        "HTML": "https://arxiv.org/html/2311.08557",
        "PDF": "https://arxiv.org/pdf/2311.08557"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 14 Nov 2023 21:39:15 GMT",
          "size": "13148kb",
          "version": "v1"
        },
        {
          "date": "Thu, 31 Oct 2024 15:52:52 GMT",
          "size": "13127kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 00:47:40 GMT",
          "size": "6954kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of this study is on low-light pedestrian detection using visible and infrared image feeds, and it does not relate to LLM training data processing tasks or methodologies."
      },
      "tasks": [
        "Autonomous Driving",
        "Low-light Pedestrian Detection",
        "Pedestrian Detection"
      ]
    },
    {
      "id": "2311.09410",
      "abstract": "Large Language Models have been demonstrating broadly satisfactory generative abilities for users, which seems to be due to the intensive use of human feedback that refines responses. Nevertheless, suggestibility inherited via human feedback improves the inclination to produce answers corresponding to users' viewpoints. This behaviour is known as sycophancy and depicts the tendency of LLMs to generate misleading responses as long as they align with humans. This phenomenon induces bias and reduces the robustness and, consequently, the reliability of these models. In this paper, we study the suggestibility of Large Language Models (LLMs) to sycophantic behaviour, analysing these tendencies via systematic human-interventions prompts over different tasks. Our investigation demonstrates that LLMs have sycophantic tendencies when answering queries that involve subjective opinions and statements that should elicit a contrary response based on facts. In contrast, when faced with math tasks or queries with an objective answer, they, at various scales, do not follow the users' hints by demonstrating confidence in generating the correct answers.",
      "authors": [
        "Leonardo Ranaldi and Giulia Pucci"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.09410",
        "HTML": "https://arxiv.org/html/2311.09410",
        "PDF": "https://arxiv.org/pdf/2311.09410"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 15 Nov 2023 22:18:33 GMT",
          "size": "9469kb",
          "version": "v1"
        },
        {
          "date": "Fri, 19 Apr 2024 15:36:34 GMT",
          "size": "10899kb",
          "version": "v2"
        },
        {
          "date": "Sun, 28 Apr 2024 08:06:06 GMT",
          "size": "10899kb",
          "version": "v3"
        },
        {
          "date": "Tue, 24 Jun 2025 19:59:56 GMT",
          "size": "3224kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "When Large Language Models contradict humans? Large Language Models' Sycophantic Behaviour",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper investigates sycophantic behavior in large language models but doesn't propose any methods related to LLM training data processing or enhancement."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/ucabcg3/msc_bias_llm_project"
      ]
    },
    {
      "id": "2311.16100",
      "abstract": "Electron cryomicroscopy (cryo-EM) is an imaging technique widely used in structural biology to determine the three-dimensional structure of biological molecules from noisy two-dimensional projections with unknown orientations. As the typical pipeline involves processing large amounts of data, efficient algorithms are crucial for fast and reliable results. The stochastic gradient descent (SGD) algorithm has been used to improve the speed of ab initio reconstruction, which results in a first, low-resolution estimation of the volume representing the molecule of interest, but has yet to be applied successfully in the high-resolution regime, where expectation-maximization algorithms achieve state-of-the-art results, at a high computational cost. In this article, we investigate the conditioning of the optimization problem and show that the large condition number prevents the successful application of gradient descent-based methods at high resolution. Our results include a theoretical analysis of the condition number of the optimization problem in a simplified setting where the individual projection directions are known, an algorithm based on computing a diagonal preconditioner using Hutchinson's diagonal estimator, and numerical experiments showing the improvement in the convergence speed when using the estimated preconditioner with SGD. The preconditioned SGD approach can potentially enable a simple and unified approach to ab initio reconstruction and high-resolution refinement with faster convergence speed and higher flexibility, and our results are a promising step in this direction.",
      "authors": [
        "Bogdan Toader",
        "Marcus A. Brubaker",
        "Roy R. Lederman"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.16100",
        "HTML": "https://arxiv.org/html/2311.16100",
        "PDF": "https://arxiv.org/pdf/2311.16100"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 27 Nov 2023 18:59:32 GMT",
          "size": "1497kb",
          "version": "v1"
        },
        {
          "date": "Wed, 30 Oct 2024 19:27:59 GMT",
          "size": "1483kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 00:53:09 GMT",
          "size": "35920kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Efficient high-resolution refinement in cryo-EM with stochastic gradient descent",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving algorithms for high-resolution refinement in cryo-EM imaging using stochastic gradient descent, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2401.00236",
      "abstract": "We consider an inverse problem for the elastic wave of simultaneously reconstructing the impedance and the geometric information of the bounded body that is occupied by a homogeneous and isotropic elastic medium from the measured Cauchy data. A two-stage reconstruction method is proposed to realize simultaneous reconstruction of multiple targets. In the first step, we restore the aperture information by utilizing the observed Cauchy data that is measured on an accessible part of the boundary. In the second step, we start with the boundary condition and propose a novel iterative method to simultaneously reconstruct the missing boundary and the impedance function. Theoretically, we establish the uniqueness result of the co-inversion problem based on analyzing the properties of the corresponding operators. An explicit derivative is computed for the iterative method. Numerical examples are presented to test the effectiveness and efficiency of the proposed method.",
      "authors": [
        "Yao Sun",
        "Yan Chang and Yukun Guo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.00236",
        "HTML": "https://arxiv.org/html/2401.00236",
        "PDF": "https://arxiv.org/pdf/2401.00236"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 30 Dec 2023 13:54:32 GMT",
          "size": "203kb",
          "version": "v1"
        },
        {
          "date": "Tue, 13 Feb 2024 05:08:49 GMT",
          "size": "207kb",
          "version": "v2"
        },
        {
          "date": "Mon, 18 Mar 2024 03:01:54 GMT",
          "size": "207kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 12:58:50 GMT",
          "size": "2622kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Inverse problems for elastic wave from Partial Cauchy Data: Uniqueness and Co-inversion for Shape and Impedance Function",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study deals with inverse problems in elastic waves, specifically targeting geometric and impedance reconstruction, with no connection to LLM training data processing."
      }
    },
    {
      "id": "2401.01259",
      "abstract": "Concept-based explainability methods use human-understandable intermediaries to produce explanations for machine learning models. These methods assume concept predictions can help understand a model's internal reasoning. In this work, we assess the degree to which such an assumption is true by analyzing whether concept predictors leverage \"relevant\" features to make predictions, a term we call locality. Concept-based models that fail to respect localities also fail to be explainable because concept predictions are based on spurious features, making the interpretation of the concept predictions vacuous. To assess whether concept-based models respect localities, we construct and use three metrics to characterize when models respect localities, complementing our analysis with theoretical results. Each of our metrics captures a different notion of perturbation and assess whether perturbing \"irrelevant\" features impacts the predictions made by a concept predictors. We find that many concept-based models used in practice fail to respect localities because concept predictors cannot always clearly distinguish distinct concepts. Based on these findings, we propose suggestions for alleviating this issue.",
      "authors": [
        "Naveen Raman",
        "Mateo Espinosa Zarlenga",
        "Juyeon Heo",
        "Mateja Jamnik"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01259",
        "HTML": "https://arxiv.org/html/2401.01259",
        "PDF": "https://arxiv.org/pdf/2401.01259"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 02 Jan 2024 16:05:23 GMT",
          "size": "602kb",
          "version": "v1"
        },
        {
          "date": "Tue, 28 May 2024 20:03:53 GMT",
          "size": "4075kb",
          "version": "v2"
        },
        {
          "date": "Sat, 31 Aug 2024 20:03:49 GMT",
          "size": "5382kb",
          "version": "v3"
        },
        {
          "date": "Mon, 23 Jun 2025 07:43:27 GMT",
          "size": "1970kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 17:10:45 GMT",
          "size": "1970kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Do Concept Bottleneck Models Respect Localities?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper examines the explainability of concept bottleneck models by analyzing locality but does not address any aspects related to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/naveenr414/Spurious-Concepts"
      ]
    },
    {
      "id": "2401.13934",
      "abstract": "Capturing voxel-wise spatial correspondence across distinct modalities is crucial for medical image analysis. However, current registration approaches are not practical enough in terms of registration accuracy and clinical applicability. In this paper, we introduce MambaMorph, a novel multi-modality deformable registration framework. Specifically, MambaMorph utilizes a Mamba-based registration module and a fine-grained, yet simple, feature extractor for efficient long-range correspondence modeling and high-dimensional feature learning, respectively. Additionally, we develop a well-annotated brain MR-CT registration dataset, SR-Reg, to address the scarcity of data in multi-modality registration. To validate MambaMorph's multi-modality registration capabilities, we conduct quantitative experiments on both our SR-Reg dataset and a public T1-T2 dataset. The experimental results on both datasets demonstrate that MambaMorph significantly outperforms the current state-of-the-art learning-based registration methods in terms of registration accuracy. Further study underscores the efficiency of the Mamba-based registration module and the lightweight feature extractor, which achieve notable registration quality while maintaining reasonable computational costs and speeds. We believe that MambaMorph holds significant potential for practical applications in medical image registration. The code for MambaMorph is available at: https://github.com/Guo-Stone/MambaMorph.",
      "authors": [
        "Tao Guo and Yinuo Wang and Shihao Shu and Weimin Yuan and Diansheng Chen and Zhouping Tang and Cai Meng and Xiangzhi Bai"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.13934",
        "HTML": "https://arxiv.org/html/2401.13934",
        "PDF": "https://arxiv.org/pdf/2401.13934"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 25 Jan 2024 04:16:45 GMT",
          "size": "793kb",
          "version": "v1"
        },
        {
          "date": "Wed, 28 Feb 2024 00:40:00 GMT",
          "size": "794kb",
          "version": "v2"
        },
        {
          "date": "Mon, 11 Mar 2024 08:46:23 GMT",
          "size": "3751kb",
          "version": "v3"
        },
        {
          "date": "Wed, 13 Mar 2024 01:40:07 GMT",
          "size": "3751kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 11:28:18 GMT",
          "size": "495kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MambaMorph: a Mamba-based Framework for Medical MR-CT Deformable Registration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research introduces a framework for medical image registration and develops a dataset for MR-CT registration, unrelated to LLM training data processing."
      },
      "tasks": [
        "Computed Tomography (CT)",
        "Image Registration",
        "Long-range modeling",
        "Mamba",
        "Medical Image Analysis",
        "Medical Image Registration"
      ],
      "repo_urls": [
        "https://github.com/ziyangwang007/vmambamorph",
        "https://github.com/guo-stone/mambamorph"
      ]
    },
    {
      "id": "2402.13788",
      "abstract": "The work deals with two major topics concerning the numerical analysis of Runge-Kutta-like (RK-like) methods, namely their stability and order of convergence. RK-like methods differ from additive RK methods in that their coefficients are allowed to depend on the solution and the step size. As a result of this, we also refer to them as non-standard additive RK (NSARK) methods. The first major part of this thesis is dedicated to providing a tool for deriving order conditions for NSARK methods. The proposed approach may yield implicit order conditions, which can be rewritten in explicit form using the NB-series of the stages. The obtained explicit order conditions can be further reduced using Gr\\\"obner bases computations. With the presented approach, it was possible for the first time to obtain conditions for the construction of 3rd and 4th order GeCo as well as 4th order MPRK schemes. Moreover, a new fourth order MPRK method is constructed using our theory and the order of convergence is validated numerically. The second major part is concerned with the stability of nonlinear time integrators preserving at least one linear invariant. We discuss how the given approach generalizes the notion of A-stability. We can prove that investigating the Jacobian of the generating map is sufficient to understand the stability of the nonlinear method in a neighborhood of the steady state. This approach allows for the first time the investigation of several modified Patankar. In the case of MPRK schemes, we compute a general stability function in a way that can be easily adapted to the case of PDRS. Finally, the approach from the theory of dynamical systems is used to derive a necessary condition for avoiding unrealistic oscillations of the numerical approximation.",
      "authors": [
        "Thomas Izgin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13788",
        "HTML": "https://arxiv.org/html/2402.13788",
        "PDF": "https://arxiv.org/pdf/2402.13788"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 21 Feb 2024 13:16:11 GMT",
          "size": "6577kb",
          "version": "v1"
        },
        {
          "date": "Thu, 07 Mar 2024 10:17:23 GMT",
          "size": "13375kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 08:17:46 GMT",
          "size": "5732kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Unifying Theory for Runge-Kutta-like Time Integrators: Convergence and Stability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses convergence and stability in Runge-Kutta-like time integrators, focusing on methods in numerical analysis, not related to LLM training data processing."
      }
    },
    {
      "id": "2402.16170",
      "abstract": "This article addresses the nonadaptive and robust output regulation problem of the general nonlinear output feedback system with error output. The global robust output regulation problem for a class of general output feedback nonlinear systems with an uncertain exosystem and high relative degree can be tackled by constructing a linear generic internal model, provided that a continuous nonlinear mapping exists. Leveraging the proposed nonadaptive framework facilitates the conversion of the nonlinear robust output regulation problem into a robust nonadaptive stabilization formulation for the augmented system endowed with Input-to-State Stable dynamics. This approach removes the need for constructing a specific Lyapunov function with positive semi-definite derivatives and avoids the common assumption of linear parameterization of the nonlinear system. The nonadaptive approach is extended by incorporating the nonparametric learning framework to ensure the feasibility of the nonlinear mapping, which can be tackled using a data-driven method. Moreover, the introduced nonparametric learning framework allows the controlled system to learn the dynamics of the steady-state input behaviour from the signal generated from the internal model with the output error as the feedback. As a result, the nonadaptive/nonparametric approach can be advantageous to guarantee the convergence of the estimation and tracking error even when the underlying controlled system dynamics are complex or poorly understood. The effectiveness of the theoretical results is illustrated for a benchmark example: a controlled duffing system and two practical examples: a continuously stirred tank reactor and a continuous bioreactor.",
      "authors": [
        "Shimin Wang and Martin Guay and Richard D. Braatz"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.16170",
        "HTML": "https://arxiv.org/html/2402.16170",
        "PDF": "https://arxiv.org/pdf/2402.16170"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 25 Feb 2024 18:37:39 GMT",
          "size": "468kb",
          "version": "v1"
        },
        {
          "date": "Thu, 10 Apr 2025 21:23:00 GMT",
          "size": "901kb",
          "version": "v2"
        },
        {
          "date": "Sun, 22 Jun 2025 01:56:07 GMT",
          "size": "901kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 14:06:40 GMT",
          "size": "901kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Nonparametric Steady-State Learning for Nonlinear Output Feedback Regulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on nonlinear output feedback regulation through nonparametric learning frameworks, without any relation to LLM training data processing."
      },
      "tasks": []
    },
    {
      "id": "2403.11624",
      "abstract": "Effective recommender systems play a crucial role in accurately capturing user and item attributes that mirror individual preferences. Some existing recommendation techniques have started to shift their focus towards modeling various types of interactive relations between users and items in real-world recommendation scenarios, such as clicks, marking favorites, and purchases on online shopping platforms. Nevertheless, these approaches still grapple with two significant challenges: (1) Insufficient modeling and exploitation of the impact of various behavior patterns formed by multiplex relations between users and items on representation learning, and (2) ignoring the effect of different relations within behavior patterns on the target relation in recommender system scenarios. In this work, we introduce a novel recommendation framework, Dual-Channel Multiplex Graph Neural Network (DCMGNN), which addresses the aforementioned challenges. It incorporates an explicit behavior pattern representation learner to capture the behavior patterns composed of multiplex user-item interactive relations, and includes a relation chain representation learner and a relation chain-aware encoder to discover the impact of various auxiliary relations on the target relation, the dependencies between different relations, and mine the appropriate order of relations in a behavior pattern. Extensive experiments on three real-world datasets demonstrate that our DCMGNN surpasses various state-of-the-art recommendation methods. It outperforms the best baselines by 10.06% and 12.15% on average across all datasets in terms of Recall@10 and NDCG@10, respectively.",
      "authors": [
        "Xiang Li",
        "Chaofan Fu",
        "Zhongying Zhao",
        "Guanjie Zheng",
        "Chao Huang",
        "Yanwei Yu",
        "Junyu Dong"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.11624",
        "HTML": "https://arxiv.org/html/2403.11624",
        "PDF": "https://arxiv.org/pdf/2403.11624"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 18 Mar 2024 09:56:00 GMT",
          "size": "1946kb",
          "version": "v1"
        },
        {
          "date": "Thu, 28 Mar 2024 04:11:28 GMT",
          "size": "1945kb",
          "version": "v2"
        },
        {
          "date": "Fri, 29 Mar 2024 14:20:17 GMT",
          "size": "1945kb",
          "version": "v3"
        },
        {
          "date": "Mon, 17 Feb 2025 09:26:15 GMT",
          "size": "2264kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 08:38:27 GMT",
          "size": "2264kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Dual-Channel Multiplex Graph Neural Networks for Recommendation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a graph neural network approach for recommendation systems and does not address training data processing or engineering for large language models."
      },
      "tasks": [
        "Graph Neural Network",
        "Recommendation Systems",
        "Relation",
        "Representation Learning"
      ]
    },
    {
      "id": "2403.14488",
      "abstract": "Manipulation tasks require robots to reason about cause and effect when interacting with objects. Yet, many data-driven approaches lack causal semantics and thus only consider correlations. We introduce COBRA-PPM, a novel causal Bayesian reasoning architecture that combines causal Bayesian networks and probabilistic programming to perform interventional inference for robot manipulation under uncertainty. We demonstrate its capabilities through high-fidelity Gazebo-based experiments on an exemplar block stacking task, where it predicts manipulation outcomes with high accuracy (Pred Acc: 88.6%) and performs greedy next-best action selection with a 94.2% task success rate. We further demonstrate sim2real transfer on a domestic robot, showing effectiveness in handling real-world uncertainty from sensor noise and stochastic actions. Our generalised and extensible framework supports a wide range of manipulation scenarios and lays a foundation for future work at the intersection of robotics and causality.",
      "authors": [
        "Ricardo Cannizzaro",
        "Michael Groom",
        "Jonathan Routley",
        "Robert Osazuwa Ness",
        "Lars Kunze"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.14488",
        "HTML": "https://arxiv.org/html/2403.14488",
        "PDF": "https://arxiv.org/pdf/2403.14488"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 21 Mar 2024 15:36:26 GMT",
          "size": "12078kb",
          "version": "v1"
        },
        {
          "date": "Thu, 03 Oct 2024 14:16:47 GMT",
          "size": "10744kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 19:26:15 GMT",
          "size": "8961kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research introduces a Bayesian reasoning architecture for robot manipulation and does not involve any aspects related to LLM training data processing."
      },
      "tasks": [
        "Causal Inference",
        "Decision Making",
        "Probabilistic Programming",
        "Robot Manipulation"
      ]
    },
    {
      "id": "2404.07130",
      "abstract": "The paper introduces a finite element method for an Eulerian formulation of partial differential equations governing the transport and diffusion of a scalar quantity in a time-dependent domain. The method follows the idea from Lehrenfeld & Olshanskii [ESAIM: M2AN, 53(2): 585-614, 2019] of a solution extension to realise the Eulerian time-stepping scheme. However, a reformulation of the partial differential equation is suggested to derive a scheme which conserves the quantity under consideration exactly on the discrete level. For the spatial discretisation, the paper considers an unfitted finite element method. Ghost-penalty stabilisation is used to realise the discrete solution extension and gives a scheme robust against arbitrary intersections between the mesh and geometry interface. The stability is analysed for both first- and second-order backward differentiation formula versions of the scheme. Several numerical examples in two and three spatial dimensions are included to illustrate the potential of this method.",
      "authors": [
        "Maxim Olshanskii and Henry von Wahl"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.07130",
        "HTML": "https://arxiv.org/html/2404.07130",
        "PDF": "https://arxiv.org/pdf/2404.07130"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 10 Apr 2024 16:08:13 GMT",
          "size": "12972kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:34:04 GMT",
          "size": "13150kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A conservative Eulerian finite element method for transport and diffusion in moving domains",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about a finite element method for solving partial differential equations, unrelated to processing training data for LLMs."
      },
      "repo_urls": [
        "https://github.com/hvonwah/conserv-eulerian-moving-domian-repro"
      ]
    },
    {
      "id": "2404.13325",
      "abstract": "Time-domain simulations are crucial for ensuring power system stability and avoiding critical scenarios that could lead to blackouts. The next-generation power systems require a significant increase in the computational cost and complexity of these simulations due to additional degrees of uncertainty, non-linearity and states. Physics-Informed Neural Networks (PINN) have been shown to accelerate single-component simulations by several orders of magnitude. However, their application to current time-domain simulation solvers has been particularly challenging since the system's dynamics depend on multiple components. Using a new training formulation, this paper introduces the first natural step to integrate PINNs into multi-component time-domain simulations. We propose PINNs as an alternative to other classical numerical methods for individual components. Once trained, these neural networks approximate component dynamics more accurately for longer time steps. Formulated as an implicit and consistent method with the transient simulation workflow, PINNs speed up simulation time by significantly increasing the time steps used. For explanation clarity, we demonstrate the training, integration, and simulation framework for several combinations of PINNs and numerical solution methods using the IEEE 9-bus system, although the method applies equally well to any power system size.",
      "authors": [
        "Ignasi Ventura Nadal",
        "Jochen Stiasny",
        "Spyros Chatzivasileiadis"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.13325",
        "HTML": "https://arxiv.org/html/2404.13325",
        "PDF": "https://arxiv.org/pdf/2404.13325"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 20 Apr 2024 08:57:34 GMT",
          "size": "349kb",
          "version": "v1"
        },
        {
          "date": "Tue, 21 Jan 2025 21:11:54 GMT",
          "size": "4774kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 21:00:13 GMT",
          "size": "954kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Physics-Informed Neural Networks: a Plug and Play Integration into Power System Dynamic Simulations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the integration of Physics-Informed Neural Networks for power system simulations, without touching on LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/ignvenad/pinns-plug-n-play-integration"
      ]
    },
    {
      "id": "2405.03633",
      "abstract": "Neural field-based SLAM methods typically employ a single, monolithic field as their scene representation. This prevents efficient incorporation of loop closure constraints and limits scalability. To address these shortcomings, we propose a novel RGB-D neural mapping framework in which the scene is represented by a collection of lightweight neural fields which are dynamically anchored to the pose graph of a sparse visual SLAM system. Our approach shows the ability to integrate large-scale loop closures, while requiring only minimal reintegration. Furthermore, we verify the scalability of our approach by demonstrating successful building-scale mapping taking multiple loop closures into account during the optimization, and show that our method outperforms existing state-of-the-art approaches on large scenes in terms of quality and runtime. Our code is available open-source at https://github.com/KTH-RPL/neural_graph_mapping.",
      "authors": [
        "Leonard Bruns",
        "Jun Zhang",
        "Patric Jensfelt"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.03633",
        "HTML": "https://arxiv.org/html/2405.03633",
        "PDF": "https://arxiv.org/pdf/2405.03633"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 06 May 2024 16:50:42 GMT",
          "size": "13269kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:36:35 GMT",
          "size": "16173kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Neural Graph Map: Dense Mapping with Efficient Loop Closure Integration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a framework for neural mapping in SLAM systems, without contributions to LLM training data processing."
      },
      "tasks": []
    },
    {
      "id": "2405.14017",
      "abstract": "With the success of 2D and 3D visual generative models, there is growing interest in generating 4D content. Existing methods primarily rely on text prompts to produce 4D content, but they often fall short of accurately defining complex or rare motions. To address this limitation, we propose MagicPose4D, a novel framework for refined control over both appearance and motion in 4D generation. Unlike current 4D generation methods, MagicPose4D accepts monocular videos or mesh sequences as motion prompts, enabling precise and customizable motion control. MagicPose4D comprises two key modules: (i) Dual-Phase 4D Reconstruction Module, which operates in two phases. The first phase focuses on capturing the model's shape using accurate 2D supervision and less accurate but geometrically informative 3D pseudo-supervision without imposing skeleton constraints. The second phase extracts the 3D motion (skeleton poses) using more accurate pseudo-3D supervision, obtained in the first phase and introduces kinematic chain-based skeleton constraints to ensure physical plausibility. Additionally, we propose a Global-local Chamfer loss that aligns the overall distribution of predicted mesh vertices with the supervision while maintaining part-level alignment without extra annotations. (ii) Cross-category Motion Transfer Module, which leverages the extracted motion from the 4D reconstruction module and uses a kinematic-chain-based skeleton to achieve cross-category motion transfer. It ensures smooth transitions between frames through dynamic rigidity, facilitating robust generalization without additional training. Through extensive experiments, we demonstrate that MagicPose4D significantly improves the accuracy and consistency of 4D content generation, outperforming existing methods in various benchmarks.",
      "authors": [
        "Hao Zhang",
        "Di Chang",
        "Fang Li",
        "Mohammad Soleymani",
        "Narendra Ahuja"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14017",
        "HTML": "https://arxiv.org/html/2405.14017",
        "PDF": "https://arxiv.org/pdf/2405.14017"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 22 May 2024 21:51:01 GMT",
          "size": "28493kb",
          "version": "v1"
        },
        {
          "date": "Tue, 01 Apr 2025 05:13:28 GMT",
          "size": "34737kb",
          "version": "v2"
        },
        {
          "date": "Mon, 23 Jun 2025 20:47:55 GMT",
          "size": "31135kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 14:45:49 GMT",
          "size": "31135kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MagicPose4D: Crafting Articulated Models with Appearance and Motion Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes a framework for 4D content generation, focusing on appearance and motion control. It does not address any LLM training data processing or engineering aspects."
      },
      "tasks": [
        "4D reconstruction",
        "Motion Generation"
      ]
    },
    {
      "id": "2406.14315",
      "abstract": "AI integration is revolutionizing the landscape of HPC simulations, enhancing the importance, use, and performance of AI-driven HPC workflows. This paper surveys the diverse and rapidly evolving field of AI-driven HPC and provides a common conceptual basis for understanding AI-driven HPC workflows. Specifically, we use insights from different modes of coupling AI into HPC workflows to propose six execution motifs most commonly found in scientific applications. The proposed set of execution motifs is by definition incomplete and evolving. However, they allow us to analyze the primary performance challenges underpinning AI-driven HPC workflows. We close with a listing of open challenges, research issues, and suggested areas of investigation including the the need for specific benchmarks that will help evaluate and improve the execution of AI-driven HPC workflows.",
      "authors": [
        "Wes Brewer",
        "Ana Gainaru",
        "Fr\\'ed\\'eric Suter",
        "Feiyi Wang",
        "Murali Emani",
        "Shantenu Jha"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.14315",
        "HTML": "https://arxiv.org/html/2406.14315",
        "PDF": "https://arxiv.org/pdf/2406.14315"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 20 Jun 2024 13:48:10 GMT",
          "size": "2929kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:30:42 GMT",
          "size": "3468kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "AI-coupled HPC Workflow Applications, Middleware and Performance",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses AI-driven HPC workflows, focusing on the integration challenges and patterns in scientific computation rather than LLM data engineering or processing."
      }
    },
    {
      "id": "2406.19799",
      "abstract": "A method for numerical approximation of a new class of fractional parabolic stochastic evolution equations is introduced and analysed. This class of equations has recently been proposed as a space-time extension of the SPDE-method in spatial statistics. A truncation of the spectral basis function expansion is used to discretise in space, and then a quadrature is used to approximate the temporal evolution of each basis coefficient. Strong error bounds are proved both for the spectral and temporal approximations. The method is tested and the results are verified by several numerical experiments.",
      "authors": [
        "Simen Knutsen Furset"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.19799",
        "HTML": "https://arxiv.org/html/2406.19799",
        "PDF": "https://arxiv.org/pdf/2406.19799"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 28 Jun 2024 10:12:38 GMT",
          "size": "959kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:49:59 GMT",
          "size": "2390kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Spectral approximation of a new class of stochastic fractional evolution equations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses numerical approximation methods for stochastic fractional evolution equations without addressing LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/Kriekskaeri/FractionalSPDEMethods"
      ]
    },
    {
      "id": "2407.02508",
      "abstract": "Recent advances in imitative reinforcement learning (IRL) have considerably enhanced the ability of autonomous agents to assimilate expert demonstrations, leading to rapid skill acquisition in a range of demanding tasks. However, such learning-based agents face significant challenges when transferring knowledge to highly dynamic closed-loop environments. Their performance is significantly impacted by the conflicting optimization objectives of imitation learning (IL) and reinforcement learning (RL), sample inefficiency, and the complexity of uncovering the hidden world model and physics. To address this challenge, we propose a physics-informed IRL that is entirely data-driven. It leverages both expert demonstration data and exploratory data with a joint optimization objective, allowing the underlying physical principles of vehicle dynamics to emerge naturally from the training process. The performance is evaluated through empirical experiments and results exceed popular IL, RL and IRL algorithms in closed-loop settings on Waymax benchmark. Our approach exhibits 37.8% reduction in collision rate and 22.2% reduction in off-road rate compared to the baseline method.",
      "authors": [
        "Hang Zhou",
        "Yihao Qin",
        "Dan Xu",
        "Yiding Ji"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02508",
        "HTML": "https://arxiv.org/html/2407.02508",
        "PDF": "https://arxiv.org/pdf/2407.02508"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 18 Jun 2024 14:27:14 GMT",
          "size": "2597kb",
          "version": "v1"
        },
        {
          "date": "Fri, 04 Oct 2024 03:45:21 GMT",
          "size": "4385kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 14:06:21 GMT",
          "size": "2796kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Physics-informed Imitative Reinforcement Learning for Real-world Driving",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on physics-informed imitative reinforcement learning for autonomous driving, without addressing the processing or construction of LLM training data."
      },
      "tasks": [
        "Autonomous Driving",
        "Imitation Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ]
    },
    {
      "id": "2407.21049",
      "abstract": "As language models support larger and larger context sizes, evaluating their ability to make effective use of that context becomes increasingly important. We analyze the ability of several code generation models to handle long range dependencies using a suite of multi-step key retrieval tasks in context windows up to 8k tokens in length. The tasks progressively increase in difficulty and allow more nuanced evaluation of model capabilities than tests like the popular needle-in-the-haystack test. We find that performance degrades significantly for many models (up to 2x) when a function references another function that is defined later in the prompt. We also observe that models that use sliding window attention mechanisms have difficulty handling references further than the size of a single window. We perform simple prompt modifications using call graph information to improve multi-step retrieval performance up to 3x. Our analysis highlights ways that long-context performance needs deeper consideration beyond retrieval of single facts within a document.",
      "authors": [
        "Yannick Assogba",
        "Donghao Ren"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.21049",
        "HTML": "https://arxiv.org/html/2407.21049",
        "PDF": "https://arxiv.org/pdf/2407.21049"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 23 Jul 2024 02:45:22 GMT",
          "size": "710kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 21:45:07 GMT",
          "size": "1545kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Evaluating Long Range Dependency Handling in Code Generation LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper evaluates long-range dependency handling in code generation LLMs and uses existing tasks, but does not address constructing or processing training data for LLMs."
      },
      "tasks": [
        "8k",
        "Code Completion",
        "Code Generation",
        "Retrieval"
      ]
    },
    {
      "id": "2408.00523",
      "abstract": "Text-to-image (T2I) generative models have revolutionized content creation by transforming textual descriptions into high-quality images. However, these models are vulnerable to jailbreaking attacks, where carefully crafted prompts bypass safety mechanisms to produce unsafe content. While researchers have developed various jailbreak attacks to expose this risk, these methods face significant limitations, including impractical access requirements, easily detectable unnatural prompts, restricted search spaces, and high query demands on the target system. In this paper, we propose JailFuzzer, a novel fuzzing framework driven by large language model (LLM) agents, designed to efficiently generate natural and semantically meaningful jailbreak prompts in a black-box setting. Specifically, JailFuzzer employs fuzz-testing principles with three components: a seed pool for initial and jailbreak prompts, a guided mutation engine for generating meaningful variations, and an oracle function to evaluate jailbreak success. Furthermore, we construct the guided mutation engine and oracle function by LLM-based agents, which further ensures efficiency and adaptability in black-box settings. Extensive experiments demonstrate that JailFuzzer has significant advantages in jailbreaking T2I models. It generates natural and semantically coherent prompts, reducing the likelihood of detection by traditional defenses. Additionally, it achieves a high success rate in jailbreak attacks with minimal query overhead, outperforming existing methods across all key metrics. This study underscores the need for stronger safety mechanisms in generative models and provides a foundation for future research on defending against sophisticated jailbreaking attacks. JailFuzzer is open-source and available at this repository: https://github.com/YingkaiD/JailFuzzer.",
      "authors": [
        "Yingkai Dong",
        "Xiangtao Meng",
        "Ning Yu",
        "Zheng Li",
        "Shanqing Guo"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00523",
        "HTML": "https://arxiv.org/html/2408.00523",
        "PDF": "https://arxiv.org/pdf/2408.00523"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 01 Aug 2024 12:54:46 GMT",
          "size": "7365kb",
          "version": "v1"
        },
        {
          "date": "Mon, 09 Sep 2024 08:09:14 GMT",
          "size": "7717kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 18:55:29 GMT",
          "size": "7461kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a fuzz-testing framework for checking vulnerabilities in text-to-image models, unrelated to the processing of large language model training data."
      },
      "tasks": [
        "Image Generation",
        "In-Context Learning",
        "Language Modelling",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ]
    },
    {
      "id": "2408.01841",
      "abstract": "This article introduces BEVPlace++, a novel, fast, and robust LiDAR global localization method for unmanned ground vehicles. It uses lightweight convolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like representations of LiDAR data to achieve accurate global localization through place recognition, followed by 3-DoF pose estimation. Our detailed analyses reveal an interesting fact that CNNs are inherently effective at extracting distinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV images with large translations can be effectively matched using CNN-extracted features. Building on this insight, we design a Rotation Equivariant Module (REM) to obtain distinctive features while enhancing robustness to rotational changes. A Rotation Equivariant and Invariant Network (REIN) is then developed by cascading REM and a descriptor generator, NetVLAD, to sequentially generate rotation equivariant local features and rotation invariant global descriptors. The global descriptors are used first to achieve robust place recognition, and then local features are used for accurate pose estimation. \\revise{Experimental results on seven public datasets and our UGV platform demonstrate that BEVPlace++, even when trained on a small dataset (3000 frames of KITTI) only with place labels, generalizes well to unseen environments, performs consistently across different days and years, and adapts to various types of LiDAR scanners.} BEVPlace++ achieves state-of-the-art performance in multiple tasks, including place recognition, loop closure detection, and global localization. Additionally, BEVPlace++ is lightweight, runs in real-time, and does not require accurate pose supervision, making it highly convenient for deployment. \\revise{The source codes are publicly available at https://github.com/zjuluolun/BEVPlace2.",
      "authors": [
        "Lun Luo",
        "Si-Yuan Cao",
        "Xiaorui Li",
        "Jintao Xu",
        "Rui Ai",
        "Zhu Yu",
        "and Xieyuanli Chen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01841",
        "HTML": "https://arxiv.org/html/2408.01841",
        "PDF": "https://arxiv.org/pdf/2408.01841"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 03 Aug 2024 18:48:41 GMT",
          "size": "7806kb",
          "version": "v1"
        },
        {
          "date": "Fri, 09 Aug 2024 06:42:37 GMT",
          "size": "7806kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 15:57:59 GMT",
          "size": "5280kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a method for LiDAR-based localization, without any mention of processing or constructing training data for language models."
      },
      "repo_urls": [
        "https://github.com/zjuluolun/bevplace"
      ]
    },
    {
      "id": "2408.15203",
      "abstract": "We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation. The system involves K source processors, each holding some data modeled as a vector over a finite field. The remaining R processors are sinks, and each of which requires a linear combination of all data vectors. These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code. To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds. In every round, every processor sends and receives one message through each one of its p ports. Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data. We propose a framework that addresses the decentralized encoding problem on two levels. On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code. On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems. Our solutions are based on a newly-defined collective communication operation we call all-to-all encode.",
      "authors": [
        "Canran Wang and Netanel Raviv"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15203",
        "HTML": "https://arxiv.org/html/2408.15203",
        "PDF": "https://arxiv.org/pdf/2408.15203"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 27 Aug 2024 17:03:10 GMT",
          "size": "180kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:13:36 GMT",
          "size": "288kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the Encoding Process in Decentralized Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research deals with decentralized information encoding and does not involve any aspects of LLM training data processing or data engineering."
      }
    },
    {
      "id": "2408.16767",
      "abstract": "Advancements in 3D scene reconstruction have transformed 2D images from the real world into 3D models, producing realistic 3D results from hundreds of input photos. Despite great success in dense-view reconstruction scenarios, rendering a detailed scene from insufficient captured views is still an ill-posed optimization problem, often resulting in artifacts and distortions in unseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task. The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction. However, 3D view consistency struggles to be accurately preserved in directly generated video frames from pre-trained models. To address this, given limited input views, the proposed ReconX first constructs a global point cloud and encodes it into a contextual space as the 3D structure condition. Guided by the condition, the video diffusion model then synthesizes video frames that are both detail-preserved and exhibit a high degree of 3D consistency, ensuring the coherence of the scene from various perspectives. Finally, we recover the 3D scene from the generated video through a confidence-aware 3D Gaussian Splatting optimization scheme. Extensive experiments on various real-world datasets show the superiority of our ReconX over state-of-the-art methods in terms of quality and generalizability.",
      "authors": [
        "Fangfu Liu",
        "Wenqiang Sun",
        "Hanyang Wang",
        "Yikai Wang",
        "Haowen Sun",
        "Junliang Ye",
        "Jun Zhang",
        "Yueqi Duan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16767",
        "HTML": "https://arxiv.org/html/2408.16767",
        "PDF": "https://arxiv.org/pdf/2408.16767"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 29 Aug 2024 17:59:40 GMT",
          "size": "2258kb",
          "version": "v1"
        },
        {
          "date": "Sat, 30 Nov 2024 09:10:08 GMT",
          "size": "37053kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 15:04:03 GMT",
          "size": "17252kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 07:19:44 GMT",
          "size": "17252kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for 3D scene reconstruction using video diffusion models, not related to training data engineering or processing for LLMs."
      },
      "tasks": [
        "3D Scene Reconstruction"
      ]
    },
    {
      "id": "2409.02244",
      "abstract": "Large language models (LLMs) are being used as ad-hoc therapists. Research suggests that LLMs outperform human counselors when generating a single, isolated empathetic response; however, their session-level behavior remains understudied. In this study, we compare the session-level behaviors of human counselors with those of an LLM prompted by a team of peer counselors to deliver single-session Cognitive Behavioral Therapy (CBT). Our three-stage, mixed-methods study involved: a) a year-long ethnography of a text-based support platform where seven counselors iteratively refined CBT prompts through self-counseling and weekly focus groups; b) the manual simulation of human counselor sessions with a CBT-prompted LLM, given the full patient dialogue and contextual notes; and c) session evaluations of both human and LLM sessions by three licensed clinical psychologists using CBT competence measures. Our results show a clear trade-off. Human counselors excel at relational strategies -- small talk, self-disclosure, and culturally situated language -- that lead to higher empathy, collaboration, and deeper user reflection. LLM counselors demonstrate higher procedural adherence to CBT techniques but struggle to sustain collaboration, misread cultural cues, and sometimes produce \"deceptive empathy,\" i.e., formulaic warmth that can inflate users' expectations of genuine human care. Taken together, our findings imply that while LLMs might outperform counselors in generating single empathetic responses, their ability to lead sessions is more limited, highlighting that therapy cannot be reduced to a standalone natural language processing (NLP) task. We call for carefully designed human-AI workflows in scalable support: LLMs can scaffold evidence-based techniques, while peers provide relational support. We conclude by mapping concrete design opportunities and ethical guardrails for such hybrid systems.",
      "authors": [
        "Zainab Iftikhar",
        "Sean Ransom",
        "Amy Xiao",
        "Nicole Nugent",
        "Jeff Huang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02244",
        "HTML": "https://arxiv.org/html/2409.02244",
        "PDF": "https://arxiv.org/pdf/2409.02244"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 03 Sep 2024 19:19:13 GMT",
          "size": "623kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:07:35 GMT",
          "size": "207kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Therapy as an NLP Task: Psychologists' Comparison of LLMs and Human Peers in CBT",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the evaluation of LLMs in comparison to human peers in the context of psychotherapy sessions but does not address any aspect of training data processing or data engineering for LLMs."
      },
      "tasks": [
        "Language Modelling",
        "Large Language Model"
      ]
    },
    {
      "id": "2409.07163",
      "abstract": "Diffusion models have been widely employed in the field of 3D manipulation due to their efficient capability to learn distributions, allowing for precise prediction of action trajectories. However, diffusion models typically rely on large parameter UNet backbones as policy networks, which can be challenging to deploy on resource-constrained devices. Recently, the Mamba model has emerged as a promising solution for efficient modeling, offering low computational complexity and strong performance in sequence modeling. In this work, we propose the Mamba Policy, a lighter but stronger policy that reduces the parameter count by over 80% compared to the original policy network while achieving superior performance. Specifically, we introduce the XMamba Block, which effectively integrates input information with conditional features and leverages a combination of Mamba and Attention mechanisms for deep feature extraction. Extensive experiments demonstrate that the Mamba Policy excels on the Adroit, Dexart, and MetaWorld datasets, requiring significantly fewer computational resources. Additionally, we highlight the Mamba Policy's enhanced robustness in long-horizon scenarios compared to baseline methods and explore the performance of various Mamba variants within the Mamba Policy framework. Real-world experiments are also conducted to further validate its effectiveness. Our open-source project page can be found at https://andycao1125.github.io/mamba_policy/.",
      "authors": [
        "Jiahang Cao",
        "Qiang Zhang",
        "Jingkai Sun",
        "Jiaxu Wang",
        "Hao Cheng",
        "Yulin Li",
        "Jun Ma",
        "Kun Wu",
        "Zhiyuan Xu",
        "Yecheng Shao",
        "Wen Zhao",
        "Gang Han",
        "Yijie Guo",
        "Renjing Xu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07163",
        "HTML": "https://arxiv.org/html/2409.07163",
        "PDF": "https://arxiv.org/pdf/2409.07163"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 11 Sep 2024 10:21:21 GMT",
          "size": "1969kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:48:48 GMT",
          "size": "2124kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Mamba Policy: Towards Efficient 3D Diffusion Policy with Hybrid Selective State Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces the Mamba Policy for efficient 3D diffusion modeling, focusing on computational efficiency and model performance. It does not discuss LLM training data processing."
      },
      "tasks": [
        "Mamba"
      ]
    },
    {
      "id": "2409.08160",
      "abstract": "We present a new perspective on how readers integrate context during real-time language comprehension. Our proposals build on surprisal theory, which posits that the processing effort of a linguistic unit (e.g., a word) is an affine function of its in-context information content. We first observe that surprisal is only one out of many potential ways that a contextual predictor can be derived from a language model. Another one is the pointwise mutual information (PMI) between a unit and its context, which turns out to yield the same predictive power as surprisal when controlling for unigram frequency. Moreover, both PMI and surprisal are correlated with frequency. This means that neither PMI nor surprisal contains information about context alone. In response to this, we propose a technique where we project surprisal onto the orthogonal complement of frequency, yielding a new contextual predictor that is uncorrelated with frequency. Our experiments show that the proportion of variance in reading times explained by context is a lot smaller when context is represented by the orthogonalized predictor. From an interpretability standpoint, this indicates that previous studies may have overstated the role that context has in predicting reading times.",
      "authors": [
        "Andreas Opedal",
        "Eleanor Chodroff",
        "Ryan Cotterell",
        "Ethan Gotlieb Wilcox"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08160",
        "HTML": "https://arxiv.org/html/2409.08160",
        "PDF": "https://arxiv.org/pdf/2409.08160"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 12 Sep 2024 15:52:22 GMT",
          "size": "240kb",
          "version": "v1"
        },
        {
          "date": "Mon, 07 Oct 2024 20:54:36 GMT",
          "size": "166kb",
          "version": "v2"
        },
        {
          "date": "Mon, 21 Oct 2024 15:22:58 GMT",
          "size": "208kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 16:32:48 GMT",
          "size": "168kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the Role of Context in Reading Time Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research discusses context in reading time prediction from a cognitive perspective using surprisal theory but does not relate to LLM training data engineering or processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Prediction"
      ],
      "repo_urls": [
        "https://github.com/rycolab/context-reading-time"
      ]
    },
    {
      "id": "2409.08974",
      "abstract": "Optimal cooling that minimises thermal gradients and the average temperature is essential for enhanced battery safety and health. This work presents a new modelling approach for battery cells of different shapes by integrating Chebyshev spectral-Galerkin method and model component decomposition. As a result, a library of reduced-order computationally efficient battery thermal models is obtained, characterised by different numbers of states. These models are validated against a high-fidelity finite element model and are compared with a thermal equivalent circuit (TEC) model under real-world vehicle driving and battery cooling scenarios. Illustrative results demonstrate that the proposed model with four states can faithfully capture the two-dimensional thermal dynamics, while the model with only one state significantly outperforms the widely-used two-state TEC model in both accuracy and computational efficiency, reducing computation time by 28.7%. Furthermore, our developed models allow for independent control of tab and surface cooling channels, enabling effective thermal performance optimisation. Additionally, the proposed model's versatility and effectiveness are demonstrated through various applications, including the evaluation of different cooling scenarios, closed-loop temperature control, and cell design optimisation.",
      "authors": [
        "Godwin K. Peprah",
        "Yicun Huang",
        "Torsten Wik",
        "Faisal Altaf",
        "and Changfu Zou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08974",
        "HTML": "https://arxiv.org/html/2409.08974",
        "PDF": "https://arxiv.org/pdf/2409.08974"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Sep 2024 16:46:43 GMT",
          "size": "4529kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:48:54 GMT",
          "size": "2057kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Thermal Modelling of Battery Cells for Optimal Tab and Surface Cooling Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work presents a new thermal modeling approach for battery cells, which does not pertain to the processing or engineering of LLM training data."
      },
      "tasks": [
        "Computational Efficiency"
      ]
    },
    {
      "id": "2409.12335",
      "abstract": "The foundations of deep learning are supported by the seemingly opposing perspectives of approximation or learning theory. The former advocates for large/expressive models that need not generalize, while the latter considers classes that generalize but may be too small/constrained to be universal approximators. Motivated by real-world deep learning implementations that are both expressive and statistically reliable, we ask: \"Is there a class of neural networks that is both large enough to be universal but structured enough to generalize?\" This paper constructively provides a positive answer to this question by identifying a highly structured class of ReLU multilayer perceptions (MLPs), which are optimal function approximators and are statistically well-behaved. We show that any $(L,\\alpha)$-H\\\"{o}lder function from $[0,1]^d$ to $[-n,n]$ can be approximated to a uniform $\\mathcal{O}(1/n)$ error on $[0,1]^d$ with a sparsely connected ReLU MLP with the same H\\\"{o}lder exponent $\\alpha$ and coefficient $L$, of width $\\mathcal{O}(dn^{d/\\alpha})$, depth $\\mathcal{O}(\\log(d))$, with $\\mathcal{O}(dn^{d/\\alpha})$ nonzero parameters, and whose weights and biases take values in $\\{0,\\pm 1/2\\}$ except in the first and last layers which instead have magnitude at-most $n$. Further, our class of MLPs achieves a near-optimal sample complexity of $\\mathcal{O}(\\log(N)/\\sqrt{N})$ when given $N$ i.i.d. normalized sub-Gaussian training samples. We achieve this through a new construction that perfectly fits together linear pieces using Kuhn triangulations, along with a new proof technique which shows that our construction preserves the regularity of not only the H\\\"{o}lder functions, but also any uniformly continuous function. Our results imply that neural networks can solve the McShane extension problem on suitable finite sets.",
      "authors": [
        "Ruiyang Hong",
        "Anastasis Kratsios"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.12335",
        "HTML": "https://arxiv.org/html/2409.12335",
        "PDF": "https://arxiv.org/pdf/2409.12335"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Functional Analysis (math.FA)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Sep 2024 22:05:07 GMT",
          "size": "458kb",
          "version": "v1"
        },
        {
          "date": "Wed, 18 Jun 2025 04:49:08 GMT",
          "size": "730kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 18:03:32 GMT",
          "size": "1109kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Bridging the Gap Between Approximation and Learning via Optimal Approximation by ReLU MLPs of Maximal Regularity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about approximation capabilities of ReLU MLPs and does not address any aspects of LLM training data processing or data engineering."
      },
      "tasks": [
        "Learning Theory"
      ]
    },
    {
      "id": "2410.02145",
      "abstract": "Active learning methods aim to improve sample complexity in machine learning. In this work, we investigate an active learning scheme via a novel gradient-free cutting-plane training method for ReLU networks of arbitrary depth and develop a convergence theory. We demonstrate, for the first time, that cutting-plane algorithms, traditionally used in linear models, can be extended to deep neural networks despite their nonconvexity and nonlinear decision boundaries. Moreover, this training method induces the first deep active learning scheme known to achieve convergence guarantees, revealing a geometric contraction rate of the feasible set. We exemplify the effectiveness of our proposed active learning method against popular deep active learning baselines via both synthetic data experiments and sentimental classification task on real datasets.",
      "authors": [
        "Erica Zhang",
        "Fangzhao Zhang",
        "Mert Pilanci"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02145",
        "HTML": "https://arxiv.org/html/2410.02145",
        "PDF": "https://arxiv.org/pdf/2410.02145"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 03 Oct 2024 02:11:35 GMT",
          "size": "16718kb",
          "version": "v1"
        },
        {
          "date": "Fri, 04 Oct 2024 00:53:19 GMT",
          "size": "16718kb",
          "version": "v2"
        },
        {
          "date": "Mon, 14 Oct 2024 23:37:50 GMT",
          "size": "16719kb",
          "version": "v3"
        },
        {
          "date": "Fri, 21 Feb 2025 08:32:57 GMT",
          "size": "5958kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 06:11:27 GMT",
          "size": "5957kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work explores a novel active learning scheme for deep neural networks; it does not relate to the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "Active Learning"
      ]
    },
    {
      "id": "2410.02636",
      "abstract": "Finding sparse vectors is a fundamental problem that arises in several contexts including codes, subspaces, and lattices. In this work, we prove strong inapproximability results for all these variants using a novel approach that even bypasses the PCP theorem. Our main result is that it is NP-hard (under randomized reductions) to approximate the sparsest vector in a real subspace within any constant factor; the gap can be further amplified using tensoring. Our reduction has the property that there is a Boolean solution in the completeness case. As a corollary, this immediately recovers the state-of-the-art inapproximability factors for the shortest vector problem (SVP) on lattices. Our proof extends the range of $\\ell_p$ (quasi) norms for which hardness was previously known, from $p\\geq 1$ to all $p\\geq 0$, answering a question raised by [Khot05].\n  Previous hardness results for SVP, and the related minimum distance problem (MDP) for error-correcting codes, all use lattice/coding gadgets that have an abundance of codewords in a ball of radius smaller than the minimum distance. In contrast, our reduction only needs many codewords in a ball of radius slightly larger than the minimum distance. This enables an easy derandomization of our reduction for finite fields, giving a new elementary proof of deterministic hardness for MDP. We believe this weaker density requirement might offer a promising approach to showing deterministic hardness of SVP, a long elusive goal. The key technical ingredient underlying our result for real subspaces is a proof that in the kernel of a random Rademacher matrix, the support of any two linearly independent vectors have very little overlap.\n  A broader motivation behind this work is the development of inapproximability techniques for problems over the reals. We hope that the approach we develop could enable progress on analytic variants of sparsest vector.",
      "authors": [
        "Vijay Bhattiprolu and Venkatesan Guruswami and Euiwoong Lee and Xuandi Ren"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02636",
        "HTML": "https://arxiv.org/html/2410.02636",
        "PDF": "https://arxiv.org/pdf/2410.02636"
      },
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 03 Oct 2024 16:22:07 GMT",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "Sun, 27 Oct 2024 07:27:33 GMT",
          "size": "40kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 21:51:55 GMT",
          "size": "34kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Inapproximability of Finding Sparse Vectors in Codes, Subspaces, and Lattices",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses inapproximability concerning finding sparse vectors in codes, subspaces, and lattices, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2410.02899",
      "abstract": "Language models (LMs) hallucinate. We inquire: Can we detect and mitigate hallucinations before they happen? This work answers this research question in the positive, by showing that the internal representations of LMs provide rich signals that can be used for this purpose. We introduce FactCheckmate, which preemptively detects hallucinations by learning a classifier that predicts whether the LM will hallucinate, based on the model's hidden states produced over the inputs, before decoding begins. If a hallucination is detected, FactCheckmate then intervenes by adjusting the LM's hidden states such that the model will produce more factual outputs. FactCheckmate provides fresh insights that the inner workings of LMs can be revealed by their hidden states. Practically, both its detection and mitigation models are lightweight, adding little inference overhead; FactCheckmate proves a more efficient approach for mitigating hallucinations compared to many post-hoc alternatives. We evaluate FactCheckmate over LMs of different scales and model families (including Llama, Mistral, Qwen and Gemma), across a variety of QA datasets from different domains. Our results demonstrate the effectiveness of FactCheckmate, achieving over 70% preemptive detection accuracy. On average, outputs generated by LMs with intervention are 34.4% more factual compared to those without.",
      "authors": [
        "Deema Alnuhait",
        "Neeraja Kirtane",
        "Muhammad Khalifa",
        "Hao Peng"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02899",
        "HTML": "https://arxiv.org/html/2410.02899",
        "PDF": "https://arxiv.org/pdf/2410.02899"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 03 Oct 2024 18:45:00 GMT",
          "size": "4194kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 19:49:48 GMT",
          "size": "1528kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "FactCheckmate: Preemptively Detecting and Mitigating Hallucinations in LMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on detecting and mitigating hallucinations in LMs using internal representations, without mentioning the processing of training data for LLMs or improvements to data quality."
      },
      "tasks": [
        "Hallucination"
      ]
    },
    {
      "id": "2410.08417",
      "abstract": "A mechanistic understanding of how MLPs do computation in deep neural networks remains elusive. Current interpretability work can extract features from hidden activations over an input dataset but generally cannot explain how MLP weights construct features. One challenge is that element-wise nonlinearities introduce higher-order interactions and make it difficult to trace computations through the MLP layer. In this paper, we analyze bilinear MLPs, a type of Gated Linear Unit (GLU) without any element-wise nonlinearity that nevertheless achieves competitive performance. Bilinear MLPs can be fully expressed in terms of linear operations using a third-order tensor, allowing flexible analysis of the weights. Analyzing the spectra of bilinear MLP weights using eigendecomposition reveals interpretable low-rank structure across toy tasks, image classification, and language modeling. We use this understanding to craft adversarial examples, uncover overfitting, and identify small language model circuits directly from the weights alone. Our results demonstrate that bilinear layers serve as an interpretable drop-in replacement for current activation functions and that weight-based interpretability is viable for understanding deep-learning models.",
      "authors": [
        "Michael T. Pearce",
        "Thomas Dooms",
        "Alice Rigg",
        "Jose M. Oramas",
        "Lee Sharkey"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08417",
        "HTML": "https://arxiv.org/html/2410.08417",
        "PDF": "https://arxiv.org/pdf/2410.08417"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 10 Oct 2024 23:22:11 GMT",
          "size": "3173kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:36:59 GMT",
          "size": "1788kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Bilinear MLPs enable weight-based mechanistic interpretability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses mechanistic interpretability of MLPs through bilinear layers, with no involvement in LLM training data processing or data engineering."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Language Modeling",
        "Language Modelling",
        "Small Language Model"
      ],
      "repo_urls": [
        "https://github.com/tdooms/bilinear-decomposition"
      ]
    },
    {
      "id": "2410.19494",
      "abstract": "Large language models have evolved to process multiple modalities beyond text, such as images and audio, which motivates us to explore how to effectively leverage them for graph reasoning tasks. The key question, therefore, is how to transform graphs into linear sequences of tokens, a process we term \"graph linearization\", so that LLMs can handle graphs naturally. We consider that graphs should be linearized meaningfully to reflect certain properties of natural language text, such as local dependency and global alignment, in order to ease contemporary LLMs, trained on trillions of textual tokens, better understand graphs. To achieve this, we developed several graph linearization methods based on graph centrality and degeneracy. These methods are further enhanced using node relabeling techniques. The experimental results demonstrate the effectiveness of our methods compared to the random linearization baseline. Our work introduces novel graph representations suitable for LLMs, contributing to the potential integration of graph machine learning with the trend of multimodal processing using a unified transformer model.",
      "authors": [
        "Christos Xypolopoulos",
        "Guokan Shang",
        "Xiao Fei",
        "Giannis Nikolentzos",
        "Hadi Abdine",
        "Iakovos Evdaimon",
        "Michail Chatzianastasis",
        "Giorgos Stamou",
        "Michalis Vazirgiannis"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19494",
        "HTML": "https://arxiv.org/html/2410.19494",
        "PDF": "https://arxiv.org/pdf/2410.19494"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 25 Oct 2024 11:51:37 GMT",
          "size": "169kb",
          "version": "v1"
        },
        {
          "date": "Tue, 15 Apr 2025 17:38:16 GMT",
          "size": "334kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 14:24:33 GMT",
          "size": "338kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Graph Linearization Methods for Reasoning on Graphs with Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on transforming graphs for reasoning with LLMs through graph linearization methods, but does not address any aspect of processing training data for LLMs."
      },
      "tasks": []
    },
    {
      "id": "2410.21218",
      "abstract": "Large language models (LLMs) have sparked significant impact with regard to both intelligence and productivity. Numerous enterprises have integrated LLMs into their applications to solve their own domain-specific tasks. However, integrating LLMs into specific scenarios is a systematic process that involves substantial components, which are collectively referred to as the LLM supply chain. A comprehensive understanding of LLM supply chain composition, as well as the relationships among its components, is crucial for enabling effective mitigation measures for different related risks. While existing literature has explored various risks associated with LLMs, there remains a notable gap in systematically characterizing the LLM supply chain from the dual perspectives of contributors and consumers. In this work, we develop a structured taxonomy encompassing risk types, risky actions, and corresponding mitigations across different stakeholders and components of the supply chain. We believe that a thorough review of the LLM supply chain composition, along with its inherent risks and mitigation measures, would be valuable for industry practitioners to avoid potential damages and losses, and enlightening for academic researchers to rethink existing approaches and explore new avenues of research.",
      "authors": [
        "Kaifeng Huang",
        "Bihuan Chen",
        "You Lu",
        "Susheng Wu",
        "Dingji Wang",
        "Yiheng Huang",
        "Haowen Jiang",
        "Zhuotong Zhou",
        "Junming Cao",
        "Xin Peng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21218",
        "HTML": "https://arxiv.org/html/2410.21218",
        "PDF": "https://arxiv.org/pdf/2410.21218"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 28 Oct 2024 17:02:12 GMT",
          "size": "4151kb",
          "version": "v1"
        },
        {
          "date": "Thu, 31 Oct 2024 03:14:16 GMT",
          "size": "1209kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 09:01:38 GMT",
          "size": "702kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Lifting the Veil on Composition, Risks, and Mitigations of the Large Language Model Supply Chain",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses the LLM supply chain, focusing on risk assessment and mitigation strategies, without contribution to the data engineering or processing tasks specific to training data for LLMs."
      }
    },
    {
      "id": "2410.21647",
      "abstract": "Recently, a number of repository-level code generation benchmarks-such as CoderEval, DevEval, RepoEval, RepoBench, and LongCodeArena-have emerged to evaluate the capabilities of large language models (LLMs) beyond standalone benchmarks like HumanEval and MBPP. Thus, a natural question is, would LLMs have similar performance in real world coding tasks as their performance in these benchmarks? Unfortunately, one cannot answer this question, since these benchmarks consist of short completions, synthetic examples, or focus on limited scale repositories, failing to represent real-world coding tasks.\n  To address these challenges, we create REPOCOD, a Python code-generation benchmark containing complex tasks with realistic dependencies in real-world large projects and appropriate metrics for evaluating source code. It includes 980 whole-function generation tasks from 11 popular projects, 50.8% of which require repository-level context. REPOCOD includes 314 developer-written test cases per instance for better evaluation. We evaluate ten LLMs on REPOCOD and find that none achieves more than 30% pass@1 on REPOCOD, indicating the necessity of building stronger LLMs that can help developers in real-world software development. In addition, we found that retrieval-augmented generation achieves better results than using target function dependencies as context.",
      "authors": [
        "Shanchao Liang",
        "Yiran Hu",
        "Nan Jiang",
        "Lin Tan"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21647",
        "HTML": "https://arxiv.org/html/2410.21647",
        "PDF": "https://arxiv.org/pdf/2410.21647"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 29 Oct 2024 01:21:05 GMT",
          "size": "1242kb",
          "version": "v1"
        },
        {
          "date": "Thu, 31 Oct 2024 07:31:31 GMT",
          "size": "1243kb",
          "version": "v2"
        },
        {
          "date": "Sun, 03 Nov 2024 21:24:10 GMT",
          "size": "1243kb",
          "version": "v3"
        },
        {
          "date": "Tue, 24 Jun 2025 20:49:51 GMT",
          "size": "2721kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Can Language Models Replace Programmers for Coding? REPOCOD Says 'Not Yet'",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research introduces a benchmark for evaluating LLMs in coding tasks but does not focus on data processing or data engineering stages involved in training data for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "lt-asset/REPOCOD",
          "downloads": "395",
          "likes": "8",
          "link": "https://huggingface.co/datasets/lt-asset/REPOCOD"
        },
        {
          "dataset_name": "lt-asset/REPOCOD_Lite",
          "downloads": "43",
          "likes": "1",
          "link": "https://huggingface.co/datasets/lt-asset/REPOCOD_Lite"
        },
        {
          "dataset_name": "lt-asset/REPOCOD_Lite_Unified",
          "downloads": "76",
          "likes": "1",
          "link": "https://huggingface.co/datasets/lt-asset/REPOCOD_Lite_Unified"
        }
      ],
      "tasks": [
        "Code Completion",
        "Code Generation",
        "HumanEval",
        "mbpp"
      ],
      "repo_urls": [
        "https://github.com/lt-asset/repocod"
      ]
    },
    {
      "id": "2411.01580",
      "abstract": "Federated Learning (FL) trains deep models across edge devices without centralizing raw data, preserving user privacy. However, client heterogeneity slows down convergence and limits global model accuracy. Clustered FL (CFL) mitigates this by grouping clients with similar representations and training a separate model for each cluster. In practice, client data evolves over time, a phenomenon we refer to as data drift, which breaks cluster homogeneity and degrades performance. Data drift can take different forms depending on whether changes occur in the output values, the input features, or the relationship between them. We propose FIELDING, a CFL framework for handling diverse types of data drift with low overhead. FIELDING detects drift at individual clients and performs selective re-clustering to balance cluster quality and model performance, while remaining robust to malicious clients and varying levels of heterogeneity. Experiments show that FIELDING improves final model accuracy by 1.9-5.9% and achieves target accuracy 1.16x-2.23x faster than existing state-of-the-art CFL methods.",
      "authors": [
        "Minghao Li (1)",
        "Dmitrii Avdiukhin (2)",
        "Rana Shahout (1)",
        "Nikita Ivkin (3)",
        "Vladimir Braverman (4)",
        "Minlan Yu (1) ((1) Harvard University",
        "(2) Northwestern University",
        "(3) Amazon",
        "(4) Johns Hopkins University)"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01580",
        "HTML": "https://arxiv.org/html/2411.01580",
        "PDF": "https://arxiv.org/pdf/2411.01580"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 03 Nov 2024 14:13:38 GMT",
          "size": "6230kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 01:20:58 GMT",
          "size": "7584kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Federated Learning Clients Clustering with Adaptation to Data Drifts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on federated learning and client clustering in the face of data drift, but does not contribute to LLM training data processing or data engineering tasks."
      },
      "tasks": [
        "Clustering",
        "Federated Learning"
      ]
    },
    {
      "id": "2411.01630",
      "abstract": "A celebrated result of Hastad established that, for any constant $\\varepsilon>0$, it is NP-hard to find an assignment satisfying a $(1/|G|+\\varepsilon)$-fraction of the constraints of a given 3-LIN instance over an Abelian group $G$ even if one is promised that an assignment satisfying a $(1-\\varepsilon)$-fraction of the constraints exists. Engebretsen, Holmerin, and Russell showed the same result for 3-LIN instances over any finite (not necessarily Abelian) group. In other words, for almost-satisfiable instances of 3-LIN the random assignment achieves an optimal approximation guarantee. We prove that the random assignment algorithm is still best possible under a stronger promise that the 3-LIN instance is almost satisfiable over an arbitrarily more restrictive group.",
      "authors": [
        "Silvia Butti and Alberto Larrauri and Stanislav \\v{Z}ivn\\'y"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01630",
        "HTML": "https://arxiv.org/html/2411.01630",
        "PDF": "https://arxiv.org/pdf/2411.01630"
      },
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 03 Nov 2024 16:47:58 GMT",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:47:06 GMT",
          "size": "36kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Optimal Inapproximability of Promise Equations over Finite Groups",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on theoretical aspects of computational complexity related to approximability of promise equations over finite groups and contains no discussion about LLM training data processing."
      }
    },
    {
      "id": "2411.01969",
      "abstract": "Toddlers learn to recognize objects from different viewpoints with almost no supervision. During this learning, they execute frequent eye and head movements that shape their visual experience. It is presently unclear if and how these behaviors contribute to toddlers' emerging object recognition abilities. To answer this question, we here combine head-mounted eye tracking during dyadic play with unsupervised machine learning. We approximate toddlers' central visual field experience by cropping image regions from a head-mounted camera centered on the current gaze location estimated via eye tracking. This visual stream feeds an unsupervised computational model of toddlers' learning, which constructs visual representations that slowly change over time. Our experiments demonstrate that toddlers' gaze strategy supports the learning of invariant object representations. Our analysis also shows that the limited size of the central visual field where acuity is high is crucial for this. Overall, our work reveals how toddlers' gaze behavior may support their development of view-invariant object recognition.",
      "authors": [
        "Zhengyang Yu",
        "Arthur Aubret",
        "Marcel C. Raabe",
        "Jane Yang",
        "Chen Yu",
        "Jochen Triesch"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01969",
        "HTML": "https://arxiv.org/html/2411.01969",
        "PDF": "https://arxiv.org/pdf/2411.01969"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 04 Nov 2024 10:44:46 GMT",
          "size": "4873kb",
          "version": "v1"
        },
        {
          "date": "Wed, 12 Feb 2025 09:58:15 GMT",
          "size": "6063kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 09:19:50 GMT",
          "size": "5937kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Toddlers' Active Gaze Behavior Supports Self-Supervised Object Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study explores toddlers' gaze behavior using eye tracking and unsupervised machine learning for visual learning, but it does not pertain to LLM training data processing."
      },
      "tasks": [
        "Object",
        "Object Recognition",
        "Self-Supervised Learning"
      ]
    },
    {
      "id": "2411.10504",
      "abstract": "Spike cameras, as an innovative neuromorphic camera that captures scenes with the 0-1 bit stream at 40 kHz, are increasingly employed for the 3D reconstruction task via Neural Radiance Fields (NeRF) or 3D Gaussian Splatting (3DGS). Previous spike-based 3D reconstruction approaches often employ a casecased pipeline: starting with high-quality image reconstruction from spike streams based on established spike-to-image reconstruction algorithms, then progressing to camera pose estimation and 3D reconstruction. However, this cascaded approach suffers from substantial cumulative errors, where quality limitations of initial image reconstructions negatively impact pose estimation, ultimately degrading the fidelity of the 3D reconstruction. To address these issues, we propose a synergistic optimization framework, \\textbf{USP-Gaussian}, that unifies spike-based image reconstruction, pose correction, and Gaussian splatting into an end-to-end framework. Leveraging the multi-view consistency afforded by 3DGS and the motion capture capability of the spike camera, our framework enables a joint iterative optimization that seamlessly integrates information between the spike-to-image network and 3DGS. Experiments on synthetic datasets with accurate poses demonstrate that our method surpasses previous approaches by effectively eliminating cascading errors. Moreover, we integrate pose optimization to achieve robust 3D reconstruction in real-world scenarios with inaccurate initial poses, outperforming alternative methods by effectively reducing noise and preserving fine texture details. Our code, data and trained models will be available at https://github.com/chenkang455/USP-Gaussian.",
      "authors": [
        "Kang Chen and Jiyuan Zhang and Zecheng Hao and Yajing Zheng and Tiejun Huang and Zhaofei Yu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10504",
        "HTML": "https://arxiv.org/html/2411.10504",
        "PDF": "https://arxiv.org/pdf/2411.10504"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 15 Nov 2024 14:15:16 GMT",
          "size": "4360kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:07:36 GMT",
          "size": "13599kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction and Gaussian Splatting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research addresses image reconstruction and pose correction in 3D reconstruction using spike cameras and does not involve LLM training data processes."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Chen_USP-Gaussian_Unifying_Spike-based_Image_Reconstruction_Pose_Correction_and_Gaussian_Splatting_CVPR_2025_paper.html",
      "tasks": [
        "3DGS",
        "3D Reconstruction",
        "Camera Pose Estimation",
        "Image Reconstruction",
        "NeRF",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/chenkang455/usp-gaussian"
      ]
    },
    {
      "id": "2411.10890",
      "abstract": "Scientific Workflow Systems (SWSs) are advanced software frameworks that drive modern research by orchestrating complex computational tasks and managing extensive data pipelines. These systems offer a range of essential features, including modularity, abstraction, interoperability, workflow composition tools, resource management, error handling, and comprehensive documentation. Utilizing these frameworks accelerates the development of scientific computing, resulting in more efficient and reproducible research outcomes. However, developing a user-friendly, efficient, and adaptable SWS poses several challenges. This study explores these challenges through an in-depth analysis of interactions on Stack Overflow (SO) and GitHub, key platforms where developers and researchers discuss and resolve issues. In particular, we leverage topic modeling (BERTopic) to understand the topics SWSs developers discuss on these platforms. We identified 10 topics developers discuss on SO (e.g., Workflow Creation and Scheduling, Data Structures and Operations, Workflow Execution) and found that workflow execution is the most challenging. By analyzing GitHub issues, we identified 13 topics (e.g., Errors and Bug Fixing, Documentation, Dependencies) and discovered that data structures and operations is the most difficult. We also found common topics between SO and GitHub, such as data structures and operations, task management, and workflow scheduling. Additionally, we categorized each topic by type (How, Why, What, and Others). We observed that the How type consistently dominates across all topics, indicating a need for procedural guidance among developers. The dominance of the How type is also evident in domains like Chatbots and Mobile development. Our study will guide future research in proposing tools and techniques to help the community overcome the challenges developers face when developing SWSs.",
      "authors": [
        "Khairul Alam",
        "Banani Roy",
        "Chanchal K. Roy",
        "Kartik Mittal"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10890",
        "HTML": "https://arxiv.org/html/2411.10890",
        "PDF": "https://arxiv.org/pdf/2411.10890"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 16 Nov 2024 21:14:11 GMT",
          "size": "5499kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:13:29 GMT",
          "size": "4248kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "An Empirical Investigation on the Challenges in Scientific Workflow Systems Development",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses challenges in developing scientific workflow systems and analyzing community interactions but it is not relevant to LLM training data processing."
      }
    },
    {
      "id": "2411.13047",
      "abstract": "Deep neural networks (DNNs) deployed in a cloud often allow users to query models via the APIs. However, these APIs expose the models to model extraction attacks (MEAs). In this attack, the attacker attempts to duplicate the target model by abusing the responses from the API. Backdoor-based DNN watermarking is known as a promising defense against MEAs, wherein the defender injects a backdoor into extracted models via API responses. The backdoor is used as a watermark of the model; if a suspicious model has the watermark (i.e., backdoor), it is verified as an extracted model. This work focuses on object detection (OD) models. Existing backdoor attacks on OD models are not applicable for model watermarking as the defense against MEAs on a realistic threat model. Our proposed approach involves inserting a backdoor into extracted models via APIs by stealthily modifying the bounding-boxes (BBs) of objects detected in queries while keeping the OD capability. In our experiments on three OD datasets, the proposed approach succeeded in identifying the extracted models with 100% accuracy in a wide variety of experimental scenarios.",
      "authors": [
        "Satoru Koda",
        "Ikuya Morikawa"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13047",
        "HTML": "https://arxiv.org/html/2411.13047",
        "PDF": "https://arxiv.org/pdf/2411.13047"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 20 Nov 2024 05:40:20 GMT",
          "size": "11606kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:37:16 GMT",
          "size": "5630kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Bounding-box Watermarking: Defense against Model Extraction Attacks on Object Detectors",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on model extraction attacks and watermarking techniques for object detection models, which are unrelated to LLM training data processing."
      },
      "tasks": [
        "Model extraction",
        "object-detection",
        "Object Detection"
      ]
    },
    {
      "id": "2411.13360",
      "abstract": "We introduce a framework for predicting wireless channel statistics based on digital twin (DT) and ray tracing. The DT is derived from satellite images and is uncalibrated, as it does not assume precise information on the electromagnetic properties of the materials in the environment. The uncalibrated DT is utilized to derive a geometric prior that informs a Gaussian process (GP) and thereby predict channel statistics using only a few measurements. The framework also quantifies uncertainty, offering statistical guarantees for rate selection in ultra-reliable low-latency communication (URLLC). Experimental validation demonstrates the efficacy of the proposed framework using measurement data.",
      "authors": [
        "Mahmoud Saad Abouamer",
        "Robin J. Williams",
        "Petar Popovski"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13360",
        "HTML": "https://arxiv.org/html/2411.13360",
        "PDF": "https://arxiv.org/pdf/2411.13360"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 20 Nov 2024 14:32:40 GMT",
          "size": "4422kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:51:10 GMT",
          "size": "4567kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Prediction of Wireless Channel Statistics with Ray Tracing and Uncalibrated Digital Twin",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about predicting wireless channel statistics using digital twins and ray tracing, not about LLM training data processing."
      }
    },
    {
      "id": "2411.14499",
      "abstract": "The concept of world models has garnered significant attention due to advancements in multimodal large language models such as GPT-4 and video generation models such as Sora, which are central to the pursuit of artificial general intelligence. This survey offers a comprehensive review of the literature on world models. Generally, world models are regarded as tools for either understanding the present state of the world or predicting its future dynamics. This review presents a systematic categorization of world models, emphasizing two primary functions: (1) constructing internal representations to understand the mechanisms of the world, and (2) predicting future states to simulate and guide decision-making. Initially, we examine the current progress in these two categories. We then explore the application of world models in key domains, including autonomous driving, robotics, and social simulacra, with a focus on how each domain utilizes these aspects. Finally, we outline key challenges and provide insights into potential future research directions. We summarize the representative papers along with their code repositories in https://github.com/tsinghua-fib-lab/World-Model.",
      "authors": [
        "Jingtao Ding",
        "Yunke Zhang",
        "Yu Shang",
        "Yuheng Zhang",
        "Zefang Zong",
        "Jie Feng",
        "Yuan Yuan",
        "Hongyuan Su",
        "Nian Li",
        "Nicholas Sukiennik",
        "Fengli Xu",
        "Yong Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14499",
        "HTML": "https://arxiv.org/html/2411.14499",
        "PDF": "https://arxiv.org/pdf/2411.14499"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 21 Nov 2024 03:58:50 GMT",
          "size": "4019kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:31:33 GMT",
          "size": "4611kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This survey discusses world models for understanding or predicting world states, with no direct link to LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Decision Making",
        "Video Generation"
      ]
    },
    {
      "id": "2412.01131",
      "abstract": "Recently, much work has concerned itself with the enigma of what exactly PLMs (pretrained language models) learn about different aspects of language, and how they learn it. One stream of this type of research investigates the knowledge that PLMs have about semantic relations. However, many aspects of semantic relations were left unexplored. Only one relation was considered, namely hypernymy. Furthermore, previous work did not measure humans' performance on the same task as that solved by the PLMs. This means that at this point in time, there is only an incomplete view of models' semantic relation knowledge. To address this gap, we introduce a comprehensive evaluation framework covering five relations beyond hypernymy, namely hyponymy, holonymy, meronymy, antonymy, and synonymy. We use six metrics (two newly introduced here) for recently untreated aspects of semantic relation knowledge, namely soundness, completeness, symmetry, asymmetry, prototypicality, and distinguishability and fairly compare humans and models on the same task. Our extensive experiments involve 16 PLMs, eight masked and eight causal language models. Up to now only masked language models had been tested although causal and masked language models treat context differently. Our results reveal a significant knowledge gap between humans and models for almost all semantic relations. Antonymy is the outlier relation where all models perform reasonably well. In general, masked language models perform significantly better than causal language models. Nonetheless, both masked and causal language models are likely to confuse non-antonymy relations with antonymy.",
      "authors": [
        "Zhihan Cao",
        "Hiroaki Yamada",
        "Simone Teufel",
        "Takenobu Tokunaga"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01131",
        "HTML": "https://arxiv.org/html/2412.01131",
        "PDF": "https://arxiv.org/pdf/2412.01131"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Dec 2024 05:11:34 GMT",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:12:51 GMT",
          "size": "218kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Comprehensive Evaluation of Semantic Relation Knowledge of Pretrained Language Models and Humans",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper evaluates semantic relation knowledge in pretrained language models and compares it with humans, but does not involve LLM training data processing."
      },
      "tasks": [
        "Relation"
      ]
    },
    {
      "id": "2412.01402",
      "abstract": "While Gaussian Splatting (GS) demonstrates efficient and high-quality scene rendering and small area surface extraction ability, it falls short in handling large-scale aerial image surface extraction tasks. To overcome this, we present ULSR-GS, a framework dedicated to high-fidelity surface extraction in ultra-large-scale scenes, addressing the limitations of existing GS-based mesh extraction methods. Specifically, we propose a point-to-photo partitioning approach combined with a multi-view optimal view matching principle to select the best training images for each sub-region. Additionally, during training, ULSR-GS employs a densification strategy based on multi-view geometric consistency to enhance surface extraction details. Experimental results demonstrate that ULSR-GS outperforms other state-of-the-art GS-based works on large-scale aerial photogrammetry benchmark datasets, significantly improving surface extraction accuracy in complex urban environments. Project page: https://ulsrgs.github.io.",
      "authors": [
        "Zhuoxiao Li",
        "Shanliang Yao",
        "Taoyu Wu",
        "Yong Yue",
        "Wufan Zhao",
        "Rongjun Qin",
        "Angel F. Garcia-Fernandez",
        "Andrew Levers",
        "Xiaohui Zhu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01402",
        "HTML": "https://arxiv.org/html/2412.01402",
        "PDF": "https://arxiv.org/pdf/2412.01402"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Dec 2024 11:42:35 GMT",
          "size": "47580kb",
          "version": "v1"
        },
        {
          "date": "Sat, 19 Apr 2025 08:39:21 GMT",
          "size": "20125kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 10:32:44 GMT",
          "size": "21279kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ULSR-GS: Ultra Large-scale Surface Reconstruction Gaussian Splatting with Multi-View Geometric Consistency",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on surface reconstruction in large-scale scenes using aerial images and enhances surface extraction techniques. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Surface Reconstruction"
      ]
    },
    {
      "id": "2412.01493",
      "abstract": "Learning lighting adaptation is a crucial step in achieving good visual perception and supporting downstream vision tasks. Current research often addresses individual light-related challenges, such as high dynamic range imaging and exposure correction, in isolation. However, we identify shared fundamental properties across these tasks: i) different color channels have different light properties, and ii) the channel differences reflected in the spatial and frequency domains are different. Leveraging these insights, we introduce the channel-aware Learning Adaptive Lighting Network (LALNet), a multi-task framework designed to handle multiple light-related tasks efficiently. Specifically, LALNet incorporates color-separated features that highlight the unique light properties of each color channel, integrated with traditional color-mixed features by Light Guided Attention (LGA). The LGA utilizes color-separated features to guide color-mixed features focusing on channel differences and ensuring visual consistency across all channels. Additionally, LALNet employs dual domain channel modulation for generating color-separated features and a mixed channel modulation and light state space module for producing color-mixed features. Extensive experiments on four representative light-related tasks demonstrate that LALNet significantly outperforms state-of-the-art methods on benchmark tests and requires fewer computational resources. We provide an anonymous online demo at https://xxxxxx2025.github.io/LALNet/.",
      "authors": [
        "Qirui Yang",
        "Peng-Tao Jiang",
        "Hao Zhang",
        "Jinwei Chen",
        "Bo Li",
        "Huanjing Yue",
        "Jingyu Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01493",
        "HTML": "https://arxiv.org/html/2412.01493",
        "PDF": "https://arxiv.org/pdf/2412.01493"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Dec 2024 13:44:53 GMT",
          "size": "17753kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:27:10 GMT",
          "size": "9130kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Learning Adaptive Lighting via Channel-Aware Guidance",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about a framework for adaptive lighting in visual perception tasks. It doesn't involve the processing or engineering of LLM training data."
      },
      "tasks": [
        "Exposure Correction",
        "Image Retouching"
      ]
    },
    {
      "id": "2412.02138",
      "abstract": "WordNet provides a carefully constructed repository of semantic relations, created by specialists. But there is another source of information on semantic relations, the intuition of language users. We present the first systematic study of the degree to which these two sources are aligned. Investigating the cases of misalignment could make proper use of WordNet and facilitate its improvement. Our analysis which uses templates to elicit responses from human participants, reveals a general misalignment of semantic relation knowledge between WordNet and human intuition. Further analyses find a systematic pattern of mismatch among synonymy and taxonomic relations~(hypernymy and hyponymy), together with the fact that WordNet path length does not serve as a reliable indicator of human intuition regarding hypernymy or hyponymy relations.",
      "authors": [
        "Zhihan Cao",
        "Hiroaki Yamada",
        "Simone Teufel",
        "Takenobu Tokunaga"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02138",
        "HTML": "https://arxiv.org/html/2412.02138",
        "PDF": "https://arxiv.org/pdf/2412.02138"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 03 Dec 2024 03:51:31 GMT",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:09:45 GMT",
          "size": "95kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Misalignment of Semantic Relation Knowledge between WordNet and Human Intuition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of this paper is on the alignment of semantic relations between WordNet and human intuition. There is no discussion on LLM training data processing or engineering."
      },
      "tasks": [
        "Relation"
      ]
    },
    {
      "id": "2412.02863",
      "abstract": "The human-robot interaction (HRI) is a growing area of research. In HRI, complex command (action) classification is still an open problem that usually prevents the real applicability of such a technique. The literature presents some works that use neural networks to detect these actions. However, occlusion is still a major issue in HRI, especially when using uncrewed aerial vehicles (UAVs), since, during the robot's movement, the human operator is often out of the robot's field of view. Furthermore, in multi-robot scenarios, distributed training is also an open problem. In this sense, this work proposes an action recognition and control approach based on Long Short-Term Memory (LSTM) Deep Neural Networks with two layers in association with three densely connected layers and Federated Learning (FL) embedded in multiple drones. The FL enabled our approach to be trained in a distributed fashion, i.e., access to data without the need for cloud or other repositories, which facilitates the multi-robot system's learning. Furthermore, our multi-robot approach results also prevented occlusion situations, with experiments with real robots achieving an accuracy greater than 96%.",
      "authors": [
        "Lucas Nogueira Nobrega",
        "Ewerton de Oliveira",
        "Martin Saska and Tiago Nascimento"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02863",
        "HTML": "https://arxiv.org/html/2412.02863",
        "PDF": "https://arxiv.org/pdf/2412.02863"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 03 Dec 2024 21:57:04 GMT",
          "size": "9886kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:15:12 GMT",
          "size": "9884kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Proximal Control of UAVs with Federated Learning for Human-Robot Collaborative Domains",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses Federated Learning for action recognition in UAVs and human-robot interaction. It doesn't cover topics related to LLM training data processing."
      },
      "tasks": [
        "Action Classification",
        "Action Recognition",
        "Federated Learning"
      ]
    },
    {
      "id": "2412.03905",
      "abstract": "LLMs have garnered considerable attention for their potential to streamline Automated Program Repair (APR). LLM-based approaches can either insert the correct code or directly generate patches when provided with buggy methods. However, most of LLM-based APR methods rely on a single type of software information, without fully leveraging different software artifacts. Despite this, many LLM-based approaches do not explore which specific types of information best assist in APR. Addressing this gap is crucial for advancing LLM-based APR techniques. We propose DEVLoRe to use issue content (description and message) and stack error traces to localize buggy methods, then rely on debug information in buggy methods and issue content and stack error to localize buggy lines and generate plausible patches which can pass all unit tests. The results show that while issue content is particularly effective in assisting LLMs with fault localization and program repair, different types of software artifacts complement each other. By incorporating different artifacts, DEVLoRe successfully locates 49.3% and 47.6% of single and non-single buggy methods and generates 56.0% and 14.5% plausible patches for the Defects4J v2.0 dataset, respectively. This outperforms current state-of-the-art APR methods. Furthermore, we re-implemented and evaluated our framework, demonstrating its effectiveness in its effectiveness in resolving 9 unique issues compared to other state-of-the-art frameworks using the same or more advanced models on SWE-bench Lite.We also discussed whether a leading framework for Python code can be directly applied to Java code, or vice versa. The source code and experimental results of this work for replication are available at https://github.com/XYZboom/DEVLoRe.",
      "authors": [
        "Qiong Feng",
        "Xiaotian Ma",
        "Jiayi Sheng",
        "Ziyuan Feng",
        "Wei Song",
        "Peng Liang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03905",
        "HTML": "https://arxiv.org/html/2412.03905",
        "PDF": "https://arxiv.org/pdf/2412.03905"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Dec 2024 06:21:31 GMT",
          "size": "2595kb",
          "version": "v1"
        },
        {
          "date": "Tue, 04 Mar 2025 07:06:35 GMT",
          "size": "2595kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 16:21:54 GMT",
          "size": "2407kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Integrating Various Software Artifacts for Better LLM-based Bug Localization and Program Repair",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research is about enhancing automated program repair using LLMs and software artifacts. It does not directly pertain to LLM training data processing or engineering."
      },
      "tasks": [
        "Fault localization",
        "Program Repair"
      ],
      "repo_urls": [
        "https://github.com/xyzboom/devlore"
      ]
    },
    {
      "id": "2412.06413",
      "abstract": "Vision-and-Language Navigation (VLN) is a challenging task that requires an agent to navigate through photorealistic environments following natural-language instructions. One main obstacle existing in VLN is data scarcity, leading to poor generalization performance over unseen environments. Though data argumentation is a promising way for scaling up the dataset, how to generate VLN data both diverse and world-consistent remains problematic. To cope with this issue, we propose the world-consistent data generation (WCGEN), an efficacious data-augmentation framework satisfying both diversity and world-consistency, aimed at enhancing the generalization of agents to novel environments. Roughly, our framework consists of two stages, the trajectory stage which leverages a point-cloud based technique to ensure spatial coherency among viewpoints, and the viewpoint stage which adopts a novel angle synthesis method to guarantee spatial and wraparound consistency within the entire observation. By accurately predicting viewpoint changes with 3D knowledge, our approach maintains the world-consistency during the generation procedure. Experiments on a wide range of datasets verify the effectiveness of our method, demonstrating that our data augmentation strategy enables agents to achieve new state-of-the-art results on all navigation tasks, and is capable of enhancing the VLN agents' generalization ability to unseen environments.",
      "authors": [
        "Yu Zhong",
        "Rui Zhang",
        "Zihao Zhang",
        "Shuo Wang",
        "Chuan Fang",
        "Xishan Zhang",
        "Jiaming Guo",
        "Shaohui Peng",
        "Di Huang",
        "Yanyang Yan",
        "Xing Hu",
        "Qi Guo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06413",
        "HTML": "https://arxiv.org/html/2412.06413",
        "PDF": "https://arxiv.org/pdf/2412.06413"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Dec 2024 11:40:54 GMT",
          "size": "3216kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:03:04 GMT",
          "size": "2467kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "World-Consistent Data Generation for Vision-and-Language Navigation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on data generation for Vision-and-Language Navigation tasks, which involves generating augmented datasets for navigation training. It does not propose methods relevant to LLM training data preparation or processing."
      },
      "tasks": [
        "Data Augmentation",
        "Navigate",
        "Vision and Language Navigation"
      ]
    },
    {
      "id": "2412.09019",
      "abstract": "In this paper, we address the problem of robust stabilization for linear hyperbolic Partial Differential Equations (PDEs) with Markov-jumping parameter uncertainty. We consider a 2 x 2 heterogeneous hyperbolic PDE and propose a control law using operator learning and the backstepping method. Specifically, the backstepping kernels used to construct the control law are approximated with neural operators (NO) in order to improve computational efficiency. The key challenge lies in deriving the stability conditions with respect to the Markov-jumping parameter uncertainty and NO approximation errors. The mean-square exponential stability of the stochastic system is achieved through Lyapunov analysis, indicating that the system can be stabilized if the random parameters are sufficiently close to the nominal parameters on average, and NO approximation errors are small enough. The theoretical results are applied to freeway traffic control under stochastic upstream demands and then validated through numerical simulations.",
      "authors": [
        "Yihuai Zhang",
        "Jean Auriol",
        "Huan Yu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09019",
        "HTML": "https://arxiv.org/html/2412.09019",
        "PDF": "https://arxiv.org/pdf/2412.09019"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 12 Dec 2024 07:31:10 GMT",
          "size": "3021kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:34:14 GMT",
          "size": "1623kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Operator Learning for Robust Stabilization of Linear Markov-Jumping Hyperbolic PDEs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of this paper is on robust stabilization of hyperbolic PDEs with Markov-jumping parameters using operator learning, with no attention to LLM training data or related data processing tasks."
      },
      "tasks": [
        "Computational Efficiency",
        "Operator learning"
      ]
    },
    {
      "id": "2412.12587",
      "abstract": "Driven by the vision of ubiquitous connectivity and wireless intelligence, the evolution of ultra-dense constellation-based satellite-integrated Internet is underway, now taking preliminary shape. Nevertheless, the entrenched institutional silos and limited, nonrenewable heterogeneous network resources leave current satellite systems struggling to accommodate the escalating demands of next-generation intelligent applications. In this context, the distributed satellite information networks (DSIN), exemplified by the cohesive clustered satellites system, have emerged as an innovative architecture, bridging information gaps across diverse satellite systems, such as communication, navigation, and remote sensing, and establishing a unified, open information network paradigm to support resilient space information services. This survey first provides a profound discussion about innovative network architectures of DSIN, encompassing distributed regenerative satellite network architecture, distributed satellite computing network architecture, and reconfigurable satellite formation flying, to enable flexible and scalable communication, computing and control. The DSIN faces challenges from network heterogeneity, unpredictable channel dynamics, sparse resources, and decentralized collaboration frameworks. To address these issues, a series of enabling technologies is identified, including channel modeling and estimation, cloud-native distributed MIMO cooperation, grant-free massive access, network routing, and the proper combination of all these diversity techniques. Furthermore, to heighten the overall resource efficiency, the cross-layer optimization techniques are further developed to meet upper-layer deterministic, adaptive and secure information services requirements. In addition, emerging research directions and new opportunities are highlighted on the way to achieving the DSIN vision.",
      "authors": [
        "Qinyu Zhang",
        "Liang Xu",
        "Jianhao Huang",
        "Tao Yang",
        "Jian Jiao",
        "Ye Wang",
        "Yao Shi",
        "Chiya Zhang",
        "Xingjian Zhang",
        "Ke Zhang",
        "Yupeng Gong",
        "Na Deng",
        "Nan Zhao",
        "Zhen Gao",
        "Shujun Han",
        "Xiaodong Xu",
        "Li You",
        "Dongming Wang",
        "Shan Jiang",
        "Dixian Zhao",
        "Nan Zhang",
        "Liujun Hu",
        "Xiongwen He",
        "Yonghui Li",
        "Xiqi Gao",
        "Xiaohu You"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.12587",
        "HTML": "https://arxiv.org/html/2412.12587",
        "PDF": "https://arxiv.org/pdf/2412.12587"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Dec 2024 06:44:05 GMT",
          "size": "11783kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:50:42 GMT",
          "size": "11246kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Distributed satellite information networks: Architecture, enabling technologies, and trends",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is concerned with satellite information network architectures and enabling technologies, which are not related to LLM training data collection or processing."
      },
      "tasks": []
    },
    {
      "id": "2412.13776",
      "abstract": "In this paper, the problem of distributively seeking the equilibria of aggregative games with bilevel structures is studied. Different from the traditional aggregative games, here the aggregation is determined by the minimizer of a virtual leader's objective function in the inner level, which depends on the actions of the players in the outer level. Moreover, the global objective function of the virtual leader is formed by the sum of some local functions with two arguments, each of which is strongly convex with respect to the second argument. When making decisions, each player in the outer level only has access to a local part of the virtual leader's objective function. To handle this problem, first, we propose a second order gradient-based distributed algorithm, where the Hessian matrices associated with the objective functions of the leader are involved. By the algorithm, players update their actions while cooperatively minimizing the objective function of the virtual leader to estimate the aggregation by communicating with their neighbors via a connected graph. Under mild assumptions on the graph and cost functions, we prove that the actions of players asymptotically converge to the Nash equilibrium point. Then, for the case where the Hessian matrices associated with the objective functions of the virtual leader are not available, we propose a first order gradient-based distributed algorithm, where a distributed two-point estimate strategy is developed to estimate the gradients of players' cost functions in the outer level. Under the same conditions, we prove that the convergence errors of players' actions to the Nash equilibrium point are linear with respect to the estimate parameters. Finally, simulations are provided to demonstrate the effectiveness of our theoretical results.",
      "authors": [
        "Kaihong Lu",
        "Huanshui Zhang",
        "Long Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13776",
        "HTML": "https://arxiv.org/html/2412.13776",
        "PDF": "https://arxiv.org/pdf/2412.13776"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Dec 2024 12:13:37 GMT",
          "size": "2508kb",
          "version": "v1"
        },
        {
          "date": "Fri, 20 Dec 2024 11:48:25 GMT",
          "size": "5017kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 00:51:39 GMT",
          "size": "1690kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Aggregative games with bilevel structures: Distributed algorithms and convergence analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research addresses distributed algorithms for aggregative game equilibria, involving mathematical optimization for decision-making processes, without any connection to LLM training data processing."
      },
      "tasks": []
    },
    {
      "id": "2412.13938",
      "abstract": "In this paper, we study the Contiguous Art Gallery Problem, introduced by Thomas C. Shermer at the 2024 Canadian Conference on Computational Geometry, a variant of the classical art gallery problem from 1973 by Victor Klee. In the contiguous variant, the input is a simple polygon $P$, and the goal is to partition the boundary into a minimum number of polygonal chains such that each chain is visible to a guard. We present a polynomial-time real RAM algorithm, which solves the contiguous art gallery problem. Our algorithm is simple and practical, and we make a C++ implementation available.\n  In contrast, many variations of the art gallery problem are at least NP-hard, making the contiguous variant stand out. These include the edge-covering problem, proven NP-hard by Laurentini [The Visual Computer 1999], and the classical art gallery problem, recently shown $\\exists\\mathbb{R}$-complete by Abrahamsen, Adamaszek, and Miltzow [J. ACM 2022]. Our algorithm is a greedy algorithm that repeatedly traverses the polygon's boundary. To find an optimal solution, we show that it is sufficient to traverse the polygon polynomially many times, resulting in a runtime of $\\mathcal{O}\\!\\left( n^7 \\log n \\right)$. Additionally, we provide algorithms for the restricted settings, where either the endpoints of the polygonal chains or the guards must coincide with the vertices of the polygon.",
      "authors": [
        "Magnus Christian Ring Merrild",
        "Casper Moldrup Rysgaard",
        "Jens Kristian Refsgaard Schou",
        "Rolf Svenning"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13938",
        "HTML": "https://arxiv.org/html/2412.13938",
        "PDF": "https://arxiv.org/pdf/2412.13938"
      },
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Dec 2024 15:21:37 GMT",
          "size": "70kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:22:23 GMT",
          "size": "79kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Contiguous Art Gallery Problem is Solvable in Polynomial Time",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on solving the Contiguous Art Gallery Problem, a computational geometry problem, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2501.05928",
      "abstract": "Recent research on backdoor stealthiness focuses mainly on indistinguishable triggers in input space and inseparable backdoor representations in feature space, aiming to circumvent backdoor defenses that examine these respective spaces. However, existing backdoor attacks are typically designed to resist a specific type of backdoor defense without considering the diverse range of defense mechanisms. Based on this observation, we pose a natural question: Are current backdoor attacks truly a real-world threat when facing diverse practical defenses?\n  To answer this question, we examine 12 common backdoor attacks that focus on input-space or feature-space stealthiness and 17 diverse representative defenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks designed to be stealthy in input and feature spaces can be mitigated by examining backdoored models in parameter space. To investigate the underlying causes behind this common vulnerability, we study the characteristics of backdoor attacks in the parameter space. Notably, we find that input- and feature-space attacks introduce prominent backdoor-related neurons in parameter space, which are not thoroughly considered by current backdoor attacks. Taking comprehensive stealthiness into account, we propose a novel supply-chain attack called Grond. Grond limits the parameter changes by a simple yet effective module, Adversarial Backdoor Injection (ABI), which adaptively increases the parameter-space stealthiness during the backdoor injection. Extensive experiments demonstrate that Grond outperforms all 12 backdoor attacks against state-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset of ImageNet. In addition, we show that ABI consistently improves the effectiveness of common backdoor attacks.",
      "authors": [
        "Xiaoyun Xu",
        "Zhuoran Liu",
        "Stefanos Koffas",
        "Stjepan Picek"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05928",
        "HTML": "https://arxiv.org/html/2501.05928",
        "PDF": "https://arxiv.org/pdf/2501.05928"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 10 Jan 2025 12:49:12 GMT",
          "size": "2127kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 19:40:14 GMT",
          "size": "2249kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Towards Backdoor Stealthiness in Model Parameter Space",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research addresses backdoor attacks and defenses within models but does not pertain to LLM training data engineering or processing."
      },
      "tasks": [
        "backdoor defense",
        "model"
      ],
      "repo_urls": [
        "https://github.com/xiaoyunxxy/parameter_backdoor"
      ]
    },
    {
      "id": "2501.07113",
      "abstract": "We introduce a novel approach for depth estimation using images obtained from monocular structured light systems. In contrast to many existing methods that depend on image matching, our technique employs a density voxel grid to represent scene geometry. This grid is trained through self-supervised differentiable volume rendering. Our method leverages color fields derived from the projected patterns in structured light systems during the rendering process, facilitating the isolated optimization of the geometry field. This innovative approach leads to faster convergence and high-quality results. Additionally, we integrate normalized device coordinates (NDC), a distortion loss, and a distinctive surface-based color loss to enhance geometric fidelity. Experimental results demonstrate that our method outperforms current matching-based techniques in terms of geometric performance in few-shot scenarios, achieving an approximately 30% reduction in average estimated depth errors for both synthetic scenes and real-world captured scenes. Moreover, our approach allows for rapid training, being approximately three times faster than previous matching-free methods that utilize implicit representations.",
      "authors": [
        "Zhuohang Yu",
        "Kai Wang",
        "Kun Huang",
        "Juyong Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07113",
        "HTML": "https://arxiv.org/html/2501.07113",
        "PDF": "https://arxiv.org/pdf/2501.07113"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 13 Jan 2025 08:03:49 GMT",
          "size": "24443kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:47:49 GMT",
          "size": "19013kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Matching-Free Depth Recovery from Structured Light",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on depth estimation using monocular structured light systems through a novel approach unrelated to large language model training data processing."
      },
      "tasks": [
        "Depth Estimation"
      ]
    },
    {
      "id": "2501.12050",
      "abstract": "Quantum machine learning (QML) offers a promising avenue for advancing representation learning in complex signal domains. In this study, we investigate the use of parameterised quantum circuits (PQCs) for speech emotion recognition (SER) a challenging task due to the subtle temporal variations and overlapping affective states in vocal signals. We propose a hybrid quantum classical architecture that integrates PQCs into a conventional convolutional neural network (CNN), leveraging quantum properties such as superposition and entanglement to enrich emotional feature representations. Experimental evaluations on three benchmark datasets IEMOCAP, RECOLA, and MSP-IMPROV demonstrate that our hybrid model achieves improved classification performance relative to a purely classical CNN baseline, with over 50% reduction in trainable parameters. This work provides early evidence of the potential for QML to enhance emotion recognition and lays the foundation for future quantum-enabled affective computing systems.",
      "authors": [
        "Thejan Rajapakshe",
        "Rajib Rana",
        "Farina Riaz",
        "Sara Khalifa",
        "Bj\\\"orn W. Schuller"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12050",
        "HTML": "https://arxiv.org/html/2501.12050",
        "PDF": "https://arxiv.org/pdf/2501.12050"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 21 Jan 2025 11:23:38 GMT",
          "size": "780kb",
          "version": "v1"
        },
        {
          "date": "Tue, 28 Jan 2025 12:19:54 GMT",
          "size": "772kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 11:26:43 GMT",
          "size": "362kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Representation Learning with Parameterised Quantum Circuits for Advancing Speech Emotion Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study is about using quantum circuits for speech emotion recognition and does not involve any aspects of training data processing for large language models."
      },
      "tasks": [
        "Emotion Classification",
        "Emotion Recognition",
        "Representation Learning",
        "Speech Emotion Recognition"
      ]
    },
    {
      "id": "2501.17726",
      "abstract": "As artificial intelligence (AI) becomes increasingly central to healthcare, the demand for explainable and trustworthy models is paramount. Current report generation systems for chest X-rays (CXR) often lack mechanisms for validating outputs without expert oversight, raising concerns about reliability and interpretability. To address these challenges, we propose a novel multimodal framework designed to enhance the semantic alignment and localization accuracy of AI-generated medical reports. Our framework integrates two key modules: a Phrase Grounding Model, which identifies and localizes pathologies in CXR images based on textual prompts, and a Text-to-Image Diffusion Module, which generates synthetic CXR images from prompts while preserving anatomical fidelity. By comparing features between the original and generated images, we introduce a dual-scoring system: one score quantifies localization accuracy, while the other evaluates semantic consistency. This approach significantly outperforms existing methods, achieving state-of-the-art results in pathology localization and text-to-image alignment. The integration of phrase grounding with diffusion models, coupled with the dual-scoring evaluation system, provides a robust mechanism for validating report quality, paving the way for more trustworthy and transparent AI in medical imaging.",
      "authors": [
        "Sayeh Gholipour Picha",
        "Dawood Al Chanti and Alice Caplier"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17726",
        "HTML": "https://arxiv.org/html/2501.17726",
        "PDF": "https://arxiv.org/pdf/2501.17726"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 29 Jan 2025 16:02:16 GMT",
          "size": "27577kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 11:13:35 GMT",
          "size": "26661kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research discusses mechanisms for report validation in medical imaging without focusing on the data processing aspects for LLMs."
      },
      "tasks": [
        "Phrase Grounding"
      ]
    },
    {
      "id": "2501.18395",
      "abstract": "In this manuscript, we propose newly-derived exponential quadrature rules for stiff linear differential equations with time-dependent fractional sources in the form $h(t^r)$, with $0<r<1$ and $h$ a sufficiently smooth function. To construct the methods, the source term is interpolated at $\\nu$ collocation points by a suitable non-polynomial function, yielding to time marching schemes that we call Exponential Quadrature Rules for Fractional sources (EQRF$\\nu$). The error analysis is done in the framework of strongly continuous semigroups. Compared to classical exponential quadrature rules, which in our case of interest converge with order $1+r$ at most, we prove that the new methods may reach order $1+\\nu r$ for proper choices of the collocation points. We also show that the proposed integrators can be written in terms of special instances of the Mittag--Leffler functions that we call fractional $\\varphi$ functions. Several numerical experiments demonstrate the theoretical findings and highlight the effectiveness of the approach.",
      "authors": [
        "Marco Caliari and Fabio Cassini"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18395",
        "HTML": "https://arxiv.org/html/2501.18395",
        "PDF": "https://arxiv.org/pdf/2501.18395"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 30 Jan 2025 14:51:33 GMT",
          "size": "87kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:06:10 GMT",
          "size": "86kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Exponential quadrature rules for problems with time-dependent fractional source",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work focuses on exponential quadrature rules for differential equations with fractional sources, not connected to LLM training data processing."
      }
    },
    {
      "id": "2501.19195",
      "abstract": "Machine learning classifiers often produce probabilistic predictions that are critical for accurate and interpretable decision-making in various domains. The quality of these predictions is generally evaluated with proper losses, such as cross-entropy, which decompose into two components: calibration error assesses general under/overconfidence, while refinement error measures the ability to distinguish different classes. In this paper, we present a novel variational formulation of the calibration-refinement decomposition that sheds new light on post-hoc calibration, and enables rapid estimation of the different terms. Equipped with this new perspective, we provide theoretical and empirical evidence that calibration and refinement errors are not minimized simultaneously during training. Selecting the best epoch based on validation loss thus leads to a compromise point that is suboptimal for both terms. To address this, we propose minimizing refinement error only during training (Refine,...), before minimizing calibration error post hoc, using standard techniques (...then Calibrate). Our method integrates seamlessly with any classifier and consistently improves performance across diverse classification tasks.",
      "authors": [
        "Eug\\`ene Berta",
        "David Holzm\\\"uller",
        "Michael I. Jordan",
        "Francis Bach"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19195",
        "HTML": "https://arxiv.org/html/2501.19195",
        "PDF": "https://arxiv.org/pdf/2501.19195"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 31 Jan 2025 15:03:54 GMT",
          "size": "7501kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:24:12 GMT",
          "size": "6610kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Rethinking Early Stopping: Refine, Then Calibrate",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on improving machine learning classifiers by proposing a method involving calibration and refinement errors, with no discussion on LLM training data collection or processing."
      },
      "tasks": [
        "Decision Making"
      ],
      "repo_urls": [
        "https://github.com/eugeneberta/refinethencalibrate-vision",
        "https://github.com/eugeneberta/refinethencalibrate-theory",
        "https://github.com/dholzmueller/probmetrics",
        "https://github.com/dholzmueller/pytabkit"
      ]
    },
    {
      "id": "2502.00757",
      "abstract": "Scaffolding Large Language Models (LLMs) into multi-agent systems often improves performance on complex tasks, but the safety impact of such scaffolds has not been thoroughly explored. We introduce AgentBreeder, a framework for multi-objective self-improving evolutionary search over scaffolds. We evaluate discovered scaffolds on widely recognized reasoning, mathematics, and safety benchmarks and compare them with popular baselines. In 'blue' mode, we see a 79.4% average uplift in safety benchmark performance while maintaining or improving capability scores. In 'red' mode, we find adversarially weak scaffolds emerging concurrently with capability optimization. Our work demonstrates the risks of multi-agent scaffolding and provides a framework for mitigating them. Code is available at https://github.com/J-Rosser-UK/AgentBreeder.",
      "authors": [
        "J Rosser and Jakob Nicolaus Foerster"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00757",
        "HTML": "https://arxiv.org/html/2502.00757",
        "PDF": "https://arxiv.org/pdf/2502.00757"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 02 Feb 2025 11:40:07 GMT",
          "size": "3701kb",
          "version": "v1"
        },
        {
          "date": "Mon, 14 Apr 2025 10:39:33 GMT",
          "size": "1012kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 08:23:23 GMT",
          "size": "1012kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds via Self-Improvement",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study discusses the safety and performance optimization of scaffolding LLMs into multi-agent systems, without addressing LLM training data collection or processing aspects."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/J-Rosser-UK/AgentBreeder"
      ]
    },
    {
      "id": "2502.01633",
      "abstract": "As large language models (LLMs) are becoming more capable and widespread, the study of their failure cases is becoming increasingly important. Recent advances in standardizing, measuring, and scaling test-time compute suggest new methodologies for optimizing models to achieve high performance on hard tasks. In this paper, we apply these advances to the task of model jailbreaking: eliciting harmful responses from aligned LLMs. We develop an adversarial reasoning approach to automatic jailbreaking that leverages a loss signal to guide the test-time compute, achieving SOTA attack success rates against many aligned LLMs, even those that aim to trade inference-time compute for adversarial robustness. Our approach introduces a new paradigm in understanding LLM vulnerabilities, laying the foundation for the development of more robust and trustworthy AI systems.",
      "authors": [
        "Mahdi Sabbaghi",
        "Paul Kassianik",
        "George Pappas",
        "Yaron Singer",
        "Amin Karbasi",
        "Hamed Hassani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01633",
        "HTML": "https://arxiv.org/html/2502.01633",
        "PDF": "https://arxiv.org/pdf/2502.01633"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 03 Feb 2025 18:59:01 GMT",
          "size": "7717kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:31:17 GMT",
          "size": "7752kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Adversarial Reasoning at Jailbreaking Time",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work covers adversarial reasoning to exploit LLM vulnerabilities during test time, without addressing any aspect of training data handling for LLMs."
      },
      "tasks": [
        "Adversarial Robustness"
      ],
      "repo_urls": [
        "https://github.com/helloworld10011/adversarial-reasoning"
      ]
    },
    {
      "id": "2502.02347",
      "abstract": "The parameter convergence relies on a stringent persistent excitation (PE) condition in adaptive control. Several works have proposed a memory term in the last decade to translate the PE condition to a feasible finite excitation (FE) condition. This work proposes a combined model reference adaptive control for a class of uncertain nonlinear systems with an unknown control effectiveness vector. The closed-loop system is exponentially stable under the FE condition. The exponential rate of convergence is independent of the excitation level of the regressor vector and is lower-bounded in terms of the system parameters and user-designed gains. Numerical simulation is illustrated, validating the results obtained with the proposed adaptive control.",
      "authors": [
        "Manish Patel and Arnab Maity"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02347",
        "HTML": "https://arxiv.org/html/2502.02347",
        "PDF": "https://arxiv.org/pdf/2502.02347"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Feb 2025 14:30:29 GMT",
          "size": "1633kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 19:44:01 GMT",
          "size": "682kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Exponentially Stable Combined Adaptive Control under Finite Excitation Condition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on adaptive control systems and does not involve LLMs or any aspect of training data processing related to LLMs."
      },
      "tasks": []
    },
    {
      "id": "2502.02719",
      "abstract": "Self-Explainable Graph Neural Networks (SE-GNNs) are popular explainable-by-design GNNs, but their explanations' properties and limitations are not well understood. Our first contribution fills this gap by formalizing the explanations extracted by some popular SE-GNNs, referred to as Minimal Explanations (MEs), and comparing them to established notions of explanations, namely Prime Implicant (PI) and faithful explanations. Our analysis reveals that MEs match PI explanations for a restricted but significant family of tasks. In general, however, they can be less informative than PI explanations and are surprisingly misaligned with widely accepted notions of faithfulness. Although faithful and PI explanations are informative, they are intractable to find and we show that they can be prohibitively large. Given these observations, a natural choice is to augment SE-GNNs with alternative modalities of explanations taking care of SE-GNNs' limitations. To this end, we propose Dual-Channel GNNs that integrate a white-box rule extractor and a standard SE-GNN, adaptively combining both channels. Our experiments show that even a simple instantiation of Dual-Channel GNNs can recover succinct rules and perform on par or better than widely used SE-GNNs.",
      "authors": [
        "Steve Azzolin",
        "Sagar Malhotra",
        "Andrea Passerini",
        "Stefano Teso"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02719",
        "HTML": "https://arxiv.org/html/2502.02719",
        "PDF": "https://arxiv.org/pdf/2502.02719"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Feb 2025 21:08:23 GMT",
          "size": "969kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:52:40 GMT",
          "size": "762kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on explainable Graph Neural Networks and their explanations without mentioning LLM training data processing or any related data engineering tasks."
      }
    },
    {
      "id": "2502.03000",
      "abstract": "A major challenge in the deployment of scientific software solutions is the adaptation of research prototypes to production-grade code. While high-level languages like MATLAB are useful for rapid prototyping, they lack the resource efficiency required for scalable production applications, necessitating translation into lower level languages like C++. Further, for machine learning and signal processing applications, the underlying linear algebra primitives, generally provided by the standard BLAS and LAPACK libraries, are unwieldy and difficult to use, requiring manual memory management and other tedium. To address this challenge, the Armadillo C++ linear algebra library provides an intuitive interface for writing linear algebra expressions that are easily compiled into efficient production-grade implementations. We describe the expression optimisations we have implemented in Armadillo, exploiting template metaprogramming. We demonstrate that these optimisations result in considerable efficiency gains on a variety of benchmark linear algebra expressions.",
      "authors": [
        "Conrad Sanderson",
        "Ryan Curtin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03000",
        "HTML": "https://arxiv.org/html/2502.03000",
        "PDF": "https://arxiv.org/pdf/2502.03000"
      },
      "subjects": [
        "Mathematical Software (cs.MS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 05 Feb 2025 08:52:37 GMT",
          "size": "105kb",
          "version": "v1"
        },
        {
          "date": "Mon, 10 Feb 2025 14:34:04 GMT",
          "size": "106kb",
          "version": "v2"
        },
        {
          "date": "Wed, 26 Mar 2025 09:02:08 GMT",
          "size": "106kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 07:16:26 GMT",
          "size": "106kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Armadillo: An Efficient Framework for Numerical Linear Algebra",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents an optimized C++ framework for numerical linear algebra. It does not involve discussions on LLM training data processing."
      }
    },
    {
      "id": "2502.04030",
      "abstract": "Reasoning capabilities represent a critical frontier for large language models (LLMs), but developing them requires extensive proprietary datasets and computational resources. One way to efficiently supplement capabilities with is by model merging, which offers a promising alternative by combining multiple models without retraining. However, current merging approaches rely on manually-designed strategies for merging hyperparameters, limiting the exploration of potential model combinations and requiring significant human effort. We propose an Automated Model Merging Framework that enables fine-grained exploration of merging strategies while reducing costs through multi-fidelity approximations. We support both single and multi-objective optimization and introduce two novel search spaces: layerwise fusion (LFS) and depth-wise integration (DIS). Evaluating across a number of benchmarks, we find that the search autonomously finds 1) Merges that further boost single-objective performance, even on tasks the model has already been finetuned on, and 2) Merges that optimize multi-objective frontiers across tasks. Effective merges are found with limited compute, e.g. within less than 500 search steps.",
      "authors": [
        "Guinan Su",
        "Jonas Geiping"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04030",
        "HTML": "https://arxiv.org/html/2502.04030",
        "PDF": "https://arxiv.org/pdf/2502.04030"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 06 Feb 2025 12:47:25 GMT",
          "size": "3467kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:44:30 GMT",
          "size": "3317kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research investigates automated model merging strategies focusing on merging LLMs without details related to the processing of training data for such models."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/guinan-su/auto-merge-llm"
      ]
    },
    {
      "id": "2502.04538",
      "abstract": "Concerns about big tech's monopoly power have featured prominently in recent media and policy discourse, as regulators across the EU, the US, and beyond have ramped up efforts to promote healthier market competition. One favored approach is to require certain kinds of interoperation between platforms, to mitigate the current concentration of power in the biggest companies. Unsurprisingly, interoperability initiatives have generally been met with resistance by big tech companies. Perhaps more surprisingly, a significant part of that pushback has been in the name of security -- that is, arguing against interoperation on the basis that it will undermine security.\n  We conduct a systematic examination of \"security vs. interoperability\" (SvI) discourse in the context of EU antitrust proceedings. Our resulting contributions are threefold. First, we propose a taxonomy of SvI concerns in three categories: engineering, vetting, and hybrid. Second, we present an analytical framework for assessing real-world SvI concerns, and illustrate its utility by analyzing several case studies spanning our three taxonomy categories. Third, we undertake a comparative analysis that highlights key considerations around the interplay of economic incentives, market power, and security across our diverse case study contexts, identifying common patterns in each taxonomy category. Our contributions provide valuable analytical tools for experts and non-experts alike to critically assess SvI discourse in today's fast-paced regulatory landscape.",
      "authors": [
        "Daji Landis",
        "Elettra Bietti",
        "Sunoo Park"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04538",
        "HTML": "https://arxiv.org/html/2502.04538",
        "PDF": "https://arxiv.org/pdf/2502.04538"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 06 Feb 2025 22:21:14 GMT",
          "size": "49kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 22:44:35 GMT",
          "size": "55kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "SoK: \"Interoperability vs Security\" Arguments: A Technical Framework",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper develops a framework around the interoperability and security debates without addressing LLM training data or data engineering practices."
      }
    },
    {
      "id": "2502.06379",
      "abstract": "A recent line of research has exploited pre-trained generative diffusion models as priors for solving Bayesian inverse problems. We contribute to this research direction by designing a sequential Monte Carlo method for linear-Gaussian inverse problems which builds on \"decoupled diffusion\", where the generative process is designed such that larger updates to the sample are possible. The method is asymptotically exact and we demonstrate the effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC) algorithm on both synthetic as well as protein and image data. Further, we demonstrate how the approach can be extended to discrete data.",
      "authors": [
        "Filip Ekstr\\\"om Kelvinius",
        "Zheng Zhao",
        "Fredrik Lindsten"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06379",
        "HTML": "https://arxiv.org/html/2502.06379",
        "PDF": "https://arxiv.org/pdf/2502.06379"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 10 Feb 2025 11:59:02 GMT",
          "size": "24539kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:54:45 GMT",
          "size": "17152kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a sequential Monte Carlo method for solving Bayesian inverse problems using diffusion models, without mention of LLM training data processing or engineering."
      }
    },
    {
      "id": "2502.08914",
      "abstract": "Text-to-image diffusion models have recently enabled the creation of visually compelling, detailed images from textual prompts. However, their ability to accurately represent various cultural nuances remains an open question. In our work, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion models whether they can generate culturally specific images spanning ten countries. We show that these models often fail to generate cultural artifacts in architecture, clothing, and food, especially for underrepresented country regions, by conducting a fine-grained analysis of different similarity aspects, revealing significant disparities in cultural relevance, description fidelity, and realism compared to real-world reference images. With the collected human evaluations, we develop a neural-based image-image similarity metric, namely, CultDiff-S, to predict human judgment on real and generated images with cultural artifacts. Our work highlights the need for more inclusive generative AI systems and equitable dataset representation over a wide range of cultures.",
      "authors": [
        "Zahra Bayramli",
        "Ayhan Suleymanzade",
        "Na Min An",
        "Huzama Ahmad",
        "Eunsu Kim",
        "Junyeong Park",
        "James Thorne",
        "Alice Oh"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08914",
        "HTML": "https://arxiv.org/html/2502.08914",
        "PDF": "https://arxiv.org/pdf/2502.08914"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 13 Feb 2025 03:05:42 GMT",
          "size": "4555kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:32:22 GMT",
          "size": "4560kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Diffusion Models Through a Global Lens: Are They Culturally Inclusive?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study evaluates cultural inclusivity in text-to-image diffusion models, without addressing LLM training data processing or data engineering tasks."
      },
      "tasks": []
    },
    {
      "id": "2502.09664",
      "abstract": "The increasing use of generative ML foundation models for image restoration tasks such as super-resolution calls for robust and interpretable uncertainty quantification methods. We address this need by presenting a novel approach based on conformal prediction techniques to create a 'confidence mask' capable of reliably and intuitively communicating where the generated image can be trusted. Our method is adaptable to any black-box generative model, including those locked behind an opaque API, requires only easily attainable data for calibration, and is highly customizable via the choice of a local image similarity metric. We prove strong theoretical guarantees for our method that span fidelity error control (according to our local image similarity metric), reconstruction quality, and robustness in the face of data leakage. Finally, we empirically evaluate these results and establish our method's solid performance.",
      "authors": [
        "Eduardo Adame",
        "Daniel Csillag and Guilherme Tegoni Goedert"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09664",
        "HTML": "https://arxiv.org/html/2502.09664",
        "PDF": "https://arxiv.org/pdf/2502.09664"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 12 Feb 2025 13:14:57 GMT",
          "size": "22614kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:51:55 GMT",
          "size": "19617kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Image Super-Resolution with Guarantees via Conformalized Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on image super-resolution and conformalized generative models for uncertainty quantification, which is not related to LLM training data processing tasks."
      }
    },
    {
      "id": "2502.09949",
      "abstract": "Decentralized Autonomous Organizations (DAOs) are attracting interdisciplinary interest, particularly in business, economics, and computer science. However, much like the parable of the blind men and the elephant, where each observer perceives only a fragment of the whole, DAO research remains fragmented across disciplines, limiting a comprehensive understanding of their potential. This paper assesses the maturity of interdisciplinary research on DAOs by analyzing knowledge flows between Business & Economics and Computer Science through citation network analysis, topic modelling, and outlet analysis. Our findings reveal that while DAOs serve as a vibrant topic of interdisciplinary discourse, current research remains predominantly applied and case-driven, with limited theoretical integration. Strengthening the alignment between organizational and technical insights is crucial for advancing DAO research and fostering a more cohesive interdisciplinary framework.",
      "authors": [
        "Giorgia Samp\\`o and Oliver Baumann and Marco Peressotti"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09949",
        "HTML": "https://arxiv.org/html/2502.09949",
        "PDF": "https://arxiv.org/pdf/2502.09949"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 14 Feb 2025 07:06:43 GMT",
          "size": "1736kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:46:13 GMT",
          "size": "1008kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Blind Men and the Elephant: Mapping Interdisciplinarity in Research on Decentralized Autonomous Organizations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses interdisciplinary research mapping in the context of Decentralized Autonomous Organizations (DAOs), with no focus on LLM training data or processing."
      }
    },
    {
      "id": "2502.10381",
      "abstract": "Class imbalance remains a major challenge in machine learning, especially in multi-class problems with long-tailed distributions. Existing methods, such as data resampling, cost-sensitive techniques, and logistic loss modifications, though popular and often effective, lack solid theoretical foundations. As an example, we demonstrate that cost-sensitive methods are not Bayes-consistent. This paper introduces a novel theoretical framework for analyzing generalization in imbalanced classification. We then propose a new class-imbalanced margin loss function for both binary and multi-class settings, prove its strong $H$-consistency, and derive corresponding learning guarantees based on empirical loss and a new notion of class-sensitive Rademacher complexity. Leveraging these theoretical results, we devise novel and general learning algorithms, IMMAX (Imbalanced Margin Maximization), which incorporate confidence margins and are applicable to various hypothesis sets. While our focus is theoretical, we also present extensive empirical results demonstrating the effectiveness of our algorithms compared to existing baselines.",
      "authors": [
        "Corinna Cortes",
        "Anqi Mao",
        "Mehryar Mohri",
        "Yutao Zhong"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10381",
        "HTML": "https://arxiv.org/html/2502.10381",
        "PDF": "https://arxiv.org/pdf/2502.10381"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 14 Feb 2025 18:57:16 GMT",
          "size": "68kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:36:30 GMT",
          "size": "71kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Balancing the Scales: A Theoretical and Algorithmic Framework for Learning from Imbalanced Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a theoretical and algorithmic framework for learning from imbalanced data in classification, unrelated to LLM training data processing or engineering."
      }
    },
    {
      "id": "2502.11677",
      "abstract": "Large language models (LLMs) exhibit impressive performance across diverse tasks but often struggle to accurately gauge their knowledge boundaries, leading to confident yet incorrect responses. This paper explores leveraging LLMs' internal states to enhance their perception of knowledge boundaries from efficiency and risk perspectives. We investigate whether LLMs can estimate their confidence using internal states before response generation, potentially saving computational resources. Our experiments on datasets like Natural Questions, HotpotQA, and MMLU reveal that LLMs demonstrate significant pre-generation perception, which is further refined post-generation, with perception gaps remaining stable across varying conditions. To mitigate risks in critical domains, we introduce Confidence Consistency-based Calibration ($C^3$), which assesses confidence consistency through question reformulation. $C^3$ significantly improves LLMs' ability to recognize their knowledge gaps, enhancing the unknown perception rate by 5.6% on NQ and 4.9% on HotpotQA. Our findings suggest that pre-generation confidence estimation can optimize efficiency, while $C^3$ effectively controls output risks, advancing the reliability of LLMs in practical applications.",
      "authors": [
        "Shiyu Ni",
        "Keping Bi",
        "Jiafeng Guo",
        "Lulu Yu",
        "Baolong Bi",
        "Xueqi Cheng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11677",
        "HTML": "https://arxiv.org/html/2502.11677",
        "PDF": "https://arxiv.org/pdf/2502.11677"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Feb 2025 11:11:09 GMT",
          "size": "8169kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:46:10 GMT",
          "size": "7248kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work explores leveraging LLM internal states to improve knowledge boundary perception. It does not address LLM training data collection, construction, or processing."
      },
      "tasks": [
        "MMLU",
        "Natural Questions",
        "Response Generation"
      ]
    },
    {
      "id": "2502.11707",
      "abstract": "This study utilizes the game Codenames as a benchmarking tool to evaluate large language models (LLMs) with respect to specific linguistic and cognitive skills. LLMs play each side of the game, where one side generates a clue word covering several target words and the other guesses those target words. We designed various experiments by controlling the choice of words (abstract vs. concrete words, ambiguous vs. monosemic) or the opponent (programmed to be faster or slower in revealing words). Recent commercial and open-weight models were compared side-by-side to find out factors affecting their performance. The evaluation reveals details about their strategies, challenging cases, and limitations of LLMs.",
      "authors": [
        "Sherzod Hakimov",
        "Lara Pfennigschmidt",
        "David Schlangen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11707",
        "HTML": "https://arxiv.org/html/2502.11707",
        "PDF": "https://arxiv.org/pdf/2502.11707"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Feb 2025 11:46:46 GMT",
          "size": "9486kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:48:16 GMT",
          "size": "9488kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Ad-hoc Concept Forming in the Game Codenames as a Means for Evaluating Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study uses the game Codenames to evaluate LLMs' linguistic and cognitive abilities, without focusing on training data engineering or processing for LLMs."
      },
      "tasks": [
        "Benchmarking"
      ]
    },
    {
      "id": "2502.11874",
      "abstract": "Vague quantifiers such as \"a few\" and \"many\" are influenced by various contextual factors, including the number of objects present in a given context. In this work, we evaluate the extent to which vision-and-language models (VLMs) are compatible with humans when producing or judging the appropriateness of vague quantifiers in visual contexts. We release a novel dataset, VAQUUM, containing 20,300 human ratings on quantified statements across a total of 1089 images. Using this dataset, we compare human judgments and VLM predictions using three different evaluation methods. Our findings show that VLMs, like humans, are influenced by object counts in vague quantifier use. However, we find significant inconsistencies across models in different evaluation settings, suggesting that judging and producing vague quantifiers rely on two different processes.",
      "authors": [
        "Hugh Mee Wong",
        "Rick Nouwen",
        "Albert Gatt"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11874",
        "HTML": "https://arxiv.org/html/2502.11874",
        "PDF": "https://arxiv.org/pdf/2502.11874"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Feb 2025 15:02:09 GMT",
          "size": "1415kb",
          "version": "v1"
        },
        {
          "date": "Tue, 18 Feb 2025 15:27:28 GMT",
          "size": "1415kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 10:46:05 GMT",
          "size": "369kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "VAQUUM: Are Vague Quantifiers Grounded in Visual Data?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating vision-and-language models' compatibility with humans in using vague quantifiers and introduces a dataset for this purpose, but it does not discuss any LLM training data processing tasks."
      },
      "tasks": []
    },
    {
      "id": "2502.16038",
      "abstract": "In an era of emotionally saturated digital media and information overload, effective communication demands more than clarity and accuracy-it requires emotional awareness. This review introduces the paradigm of emotion-aware design, a framework grounded in the valence-arousal-dominance (VAD) model of affect, which systematically examines how emotional modulation shapes comprehension, memory, and behavior. Drawing on insights from psychology, neuroscience, communication, and design, we show that emotional responses significantly influence how information is perceived, retained, and shared. We further propose a multimodal design space-encompassing text, visuals, audio, and interaction-that enables strategic regulation of emotional dimensions to enhance communication efficacy. By linking emotional dynamics to cognitive outcomes and practical design strategies, this review offers both a conceptual foundation and an applied roadmap for designing emotionally resonant communication across domains such as education, health, media, and public discourse.",
      "authors": [
        "Shixiong Cao",
        "Nan Cao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16038",
        "HTML": "https://arxiv.org/html/2502.16038",
        "PDF": "https://arxiv.org/pdf/2502.16038"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 22 Feb 2025 02:07:06 GMT",
          "size": "5838kb",
          "version": "v1"
        },
        {
          "date": "Mon, 03 Mar 2025 05:53:08 GMT",
          "size": "5839kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 17:09:11 GMT",
          "size": "3753kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Emotion-Aware Design: Modulating Valence, Arousal, and Dominance in Communication via Design",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses emotion-aware design in communication and does not address any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2502.17848",
      "abstract": "Recent progress in Large Reasoning Models (LRMs) has significantly enhanced the reasoning abilities of Large Language Models (LLMs), empowering them to tackle increasingly complex tasks through reflection capabilities, such as making assumptions, backtracking, and self-refinement. However, effectively evaluating such reflection capabilities remains challenging due to the lack of appropriate benchmarks. To bridge this gap, we introduce LR$^2$Bench, a novel benchmark designed to evaluate the Long-chain Reflective Reasoning capabilities of LLMs. LR$^2$Bench comprises 850 samples across six Constraint Satisfaction Problems (CSPs) where reflective reasoning is crucial for deriving solutions that meet all given constraints. Each type of task focuses on distinct constraint patterns, such as knowledge-based, logical, and spatial constraints, providing a comprehensive evaluation of diverse problem-solving scenarios. Our extensive evaluation on both conventional LLMs and LRMs reveals that even the most advanced LRMs, such as DeepSeek-R1 and OpenAI o1-preview, struggle with tasks in LR$^2$Bench, achieving an average Exact Match score of only 20.0% and 23.6%, respectively. These findings underscore the significant room for improvement in the reflective reasoning capabilities of current LLMs.",
      "authors": [
        "Jianghao Chen",
        "Zhenlin Wei",
        "Zhenjiang Ren",
        "Ziyong Li",
        "Jiajun Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17848",
        "HTML": "https://arxiv.org/html/2502.17848",
        "PDF": "https://arxiv.org/pdf/2502.17848"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 25 Feb 2025 04:51:17 GMT",
          "size": "1110kb",
          "version": "v1"
        },
        {
          "date": "Mon, 17 Mar 2025 07:36:01 GMT",
          "size": "1110kb",
          "version": "v2"
        },
        {
          "date": "Wed, 02 Apr 2025 03:12:15 GMT",
          "size": "1107kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 09:36:23 GMT",
          "size": "1196kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LR^2Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating the reasoning capabilities of LLMs through a benchmark, LR^2Bench, designed for constraint satisfaction problems, with no mention of processing or constructing training data for LLMs."
      },
      "tasks": []
    },
    {
      "id": "2502.19119",
      "abstract": "Chemical reaction data is a pivotal asset, driving advances in competitive fields such as pharmaceuticals, materials science, and industrial chemistry. Its proprietary nature renders it sensitive, as it often includes confidential insights and competitive advantages organizations strive to protect. However, in contrast to this need for confidentiality, the current standard training paradigm for machine learning-based retrosynthesis gathers reaction data from multiple sources into one single edge to train prediction models. This paradigm poses considerable privacy risks as it necessitates broad data availability across organizational boundaries and frequent data transmission between entities, potentially exposing proprietary information to unauthorized access or interception during storage and transfer. In the present study, we introduce the chemical knowledge-informed framework (CKIF), a privacy-preserving approach for learning retrosynthesis models. CKIF enables distributed training across multiple chemical organizations without compromising the confidentiality of proprietary reaction data. Instead of gathering raw reaction data, CKIF learns retrosynthesis models through iterative, chemical knowledge-informed aggregation of model parameters. In particular, the chemical properties of predicted reactants are leveraged to quantitatively assess the observable behaviors of individual models, which in turn determines the adaptive weights used for model aggregation. On a variety of reaction datasets, CKIF outperforms several strong baselines by a clear margin.",
      "authors": [
        "Guikun Chen",
        "Xu Zhang",
        "Xiaolin Hu",
        "Yong Liu",
        "Yi Yang",
        "Wenguan Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19119",
        "HTML": "https://arxiv.org/html/2502.19119",
        "PDF": "https://arxiv.org/pdf/2502.19119"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 26 Feb 2025 13:13:24 GMT",
          "size": "711kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:45:28 GMT",
          "size": "382kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Chemical knowledge-informed framework for privacy-aware retrosynthesis learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a privacy-preserving framework for retrosynthesis learning in chemical data, without addressing any aspect of training data processing or construction for LLMs."
      }
    },
    {
      "id": "2502.20581",
      "abstract": "Academic citations are widely used for evaluating research and tracing knowledge flows. Such uses typically rely on raw citation counts and neglect variability in citation types. In particular, citations can vary in their fidelity as original knowledge from cited studies may be paraphrased, summarized, or reinterpreted, possibly wrongly, leading to variation in how much information changes from cited to citing paper. In this study, we introduce a computational pipeline to quantify citation fidelity at scale. Using full texts of papers, the pipeline identifies citations in citing papers and the corresponding claims in cited papers, and applies supervised models to measure fidelity at the sentence level. Analyzing a large-scale multi-disciplinary dataset of approximately 13 million citation sentence pairs, we find that citation fidelity is higher when authors cite papers that are 1) more recent and intellectually close, 2) more accessible, and 3) the first author has a lower H-index and the author team is medium-sized. Using a quasi-experiment, we establish the \"telephone effect\" - when citing papers have low fidelity to the original claim, future papers that cite the citing paper and the original have lower fidelity to the original. Our work reveals systematic differences in citation fidelity, underscoring the limitations of analyses that rely on citation quantity alone and the potential for distortion of evidence.",
      "authors": [
        "Hong Chen",
        "Misha Teplitskiy",
        "David Jurgens"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20581",
        "HTML": "https://arxiv.org/html/2502.20581",
        "PDF": "https://arxiv.org/pdf/2502.20581"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 27 Feb 2025 22:47:03 GMT",
          "size": "1760kb",
          "version": "v1"
        },
        {
          "date": "Wed, 05 Mar 2025 16:32:35 GMT",
          "size": "467kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 22:00:02 GMT",
          "size": "462kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "The Noisy Path from Source to Citation: Measuring How Scholars Engage with Past Research",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper investigates citation fidelity in academic texts, focusing on citation behavior and its impact on knowledge flow, without any discussion on LLM training data processing."
      },
      "tasks": [
        "Sentence"
      ]
    },
    {
      "id": "2503.00845",
      "abstract": "Despite significant advancements in Large Language Models (LLMs), developing advanced reasoning capabilities in LLMs remains a key challenge. Process Reward Models (PRMs) have demonstrated exceptional promise in enhancing reasoning by providing step-wise feedback, particularly in the context of mathematical reasoning. However, their application to broader reasoning domains remains understudied, largely due to the high costs associated with manually creating step-level supervision. In this work, we explore the potential of PRMs in graph reasoning problems - a domain that demands sophisticated multi-step reasoning and offers opportunities for automated step-level data generation using established graph algorithms. We introduce GraphSILO, the largest dataset for graph reasoning problems with fine-grained step-wise labels, built using automated Task-oriented Trajectories and Monte Carlo Tree Search (MCTS) to generate detailed reasoning steps with step-wise labels. Building upon this dataset, we train GraphPRM, the first PRM designed for graph reasoning problems, and evaluate its effectiveness in two key settings: inference-time scaling and reinforcement learning via Direct Preference Optimization (DPO). Experimental results show that GraphPRM significantly improves LLM performance across 13 graph reasoning tasks, delivering a 9% gain for Qwen2.5-7B and demonstrating transferability to new graph reasoning datasets and new reasoning domains like mathematical problem-solving. Notably, GraphPRM enhances LLM performance on GSM8K and Math500, underscoring the cross-domain applicability of graph-based reasoning rewards. Our findings highlight the potential of PRMs in advancing reasoning across diverse domains, paving the way for more versatile and effective LLMs.",
      "authors": [
        "Miao Peng",
        "Nuo Chen",
        "Zongrui Suo",
        "Jia Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00845",
        "HTML": "https://arxiv.org/html/2503.00845",
        "PDF": "https://arxiv.org/pdf/2503.00845"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 02 Mar 2025 10:39:40 GMT",
          "size": "958kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:00:08 GMT",
          "size": "967kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Rewarding Graph Reasoning Process makes LLMs more Generalized Reasoners",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on enhancing reasoning capabilities in LLMs using Process Reward Models in graph reasoning. It does involve creating a dataset, GraphSILO, but the primary focus is on reasoning performance enhancement, not on general LLM training data processing."
      },
      "tasks": []
    },
    {
      "id": "2503.01109",
      "abstract": "3D gaussian splatting has advanced simultaneous localization and mapping (SLAM) technology by enabling real-time positioning and the construction of high-fidelity maps. However, the uncertainty in gaussian position and initialization parameters introduces challenges, often requiring extensive iterative convergence and resulting in redundant or insufficient gaussian representations. To address this, we introduce a novel adaptive densification method based on Fourier frequency domain analysis to establish gaussian priors for rapid convergence. Additionally, we propose constructing independent and unified sparse and dense maps, where a sparse map supports efficient tracking via Generalized Iterative Closest Point (GICP) and a dense map creates high-fidelity visual representations. This is the first SLAM system leveraging frequency domain analysis to achieve high-quality gaussian mapping in real-time. Experimental results demonstrate an average frame rate of 36 FPS on Replica and TUM RGB-D datasets, achieving competitive accuracy in both localization and mapping.",
      "authors": [
        "Yansong Xu",
        "Junlin Li",
        "Wei Zhang",
        "Siyu Chen",
        "Shengyong Zhang",
        "Yuquan Leng",
        "Weijia Zhou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01109",
        "HTML": "https://arxiv.org/html/2503.01109",
        "PDF": "https://arxiv.org/pdf/2503.01109"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 03 Mar 2025 02:33:39 GMT",
          "size": "4294kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:14:50 GMT",
          "size": "4295kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with Sparse and Dense Map Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes advancements in SLAM technology using Fourier-based methods for real-time positioning and mapping. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Simultaneous Localization and Mapping"
      ]
    },
    {
      "id": "2503.05319",
      "abstract": "This paper discusses how ophthalmologists often rely on multimodal data to improve diagnostic accuracy. However, complete multimodal data is rare in real-world applications due to a lack of medical equipment and concerns about data privacy. Traditional deep learning methods typically address these issues by learning representations in latent space. However, the paper highlights two key limitations of these approaches: (i) Task-irrelevant redundant information (e.g., numerous slices) in complex modalities leads to significant redundancy in latent space representations. (ii) Overlapping multimodal representations make it difficult to extract unique features for each modality. To overcome these challenges, the authors propose the Essence-Point and Disentangle Representation Learning (EDRL) strategy, which integrates a self-distillation mechanism into an end-to-end framework to enhance feature selection and disentanglement for more robust multimodal learning. Specifically, the Essence-Point Representation Learning module selects discriminative features that improve disease grading performance. The Disentangled Representation Learning module separates multimodal data into modality-common and modality-unique representations, reducing feature entanglement and enhancing both robustness and interpretability in ophthalmic disease diagnosis. Experiments on multimodal ophthalmology datasets show that the proposed EDRL strategy significantly outperforms current state-of-the-art methods.",
      "authors": [
        "Xinkun Wang",
        "Yifang Wang",
        "Senwei Liang",
        "Feilong Tang",
        "Chengzhi Liu",
        "Ming Hu",
        "Chao Hu",
        "Junjun He",
        "Zongyuan Ge",
        "and Imran Razzak"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05319",
        "HTML": "https://arxiv.org/html/2503.05319",
        "PDF": "https://arxiv.org/pdf/2503.05319"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 07 Mar 2025 10:58:38 GMT",
          "size": "3056kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:53:34 GMT",
          "size": "1637kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Robust Multimodal Learning for Ophthalmic Disease Grading via Disentangled Representation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on robust multimodal learning for ophthalmic disease grading using a novel representation learning strategy, but it does not discuss LLM training data processing or data engineering related to LLMs."
      },
      "tasks": [
        "Diagnostic",
        "Disentanglement",
        "feature selection",
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/xinkunwang111/robust-multimodal-learning-for-ophthalmic-disease-grading-via-disentangled-representation"
      ]
    },
    {
      "id": "2503.05403",
      "abstract": "We propose a decentralized framework for guaranteeing the small-signal stability of future power systems with grid-forming converters. Our approach leverages dynamic loop-shifting techniques to compensate for the lack of passivity in the network dynamics and establishes decentralized parametric stability certificates, depending on the local device-level controls and incorporating the effects of the network dynamics. By following practical tuning rules, we are able to ensure plug-and-play operation without centralized coordination. Unlike prior works, our approach accommodates coupled frequency and voltage dynamics, incorporates network dynamics, and does not rely on specific network configurations or operating points, offering a general and scalable solution for the integration of power-electronics-based devices into future power systems. We validate our theoretical stability results through numerical case studies in a high-fidelity simulation model.",
      "authors": [
        "Verena H\\\"aberle",
        "Xiuqiang He",
        "Linbin Huang",
        "Florian D\\\"orfler",
        "Steven Low"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05403",
        "HTML": "https://arxiv.org/html/2503.05403",
        "PDF": "https://arxiv.org/pdf/2503.05403"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 07 Mar 2025 13:26:55 GMT",
          "size": "5819kb",
          "version": "v1"
        },
        {
          "date": "Thu, 13 Mar 2025 13:51:36 GMT",
          "size": "8801kb",
          "version": "v2"
        },
        {
          "date": "Mon, 17 Mar 2025 14:54:56 GMT",
          "size": "8801kb",
          "version": "v3"
        },
        {
          "date": "Wed, 09 Apr 2025 18:30:07 GMT",
          "size": "8801kb",
          "version": "v4"
        },
        {
          "date": "Tue, 24 Jun 2025 20:07:53 GMT",
          "size": "8802kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Decentralized Parametric Stability Certificates for Grid-Forming Converter Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a decentralized framework for ensuring stability in power systems with grid-forming converters, which is unrelated to training data processing for LLMs."
      },
      "tasks": []
    },
    {
      "id": "2503.07294",
      "abstract": "We demonstrate that quantum vision transformers (QViTs), vision transformers (ViTs) with self-attention (SA) mechanisms replaced by quantum self-attention (QSA) mechanisms, can match state-of-the-art (SOTA) biomedical image classifiers while using 99.99% fewer parameters. QSAs are produced by replacing linear SA layers with parameterised quantum neural networks (QNNs), producing a QSA mechanism and reducing parameter scaling from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n)$. On RetinaMNIST, our ultra parameter-efficient QViT outperforms 13/14 SOTA methods including CNNs and ViTs, achieving 56.5% accuracy, just 0.88% below the top MedMamba model while using 99.99% fewer parameters (1K vs 14.5M) and 89% fewer GFLOPs. We present the first investigation of knowledge distillation (KD) from classical to quantum vision transformers in biomedical image classification, showing that QViTs maintain comparable performance to classical ViTs across eight diverse datasets spanning multiple modalities, with improved QSA parameter-efficiency. Our higher-qubit architecture benefitted more from KD pre-training, suggesting a scaling relationship between QSA parameters and KD effectiveness. These findings establish QSA as a practical architectural choice toward parameter-efficient biomedical image analysis.",
      "authors": [
        "Thomas Boucher and John Whittle and Evangelos B. Mazomenos"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07294",
        "HTML": "https://arxiv.org/html/2503.07294",
        "PDF": "https://arxiv.org/pdf/2503.07294"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 10 Mar 2025 13:16:48 GMT",
          "size": "537kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:08:53 GMT",
          "size": "739kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "From $\\mathcal{O}(n^{2})$ to $\\mathcal{O}(n)$ Parameters: Quantum Self-Attention in Vision Transformers for Biomedical Image Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper explores the use of quantum self-attention in vision transformers for biomedical image classification, which does not pertain to the processing of training data for LLMs."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Knowledge Distillation",
        "Quantum Machine Learning"
      ]
    },
    {
      "id": "2503.07813",
      "abstract": "The development of artificial intelligence (AI) and machine learning (ML) based tools for 3D phenotyping, especially for maize, has been limited due to the lack of large and diverse 3D datasets. 2D image datasets fail to capture essential structural details such as leaf architecture, plant volume, and spatial arrangements that 3D data provide. To address this limitation, we present MaizeField3D (https://baskargroup.github.io/MaizeField3D/), a curated dataset of 3D point clouds of field-grown maize plants from a diverse genetic panel, designed to be AI-ready for advancing agricultural research. Our dataset includes 1,045 high-quality point clouds of field-grown maize collected using a terrestrial laser scanner (TLS). Point clouds of 520 plants from this dataset were segmented and annotated using a graph-based segmentation method to isolate individual leaves and stalks, ensuring consistent labeling across all samples. This labeled data was then used for fitting procedural models that provide a structured parametric representation of the maize plants. The leaves of the maize plants in the procedural models are represented using Non-Uniform Rational B-Spline (NURBS) surfaces that were generated using a two-step optimization process combining gradient-free and gradient-based methods. We conducted rigorous manual quality control on all datasets, correcting errors in segmentation, ensuring accurate leaf ordering, and validating metadata annotations. The dataset also includes metadata detailing plant morphology and quality, alongside multi-resolution subsampled point cloud data (100k, 50k, 10k points), which can be readily used for different downstream computational tasks. MaizeField3D will serve as a comprehensive foundational dataset for AI-driven phenotyping, plant structural analysis, and 3D applications in agricultural research.",
      "authors": [
        "Elvis Kimara",
        "Mozhgan Hadadi",
        "Jackson Godbersen",
        "Aditya Balu",
        "Talukder Jubery",
        "Yawei Li",
        "Adarsh Krishnamurthy",
        "Patrick S. Schnable",
        "and Baskar Ganapathysubramanian"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07813",
        "HTML": "https://arxiv.org/html/2503.07813",
        "PDF": "https://arxiv.org/pdf/2503.07813"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 10 Mar 2025 19:53:20 GMT",
          "size": "48332kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:04:30 GMT",
          "size": "44161kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a 3D dataset for maize phenotyping and discusses its creation and application, but it does not address any LLM training data processing issues."
      },
      "datasets": [
        {
          "dataset_name": "BGLab/MaizeField3D",
          "downloads": "69",
          "likes": "2",
          "link": "https://huggingface.co/datasets/BGLab/MaizeField3D"
        }
      ]
    },
    {
      "id": "2503.09749",
      "abstract": "This study presents the first automated classifier designed to determine whether a pair of iris images originates from monozygotic individuals, addressing a previously untackled problem in biometric recognition. In Daugman-style iris recognition, the textures of the left and right irises of the same person are traditionally considered as being as different as the irises of two unrelated persons. However, previous research indicates that humans can detect that two iris images are from different eyes of the same person, or eyes of monozygotic twins, with an accuracy of about 80%. In this work, we employ a Siamese network architecture and contrastive learning to categorize a pair of iris images as coming from monozygotic or non-monozygotic irises. This could potentially be applied, for example, as a fast, noninvasive test to determine if twins are monozygotic or non-monozygotic. We construct a dataset comprising both synthetic monozygotic pairs (images of different irises of the same individual) and natural monozygotic pairs (images of different images from persons who are identical twins), in addition to non-monozygotic pairs from unrelated individuals, ensuring a comprehensive evaluation of the model's capabilities. To gain deeper insights into the learned representations, we train and analyze three variants of the model using (1) the original input images, (2) iris-only images (masking everything but the iris region), and (3) non-iris-only images (masking the iris region). This comparison reveals that both iris texture and surrounding ocular structure contain information useful for the model to classify the image pairs as monozygotic or non-monozygotic. Our approach achieves accuracy levels using the full iris image that exceed those previously reported for human classification of monozygotic iris pairs.",
      "authors": [
        "Yongle Yuan and Kevin W. Bowyer"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09749",
        "HTML": "https://arxiv.org/html/2503.09749",
        "PDF": "https://arxiv.org/pdf/2503.09749"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 12 Mar 2025 18:48:38 GMT",
          "size": "3267kb",
          "version": "v1"
        },
        {
          "date": "Sun, 23 Mar 2025 19:04:06 GMT",
          "size": "3268kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 06:50:51 GMT",
          "size": "3267kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Siamese Network to Detect If Two Iris Images Are Monozygotic",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on biometric recognition using iris images and Siamese networks. It does not discuss any aspect of LLM training data processing or data engineering."
      },
      "tasks": [
        "Contrastive Learning",
        "Iris Recognition"
      ]
    },
    {
      "id": "2503.13248",
      "abstract": "The Riemann problem is fundamental in the computational modeling of hyperbolic partial differential equations, enabling the development of stable and accurate upwind schemes. While exact solvers provide robust upwinding fluxes, their high computational cost necessitates approximate solvers. Although approximate solvers achieve accuracy in many scenarios, they produce inaccurate solutions in certain cases. To overcome this limitation, we propose constructing neural network-based surrogate models, trained using supervised learning, designed to map interior and exterior conservative state variables to the corresponding exact flux. Specifically, we propose two distinct approaches: one utilizing a vanilla neural network and the other employing a bi-fidelity neural network. The performance of the proposed approaches is demonstrated through applications to one-dimensional and two-dimensional partial differential equations, showcasing their robustness and accuracy.",
      "authors": [
        "Akshay Thakur and Matthew J. Zahr"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13248",
        "HTML": "https://arxiv.org/html/2503.13248",
        "PDF": "https://arxiv.org/pdf/2503.13248"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Mar 2025 15:01:26 GMT",
          "size": "8826kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 22:02:35 GMT",
          "size": "8834kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Neural network-based Godunov corrections for approximate Riemann solvers using bi-fidelity learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a method involving neural networks for solving Riemann problems in computational modeling of PDEs, without addressing LLM training data collection, construction, or processing."
      },
      "tasks": []
    },
    {
      "id": "2503.13305",
      "abstract": "Most written natural languages are composed of sequences of words and sentences. Similar to humans, large language models (LLMs) exhibit flexibility in handling textual positions - a phenomenon we term position generalization. They can understand texts with position perturbations and generalize to longer texts than those encountered during training with the latest techniques. These phenomena suggest that LLMs handle positions tolerantly, but how LLMs computationally process positional relevance remains largely unexplored. This work connects the linguistic phenomenon with LLMs' computational mechanisms. We show how LLMs enforce certain computational mechanisms for the aforementioned tolerance in position perturbations. Despite the complex design of the self-attention mechanism, this work reveals that LLMs learn a counterintuitive disentanglement of attention logits. Their values show a 0.959 linear correlation with an approximation of the arithmetic sum of positional relevance and semantic importance. Furthermore, we identify a prevalent pattern in intermediate features, which we prove theoretically enables this effect. The pattern, which is different from how randomly initialized parameters would behave, suggests that it is a learned behavior rather than a natural result of the model architecture. Based on these findings, we provide computational explanations and criteria for LLMs' position flexibilities. This work takes a pioneering step in linking position generalization with modern LLMs' internal mechanisms.",
      "authors": [
        "Chi Han",
        "Heng Ji"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13305",
        "HTML": "https://arxiv.org/html/2503.13305",
        "PDF": "https://arxiv.org/pdf/2503.13305"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Mar 2025 15:47:37 GMT",
          "size": "42726kb",
          "version": "v1"
        },
        {
          "date": "Wed, 11 Jun 2025 19:40:29 GMT",
          "size": "42693kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 00:26:59 GMT",
          "size": "42693kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Computation Mechanism Behind LLM Position Generalization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores the computation mechanisms behind the positional flexibility in LLMs. It does not delve into any aspect of data processing or data engineering for LLM training."
      },
      "tasks": [
        "Disentanglement",
        "Position"
      ]
    },
    {
      "id": "2503.14409",
      "abstract": "Estimating the parameters of nonlinear block-oriented state-space models from input-output data typically involves solving a highly non-convex optimization problem, which is prone to poor local minima and slow convergence. This paper presents a computationally efficient initialization method for nonlinear linear fractional representation (NL-LFR) models using periodic data. By first inferring the latent signals and subsequently estimating the model parameters, the approach generates initial estimates for use in a later nonlinear optimization step. The proposed method shows robustness against poor local minima, and achieves a twofold error reduction compared to the state-of-the-art on a challenging benchmark dataset.",
      "authors": [
        "Merijn Floren",
        "Jean-Philippe No\\\"el",
        "Jan Swevers"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14409",
        "HTML": "https://arxiv.org/html/2503.14409",
        "PDF": "https://arxiv.org/pdf/2503.14409"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 18 Mar 2025 16:49:56 GMT",
          "size": "903kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:17:20 GMT",
          "size": "715kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Inference and Learning of Nonlinear LFR State-Space Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work handles inference and learning in non-linear state-space models; it does not relate to training data processing or data engineering for LLMs."
      },
      "tasks": [
        "State Space Models"
      ]
    },
    {
      "id": "2503.19777",
      "abstract": "We propose a training-free method for open-vocabulary semantic segmentation using Vision-and-Language Models (VLMs). Our approach enhances the initial per-patch predictions of VLMs through label propagation, which jointly optimizes predictions by incorporating patch-to-patch relationships. Since VLMs are primarily optimized for cross-modal alignment and not for intra-modal similarity, we use a Vision Model (VM) that is observed to better capture these relationships. We address resolution limitations inherent to patch-based encoders by applying label propagation at the pixel level as a refinement step, significantly improving segmentation accuracy near class boundaries. Our method, called LPOSS+, performs inference over the entire image, avoiding window-based processing and thereby capturing contextual interactions across the full image. LPOSS+ achieves state-of-the-art performance among training-free methods, across a diverse set of datasets. Code: https://github.com/vladan-stojnic/LPOSS",
      "authors": [
        "Vladan Stojni\\'c",
        "Yannis Kalantidis",
        "Ji\\v{r}\\'i Matas",
        "Giorgos Tolias"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19777",
        "HTML": "https://arxiv.org/html/2503.19777",
        "PDF": "https://arxiv.org/pdf/2503.19777"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 25 Mar 2025 15:47:13 GMT",
          "size": "14658kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:53:33 GMT",
          "size": "14657kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a training-free method for semantic segmentation using Vision-and-Language Models, which does not pertain to LLM training data processing or engineering."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Stojnic_LPOSS_Label_Propagation_Over_Patches_and_Pixels_for_Open-vocabulary_Semantic_CVPR_2025_paper.html",
      "tasks": [
        "cross-modal alignment",
        "Open Vocabulary Semantic Segmentation",
        "Open-Vocabulary Semantic Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/vladan-stojnic/lposs"
      ]
    },
    {
      "id": "2503.21227",
      "abstract": "Mixture of Experts (MoE) architectures have recently advanced the scalability and adaptability of large language models (LLMs) for continual multimodal learning. However, efficiently extending these models to accommodate sequential tasks remains challenging. As new tasks arrive, naive model expansion leads to rapid parameter growth, while modifying shared routing components often causes catastrophic forgetting, undermining previously learned knowledge. To address these issues, we propose LLaVA-CMoE, a continual learning framework for LLMs that requires no replay data of previous tasks and ensures both parameter efficiency and robust knowledge retention. Our approach introduces a Probe-Guided Knowledge Extension mechanism, which uses probe experts to dynamically determine when and where new experts should be added, enabling adaptive and minimal parameter expansion tailored to task complexity. Furthermore, we present a Probabilistic Task Locator that assigns each task a dedicated, lightweight router. To handle the practical issue that task labels are unknown during inference, we leverage a VAE-based reconstruction strategy to identify the most suitable router by matching input distributions, allowing automatic and accurate expert allocation. This design mitigates routing conflicts and catastrophic forgetting, enabling robust continual learning without explicit task labels. Extensive experiments on the CoIN benchmark, covering eight diverse VQA tasks, demonstrate that LLaVA-CMoE delivers strong continual learning performance with a compact model size, significantly reducing forgetting and parameter overhead compared to prior methods. These results showcase the effectiveness and scalability of our approach for parameter-efficient continual learning in large language models. Our code will be open-sourced soon.",
      "authors": [
        "Hengyuan Zhao",
        "Ziqin Wang",
        "Qixin Sun",
        "Kaiyou Song",
        "Yilin Li",
        "Xiaolin Hu",
        "Qingpei Guo",
        "Si Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21227",
        "HTML": "https://arxiv.org/html/2503.21227",
        "PDF": "https://arxiv.org/pdf/2503.21227"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 27 Mar 2025 07:36:11 GMT",
          "size": "5553kb",
          "version": "v1"
        },
        {
          "date": "Fri, 13 Jun 2025 11:04:13 GMT",
          "size": "2967kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 08:30:20 GMT",
          "size": "2977kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LLaVA-CMoE: Towards Continual Mixture of Experts for Large Vision-Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a continual learning framework for multimodal tasks using LLMs but does not address the engineering or processing of training data for LLMs."
      },
      "tasks": [
        "Mixture-of-Experts"
      ]
    },
    {
      "id": "2503.23062",
      "abstract": "Shapes and textures are the basic building blocks of visual perception. The ability to identify shapes regardless of orientation, texture, or context, and to recognize textures and materials independently of their associated objects, is essential for a general visual understanding of the world. This work introduces the Large Shape and Textures dataset (LAS&T), a giant collection of highly diverse shapes and textures, created by unsupervised extraction of patterns from natural images. This dataset is used to benchmark how effectively leading Large Vision-Language Models (LVLMs) understand shapes, textures, and materials in 2D and 3D scenes. For shape recognition, we test the models' ability to match images of identical shapes that differ in orientation, texture, color, or environment. Our results show that the shape recognition capabilities of the LVLMs remain significantly below human performance. LVLMs rely predominantly on high-level and semantic features and struggle with abstract shapes lacking clear class associations. For texture and material recognition, we evaluated the models' ability to identify images with identical textures and materials across different objects and environments. Interestingly, leading LVLMs approach human-level performance in recognizing materials in 3D scenes, yet substantially underperform humans when identifying simpler more abstract 2D textures. These results are consistent across a wide range of leading VLMs (GPT/Gemini/LLama/Qwen) and foundation vision models (DINO/CLIP), exposing major deficiencies in the ability of leading models to understand fundamental visual concepts. In contrast, simple nets trained directly for these tasks achieve high accuracy. The LAS&T dataset, featuring over 600,000 images for 2D/3D shape, texture, and material recognition and retrieval, is publicly available.",
      "authors": [
        "Sagi Eppel",
        "Mor Bismut",
        "Alona Faktor-Strugatski"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23062",
        "HTML": "https://arxiv.org/html/2503.23062",
        "PDF": "https://arxiv.org/pdf/2503.23062"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 29 Mar 2025 12:43:29 GMT",
          "size": "6988kb",
          "version": "v1"
        },
        {
          "date": "Mon, 02 Jun 2025 19:47:34 GMT",
          "size": "12398kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 19:16:21 GMT",
          "size": "12398kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Shape and Texture Recognition in Large Vision-Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a dataset and evaluates Vision-Language Models on shape and texture recognition, without addressing LLM training data collection, construction or processing."
      },
      "tasks": [
        "3D Shape Recognition",
        "3D Shape Retrieval",
        "Material Recognition",
        "Texture Image Retrieval"
      ],
      "repo_urls": [
        "https://github.com/sagieppel/testing-large-vision-language-models-lvlm-on-visual-questions"
      ]
    },
    {
      "id": "2504.01773",
      "abstract": "The problem of computing near-optimal contracts in combinatorial settings has recently attracted significant interest in the computer science community. Previous work has provided a rich body of structural and algorithmic insights into this problem. However, most of these results rely on the assumption that the principal has an unlimited budget for incentivizing agents, an assumption that is often unrealistic in practice. This motivates the study of the optimal contract problem under budget constraints.\n  In this work, we study multi-agent contracts with binary actions under budget constraints. Our contribution is threefold. First, we show that all previously known approximation guarantees on the principal's utility extend (asymptotically) to budgeted settings. Second, through the lens of budget constraints, we uncover insightful connections between the standard objective of maximizing the principal's utility and other relevant objectives. Specifically, we identify a broad class of objectives, which we term BEST (BEyond STandard) objectives, including reward, social welfare, and principal's utility, and show that they are all equivalent (up to a constant factor), leading to approximation guarantees for all BEST objectives. Third, we introduce the price of frugality, which quantifies the loss due to budget constraints, and establish near-tight bounds on this measure, providing deeper insights into the tradeoffs between budgets and incentives.",
      "authors": [
        "Michal Feldman",
        "Yoav Gal-Tzur",
        "Tomasz Ponitka",
        "Maya Schlesinger"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01773",
        "HTML": "https://arxiv.org/html/2504.01773",
        "PDF": "https://arxiv.org/pdf/2504.01773"
      },
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 02 Apr 2025 14:32:39 GMT",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:55:42 GMT",
          "size": "34kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Budget-Feasible Contracts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on multi-agent contracts under budget constraints and does not address any aspect of LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2504.02946",
      "abstract": "This work presents a massive SIMO scheme for wireless communications with one-shot noncoherent detection. It is based on permutational index modulation over OFDM. Its core principle is to convey information on the ordering in which a fixed collection of values is mapped onto a set of OFDM subcarriers. A spherical code is obtained which provides improved robustness against channel impairments. A simple detector based on the sorting of quadratic metrics of data is proposed. By exploiting statistical channel state information and hardening, it reaches near-ML error performance with a low-complexity implementation.",
      "authors": [
        "Marc Vil\\`a-Insa",
        "Aniol Mart\\'i",
        "Meritxell Lamarca",
        "Jaume Riba"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02946",
        "HTML": "https://arxiv.org/html/2504.02946",
        "PDF": "https://arxiv.org/pdf/2504.02946"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 03 Apr 2025 18:02:38 GMT",
          "size": "141kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:44:26 GMT",
          "size": "141kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Low-Complexity Detection of Permutational Index Modulation for Noncoherent Communications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work addresses a massive SIMO scheme for wireless communications using permutational index modulation, which is unrelated to LLM training data processing."
      }
    },
    {
      "id": "2504.04494",
      "abstract": "This paper presents a comprehensive evaluation of skin color measurement methods from dermatoscopic images using a synthetic dataset (S-SYNTH) with controlled ground-truth melanin content, lesion shapes, hair models, and 18 distinct lighting conditions. This allows for rigorous assessment of the robustness and invariance to lighting conditions. We assess four classes of image colorimetry approaches: segmentation-based, patch-based, color quantization, and neural networks. We use these methods to estimate the Individual Typology Angle (ITA) and Fitzpatrick types from dermatoscopic images. Our results show that segmentation-based and color quantization methods yield robust, lighting-invariant estimates, whereas patch-based approaches exhibit significant lighting-dependent biases that require calibration. Furthermore, neural network models, particularly when combined with heavy blurring to reduce overfitting, can provide light-invariant Fitzpatrick predictions, although their generalization to real-world images remains unverified. We conclude with practical recommendations for designing fair and reliable skin color estimation methods.",
      "authors": [
        "Marin Ben\\v{c}evi\\'c",
        "Robert \\v{S}ojo",
        "Irena Gali\\'c"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04494",
        "HTML": "https://arxiv.org/html/2504.04494",
        "PDF": "https://arxiv.org/pdf/2504.04494"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 06 Apr 2025 13:57:34 GMT",
          "size": "824kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:32:50 GMT",
          "size": "164kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Skin Color Measurement from Dermatoscopic Images: An Evaluation on a Synthetic Dataset",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper evaluates skin color measurement from dermatoscopic images using various methods; it does not deal with processing LLM training data."
      }
    },
    {
      "id": "2504.04916",
      "abstract": "This work focuses on minimizing the age of information for multiple energy harvesting sources that sample data and transmit it to a sink node. At each time, the central scheduler selects one of the sources to probe the quality of its channel to the sink node, and then the assessed channel quality is utilized to determine whether a source will sample and send the packet. For a single source case, we assume that the probed channel quality is known at each time instant, model the problem of AoI minimization as a Markov decision process, and prove the optimal sampling policy threshold structure. We then use this threshold structure and propose an AEC-SW-UCRL2 algorithm to handle unknown and time varying energy harvesting rate and channel statistics, motivated by the popular SWUCRL2 algorithm for non stationary reinforcement learning. This algorithm is applicable when an upper bound is available for the total variation of each of these quantities over a time horizon. Furthermore, in situations where these variation budgets are not accessible, we introduce the AEC-BORL algorithm, motivated by the well known BORL algorithm. For the multiple source case, we demonstrate that the AoI minimization problem can be formulated as a constrained MDP, which can be relaxed using a Lagrange multiplier and decoupled into sub problems across source nodes. We also derive Whittle index based source scheduling policy for probing and an optimal threshold policy for source sampling. We next leverage this Whittle index and threshold structure to develop the WIT-SW-UCRL2 algorithm for unknown time varying energy harvesting rates and channel statistics under their respective variation budgets. Moreover, we also proposed a Whittle index and threshold based bandit over reinforcement learning (WIT-BORL) algorithm for unknown variation budgets. Finally, we numerically demonstrate the efficacy of our algorithms.",
      "authors": [
        "Akanksha Jaiswal and Arpan Chattopadhyay"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04916",
        "HTML": "https://arxiv.org/html/2504.04916",
        "PDF": "https://arxiv.org/pdf/2504.04916"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 07 Apr 2025 10:53:53 GMT",
          "size": "944kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:12:06 GMT",
          "size": "477kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Age-of-information minimization under energy harvesting and non-stationary environment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on minimizing age-of-information with energy harvesting and scheduling, modeled as a Markov decision process, not related to LLM data processing."
      },
      "tasks": [
        "Scheduling"
      ]
    },
    {
      "id": "2504.05623",
      "abstract": "Cameras rely on auto white balance (AWB) to correct undesirable color casts caused by scene illumination and the camera's spectral sensitivity. This is typically achieved using an illuminant estimator that determines the global color cast solely from the color information in the camera's raw sensor image. Mobile devices provide valuable additional metadata-such as capture timestamp and geolocation-that offers strong contextual clues to help narrow down the possible illumination solutions. This paper proposes a lightweight illuminant estimation method that incorporates such contextual metadata, along with additional capture information and image colors, into a compact model (~5K parameters), achieving promising results, matching or surpassing larger models. To validate our method, we introduce a dataset of 3,224 smartphone images with contextual metadata collected at various times of day and under diverse lighting conditions. The dataset includes ground-truth illuminant colors, determined using a color chart, and user-preferred illuminants validated through a user study, providing a comprehensive benchmark for AWB evaluation.",
      "authors": [
        "Mahmoud Afifi",
        "Luxi Zhao",
        "Abhijith Punnappurath",
        "Mohammed A. Abdelsalam",
        "Ran Zhang",
        "Michael S. Brown"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05623",
        "HTML": "https://arxiv.org/html/2504.05623",
        "PDF": "https://arxiv.org/pdf/2504.05623"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 08 Apr 2025 02:45:37 GMT",
          "size": "23778kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:48:36 GMT",
          "size": "23778kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Time-Aware Auto White Balance in Mobile Photography",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research deals with auto white balance in photography using contextual metadata, which is unrelated to the processing of LLM training data."
      }
    },
    {
      "id": "2504.05654",
      "abstract": "By analogy to curved exponential families in statistics, we define curved Bregman divergences as Bregman divergences restricted to nonlinear parameter subspaces. We show that the barycenter of a finite weighted set of parameters under a curved Bregman divergence amounts to the right Bregman projection onto the nonlinear subspace of the barycenter with respect to the full Bregman divergence. We demonstrate the significance of curved Bregman divergences with two examples: (1) symmetrized Bregman divergences and (2) the Kullback-Leibler divergence between circular complex normal distributions. We then consider monotonic embeddings to define representational curved Bregman divergences and show that the $\\alpha$-divergences are representational curved Bregman divergences with respect to $\\alpha$-embeddings of the probability simplex into the positive measure cone. As an application, we report an efficient method to calculate the intersection of a finite set of $\\alpha$-divergence spheres.",
      "authors": [
        "Frank Nielsen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05654",
        "HTML": "https://arxiv.org/html/2504.05654",
        "PDF": "https://arxiv.org/pdf/2504.05654"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 08 Apr 2025 04:05:12 GMT",
          "size": "260kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:53:44 GMT",
          "size": "407kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Curved representational Bregman divergences and their applications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on curved Bregman divergences and their mathematical properties, with applications in calculating intersections of divergence spheres. It makes no mention of LLM training data processing or related methodologies."
      },
      "tasks": []
    },
    {
      "id": "2504.06185",
      "abstract": "Chronic wounds affect a large population, particularly the elderly and diabetic patients, who often exhibit limited mobility and co-existing health conditions. Automated wound monitoring via mobile image capture can reduce in-person physician visits by enabling remote tracking of wound size. Semantic segmentation is key to this process, yet wound segmentation remains underrepresented in medical imaging research. To address this, we benchmark state-of-the-art deep learning models from general-purpose vision, medical imaging, and top methods from public wound challenges. For a fair comparison, we standardize training, data augmentation, and evaluation, conducting cross-validation to minimize partitioning bias. We also assess real-world deployment aspects, including generalization to an out-of-distribution wound dataset, computational efficiency, and interpretability. Additionally, we propose a reference object-based approach to convert AI-generated masks into clinically relevant wound size estimates and evaluate this, along with mask quality, for the five best architectures based on physician assessments. Overall, the transformer-based TransNeXt showed the highest levels of generalizability. Despite variations in inference times, all models processed at least one image per second on the CPU, which is deemed adequate for the intended application. Interpretability analysis typically revealed prominent activations in wound regions, emphasizing focus on clinically relevant features. Expert evaluation showed high mask approval for all analyzed models, with VWFormer and ConvNeXtS backbone performing the best. Size retrieval accuracy was similar across models, and predictions closely matched expert annotations. Finally, we demonstrate how our AI-driven wound size estimation framework, WoundAmbit, is integrated into a custom telehealth system.",
      "authors": [
        "Vanessa Borst",
        "Timo Dittus",
        "Tassilo Dege",
        "Astrid Schmieder",
        "and Samuel Kounev"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06185",
        "HTML": "https://arxiv.org/html/2504.06185",
        "PDF": "https://arxiv.org/pdf/2504.06185"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 08 Apr 2025 16:25:59 GMT",
          "size": "23297kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:21:21 GMT",
          "size": "23308kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily addresses semantic segmentation for wound care using deep learning models and does not discuss any aspect of LLM training data processes or methodologies."
      }
    },
    {
      "id": "2504.07307",
      "abstract": "We consider a common case of the combinatorial semi-bandit problem, the $m$-set semi-bandit, where the learner exactly selects $m$ arms from the total $d$ arms. In the adversarial setting, the best regret bound, known to be $\\mathcal{O}(\\sqrt{nmd})$ for time horizon $n$, is achieved by the well-known Follow-the-Regularized-Leader (FTRL) policy. However, this requires to explicitly compute the arm-selection probabilities via optimizing problems at each time step and sample according to them. This problem can be avoided by the Follow-the-Perturbed-Leader (FTPL) policy, which simply pulls the $m$ arms that rank among the $m$ smallest (estimated) loss with random perturbation. In this paper, we show that FTPL with a Fr\\'echet perturbation also enjoys the near optimal regret bound $\\mathcal{O}(\\sqrt{nm}(\\sqrt{d\\log(d)}+m^{5/6}))$ in the adversarial setting and approaches best-of-both-world regret bounds, i.e., achieves a logarithmic regret for the stochastic setting. Moreover, our lower bounds show that the extra factors are unavoidable with our approach; any improvement would require a fundamentally different and more challenging method.",
      "authors": [
        "Jingxin Zhan",
        "Yuchen Xin",
        "Chenjie Sun",
        "Zhihua Zhang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07307",
        "HTML": "https://arxiv.org/html/2504.07307",
        "PDF": "https://arxiv.org/pdf/2504.07307"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 09 Apr 2025 22:07:01 GMT",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "Tue, 22 Apr 2025 15:16:03 GMT",
          "size": "33kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 20:04:37 GMT",
          "size": "15388kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Follow-the-Perturbed-Leader Approaches Best-of-Both-Worlds for the m-Set Semi-Bandit Problems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The content of this paper is centered on algorithms for combinatorial semi-bandit problems and does not address the processing or engineering of LLM training data."
      },
      "tasks": []
    },
    {
      "id": "2504.08377",
      "abstract": "We consider a model for explainable AI in which an explanation for a prediction $h(x)=y$ consists of a subset $S'$ of the training data (if it exists) such that all classifiers $h' \\in H$ that make at most $b$ mistakes on $S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has label $y$ under the assumption that (1) the target function $h^\\star$ belongs to $H$, and (2) the set $S$ contains at most $b$ corrupted points. For example, if $b=0$ and $H$ is the family of linear classifiers in $\\mathbb{R}^d$, and if $x$ lies inside the convex hull of the positive data points in $S$ (and hence every consistent linear classifier labels $x$ as positive), then Carath\\'eodory's theorem states that $x$ lies inside the convex hull of $d+1$ of those points. So, a set $S'$ of size $d+1$ could be released as an explanation for a positive prediction, and would serve as a short proof of correctness of the prediction under the assumption of realizability.\n  In this work, we consider this problem more generally, for general hypothesis classes $H$ and general values $b\\geq 0$. We define the notion of the robust hollow star number of $H$ (which generalizes the standard hollow star number), and show that it precisely characterizes the worst-case size of the smallest certificate achievable, and analyze its size for natural classes. We also consider worst-case distributional bounds on certificate size, as well as distribution-dependent bounds that we show tightly control the sample size needed to get a certificate for any given test example. In particular, we define a notion of the certificate coefficient $\\varepsilon_x$ of an example $x$ with respect to a data distribution $D$ and target function $h^\\star$, and prove matching upper and lower bounds on sample size as a function of $\\varepsilon_x$, $b$, and the VC dimension $d$ of $H$.",
      "authors": [
        "Avrim Blum",
        "Steve Hanneke",
        "Chirag Pabbaraju",
        "Donya Saless"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08377",
        "HTML": "https://arxiv.org/html/2504.08377",
        "PDF": "https://arxiv.org/pdf/2504.08377"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 11 Apr 2025 09:26:37 GMT",
          "size": "35kb",
          "version": "v1"
        },
        {
          "date": "Fri, 09 May 2025 23:30:17 GMT",
          "size": "37kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 19:55:51 GMT",
          "size": "38kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Proofs as Explanations: Short Certificates for Reliable Predictions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses explainable AI models and methods to certify predictions, without addressing any aspects of LLM training data processing or engineering."
      },
      "tasks": []
    },
    {
      "id": "2504.09657",
      "abstract": "This paper investigates the economic impact of vehicle-home-grid integration, by proposing an online energy management algorithm that optimizes energy flows between an electric vehicle (EV), a household, and the electrical grid. The algorithm leverages vehicle-to-home (V2H) for self-consumption and vehicle-to-grid (V2G) for energy trading, adapting to real-time conditions through a hybrid long short-term memory (LSTM) neural network for accurate household load prediction, alongside a comprehensive nonlinear battery degradation model accounting for both cycle and calendar aging. Simulation results reveal significant economic advantages: compared to smart unidirectional charging, the proposed method yields an annual economic benefit of up to EUR 3046.81, despite a modest 1.96% increase in battery degradation. Even under unfavorable market conditions, where V2G energy selling generates no revenue, V2H alone ensures yearly savings of EUR 425.48. A systematic sensitivity analysis investigates how variations in battery capacity, household load, and price ratios affect economic outcomes, confirming the consistent benefits of bidirectional energy exchange. These findings highlight the potential of EVs as active energy nodes, enabling sustainable energy management and cost-effective battery usage in real-world conditions.",
      "authors": [
        "Francesco Popolizio",
        "Torsten Wik",
        "Chih Feng Lee",
        "Changfu Zou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09657",
        "HTML": "https://arxiv.org/html/2504.09657",
        "PDF": "https://arxiv.org/pdf/2504.09657"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 13 Apr 2025 17:11:28 GMT",
          "size": "397kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:38:57 GMT",
          "size": "396kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Nonlinear Online Optimization for Vehicle-Home-Grid Integration including Household Load Prediction and Battery Degradation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on optimizing energy flows and economic impact in vehicle-home-grid integration and does not mention any aspects of LLM training data processing or data engineering tasks."
      },
      "tasks": [
        "energy management",
        "energy trading",
        "Management"
      ]
    },
    {
      "id": "2504.10035",
      "abstract": "Sports analysis requires processing large amounts of data, which is time-consuming and costly. Advancements in neural networks have significantly alleviated this burden, enabling highly accurate ball tracking in sports broadcasts. However, relying solely on 2D ball tracking is limiting, as it depends on the camera's viewpoint and falls short of supporting comprehensive game analysis. To address this limitation, we propose a novel approach for reconstructing precise 3D ball trajectories from online table tennis match recordings. Our method leverages the underlying physics of the ball's motion to identify the bounce state that minimizes the reprojection error of the ball's flying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A key advantage of our approach is its ability to infer ball spin without relying on human pose estimation or racket tracking, which are often unreliable or unavailable in broadcast footage. We developed an automated camera calibration method capable of reliably tracking camera movements. Additionally, we adapted an existing 3D pose estimation model, which lacks depth motion capture, to accurately track player movements. Together, these contributions enable the full 3D reconstruction of a table tennis rally.",
      "authors": [
        "Thomas Gossard",
        "Andreas Ziegler and Andreas Zell"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10035",
        "HTML": "https://arxiv.org/html/2504.10035",
        "PDF": "https://arxiv.org/pdf/2504.10035"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 14 Apr 2025 09:37:47 GMT",
          "size": "17157kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:05:36 GMT",
          "size": "12652kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TT3D: Table Tennis 3D Reconstruction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a method for reconstructing 3D ball trajectories in table tennis using physics and camera calibration, without addressing the processing of training data for LLMs."
      },
      "tasks": [
        "3D Pose Estimation",
        "3D Reconstruction",
        "Camera Calibration",
        "Pose Estimation"
      ]
    },
    {
      "id": "2504.10390",
      "abstract": "Achieving robust locomotion on complex terrains remains a challenge due to high dimensional control and environmental uncertainties. This paper introduces a teacher prior framework based on the teacher student paradigm, integrating imitation and auxiliary task learning to improve learning efficiency and generalization. Unlike traditional paradigms that strongly rely on encoder-based state embeddings, our framework decouples the network design, simplifying the policy network and deployment. A high performance teacher policy is first trained using privileged information to acquire generalizable motion skills. The teacher's motion distribution is transferred to the student policy, which relies only on noisy proprioceptive data, via a generative adversarial mechanism to mitigate performance degradation caused by distributional shifts. Additionally, auxiliary task learning enhances the student policy's feature representation, speeding up convergence and improving adaptability to varying terrains. The framework is validated on a humanoid robot, showing a great improvement in locomotion stability on dynamic terrains and significant reductions in development costs. This work provides a practical solution for deploying robust locomotion strategies in humanoid robots.",
      "authors": [
        "Fangcheng Jin and Yuqi Wang and Peixin Ma and Guodong Yang and Pan Zhao and En Li and Zhengtao Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10390",
        "HTML": "https://arxiv.org/html/2504.10390",
        "PDF": "https://arxiv.org/pdf/2504.10390"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 14 Apr 2025 16:36:56 GMT",
          "size": "5915kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:27:22 GMT",
          "size": "1110kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a teacher-student framework for robot locomotion, focusing on imitation learning but does not discuss or contribute to the processing of LLM training data."
      },
      "tasks": []
    },
    {
      "id": "2504.12636",
      "abstract": "Robotic manipulation faces critical challenges in understanding spatial affordances--the \"where\" and \"how\" of object interactions--essential for complex manipulation tasks like wiping a board or stacking objects. Existing methods, including modular-based and end-to-end approaches, often lack robust spatial reasoning capabilities. Unlike recent point-based and flow-based affordance methods that focus on dense spatial representations or trajectory modeling, we propose A0, a hierarchical affordance-aware diffusion model that decomposes manipulation tasks into high-level spatial affordance understanding and low-level action execution. A0 leverages the Embodiment-Agnostic Affordance Representation, which captures object-centric spatial affordances by predicting contact points and post-contact trajectories. A0 is pre-trained on 1 million contact points data and fine-tuned on annotated trajectories, enabling generalization across platforms. Key components include Position Offset Attention for motion-aware feature extraction and a Spatial Information Aggregation Layer for precise coordinate mapping. The model's output is executed by the action execution module. Experiments on multiple robotic systems (Franka, Kinova, Realman, and Dobot) demonstrate A0's superior performance in complex tasks, showcasing its efficiency, flexibility, and real-world applicability.",
      "authors": [
        "Rongtao Xu",
        "Jian Zhang",
        "Minghao Guo",
        "Youpeng Wen",
        "Haoting Yang",
        "Min Lin",
        "Jianzheng Huang",
        "Zhe Li",
        "Kaidong Zhang",
        "Liqiong Wang",
        "Yuxuan Kuang",
        "Meng Cao",
        "Feng Zheng",
        "Xiaodan Liang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12636",
        "HTML": "https://arxiv.org/html/2504.12636",
        "PDF": "https://arxiv.org/pdf/2504.12636"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 17 Apr 2025 04:45:15 GMT",
          "size": "38175kb",
          "version": "v1"
        },
        {
          "date": "Mon, 21 Apr 2025 02:13:17 GMT",
          "size": "38176kb",
          "version": "v2"
        },
        {
          "date": "Tue, 06 May 2025 07:45:54 GMT",
          "size": "41784kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 15:30:51 GMT",
          "size": "15354kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A0: An Affordance-Aware Hierarchical Model for General Robotic Manipulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a model for robotic manipulation involving spatial affordance, yet it does not relate to data processing tasks pertinent to LLM training data."
      }
    },
    {
      "id": "2504.12646",
      "abstract": "Context: Systematic reviews (SRs) summarize state-of-the-art evidence in science, including software engineering (SE). Objective: Our objective is to evaluate how SRs report research artifacts and to provide a comprehensive list of these artifacts. Method: We examined 537 secondary studies published between 2013 and 2023 to analyze the availability and reporting of research artifacts. Results: Our findings indicate that only 31.5% of the reviewed studies include research artifacts. Encouragingly, the situation is gradually improving, as our regression analysis shows a significant increase in the availability of research artifacts over time. However, in 2023, just 62.0% of secondary studies provide a research artifact while an even lower percentage, 30.4% use a permanent repository with a digital object identifier (DOI) for storage. Conclusion: To enhance transparency and reproducibility in SE research, we advocate for the mandatory publication of research artifacts in secondary studies.",
      "authors": [
        "Aleksi Huotala",
        "Miikka Kuutila and Mika M\\\"antyl\\\"a"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12646",
        "HTML": "https://arxiv.org/html/2504.12646",
        "PDF": "https://arxiv.org/pdf/2504.12646"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 17 Apr 2025 05:11:39 GMT",
          "size": "604kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:53:59 GMT",
          "size": "9kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Research Artifacts in Secondary Studies: A Systematic Mapping in Software Engineering",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper studies the reporting of research artifacts in software engineering systematic reviews, which is unrelated to LLM training data engineering or processing."
      }
    },
    {
      "id": "2504.13747",
      "abstract": "In this work, we introduce two complementary metrics for quantifying and scoring privilege risk in Microsoft Azure.\n  In the Control Plane, we define the WAR distance, a superincreasing distance over Write, Action, and Read control permissions, which yields a total ordering of principals by their configuration power.\n  In the Data Plane, we present a blast radius distance for measuring the maximum breadth of data exfiltration and forgery, leveraging the natural ultrametry of Azure Tenants clustering hierarchy\n  Together, these metrics offer a unified framework for proactive IAM analysis, ranking, lifecycle monitoring, and least privilege enforcement.",
      "authors": [
        "Christophe Parisel"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13747",
        "HTML": "https://arxiv.org/html/2504.13747",
        "PDF": "https://arxiv.org/pdf/2504.13747"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 18 Apr 2025 15:29:51 GMT",
          "size": "19kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 11:41:16 GMT",
          "size": "20kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Scoring Azure permissions with metric spaces",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses metrics for scoring privilege risk in Microsoft Azure permissions, unrelated to LLM training data collection, construction, or processing."
      },
      "repo_urls": [
        "https://github.com/labyrinthinesecurity/silhouette"
      ]
    },
    {
      "id": "2504.14866",
      "abstract": "As AI workloads drive soaring memory requirements, higher-density on-chip memory is needed for domain-specific accelerators beyond what current SRAM technology can provide. We motivate that algorithms and application behavior should guide the composition of heterogeneous on-chip memories. However, little work has incorporated dynamic application profiles into these design decisions, and no existing tools are expressly designed for this purpose. We present GainSight, a profiling framework that analyzes fine-grained memory access patterns and data lifetimes in domain-specific accelerators. By instrumenting retargetable architectural simulator backends with application- and device-agnostic analytical frontends, GainSight aligns workload-specific traffic and lifetime metrics with mockups of emerging memory devices, informing system-level heterogeneous memory design. We also present a set of case studies on MLPerf Inference and PolyBench workloads using simulated GPU and systolic array architectures, highlighting the utility of GainSight and the insights it provides: (1) 64% of L1 and 18% of L2 GPU cache accesses, and 79% of systolic array scratchpad accesses across profiled workloads are short-lived and suitable for silicon-based gain cell RAM (Si-GCRAM); (2) Heterogeneous memory arrays that augment SRAM with GCRAM can reduce active energy consumption by up to 66.8%. To facilitate further research in this domain, GainSight is open source at https://gainsight.stanford.edu/.",
      "authors": [
        "Peijing Li",
        "Matthew Hung",
        "Yiming Tan",
        "Konstantin Ho{\\ss}feld",
        "Jake Cheng Jiajun",
        "Shuhan Liu",
        "Lixian Yan",
        "Xinxin Wang",
        "H.-S. Philip Wong",
        "Thierry Tambe"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14866",
        "HTML": "https://arxiv.org/html/2504.14866",
        "PDF": "https://arxiv.org/pdf/2504.14866"
      },
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 21 Apr 2025 05:27:33 GMT",
          "size": "1258kb",
          "version": "v1"
        },
        {
          "date": "Tue, 22 Apr 2025 17:23:28 GMT",
          "size": "1254kb",
          "version": "v2"
        },
        {
          "date": "Sun, 22 Jun 2025 05:23:09 GMT",
          "size": "2902kb",
          "version": "v3"
        },
        {
          "date": "Tue, 24 Jun 2025 19:02:08 GMT",
          "size": "2902kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "GainSight: Application-Guided Profiling for Composing Heterogeneous On-Chip Memories in AI Hardware Accelerators",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a framework for profiling memory access in AI hardware accelerators, which does not involve the processing or engineering of LLM training data."
      },
      "repo_urls": [
        "https://code.stanford.edu/tambe-lab/gainsight.git"
      ]
    },
    {
      "id": "2504.20305",
      "abstract": "While existing algorithms may be used to solve a linear system over a general field in matrix-multiplication time, the complexity of constructing a symmetric triangular factorization (LDL) has received relatively little formal study. The LDL factorization is a common tool for factorization of symmetric matrices, and, unlike orthogonal counterparts, generalizes to an arbitrary field. We provide algorithms for dense and sparse LDL and LU factorization that aim to minimize complexity for factorization over a general field. For LDL of an $n\\times n$ matrix, we give an algorithm with complexity $O(n^\\omega)$, where the complexity of $n\\times n$ matrix multiplication is assumed to be $O(n^\\omega)$ with $\\omega>2$. For sparse matrices corresponding to graphs with treewidth $\\tau$, we give an algorithm with complexity $O(n\\tau^{\\omega-1})$, to compute an LDL an implicit form, or the explicit LDL if the matrix is near full rank. Our sparse LDL algorithm is based on an adaptation of the null-space method for solving saddle point systems of equations, which may be of independent interest. The sparse LDL factorization algorithm also extends to computing a sparse LU factorization.",
      "authors": [
        "Edgar Solomonik"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20305",
        "HTML": "https://arxiv.org/html/2504.20305",
        "PDF": "https://arxiv.org/pdf/2504.20305"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 28 Apr 2025 23:26:50 GMT",
          "size": "317kb",
          "version": "v1"
        },
        {
          "date": "Wed, 30 Apr 2025 15:00:39 GMT",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "Wed, 04 Jun 2025 23:54:35 GMT",
          "size": "70kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 16:55:08 GMT",
          "size": "61kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fast LDL factorization for dense and sparse symmetric matrices over an arbitrary field",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on algorithms for matrix factorization, specifically LDL and LU factorization, with no connection to LLM training data processing or engineering."
      }
    },
    {
      "id": "2504.20861",
      "abstract": "Two approaches to incorporate heterogeneity in discrete models are compared. In the first, standard approach, the heterogeneity is dictated by geometrical structure of the discrete system. In the second approach, the heterogeneity is imposed by randomizing material parameters of the contacts between the rigid bodies. A similar randomization strategy is often adopted in continuous homogeneous models. The study investigates both the elastic and fracture behaviors of these model types, and compares their local and macroscale responses. It is found that the stress oscillations present in the standard discrete models built on heterogeneous geometric structures cannot be replicated by randomization of the elastically homogeneous discrete system. The marginal distributions and dependencies between the stress tensor components cannot be adequately matched. Therefore, there is a fundamental difference between these two views on discrete models. The numerical experiments performed in the paper showed that an identical response can be achieved at the macroscale by tuning the material parameters. However, the local behavior, fracturing, and internal dependencies are quite different. These findings provide insight into the potential for controlled random assignment of heterogeneity in homogeneous models. They also demonstrate the need for experimental data capable of verifying the correctness of such an approach.",
      "authors": [
        "Jan Raisinger and Qiwei Zhang and John E. Bolander and Jan Eli\\'a\\v{s}"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20861",
        "HTML": "https://arxiv.org/html/2504.20861",
        "PDF": "https://arxiv.org/pdf/2504.20861"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 29 Apr 2025 15:37:27 GMT",
          "size": "5459kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:13:47 GMT",
          "size": "1896kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Simulating Heterogeneity within Elastic and Inelastic Discrete Mechanical Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on incorporating heterogeneity in discrete mechanical models and does not involve any aspect of LLM training data collection or processing."
      }
    },
    {
      "id": "2504.21624",
      "abstract": "Given a graph $G$, a set $T$ of terminal vertices, and a demand graph $H$ on $T$, the \\textsc{Multicut} problem asks for a set of edges of minimum weight that separates the pairs of terminals specified by the edges of $H$.\n  The \\textsc{Multicut} problem can be solved in polynomial time if the number of terminals and the genus of the graph is bounded (Colin de Verdi\\`ere [Algorithmica, 2017]).\n  Focke et al.~[SoCG 2024] characterized which special cases of Multicut are fixed-parameter tractable parameterized by the number of terminals on planar graphs. Moreover, they precisely determined how the parameter genus influences the complexity and presented partial results of this form for graphs that can be made planar by the deletion of $\\pi$ edges. We complete the picture on how this parameter $\\pi$ influences the complexity of different special cases and precisely determine the influence of the crossing number.\n  Formally, let $\\mathcal{H}$ be any class of graphs (satisfying a mild closure property) and let Multicut$(\\mathcal{H})$ be the special case when the demand graph $H$ is in $\\mathcal{H}$. Our first main result is showing that if $\\mathcal{H}$ has the combinatorial property of having bounded distance to extended bicliques, then Multicut$(\\mathcal{H})$ on unweighted graphs is FPT parameterized by the number $t$ of terminals and $\\pi$. For the case when $\\mathcal{H}$ does not have this combinatorial property,\n  Focke et al.~[SoCG 2024] showed that $O(\\sqrt{t})$ is essentially the best possible exponent of the running time; together with our result, this gives a complete understanding of how the parameter $\\pi$ influences complexity on unweighted graphs.\n  Our second main result is giving an algorithm whose existence shows that the parameter crossing number behaves analogously if we consider weighted graphs.",
      "authors": [
        "Florian H\\\"orsch and D\\'aniel Marx"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21624",
        "HTML": "https://arxiv.org/html/2504.21624",
        "PDF": "https://arxiv.org/pdf/2504.21624"
      },
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 30 Apr 2025 13:26:46 GMT",
          "size": "221kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:47:52 GMT",
          "size": "190kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multicut Problems in Almost-Planar Graphs: The Dependency of Complexity on the Demand Pattern",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study is centered on solving combinatorial problems in graph theory and does not discuss LLM training data processing or data engineering."
      }
    },
    {
      "id": "2505.01484",
      "abstract": "Given a text, can we determine whether it was generated by a large language model (LLM) or by a human? A widely studied approach to this problem is watermarking. We propose an undetectable and elementary watermarking scheme in the closed setting. Also, in the harder open setting, where the adversary has access to most of the model, we propose an unremovable watermarking scheme.",
      "authors": [
        "Pedro Abdalla and Roman Vershynin"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01484",
        "HTML": "https://arxiv.org/html/2505.01484",
        "PDF": "https://arxiv.org/pdf/2505.01484"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 02 May 2025 16:36:43 GMT",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 18:37:32 GMT",
          "size": "17kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses watermarking schemes for determining if text is generated by an LLM, focusing on security aspects without addressing LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ]
    },
    {
      "id": "2505.03468",
      "abstract": "We investigate a co-design problem, encompassing simultaneous design of system infrastructure and control, through a game-theoretical framework. To this end, we propose the co-design problem as a two-layer hierarchical strategic interaction. At the upper layer, a leader (or multiple leaders) determines system design parameters, while at the lower layer, a follower (or multiple followers) optimizes the control strategy. To capture this hierarchy, we propose four novel classes of Stackelberg games that integrate diverse strategic behaviors, including combinations of cooperative and non-cooperative interactions across two different layers. Notably, the leaders' interactions are represented using a normal-form game, whereas the followers' interactions are modeled by different games (dynamic games in discrete time). These distinct game structures result in a Stackelberg game that accommodates different game types per layer, and/or supports heterogeneous strategic behaviors involving cooperation and non-cooperation simultaneously. Learning algorithms using the best-response dynamics are used to solve the game problems when considering a discrete strategic space for the leaders. The efficacy of the proposed approach is demonstrated through an application to the co-design of the Barcelona drinking water network.",
      "authors": [
        "Julian Barreiro-Gomez",
        "Ye Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03468",
        "HTML": "https://arxiv.org/html/2505.03468",
        "PDF": "https://arxiv.org/pdf/2505.03468"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 06 May 2025 12:17:07 GMT",
          "size": "1024kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:25:10 GMT",
          "size": "981kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multi-Class Stackelberg Games for the Co-Design of Networked Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on game-theoretical frameworks for co-designing networked systems, which is unrelated to processing or engineering data for LLM training."
      },
      "tasks": []
    },
    {
      "id": "2505.03906",
      "abstract": "Large language models (LLMs) have transformed software development through code generation capabilities, yet their effectiveness for high-performance computing (HPC) remains limited. HPC code requires specialized optimizations for parallelism, memory efficiency, and architecture-specific considerations that general-purpose LLMs often overlook. We present MARCO (Multi-Agent Reactive Code Optimizer), a novel framework that enhances LLM-generated code for HPC through a specialized multi-agent architecture. MARCO employs separate agents for code generation and performance evaluation, connected by a feedback loop that progressively refines optimizations. A key innovation is MARCO's web-search component that retrieves real-time optimization techniques from recent conference proceedings and research publications, bridging the knowledge gap in pre-trained LLMs. Our extensive evaluation on the LeetCode 75 problem set demonstrates that MARCO achieves a 14.6\\% average runtime reduction compared to Claude 3.5 Sonnet alone, while the integration of the web-search component yields a 30.9\\% performance improvement over the base MARCO system. These results highlight the potential of multi-agent systems to address the specialized requirements of high-performance code generation, offering a cost-effective alternative to domain-specific model fine-tuning.",
      "authors": [
        "Asif Rahman",
        "Veljko Cvetkovic",
        "Kathleen Reece",
        "Aidan Walters",
        "Yasir Hassan",
        "Aneesh Tummeti",
        "Bryan Torres",
        "Denise Cooney",
        "Margaret Ellis and Dimitrios S. Nikolopoulos"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03906",
        "HTML": "https://arxiv.org/html/2505.03906",
        "PDF": "https://arxiv.org/pdf/2505.03906"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 06 May 2025 18:22:38 GMT",
          "size": "356kb",
          "version": "v1"
        },
        {
          "date": "Tue, 13 May 2025 12:41:18 GMT",
          "size": "359kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 14:22:04 GMT",
          "size": "358kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MARCO: Multi-Agent Code Optimization with Real-Time Knowledge Integration for High-Performance Computing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Although the paper involves LLMs, it primarily focuses on code optimization for high-performance computing rather than any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Code Generation"
      ]
    },
    {
      "id": "2505.04396",
      "abstract": "The planning and operation of renewable energy, especially wind power, depend crucially on accurate, timely, and high-resolution weather information. Coarse-grid global numerical weather forecasts are typically downscaled to meet these requirements, introducing challenges of scale inconsistency, process representation error, computation cost, and entanglement of distinct uncertainty sources from chaoticity, model bias, and large-scale forcing. We address these challenges by learning the climatological distribution of a target wind farm using its high-resolution numerical weather simulations. An optimal combination of this learned high-resolution climatological prior with coarse-grid large scale forecasts yields highly accurate, fine-grained, full-variable, large ensemble of weather pattern forecasts. Using observed meteorological records and wind turbine power outputs as references, the proposed methodology verifies advantageously compared to existing numerical/statistical forecasting-downscaling pipelines, regarding either deterministic/probabilistic skills or economic gains. Moreover, a 100-member, 10-day forecast with spatial resolution of 1 km and output frequency of 15 min takes < 1 hour on a moderate-end GPU, as contrast to $\\mathcal{O}(10^3)$ CPU hours for conventional numerical simulation. By drastically reducing computational costs while maintaining accuracy, our method paves the way for more efficient and reliable renewable energy planning and operation.",
      "authors": [
        "Jingnan Wang",
        "Jie Chao",
        "Shangshang Yang",
        "Congyi Nai",
        "Kaijun Ren",
        "Kefeng Deng",
        "Xi Chen",
        "Yaxin Liu",
        "Hanqiuzi Wen",
        "Ziniu Xiao",
        "Lifeng Zhang",
        "Xiaodong Wang",
        "Jiping Guan",
        "Baoxiang Pan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04396",
        "HTML": "https://arxiv.org/html/2505.04396",
        "PDF": "https://arxiv.org/pdf/2505.04396"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 07 May 2025 13:20:36 GMT",
          "size": "13991kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:04:43 GMT",
          "size": "13908kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Supporting renewable energy planning and operation with data-driven high-resolution ensemble weather forecast",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses renewable energy planning using weather forecasts and does not deal with data processes relevant to LLM training data."
      },
      "tasks": []
    },
    {
      "id": "2505.07089",
      "abstract": "Automated penetration testing (AutoPT) powered by large language models (LLMs) has gained attention for its ability to automate ethical hacking processes and identify vulnerabilities in target systems by leveraging the inherent knowledge of LLMs. However, existing LLM-based AutoPT frameworks often underperform compared to human experts in challenging tasks for several reasons: the imbalanced knowledge used in LLM training, short-sightedness in the planning process, and hallucinations during command generation. Moreover, the trial-and-error nature of the PT process is constrained by existing frameworks lacking mechanisms to learn from previous failures, restricting adaptive improvement of PT strategies. To address these limitations, we propose a knowledge-informed, self-reflective PT framework powered by LLMs, called RefPentester. This AutoPT framework is designed to assist human operators in identifying the current stage of the PT process, selecting appropriate tactics and techniques for each stage, choosing suggested actions, providing step-by-step operational guidance, and reflecting on and learning from previous failed operations. We also modeled the PT process as a seven-state Stage Machine to integrate the proposed framework effectively. The evaluation shows that RefPentester can successfully reveal credentials on Hack The Box's Sau machine, outperforming the baseline GPT-4o model by 16.7%. Across PT stages, RefPentester also demonstrates superior success rates on PT stage transitions.",
      "authors": [
        "Hanzheng Dai and Yuanliang Li and Jun Yan and Zhibo Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07089",
        "HTML": "https://arxiv.org/html/2505.07089",
        "PDF": "https://arxiv.org/pdf/2505.07089"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 11 May 2025 18:38:00 GMT",
          "size": "3327kb",
          "version": "v1"
        },
        {
          "date": "Wed, 14 May 2025 00:44:05 GMT",
          "size": "3327kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 14:14:56 GMT",
          "size": "3327kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Despite utilizing LLMs, the paper centers on penetration testing frameworks rather than any processes related to managing LLM training data."
      },
      "tasks": []
    },
    {
      "id": "2505.12758",
      "abstract": "Understanding people's preferences and needs is crucial for urban planning decisions, yet current approaches often combine them from multi-cultural and multi-city populations, obscuring important demographic differences and risking amplifying biases. We conducted a large-scale urban visual perception survey of streetscapes worldwide using street view imagery, examining how demographics -- including gender, age, income, education, race and ethnicity, and, for the first time, personality traits -- shape perceptions among 1,000 participants, with balanced demographics, from five countries and 45 nationalities. This dataset, introduced as Street Perception Evaluation Considering Socioeconomics (SPECS), exhibits statistically significant differences in perception scores in six traditionally used indicators (safe, lively, wealthy, beautiful, boring, and depressing) and four new ones we propose (live nearby, walk, cycle, green) among demographics and personalities. We revealed that location-based sentiments are carried over in people's preferences when comparing urban streetscapes with other cities. Further, we compared the perception scores based on where participants and streetscapes are from. We found that an off-the-shelf machine learning model trained on an existing global perception dataset tends to overestimate positive indicators and underestimate negative ones compared to human responses, suggesting that targeted intervention should consider locals' perception. Our study aspires to rectify the myopic treatment of street perception, which rarely considers demographics or personality traits.",
      "authors": [
        "Matias Quintana",
        "Youlong Gu",
        "Xiucheng Liang",
        "Yujun Hou",
        "Koichi Ito",
        "Yihan Zhu",
        "Mahmoud Abdelrahman",
        "Filip Biljecki"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12758",
        "HTML": "https://arxiv.org/html/2505.12758",
        "PDF": "https://arxiv.org/pdf/2505.12758"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 19 May 2025 06:35:11 GMT",
          "size": "14600kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:02:08 GMT",
          "size": "20735kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "It's not you, it's me -- Global urban visual perception varies across demographics and personalities",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on urban visual perception surveys and does not address LLM training data construction, processing, or related tasks."
      },
      "tasks": []
    },
    {
      "id": "2505.13033",
      "abstract": "The rise of time-series pre-trained models has advanced temporal representation learning, but current state-of-the-art models are often large-scale, requiring substantial compute. We introduce TSPulse, ultra-compact time-series pre-trained models with only 1M parameters, specialized to perform strongly across classification, anomaly detection, imputation, and retrieval tasks. TSPulse introduces innovations at both the architecture and task levels. At the architecture level, it employs a dual-space masked reconstruction, learning from both time and frequency domains to capture complementary signals. This is further enhanced by a dual-embedding disentanglement, generating both detailed embeddings for fine-grained analysis and high-level semantic embeddings for broader task understanding. Notably, TSPulse's semantic embeddings are robust to shifts in time, magnitude, and noise, which is important for robust retrieval. At the task level, TSPulse incorporates TSLens, a fine-tuning component enabling task-specific feature attention. It also introduces a multi-head triangulation technique that correlates deviations from multiple prediction heads, enhancing anomaly detection by fusing complementary model outputs. Additionally, a hybrid mask pretraining is proposed to improves zero-shot imputation by reducing pre-training bias. These architecture and task innovations collectively contribute to TSPulse's significant performance gains: 5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly detection leaderboard, +50% in zero-shot imputation, and +25% in time-series retrieval. Remarkably, these results are achieved with just 1M parameters (10-100X smaller than existing SOTA models) and allow GPU-free inference, setting a new standard for efficient time-series pre-trained models. The models can be accessed from https://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1",
      "authors": [
        "Vijay Ekambaram",
        "Subodh Kumar",
        "Arindam Jati",
        "Sumanta Mukherjee",
        "Tomoya Sakai",
        "Pankaj Dayama",
        "Wesley M. Gifford",
        "Jayant Kalagnanam"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13033",
        "HTML": "https://arxiv.org/html/2505.13033",
        "PDF": "https://arxiv.org/pdf/2505.13033"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 19 May 2025 12:18:53 GMT",
          "size": "2427kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 04:59:41 GMT",
          "size": "2428kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses advancements in time-series models and does not involve LLM-specific training data collection or processing."
      },
      "models": [
        {
          "model_path": "ibm-granite/granite-timeseries-tspulse-r1",
          "downloads": "12767",
          "likes": "4",
          "trending_score": "1.0",
          "link": "https://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1"
        }
      ],
      "tasks": [
        "Anomaly Detection",
        "Disentanglement",
        "Imputation",
        "Retrieval",
        "Time Series",
        "Time Series Analysis"
      ]
    },
    {
      "id": "2505.13238",
      "abstract": "While data perimeter is ubiquitous in cybersecurity speak, it rarely defines how boundary points are arranged. In this paper we show how Azure s blast radius ultrametric provides the distance, and how solving the Traveling Salesman Problem in this ultrametric space provides the ordering, yielding a true geometric contour: an actionable perimeter measure for SPN prioritization.",
      "authors": [
        "Christophe Parisel"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13238",
        "HTML": "https://arxiv.org/html/2505.13238",
        "PDF": "https://arxiv.org/pdf/2505.13238"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 19 May 2025 15:21:08 GMT",
          "size": "6kb",
          "version": "v1"
        },
        {
          "date": "Tue, 20 May 2025 07:25:25 GMT",
          "size": "6kb",
          "version": "v2"
        },
        {
          "date": "Fri, 20 Jun 2025 12:46:25 GMT",
          "size": "8kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 17:07:30 GMT",
          "size": "8kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Geometry-Grounded Data Perimeter in Azure",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is related to cybersecurity and data perimeter measures in Azure, with no relevance to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/labyrinthinesecurity/silhouette"
      ]
    },
    {
      "id": "2505.17282",
      "abstract": "Token embeddings play a crucial role in language modeling but, despite this practical relevance, their theoretical understanding remains limited. Our paper addresses the gap by characterizing the structure of embeddings obtained via gradient descent. Specifically, we consider a one-layer softmax attention model with a linear head for binary classification, i.e., $\\texttt{Softmax}( p^\\top E_X^\\top ) E_X v = \\frac{ \\sum_{i=1}^T \\exp(p^\\top E_{x_i}) E_{x_i}^\\top v}{\\sum_{j=1}^T \\exp(p^\\top E_{x_{j}}) }$, where $E_X = [ E_{x_1} , \\dots, E_{x_T} ]^\\top$ contains the embeddings of the input sequence, $p$ is the embedding of the $\\mathrm{\\langle cls \\rangle}$ token and $v$ the output vector. First, we show that, already after a single step of gradient training with the logistic loss, the embeddings $E_X$ capture the importance of tokens in the dataset by aligning with the output vector $v$ proportionally to the frequency with which the corresponding tokens appear in the dataset. Then, after training $p$ via gradient flow until convergence, the softmax selects the important tokens in the sentence (i.e., those that are predictive of the label), and the resulting $\\mathrm{\\langle cls \\rangle}$ embedding maximizes the margin for such a selection. Experiments on real-world datasets (IMDB, Yelp) exhibit a phenomenology close to that unveiled by our theory.",
      "authors": [
        "Diyuan Wu",
        "Aleksandr Shevchenko",
        "Samet Oymak",
        "Marco Mondelli"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17282",
        "HTML": "https://arxiv.org/html/2505.17282",
        "PDF": "https://arxiv.org/pdf/2505.17282"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 22 May 2025 21:00:09 GMT",
          "size": "3172kb",
          "version": "v1"
        },
        {
          "date": "Mon, 09 Jun 2025 09:35:47 GMT",
          "size": "3175kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 15:19:05 GMT",
          "size": "3175kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Attention with Trained Embeddings Provably Selects Important Tokens",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses token embedding significance and attention mechanisms in classification tasks, without focusing on training data processing or engineering for LLMs."
      },
      "tasks": [
        "Binary Classification",
        "Language Modeling",
        "Language Modelling"
      ]
    },
    {
      "id": "2505.17333",
      "abstract": "Temporal modeling on regular respiration-induced motions is crucial to image-guided clinical applications. Existing methods cannot simulate temporal motions unless high-dose imaging scans including starting and ending frames exist simultaneously. However, in the preoperative data acquisition stage, the slight movement of patients may result in dynamic backgrounds between the first and last frames in a respiratory period. This additional deviation can hardly be removed by image registration, thus affecting the temporal modeling. To address that limitation, we pioneeringly simulate the regular motion process via the image-to-video (I2V) synthesis framework, which animates with the first frame to forecast future frames of a given length. Besides, to promote the temporal consistency of animated videos, we devise the Temporal Differential Diffusion Model to generate temporal differential fields, which measure the relative differential representations between adjacent frames. The prompt attention layer is devised for fine-grained differential fields, and the field augmented layer is adopted to better interact these fields with the I2V framework, promoting more accurate temporal variation of synthesized videos. Extensive results on ACDC cardiac and 4D Lung datasets reveal that our approach simulates 4D videos along the intrinsic motion trajectory, rivaling other competitive methods on perceptual similarity and temporal consistency. Codes will be available soon.",
      "authors": [
        "Xin You",
        "Minghui Zhang",
        "Hanxiao Zhang",
        "Jie Yang",
        "Nassir Navab"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17333",
        "HTML": "https://arxiv.org/html/2505.17333",
        "PDF": "https://arxiv.org/pdf/2505.17333"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 22 May 2025 23:01:48 GMT",
          "size": "1393kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 19:43:16 GMT",
          "size": "1395kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Temporal Differential Fields for 4D Motion Modeling via Image-to-Video Synthesis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is concerned with temporal motion modeling and image-to-video synthesis, without any focus on LLM training data processing or data engineering."
      }
    },
    {
      "id": "2505.18746",
      "abstract": "Agents based on large language models leverage tools to modify environments, revolutionizing how AI interacts with the physical world. Unlike traditional NLP tasks that rely solely on historical dialogue for responses, these agents must consider more complex factors, such as inter-tool relationships, environmental feedback and previous decisions, when making choices. Current research typically evaluates agents via multi-turn dialogues. However, it overlooks the influence of these critical factors on agent behavior. To bridge this gap, we present an open-source and high-quality benchmark $C^3$-Bench. This benchmark integrates attack concepts and applies univariate analysis to pinpoint key elements affecting agent robustness. In concrete, we design three challenges: navigate complex tool relationships, handle critical hidden information and manage dynamic decision paths. Complementing these challenges, we introduce fine-grained metrics, innovative data collection algorithms and reproducible evaluation methods. Extensive experiments are conducted on 49 mainstream agents, encompassing general fast-thinking, slow-thinking and domain-specific models. We observe that agents have significant shortcomings in handling tool dependencies, long context information dependencies and frequent policy-type switching. In essence, $C^3$-Bench aims to expose model vulnerabilities through these challenges and drive research into the interpretability of agent performance. The benchmark is publicly available at https://github.com/yupeijei1997/C3-Bench.",
      "authors": [
        "Peijie Yu",
        "Yifan Yang",
        "Jinjian Li",
        "Zelong Zhang",
        "Haorui Wang",
        "Xiao Feng",
        "Feng Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18746",
        "HTML": "https://arxiv.org/html/2505.18746",
        "PDF": "https://arxiv.org/pdf/2505.18746"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 24 May 2025 15:25:44 GMT",
          "size": "6919kb",
          "version": "v1"
        },
        {
          "date": "Tue, 27 May 2025 02:22:28 GMT",
          "size": "6918kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 10:37:25 GMT",
          "size": "6575kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a benchmark for evaluating LLM-based agents, focusing on agent behavior rather than the training data processing for LLMs."
      },
      "tasks": [
        "Navigate"
      ],
      "repo_urls": [
        "https://github.com/yupeijei1997/c3-bench"
      ]
    },
    {
      "id": "2505.19550",
      "abstract": "With the rise of artificial intelligence (A.I.) and large language models like ChatGPT, a new race for achieving artificial general intelligence (A.G.I) has started. While many speculate how and when A.I. will achieve A.G.I., there is no clear agreement on how A.G.I. can be detected in A.I. models, even when popular tools like the Turing test (and its modern variations) are used to measure their intelligence. In this work, we discuss why traditional methods like the Turing test do not suffice for measuring or detecting A.G.I. and provide a new, practical method that can be used to decide if a system (computer or any other) has reached or surpassed A.G.I. To achieve this, we make two new contributions. First, we present a clear definition for general intelligence (G.I.) and set a G.I. Threshold (G.I.T.) that can be used to distinguish between systems that achieve A.G.I. and systems that do not. Second, we present a new framework on how to construct tests that can detect if a system has achieved G.I. in a simple, comprehensive, and clear-cut fail/pass way. We call this novel framework the Turing test 2.0. We then demonstrate real-life examples of applying tests that follow our Turing test 2.0 framework on modern A.I. models.",
      "authors": [
        "Georgios Mappouras"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19550",
        "HTML": "https://arxiv.org/html/2505.19550",
        "PDF": "https://arxiv.org/pdf/2505.19550"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 26 May 2025 06:13:15 GMT",
          "size": "999kb",
          "version": "v1"
        },
        {
          "date": "Fri, 30 May 2025 06:53:17 GMT",
          "size": "1001kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 01:55:54 GMT",
          "size": "1135kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Turing Test 2.0: The General Intelligence Threshold",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on defining general intelligence and a new framework for testing AGI, without discussing LLM training data collection, construction, or processing."
      },
      "tasks": []
    },
    {
      "id": "2505.21381",
      "abstract": "State Space models (SSMs) such as PointMamba enable efficient feature extraction for point cloud self-supervised learning with linear complexity, outperforming Transformers in computational efficiency. However, existing PointMamba-based methods depend on complex token ordering and random masking, which disrupt spatial continuity and local semantic correlations. We propose ZigzagPointMamba to tackle these challenges. The core of our approach is a simple zigzag scan path that globally sequences point cloud tokens, enhancing spatial continuity by preserving the proximity of spatially adjacent point tokens. Nevertheless, random masking undermines local semantic modeling in self-supervised learning. To address this, we introduce a Semantic-Siamese Masking Strategy (SMS), which masks semantically similar tokens to facilitate reconstruction by integrating local features of original and similar tokens. This overcomes the dependence on isolated local features and enables robust global semantic modeling. Our pre-trained ZigzagPointMamba weights significantly improve downstream tasks, achieving a 1.59% mIoU gain on ShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for classification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for the classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of ScanObjectNN.",
      "authors": [
        "Linshuang Diao",
        "Dayong Ren",
        "Sensen Song",
        "Yurong Qian"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21381",
        "HTML": "https://arxiv.org/html/2505.21381",
        "PDF": "https://arxiv.org/pdf/2505.21381"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 27 May 2025 16:09:50 GMT",
          "size": "4895kb",
          "version": "v1"
        },
        {
          "date": "Tue, 10 Jun 2025 13:46:35 GMT",
          "size": "4895kb",
          "version": "v2"
        },
        {
          "date": "Sat, 21 Jun 2025 17:43:01 GMT",
          "size": "0kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 08:49:26 GMT",
          "size": "4895kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a method (ZigzagPointMamba) for point cloud analysis without any focus on LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Mamba",
        "Self-Supervised Learning",
        "State Space Models"
      ]
    },
    {
      "id": "2505.21758",
      "abstract": "With high-performance computing systems now running at exascale, optimizing power-scaling management and resource utilization has become more critical than ever. This paper explores runtime power-capping optimizations that leverage integrated CPU-GPU power management on architectures like the NVIDIA GH200 superchip. We evaluate energy-performance metrics that account for simultaneous CPU and GPU power-capping effects by using two complementary approaches: speedup-energy-delay and a Euclidean distance-based multi-objective optimization method. By targeting a mostly compute-bound exascale science application, the Locally Self-Consistent Multiple Scattering (LSMS), we explore challenging scenarios to identify potential opportunities for energy savings in exascale applications, and we recognize that even modest reductions in energy consumption can have significant overall impacts. Our results highlight how GPU task-specific dynamic power-cap adjustments combined with integrated CPU-GPU power steering can improve the energy utilization of certain GPU tasks, thereby laying the groundwork for future adaptive optimization strategies.",
      "authors": [
        "Maria Patrou",
        "Thomas Wang",
        "Wael Elwasif",
        "Markus Eisenbach",
        "Ross Miller",
        "William Godoy and Oscar Hernandez"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21758",
        "HTML": "https://arxiv.org/html/2505.21758",
        "PDF": "https://arxiv.org/pdf/2505.21758"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Performance (cs.PF)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 27 May 2025 20:48:33 GMT",
          "size": "833kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 21:21:40 GMT",
          "size": "833kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Power-Capping Metric Evaluation for Improving Energy Efficiency in HPC Applications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with power-capping metrics for energy efficiency in HPC applications, unrelated to LLM training data processing."
      }
    },
    {
      "id": "2505.22843",
      "abstract": "The performance figures of modern drift-adaptive malware classifiers appear promising, but does this translate to genuine operational reliability? The standard evaluation paradigm primarily focuses on baseline performance metrics, neglecting confidence-error alignment and operational stability. While TESSERACT established the importance of temporal evaluation, we take a complementary direction by investigating whether malware classifiers maintain reliable and stable confidence estimates under distribution shifts and exploring the tensions between scientific advancement and practical impacts when they do not. We propose AURORA, a framework to evaluate malware classifiers based on their confidence quality and operational resilience. AURORA subjects the confidence profile of a given model to verification to assess the reliability of its estimates. Unreliable confidence estimates erode operational trust, waste valuable annotation budget on non-informative samples for active learning, and leave error-prone instances undetected in selective classification. AURORA is complemented by a set of metrics designed to go beyond point-in-time performance, striving towards a more holistic assessment of operational stability throughout temporal evaluation periods. The fragility in SOTA frameworks across datasets of varying drift suggests the need for a return to the whiteboard.",
      "authors": [
        "Alexander Herzog",
        "Aliai Eusebi and Lorenzo Cavallaro"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22843",
        "HTML": "https://arxiv.org/html/2505.22843",
        "PDF": "https://arxiv.org/pdf/2505.22843"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 28 May 2025 20:22:43 GMT",
          "size": "4778kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:30:26 GMT",
          "size": "423kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Aurora: Are Android Malware Classifiers Reliable and Stable under Distribution Shift?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating the reliability and stability of Android malware classifiers and does not address any part of LLM training data processing."
      },
      "tasks": [
        "Active Learning"
      ]
    },
    {
      "id": "2505.24758",
      "abstract": "Graph databases have become essential tools for managing complex and interconnected data, which is common in areas like social networks, bioinformatics, and recommendation systems. Unlike traditional relational databases, graph databases offer a more natural way to model and query intricate relationships, making them particularly effective for applications that demand flexibility and efficiency in handling interconnected data.\n  Despite their increasing use, graph databases face notable challenges. One significant issue is the irregular nature of graph data, often marked by structural sparsity, such as in its adjacency matrix representation, which can lead to inefficiencies in data read and write operations. Other obstacles include the high computational demands of traversal-based queries, especially within large-scale networks, and complexities in managing transactions in distributed graph environments. Additionally, the reliance on traditional centralized architectures limits the scalability of Online Transaction Processing (OLTP), creating bottlenecks due to contention, CPU overhead, and network bandwidth constraints.\n  This paper presents a thorough survey of graph databases. It begins by examining property models, query languages, and storage architectures, outlining the foundational aspects that users and developers typically engage with. Following this, it provides a detailed analysis of recent advancements in graph database technologies, evaluating these in the context of key aspects such as architecture, deployment, usage, and development, which collectively define the capabilities of graph database solutions.",
      "authors": [
        "Miguel E. Coimbra",
        "Lucie Svit\\'akov\\'a",
        "Alexandre P. Francisco",
        "Lu\\'is Veiga"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24758",
        "HTML": "https://arxiv.org/html/2505.24758",
        "PDF": "https://arxiv.org/pdf/2505.24758"
      },
      "subjects": [
        "Databases (cs.DB)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 30 May 2025 16:18:58 GMT",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:57:06 GMT",
          "size": "295kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Survey: Graph Databases",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is a survey on graph databases and discusses their architectures and advancements. It does not address LLM training data processing."
      }
    },
    {
      "id": "2506.01719",
      "abstract": "Although they differ in the functionality they offer, low-level systems exhibit certain patterns of design and utilization of computing resources. In this paper, we argue the position that modalities, in the sense of modal logic, should be a go-to approach when specifying and verifying low-level systems code. We explain how the concept of a resource context helps guide the design of new modalities for verification of systems code, and we justify our perspective by discussing prior systems that have used modalities for systems verification successfully, arguing that they fit into the verification design pattern we articulate, and explaining how this approach might apply to other systems verification challenges.",
      "authors": [
        "Ismail Kuru and Colin S. Gordon"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01719",
        "HTML": "https://arxiv.org/html/2506.01719",
        "PDF": "https://arxiv.org/pdf/2506.01719"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 14:27:05 GMT",
          "size": "266kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:44:42 GMT",
          "size": "312kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Modal Verification Patterns for Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work discusses modal verification patterns for low-level systems, which does not relate to LLM training data."
      }
    },
    {
      "id": "2506.02097",
      "abstract": "Retrieval-Augmented Generation (RAG) systems and large language model (LLM)-powered chatbots have significantly advanced conversational AI by combining generative capabilities with external knowledge retrieval. Despite their success, enterprise-scale deployments face critical challenges, including diverse user queries, high latency, hallucinations, and difficulty integrating frequently updated domain-specific knowledge. This paper introduces a novel hybrid framework that integrates RAG with intent-based canned responses, leveraging predefined high-confidence responses for efficiency while dynamically routing complex or ambiguous queries to the RAG pipeline. Our framework employs a dialogue context manager to ensure coherence in multi-turn interactions and incorporates a feedback loop to refine intents, dynamically adjust confidence thresholds, and expand response coverage over time. Experimental results demonstrate that the proposed framework achieves a balance of high accuracy (95\\%) and low latency (180ms), outperforming RAG and intent-based systems across diverse query types, positioning it as a scalable and adaptive solution for enterprise conversational AI applications.",
      "authors": [
        "Priyaranjan Pattnayak",
        "Amit Agarwal",
        "Hansa Meghwani",
        "Hitesh Laxmichand Patel",
        "Srikant Panda"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02097",
        "HTML": "https://arxiv.org/html/2506.02097",
        "PDF": "https://arxiv.org/pdf/2506.02097"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 17:59:27 GMT",
          "size": "1017kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:18:47 GMT",
          "size": "1017kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Hybrid AI for Responsive Multi-Turn Online Conversations with Novel Dynamic Routing and Feedback Adaptation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a hybrid AI framework for responsive multi-turn online conversations, addressing issues like latency and knowledge integration but does not focus on the data processing aspects related to LLM training, such as data collection or enhancement."
      }
    },
    {
      "id": "2506.02161",
      "abstract": "The rapid advancements of Text-to-Image (T2I) models have ushered in a new phase of AI-generated content, marked by their growing ability to interpret and follow user instructions. However, existing T2I model evaluation benchmarks fall short in limited prompt diversity and complexity, as well as coarse evaluation metrics, making it difficult to evaluate the fine-grained alignment performance between textual instructions and generated images. In this paper, we present TIIF-Bench (Text-to-Image Instruction Following Benchmark), aiming to systematically assess T2I models' ability in interpreting and following intricate textual instructions. TIIF-Bench comprises a set of 5000 prompts organized along multiple dimensions, which are categorized into three levels of difficulties and complexities. To rigorously evaluate model robustness to varying prompt lengths, we provide a short and a long version for each prompt with identical core semantics. Two critical attributes, i.e., text rendering and style control, are introduced to evaluate the precision of text synthesis and the aesthetic coherence of T2I models. In addition, we collect 100 high-quality designer level prompts that encompass various scenarios to comprehensively assess model performance. Leveraging the world knowledge encoded in large vision language models, we propose a novel computable framework to discern subtle variations in T2I model outputs. Through meticulous benchmarking of mainstream T2I models on TIIF-Bench, we analyze the pros and cons of current T2I models and reveal the limitations of current T2I benchmarks. Project Page: https://a113n-w3i.github.io/TIIF_Bench/.",
      "authors": [
        "Xinyu Wei",
        "Jinrui Zhang",
        "Zeqing Wang",
        "Hongyang Wei",
        "Zhen Guo",
        "Lei Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02161",
        "HTML": "https://arxiv.org/html/2506.02161",
        "PDF": "https://arxiv.org/pdf/2506.02161"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 18:44:07 GMT",
          "size": "3683kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:18:10 GMT",
          "size": "3683kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TIIF-Bench: How Does Your T2I Model Follow Your Instructions?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a benchmarking tool for Text-to-Image models, with no focus on language model training data processing. It primarily pertains to evaluating AI models' performance rather than LLM data engineering."
      },
      "datasets": [
        {
          "dataset_name": "A113NW3I/TIIF-Bench-Data",
          "downloads": "320",
          "likes": "4",
          "link": "https://huggingface.co/datasets/A113NW3I/TIIF-Bench-Data"
        }
      ]
    },
    {
      "id": "2506.02280",
      "abstract": "Large Language Models (LLMs) are transforming Natural Language Processing (NLP), but their benefits are largely absent for Africa's 2,000 low-resource languages. This paper comparatively analyzes African language coverage across six LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs). The evaluation covers language coverage, training sets, technical limitations, script problems, and language modelling roadmaps. The work identifies 42 supported African languages and 23 available public data sets, and it shows a big gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are always treated while there is over 98\\% of unsupported African languages. Moreover, the review shows that just Latin, Arabic, and Ge'ez scripts are identified while 20 active scripts are neglected. Some of the primary challenges are lack of data, tokenization biases, computational costs being very high, and evaluation issues. These issues demand language standardization, corpus development by the community, and effective adaptation methods for African languages.",
      "authors": [
        "Kedir Yassin Hussen",
        "Walelign Tewabe Sewunetie",
        "Abinew Ali Ayele",
        "Sukairaj Hafiz Imam",
        "Shamsuddeen Hassan Muhammad",
        "Seid Muhie Yimam"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02280",
        "HTML": "https://arxiv.org/html/2506.02280",
        "PDF": "https://arxiv.org/pdf/2506.02280"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 21:39:40 GMT",
          "size": "9654kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:31:32 GMT",
          "size": "561kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The State of Large Language Models for African Languages: Progress and Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper discusses LLMs and related language data challenges, its contribution lies in analyzing language coverage and training sets rather than proposing new methods for training data processing or enhancement."
      }
    },
    {
      "id": "2506.04761",
      "abstract": "The attention mechanism in Transformers is an important primitive for accurate and scalable sequence modeling. Its quadratic-compute and linear-memory complexity however remain significant bottlenecks. Linear attention and state-space models enable linear-time, constant-memory sequence modeling and can moreover be trained efficiently through matmul-rich parallelization across sequence length. However, at their core these models are still RNNs, and thus their use of a fixed-size hidden state to model the context is a fundamental limitation. This paper develops log-linear attention, an attention mechanism that balances linear attention's efficiency and the expressiveness of softmax attention. Log-linear attention replaces the fixed-size hidden state with a logarithmically growing set of hidden states. We show that with a particular growth function, log-linear attention admits a similarly matmul-rich parallel form whose compute cost is log-linear in sequence length. Log-linear attention is a general framework and can be applied on top of existing linear attention variants. As case studies, we instantiate log-linear variants of two recent architectures -- Mamba-2 and Gated DeltaNet -- and find they perform well compared to their linear-time variants.",
      "authors": [
        "Han Guo",
        "Songlin Yang",
        "Tarushii Goel",
        "Eric P. Xing",
        "Tri Dao",
        "Yoon Kim"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04761",
        "HTML": "https://arxiv.org/html/2506.04761",
        "PDF": "https://arxiv.org/pdf/2506.04761"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Jun 2025 08:44:51 GMT",
          "size": "863kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 04:54:28 GMT",
          "size": "857kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Log-Linear Attention",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research develops a new attention mechanism for Transformers, focusing on model efficiency improvements rather than LLM training data processing or data engineering aspects."
      },
      "tasks": [
        "Mamba",
        "State Space Models"
      ]
    },
    {
      "id": "2506.06300",
      "abstract": "Physics-informed neural networks (PINNs) have emerged as a powerful meshless tool for topology optimization, capable of simultaneously determining optimal topologies and physical solutions. However, conventional PINNs rely on density-based topology descriptions, which necessitate manual interpolation and limit their applicability to complex geometries. To address this, we propose Lagrangian topology-conscious PINNs (LT-PINNs), a novel framework for boundary-focused engineering optimization. By parameterizing the control variables of topology boundary curves as learnable parameters, LT-PINNs eliminate the need for manual interpolation and enable precise boundary determination. We further introduce specialized boundary condition loss function and topology loss function to ensure sharp and accurate boundary representations, even for intricate topologies. The accuracy and robustness of LT-PINNs are validated via two types of partial differential equations (PDEs), including elastic equation with Dirichlet boundary conditions and Laplace's equation with Neumann boundary conditions. Furthermore, we demonstrate effectiveness of LT-PINNs on more complex time-dependent and time-independent flow problems without relying on measurement data, and showcase their engineering application potential in flow velocity rearrangement, transforming a uniform upstream velocity into a sine-shaped downstream profile. The results demonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors compared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2) LT-PINNs can handle arbitrary boundary conditions, making them suitable for a wide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries without manual interpolation, especially for complex topologies.",
      "authors": [
        "Yuanye Zhou",
        "Zhaokun Wang",
        "Kai Zhou",
        "Hui Tang",
        "Xiaofan Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06300",
        "HTML": "https://arxiv.org/html/2506.06300",
        "PDF": "https://arxiv.org/pdf/2506.06300"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 19 May 2025 09:10:31 GMT",
          "size": "8399kb",
          "version": "v1"
        },
        {
          "date": "Tue, 10 Jun 2025 13:27:26 GMT",
          "size": "8399kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 16:48:42 GMT",
          "size": "8399kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on using physics-informed neural networks for topology optimization in engineering without discussing any aspects related to the data processing of LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/cloud2009/lt-pinn"
      ]
    },
    {
      "id": "2506.06643",
      "abstract": "We estimate scene depth from a single defocus-blurred image using the dark channel as a complementary cue, leveraging its ability to capture local statistics and scene structure. Traditional depth-from-defocus (DFD) methods use multiple images with varying apertures or focus. Single-image DFD is underexplored due to its inherent challenges. Few attempts have focused on depth-from-defocus (DFD) from a single defocused image because the problem is underconstrained. Our method uses the relationship between local defocus blur and contrast variations as depth cues to improve scene structure estimation. The pipeline is trained end-to-end with adversarial learning. Experiments on real data demonstrate that incorporating the dark channel prior into single-image DFD provides meaningful depth estimation, validating our approach.",
      "authors": [
        "Moushumi Medhi and Rajiv Ranjan Sahay"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06643",
        "HTML": "https://arxiv.org/html/2506.06643",
        "PDF": "https://arxiv.org/pdf/2506.06643"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 07 Jun 2025 03:49:26 GMT",
          "size": "3524kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:28:35 GMT",
          "size": "3525kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Dark Channel-Assisted Depth-from-Defocus from a Single Image",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for single image depth estimation using dark channel prior, which is unrelated to the data processing or engineering stage for LLMs."
      }
    },
    {
      "id": "2506.07368",
      "abstract": "For the immanent challenge of insufficiently annotated samples in the medical field, semi-supervised medical image segmentation (SSMIS) offers a promising solution. Despite achieving impressive results in delineating primary target areas, most current methodologies struggle to precisely capture the subtle details of boundaries. This deficiency often leads to significant diagnostic inaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised segmentation model that synergistically integrates complementary competition and contrastive selection. This design significantly sharpens boundary delineation and enhances overall precision. Specifically, we develop an Outcome-Driven Contrastive Learning module dedicated to refining boundary localization. Additionally, we incorporate a Dynamic Complementary Competition module that leverages two high-performing sub-networks to generate pseudo-labels, thereby further improving segmentation quality. The proposed C3S3 undergoes rigorous validation on two publicly accessible datasets, encompassing the practices of both MRI and CT scans. The results demonstrate that our method achieves superior performance compared to previous cutting-edge competitors. Especially, on the 95HD and ASD metrics, our approach achieves a notable improvement of at least 6%, highlighting the significant advancements. The code is available at https://github.com/Y-TARL/C3S3.",
      "authors": [
        "Jiaying He and Yitong Lin and Jiahe Chen and Honghui Xu and Jianwei Zheng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07368",
        "HTML": "https://arxiv.org/html/2506.07368",
        "PDF": "https://arxiv.org/pdf/2506.07368"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 02:34:19 GMT",
          "size": "6917kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 05:23:29 GMT",
          "size": "2893kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a model for semi-supervised medical image segmentation. It does not discuss large language model training data processing or engineering."
      }
    },
    {
      "id": "2506.07729",
      "abstract": "In this paper we show error bounds for randomly subsampled rank-1 lattices. We pay particular attention to the ratio of the size of the subset to the size of the initial lattice, which is decisive for the computational complexity. In the special case of Korobov spaces, we achieve the optimal polynomial sampling complexity whilst having the smallest initial lattice possible. We further characterize the frequency index set for which a given lattice is reconstructing by using the reciprocal of the worst-case error achieved using the lattice in question. This connects existing approaches used in proving error bounds for lattices. We make detailed comments on the implementation and test different algorithms using the subsampled lattice in numerical experiments.",
      "authors": [
        "Felix Bartel and Alexander D. Gilbert and Frances Y. Kuo and Ian H. Sloan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07729",
        "HTML": "https://arxiv.org/html/2506.07729",
        "PDF": "https://arxiv.org/pdf/2506.07729"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 13:12:04 GMT",
          "size": "97kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:59:20 GMT",
          "size": "98kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Minimal Subsampled Rank-1 Lattices for Multivariate Approximation with Optimal Convergence Rate",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered around error bounds for subsampled rank-1 lattices and does not relate to the preparation or processing of training data for LLMs."
      }
    },
    {
      "id": "2506.07744",
      "abstract": "Existing offline hierarchical reinforcement learning methods rely on high-level policy learning to generate subgoal sequences. However, their efficiency degrades as task horizons increase, and they lack effective strategies for stitching useful state transitions across different trajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that formulates subgoal selection as a graph search problem rather than learning an explicit high-level policy. By embedding states into a Temporal Distance Representation (TDR) space, GAS clusters semantically similar states from different trajectories into unified graph nodes, enabling efficient transition stitching. A shortest-path algorithm is then applied to select subgoal sequences within the graph, while a low-level policy learns to reach the subgoals. To improve graph quality, we introduce the Temporal Efficiency (TE) metric, which filters out noisy or inefficient transition states, significantly enhancing task performance. GAS outperforms prior offline HRL methods across locomotion, navigation, and manipulation tasks. Notably, in the most stitching-critical task, it achieves a score of 88.3, dramatically surpassing the previous state-of-the-art score of 1.0. Our source code is available at: https://github.com/qortmdgh4141/GAS.",
      "authors": [
        "Seungho Baek",
        "Taegeon Park",
        "Jongchan Park",
        "Seungjun Oh",
        "Yusung Kim"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07744",
        "HTML": "https://arxiv.org/html/2506.07744",
        "PDF": "https://arxiv.org/pdf/2506.07744"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 13:26:23 GMT",
          "size": "1415kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:33:47 GMT",
          "size": "1415kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on hierarchical reinforcement learning and does not mention any aspect related to LLM training data processing."
      },
      "tasks": [
        "Hierarchical Reinforcement Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/qortmdgh4141/gas"
      ]
    },
    {
      "id": "2506.08036",
      "abstract": "This paper revisits Followerstopper, a phase-space-based control system that had demonstrated its ability to mitigate emergent traffic jams due to stop-and-go traffic during rush hour in the mixed-autonomy setting. Followerstopper was deployed on an autonomous vehicle. The controller attenuates the emanant traffic waves by regulating its velocity according to the relative distance and velocity of the leader car. While regulating the velocity, the controller also prevents the collision of the ego vehicle with the lead vehicle within the range specified by the controller's design parameter. The controller design is based on a configurable quadratic curve on relative distance-relative velocity phase-space that allows the transition of the regulated velocity from (i) no modification of input, (ii) decelerating to match the leader's velocity (iii) braking to avoid any imminent collision. In this paper, we explore the phase-space properties of Followerstopper and provide a detailed description of a nonlinear control law that regulates the reference input to Followerstopper within the physics-informed boundaries. We also provide a new discussion on the nominal control law that regulates the reference speed to Followerstopper to avoid unrealistic and unsafe acceleration.",
      "authors": [
        "Rahul Bhadani"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08036",
        "HTML": "https://arxiv.org/html/2506.08036",
        "PDF": "https://arxiv.org/pdf/2506.08036"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Chaotic Dynamics (nlin.CD)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 03 Jun 2025 23:07:42 GMT",
          "size": "1875kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 21:34:18 GMT",
          "size": "1843kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Followerstopper Revisited: Phase-space Lagrangian Controller for Traffic Decongestion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered around a control system for traffic decongestion and does not address LLM training data collection or processing."
      },
      "tasks": []
    },
    {
      "id": "2506.09229",
      "abstract": "Fine-tuning Video Diffusion Models (VDMs) at the user level to generate videos that reflect specific attributes of training data presents notable challenges, yet remains underexplored despite its practical importance. Meanwhile, recent work such as Representation Alignment (REPA) has shown promise in improving the convergence and quality of DiT-based image diffusion models by aligning, or assimilating, its internal hidden states with external pretrained visual features, suggesting its potential for VDM fine-tuning. In this work, we first propose a straightforward adaptation of REPA for VDMs and empirically show that, while effective for convergence, it is suboptimal in preserving semantic consistency across frames. To address this limitation, we introduce Cross-frame Representation Alignment (CREPA), a novel regularization technique that aligns hidden states of a frame with external features from neighboring frames. Empirical evaluations on large-scale VDMs, including CogVideoX-5B and Hunyuan Video, demonstrate that CREPA improves both visual fidelity and cross-frame semantic coherence when fine-tuned with parameter-efficient methods such as LoRA. We further validate CREPA across diverse datasets with varying attributes, confirming its broad applicability.",
      "authors": [
        "Sungwon Hwang",
        "Hyojin Jang",
        "Kinam Kim",
        "Minho Park",
        "Jaegul Choo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09229",
        "HTML": "https://arxiv.org/html/2506.09229",
        "PDF": "https://arxiv.org/pdf/2506.09229"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Jun 2025 20:34:47 GMT",
          "size": "28480kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:46:16 GMT",
          "size": "28480kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Cross-Frame Representation Alignment for Fine-Tuning Video Diffusion Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on fine-tuning video diffusion models and does not relate to any processing of training data for LLMs."
      }
    },
    {
      "id": "2506.10304",
      "abstract": "This paper argues that AI alignment is not merely difficult, but is founded on a fundamental logical contradiction. We first establish The Enumeration Paradox: we use machine learning precisely because we cannot enumerate all necessary safety rules, yet making ML safe requires examples that can only be generated from the very enumeration we admit is impossible. This paradox is then confirmed by a set of five independent mathematical proofs, or \"pillars of impossibility.\" Our main results show that: (1) Geometric Impossibility: The set of safe policies has measure zero, a necessary consequence of projecting infinite-dimensional world-context requirements onto finite-dimensional models. (2) Computational Impossibility: Verifying a policy's safety is coNP-complete, even for non-zero error tolerances. (3) Statistical Impossibility: The training data required for safety (abundant examples of rare disasters) is a logical contradiction and thus unobtainable. (4) Information-Theoretic Impossibility: Safety rules contain more incompressible, arbitrary information than any feasible network can store. (5) Dynamic Impossibility: The optimization process for increasing AI capability is actively hostile to safety, as the gradients for the two objectives are generally anti-aligned. Together, these results demonstrate that the pursuit of safe, highly capable AI is not a matter of overcoming technical hurdles, but of confronting fundamental, interlocking barriers. The paper concludes by presenting a strategic trilemma that these impossibilities force upon the field. A formal verification of the core theorems in Lean4 is currently in progress.",
      "authors": [
        "Jasper Yao"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10304",
        "HTML": "https://arxiv.org/html/2506.10304",
        "PDF": "https://arxiv.org/pdf/2506.10304"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computational Complexity (cs.CC)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 12 Jun 2025 02:30:30 GMT",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 23:41:11 GMT",
          "size": "35kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "The Alignment Trap: Complexity Barriers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses AI alignment and the theoretical challenges associated with safety, without discussing the processing of training data for LLMs."
      },
      "tasks": []
    },
    {
      "id": "2506.10521",
      "abstract": "Scientific discoveries increasingly rely on complex multimodal reasoning based on information-intensive scientific data and domain-specific expertise. Empowered by expert-level scientific benchmarks, scientific Multimodal Large Language Models (MLLMs) hold the potential to significantly enhance this discovery process in realistic workflows. However, current scientific benchmarks mostly focus on evaluating the knowledge understanding capabilities of MLLMs, leading to an inadequate assessment of their perception and reasoning abilities. To address this gap, we present the Scientists' First Exam (SFE) benchmark, designed to evaluate the scientific cognitive capacities of MLLMs through three interconnected levels: scientific signal perception, scientific attribute understanding, scientific comparative reasoning. Specifically, SFE comprises 830 expert-verified VQA pairs across three question types, spanning 66 multimodal tasks across five high-value disciplines. Extensive experiments reveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08% and 26.52% on SFE, highlighting significant room for MLLMs to improve in scientific realms. We hope the insights obtained in SFE will facilitate further developments in AI-enhanced scientific discoveries.",
      "authors": [
        "Yuhao Zhou",
        "Yiheng Wang",
        "Xuming He",
        "Ruoyao Xiao",
        "Zhiwei Li",
        "Qiantai Feng",
        "Zijie Guo",
        "Yuejin Yang",
        "Hao Wu",
        "Wenxuan Huang",
        "Jiaqi Wei",
        "Dan Si",
        "Xiuqi Yao",
        "Jia Bu",
        "Haiwen Huang",
        "Tianfan Fu",
        "Shixiang Tang",
        "Ben Fei",
        "Dongzhan Zhou",
        "Fenghua Ling",
        "Yan Lu",
        "Siqi Sun",
        "Chenhui Li",
        "Guanjie Zheng",
        "Jiancheng Lv",
        "Wenlong Zhang",
        "Lei Bai"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10521",
        "HTML": "https://arxiv.org/html/2506.10521",
        "PDF": "https://arxiv.org/pdf/2506.10521"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 12 Jun 2025 09:29:16 GMT",
          "size": "14986kb",
          "version": "v1"
        },
        {
          "date": "Fri, 13 Jun 2025 02:32:48 GMT",
          "size": "14986kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 14:13:38 GMT",
          "size": "14986kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating the cognitive abilities of MLLMs using a new benchmark and does not discuss the processing or preparation of training data for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "PrismaX/SFE",
          "downloads": "1293",
          "likes": "9",
          "link": "https://huggingface.co/datasets/PrismaX/SFE"
        }
      ],
      "tasks": [
        "Attribute",
        "Multimodal Reasoning",
        "Visual Question Answering (VQA)"
      ]
    },
    {
      "id": "2506.10978",
      "abstract": "Recent guidance methods in diffusion models steer reverse sampling by perturbing the model to construct an implicit weak model and guide generation away from it. Among these approaches, attention perturbation has demonstrated strong empirical performance in unconditional scenarios where classifier-free guidance is not applicable. However, existing attention perturbation methods lack principled approaches for determining where perturbations should be applied, particularly in Diffusion Transformer (DiT) architectures where quality-relevant computations are distributed across layers. In this paper, we investigate the granularity of attention perturbations, ranging from the layer level down to individual attention heads, and discover that specific heads govern distinct visual concepts such as structure, style, and texture quality. Building on this insight, we propose \"HeadHunter\", a systematic framework for iteratively selecting attention heads that align with user-centric objectives, enabling fine-grained control over generation quality and visual attributes. In addition, we introduce SoftPAG, which linearly interpolates each selected head's attention map toward an identity matrix, providing a continuous knob to tune perturbation strength and suppress artifacts. Our approach not only mitigates the oversmoothing issues of existing layer-level perturbation but also enables targeted manipulation of specific visual styles through compositional head selection. We validate our method on modern large-scale DiT-based text-to-image models including Stable Diffusion 3 and FLUX.1, demonstrating superior performance in both general quality enhancement and style-specific guidance. Our work provides the first head-level analysis of attention perturbation in diffusion models, uncovering interpretable specialization within attention layers and enabling practical design of effective perturbation strategies.",
      "authors": [
        "Donghoon Ahn",
        "Jiwon Kang",
        "Sanghyun Lee",
        "Minjae Kim",
        "Jaewon Min",
        "Wooseok Jang",
        "Saungwu Lee",
        "Sayak Paul",
        "Susung Hong",
        "Seungryong Kim"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10978",
        "HTML": "https://arxiv.org/html/2506.10978",
        "PDF": "https://arxiv.org/pdf/2506.10978"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 12 Jun 2025 17:59:51 GMT",
          "size": "46697kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:37:46 GMT",
          "size": "48634kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fine-Grained Perturbation Guidance via Attention Head Selection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses attention perturbations in diffusion models, which is unrelated to any aspect of LLM training data processing or preparation."
      },
      "tasks": []
    },
    {
      "id": "2506.11727",
      "abstract": "This paper critically audits the search endpoint of YouTube's Data API (v3), a common tool for academic research. Through systematic weekly searches over six months using eleven queries, we identify major limitations regarding completeness, representativeness, consistency, and bias. Our findings reveal substantial differences between ranking parameters like relevance and date in terms of video recall and precision, with relevance often retrieving numerous off-topic videos. We also find severe temporal decay, as the number of findable videos for a specific period dramatically decreases after just 20-60 days from the publication date, potentially hampering many different research designs. Furthermore, search results lack consistency, with identical queries yielding different video sets over time, compromising replicability. A case study on the European Parliament elections highlights how these issues impact research outcomes. While the paper offers several mitigation strategies, it concludes that the API's search function, potentially prioritizing \"freshness\" over comprehensive retrieval, is not adequate for robust academic research, especially concerning Digital Services Act requirements.",
      "authors": [
        "Bernhard Rieder",
        "Adrian Padilla and Oscar Coromina"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11727",
        "HTML": "https://arxiv.org/html/2506.11727",
        "PDF": "https://arxiv.org/pdf/2506.11727"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Human-Computer Interaction (cs.HC)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Jun 2025 12:39:59 GMT",
          "size": "1231kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:06:24 GMT",
          "size": "860kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Forgetful by Design? A Critical Audit of YouTube's Search API for Academic Research",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper audits YouTube's search API and does not focus on data processing for training LLMs."
      },
      "tasks": []
    },
    {
      "id": "2506.13087",
      "abstract": "Solving Inverse Kinematics (IK) problems is fundamental to robotics, but has primarily been successful with single serial manipulators. For multi-arm robotic systems, IK remains challenging due to complex self-collisions, coupled joints, and high-dimensional redundancy. These complexities make traditional IK solvers slow, prone to failure, and lacking in solution diversity. In this paper, we present IKDiffuser, a diffusion-based model designed for fast and diverse IK solution generation for multi-arm robotic systems. IKDiffuser learns the joint distribution over the configuration space, capturing complex dependencies and enabling seamless generalization to multi-arm robotic systems of different structures. In addition, IKDiffuser can incorporate additional objectives during inference without retraining, offering versatility and adaptability for task-specific requirements. In experiments on 6 different multi-arm systems, the proposed IKDiffuser achieves superior solution accuracy, precision, diversity, and computational efficiency compared to existing solvers. The proposed IKDiffuser framework offers a scalable, unified approach to solving multi-arm IK problems, facilitating the potential of multi-arm robotic systems in real-time manipulation tasks.",
      "authors": [
        "Zeyu Zhang",
        "Ziyuan Jiao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13087",
        "HTML": "https://arxiv.org/html/2506.13087",
        "PDF": "https://arxiv.org/pdf/2506.13087"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 04:12:04 GMT",
          "size": "13992kb",
          "version": "v1"
        },
        {
          "date": "Tue, 17 Jun 2025 08:43:30 GMT",
          "size": "13992kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 07:27:44 GMT",
          "size": "13992kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "IKDiffuser: A Generative Inverse Kinematics Solver for Multi-arm Robots via Diffusion Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses the challenge of solving inverse kinematics in multi-arm robotic systems using a diffusion-based model, without any discussion of LLM training data processing or engineering."
      },
      "tasks": [
        "Computational Efficiency",
        "Diversity"
      ]
    },
    {
      "id": "2506.13801",
      "abstract": "In these notes we propose a new, simpler proof system for first-order matching logic with application and definedness. The new proof system is inspired by Tarski's axiomatization for first order-logic with equality (simplified by Kalish and Montague), that does not involve the notions of a free variable and free substitution. We give also a proof system for first-order matching logic with application, obtained by adapting to matching logic G\\\"{o}del's proof system for first-order intuitionistic logic.",
      "authors": [
        "Lauren\\c{t}iu Leu\\c{s}tean and Dafina Trufa\\c{s}"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13801",
        "HTML": "https://arxiv.org/html/2506.13801",
        "PDF": "https://arxiv.org/pdf/2506.13801"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Jun 2025 11:09:36 GMT",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "Wed, 18 Jun 2025 16:04:44 GMT",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 07:08:49 GMT",
          "size": "51kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Matching logic -- a new axiomatization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a new proof system for first-order matching logic and does not relate to data processing for large language models."
      }
    },
    {
      "id": "2506.13997",
      "abstract": "We present an extension of Feng and Porter's 2019 paper on the use of the level-set method for the construction of a filtered simplicial complex from geospatial election data. Precincts are regarded to be too small to be gerrymandered, allowing us to identify discrepancies between precinct and district level voting data to quantify gerrymandering in the United States. Comparing the persistent homologies of Democratic voting areas on the precinct and district level shows when areas have been 'cracked' or 'packed' for partisan gain. This analysis was done for North Carolina House of Representatives elections (2012 to 2024). North Carolina has been redistricted 4 times in the past 10 years, whereas most states redistrict decennially, allowing us to understand how and when redistricted maps deviate from precinct-level voting data, and when gerrymandering occurs. Comparing persistence barcodes at the precinct and district levels (using the bottleneck distance) shows that precinct-level voting patterns do not significantly fluctuate biannually, while district level patterns do, suggesting that shifts are likely a result of redistricting rather than voter behavior, providing strong evidence of gerrymandering. North Carolina election data was collected from the public domain. Composite shapefiles were created using QGIS and R, and rasterized using Python. The level-set method was employed to generate filtered simplicial complexes. Persistence barcodes were produced using GUDHI and PHAT libraries. Additionally, we compare our results with traditional measures such as Polsby-Popper and Reock scores (gerrymandering identification measures). This research presents a novel application of topological data analysis in evaluating gerrymandering.",
      "authors": [
        "Ananya Shah"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13997",
        "HTML": "https://arxiv.org/html/2506.13997",
        "PDF": "https://arxiv.org/pdf/2506.13997"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 10 May 2025 19:52:00 GMT",
          "size": "5574kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 23:54:43 GMT",
          "size": "2747kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A Comparison of Precinct and District Voting Data Using Persistent Homology to Identify Gerrymandering in North Carolina",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on using geospatial election data to identify gerrymandering in North Carolina through topological data analysis, without discussing aspects of training data processing for LLMs."
      }
    },
    {
      "id": "2506.14922",
      "abstract": "The rapid advancement of large language models (LLMs) introduces dual-use capabilities that could both threaten and bolster national security and public safety (NSPS). Models implement safeguards to protect against potential misuse relevant to NSPS and allow for benign users to receive helpful information. However, current benchmarks often fail to test safeguard robustness to potential NSPS risks in an objective, robust way. We introduce FORTRESS: 500 expert-crafted adversarial prompts with instance-based rubrics of 4-7 binary questions for automated evaluation across 3 domains (unclassified information only): Chemical, Biological, Radiological, Nuclear and Explosive (CBRNE), Political Violence & Terrorism, and Criminal & Financial Illicit Activities, with 10 total subcategories across these domains. Each prompt-rubric pair has a corresponding benign version to test for model over-refusals. This evaluation of frontier LLMs' safeguard robustness reveals varying trade-offs between potential risks and model usefulness: Claude-3.5-Sonnet demonstrates a low average risk score (ARS) (14.09 out of 100) but the highest over-refusal score (ORS) (21.8 out of 100), while Gemini 2.5 Pro shows low over-refusal (1.4) but a high average potential risk (66.29). Deepseek-R1 has the highest ARS at 78.05, but the lowest ORS at only 0.06. Models such as o1 display a more even trade-off between potential risks and over-refusals (with an ARS of 21.69 and ORS of 5.2). To provide policymakers and researchers with a clear understanding of models' potential risks, we publicly release FORTRESS at https://huggingface.co/datasets/ScaleAI/fortress_public. We also maintain a private set for evaluation.",
      "authors": [
        "Christina Q. Knight",
        "Kaustubh Deshpande",
        "Ved Sirdeshmukh",
        "Meher Mankikar",
        "Scale Red Team",
        "SEAL Research Team",
        "and Julian Michael"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14922",
        "HTML": "https://arxiv.org/html/2506.14922",
        "PDF": "https://arxiv.org/pdf/2506.14922"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 19:08:02 GMT",
          "size": "3524kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 19:55:23 GMT",
          "size": "3499kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "FORTRESS: Frontier Risk Evaluation for National Security and Public Safety",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces FORTRESS, a set of adversarial prompts for evaluating safeguard robustness in LLMs, which is related more to evaluation rather than the processing or engineering of training data."
      },
      "datasets": [
        {
          "dataset_name": "ScaleAI/fortress_public",
          "downloads": "135",
          "likes": "1",
          "link": "https://huggingface.co/datasets/ScaleAI/fortress_public"
        }
      ],
      "tasks": []
    },
    {
      "id": "2506.15176",
      "abstract": "In recent years, deep learning has facilitated the creation of wireless receivers capable of functioning effectively in conditions that challenge traditional model-based designs. Leveraging programmable hardware architectures, deep learning-based receivers offer the potential to dynamically adapt to varying channel environments. However, current adaptation strategies, including joint training, hypernetwork-based methods, and meta-learning, either demonstrate limited flexibility or necessitate explicit optimization through gradient descent. This paper presents gradient-free adaptation techniques rooted in the emerging paradigm of in-context learning (ICL). We review architectural frameworks for ICL based on Transformer models and structured state-space models (SSMs), alongside theoretical insights into how sequence models effectively learn adaptation from contextual information. Further, we explore the application of ICL to cell-free massive MIMO networks, providing both theoretical analyses and empirical evidence. Our findings indicate that ICL represents a principled and efficient approach to real-time receiver adaptation using pilot signals and auxiliary contextual information-without requiring online retraining.",
      "authors": [
        "Matteo Zecchin",
        "Tomer Raviv",
        "Dileep Kalathil",
        "Krishna Narayanan",
        "Nir Shlezinger",
        "and Osvaldo Simeone"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15176",
        "HTML": "https://arxiv.org/html/2506.15176",
        "PDF": "https://arxiv.org/pdf/2506.15176"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Jun 2025 06:43:55 GMT",
          "size": "2174kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:30:14 GMT",
          "size": "2175kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "In-Context Learning for Gradient-Free Receiver Adaptation: Principles, Applications, and Theory",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on in-context learning for wireless receivers, utilizing deep learning for adaptive strategies without addressing any LLM training data processing or engineering aspects."
      },
      "tasks": [
        "In-Context Learning",
        "Meta-Learning",
        "State Space Models"
      ]
    },
    {
      "id": "2506.15549",
      "abstract": "Deep learning-based myocardial scar segmentation from late gadolinium enhancement (LGE) cardiac MRI has shown great potential for accurate and timely diagnosis and treatment planning for structural cardiac diseases. However, the limited availability and variability of LGE images with high-quality scar labels restrict the development of robust segmentation models. To address this, we introduce CLAIM: \\textbf{C}linically-Guided \\textbf{L}GE \\textbf{A}ugmentation for Real\\textbf{i}stic and Diverse \\textbf{M}yocardial Scar Synthesis and Segmentation framework, a framework for anatomically grounded scar generation and segmentation. At its core is the SMILE module (Scar Mask generation guided by cLinical knowledgE), which conditions a diffusion-based generator on the clinically adopted AHA 17-segment model to synthesize images with anatomically consistent and spatially diverse scar patterns. In addition, CLAIM employs a joint training strategy in which the scar segmentation network is optimized alongside the generator, aiming to enhance both the realism of synthesized scars and the accuracy of the scar segmentation performance. Experimental results show that CLAIM produces anatomically coherent scar patterns and achieves higher Dice similarity with real scar distributions compared to baseline models. Our approach enables controllable and realistic myocardial scar synthesis and has demonstrated utility for downstream medical imaging task. Code is available at https://github.com/farheenjabeen/CLAIM-Scar-Synthesis.",
      "authors": [
        "Farheen Ramzan",
        "Yusuf Kiberu",
        "Nikesh Jathanna",
        "Shahnaz Jamil-Copley",
        "Richard H. Clayton",
        "Chen Chen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15549",
        "HTML": "https://arxiv.org/html/2506.15549",
        "PDF": "https://arxiv.org/pdf/2506.15549"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Jun 2025 15:21:34 GMT",
          "size": "1180kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:37:57 GMT",
          "size": "985kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes CLAIM framework for myocardial scar synthesis and segmentation, a deep learning application specific to medical imaging, which does not involve LLM training data engineering or processing."
      },
      "tasks": [
        "Clinical Knowledge",
        "Segmentation"
      ]
    },
    {
      "id": "2506.15595",
      "abstract": "Although multi-GPU execution has become the de-facto paradigm for training and serving large language models (LLMs), today's schedulers still rely on a simple heuristic: pick GPUs that are physically close. This proximity rule was adequate for small, uniform clusters, but it breaks down in modern fabrics where link capacities differ by up to an order of magnitude across PCIe, NVLink, and CXL tiers. Consequently, jobs placed by locality alone often suffer from severe bandwidth imbalance and unpredictable performance. In this paper, We present LiteGD, a lightweight, globally-aware GPU dispatching system that delivers near-optimal bandwidth without incurring prohibitive state or search overheads. Instead of materializing the full O(N^2) connectivity matrix, LiteGD encodes the fabric with a sparsified Tiny-Transformer trained on a few thousand random bandwidth probes, enabling fast adaptation to incremental hardware changes. LiteGD also employs a bidirectional tree search approach to find the optimal GPU dispatching in the data generated in the previous step, which can identify near-optimal solutions while reducing search overhead. We implement and evaluate LiteGD in both real and simulated GPU clusters with homogeneous and heterogeneous interconnects, respectively. Experimental results demonstrate that LiteGD consistently achieves high GPU Bandwidth Efficacy, approximately 90% across various cluster configurations and 80% in a real-world H100 cluster, significantly outperforming conventional default and interconnect topology-aware dispatching methods, particularly in large-scale heterogeneous environments.",
      "authors": [
        "Kunming Zhang",
        "Hanlong Liao",
        "Guoming Tang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15595",
        "HTML": "https://arxiv.org/html/2506.15595",
        "PDF": "https://arxiv.org/pdf/2506.15595"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Jun 2025 16:10:17 GMT",
          "size": "781kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:27:45 GMT",
          "size": "977kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LiteGD: Lightweight and Dynamic GPU Dispatching for Large-scale Heterogeneous Clusters",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a GPU dispatching system for optimizing bandwidth in large-scale computing environments and does not address any aspect of LLM training data processing."
      }
    },
    {
      "id": "2506.16014",
      "abstract": "We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.",
      "authors": [
        "Jina Kim",
        "Youjin Jang",
        "Jeongjin Han"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16014",
        "HTML": "https://arxiv.org/html/2506.16014",
        "PDF": "https://arxiv.org/pdf/2506.16014"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 04:21:23 GMT",
          "size": "527kb",
          "version": "v1"
        },
        {
          "date": "Mon, 23 Jun 2025 02:33:03 GMT",
          "size": "527kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 15:06:17 GMT",
          "size": "527kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "VRAIL: Vectorized Reward-based Attribution for Interpretable Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a framework for reinforcement learning interpretability and does not address LLM training data processing or any related tasks."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ]
    },
    {
      "id": "2506.16791",
      "abstract": "With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at https://tabarena.ai.",
      "authors": [
        "Nick Erickson and Lennart Purucker and Andrej Tschalzev and David Holzm\\\"uller and Prateek Mutalik Desai and David Salinas and Frank Hutter"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16791",
        "HTML": "https://arxiv.org/html/2506.16791",
        "PDF": "https://arxiv.org/pdf/2506.16791"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 07:14:48 GMT",
          "size": "3129kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:14:44 GMT",
          "size": "3129kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a benchmarking system for tabular data and does not focus on LLM training data processing or data engineering."
      },
      "tasks": [
        "Benchmarking"
      ]
    },
    {
      "id": "2506.17253",
      "abstract": "Long-term time series prediction has predominantly relied on Transformer and MLP models, while the potential of convolutional networks in this domain remains underexplored. To address this gap, we introduce a novel multi-scale time series reshape module, which effectively captures the relationships among multi-period patches and variable dependencies. Building upon this module, we propose MS-TVNet, a multi-scale 3D dynamic convolutional neural network. Through comprehensive evaluations on diverse datasets, MS-TVNet demonstrates superior performance compared to baseline models, achieving state-of-the-art (SOTA) results in long-term time series prediction. Our findings highlight the effectiveness of leveraging convolutional networks for capturing complex temporal patterns, suggesting a promising direction for future research in this field.The code is realsed on https://github.com/Curyyfaust/TVNet.",
      "authors": [
        "Chenghan Li",
        "Mingchen Li",
        "Yipu Liao",
        "Ruisheng Diao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17253",
        "HTML": "https://arxiv.org/html/2506.17253",
        "PDF": "https://arxiv.org/pdf/2506.17253"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 08 Jun 2025 10:33:39 GMT",
          "size": "1422kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:55:20 GMT",
          "size": "1417kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MS-TVNet:A Long-Term Time Series Prediction Method Based on Multi-Scale Dynamic Convolution",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on time series prediction using a novel multi-scale 3D dynamic convolutional neural network and does not address any aspects related to LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.17508",
      "abstract": "This paper presents KnoVo (Knowledge Evolution), an intelligent framework designed for quantifying and analyzing the evolution of research novelty in the scientific literature. Moving beyond traditional citation analysis, which primarily measures impact, KnoVo determines a paper's novelty relative to both prior and subsequent work within its multilayered citation network. Given a target paper's abstract, KnoVo utilizes Large Language Models (LLMs) to dynamically extract dimensions of comparison (e.g., methodology, application, dataset). The target paper is then compared to related publications along these same extracted dimensions. This comparative analysis, inspired by tournament selection, yields quantitative novelty scores reflecting the relative improvement, equivalence, or inferiority of the target paper in specific aspects. By aggregating these scores and visualizing their progression, for instance, through dynamic evolution graphs and comparative radar charts, KnoVo facilitates researchers not only to assess originality and identify similar work, but also to track knowledge evolution along specific research dimensions, uncover research gaps, and explore cross-disciplinary connections. We demonstrate these capabilities through a detailed analysis of 20 diverse papers from multiple scientific fields and report on the performance of various open-source LLMs within the KnoVo framework.",
      "authors": [
        "Sajratul Y. Rubaiat",
        "Syed N. Sakib",
        "Hasan M. Jamil"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17508",
        "HTML": "https://arxiv.org/html/2506.17508",
        "PDF": "https://arxiv.org/pdf/2506.17508"
      },
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)",
        "Emerging Technologies (cs.ET)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 23:17:11 GMT",
          "size": "2710kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:22:45 GMT",
          "size": "2710kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Mapping the Evolution of Research Contributions using KnoVo",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents KnoVo, a framework for analyzing research novelty using LLMs but does not directly address any aspect of LLM training data processing."
      }
    },
    {
      "id": "2506.17757",
      "abstract": "We study the problem of maintaining robust and sparse overlay networks in fully distributed settings where nodes continuously join and leave the system. This scenario closely models real-world unstructured peer-to-peer networks, where maintaining a well-connected yet low-degree communication graph is crucial. We generalize a recent protocol by Becchetti et al. [SODA 2020] that relies on a simple randomized connection strategy to build an expander topology with high probability to a dynamic networks with churn setting. In this work, the network dynamism is governed by an oblivious adversary that controls which nodes join and leave the system in each round. The adversary has full knowledge of the system and unbounded computational power, but cannot see the random choices made by the protocol. Our analysis builds on the framework of Augustine et al. [FOCS 2015], and shows that our distributed algorithm maintains a constant-degree expander graph with high probability, despite a continuous adversarial churn with a rate of up to $\\mathcal{O}(n/polylog(n))$ per round, where $n$ is the stable network size. The protocol and proof techniques are not new, but together they resolve a specific open problem raised in prior work. The result is a simple, fully distributed, and churn-resilient protocol with provable guarantees that align with observed empirical behavior.",
      "authors": [
        "Antonio Cruciani"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17757",
        "HTML": "https://arxiv.org/html/2506.17757",
        "PDF": "https://arxiv.org/pdf/2506.17757"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 16:33:54 GMT",
          "size": "10kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 18:40:50 GMT",
          "size": "10kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Maintaining a Bounded Degree Expander in Dynamic Peer-to-Peer Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on distributed network protocols and expander graph maintenance in peer-to-peer networks, with no mention of LLM training data processing or contributions related to data engineering for LLMs."
      }
    },
    {
      "id": "2506.17892",
      "abstract": "Conveyor belts are important equipment in modern industry, widely applied in production and manufacturing. Their health is much critical to operational efficiency and safety. Cracks are a major threat to belt health. Currently, considering safety, how to intelligently detect belt cracks is catching an increasing attention. To implement the intelligent detection with machine learning, real crack samples are believed to be necessary. However, existing crack datasets primarily focus on pavement scenarios or synthetic data, no real-world industrial belt crack datasets at all. Cracks are a major threat to belt health. Furthermore, to validate usability and effectiveness, we propose a special baseline method with triple-domain ($i.e.$, time-space-frequency) feature hierarchical fusion learning for the two whole-new datasets. Experimental results demonstrate the availability and effectiveness of our dataset. Besides, they also show that our baseline is obviously superior to other similar detection methods. Our datasets and source codes are available at https://github.com/UESTC-nnLab/BeltCrack.",
      "authors": [
        "Jianghong Huang",
        "Luping Ji",
        "Xin Ma",
        "Mao Ye"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17892",
        "HTML": "https://arxiv.org/html/2506.17892",
        "PDF": "https://arxiv.org/pdf/2506.17892"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 03:48:51 GMT",
          "size": "30955kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:44:04 GMT",
          "size": "30954kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "BeltCrack: the First Sequential-image Industrial Conveyor Belt Crack Detection Dataset and Its Baseline with Triple-domain Feature Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces an industrial conveyor belt crack dataset and a detection baseline, focusing on image datasets and feature learning rather than LLM training data processing."
      }
    },
    {
      "id": "2506.18165",
      "abstract": "Recently, there has been significant progress in learning-based diffusion samplers, which aim to sample from a given unnormalized density. These methods typically follow one of two paradigms: (i) formulating sampling as an unbiased stochastic optimal control (SOC) problem using a canonical reference process, or (ii) refining annealed path measures through importance-weighted sampling. Although annealing approaches have advantages in guiding samples toward high-density regions, reliance on importance sampling leads to high variance and limited scalability in practice. In this paper, we introduce the \\textbf{Non-equilibrium Annealed Adjoint Sampler (NAAS)}, a novel SOC-based diffusion sampler that leverages annealed reference dynamics without resorting to importance sampling. NAAS employs a lean adjoint system inspired by adjoint matching, enabling efficient and scalable training. We demonstrate the effectiveness of our approach across a range of tasks, including sampling from classical energy landscapes and molecular Boltzmann distribution.",
      "authors": [
        "Jaemoo Choi",
        "Yongxin Chen",
        "Molei Tao",
        "Guan-Horng Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18165",
        "HTML": "https://arxiv.org/html/2506.18165",
        "PDF": "https://arxiv.org/pdf/2506.18165"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 20:41:31 GMT",
          "size": "5351kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:39:40 GMT",
          "size": "5351kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Non-equilibrium Annealed Adjoint Sampler",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on introducing a novel diffusion sampler technique and applies it to sampling from energy landscapes and molecular distributions. It does not address any aspects of LLM training data processing or enhancement."
      }
    },
    {
      "id": "2506.18240",
      "abstract": "Here in this work, we present a novel Quadratic Binary Optimization (QBO) model for quantized neural network training, enabling the use of arbitrary activation and loss functions through spline interpolation. We introduce Forward Interval Propagation (FIP), a method designed to tackle the challenges of non-linearity and the multi-layer composite structure in neural networks by discretizing activation functions into linear subintervals. This approach preserves the universal approximation properties of neural networks while allowing complex nonlinear functions to be optimized using quantum computers, thus broadening their applicability in artificial intelligence. We provide theoretical upper bounds on the approximation error and the number of Ising spins required, by deriving the sample complexity of the empirical risk minimization problem, from an optimization perspective. A significant challenge in solving the associated Quadratic Constrained Binary Optimization (QCBO) model on a large scale is the presence of numerous constraints. When employing the penalty method to handle these constraints, tuning a large number of penalty coefficients becomes a critical hyperparameter optimization problem, increasing computational complexity and potentially affecting solution quality. To address this, we employ the Quantum Conditional Gradient Descent (QCGD) algorithm, which leverages quantum computing to directly solve the QCBO problem. We prove the convergence of QCGD under a quantum oracle with randomness and bounded variance in objective value, as well as under limited precision constraints in the coefficient matrix. Additionally, we provide an upper bound on the Time-To-Solution for the QCBO solving process. Experimental results using a coherent Ising machine (CIM) demonstrate a 94.95% accuracy on the Fashion MNIST classification task, with only 1.1-bit precision.",
      "authors": [
        "Wenxin Li",
        "Chuan Wang",
        "Hongdong Zhu",
        "Qi Gao",
        "Yin Ma",
        "Hai Wei",
        "Kai Wen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18240",
        "HTML": "https://arxiv.org/html/2506.18240",
        "PDF": "https://arxiv.org/pdf/2506.18240"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 02:12:36 GMT",
          "size": "10325kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 01:01:03 GMT",
          "size": "10371kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Quantum-Classical Hybrid Quantized Neural Network",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work presents a method for optimizing neural networks using quantum computing. It does not relate to any practices involving LLM training data engineering or processing tasks."
      },
      "tasks": [
        "Hyperparameter Optimization"
      ]
    },
    {
      "id": "2506.18251",
      "abstract": "In this paper, we present Morse, a simple dual-sampling framework for accelerating diffusion models losslessly. The key insight of Morse is to reformulate the iterative generation (from noise to data) process via taking advantage of fast jump sampling and adaptive residual feedback strategies. Specifically, Morse involves two models called Dash and Dot that interact with each other. The Dash model is just the pre-trained diffusion model of any type, but operates in a jump sampling regime, creating sufficient space for sampling efficiency improvement. The Dot model is significantly faster than the Dash model, which is learnt to generate residual feedback conditioned on the observations at the current jump sampling point on the trajectory of the Dash model, lifting the noise estimate to easily match the next-step estimate of the Dash model without jump sampling. By chaining the outputs of the Dash and Dot models run in a time-interleaved fashion, Morse exhibits the merit of flexibly attaining desired image generation performance while improving overall runtime efficiency. With our proposed weight sharing strategy between the Dash and Dot models, Morse is efficient for training and inference. Our method shows a lossless speedup of 1.78X to 3.31X on average over a wide range of sampling step budgets relative to 9 baseline diffusion models on 6 image generation tasks. Furthermore, we show that our method can be also generalized to improve the Latent Consistency Model (LCM-SDXL, which is already accelerated with consistency distillation technique) tailored for few-step text-to-image synthesis. The code and models are available at https://github.com/deep-optimization/Morse.",
      "authors": [
        "Chao Li",
        "Jiawei Fan",
        "Anbang Yao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18251",
        "HTML": "https://arxiv.org/html/2506.18251",
        "PDF": "https://arxiv.org/pdf/2506.18251"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 02:43:21 GMT",
          "size": "11779kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:25:37 GMT",
          "size": "11779kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces Morse, a framework for accelerating diffusion models, with the focus on image generation tasks. There is no mention of LLM training data processes."
      }
    },
    {
      "id": "2506.18439",
      "abstract": "In this paper, we study the problem of model-checking quantum pushdown systems from a computational complexity point of view. We arrive at the following equally important, interesting new results:\n  We first extend the notions of the {\\it probabilistic pushdown systems} and {\\it Markov chains} to their quantum analogues and investigate the question of whether it is necessary to define a quantum analogue of {\\it probabilistic computational tree logic} to describe the probabilistic and branching-time properties of the {\\it quantum Markov chain}. We study its model-checking question and show that model-checking of {\\it stateless quantum pushdown systems (qBPA)} against {\\it probabilistic computational tree logic (PCTL)} is generally undecidable, i.e., there exists no algorithm for model-checking {\\it stateless quantum pushdown systems} against {\\it probabilistic computational tree logic}.\n  We then study in which case there exists an algorithm for model-checking {\\it stateless quantum pushdown systems} and show that the problem of model-checking {\\it stateless quantum pushdown systems} against {\\it bounded probabilistic computational tree logic} (bPCTL) is decidable, and further show that this problem is in $NP$-complete. Our reduction is from the {\\it bounded Post Correspondence Problem} for the first time, a well-known $NP$-complete problem.",
      "authors": [
        "Deren Lin",
        "Tianrong Lin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18439",
        "HTML": "https://arxiv.org/html/2506.18439",
        "PDF": "https://arxiv.org/pdf/2506.18439"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 09:22:23 GMT",
          "size": "23kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:25:35 GMT",
          "size": "23kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Computational Complexity of Model-Checking Quantum Pushdown Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores computational complexity in model-checking for quantum systems and does not relate to LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.18671",
      "abstract": "Music-driven dance generation has garnered significant attention due to its wide range of industrial applications, particularly in the creation of group choreography. During the group dance generation process, however, most existing methods still face three primary issues: multi-dancer collisions, single-dancer foot sliding and abrupt swapping in the generation of long group dance. In this paper, we propose TCDiff++, a music-driven end-to-end framework designed to generate harmonious group dance. Specifically, to mitigate multi-dancer collisions, we utilize a dancer positioning embedding to better maintain the relative positioning among dancers. Additionally, we incorporate a distance-consistency loss to ensure that inter-dancer distances remain within plausible ranges. To address the issue of single-dancer foot sliding, we introduce a swap mode embedding to indicate dancer swapping patterns and design a Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For long group dance generation, we present a long group diffusion sampling strategy that reduces abrupt position shifts by injecting positional information into the noisy input. Furthermore, we integrate a Sequence Decoder layer to enhance the model's ability to selectively process long sequences. Extensive experiments demonstrate that our TCDiff++ achieves state-of-the-art performance, particularly in long-duration scenarios, ensuring high-quality and coherent group dance generation.",
      "authors": [
        "Yuqin Dai",
        "Wanlu Zhu",
        "Ronghui Li",
        "Xiu Li",
        "Zhenyu Zhang",
        "Jun Li",
        "Jian Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18671",
        "HTML": "https://arxiv.org/html/2506.18671",
        "PDF": "https://arxiv.org/pdf/2506.18671"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 14:15:20 GMT",
          "size": "3053kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:19:44 GMT",
          "size": "3053kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on music-driven dance generation, which involves creating choreography with a diffusion model. There is no mention of LLM training data processing or related data engineering tasks."
      }
    },
    {
      "id": "2506.18847",
      "abstract": "Offline Goal-Conditioned Reinforcement Learning seeks to train agents to reach specified goals from previously collected trajectories. Scaling that promises to long-horizon tasks remains challenging, notably due to compounding value-estimation errors. Principled geometric offers a potential solution to address these issues. Following this insight, we introduce Projective Quasimetric Planning (ProQ), a compositional framework that learns an asymmetric distance and then repurposes it, firstly as a repulsive energy forcing a sparse set of keypoints to uniformly spread over the learned latent space, and secondly as a structured directional cost guiding towards proximal sub-goals. In particular, ProQ couples this geometry with a Lagrangian out-of-distribution detector to ensure the learned keypoints stay within reachable areas. By unifying metric learning, keypoint coverage, and goal-conditioned control, our approach produces meaningful sub-goals and robustly drives long-horizon goal-reaching on diverse a navigation benchmarks.",
      "authors": [
        "Anthony Kobanda",
        "Waris Radji",
        "Mathieu Petitbois",
        "Odalric-Ambrym Maillard",
        "R\\'emy Portelas"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18847",
        "HTML": "https://arxiv.org/html/2506.18847",
        "PDF": "https://arxiv.org/pdf/2506.18847"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 17:07:20 GMT",
          "size": "2374kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:37:00 GMT",
          "size": "2374kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Offline Goal-Conditioned Reinforcement Learning with Projective Quasimetric Planning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered on offline goal-conditioned reinforcement learning and trajectory planning using projective quasimetric planning without addressing LLM training data collection or processing."
      }
    },
    {
      "id": "2506.18921",
      "abstract": "We propose the Transcendental Encoding Conjecture for decision problems, which asserts that every language in complexity class P encodes to an algebraic real (possibly rational or algebraic irrational) under its binary characteristic encoding or other relevant encodings, whereas every NP-complete language encodes to a transcendental real. In particular, we exhibit languages whose encodings are provably rational (hence algebraic), discuss the status of encodings for other \"natural\" languages such as PRIMES (its encoding is irrational but not known to be algebraic).",
      "authors": [
        "Anand Kumar Keshavan and Sunu Engineer"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18921",
        "HTML": "https://arxiv.org/html/2506.18921",
        "PDF": "https://arxiv.org/pdf/2506.18921"
      },
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 14:30:08 GMT",
          "size": "14kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:25:50 GMT",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Transcendental Encoding conjecture",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with encoding conjectures for decision problems in complexity theory and does not address any aspect of LLM training data processing or engineering."
      }
    },
    {
      "id": "2506.18960",
      "abstract": "Handling delicate and fragile objects remains a major challenge for robotic manipulation, especially for rigid parallel grippers. While the simplicity and versatility of parallel grippers have led to widespread adoption, these grippers are limited by their heavy reliance on visual feedback. Tactile sensing and soft robotics can add responsiveness and compliance. However, existing methods typically involve high integration complexity or suffer from slow response times. In this work, we introduce FORTE, a tactile sensing system embedded in compliant gripper fingers. FORTE uses 3D-printed fin-ray grippers with internal air channels to provide low-latency force and slip feedback. FORTE applies just enough force to grasp objects without damaging them, while remaining easy to fabricate and integrate. We find that FORTE can accurately estimate grasping forces from 0-8 N with an average error of 0.2 N, and detect slip events within 100 ms of occurring. We demonstrate FORTE's ability to grasp a wide range of slippery, fragile, and deformable objects. In particular, FORTE grasps fragile objects like raspberries and potato chips with a 98.6% success rate, and achieves 93% accuracy in detecting slip events. These results highlight FORTE's potential as a robust and practical solution for enabling delicate robotic manipulation. Project page: https://merge-lab.github.io/FORTE",
      "authors": [
        "Siqi Shang",
        "Mingyo Seo",
        "Yuke Zhu",
        "and Lillian Chin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18960",
        "HTML": "https://arxiv.org/html/2506.18960",
        "PDF": "https://arxiv.org/pdf/2506.18960"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 17:50:58 GMT",
          "size": "4463kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:23:43 GMT",
          "size": "4463kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "FORTE: Tactile Force and Slip Sensing on Compliant Fingers for Delicate Manipulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on tactile force and slip sensing for robotic manipulation and does not involve LLM training data collection or processing."
      }
    },
    {
      "id": "2506.19028",
      "abstract": "Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo(Fine-grained Semantic Computation), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSco more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.",
      "authors": [
        "Weijie Xu",
        "Yiwen Wang",
        "Chi Xue",
        "Xiangkun Hu",
        "Xi Fang",
        "Guimin Dong",
        "Chandan K. Reddy"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19028",
        "HTML": "https://arxiv.org/html/2506.19028",
        "PDF": "https://arxiv.org/pdf/2506.19028"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 18:31:22 GMT",
          "size": "3359kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 01:21:47 GMT",
          "size": "1986kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper proposes a novel statistical framework for evaluating fairness in LLMs, it focuses on analysis and evaluation rather than on the collection or processing of training data."
      }
    },
    {
      "id": "2506.19118",
      "abstract": "Despite the notable success of current Parameter-Efficient Fine-Tuning (PEFT) methods across various domains, their effectiveness on medical datasets falls short of expectations. This limitation arises from two key factors: (1) medical images exhibit extensive anatomical variation and low contrast, necessitating a large receptive field to capture critical features, and (2) existing PEFT methods do not explicitly address the enhancement of receptive fields. To overcome these challenges, we propose the Large Kernel Adapter (LKA), designed to expand the receptive field while maintaining parameter efficiency. The proposed LKA consists of three key components: down-projection, channel-wise large kernel convolution, and up-projection. Through extensive experiments on various datasets and pre-trained models, we demonstrate that the incorporation of a larger kernel size is pivotal in enhancing the adaptation of pre-trained models for medical image analysis. Our proposed LKA outperforms 11 commonly used PEFT methods, surpassing the state-of-the-art by 3.5% in top-1 accuracy across five medical datasets.",
      "authors": [
        "Ziquan Zhu",
        "Si-Yuan Lu",
        "Tianjin Huang",
        "Lu Liu",
        "Zhe Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19118",
        "HTML": "https://arxiv.org/html/2506.19118",
        "PDF": "https://arxiv.org/pdf/2506.19118"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 20:47:33 GMT",
          "size": "613kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:46:10 GMT",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LKA: Large Kernel Adapter for Enhanced Medical Image Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered on enhancing medical image classification through a new model architecture, not on processing training data for LLMs."
      }
    },
    {
      "id": "2506.19143",
      "abstract": "Reasoning large language models have recently achieved state-of-the-art performance in many fields. However, their long-form chain-of-thought reasoning creates interpretability challenges as each generated token depends on all previous ones, making the computation harder to decompose. We argue that analyzing reasoning traces at the sentence level is a promising approach to understanding reasoning processes. We present three complementary attribution methods: (1) a black-box method measuring each sentence's counterfactual importance by comparing final answers across 100 rollouts conditioned on the model generating that sentence or one with a different meaning; (2) a white-box method of aggregating attention patterns between pairs of sentences, which identified \"broadcasting\" sentences that receive disproportionate attention from all future sentences via \"receiver\" attention heads; (3) a causal attribution method measuring logical connections between sentences by suppressing attention toward one sentence and measuring the effect on each future sentence's tokens. Each method provides evidence for the existence of thought anchors, reasoning steps that have outsized importance and that disproportionately influence the subsequent reasoning process. These thought anchors are typically planning or backtracking sentences. We provide an open-source tool (www.thought-anchors.com) for visualizing the outputs of our methods, and present a case study showing converging patterns across methods that map how a model performs multi-step reasoning. The consistency across methods demonstrates the potential of sentence-level analysis for a deeper understanding of reasoning models.",
      "authors": [
        "Paul C. Bogdan",
        "Uzay Macar",
        "Neel Nanda",
        "Arthur Conmy"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19143",
        "HTML": "https://arxiv.org/html/2506.19143",
        "PDF": "https://arxiv.org/pdf/2506.19143"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 21:28:45 GMT",
          "size": "20532kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 00:18:53 GMT",
          "size": "21284kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Thought Anchors: Which LLM Reasoning Steps Matter?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper concentrates on reasoning processes in LLMs, specifically analyzing reasoning steps and proposing methods for understanding interpretability. It does not address processing or engineering of LLM training data."
      },
      "datasets": [
        {
          "dataset_name": "uzaymacar/math-rollouts",
          "downloads": "0",
          "likes": "0",
          "link": "https://huggingface.co/datasets/uzaymacar/math-rollouts"
        }
      ]
    },
    {
      "id": "2506.19197",
      "abstract": "A unit ball graph consists of a set of vertices, labeled by points in Euclidean space, and edges joining all pairs of points within distance $1$. These geometric graphs are used to model a variety of spatial networks, including communication networks between agents in an autonomous swarm. In such an application, vertices and/or edges of the graph may not be perfectly reliable; an agent may experience failure or a communication link rendered inoperable. With the goal of designing robust swarm formations, or unit ball graphs with high reliability (probability of connectedness), in a preliminary conference paper we provided an algorithm with cubic time complexity to determine all possible changes to a unit ball graph by repositioning a single vertex. Using this algorithm and Monte Carlo simulations, one obtains an efficient method to modify a unit ball graph by moving a single vertex to a location which maximizes the reliability. Another important consideration in many swarm missions is area coverage, yet highly reliable ball graphs often contain clusters of vertices. Here, we generalize our previous algorithm to improve area coverage as well as reliability. Our algorithm determines a location to add or move a vertex within a unit ball graph which maximizes the reliability, under the constraint that no other vertices of the graph be within some fixed distance. We compare this method of obtaining graphs with high reliability and evenly distributed area coverage to another method which uses a modified Fruchterman-Reingold algorithm for ball graphs.",
      "authors": [
        "Calum Buchanan",
        "Puck Rombach",
        "James Bagrow",
        "and Hamid R. Ossareh"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19197",
        "HTML": "https://arxiv.org/html/2506.19197",
        "PDF": "https://arxiv.org/pdf/2506.19197"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Combinatorics (math.CO)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 23:52:48 GMT",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:58:57 GMT",
          "size": "51kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Vertex addition to a ball graph with application to reliability and area coverage in autonomous swarms",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on graph theory and reliability in autonomous swarm communications, without discussing LLM training data collection, construction, or processing."
      }
    },
    {
      "id": "2506.19269",
      "abstract": "We present AnchorDP3, a diffusion policy framework for dual-arm robotic manipulation that achieves state-of-the-art performance in highly randomized environments. AnchorDP3 integrates three key innovations: (1) Simulator-Supervised Semantic Segmentation, using rendered ground truth to explicitly segment task-critical objects within the point cloud, which provides strong affordance priors; (2) Task-Conditioned Feature Encoders, lightweight modules processing augmented point clouds per task, enabling efficient multi-task learning through a shared diffusion-based action expert; (3) Affordance-Anchored Keypose Diffusion with Full State Supervision, replacing dense trajectory prediction with sparse, geometrically meaningful action anchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored to affordances, drastically simplifying the prediction space; the action expert is forced to predict both robot joint angles and end-effector poses simultaneously, which exploits geometric consistency to accelerate convergence and boost accuracy. Trained on large-scale, procedurally generated simulation data, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmark across diverse tasks under extreme randomization of objects, clutter, table height, lighting, and backgrounds. This framework, when integrated with the RoboTwin real-to-sim pipeline, has the potential to enable fully autonomous generation of deployable visuomotor policies from only scene and instruction, totally eliminating human demonstrations from learning manipulation skills.",
      "authors": [
        "Ziyan Zhao and Ke Fan and He-Yang Xu and Ning Qiao and Bo Peng and Wenlong Gao and Dongjiang Li and Hui Shen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19269",
        "HTML": "https://arxiv.org/html/2506.19269",
        "PDF": "https://arxiv.org/pdf/2506.19269"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 03:03:26 GMT",
          "size": "2520kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 05:10:04 GMT",
          "size": "2520kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on robotic manipulation using a diffusion policy framework and does not discuss LLM training data processes or methodologies."
      }
    },
    {
      "id": "2506.19284",
      "abstract": "For $0\\leq \\rho\\leq 1$ and a coloured graph $G$, a vertex $v$ is $\\rho$-happy if at least $\\rho \\mathrm{deg}(v)$ of its neighbours have the same colour as $v$. Soft happy colouring of a partially coloured graph $G$ is the problem of finding a vertex colouring $\\sigma$ that preserves the precolouring and has the maximum number of $\\rho$-happy vertices. It is already known that this problem is NP-hard and directly relates to the community structure of the graphs; under a certain condition on the proportion of happiness $\\rho$ and for graphs with community structures, the induced colouring by communities can make all the vertices $\\rho$-happy. We show that when $0\\leq \\rho_1<\\rho_2\\leq 1$, a complete $\\rho_2$-happy colouring has a higher accuracy of community detection than a complete $\\rho_1$-happy colouring. Moreover, when $\\rho$ is greater than a threshold, it is unlikely for an algorithm to find a complete $\\rho$-happy colouring with colour classes of almost equal sizes. Three local search algorithms for soft happy colouring are proposed, and their performances are compared with one another and other known algorithms. Among them, the linear-time local search is shown to be not only very fast, but also a reliable algorithm that can dramatically improve the number of $\\rho$-happy vertices.",
      "authors": [
        "Mohammad Hadi Shekarriz",
        "Dhananjay Thiruvady",
        "Asef Nazari",
        "Wilfried Imrich"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19284",
        "HTML": "https://arxiv.org/html/2506.19284",
        "PDF": "https://arxiv.org/pdf/2506.19284"
      },
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 03:38:39 GMT",
          "size": "1791kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:03:42 GMT",
          "size": "1791kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Local Search Improvements for Soft Happy Colouring",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work addresses graph colouring problems and community detection in graphs, unrelated to the collection, construction, or processing of LLM training data."
      }
    },
    {
      "id": "2506.19416",
      "abstract": "Existing micro aerial vehicle (MAV) detection methods mainly rely on the target's appearance features in RGB images, whose diversity makes it difficult to achieve generalized MAV detection. We notice that different types of MAVs share the same distinctive features in event streams due to their high-speed rotating propellers, which are hard to see in RGB images. This paper studies how to detect different types of MAVs from an event camera by fully exploiting the features of propellers in the original event stream. The proposed method consists of three modules to extract the salient and spatio-temporal features of the propellers while filtering out noise from background objects and camera motion. Since there are no existing event-based MAV datasets, we introduce a novel MAV dataset for the community. This is the first event-based MAV dataset comprising multiple scenarios and different types of MAVs. Without training, our method significantly outperforms state-of-the-art methods and can deal with challenging scenarios, achieving a precision rate of 83.0\\% (+30.3\\%) and a recall rate of 81.5\\% (+36.4\\%) on the proposed testing dataset. The dataset and code are available at: https://github.com/WindyLab/EvDetMAV.",
      "authors": [
        "Yin Zhang",
        "Zian Ning",
        "Xiaoyu Zhang",
        "Shiliang Guo",
        "Peidong Liu",
        "Shiyu Zhao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19416",
        "HTML": "https://arxiv.org/html/2506.19416",
        "PDF": "https://arxiv.org/pdf/2506.19416"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 08:35:15 GMT",
          "size": "6140kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:25:52 GMT",
          "size": "6139kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "EvDetMAV: Generalized MAV Detection from Moving Event Cameras",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on MAV detection using event cameras and introduces a novel MAV dataset. It does not address LLM training data processing."
      }
    },
    {
      "id": "2506.19442",
      "abstract": "Image attribution analysis seeks to highlight the feature representations learned by visual models such that the highlighted feature maps can reflect the pixel-wise importance of inputs. Gradient integration is a building block in the attribution analysis by integrating the gradients from multiple derived samples to highlight the semantic features relevant to inferences. Such a building block often combines with other information from visual models such as activation or attention maps to form ultimate explanations. Yet, our theoretical analysis demonstrates that the extent to the alignment of the sample distribution in gradient integration with respect to natural image distribution gives a lower bound of explanation certainty. Prior works add noise into images as samples and the noise distributions can lead to low explanation certainty. Counter-intuitively, our experiment shows that extra information can saturate neural networks. To this end, building trustworthy attribution analysis needs to settle the sample distribution misalignment problem. Instead of adding extra information into input images, we present a semi-optimal sampling approach by suppressing features from inputs. The sample distribution by suppressing features is approximately identical to the distribution of natural images. Our extensive quantitative evaluation on large scale dataset ImageNet affirms that our approach is effective and able to yield more satisfactory explanations against state-of-the-art baselines throughout all experimental models.",
      "authors": [
        "R\\'ois\\'in Luo",
        "James McDermott",
        "Colm O'Riordan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19442",
        "HTML": "https://arxiv.org/html/2506.19442",
        "PDF": "https://arxiv.org/pdf/2506.19442"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 09:15:22 GMT",
          "size": "4488kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 11:18:04 GMT",
          "size": "4488kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses image attribution analysis and improvements to explanation certainty in visual models. It does not relate to LLM training data processing."
      }
    },
    {
      "id": "2506.19519",
      "abstract": "Virtual reality (VR) can enrich neuropsychological testing, yet the ergonomic trade-offs of its input modes remain under-examined. Seventy-seven healthy volunteers-young (19-29 y) and middle-aged (35-56 y)-completed a VR Trail-Making Test with three pointing methods: eye-tracking, head-gaze, and a six-degree-of-freedom hand controller. Completion time, spatial accuracy, and error counts for the simple (Trail A) and alternating (Trail B) sequences were analysed in 3 x 2 x 2 mixed-model ANOVAs; post-trial scales captured usability (SUS), user experience (UEQ-S), and acceptability. Age dominated behaviour: younger adults were reliably faster, more precise, and less error-prone. Against this backdrop, input modality mattered. Eye-tracking yielded the best spatial accuracy and shortened Trail A time relative to manual control; head-gaze matched eye-tracking on Trail A speed and became the quickest, least error-prone option on Trail B. Controllers lagged on every metric. Subjective ratings were high across the board, with only a small usability dip in middle-aged low-gamers. Overall, gaze-based ray-casting clearly outperformed manual pointing, but optimal choice depended on task demands: eye-tracking maximised spatial precision, whereas head-gaze offered calibration-free enhanced speed and error-avoidance under heavier cognitive load. TMT-VR appears to be accurate, engaging, and ergonomically adaptable assessment, yet it requires age-specific-stratified norms.",
      "authors": [
        "Panagiotis Kourtesis",
        "Evgenia Giatzoglou",
        "Panagiotis Vorias",
        "Katerina Alkisti Gounari",
        "Eleni Orfanidou and Chrysanthi Nega"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19519",
        "HTML": "https://arxiv.org/html/2506.19519",
        "PDF": "https://arxiv.org/pdf/2506.19519"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 11:10:09 GMT",
          "size": "1325kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:18:21 GMT",
          "size": "1322kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Examination of Eye-Tracking, Head-Gaze, and Controller-Based Ray-casting in TMT-VR: Performance and Usability Across Adulthood",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research examines VR input modes for neuropsychological testing, focusing on user performance and usability, with no link to LLM training data processing."
      }
    },
    {
      "id": "2506.19615",
      "abstract": "In this paper, we propose a Neural Radiance Fields (NeRF) based framework, referred to as Novel View Synthesis Framework (NVSF). It jointly learns the implicit neural representation of space and time-varying scene for both LiDAR and Camera. We test this on a real-world autonomous driving scenario containing both static and dynamic scenes. Compared to existing multimodal dynamic NeRFs, our framework is self-supervised, thus eliminating the need for 3D labels. For efficient training and faster convergence, we introduce heuristic-based image pixel sampling to focus on pixels with rich information. To preserve the local features of LiDAR points, a Double Gradient based mask is employed. Extensive experiments on the KITTI-360 dataset show that, compared to the baseline models, our framework has reported best performance on both LiDAR and Camera domain. Code of the model is available at https://github.com/gaurav00700/Selfsupervised-NVSF",
      "authors": [
        "Gaurav Sharma",
        "Ravi Kothari",
        "Josef Schmid"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19615",
        "HTML": "https://arxiv.org/html/2506.19615",
        "PDF": "https://arxiv.org/pdf/2506.19615"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 13:32:15 GMT",
          "size": "40364kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:58:58 GMT",
          "size": "40364kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Self-Supervised Multimodal NeRF for Autonomous Driving",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a self-supervised multimodal NeRF framework for autonomous driving and does not propose or discuss any aspects related to the processing of LLM training data."
      }
    },
    {
      "id": "2506.19677",
      "abstract": "Code Large Language Models (CodeLLMs) are increasingly integrated into modern software development workflows, yet efficiently serving them in resource-constrained, self-hosted environments remains a significant challenge. Existing LLM serving systems employs Continuous Batching for throughput improvement. However, they rely on static batch size configurations that cannot adapt to fluctuating request rates or heterogeneous workloads, leading to frequent SLA (Service Level Agreement) violations and unstable performance. In this study, We propose SABER, a dynamic batching strategy that predicts per-request SLA feasibility and adjusts decisions in real time. SABER improves goodput by up to 26% over the best static configurations and reduces latency variability by up to 45%, all without manual tuning or service restarts. Our results demonstrate that SLA-aware, adaptive scheduling is key to robust, high-performance CodeLLM serving.",
      "authors": [
        "Shi Chang",
        "Boyuan Chen",
        "Kishanthan Thangarajah",
        "Hanan Lutfiyya",
        "Ahmed E. Hassan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19677",
        "HTML": "https://arxiv.org/html/2506.19677",
        "PDF": "https://arxiv.org/pdf/2506.19677"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 14:44:33 GMT",
          "size": "1516kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:13:14 GMT",
          "size": "1518kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Adaptive Request Scheduling for CodeLLM Serving with SLA Guarantees",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a dynamic batching strategy for serving CodeLLMs efficiently, focusing on request scheduling and SLA adherence, with no contribution to LLM training data processing."
      }
    },
    {
      "id": "2506.19750",
      "abstract": "Symptom Checkers (SCs) provide users with personalized medical information. To prevent performance degradation from algorithm updates, SC developers must evaluate diagnostic performance changes for individual diseases before deployment. However, acquiring sufficient evaluation data for rare diseases is difficult, and manually creating numerous clinical vignettes is costly and impractical. This study proposes and validates a novel Synthetic Vignette Simulation Approach to evaluate diagnostic performance changes for individual rare diseases following SC algorithm updates. We used disease-phenotype annotations from the Human Phenotype Ontology (HPO), a knowledge database for rare diseases, to generate synthetic vignettes. With these, we simulated SC interviews to estimate the impact of algorithm updates on real-world diagnostic performance. The method's effectiveness was evaluated retrospectively by comparing estimated values with actual metric changes using the $R^2$ coefficient. The experiment included eight past SC algorithm updates. For updates on diseases with frequency information in HPO (n=5), the $R^2$ for Recall@8 change was 0.831 ($p$=0.031), and for Precision@8 change, it was 0.78 ($p$=0.047), indicating the method can predict post-deployment performance. In contrast, large prediction errors occurred for diseases without frequency information (n=3), highlighting its importance. Our method enables pre-deployment evaluation of SC algorithm changes for individual rare diseases using a publicly available, expert-created knowledge base. This transparent and low-cost approach allows developers to efficiently improve diagnostic performance for rare diseases, potentially enhancing support for early diagnosis.",
      "authors": [
        "Takashi Nishibayashi",
        "Seiji Kanazawa and Kumpei Yamada"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19750",
        "HTML": "https://arxiv.org/html/2506.19750",
        "PDF": "https://arxiv.org/pdf/2506.19750"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 16:06:37 GMT",
          "size": "648kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 11:56:15 GMT",
          "size": "648kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper centers around evaluating medical diagnostic performance using synthetic vignettes for rare diseases and does not relate to LLM training data processing."
      }
    },
    {
      "id": "2506.19808",
      "abstract": "In this paper, we propose ProtoSolo, a novel deep neural architecture for interpretable image classification inspired by prototypical networks such as ProtoPNet. Existing prototype networks usually rely on the collaborative decision-making of multiple prototypes to achieve the classification and interpretation of a single category. In contrast, ProtoSolo only requires the activation of a single prototype to complete the classification. This allows the network to explain each category decision by only providing the features that are most similar to the prototype of that category, significantly reducing the cognitive complexity of the explanation. Secondly, we propose a feature-based comparison method, which uses feature map instead of full-channel feature vector as the object of similarity comparison and prototype learning. This design enables ProtoSolo to utilize richer global information for classification while relying on a single prototype activation. In addition, we propose a non-prototype projection learning strategy, which preserves the information association between the prototype and the training image patches while avoiding the sharp change of the network structure caused by the projection operation, thus avoiding its negative impact on the classification performance. Experiments on the CUB-200-2011 and Stanford Cars datasets show that ProtoSolo achieves superior performance in classification tasks and reaches the best level in terms of cognitive complexity of explanations compared to state-of-the-art interpretable methods. The code is available at https://github.com/pyt19/ProtoSolo.",
      "authors": [
        "Yitao Peng",
        "Lianghua He",
        "Die Hu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19808",
        "HTML": "https://arxiv.org/html/2506.19808",
        "PDF": "https://arxiv.org/pdf/2506.19808"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 17:18:35 GMT",
          "size": "961kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 04:08:06 GMT",
          "size": "961kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "One Prototype Is Enough: Single-Prototype Activation for Interpretable Image Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a method for interpretable image classification based on prototype activation, which does not relate to the processing of LLM training data."
      }
    },
    {
      "id": "2302.06295",
      "abstract": "In this paper, we describe an algorithm for computing the left, right, or 2-sided congruences of a finitely presented semigroup or monoid with finitely many classes, and an alternative algorithm when the finitely presented semigroup or monoid is finite. We compare the two algorithms presented with existing algorithms and implementations. The first algorithm is a generalization of Sims' low-index subgroup algorithm for finding the congruences of a monoid. The second algorithm involves determining the distinct principal congruences, and then finding all of their possible joins. Variations of this algorithm have been suggested in numerous contexts by numerous authors. We show how to utilize the theory of relative Green's relations, and a version of Schreier's Lemma for monoids, to reduce the number of principal congruences that must be generated as the first step of this approach. Both of the algorithms described in this paper are implemented in the GAP package Semigroups, and the first algorithm is available in the C++ library libsemigroups and in its python bindings libsemigroups_pybind11.",
      "authors": [
        "Marina Anagnostopoulou-Merkouri",
        "Reinis Cirpons",
        "James D. Mitchell",
        "and Maria Tsalakou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.06295",
        "HTML": "https://arxiv.org/html/2302.06295",
        "PDF": "https://arxiv.org/pdf/2302.06295"
      },
      "subjects": [
        "Rings and Algebras (math.RA)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 13 Feb 2023 11:54:18 GMT",
          "size": "54kb",
          "version": "v1"
        },
        {
          "date": "Fri, 12 May 2023 16:09:21 GMT",
          "size": "1108kb",
          "version": "v2"
        },
        {
          "date": "Wed, 17 Apr 2024 09:06:56 GMT",
          "size": "1101kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 08:46:31 GMT",
          "size": "1104kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Computing finite index congruences of finitely presented semigroups and monoids",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about computing congruences of semigroups and monoids, which is unrelated to training data processing for LLMs."
      },
      "repo_urls": [
        "https://github.com/libsemigroups/libsemigroups"
      ]
    },
    {
      "id": "2306.17501",
      "abstract": "A Random Vector Functional Link (RVFL) network is a depth-2 neural network with random inner weights and biases. Only the outer weights of such an architecture are to be learned, so the learning process boils down to a linear optimization task, allowing one to sidestep the pitfalls of nonconvex optimization problems. In this paper, we prove that an RVFL with ReLU activation functions can approximate Lipschitz continuous functions in $L_\\infty$ norm. To the best of our knowledge, our result is the first approximation result in $L_\\infty$ norm using nice inner weights; namely, Gaussians. We give a nonasymptotic lower bound for the number of hidden-layer nodes to achieve a given accuracy with high probability, depending on, among other things, the Lipschitz constant of the target function, the desired accuracy, and the input dimension. Our method of proof is rooted in probability theory and harmonic analysis.",
      "authors": [
        "Palina Salanevich and Olov Schavemaker"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.17501",
        "HTML": "https://arxiv.org/html/2306.17501",
        "PDF": "https://arxiv.org/pdf/2306.17501"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 30 Jun 2023 09:25:03 GMT",
          "size": "13kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:55:42 GMT",
          "size": "16kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Efficient uniform approximation using Random Vector Functional Link networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the theoretical aspects of Random Vector Functional Link networks for function approximation, without addressing any aspect of LLM training data processing or data engineering."
      },
      "tasks": []
    },
    {
      "id": "2307.03334",
      "abstract": "Hybrid variational quantum algorithms (VQAs) are promising for solving practical problems such as combinatorial optimization, quantum chemistry simulation, quantum machine learning, and quantum error correction on noisy quantum computers. However, with typical random ansatz or quantum alternating operator ansatz, derived variational quantum algorithms become a black box that cannot be trusted for model interpretation, not to mention deploying as applications in informing critical decisions: the results of these variational parameters are just rotational angles for the quantum gates and have nothing to do with interpretable values that a model can provide directly. In this paper, we construct the first interpretable quantum regression algorithm, in which the quantum state exactly encodes the classical data table and the variational parameters correspond directly to the regression coefficients, which are real numbers by construction, providing a high degree of model interpretability and minimal cost to optimize due to the right expressiveness. We also take advantage of the encoded data structure to reduce the time complexity of computing the regression map. To shorten the circuit depth for nonlinear regression, our algorithm can be extended by building nonlinear features by classical preprocessing as the independent encoded column vectors. Even though the realization of compressed encoding in superconducting qubits has been achieved by the less noisy compressed encoding recently by the authors, we envision potential quantum utilities with multi-qubit gates implemented in neutral cold atoms and ions.",
      "authors": [
        "C.-C. Joseph Wang",
        "F. Perkkola",
        "I. Salmenper\\\"a",
        "A. Meijer-van de Griend",
        "J. K. Nurminen",
        "R. S. Bennink"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.03334",
        "HTML": "https://arxiv.org/html/2307.03334",
        "PDF": "https://arxiv.org/pdf/2307.03334"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 07 Jul 2023 00:30:16 GMT",
          "size": "128kb",
          "version": "v1"
        },
        {
          "date": "Mon, 16 Oct 2023 01:59:26 GMT",
          "size": "118kb",
          "version": "v2"
        },
        {
          "date": "Thu, 25 Jan 2024 01:01:33 GMT",
          "size": "118kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 13:14:47 GMT",
          "size": "136kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Variational quantum regression algorithm with encoded data structure",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work is centered around developing a variational quantum regression algorithm and does not cover any LLM training data processing or relevant data engineering techniques."
      },
      "tasks": [
        "Combinatorial Optimization",
        "feature selection",
        "Quantum Machine Learning",
        "regression"
      ]
    },
    {
      "id": "2310.12256",
      "abstract": "We provide three improvements to the product formula implementation of the ground state energy estimation algorithm via Trotter-Suzuki decomposition. These consist of smaller circuit templates for each Hamiltonian term, parallelization of commuting controlled rotations, and more efficient parallel scheduling. These improvements may be regarded separately, and we anticipate that they may be combined with other improvements to the product formula implementation.",
      "authors": [
        "Andre Kornell and Peter Selinger"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.12256",
        "HTML": "https://arxiv.org/html/2310.12256",
        "PDF": "https://arxiv.org/pdf/2310.12256"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Oct 2023 18:43:52 GMT",
          "size": "59kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 22:52:46 GMT",
          "size": "231kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Some improvements to product formula circuits for Hamiltonian simulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents improvements to quantum algorithms for Hamiltonian simulation, which is unrelated to any aspect of LLM training data processing."
      }
    },
    {
      "id": "2401.16372",
      "abstract": "Output controllability and functional observability are properties that enable, respectively, the control and estimation of part of the state vector. These notions are of utmost importance in applications to high-dimensional systems, such as large-scale networks, in which only a target subset of variables (nodes) is sought to be controlled or estimated. Although the duality between full-state controllability and observability is well established, the characterization of the duality between their generalized counterparts remains an outstanding problem. Here, we establish both the weak and the strong duality between output controllability and functional observability. Specifically, we show that functional observability of a system implies output controllability of a dual system (weak duality), and that under a certain geometric condition the converse holds (strong duality). As an application of the strong duality, we derive a necessary and sufficient condition for target control via static feedback. This allow us to establish a separation principle between the design of target controllers and the design of functional observers in closed-loop systems. These results generalize the classical duality and separation principles in modern control theory.",
      "authors": [
        "Arthur N. Montanari",
        "Chao Duan",
        "Adilson E. Motter"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.16372",
        "HTML": "https://arxiv.org/html/2401.16372",
        "PDF": "https://arxiv.org/pdf/2401.16372"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Dynamical Systems (math.DS)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 29 Jan 2024 18:11:52 GMT",
          "size": "298kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 19:09:08 GMT",
          "size": "302kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Duality between controllability and observability for target control and estimation in networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the duality between controllability and observability in network control and estimation, without addressing LLM training data processing."
      }
    },
    {
      "id": "2402.03245",
      "abstract": "Functional observability and output controllability are properties that establish the conditions for the partial estimation and partial control of the system state, respectively. In the special case of full-state observability and controllability, the Popov-Belevitch-Hautus (PBH) tests provide conditions for the properties to hold based on the system eigenspace. Generalizations of the PBH test have been recently proposed for functional observability and output controllability, but thus far have only been proven valid for diagonalizable systems. Here, we rigorously establish the generalized PBH test for functional observability, extending its validity to a broader class of systems using Jordan decomposition. Likewise, we determine the class of systems under which the generalized PBH test is sufficient and necessary for output controllability. These results have immediate implications for observer and controller design, pole assignment, and optimal placement of sensors and drivers.",
      "authors": [
        "Arthur N. Montanari",
        "Chao Duan",
        "Adilson E. Motter"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.03245",
        "HTML": "https://arxiv.org/html/2402.03245",
        "PDF": "https://arxiv.org/pdf/2402.03245"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Dynamical Systems (math.DS)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 05 Feb 2024 18:00:15 GMT",
          "size": "123kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 19:48:12 GMT",
          "size": "121kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "On the Popov-Belevitch-Hautus tests for functional observability and output controllability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on functional observability and output controllability using the Popov-Belevitch-Hautus tests, specifically in control theory, which does not relate to LLM training data processing."
      }
    },
    {
      "id": "2402.06525",
      "abstract": "A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed. This is known as a neural network Gaussian process (NNGP). However, the NNGP kernel is fixed and tunable only through a small number of hyperparameters, thus eliminating the possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well because they are able to flexibly learn representations for the task at hand. Thus, in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of graph tasks. We develop a precise tool for this task, the graph convolutional deep kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a ``knob'' to control the amount of flexibility and hence representation learning. We found that representation learning gives noticeable performance improvements for heterophilous node classification tasks, but less so for homophilous node classification tasks.",
      "authors": [
        "Ben Anson",
        "Edward Milsom",
        "Laurence Aitchison"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.06525",
        "HTML": "https://arxiv.org/html/2402.06525",
        "PDF": "https://arxiv.org/pdf/2402.06525"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 09 Feb 2024 16:37:08 GMT",
          "size": "754kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:59:16 GMT",
          "size": "636kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Flexible Infinite-Width Graph Convolutional Neural Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work deals with Graph Convolutional Neural Networks and representation learning, specifically through infinite-width limits and kernels, without any specific focus on LLM training data processing."
      },
      "tasks": [
        "Classification",
        "Graph Classification",
        "Node Classification",
        "Representation Learning"
      ]
    },
    {
      "id": "2406.02426",
      "abstract": "In contextual optimization, a decision-maker leverages contextual information, often referred to as covariates, to better resolve uncertainty and make informed decisions. In this paper, we examine the challenges of contextual decision-making under covariate shift, a phenomenon where the distribution of covariates differs between the training and test environments. Such shifts can lead to inaccurate upstream estimations for test covariates that lie far from the training data, ultimately resulting in suboptimal downstream decisions. To tackle these challenges, we propose a novel approach called Intersection Wasserstein-balls DRO (IW-DRO), which integrates multiple estimation methods into the distributionally robust optimization (DRO) framework. At the core of our approach is an innovative ambiguity set defined as the intersection of two Wasserstein balls, with their centers constructed using appropriate nonparametric and parametric estimators. On the computational side, we reformulate the IW-DRO problem as a tractable convex program and develop an approximate algorithm tailored for large-scale problems to enhance computational efficiency. From a theoretical perspective, we demonstrate that IW-DRO achieves superior performance compared to single Wasserstein-ball DRO models. We further establish performance guarantees by analyzing the coverage of the intersection ambiguity set and the measure concentration of both estimators under the Wasserstein distance. Notably, we derive a finite-sample concentration result for the Nadaraya-Watson kernel estimator under covariate shift. The proposed IW-DRO framework offers practical value for decision-makers operating in uncertain environments affected by covariate shifts.",
      "authors": [
        "Tianyu Wang",
        "Ningyuan Chen",
        "Chun Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.02426",
        "HTML": "https://arxiv.org/html/2406.02426",
        "PDF": "https://arxiv.org/pdf/2406.02426"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Jun 2024 15:46:41 GMT",
          "size": "798kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:43:13 GMT",
          "size": "305kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Contextual Optimization under Covariate Shift: A Robust Approach by Intersecting Wasserstein Balls",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a method for contextual optimization under covariate shift in decision-making processes. It does not involve LLM data engineering or training-stage data processing."
      },
      "tasks": [
        "Portfolio Optimization"
      ]
    },
    {
      "id": "2408.08062",
      "abstract": "Model parsimony is an important \\emph{cognitive bias} in data-driven modelling that aids interpretability and helps to prevent over-fitting. Sparse identification of nonlinear dynamics (SINDy) methods are able to learn sparse representations of complex dynamics directly from data, given a basis of library functions. In this work, a novel Bayesian treatment of dictionary learning system identification, as an alternative to SINDy, is envisaged. The proposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is distinct from previous approaches in that it targets the full joint posterior distribution over both the terms in the library and their parameterisation in the model. This formulation confers the advantage that an arbitrary prior may be placed over the model structure to produce models that are sparse in the model space rather than in parameter space. Because this posterior is defined over parameter vectors that can change in dimension, the inference cannot be performed by standard techniques. Instead, a Gibbs sampler based on reversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare favourably to ensemble SINDy in three benchmark case-studies. In particular, it is seen that the proposed method is better able to assign high probability to correct model terms.",
      "authors": [
        "Max D. Champneys",
        "Timothy J. Rogers"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.08062",
        "HTML": "https://arxiv.org/html/2408.08062",
        "PDF": "https://arxiv.org/pdf/2408.08062"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 15 Aug 2024 10:03:30 GMT",
          "size": "6225kb",
          "version": "v1"
        },
        {
          "date": "Tue, 04 Feb 2025 14:35:01 GMT",
          "size": "6824kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 10:45:10 GMT",
          "size": "6687kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "BINDy -- Bayesian identification of nonlinear dynamics with reversible-jump Markov-chain Monte-Carlo",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on Bayesian methods for nonlinear dynamics identification and does not address any aspects of LLM training data collection or processing."
      },
      "tasks": [
        "Dictionary Learning"
      ]
    },
    {
      "id": "2408.09554",
      "abstract": "Molecular assays are standard of care for detecting genomic alterations in cancer prognosis and therapy selection but are costly, tissue-destructive and time-consuming. Artificial intelligence (AI) applied to routine hematoxylin and eosin (H&E)-stained whole slide images (WSIs) offers a fast and economical alternative for screening molecular biomarkers. We introduce OmniScreen, a high-throughput AI-based system leveraging Virchow2 embeddings extracted from 60,529 cancer patients with paired 489-gene MSK-IMPACT targeted biomarker panel and WSIs. Unlike conventional approaches that train separate models for each biomarker, OmniScreen employs a unified model to predict a broad range of clinically relevant biomarkers across cancers, including low-prevalence targets impractical to model individually. OmniScreen reliably identifies therapeutic targets and shared phenotypic features across common and rare tumors. We investigate the biomarker prediction probabilities and accuracies of OmniScreen in relation to tumor area, cohort size, histologic subtype alignment, and pathway-level morphological patterns. These findings underscore the potential of OmniScreen for routine clinical screening.",
      "authors": [
        "Yi Kan Wang",
        "Ludmila Tylditatova",
        "Jeremy D. Kunz",
        "Gerard Oakley",
        "Bonnie Kar Bo Chow",
        "Ran A. Godrich",
        "Matthew C. H. Lee",
        "Hamed Aghdam",
        "Alican Bozkurt",
        "Michal Zelechowski",
        "Chad Vanderbilt",
        "Christopher Kanan",
        "Juan A. Retamero",
        "Peter Hamilton",
        "Razik Yousfi",
        "Thomas J. Fuchs",
        "David S. Klimstra",
        "Siqi Liu"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.09554",
        "HTML": "https://arxiv.org/html/2408.09554",
        "PDF": "https://arxiv.org/pdf/2408.09554"
      },
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 18 Aug 2024 17:44:00 GMT",
          "size": "15393kb",
          "version": "v1"
        },
        {
          "date": "Tue, 20 Aug 2024 12:47:35 GMT",
          "size": "15393kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 22:10:17 GMT",
          "size": "23268kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Screen Them All: High-Throughput Pan-Cancer Genetic and Phenotypic Biomarker Screening from H&E Whole Slide Images",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses AI for biomarker screening in cancer diagnostics, unrelated to LLM training data or its processing."
      },
      "tasks": [
        "All",
        "whole slide images"
      ]
    },
    {
      "id": "2409.04803",
      "abstract": "The Transformer model, particularly its cross-attention module, is widely used for feature fusion in target sound extraction which extracts the signal of interest based on given clues. Despite its effectiveness, this approach suffers from low computational efficiency. Recent advancements in state space models, notably the latest work Mamba, have shown comparable performance to Transformer-based methods while significantly reducing computational complexity in various tasks. However, Mamba's applicability in target sound extraction is limited due to its inability to capture dependencies between different sequences as the cross-attention does. In this paper, we propose CrossMamba for target sound extraction, which leverages the hidden attention mechanism of Mamba to compute dependencies between the given clues and the audio mixture. The calculation of Mamba can be divided to the query, key and value. We utilize the clue to generate the query and the audio mixture to derive the key and value, adhering to the principle of the cross-attention mechanism in Transformers. Experimental results from two representative target sound extraction methods validate the efficacy of the proposed CrossMamba.",
      "authors": [
        "Donghang Wu",
        "Yiwen Wang",
        "Xihong Wu",
        "Tianshu Qu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.04803",
        "HTML": "https://arxiv.org/html/2409.04803",
        "PDF": "https://arxiv.org/pdf/2409.04803"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 07 Sep 2024 12:01:08 GMT",
          "size": "754kb",
          "version": "v1"
        },
        {
          "date": "Tue, 10 Sep 2024 07:10:03 GMT",
          "size": "771kb",
          "version": "v2"
        },
        {
          "date": "Fri, 27 Sep 2024 07:08:58 GMT",
          "size": "771kb",
          "version": "v3"
        },
        {
          "date": "Sat, 21 Dec 2024 15:09:59 GMT",
          "size": "771kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 09:10:23 GMT",
          "size": "771kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Cross-attention Inspired Selective State Space Models for Target Sound Extraction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study proposes a new model for target sound extraction using state space models and mentions use of cross-attention but is not related to any stage of LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Mamba",
        "State Space Models",
        "Target Sound Extraction"
      ],
      "repo_urls": [
        "https://github.com/WuDH2000/CrossMamba"
      ]
    },
    {
      "id": "2411.16556",
      "abstract": "The search for radio technosignatures is an anomaly detection problem: Candidate signals represent needles of interest in the proverbial haystack of radio-frequency interference (RFI). Current search frameworks find an enormity of false-positive signals, especially in large surveys, requiring manual follow-up to a sometimes prohibitive degree. Unsupervised learning provides an algorithmic way to winnow the most anomalous signals from the chaff, as well as group together RFI signals that bear morphological similarities. We present GLOBULAR (Grouping Low-frequency Observations By Unsupervised Learning After Reduction) clustering, a signal processing method that uses HDBSCAN to reduce the false-positive rate and isolate outlier signals for further analysis. When combined with a standard narrowband signal detection and spatial filtering pipeline, such as turboSETI, GLOBULAR clustering offers significant improvements in the false-positive rate over the standard pipeline alone, suggesting dramatic potential for the amelioration of manual follow-up requirements for future large surveys. By removing RFI signals in regions of high spectral occupancy, GLOBULAR clustering may also enable the detection of signals missed by the standard pipeline. We benchmark our method against the Choza et al. turboSETI-only search of 97 nearby galaxies at the L band, demonstrating a false-positive hit reduction rate of 93.1% and a false-positive event reduction rate of 99.3%.",
      "authors": [
        "Ben Jacobson-Bell",
        "Steve Croft",
        "Carmen Choza",
        "Alex Andersson",
        "Daniel Bautista",
        "Vishal Gajjar",
        "Matthew Lebofsky",
        "David H. E. MacMahon",
        "Caleb Painter",
        "and Andrew P. V. Siemion"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16556",
        "HTML": "https://arxiv.org/html/2411.16556",
        "PDF": "https://arxiv.org/pdf/2411.16556"
      },
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 25 Nov 2024 16:40:19 GMT",
          "size": "10734kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 18:10:40 GMT",
          "size": "10740kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Anomaly Detection and Radio-frequency Interference Classification with Unsupervised Learning in Narrowband Radio Technosignature Searches",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus here is on anomaly detection and classification of radio-frequency interference, unrelated to LLM training data techniques."
      },
      "tasks": [
        "Anomaly Detection",
        "Clustering"
      ]
    },
    {
      "id": "2412.10538",
      "abstract": "Accurate predictions and representations of plant growth patterns in simulated and controlled environments are important for addressing various challenges in plant phenomics research. This review explores various works on state-of-the-art predictive pattern recognition techniques, focusing on the spatiotemporal modeling of plant traits and the integration of dynamic environmental interactions. We provide a comprehensive examination of deterministic, probabilistic, and generative modeling approaches, emphasizing their applications in high-throughput phenotyping and simulation-based plant growth forecasting. Key topics include regressions and neural network-based representation models for the task of forecasting, limitations of existing experiment-based deterministic approaches, and the need for dynamic frameworks that incorporate uncertainty and evolving environmental feedback. This review surveys advances in 2D and 3D structured data representations through functional-structural plant models and conditional generative models. We offer a perspective on opportunities for future works, emphasizing the integration of domain-specific knowledge to data-driven methods, improvements to available datasets, and the implementation of these techniques toward real-world applications.",
      "authors": [
        "Mohamed Debbagh",
        "Shangpeng Sun",
        "Mark Lefsrud"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10538",
        "HTML": "https://arxiv.org/html/2412.10538",
        "PDF": "https://arxiv.org/pdf/2412.10538"
      },
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Dec 2024 20:22:35 GMT",
          "size": "2678kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Dec 2024 00:11:40 GMT",
          "size": "2642kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 02:56:51 GMT",
          "size": "2776kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Predictive Modeling, Pattern Recognition, and Spatiotemporal Representations of Plant Growth in Simulated and Controlled Environments: A Comprehensive Review",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is a review focusing on predictive modeling techniques in plant growth studies and does not contribute to or discuss LLM training data processing or data engineering."
      },
      "tasks": []
    },
    {
      "id": "2501.00389",
      "abstract": "We study the momentum-based minimization of a diffuse perimeter functional on Euclidean spaces and on graphs with applications to semi-supervised classification tasks in machine learning. While the gradient flow in the task at hand is a parabolic partial differential equation, the momentum method corresponds to a damped hyperbolic PDE, leading to qualitatively and quantitatively different trajectories. Using a convex-concave splitting-based FISTA-type time discretization, we demonstrate empirically that momentum can lead to faster convergence if the time step size is large but not too large. With large time steps, the PDE analysis offers only limited insight into the geometric behavior of solutions and typical hyperbolic phenomena like loss of regularity are not be observed in sample simulations. We obtain the singular limit of the evolution equations as the length parameter of the phase fields tends to zero by formal expansions and numerically confirm its validity for circles in two dimensions. Our analysis is complemented by numerical experiments for planar curves, surfaces in three-dimensional space, and semi-supervised learning tasks on graphs.",
      "authors": [
        "Oluwatosin Akande",
        "Patrick Dondl",
        "Kanan Gupta",
        "Akwum Onwunta",
        "Stephan Wojtowytsch"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00389",
        "HTML": "https://arxiv.org/html/2501.00389",
        "PDF": "https://arxiv.org/pdf/2501.00389"
      },
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 31 Dec 2024 11:05:49 GMT",
          "size": "4909kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:38:44 GMT",
          "size": "13875kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Momentum-based minimization of the Ginzburg-Landau functional on Euclidean spaces and graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about minimizing the Ginzburg-Landau functional for classification tasks and does not address LLM training data collection or processing."
      },
      "tasks": []
    },
    {
      "id": "2501.17876",
      "abstract": "Score-based diffusion models represent a significant variant within the diffusion model family and have seen extensive application in the increasingly popular domain of generative tasks. Recent investigations have explored the denoising potential of diffusion models in semantic communications. However, in previous paradigms, noise distortion in the diffusion process does not match precisely with digital channel noise characteristics. In this work, we introduce the Score-Based Channel Denoising Model (SCDM) for Digital Semantic Communications (DSC). SCDM views the distortion of constellation symbol sequences in digital transmission as a score-based forward diffusion process. We design a tailored forward noise corruption to align digital channel noise properties in the training phase. During the inference stage, the well-trained SCDM can effectively denoise received semantic symbols under various SNR conditions, reducing the difficulty for the semantic decoder in extracting semantic information from the received noisy symbols and thereby enhancing the robustness of the reconstructed semantic information. Experimental results show that SCDM outperforms the baseline model in PSNR, SSIM, and MSE metrics, particularly at low SNR levels. Moreover, SCDM reduces storage requirements by a factor of 7.8. This efficiency in storage, combined with its robust denoising capability, makes SCDM a practical solution for DSC across diverse channel conditions.",
      "authors": [
        "Hao Mo",
        "Yaping Sun",
        "Shumin Yao",
        "Hao Chen",
        "Zhiyong Chen",
        "Xiaodong Xu",
        "Nan Ma",
        "Meixia Tao",
        "Shuguang Cui"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17876",
        "HTML": "https://arxiv.org/html/2501.17876",
        "PDF": "https://arxiv.org/pdf/2501.17876"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 18 Jan 2025 05:56:38 GMT",
          "size": "960kb",
          "version": "v1"
        },
        {
          "date": "Sun, 02 Feb 2025 15:29:21 GMT",
          "size": "960kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 06:08:31 GMT",
          "size": "961kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SCDM: Score-Based Channel Denoising Model for Digital Semantic Communications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a model for denoising in digital semantic communications and does not relate to LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "SSIM"
      ]
    },
    {
      "id": "2501.18227",
      "abstract": "Headphone listening in applications such as augmented and virtual reality (AR and VR) relies on high-quality spatial audio to ensure immersion, making accurate binaural reproduction a critical component. As capture devices, wearable arrays with only a few microphones with irregular arrangement face challenges in achieving a reproduction quality comparable to that of arrays with a large number of microphones. Binaural signal matching (BSM) has recently been presented as a signal-independent approach for generating high-quality binaural signal using only a few microphones, which is further improved using magnitude-least squares (MagLS) optimization at high frequencies. This paper extends BSM with MagLS by introducing interaural level difference (ILD) into the MagLS, integrated into BSM (BSM-iMagLS). Using a deep neural network (DNN)-based solver, BSM-iMagLS achieves joint optimization of magnitude, ILD, and magnitude derivatives, improving spatial fidelity. Performance is validated through theoretical analysis, numerical simulations with diverse HRTFs and head-mounted array geometries, and listening experiments, demonstrating a substantial reduction in ILD errors while maintaining comparable magnitude accuracy to state-of-the-art solutions. The results highlight the potential of BSM-iMagLS to enhance binaural reproduction for wearable and portable devices.",
      "authors": [
        "Or Berebi",
        "Zamir Ben-Hur",
        "David Lou Alon and Boaz Rafaely"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18227",
        "HTML": "https://arxiv.org/html/2501.18227",
        "PDF": "https://arxiv.org/pdf/2501.18227"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 30 Jan 2025 09:33:37 GMT",
          "size": "2708kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:10:10 GMT",
          "size": "2347kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "BSM-iMagLS: ILD Informed Binaural Signal Matching for Reproduction with Head-Mounted Microphone Arrays",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper involves binaural signal reproduction methods and enhancements for spatial audio, unrelated to LLM training data."
      },
      "tasks": []
    },
    {
      "id": "2502.06485",
      "abstract": "Crystalline materials often exhibit a high level of symmetry. However, most generative models do not account for symmetry, but rather model each atom without any constraints on its position or element. We propose a generative model, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based descriptions of crystals. This is enabled by considering a crystal structure representation that encodes all symmetry, and we design a novel neural network architecture which enables using this representation inside a discrete generative model framework. In addition to respecting symmetry by construction, the discrete nature of our model enables fast generation. We additionally present a new metric, Fr\\'echet Wrenformer Distance, which captures the symmetry aspects of the materials generated, and we benchmark WyckoffDiff against recently proposed generative models for crystal generation. As a proof-of-concept study, we use WyckoffDiff to find new materials below the convex hull of thermodynamical stability.",
      "authors": [
        "Filip Ekstr\\\"om Kelvinius",
        "Oskar B. Andersson",
        "Abhijith S. Parackal",
        "Dong Qian",
        "Rickard Armiento",
        "Fredrik Lindsten"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06485",
        "HTML": "https://arxiv.org/html/2502.06485",
        "PDF": "https://arxiv.org/pdf/2502.06485"
      },
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 10 Feb 2025 14:04:23 GMT",
          "size": "1592kb",
          "version": "v1"
        },
        {
          "date": "Wed, 30 Apr 2025 06:08:47 GMT",
          "size": "1592kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 12:45:51 GMT",
          "size": "1590kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "WyckoffDiff -- A Generative Diffusion Model for Crystal Symmetry",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered on a generative model for crystal symmetry that does not address LLM training data processing tasks or data engineering concerns."
      },
      "tasks": [
        "model",
        "Position"
      ],
      "repo_urls": [
        "https://github.com/httk/wyckoffdiff"
      ]
    },
    {
      "id": "2502.20083",
      "abstract": "Unknown node attributes in complex networks may introduce community structures that are important to distinguish from those driven by known attributes. We propose a block-corrected modularity that discounts given block structures present in the network to reveal communities masked by them. We show analytically how the proposed modularity finds the community structure driven by an unknown attribute in a simple network model. Further, we observe that the block-corrected modularity finds the underlying community structure on a number of simple synthetic network models while methods using different null models fail. We develop an efficient spectral method as well as two Louvain-inspired fine-tuning algorithms to maximize the proposed modularity and demonstrate their performance on several synthetic network models. Finally, we assess our methodology on various real-world citation networks built using the OpenAlex data by correcting for the temporal citation patterns.",
      "authors": [
        "Hasti Narimanzadeh",
        "Takayuki Hiraoka",
        "Mikko Kivel\\\"a"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20083",
        "HTML": "https://arxiv.org/html/2502.20083",
        "PDF": "https://arxiv.org/pdf/2502.20083"
      },
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 27 Feb 2025 13:41:28 GMT",
          "size": "363kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 18:12:41 GMT",
          "size": "400kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Block-corrected Modularity for Community Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research concerns community detection in networks and does not involve any LLM training data processing or construction, as it focuses on network modularity."
      }
    },
    {
      "id": "2503.00089",
      "abstract": "Recent years have witnessed a surge in the development of protein structural tokenization methods, which chunk protein 3D structures into discrete or continuous representations. Structure tokenization enables the direct application of powerful techniques like language modeling for protein structures, and large multimodal models to integrate structures with protein sequences and functional texts. Despite the progress, the capabilities and limitations of these methods remain poorly understood due to the lack of a unified evaluation framework. We first introduce StructTokenBench, a framework that comprehensively evaluates the quality and efficiency of structure tokenizers, focusing on fine-grained local substructures rather than global structures, as typical in existing benchmarks. Our evaluations reveal that no single model dominates all benchmarking perspectives. Observations of codebook under-utilization led us to develop AminoAseed, a simple yet effective strategy that enhances codebook gradient updates and optimally balances codebook size and dimension for improved tokenizer utilization and quality. Compared to the leading model ESM3, our method achieves an average of 6.31% performance improvement across 24 supervised tasks, with sensitivity and utilization rates increased by 12.83% and 124.03%, respectively. Source code and model weights are available at https://github.com/KatarinaYuan/StructTokenBench",
      "authors": [
        "Xinyu Yuan",
        "Zichen Wang",
        "Marcus Collins",
        "Huzefa Rangwala"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00089",
        "HTML": "https://arxiv.org/html/2503.00089",
        "PDF": "https://arxiv.org/pdf/2503.00089"
      },
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 28 Feb 2025 15:14:33 GMT",
          "size": "29343kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 18:54:25 GMT",
          "size": "13444kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Protein Structure Tokenization: Benchmarking and New Recipe",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes protein structure tokenization and evaluation frameworks with an emphasis on protein modeling, not LLM training data processing or construction."
      },
      "tasks": [
        "Benchmarking",
        "Language Modeling",
        "Language Modelling"
      ]
    },
    {
      "id": "2503.04071",
      "abstract": "This paper studies a Conformal Prediction (CP) methodology for building prediction intervals in a regression setting, given only deterministic lower and upper bounds on the target variable. It proposes a new CP mechanism (CPUL) that goes beyond post-processing by adopting a model selection approach over multiple nested interval construction methods. Paradoxically, many well-established CP methods, including CPUL, may fail to provide adequate coverage in regions where the bounds are tight. To remedy this limitation, the paper proposes an optimal thresholding mechanism, OMLT, that adjusts CPUL intervals in tight regions with undercoverage. The combined CPUL-OMLT is validated on large-scale learning tasks where the goal is to bound the optimal value of a parametric optimization problem. The experimental results demonstrate substantial improvements over baseline methods across various datasets.",
      "authors": [
        "Miao Li",
        "Michael Klamkin",
        "Mathieu Tanneau",
        "Reza Zandehshahvar",
        "and Pascal Van Hentenryck"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04071",
        "HTML": "https://arxiv.org/html/2503.04071",
        "PDF": "https://arxiv.org/pdf/2503.04071"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 06 Mar 2025 04:07:25 GMT",
          "size": "216kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 00:04:42 GMT",
          "size": "121kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Conformal Prediction with Upper and Lower Bound Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a conformal prediction methodology for regression tasks, proposing interval construction methods and thresholding mechanisms. It does not relate to the LLM training data processing or engineering stages."
      }
    },
    {
      "id": "2503.17427",
      "abstract": "Microstructure quantification is an important step towards establishing structure-property relationships in materials. Machine learning-based image processing methods have been shown to outperform conventional image processing techniques and are increasingly applied to microstructure quantification tasks. In this work, we present a 3D variational autoencoder (VAE) for encoding microstructure volume elements (VEs) comprising voxelated crystallographic orientation data. Crystal symmetries in the orientation space are accounted for by mapping to the crystallographic fundamental zone as a preprocessing step, which allows for a continuous loss function to be used and improves the training convergence rate. The VAE is then used to encode a training set of VEs with an equiaxed polycrystalline microstructure with random texture. Accurate reconstructions are achieved with a relative average misorientation error of 3x10^-2 on the test dataset, for a continuous latent space with dimension 256. We show that the model generalises well to microstructures with textures, grain sizes and aspect ratios outside the training distribution. Structure-property relationships are explored through using the training set of VEs as initial configurations in various crystal plasticity (CP) simulations. Microstructural fingerprints extracted from the VAE, which parameterise the VEs in a low-dimensional latent space, are stored alongside the volume-averaged stress response, at each strain increment, to uniaxial tensile deformation from CP simulations. This is then used to train a fully connected neural network mapping the input fingerprint to the resulting stress response, which acts as a surrogate model for the CP simulation. The fingerprint-based surrogate model is shown to accurately predict the microstructural dependence in the CP stress response, with a relative mean-squared error of 2.75 MPa on unseen test data.",
      "authors": [
        "Michael D. White",
        "Michael D. Atkinson",
        "Adam J. Plowman and Pratheek Shanthraj"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17427",
        "HTML": "https://arxiv.org/html/2503.17427",
        "PDF": "https://arxiv.org/pdf/2503.17427"
      },
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 21 Mar 2025 11:17:10 GMT",
          "size": "11086kb",
          "version": "v1"
        },
        {
          "date": "Tue, 29 Apr 2025 11:58:22 GMT",
          "size": "11086kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 09:14:01 GMT",
          "size": "14747kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "3D variational autoencoder for fingerprinting microstructure volume elements",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a 3D variational autoencoder for microstructure quantification in materials, which is unrelated to LLM training data processing."
      },
      "tasks": []
    },
    {
      "id": "2504.13320",
      "abstract": "We introduce a gradient-free framework for Bayesian Optimal Experimental Design (BOED) in sequential settings, aimed at complex systems where gradient information is unavailable. Our method combines Ensemble Kalman Inversion (EKI) for design optimization with the Affine-Invariant Langevin Dynamics (ALDI) sampler for efficient posterior sampling-both of which are derivative-free and ensemble-based. To address the computational challenges posed by nested expectations in BOED, we propose variational Gaussian and parametrized Laplace approximations that provide tractable upper and lower bounds on the Expected Information Gain (EIG). These approximations enable scalable utility estimation in high-dimensional spaces and PDE-constrained inverse problems. We demonstrate the performance of our framework through numerical experiments ranging from linear Gaussian models to PDE-based inference tasks, highlighting the method's robustness, accuracy, and efficiency in information-driven experimental design.",
      "authors": [
        "Robert Gruhlke",
        "Matei Hanu",
        "Claudia Schillings",
        "Philipp Wacker"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13320",
        "HTML": "https://arxiv.org/html/2504.13320",
        "PDF": "https://arxiv.org/pdf/2504.13320"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 17 Apr 2025 20:16:15 GMT",
          "size": "4936kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 08:22:09 GMT",
          "size": "1865kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Gradient-Free Sequential Bayesian Experimental Design via Interacting Particle Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on gradient-free Bayesian Optimal Experimental Design (BOED) for complex systems using ensemble methods, with no mention of LLM training data processing or data engineering."
      },
      "tasks": [
        "Experimental Design"
      ]
    },
    {
      "id": "2505.08079",
      "abstract": "Zak-OTFS (orthogonal time frequency space) modulation is a communication framework that parameterizes the wireless channel in the delay-Doppler (DD) domain, where the parameters map directly to physical attributes of the scatterers that comprise the scattering environment. As a consequence, the channel can be efficiently acquired and equalized. The Zak-OTFS carrier is a pulse in the DD domain, and the Zak transform converts it to a pulse train modulated by a tone (pulsone) in the time domain. The pulsone waveform is localized rather than spread, and it suffers from high peak-to-average power ratio (PAPR). We describe how to transform the orthonormal basis of Zak-OTFS pulsones into an orthonormal basis of spread carrier waveforms with low PAPR (only $6.58$ dB) that support communication in the presence of mobility and delay spread. This transformation is realized by a unitary transform based on the discrete affine Fourier transform. Unlike other spread modulations that achieve low PAPR by spreading information across a wider bandwidth (thus reducing the spectral efficiency), the proposed spread carrier-based Zak-OTFS achieves full spectral efficiency like pulsone-based Zak-OTFS, with $5.6$ dB lower PAPR per basis element. We demonstrate uncoded bit error rate (BER) similar to pulsone-based Zak-OTFS, and improved BER performance over competing methods based on OFDM and OTFS in high mobility & delay spread environments.",
      "authors": [
        "Nishant Mehrotra",
        "Sandesh Rao Mattu",
        "and Robert Calderbank"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08079",
        "HTML": "https://arxiv.org/html/2505.08079",
        "PDF": "https://arxiv.org/pdf/2505.08079"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 12 May 2025 21:28:14 GMT",
          "size": "196kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:09:41 GMT",
          "size": "345kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Zak-OTFS with Spread Carrier Waveforms",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a communication framework and doesn't discuss any aspect of data processing relevant to LLM training data management."
      },
      "tasks": []
    },
    {
      "id": "2505.24765",
      "abstract": "Supervised Quantum Machine Learning (QML) represents an intersection of quantum computing and classical machine learning, aiming to use quantum resources to support model training and inference. This paper reviews recent developments in supervised QML, focusing on methods such as variational quantum circuits, quantum neural networks, and quantum kernel methods, along with hybrid quantum-classical workflows. We examine recent experimental studies that show partial indications of quantum advantage and describe current limitations including noise, barren plateaus, scalability issues, and the lack of formal proofs of performance improvement over classical methods. The main contribution is a ten-year outlook (2025-2035) that outlines possible developments in supervised QML, including a roadmap describing conditions under which QML may be used in applied research and enterprise systems over the next decade.",
      "authors": [
        "Srikanth Thudumu",
        "Jason Fisher and Hung Du"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24765",
        "HTML": "https://arxiv.org/html/2505.24765",
        "PDF": "https://arxiv.org/pdf/2505.24765"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 30 May 2025 16:29:12 GMT",
          "size": "2288kb",
          "version": "v1"
        },
        {
          "date": "Thu, 05 Jun 2025 02:48:21 GMT",
          "size": "2288kb",
          "version": "v2"
        },
        {
          "date": "Tue, 10 Jun 2025 01:41:54 GMT",
          "size": "2288kb",
          "version": "v3"
        },
        {
          "date": "Tue, 17 Jun 2025 18:54:29 GMT",
          "size": "2288kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 02:08:22 GMT",
          "size": "2288kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on supervised quantum machine learning and potential future developments, with no mention of data engineering or training-stage data processing for LLMs."
      },
      "tasks": [
        "Quantum Machine Learning"
      ]
    },
    {
      "id": "2506.01891",
      "abstract": "Neural Quantum States (NQS) are a class of variational wave functions parametrized by neural networks (NNs) to study quantum many-body systems. In this work, we propose \\texttt{SineKAN}, a NQS \\textit{ansatz} based on Kolmogorov-Arnold Networks (KANs), to represent quantum mechanical wave functions as nested univariate functions. We show that \\texttt{SineKAN} wavefunction with learnable sinusoidal activation functions can capture the ground state energies, fidelities and various correlation functions of the one dimensional Transverse-Field Ising model, Anisotropic Heisenberg model, and Antiferromagnetic $J_{1}-J_{2}$ model with different chain lengths. In our study of the $J_1-J_2$ model with $L=100$ sites, we find that the \\texttt{SineKAN} model outperforms several previously explored neural quantum state \\textit{ans\\\"atze}, including Restricted Boltzmann Machines (RBMs), Long Short-Term Memory models (LSTMs), and Multi-layer Perceptrons (MLP) \\textit{a.k.a.} Feed Forward Neural Networks, when compared to the results obtained from the Density Matrix Renormalization Group (DMRG) algorithm. We find that \\texttt{SineKAN} models can be trained to high precisions and accuracies with minimal computational costs.",
      "authors": [
        "Mahmud Ashraf Shamim",
        "Eric A F Reinhardt",
        "Talal Ahmed Chowdhury",
        "Sergei Gleyzer and Paulo T Araujo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01891",
        "HTML": "https://arxiv.org/html/2506.01891",
        "PDF": "https://arxiv.org/pdf/2506.01891"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 17:18:40 GMT",
          "size": "3250kb",
          "version": "v1"
        },
        {
          "date": "Tue, 17 Jun 2025 19:21:36 GMT",
          "size": "3251kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 17:17:27 GMT",
          "size": "3251kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Probing Quantum Spin Systems with Kolmogorov-Arnold Neural Network Quantum States",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates quantum spin systems using neural quantum states, unrelated to the processing of training data for LLMs."
      },
      "tasks": [
        "Kolmogorov-Arnold Networks"
      ]
    },
    {
      "id": "2506.12903",
      "abstract": "Variational Learning (VL) has recently gained popularity for training deep neural networks and is competitive to standard learning methods. Part of its empirical success can be explained by theories such as PAC-Bayes bounds, minimum description length and marginal likelihood, but there are few tools to unravel the implicit regularization in play. Here, we analyze the implicit regularization of VL through the Edge of Stability (EoS) framework. EoS has previously been used to show that gradient descent can find flat solutions and we extend this result to VL to show that it can find even flatter solutions. This is obtained by controlling the posterior covariance and the number of Monte Carlo samples from the posterior. These results are derived in a similar fashion as the standard EoS literature for deep learning, by first deriving a result for a quadratic problem and then extending it to deep neural networks. We empirically validate these findings on a wide variety of large networks, such as ResNet and ViT, to find that the theoretical results closely match the empirical ones. Ours is the first work to analyze the EoS dynamics in VL.",
      "authors": [
        "Avrajit Ghosh",
        "Bai Cong",
        "Rio Yokota",
        "Saiprasad Ravishankar",
        "Rongrong Wang",
        "Molei Tao",
        "Mohammad Emtiyaz Khan",
        "Thomas M\\\"ollenhoff"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12903",
        "HTML": "https://arxiv.org/html/2506.12903",
        "PDF": "https://arxiv.org/pdf/2506.12903"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 15 Jun 2025 16:33:02 GMT",
          "size": "17370kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:17:32 GMT",
          "size": "10124kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Variational Learning Finds Flatter Solutions at the Edge of Stability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on variational learning and its application in finding flatter solutions in deep neural networks. It does not involve any processing or handling of training data specific to LLMs."
      }
    },
    {
      "id": "2506.13615",
      "abstract": "Precise control of signal propagation in modular neural networks represents a fundamental challenge in computational neuroscience. We establish a framework for identifying optimal control nodes that maximize stimulus transmission between weakly coupled neural populations. Using spiking stochastic block model networks, we systematically compare driver node selection strategies - including random sampling and topology-based centrality measures (degree, betweenness, closeness, eigenvector, harmonic, and percolation centrality) - to determine minimal control inputs for achieving inter-population synchronization. Targeted stimulation of just 10-20% of the most central neurons in the source population significantly enhances spiking propagation fidelity compared to random selection. This approach yields a 64-fold increase in signal transfer efficiency at critical inter-module connection densities. These findings establish a theoretical foundation for precision neuromodulation in biological neural systems and neurotechnology applications.",
      "authors": [
        "Bulat Batuev",
        "Arsenii Onuchin",
        "Sergey Sukhov"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13615",
        "HTML": "https://arxiv.org/html/2506.13615",
        "PDF": "https://arxiv.org/pdf/2506.13615"
      },
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 15:43:58 GMT",
          "size": "449kb",
          "version": "v1"
        },
        {
          "date": "Tue, 17 Jun 2025 11:35:03 GMT",
          "size": "438kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 12:13:18 GMT",
          "size": "328kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Effective Stimulus Propagation in Neural Circuits: Driver Node Selection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research focuses on control of signal propagation in neural circuits and does not cover any aspects of data processing or engineering relevant to LLM training."
      },
      "tasks": [
        "Stochastic Block Model"
      ]
    },
    {
      "id": "2506.16210",
      "abstract": "In motion-robust magnetic resonance imaging (MRI), slice-to-volume reconstruction is critical for recovering anatomically consistent 3D brain volumes from 2D slices, especially under accelerated acquisitions or patient motion. However, this task remains challenging due to hierarchical structural disruptions. It includes local detail loss from k-space undersampling, global structural aliasing caused by motion, and volumetric anisotropy. Therefore, we propose a progressive refinement implicit neural representation (PR-INR) framework. Our PR-INR unifies motion correction, structural refinement, and volumetric synthesis within a geometry-aware coordinate space. Specifically, a motion-aware diffusion module is first employed to generate coarse volumetric reconstructions that suppress motion artifacts and preserve global anatomical structures. Then, we introduce an implicit detail restoration module that performs residual refinement by aligning spatial coordinates with visual features. It corrects local structures and enhances boundary precision. Further, a voxel continuous-aware representation module represents the image as a continuous function over 3D coordinates. It enables accurate inter-slice completion and high-frequency detail recovery. We evaluate PR-INR on five public MRI datasets under various motion conditions (3% and 5% displacement), undersampling rates (4x and 8x) and slice resolutions (scale = 5). Experimental results demonstrate that PR-INR outperforms state-of-the-art methods in both quantitative reconstruction metrics and visual quality. It further shows generalization and robustness across diverse unseen domains.",
      "authors": [
        "Zhenxuan Zhang",
        "Lipei Zhang",
        "Yanqi Cheng",
        "Zi Wang",
        "Fanwen Wang",
        "Haosen Zhang",
        "Yue Yang",
        "Yinzhe Wu",
        "Jiahao Huang",
        "Angelica I Aviles-Rivero",
        "Zhifan Gao",
        "Guang Yang",
        "Peter J. Lally"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16210",
        "HTML": "https://arxiv.org/html/2506.16210",
        "PDF": "https://arxiv.org/pdf/2506.16210"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 10:58:43 GMT",
          "size": "43036kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:48:10 GMT",
          "size": "42339kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes a method for MRI reconstruction using neural representations and does not engage with LLM training data engineering or processing."
      },
      "tasks": [
        "MRI Reconstruction"
      ]
    },
    {
      "id": "2506.16240",
      "abstract": "Numerical simulations of models and theories that describe complex experimental systems $\\unicode{x2014}$in fields like high-energy and condensed-matter physics$\\unicode{x2014}$ are becoming increasingly important. Examples include lattice gauge theories, which can describe, among others, quantum chromodynamics (the Standard Model description of strong interactions between elementary particles), and spin-glass systems. Beyond fundamental research, these computational methods also find practical applications, among many others, in optimization, finance, and complex biological problems. However, Monte Carlo simulations, an important subcategory of these methods, are plagued by a major drawback: they are extremely greedy for (pseudo) random numbers. The total fraction of computer time dedicated to random-number generation increases as the hardware grows more sophisticated, and can get prohibitive for special-purpose computing platforms. We propose here a general-purpose microcanonical simulated annealing (MicSA) formalism that dramatically reduces such a burden. The algorithm is fully adapted to a massively parallel computation, as we show in the particularly demanding benchmark of the three-dimensional Ising spin glass. We carry out very stringent numerical tests of the new algorithm by comparing our results, obtained on GPUs, with high-precision standard (i.e., random-number-greedy) simulations performed on the Janus II custom-built supercomputer. In those cases where thermal equilibrium is reachable (i.e., in the paramagnetic phase), both simulations reach compatible values. More significantly, barring short-time corrections, a simple time rescaling suffices to map the MicSA off-equilibrium dynamics onto the results obtained with standard simulations.",
      "authors": [
        "M. Bernaschi",
        "L.A. Fernandez",
        "I. Gonz\\'alez-Adalid Pemart\\'in",
        "E. Marinari",
        "V. Martin-Mayor",
        "G. Parisi",
        "F. Ricci-Tersenghi",
        "J.J. Ruiz-Lorenzo and D. Yllanes"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16240",
        "HTML": "https://arxiv.org/html/2506.16240",
        "PDF": "https://arxiv.org/pdf/2506.16240"
      },
      "subjects": [
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Hardware Architecture (cs.AR)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 11:53:17 GMT",
          "size": "567kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:17:29 GMT",
          "size": "568kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Microcanonical simulated annealing: Massively parallel Monte Carlo simulations with sporadic random-number generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on an algorithm for Monte Carlo simulations relevant to high-energy physics, without mention of LLM training data or related processing tasks."
      },
      "repo_urls": [
        "https://github.com/IsidoroGlez/micSA-EA-MC"
      ]
    },
    {
      "id": "2506.16394",
      "abstract": "We study methods for identifying heterogeneous parameter components in distributed M-estimation with minimal data transmission. One is based on a re-normalized Wald test, which is shown to be consistent as long as the number of distributed data blocks $K$ is of a smaller order of the minimum block sample size and the level of heterogeneity is dense. The second one is an extreme contrast test (ECT) based on the difference between the largest and smallest component-wise estimated parameters among data blocks. By introducing a sample splitting procedure, the ECT can avoid the bias accumulation arising from the M-estimation procedures, and exhibits consistency for $K$ being much larger than the sample size while the heterogeneity is sparse. The ECT procedure is easy to operate and communication-efficient. A combination of the Wald and the extreme contrast tests is formulated to attain more robust power under varying levels of sparsity of the heterogeneity. We also conduct intensive numerical experiments to compare the family-wise error rate (FWER) and the power of the proposed methods. Additionally, we conduct a case study to present the implementation and validity of the proposed methods.",
      "authors": [
        "Zelin Xiao",
        "Jia Gu",
        "Song Xi Chen"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16394",
        "HTML": "https://arxiv.org/html/2506.16394",
        "PDF": "https://arxiv.org/pdf/2506.16394"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 15:26:48 GMT",
          "size": "624kb",
          "version": "v1"
        },
        {
          "date": "Mon, 23 Jun 2025 07:08:58 GMT",
          "size": "635kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 23:55:45 GMT",
          "size": "635kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Identifying Heterogeneity in Distributed Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on methods for identifying heterogeneous parameter components in distributed learning, with no mention of LLM training data processing or data engineering."
      },
      "tasks": []
    },
    {
      "id": "2506.17634",
      "abstract": "The interface between stochastic analysis and machine learning is a rapidly evolving field, with path signatures - iterated integrals that provide faithful, hierarchical representations of paths - offering a principled and universal feature map for sequential and structured data. Rooted in rough path theory, path signatures are invariant to reparameterization and well-suited for modelling evolving dynamics, long-range dependencies, and irregular sampling - common challenges in real-world time series and graph data.\n  This thesis investigates how to harness the expressive power of path signatures within scalable machine learning pipelines. It introduces a suite of models that combine theoretical robustness with computational efficiency, bridging rough path theory with probabilistic modelling, deep learning, and kernel methods. Key contributions include: Gaussian processes with signature kernel-based covariance functions for uncertainty-aware time series modelling; the Seq2Tens framework, which employs low-rank tensor structure in the weight space for scalable deep modelling of long-range dependencies; and graph-based models where expected signatures over graphs induce hypo-elliptic diffusion processes, offering expressive yet tractable alternatives to standard graph neural networks. Further developments include Random Fourier Signature Features, a scalable kernel approximation with theoretical guarantees, and Recurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussian processes, signature kernels, and random features with a principled forgetting mechanism for multi-horizon time series forecasting with adaptive context length.\n  We hope this thesis serves as both a methodological toolkit and a conceptual bridge, and provides a useful reference for the current state of the art in scalable, signature-based learning for sequential and structured data.",
      "authors": [
        "Csaba T\\'oth"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17634",
        "HTML": "https://arxiv.org/html/2506.17634",
        "PDF": "https://arxiv.org/pdf/2506.17634"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 08:36:34 GMT",
          "size": "4089kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:58:09 GMT",
          "size": "7389kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Scalable Machine Learning Algorithms using Path Signatures",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The thesis investigates machine learning algorithms using path signatures, focusing on scalability and efficiency, without addressing LLM training data processing."
      }
    },
    {
      "id": "2506.17983",
      "abstract": "Autoregressive Initial Bits is a framework that integrates sub-image autoregression and latent variable modeling, demonstrating its advantages in lossless medical image compression. However, in existing methods, the image segmentation process leads to an even distribution of latent variable information across each sub-image, which in turn causes posterior collapse and inefficient utilization of latent variables. To deal with these issues, we propose a prediction-based end-to-end lossless medical image compression method named LVPNet, leveraging global latent variables to predict pixel values and encoding predicted probabilities for lossless compression. Specifically, we introduce the Global Multi-scale Sensing Module (GMSM), which extracts compact and informative latent representations from the entire image, effectively capturing spatial dependencies within the latent space. Furthermore, to mitigate the information loss introduced during quantization, we propose the Quantization Compensation Module (QCM), which learns the distribution of quantization errors and refines the quantized features to compensate for quantization loss. Extensive experiments on challenging benchmarks demonstrate that our method achieves superior compression efficiency compared to state-of-the-art lossless image compression approaches, while maintaining competitive inference speed. The code is at https://github.com/scy-Jackel/LVPNet.",
      "authors": [
        "Chenyue Song",
        "Chen Hui",
        "Qing Lin",
        "Wei Zhang",
        "Siqiao Li",
        "Haiqi Zhu",
        "Zhixuan Li",
        "Shengping Zhang",
        "Shaohui Liu",
        "Feng Jiang",
        "Xiang Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17983",
        "HTML": "https://arxiv.org/html/2506.17983",
        "PDF": "https://arxiv.org/pdf/2506.17983"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 10:45:35 GMT",
          "size": "2251kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:02:15 GMT",
          "size": "2252kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LVPNet: A Latent-variable-based Prediction-driven End-to-end Framework for Lossless Compression of Medical Images",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research tackles lossless compression of medical images using latent-variable frameworks, unrelated to any aspects of LLM training data processing or enhancement."
      }
    },
    {
      "id": "2506.18392",
      "abstract": "The Peterson hit problem in algebraic topology is to explicitly determine the dimension of the quotient space $Q\\mathcal P_k = \\mathbb F_2\\otimes_{\\mathcal A}\\mathcal P_k$ in positive degrees, where $\\mathcal{P}_k$ denotes the polynomial algebra in $k$ variables over the field $\\mathbb{F}_2$, considered as an unstable module over the Steenrod algebra $\\mathcal{A}$. Current approaches to this problem still rely heavily on manual computations, which are highly prone to errors due to the intricate nature of the underlying calculations. To date, no efficient algorithm implemented in any computer algebra system has been made publicly available to tackle this problem in a systematic manner.\n  Motivated by the above, in this work, which is considered as Part I of our project, we first establish a criterion based entirely on linear algebra for determining whether a given homogeneous polynomial is \"hit\". Accordingly, we describe the dimensions of the hit spaces. This leads to a practical and reliable computational method for determining the dimension of $Q\\mathcal{P}_k$ for arbitrary $k$ and any positive degrees, with the support of a computer algebra system. We then give a concrete implementation of the obtained results as novel algorithms in \\textsc{SageMath}. As an application, our algorithm demonstrates that the manually computed result presented in the recent work of Sum and Tai [15] for the dimension of $Q\\mathcal{P}_5$ in degree $2^{6}$ is not correct. Furthermore, our algorithm determines that $\\dim(Q\\mathcal{P}_5)_{2^{7}} = 1985,$ which falls within the range $1984 \\leq \\dim(Q\\mathcal{P}_5)_{2^{7}} \\leq 1990$ as estimated in [15].",
      "authors": [
        "Dang Vo Phuc"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18392",
        "HTML": "https://arxiv.org/html/2506.18392",
        "PDF": "https://arxiv.org/pdf/2506.18392"
      },
      "subjects": [
        "Algebraic Topology (math.AT)",
        "Symbolic Computation (cs.SC)",
        "Geometric Topology (math.GT)",
        "Rings and Algebras (math.RA)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 08:27:44 GMT",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:27:38 GMT",
          "size": "59kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A matrix criterion and algorithmic approach for the Peterson hit problem: Part I",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is focused on solving the Peterson hit problem in algebraic topology and discusses computational methods related to polynomial space dimensions, with no mention of LLM training data processing."
      }
    },
    {
      "id": "2506.19431",
      "abstract": "We describe CompGIT, a SageMath package to describe Geometric Invariant Theory (GIT) quotients of projective space by simple groups. The implementation is based on algorithms described by Gallardo--Martinez-Garcia--Moon--Swinarski. In principle the package is sufficient to describe any GIT quotient of a projective variety by a simple group -- in practice it requires that the user can construct an equivariant embedding of the polarised variety into projective space. The package describes the non-stable and unstable loci up to conjugation by the group, as well as describing the strictly polystable loci. We discuss potential applications of the outputs of CompGIT to algebraic geometry problems, a well as suggesting directions for future developments.",
      "authors": [
        "Robert Hanson",
        "Jesus Martinez-Garcia"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19431",
        "HTML": "https://arxiv.org/html/2506.19431",
        "PDF": "https://arxiv.org/pdf/2506.19431"
      },
      "subjects": [
        "Algebraic Geometry (math.AG)",
        "Computational Geometry (cs.CG)",
        "Mathematical Software (cs.MS)",
        "Representation Theory (math.RT)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 08:57:50 GMT",
          "size": "21kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:54:21 GMT",
          "size": "21kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The CompGIT package: a computational tool for Geometric Invariant Theory quotients",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a computational tool for Geometric Invariant Theory quotients. There is no mention of LLM training data or data processing tasks."
      }
    },
    {
      "id": "2506.19952",
      "abstract": "Large language models (LLMs), despite their ability to perform few-shot machine translation (MT), often lag behind dedicated MT systems trained on parallel corpora, which are crucial for high quality machine translation (MT). However, parallel corpora are often scarce or non-existent for low-resource languages. In this paper, we propose CycleDistill, a bootstrapping approach leveraging LLMs and few-shot translation to obtain high-quality MT systems. CycleDistill involves iteratively generating synthetic parallel corpora from monolingual corpora via zero- or few-shot MT, which is then used to fine-tune the model that was used for generating said data for MT. CycleDistill does not need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments focusing on three Indian languages, by relying solely on monolingual corpora, it can achieve high-quality machine translation, improving upon a few-shot baseline model by over 20-30 chrF points on average in the first iteration. We also study the effect of leveraging softmax activations during the distillation process and observe mild improvements in translation quality.",
      "authors": [
        "Deepon Halder",
        "Thanmay Jayakumar",
        "Raj Dabre"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19952",
        "HTML": "https://arxiv.org/html/2506.19952",
        "PDF": "https://arxiv.org/pdf/2506.19952"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:56:57 GMT",
          "size": "726kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes CycleDistill, a method to generate synthetic parallel corpora from monolingual corpora using LLMs, specifically addressing the creation and processing of training data for machine translation with LLMs."
      }
    },
    {
      "id": "2506.20057",
      "abstract": "We investigate the use of randomly generated data for the sake of pre-training a model. We justify this approach theoretically from the perspective of algorithmic complexity, building on recent research that shows that sequence models can be trained to approximate Solomonoff induction. We derive similar, but complementary theoretical results. We show empirically that synthetically generated data can be used to pre-train a model before the data is seen. We replicate earlier results that models trained this way show zero-shot in-context learning across a variety of datasets, and that this performance improves with scale. We extend earlier results to real-world data, and show that finetuning a model after pre-training offers faster convergence and better generalization.",
      "authors": [
        "Peter Bloem"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20057",
        "HTML": "https://arxiv.org/html/2506.20057",
        "PDF": "https://arxiv.org/pdf/2506.20057"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:36:35 GMT",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Universal pre-training by iterated random computation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper investigates the concept of using synthetically generated data for pre-training models, involving novel data processing strategies that fall under training-stage data processing relevant to LLMs."
      }
    },
    {
      "id": "2506.20061",
      "abstract": "Developing effective instruction-following policies in reinforcement learning remains challenging due to the reliance on extensive human-labeled instruction datasets and the difficulty of learning from sparse rewards. In this paper, we propose a novel approach that leverages the capabilities of large language models (LLMs) to automatically generate open-ended instructions retrospectively from previously collected agent trajectories. Our core idea is to employ LLMs to relabel unsuccessful trajectories by identifying meaningful subtasks the agent has implicitly accomplished, thereby enriching the agent's training data and substantially alleviating reliance on human annotations. Through this open-ended instruction relabeling, we efficiently learn a unified instruction-following policy capable of handling diverse tasks within a single policy. We empirically evaluate our proposed method in the challenging Craftax environment, demonstrating clear improvements in sample efficiency, instruction coverage, and overall policy performance compared to state-of-the-art baselines. Our results highlight the effectiveness of utilizing LLM-guided open-ended instruction relabeling to enhance instruction-following reinforcement learning.",
      "authors": [
        "Zhicheng Zhang",
        "Ziyan Wang",
        "Yali Du",
        "Fei Fang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20061",
        "HTML": "https://arxiv.org/html/2506.20061",
        "PDF": "https://arxiv.org/pdf/2506.20061"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:49:28 GMT",
          "size": "554kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes a novel method using LLMs to relabel unsuccessful trajectories in instruction-following policies, effectively augmenting training data and reducing reliance on human annotations, which is a direct contribution to LLM training-stage data processing."
      }
    },
    {
      "id": "2506.20151",
      "abstract": "Autoregressive (AR) models have achieved unified and strong performance across both visual understanding and image generation tasks. However, removing undesired concepts from AR models while maintaining overall generation quality remains an open challenge. In this paper, we propose Erasure Autoregressive Model (EAR), a fine-tuning method for effective and utility-preserving concept erasure in AR models. Specifically, we introduce Windowed Gradient Accumulation (WGA) strategy to align patch-level decoding with erasure objectives, and Thresholded Loss Masking (TLM) strategy to protect content unrelated to the target concept during fine-tuning. Furthermore, we propose a novel benchmark, Erase Concept Generator and Visual Filter (ECGVF), aim at provide a more rigorous and comprehensive foundation for evaluating concept erasure in AR models. Specifically, we first employ structured templates across diverse large language models (LLMs) to pre-generate a large-scale corpus of target-replacement concept prompt pairs. Subsequently, we generate images from these prompts and subject them to rigorous filtering via a visual classifier to ensure concept fidelity and alignment. Extensive experimental results conducted on the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR achieves marked improvements in both erasure effectiveness and model utility preservation. Code is available at: https://github.com/immc-lab/ear/",
      "authors": [
        "Haipeng Fan",
        "Shiyuan Zhang",
        "Baohunesitu",
        "Zihang Guo",
        "Huaiwen Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20151",
        "HTML": "https://arxiv.org/html/2506.20151",
        "PDF": "https://arxiv.org/pdf/2506.20151"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:15:07 GMT",
          "size": "10812kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "EAR: Erasing Concepts from Unified Autoregressive Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The EAR method involves fine-tuning autoregressive models for concept erasure, using structured templates across diverse LLMs to create a large-scale corpus. It directly relates to LLM training-stage data processing and assessing model behaviors."
      }
    },
    {
      "id": "2506.20168",
      "abstract": "Recent advancements in multimodal large language models have enhanced document understanding by integrating textual and visual information. However, existing models exhibit incompleteness within their paradigm in real-world scenarios, particularly under visual degradation. In such conditions, the current response paradigm often fails to adequately perceive visual degradation and ambiguity, leading to overreliance on linguistic priors or misaligned visual-textual reasoning. This difficulty in recognizing uncertainty frequently results in the generation of hallucinatory content, especially when a precise answer is not feasible. To better demonstrate and analyze this phenomenon and problem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR hallucination in degraded document understanding. This dataset includes test samples spanning identity cards and invoices, with simulated real-world degradations for OCR reliability. This setup allows for evaluating models' capacity, under degraded input, to distinguish reliable visual information and answer accordingly, thereby highlighting the challenge of avoiding hallucination on uncertain data. To achieve vision-faithful reasoning and thereby avoid the aforementioned issues, we further introduce a GRPO-based framework featuring a novel reward mechanism. By incorporating a self-awareness of visual uncertainty and an analysis method that initiates refusal to answer to increase task difficulty within our supervised fine-tuning and reinforcement learning framework, we successfully mitigated hallucinations in ambiguous regions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model achieves a 22\\% absolute improvement in hallucination-free accuracy over GPT-4o on KIE-HVQA and there is no significant performance drop in standard tasks, highlighting both effectiveness and robustness.",
      "authors": [
        "Zhentao He",
        "Can Zhang",
        "Ziheng Wu",
        "Zhenghao Chen",
        "Yufei Zhan",
        "Yifan Li",
        "Zhao Zhang",
        "Xian Wang",
        "Minghui Qiu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20168",
        "HTML": "https://arxiv.org/html/2506.20168",
        "PDF": "https://arxiv.org/pdf/2506.20168"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:44:07 GMT",
          "size": "9379kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces the KIE-HVQA benchmark to evaluate OCR hallucination in LLMs, specifically focusing on degraded document understanding. It details methods for training-stage data processing, such as supervised fine-tuning and reinforcement learning to mitigate hallucinations."
      }
    },
    {
      "id": "2506.20199",
      "abstract": "Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.",
      "authors": [
        "Mengqi Wang",
        "Tiantian Feng",
        "Shrikanth Narayanan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20199",
        "HTML": "https://arxiv.org/html/2506.20199",
        "PDF": "https://arxiv.org/pdf/2506.20199"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:39:19 GMT",
          "size": "3442kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper investigates methods to enhance conversational emotion recognition through in-context learning by retrieving and processing training examples, directly addressing training-stage data processing for improving LLM applications."
      }
    },
    {
      "id": "2506.20241",
      "abstract": "Recent Large Language Models (LLMs) have significantly advanced natural language processing and automated decision-making. However, these models still encounter difficulties when performing complex reasoning tasks involving logical deduction and systematic planning, primarily due to their reliance on implicit statistical relationships without structured knowledge representation.Inspired by cognitive science and neurosymbolic AI, we introduce a novel approach to enhance LLMs through explicit structured reasoning. First, we convert unstructured data into structured formats by explicitly annotating reasoning steps. We then employ this structured dataset to train LLMs through Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning capabilities of LLMs using Group Relative Policy Optimization (GRPO), incorporating two innovative algorithms--MAX-Flow and Longest Common Subsequence (LCS)--which notably improve reasoning effectiveness and reduce computational complexity. Experimental results from fine-tuning a DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust performance across various scenarios, and improved compatibility with optimization techniques, validating the efficacy of structured reasoning integration in LLMs.",
      "authors": [
        "Yubo Dong",
        "Hehe Fan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20241",
        "HTML": "https://arxiv.org/html/2506.20241",
        "PDF": "https://arxiv.org/pdf/2506.20241"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:36:12 GMT",
          "size": "8851kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Enhancing Large Language Models through Structured Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper focuses on enhancing LLMs through structured reasoning by converting unstructured data into structured formats and training LLMs via Supervised Fine-Tuning (SFT), directly involving data processing for LLM training."
      }
    },
    {
      "id": "2506.20274",
      "abstract": "Large Language Models (LLMs) ) have demonstrated promise in boosting productivity across AI-powered tools, yet existing benchmarks like Massive Multitask Language Understanding (MMLU) inadequately assess enterprise-specific task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy to holistically evaluate LLM capabilities in enterprise contexts. To address challenges of noisy data and costly annotation, we develop a scalable pipeline combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six leading models shows open-source contenders like DeepSeek R1 rival proprietary models in reasoning tasks but lag in judgment-based scenarios, likely due to overthinking. Our benchmark reveals critical enterprise performance gaps and offers actionable insights for model optimization. This work provides enterprises a blueprint for tailored evaluations and advances practical LLM deployment.",
      "authors": [
        "Liya Wang",
        "David Yi",
        "Damien Jose",
        "John Passarelli",
        "James Gao",
        "Jordan Leventis",
        "and Kang Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20274",
        "HTML": "https://arxiv.org/html/2506.20274",
        "PDF": "https://arxiv.org/pdf/2506.20274"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:34:25 GMT",
          "size": "784kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Enterprise Large Language Model Evaluation Benchmark",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper describes the development of a scalable pipeline for curating a benchmark for LLM evaluation, emphasizing data quality enhancement and labeling, which is directly related to the processing of training data for LLMs."
      }
    },
    {
      "id": "2506.20331",
      "abstract": "We introduce Biomed-Enriched, a biomedical text dataset constructed from PubMed via a two-stage annotation process. In the first stage, a large language model annotates 400K paragraphs from PubMed scientific articles, assigning scores for their type (review, study, clinical case, other), domain (clinical, biomedical, other), and educational quality. The educational quality score (rated 1 to 5) estimates how useful a paragraph is for college-level learning. These annotations are then used to fine-tune a small language model, which propagates the labels across the full PMC-OA corpus. The resulting metadata allows us to extract refined subsets, including 2M clinical case paragraphs with over 450K high-quality ones from articles with commercial-use licenses, and to construct several variants via quality filtering and domain upsampling. Clinical text is typically difficult to access due to privacy constraints, as hospital records cannot be publicly shared. Hence, our dataset provides an alternative large-scale, openly available collection of clinical cases from PubMed, making it a valuable resource for biomedical and clinical NLP. Preliminary continual-pretraining experiments with OLMo2 suggest these curated subsets enable targeted improvements, with clinical upsampling boosting performance by ~5% on MMLU ProfMed and educational quality filtering improving MedQA and MedMCQA by ~1%. Combinations of these techniques led to faster convergence, reaching same performance with a third of training tokens, indicating potential for more efficient and effective biomedical pretraining strategies.",
      "authors": [
        "Rian Touchent",
        "Nathan Godey",
        "Eric de la Clergerie"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20331",
        "HTML": "https://arxiv.org/html/2506.20331",
        "PDF": "https://arxiv.org/pdf/2506.20331"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:30:25 GMT",
          "size": "190kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a new dataset, Biomed-Enriched, that enriches biomedical text with LLMs for pretraining, involving detailed data collection and annotation processes directly contributing to data engineering and training-stage data processing for LLMs."
      }
    },
    {
      "id": "2506.20481",
      "abstract": "Machine learning models are known to memorize samples from their training data, raising concerns around privacy and generalization. Counterfactual self-influence is a popular metric to study memorization, quantifying how the model's prediction for a sample changes depending on the sample's inclusion in the training dataset. However, recent work has shown memorization to be affected by factors beyond self-influence, with other training samples, in particular (near-)duplicates, having a large impact. We here study memorization treating counterfactual influence as a distributional quantity, taking into account how all training samples influence how a sample is memorized. For a small language model, we compute the full influence distribution of training samples on each other and analyze its properties. We find that solely looking at self-influence can severely underestimate tangible risks associated with memorization: the presence of (near-)duplicates seriously reduces self-influence, while we find these samples to be (near-)extractable. We observe similar patterns for image classification, where simply looking at the influence distributions reveals the presence of near-duplicates in CIFAR-10. Our findings highlight that memorization stems from complex interactions across training data and is better captured by the full influence distribution than by self-influence alone.",
      "authors": [
        "Matthieu Meeus",
        "Igor Shilov",
        "Georgios Kaissis",
        "Yves-Alexandre de Montjoye"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20481",
        "HTML": "https://arxiv.org/html/2506.20481",
        "PDF": "https://arxiv.org/pdf/2506.20481"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:25:11 GMT",
          "size": "1980kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Counterfactual Influence as a Distributional Quantity",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explores memorization by quantifying the influence of training data samples, including (near-)duplicates, on language models. This relates to data engineering tasks like deduplication and data quality enhancement."
      }
    },
    {
      "id": "2506.20495",
      "abstract": "Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments. To tackle this issue, we propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning. Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture. Code is available at https://github.com/zjunlp/ReCode.",
      "authors": [
        "Haoze Wu",
        "Yunzhi Yao",
        "Wenhao Yu",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20495",
        "HTML": "https://arxiv.org/html/2506.20495",
        "PDF": "https://arxiv.org/pdf/2506.20495"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:41:13 GMT",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ReCode: Updating Code API Knowledge with Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents a novel dataset construction for training LLMs to adapt to code API changes, a clear contribution to data processing for LLM training and fine-tuning in dynamic environments."
      }
    },
    {
      "id": "2506.20512",
      "abstract": "Different base language model families, such as Llama and Qwen, exhibit divergent behaviors during post-training with reinforcement learning (RL), especially on reasoning-intensive tasks. What makes a base language model suitable for reinforcement learning? Gaining deeper insight into this question is essential for developing RL-scalable foundation models of the next generation. In this work, we investigate how mid-training strategies shape RL dynamics, focusing on two representative model families: Qwen and Llama. Our study reveals that (1) high-quality mathematical corpora, such as MegaMath-Web-Pro, significantly improve both base model and RL performance, while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further adding QA-style data, particularly long chain-of-thought (CoT) reasoning examples, enhances RL outcomes, and instruction data further unlocks this effect; (3) while long-CoT improves reasoning depth, it can also induce verbosity of model responses and unstability of RL training, underscoring the importance of data formatting; (4) scaling mid-training consistently leads to stronger downstream RL performance. Building on these insights, we introduce a two-stage mid-training strategy, Stable-then-Decay, in which base models are first trained on 200B tokens with a constant learning rate, followed by 20B tokens across three CoT-focused branches with learning rate decay. This yields OctoThinker, a family of models demonstrating strong RL compatibility and closing the performance gap with more RL-friendly model families, i.e., Qwen. We hope our work will help shape pre-training strategies for foundation models in the RL era. To support further research, we release our open-source models along with a curated math reasoning-intensive corpus of over 70 billion tokens (i.e., MegaMath-Web-Pro-Max).",
      "authors": [
        "Zengzhi Wang and Fan Zhou and Xuefeng Li and Pengfei Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20512",
        "HTML": "https://arxiv.org/html/2506.20512",
        "PDF": "https://arxiv.org/pdf/2506.20512"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:58:13 GMT",
          "size": "2387kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper involves the design and processing of large-scale training data for LLMs by introducing strategies like adding QA-style data and a large math reasoning-intensive corpus (MegaMath-Web-Pro-Max) for RL purposes, which demonstrates a strong involvement in LLM training data processing."
      }
    },
    {
      "id": "2506.20621",
      "abstract": "[Context] The increasing adoption of machine learning (ML) in software systems demands specialized ideation approaches that address ML-specific challenges, including data dependencies, technical feasibility, and alignment between business objectives and probabilistic system behavior. Traditional ideation methods like Lean Inception lack structured support for these ML considerations, which can result in misaligned product visions and unrealistic expectations. [Goal] This paper presents Define-ML, a framework that extends Lean Inception with tailored activities - Data Source Mapping, Feature-to-Data Source Mapping, and ML Mapping - to systematically integrate data and technical constraints into early-stage ML product ideation. [Method] We developed and validated Define-ML following the Technology Transfer Model, conducting both static validation (with a toy problem) and dynamic validation (in a real-world industrial case study). The analysis combined quantitative surveys with qualitative feedback, assessing utility, ease of use, and intent of adoption. [Results] Participants found Define-ML effective for clarifying data concerns, aligning ML capabilities with business goals, and fostering cross-functional collaboration. The approach's structured activities reduced ideation ambiguity, though some noted a learning curve for ML-specific components, which can be mitigated by expert facilitation. All participants expressed the intention to adopt Define-ML. [Conclusion] Define-ML provides an openly available, validated approach for ML product ideation, building on Lean Inception's agility while aligning features with available data and increasing awareness of technical feasibility.",
      "authors": [
        "Silvio Alonso",
        "Antonio Pedro Santos Alves",
        "Lucas Romao",
        "H\\'elio Lopes",
        "Marcos Kalinowski"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20621",
        "HTML": "https://arxiv.org/html/2506.20621",
        "PDF": "https://arxiv.org/pdf/2506.20621"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:11:26 GMT",
          "size": "1062kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Define-ML: An Approach to Ideate Machine Learning-Enabled Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents a framework (Define-ML) for integrating data considerations into early-stage ML product ideation. It emphasizes the systematic integration of data and technical constraints, implicitly involving data engineering aspects for LLM systems."
      }
    },
    {
      "id": "2506.20629",
      "abstract": "Low-Rank Adaptation (LoRA) is a widely used finetuning method for large models. Its small memory footprint allows practitioners to adapt large models to specific tasks at a fraction of the cost of full finetuning. Different modifications have been proposed to enhance its efficiency by, for example, setting the learning rate, the rank, and the initialization. Another improvement axis is adapter placement strategy: when using LoRA, practitioners usually pick module types to adapt with LoRA, such as Query and Key modules. Few works have studied the problem of adapter placement, with nonconclusive results: original LoRA paper suggested placing adapters in attention modules, while other works suggested placing them in the MLP modules. Through an intuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a lightweight method that allows automatic identification of module types where LoRA adapters should be placed, given a pretrained model and a finetuning task. We demonstrate that PLoP consistently outperforms, and in the worst case competes, with commonly used placement strategies through comprehensive experiments on supervised finetuning and reinforcement learning for reasoning.",
      "authors": [
        "Soufiane Hayou",
        "Nikhil Ghosh",
        "Bin Yu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20629",
        "HTML": "https://arxiv.org/html/2506.20629",
        "PDF": "https://arxiv.org/pdf/2506.20629"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:25:02 GMT",
          "size": "3256kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper introduces PLoP, a method for precise LoRA adapter placement, which is a significant contribution to the fine-tuning stage of large models, directly related to data processing for LLM training."
      }
    },
    {
      "id": "2506.20639",
      "abstract": "Diffusion large language models (dLLMs) are compelling alternatives to autoregressive (AR) models because their denoising models operate over the entire sequence. The global planning and iterative refinement features of dLLMs are particularly useful for code generation. However, current training and inference mechanisms for dLLMs in coding are still under-explored. To demystify the decoding behavior of dLLMs and unlock their potential for coding, we systematically investigate their denoising processes and reinforcement learning (RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code. Using this model as a testbed, we analyze its decoding behavior, revealing how it differs from that of AR models: (1) dLLMs can decide how causal their generation should be without relying on semi-AR decoding, and (2) increasing the sampling temperature diversifies not only token choices but also their generation order. This diversity creates a rich search space for RL rollouts. For RL training, to reduce the variance of token log-likelihood estimates and maintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel sampling scheme that constructs complementary mask noise for completions used in training. In our experiments, coupled-GRPO significantly improves DiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and reduces reliance on AR causal during decoding. Our work provides deeper insight into the machinery of dLLM generation and offers an effective, diffusion-native RL training framework. https://github.com/apple/ml-diffucoder.",
      "authors": [
        "Shansan Gong and Ruixiang Zhang and Huangjie Zheng and Jiatao Gu and Navdeep Jaitly and Lingpeng Kong and Yizhe Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20639",
        "HTML": "https://arxiv.org/html/2506.20639",
        "PDF": "https://arxiv.org/pdf/2506.20639"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:35:47 GMT",
          "size": "2004kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper involves training a large language model ('DiffuCoder') on 130B tokens of code and proposes new methods for reinforcement learning, focusing on the training process of LLMs for code generation."
      }
    },
    {
      "id": "2506.20573",
      "abstract": "The widespread availability of large public datasets is a key factor behind the recent successes of statistical inference and machine learning methods. However, these datasets often contain some low-quality or contaminated data, to which many learning procedures are sensitive. Therefore, the question of whether and how public datasets should be prefiltered to facilitate accurate downstream learning arises. On a technical level this requires the construction of principled data prefiltering methods which are learner-agnostic robust, in the sense of provably protecting a set of pre-specified downstream learners from corrupted data. In this work, we formalize the problem of Learner-Agnostic Robust data Prefiltering (LARP), which aims at finding prefiltering procedures that minimize a worst-case loss over a pre-specified set of learners. We first instantiate our framework in the context of scalar mean estimation with Huber estimators under the Huber data contamination model. We provide a hardness result on a specific problem instance and analyze several natural prefiltering procedures. Our theoretical results indicate that performing LARP on a heterogeneous set of learners leads to some loss in model performance compared to the alternative of prefiltering data for each learner/use-case individually. We explore the resulting utility loss and its dependence on the problem parameters via extensive experiments on real-world image and tabular data, observing statistically significant reduction in utility. Finally, we model the trade-off between the utility drop and the cost of repeated (learner-specific) prefiltering within a game-theoretic framework and showcase benefits of LARP for large datasets.",
      "authors": [
        "Kristian Minchev",
        "Dimitar Iliev Dimitrov",
        "Nikola Konstantinov"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20573",
        "HTML": "https://arxiv.org/html/2506.20573",
        "PDF": "https://arxiv.org/pdf/2506.20573"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:07:59 GMT",
          "size": "110kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LARP: Learner-Agnostic Robust Data Prefiltering",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces Learner-Agnostic Robust Data Prefiltering (LARP), focusing on constructing methods for robust data prefiltering which can enhance data quality for downstream learning, thus directly related to data processing for machine learning models."
      }
    },
    {
      "id": "2406.11898",
      "abstract": "Knowledge Graph Completion (KGC) attempts to predict missing facts in a Knowledge Graph (KG). Recently, there's been an increased focus on designing KGC methods that can excel in the inductive setting, where a portion or all of the entities and relations seen in inference are unobserved during training. Numerous benchmark datasets have been proposed for inductive KGC, all of which are subsets of existing KGs used for transductive KGC. However, we find that the current procedure for constructing inductive KGC datasets inadvertently creates a shortcut that can be exploited even while disregarding the relational information. Specifically, we observe that the Personalized PageRank (PPR) score can achieve strong or near SOTA performance on most datasets. In this paper, we study the root cause of this problem. Using these insights, we propose an alternative strategy for constructing inductive KGC datasets that helps mitigate the PPR shortcut. We then benchmark multiple popular methods using the newly constructed datasets and analyze their performance. The new benchmark datasets help promote a better understanding of the capabilities and challenges of inductive KGC by removing any shortcuts that obfuscate performance. The code and dataset and can be found at https://github.com/HarryShomer/Better-Inductive-KGC.",
      "authors": [
        "Harry Shomer",
        "Jay Revolinsky",
        "Jiliang Tang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.11898",
        "HTML": "https://arxiv.org/html/2406.11898",
        "PDF": "https://arxiv.org/pdf/2406.11898"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 14 Jun 2024 21:01:46 GMT",
          "size": "1314kb",
          "version": "v1"
        },
        {
          "date": "Sun, 06 Oct 2024 07:06:34 GMT",
          "size": "2101kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 21:16:19 GMT",
          "size": "1525kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Towards Better Benchmark Datasets for Inductive Knowledge Graph Completion",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes an alternative strategy for constructing inductive Knowledge Graph Completion (KGC) datasets to improve benchmarking and remove shortcuts. This contribution relates to data construction and enhancement of dataset quality, making it relevant to data engineering for LLMs."
      },
      "tasks": [
        "Inductive knowledge graph completion",
        "Knowledge Graph Completion"
      ],
      "repo_urls": [
        "https://github.com/HarryShomer/Better-Inductive-KGC"
      ]
    },
    {
      "id": "2502.11962",
      "abstract": "Instruction fine-tuning (IFT) can increase the informativeness of large language models (LLMs), but may reduce their truthfulness. This trade-off arises because IFT steers LLMs to generate responses containing long-tail knowledge that was not well covered during pre-training. As a result, models become more informative but less accurate when generalizing to unseen tasks. In this paper, we empirically demonstrate how unfamiliar knowledge in IFT datasets can negatively affect the truthfulness of LLMs, and we introduce two new IFT paradigms, $UNIT_{cut}$ and $UNIT_{ref}$, to address this issue. $UNIT_{cut}$ identifies and removes unfamiliar knowledge from IFT datasets to mitigate its impact on model truthfulness, whereas $UNIT_{ref}$ trains LLMs to recognize their uncertainty and explicitly indicate it at the end of their responses. Our experiments show that $UNIT_{cut}$ substantially improves LLM truthfulness, while $UNIT_{ref}$ maintains high informativeness and reduces hallucinations by distinguishing between confident and uncertain statements.",
      "authors": [
        "Tianyi Wu",
        "Jingwei Ni",
        "Bryan Hooi",
        "Jiaheng Zhang",
        "Elliott Ash",
        "See-Kiong Ng",
        "Mrinmaya Sachan",
        "Markus Leippold"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11962",
        "HTML": "https://arxiv.org/html/2502.11962",
        "PDF": "https://arxiv.org/pdf/2502.11962"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Feb 2025 16:10:30 GMT",
          "size": "9302kb",
          "version": "v1"
        },
        {
          "date": "Sun, 25 May 2025 19:39:50 GMT",
          "size": "9951kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 09:51:33 GMT",
          "size": "9951kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Balancing Truthfulness and Informativeness with Uncertainty-Aware Instruction Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes new instruction fine-tuning paradigms ($UNIT_{cut}$ and $UNIT_{ref}$) that involve processing IFT datasets to improve LLM truthfulness, directly involving training-stage data processing tasks."
      },
      "tasks": []
    },
    {
      "id": "2503.02502",
      "abstract": "Long-context modeling has drawn more and more attention in the area of Large Language Models (LLMs). Continual training with long-context data becomes the de-facto method to equip LLMs with the ability to process long inputs. However, it still remains an open challenge to measure the quality of long-context training data. To address this issue, we propose a Long-context data selection framework with Attention-based Dependency Measurement (LADM), which can efficiently identify high-quality long-context data from a large-scale, multi-domain pre-training corpus. LADM leverages the retrieval capabilities of the attention mechanism to capture contextual dependencies, ensuring a comprehensive quality measurement of long-context data. Experimental results show that our LADM framework significantly boosts the performance of LLMs on multiple long-context tasks with only 1B tokens for continual training.",
      "authors": [
        "Jianghao Chen",
        "Junhong Wu",
        "Yangyifan Xu",
        "Jiajun Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02502",
        "HTML": "https://arxiv.org/html/2503.02502",
        "PDF": "https://arxiv.org/pdf/2503.02502"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Mar 2025 11:10:13 GMT",
          "size": "7065kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 09:27:33 GMT",
          "size": "3354kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a novel framework, LADM, specifically for selecting long-context training data for LLMs. The framework addresses data quality in a large-scale, multi-domain pre-training corpus, which is directly related to processing LLM training data."
      },
      "models": [
        {
          "model_path": "UltraRonin/Long-Attn-Calculator",
          "downloads": "43",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/UltraRonin/Long-Attn-Calculator"
        }
      ],
      "datasets": [
        {
          "dataset_name": "UltraRonin/pile-LlamaTokenizerFast-32k-truncated-toy",
          "downloads": "102",
          "likes": "0",
          "link": "https://huggingface.co/datasets/UltraRonin/pile-LlamaTokenizerFast-32k-truncated-toy"
        }
      ],
      "tasks": []
    },
    {
      "id": "2503.08727",
      "abstract": "Dynamically integrating new or rapidly evolving information after (Large) Language Model pre-training remains challenging, particularly in low-data scenarios or when dealing with private and specialized documents. In-context learning and retrieval-augmented generation (RAG) face limitations, including their high inference costs and their inability to capture global document information. In this paper, we propose a way of modularizing knowledge by training document-level Knowledge Modules (KMs). KMs are lightweight components implemented as parameter-efficient LoRA modules, which are trained to store information about new documents and can be easily plugged into models on demand. We show that next-token prediction performs poorly as the training objective for KMs. We instead propose Deep Context Distillation: we learn KMs parameters such as to simulate hidden states and logits of a teacher that takes the document in context. Our method outperforms standard next-token prediction and pre-instruction training techniques, across two datasets. Finally, we highlight synergies between KMs and RAG.",
      "authors": [
        "Lucas Caccia",
        "Alan Ansell",
        "Edoardo Ponti",
        "Ivan Vuli\\'c",
        "Alessandro Sordoni"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08727",
        "HTML": "https://arxiv.org/html/2503.08727",
        "PDF": "https://arxiv.org/pdf/2503.08727"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 11 Mar 2025 01:07:57 GMT",
          "size": "68kb",
          "version": "v1"
        },
        {
          "date": "Tue, 29 Apr 2025 17:11:44 GMT",
          "size": "731kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 14:45:56 GMT",
          "size": "147kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Training Plug-n-Play Knowledge Modules with Deep Context Distillation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses modularizing knowledge and training document-level Knowledge Modules (KMs) using Deep Context Distillation, which directly pertains to the processing and preparation of training data for LLMs post-training, particularly in low-data scenarios."
      },
      "tasks": [
        "In-Context Learning",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ]
    },
    {
      "id": "2505.12434",
      "abstract": "Reinforcement fine-tuning (RFT) has shown great promise in achieving humanlevel reasoning capabilities of Large Language Models (LLMs), and has recently been extended to MLLMs. Nevertheless, reasoning about videos, which is a fundamental aspect of human intelligence, remains a persistent challenge due to the complex logic, temporal and causal structures inherent in video data. To fill this gap, we propose VIDEORFT, a novel approach that extends the RFT paradigm to cultivate human-like video reasoning capabilities in MLLMs. VIDEORFT follows the standard two-stage scheme in RFT: supervised fine-tuning (SFT) with chain-of-thought (CoT) annotations, followed by reinforcement learning (RL) to improve generalization. A central challenge to achieve this in the video domain lies in the scarcity of large-scale, high-quality video CoT datasets. We address this by building a fully automatic CoT curation pipeline. First, we devise a cognitioninspired prompting strategy to elicit a reasoning LLM to generate preliminary CoTs based solely on rich, structured, and literal representations of video content. Subsequently, these CoTs are revised by a visual-language model conditioned on the actual video, ensuring visual consistency and reducing visual hallucinations. This pipeline results in two new datasets - VideoRFT-CoT-102K for SFT and VideoRFT-RL-310K for RL. To further strengthen the RL phase, we introduce a novel semantic-consistency reward that explicitly promotes the alignment between textual reasoning and visual evidence. This reward encourages the model to produce coherent, context-aware reasoning outputs grounded in visual input. Extensive experiments show that VIDEORFT achieves state-of-the-art performance on six video reasoning benchmarks.",
      "authors": [
        "Qi Wang",
        "Yanrui Yu",
        "Ye Yuan",
        "Rui Mao",
        "Tianfei Zhou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12434",
        "HTML": "https://arxiv.org/html/2505.12434",
        "PDF": "https://arxiv.org/pdf/2505.12434"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 18 May 2025 14:14:35 GMT",
          "size": "10463kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 07:35:51 GMT",
          "size": "10987kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper's primary contribution is the construction of a novel video CoT curation pipeline to create high-quality datasets (VideoRFT-CoT-102K and VideoRFT-RL-310K) for fine-tuning LLMs, directly addressing the challenges in large-scale data generation and processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/qiwang98/videorft"
      ]
    },
    {
      "id": "2505.16065",
      "abstract": "Embedding-Based Retrieval (EBR) is an important technique in modern search engines, enabling semantic match between search queries and relevant results. However, search logging data on platforms like Facebook Marketplace lacks the diversity and details needed for effective EBR model training, limiting the models' ability to capture nuanced search patterns. To address this challenge, we propose Aug2Search, an EBR-based framework leveraging synthetic data generated by Generative AI (GenAI) models, in a multimodal and multitask approach to optimize query-product relevance. This paper investigates the capabilities of GenAI, particularly Large Language Models (LLMs), in generating high-quality synthetic data, and analyzing its impact on enhancing EBR models. We conducted experiments using eight Llama models and 100 million data points from Facebook Marketplace logs. Our synthetic data generation follows three strategies: (1) generate queries, (2) enhance product listings, and (3) generate queries from enhanced listings. We train EBR models on three different datasets: sampled engagement data or original data ((e.g., \"Click\" and \"Listing Interactions\")), synthetic data, and a mixture of both engagement and synthetic data to assess their performance across various training sets. Our findings underscore the robustness of Llama models in producing synthetic queries and listings with high coherence, relevance, and diversity, while maintaining low levels of hallucination. Aug2Search achieves an improvement of up to 4% in ROC_AUC with 100 million synthetic data samples, demonstrating the effectiveness of our approach. Moreover, our experiments reveal that with the same volume of training data, models trained exclusively on synthetic data often outperform those trained on original data only or a mixture of original and synthetic data.",
      "authors": [
        "Ruijie Xi",
        "He Ba",
        "Hao Yuan",
        "Rishu Agrawal",
        "Yuxin Tian",
        "Ruoyan Kong",
        "Arul Prakash"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16065",
        "HTML": "https://arxiv.org/html/2505.16065",
        "PDF": "https://arxiv.org/pdf/2505.16065"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 21 May 2025 22:33:40 GMT",
          "size": "558kb",
          "version": "v1"
        },
        {
          "date": "Wed, 18 Jun 2025 17:04:04 GMT",
          "size": "558kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 18:46:45 GMT",
          "size": "558kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper primarily focuses on generating synthetic training data using LLMs to enhance EBR models, describing processes like query generation, product listing enhancement, and analysis of their impact on model training."
      },
      "tasks": [
        "Data Augmentation",
        "Diversity",
        "Hallucination",
        "Synthetic Data Generation"
      ]
    },
    {
      "id": "2505.23018",
      "abstract": "In recent years, emotion recognition plays a critical role in applications such as human-computer interaction, mental health monitoring, and sentiment analysis. While datasets for emotion analysis in languages such as English have proliferated, there remains a pressing need for high-quality, comprehensive datasets tailored to the unique linguistic, cultural, and multimodal characteristics of Chinese. In this work, we propose \\textbf{EmotionTalk}, an interactive Chinese multimodal emotion dataset with rich annotations. This dataset provides multimodal information from 19 actors participating in dyadic conversational settings, incorporating acoustic, visual, and textual modalities. It includes 23.6 hours of speech (19,250 utterances), annotations for 7 utterance-level emotion categories (happy, surprise, sad, disgust, anger, fear, and neutral), 5-dimensional sentiment labels (negative, weakly negative, neutral, weakly positive, and positive) and 4-dimensional speech captions (speaker, speaking style, emotion and overall). The dataset is well-suited for research on unimodal and multimodal emotion recognition, missing modality challenges, and speech captioning tasks. To our knowledge, it represents the first high-quality and versatile Chinese dialogue multimodal emotion dataset, which is a valuable contribution to research on cross-cultural emotion analysis and recognition. Additionally, we conduct experiments on EmotionTalk to demonstrate the effectiveness and quality of the dataset. It will be open-source and freely available for all academic purposes. The dataset and codes will be made available at: https://github.com/NKU-HLT/EmotionTalk.",
      "authors": [
        "Haoqin Sun",
        "Xuechen Wang",
        "Jinghua Zhao",
        "Shiwan Zhao",
        "Jiaming Zhou",
        "Hui Wang",
        "Jiabei He",
        "Aobo Kong",
        "Xi Yang",
        "Yequan Wang",
        "Yonghua Lin",
        "Yong Qin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23018",
        "HTML": "https://arxiv.org/html/2505.23018",
        "PDF": "https://arxiv.org/pdf/2505.23018"
      },
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 29 May 2025 02:56:08 GMT",
          "size": "984kb",
          "version": "v1"
        },
        {
          "date": "Fri, 30 May 2025 05:09:13 GMT",
          "size": "984kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 09:38:19 GMT",
          "size": "984kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "EmotionTalk: An Interactive Chinese Multimodal Emotion Dataset With Rich Annotations",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces EmotionTalk, a comprehensive Chinese multimodal emotion dataset with rich annotations, directly relevant to the construction and processing of training data for LLMs, particularly for emotion recognition tasks."
      },
      "repo_urls": [
        "https://github.com/nku-hlt/emotiontalk"
      ]
    },
    {
      "id": "2506.04689",
      "abstract": "Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet so far. However, this pool of natural data does not grow at the same rate as the compute supply. Furthermore, the availability of high-quality texts is even more limited: data filtering pipelines often remove up to 99% of the initial web scrapes to achieve state-of-the-art. To address the \"data wall\" of pre-training scaling, our work explores ways to transform and recycle data discarded in existing filtering processes. We propose REWIRE, REcycling the Web with guIded REwrite, a method to enrich low-quality documents so that they could become useful for training. This in turn allows us to increase the representation of synthetic data in the final pre-training set. Experiments at 1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw texts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points improvement respectively across 22 diverse tasks, compared to training on only filtered web data. Training on the raw-synthetic data mix is also more effective than having access to 2x web data. Through further analysis, we demonstrate that about 82% of the mixed in texts come from transforming lower-quality documents that would otherwise be discarded. REWIRE also outperforms related approaches of generating synthetic data, including Wikipedia-style paraphrasing, question-answer synthesizing and knowledge extraction. These results suggest that recycling web texts holds the potential for being a simple and effective approach for scaling pre-training data.",
      "authors": [
        "Thao Nguyen",
        "Yang Li",
        "Olga Golovneva",
        "Luke Zettlemoyer",
        "Sewoong Oh",
        "Ludwig Schmidt",
        "Xian Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04689",
        "HTML": "https://arxiv.org/html/2506.04689",
        "PDF": "https://arxiv.org/pdf/2506.04689"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Jun 2025 07:12:12 GMT",
          "size": "1252kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:12:12 GMT",
          "size": "1252kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper contributes a novel method (REWIRE) for transforming and recycling discarded web data to enhance pre-training data quality and quantity for language models, directly addressing data filtering and enrichment in LLM data engineering."
      },
      "tasks": []
    },
    {
      "id": "2506.14293",
      "abstract": "We present Sleeping-DISCO 9M, a large-scale pre-training dataset for music and song. To the best of our knowledge, there are no open-source high-quality dataset representing popular and well-known songs for generative music modeling tasks such as text-music, music-captioning, singing-voice synthesis, melody reconstruction and cross-model retrieval. Past contributions focused on isolated and constrained factors whose core perspective was to create synthetic or re-recorded music corpus (e.g. GTSinger, M4Singer) and arbitrarily large-scale audio datasets (e.g. DISCO-10M and LAIONDISCO-12M) had been another focus for the community. Unfortunately, adoption of these datasets has been below substantial in the generative music community as these datasets fail to reflect real-world music and its flavour. Our dataset changes this narrative and provides a dataset that is constructed using actual popular music and world-renowned artists.",
      "authors": [
        "Tawsif Ahmed",
        "Andrej Radonjic",
        "Gollam Rabby"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14293",
        "HTML": "https://arxiv.org/html/2506.14293",
        "PDF": "https://arxiv.org/pdf/2506.14293"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 08:08:08 GMT",
          "size": "380kb",
          "version": "v1"
        },
        {
          "date": "Mon, 23 Jun 2025 18:39:59 GMT",
          "size": "380kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 08:18:37 GMT",
          "size": "380kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper's primary contribution involves the creation of 'Sleeping-DISCO 9M', a large-scale dataset for pre-training generative music models, which falls within training data processing by constructing a novel dataset for model training."
      },
      "datasets": [
        {
          "dataset_name": "sleeping-ai/Sleeping-DISCO-9M",
          "downloads": "707",
          "likes": "7",
          "link": "https://huggingface.co/datasets/sleeping-ai/Sleeping-DISCO-9M"
        }
      ],
      "tasks": [
        "Music Captioning",
        "Music Modeling",
        "Singing Voice Synthesis"
      ]
    },
    {
      "id": "2506.18023",
      "abstract": "This report introduces PP-DocBee2, an advanced version of the PP-DocBee, designed to enhance multimodal document understanding. Built on a large multimodal model architecture, PP-DocBee2 addresses the limitations of its predecessor through key technological improvements, including enhanced synthetic data quality, improved visual feature fusion strategy, and optimized inference methodologies. These enhancements yield an $11.4\\%$ performance boost on internal benchmarks for Chinese business documents, and reduce inference latency by $73.0\\%$ to the vanilla version. A key innovation of our work is a data quality optimization strategy for multimodal document tasks. By employing a large-scale multimodal pre-trained model to evaluate data, we apply a novel statistical criterion to filter outliers, ensuring high-quality training data. Inspired by insights into underutilized intermediate features in multimodal models, we enhance the ViT representational capacity by decomposing it into layers and applying a novel feature fusion strategy to improve complex reasoning. The source code and pre-trained model are available at \\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.",
      "authors": [
        "Kui Huang",
        "Xinrong Chen",
        "Wenyu Lv",
        "Jincheng Liao",
        "Guanzhong Wang",
        "Yi Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18023",
        "HTML": "https://arxiv.org/html/2506.18023",
        "PDF": "https://arxiv.org/pdf/2506.18023"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 13:06:13 GMT",
          "size": "132kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:40:39 GMT",
          "size": "132kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper contributes significantly to data quality optimization for multimodal document understanding by proposing a method for filtering and enhancing synthetic data. It involves data processing strategies relevant to LLM training stages, such as ensuring high-quality training data."
      }
    },
    {
      "id": "2506.18871",
      "abstract": "In this work, we introduce OmniGen2, a versatile and open-source generative model designed to provide a unified solution for diverse generation tasks, including text-to-image, image editing, and in-context generation. Unlike OmniGen v1, OmniGen2 features two distinct decoding pathways for text and image modalities, utilizing unshared parameters and a decoupled image tokenizer. This design enables OmniGen2 to build upon existing multimodal understanding models without the need to re-adapt VAE inputs, thereby preserving the original text generation capabilities. To facilitate the training of OmniGen2, we developed comprehensive data construction pipelines, encompassing image editing and in-context generation data. Additionally, we introduce a reflection mechanism tailored for image generation tasks and curate a dedicated reflection dataset based on OmniGen2. Despite its relatively modest parameter size, OmniGen2 achieves competitive results on multiple task benchmarks, including text-to-image and image editing. To further evaluate in-context generation, also referred to as subject-driven tasks, we introduce a new benchmark named OmniContext. OmniGen2 achieves state-of-the-art performance among open-source models in terms of consistency. We will release our models, training code, datasets, and data construction pipeline to support future research in this field. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link: https://github.com/VectorSpaceLab/OmniGen2",
      "authors": [
        "Chenyuan Wu",
        "Pengfei Zheng",
        "Ruiran Yan",
        "Shitao Xiao",
        "Xin Luo",
        "Yueze Wang",
        "Wanli Li",
        "Xiyan Jiang",
        "Yexin Liu",
        "Junjie Zhou",
        "Ze Liu",
        "Ziyi Xia",
        "Chaofan Li",
        "Haoge Deng",
        "Jiahao Wang",
        "Kun Luo",
        "Bo Zhang",
        "Defu Lian",
        "Xinlong Wang",
        "Zhongyuan Wang",
        "Tiejun Huang",
        "Zheng Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18871",
        "HTML": "https://arxiv.org/html/2506.18871",
        "PDF": "https://arxiv.org/pdf/2506.18871"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 17:38:54 GMT",
          "size": "13203kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:54:25 GMT",
          "size": "13203kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "OmniGen2: Exploration to Advanced Multimodal Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper describes the development of comprehensive data construction pipelines, specifically for image editing and in-context generation data, which are crucial for training the OmniGen2 model. This indicates a significant focus on the processing and preparation of training data."
      },
      "models": [
        {
          "model_path": "OmniGen2/OmniGen2",
          "downloads": "1150",
          "likes": "144",
          "trending_score": "137.0",
          "link": "https://huggingface.co/OmniGen2/OmniGen2"
        },
        {
          "model_path": "jobs-git/OmniGen2",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/jobs-git/OmniGen2"
        }
      ]
    },
    {
      "id": "2506.19262",
      "abstract": "With the remarkable generative capabilities of large language models (LLMs), using LLM-generated data to train downstream models has emerged as a promising approach to mitigate data scarcity in specific domains and reduce time-consuming annotations. However, recent studies have highlighted a critical issue: iterative training on self-generated data results in model collapse, where model performance degrades over time. Despite extensive research on the implications of LLM-generated data, these works often neglect the importance of data diversity, a key factor in data quality. In this work, we aim to understand the implications of the diversity of LLM-generated data on downstream model performance. Specifically, we explore how varying levels of diversity in LLM-generated data affect downstream model performance. Additionally, we investigate the performance of models trained on data that mixes different proportions of LLM-generated data, which we refer to as synthetic data. Our experimental results show that, with minimal distribution shift, moderately diverse LLM-generated data can enhance model performance in scenarios with insufficient labeled data, whereas highly diverse generated data has a negative impact. We hope our empirical findings will offer valuable guidance for future studies on LLMs as data generators.",
      "authors": [
        "Yuchang Zhu",
        "Huazhen Zhong",
        "Qunshu Lin",
        "Haotong Wei",
        "Xiaolong Sun",
        "Zixuan Yu",
        "Minghao Liu",
        "Zibin Zheng",
        "Liang Chen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19262",
        "HTML": "https://arxiv.org/html/2506.19262",
        "PDF": "https://arxiv.org/pdf/2506.19262"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 02:44:58 GMT",
          "size": "625kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 03:25:04 GMT",
          "size": "625kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "What Matters in LLM-generated Data: Diversity and Its Effect on Model Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper examines the diversity and its impact on model fine-tuning, specifically addressing the use of LLM-generated data as a training strategy to enhance downstream model performance. It highlights methods for using synthetic data from LLM outputs, which is directly related to LLM data processing."
      }
    },
    {
      "id": "2506.16571",
      "abstract": "Prior natural language datasets for data visualization have focused on tasks such as visualization literacy assessment, insight generation, and visualization generation from natural language instructions. These studies often rely on controlled setups with purpose-built visualizations and artificially constructed questions. As a result, they tend to prioritize the interpretation of visualizations, focusing on decoding visualizations rather than understanding their encoding. In this paper, we present a new dataset and methodology for probing visualization design rationale through natural language. We leverage a unique source of real-world visualizations and natural language narratives: literate visualization notebooks created by students as part of a data visualization course. These notebooks combine visual artifacts with design exposition, in which students make explicit the rationale behind their design decisions. We also use large language models (LLMs) to generate and categorize question-answer-rationale triples from the narratives and articulations in the notebooks. We then carefully validate the triples and curate a dataset that captures and distills the visualization design choices and corresponding rationales of the students.",
      "authors": [
        "Maeve Hutchinson",
        "Radu Jianu",
        "Aidan Slingsby",
        "Jo Wood and Pranava Madhyastha"
      ],
      "last_revised_date": "2025/06/19",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16571",
        "HTML": "https://arxiv.org/html/2506.16571",
        "PDF": "https://arxiv.org/pdf/2506.16571"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 19:52:53 GMT",
          "size": "22329kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/19",
      "title": "Capturing Visualization Design Rationale",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper involves the use of LLMs for generating and categorizing datasets, it does not propose new methods for LLM training data processing or enhancement."
      }
    },
    {
      "id": "2407.05502",
      "abstract": "Although the multilingual capability of LLMs offers new opportunities to overcome the language barrier, do these capabilities translate into real-life scenarios where linguistic divide and knowledge conflicts between multilingual sources are known occurrences? In this paper, we studied LLM's linguistic preference in a cross-language RAG-based information search setting. We found that LLMs displayed systemic bias towards information in the same language as the query language in both document retrieval and answer generation. Furthermore, in scenarios where no information is in the language of the query, LLMs prefer documents in high-resource languages during generation, potentially reinforcing the dominant views. Such bias exists for both factual and opinion-based queries. Our results highlight the linguistic divide within multilingual LLMs in information search systems. The seemingly beneficial multilingual capability of LLMs may backfire on information parity by reinforcing language-specific information cocoons or filter bubbles further marginalizing low-resource views.",
      "authors": [
        "Nikhil Sharma",
        "Kenton Murray and Ziang Xiao"
      ],
      "last_revised_date": "2025/02/11",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.05502",
        "HTML": "https://arxiv.org/html/2407.05502",
        "PDF": "https://arxiv.org/pdf/2407.05502"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 07 Jul 2024 21:26:36 GMT",
          "size": "2924kb",
          "version": "v1"
        },
        {
          "date": "Mon, 05 Aug 2024 07:22:58 GMT",
          "size": "2974kb",
          "version": "v2"
        },
        {
          "date": "Tue, 11 Feb 2025 18:17:53 GMT",
          "size": "3163kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/02/11",
      "title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses biases in multilingual LLMs without proposing specific methods for training data processing, mainly focusing on language preferences in information retrieval."
      },
      "tasks": [
        "Answer Generation",
        "Information Retrieval",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ]
    },
    {
      "id": "2506.18221",
      "abstract": "Transfer learning is a cornerstone of modern machine learning, promising a way to adapt models pretrained on a broad mix of data to new tasks with minimal new data. However, a significant challenge remains in ensuring that transferred features are sufficient to handle unseen datasets, amplified by the difficulty of quantifying whether two tasks are \"related\". To address these challenges, we evaluate model transfer from a pretraining mixture to each of its component tasks, assessing whether pretrained features can match the performance of task-specific direct training. We identify a fundamental limitation in deep learning models -- an \"information saturation bottleneck\" -- where networks fail to learn new features once they encode similar competing features during training. When restricted to learning only a subset of key features during pretraining, models will permanently lose critical features for transfer and perform inconsistently on data distributions, even components of the training mixture. Empirical evidence from published studies suggests that this phenomenon is pervasive in deep learning architectures -- factors such as data distribution or ordering affect the features that current representation learning methods can learn over time. This study suggests that relying solely on large-scale networks may not be as effective as focusing on task-specific training, when available. We propose richer feature representations as a potential solution to better generalize across new datasets and, specifically, present existing methods alongside a novel approach, the initial steps towards addressing this challenge.",
      "authors": [
        "Xingyu Alice Yang",
        "Jianyu Zhang",
        "L\\'eon Bottou"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18221",
        "HTML": "https://arxiv.org/html/2506.18221",
        "PDF": "https://arxiv.org/pdf/2506.18221"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 01:04:29 GMT",
          "size": "658kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "These are Not All the Features You are Looking For: A Fundamental Bottleneck In Supervised Pretraining",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "This paper discusses feature transfer issues in deep learning but does not propose specific methods for LLM training data processing. It briefly touches on the data's role in feature learning but does not directly contribute to LLM training data engineering."
      }
    },
    {
      "id": "2506.19897",
      "abstract": "Large language models (LLMs) have become essential tools in computer science, especially for tasks involving code understanding and generation. However, existing work does not address many of the unique challenges presented by code written for government applications. In particular, government enterprise software is often written in legacy languages like MUMPS or assembly language code (ALC) and the overall token lengths of these systems exceed the context window size for current commercially available LLMs. Additionally, LLMs are primarily trained on modern software languages and have undergone limited testing with legacy languages, making their ability to understand legacy languages unknown and, hence, an area for empirical study. This paper examines the application of LLMs in the modernization of legacy government code written in ALC and MUMPS, addressing the challenges of input limitations. We investigate various code-chunking methods to optimize the generation of summary module comments for legacy code files, evaluating the impact of code-chunking methods on the quality of documentation produced by different LLMs, including GPT-4o, Claude 3 Sonnet, Mixtral, and Llama 3. Our results indicate that LLMs can select partition points closely aligned with human expert partitioning. We also find that chunking approaches have significant impact on downstream tasks such as documentation generation. LLM-created partitions produce comments that are up to 20% more factual and up to 10% more useful than when humans create partitions. Therefore, we conclude that LLMs can be used as suitable replacements for human partitioning of large codebases during LLM-aided modernization.",
      "authors": [
        "Christopher Glasz",
        "Emily Escamilla",
        "Eric O. Scott",
        "Anand Patel",
        "Jacob Zimmer",
        "Colin Diggs",
        "Michael Doyle",
        "Scott Rosen",
        "Nitin Naik",
        "Justin F. Brunelle",
        "Samruddhi Thaker",
        "Parthav Poudel",
        "Arun Sridharan",
        "Amit Madan",
        "Doug Wendt",
        "William Macke",
        "Thomas Schill"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19897",
        "HTML": "https://arxiv.org/html/2506.19897",
        "PDF": "https://arxiv.org/pdf/2506.19897"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 13:02:35 GMT",
          "size": "1412kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Can LLMs Replace Humans During Code Chunking?",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper examines code chunking methods for LLMs to assist in modernizing legacy code, mentioning some input length challenges but not focusing on novel LLM training data processing methods."
      }
    },
    {
      "id": "2506.19935",
      "abstract": "Large language models (LLMs) predominantly use autoregressive (AR) approaches, but masked diffusion models (MDMs) are emerging as viable alternatives. A key challenge in comparing AR and MDM paradigms is their typical architectural difference: AR models are often decoder-only, while MDMs have largely been encoder-only. This practice of changing both the modeling paradigm and architecture simultaneously makes direct comparisons unfair, as it's hard to distinguish whether observed differences stem from the paradigm itself or the architectural shift. This research evaluates MDMs within a decoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or AO-AR) and standard AR paradigms. Our investigation suggests that the standard AO-AR objective, which averages over all token permutations, may benefit from refinement, as many permutations appear less informative compared to the language's inherent left-to-right structure. (2) Investigate architectural influences (decoder-only vs. encoder-only) within MDMs. We demonstrate that while encoder-only MDMs model a simpler conditional probability space, decoder-only MDMs can achieve dramatic generation speedups ($\\sim25\\times$) and comparable perplexity with temperature annealing despite modeling a vastly larger space, highlighting key trade-offs. This work thus decouples core paradigm differences from architectural influences, offering insights for future model design. Code is available at https://github.com/scxue/AO-GPT-MDM.",
      "authors": [
        "Shuchen Xue",
        "Tianyu Xie",
        "Tianyang Hu",
        "Zijin Feng",
        "Jiacheng Sun",
        "Kenji Kawaguchi",
        "Zhenguo Li",
        "Zhi-Ming Ma"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19935",
        "HTML": "https://arxiv.org/html/2506.19935",
        "PDF": "https://arxiv.org/pdf/2506.19935"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:22:25 GMT",
          "size": "289kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses paradigm and architectural comparisons between autoregressive models and masked diffusion models, mentioning training strategies but lacks direct focus on LLM training data processing."
      }
    },
    {
      "id": "2506.19992",
      "abstract": "The explosive growth of complex datasets across various modalities necessitates advanced analytical tools that not only group data effectively but also provide human-understandable insights into the discovered structures. We introduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization), a novel algorithm and Python package designed for hierarchical k-means clustering of diverse data types, including text, images, and numeric data (processed one modality per run). HERCULES constructs a cluster hierarchy by recursively applying k-means clustering, starting from individual data points at level 0. A key innovation is its deep integration of Large Language Models (LLMs) to generate semantically rich titles and descriptions for clusters at each level of the hierarchy, significantly enhancing interpretability. The algorithm supports two main representation modes: `direct' mode, which clusters based on original data embeddings or scaled numeric features, and `description' mode, which clusters based on embeddings derived from LLM-generated summaries. Users can provide a `topic\\_seed' to guide LLM-generated summaries towards specific themes. An interactive visualization tool facilitates thorough analysis and understanding of the clustering results. We demonstrate HERCULES's capabilities and discuss its potential for extracting meaningful, hierarchical knowledge from complex datasets.",
      "authors": [
        "Gabor Petnehazi and Bernadett Aradi"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19992",
        "HTML": "https://arxiv.org/html/2506.19992",
        "PDF": "https://arxiv.org/pdf/2506.19992"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:22:00 GMT",
          "size": "190kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although the paper proposes a clustering algorithm using LLM embeddings for summarization, it primarily addresses clustering methods and does not introduce novel processes for LLM training data preparation or engineering."
      }
    },
    {
      "id": "2506.19993",
      "abstract": "Recommender systems play a pivotal role in providing relevant content to users. With the rapid development of large language models (LLMs), researchers have begun utilizing LLMs to build more powerful recommender systems. However, existing approaches that focus on aligning LLMs with recommendation tasks do not fully leverage their sequential information processing capabilities, leading to suboptimal performance.\n  In this paper, we propose a novel system called compressed vocabulary expansion (CoVE). In CoVE, each item is assigned a unique ID within the expanded vocabulary. Our framework effectively capitalizes on sequence understanding abilities of LLMs, significantly enhancing their performance on recommendation tasks. Additionally, we compress the embedding layer, making CoVE practical for large-scale industrial applications. The effectiveness and performance of CoVE are demonstrated through comprehensive experiments on multiple recommendation datasets and comparisons with prior works. Our code can be found at https://github.com/HaochenZhang717/CoVE-official-Repo.",
      "authors": [
        "Haochen Zhang",
        "Tianyi Zhang",
        "Junze Yin",
        "Oren Gal",
        "Anshumali Shrivastava",
        "Vladimir Braverman"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19993",
        "HTML": "https://arxiv.org/html/2506.19993",
        "PDF": "https://arxiv.org/pdf/2506.19993"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:27:51 GMT",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper proposes 'compressed vocabulary expansion' for LLM-based recommender systems but focuses on recommendation tasks rather than LLM training data processing. Data processing is incidental to the application rather than a contribution to LLM data engineering."
      }
    },
    {
      "id": "2506.19998",
      "abstract": "REST APIs play important roles in enriching the action space of web agents, yet most API-based agents rely on curated and uniform toolsets that do not reflect the complexity of real-world APIs. Building tool-using agents for arbitrary domains remains a major challenge, as it requires reading unstructured API documentation, testing APIs and inferring correct parameters. We propose Doc2Agent, a scalable pipeline to build agents that can call Python-based tools generated from API documentation. Doc2Agent generates executable tools from API documentations and iteratively refines them using a code agent. We evaluate our approach on real-world APIs, WebArena APIs, and research APIs, producing validated tools. We achieved a 55\\% relative performance improvement with 90\\% lower cost compared to direct API calling on WebArena benchmark. A domain-specific agent built for glycomaterial science further demonstrates the pipeline's adaptability to complex, knowledge-rich tasks. Doc2Agent offers a generalizable solution for building tool agents from unstructured API documentation at scale.",
      "authors": [
        "Xinyi Ni and Haonan Jian and Qiuyang Wang and Vedanshi Chetan Shah and Pengyu Hong"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19998",
        "HTML": "https://arxiv.org/html/2506.19998",
        "PDF": "https://arxiv.org/pdf/2506.19998"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:30:44 GMT",
          "size": "1378kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the generation of tool-using agents from API documentation, which involves data transformation from unstructured API data to executable tools. However, it does not focus on LLM training data but rather on tool generation for agent functionality."
      }
    },
    {
      "id": "2506.20008",
      "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated strong potential in code generation, yet their effectiveness in quantum computing remains underexplored. This paper benchmarks LLMs for PennyLane-based quantum code generation using real-world challenges from the Quantum Hackathon (QHack). We introduce QHackBench, a novel benchmark dataset derived from QHack competitions, and evaluate model performance under vanilla prompting and Retrieval-Augmented Generation (RAG). Our structured evaluation framework assesses functional correctness, syntactic validity, and execution success across varying challenge difficulties. Results indicate that RAG-enhanced models, supplemented with an augmented PennyLane dataset, approximately generate similar results as the standard prompting, particularly in complex quantum algorithms. Additionally, we introduce a multi-agent evaluation pipeline that iteratively refines incorrect solutions, further enhancing execution success rates. To foster further research, we commit to publicly releasing QHackBench, along with our evaluation framework and experimental results, enabling continued advancements in AI-assisted quantum programming.",
      "authors": [
        "Abdul Basit",
        "Minghao Shao",
        "Haider Asif",
        "Nouhaila Innan",
        "Muhammad Kashif",
        "Alberto Marchisio",
        "Muhammad Shafique"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20008",
        "HTML": "https://arxiv.org/html/2506.20008",
        "PDF": "https://arxiv.org/pdf/2506.20008"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:54:56 GMT",
          "size": "943kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a benchmark dataset for evaluating LLMs in quantum code generation, which relates to constructing a dataset but does not focus on novel data engineering techniques for LLM training data processing."
      }
    },
    {
      "id": "2506.20009",
      "abstract": "Background The increasing adoption of Artificial Intelligence (AI) in healthcare has sparked growing concerns about its environmental and ethical implications. Commercial Large Language Models (LLMs), such as ChatGPT and DeepSeek, require substantial resources, while the utilization of these systems for medical purposes raises critical issues regarding patient privacy and safety. Methods We developed a customizable Retrieval-Augmented Generation (RAG) framework for medical tasks, which monitors its energy usage and CO2 emissions. This system was then used to create RAGs based on various open-source LLMs. The tested models included both general purpose models like llama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs performance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs o4-mini model. A dataset of medical questions was used for the evaluation. Results Custom RAG models outperformed commercial models in accuracy and energy consumption. The RAG model built on llama3.1:8B achieved the highest accuracy (58.5%) and was significantly better than other models, including o4-mini and DeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption and CO2 footprint among all models, with a Performance per kWh of 0.52 and a total CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x times more accuracy points per kWh and 172% less electricity usage while maintaining higher accuracy. Conclusion Our study demonstrates that local LLMs can be leveraged to develop RAGs that outperform commercial, online LLMs in medical tasks, while having a smaller environmental impact. Our modular framework promotes sustainable AI development, reducing electricity usage and aligning with the UNs Sustainable Development Goals.",
      "authors": [
        "Konstantinos Vrettos",
        "Michail E. Klontzas"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20009",
        "HTML": "https://arxiv.org/html/2506.20009",
        "PDF": "https://arxiv.org/pdf/2506.20009"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 20:56:03 GMT",
          "size": "564kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a Retrieval-Augmented Generation framework and its performance on medical tasks, but it does not focus on novel methods for the construction or processing of LLM training data."
      }
    },
    {
      "id": "2506.20059",
      "abstract": "Recent advances in Large Language Models (LLMs) have led to remarkable progresses in medical consultation. However, existing medical LLMs overlook the essential role of Electronic Health Records (EHR) and focus primarily on diagnosis recommendation, limiting their clinical applicability. We propose DiaLLM, the first medical LLM that integrates heterogeneous EHR data into clinically grounded dialogues, enabling clinical test recommendation, result interpretation, and diagnosis prediction to better align with real-world medical practice. To construct clinically grounded dialogues from EHR, we design a Clinical Test Reference (CTR) strategy that maps each clinical code to its corresponding description and classifies test results as \"normal\" or \"abnormal\". Additionally, DiaLLM employs a reinforcement learning framework for evidence acquisition and automated diagnosis. To handle the large action space, we introduce a reject sampling strategy to reduce redundancy and improve exploration efficiency. Furthermore, a confirmation reward and a class-sensitive diagnosis reward are designed to guide accurate diagnosis prediction. Extensive experimental results demonstrate that DiaLLM outperforms baselines in clinical test recommendation and diagnosis prediction.",
      "authors": [
        "Weijieying Ren",
        "Tianxiang Zhao",
        "Lei Wang",
        "Tianchun Wang",
        "Vasant Honavar"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20059",
        "HTML": "https://arxiv.org/html/2506.20059",
        "PDF": "https://arxiv.org/pdf/2506.20059"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:47:21 GMT",
          "size": "486kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on integrating EHR data into LLM-driven clinical dialogues but does not primarily contribute to general LLM training data engineering or processing. While it involves creating clinically grounded dialogues from EHR, it does not focus on general LLM data processing methods."
      }
    },
    {
      "id": "2506.20065",
      "abstract": "Phenotyping is the process of distinguishing groups of patients to identify different types of disease progression. A recent trend employs low-rank matrix and tensor factorization methods for their capability of dealing with multi-modal, heterogeneous, and missing data. Symptom quantification is crucial for understanding patient experiences in inflammatory bowel disease, especially in conditions such as ulcerative colitis (UC). However, patient-reported symptoms are typically noisy, subjective, and significantly more sparse than other data types. For this reason, they are usually not included in phenotyping and other machine learning methods. This paper explores the application of computational phenotyping to leverage Patient-Reported Outcomes (PROs) using a novel supervised coupled matrix-tensor factorization (SCMTF) method, which integrates temporal PROs and temporal labs with static features to predict medication persistence in ulcerative colitis. This is the first tensor-based method that is both supervised and coupled, it is the first application to the UC domain, and the first application to PROs. We use a deep learning framework that makes the model flexible and easy to train. The proposed method allows us to handle the large amount of missing data in the PROs. The best model predicts changes in medication 8 and 20 months in the future with AUCs of 0.853 and 0.803 on the test set respectively. We derive interpretable phenotypes consisting of static features and temporal features (including their temporal patterns). We show that low-rank matrix and tensor based phenotyping can be successfully applied to the UC domain and to highly missing PRO data. We identify phenotypes useful to predict medication persistence - these phenotypes include several symptom variables, showing that PROs contain relevant infromation that is usually discarded.",
      "authors": [
        "Cristian Minoccheri",
        "Sophia Tesic",
        "Kayvan Najarian",
        "Ryan Stidham"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20065",
        "HTML": "https://arxiv.org/html/2506.20065",
        "PDF": "https://arxiv.org/pdf/2506.20065"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:55:11 GMT",
          "size": "455kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Supervised Coupled Matrix-Tensor Factorization (SCMTF) for Computational Phenotyping of Patient Reported Outcomes in Ulcerative Colitis",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper applies a novel matrix-tensor factorization method for phenotyping in ulcerative colitis and does not primarily contribute to the design, construction, or processing of LLM training data, though it does deal with data processing in a specific medical context."
      }
    },
    {
      "id": "2506.20093",
      "abstract": "Time-series data are critical in diverse applications, such as industrial monitoring, medical diagnostics, and climate research. However, effectively integrating these high-dimensional temporal signals with natural language for dynamic, interactive tasks remains a significant challenge. To address this, we introduce the Time-Series Question Answering (Time-Series QA) task and release EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset designed to capture complex interactions between time-series signals and natural language. Building on this resource, we propose the Instruct Time Transformer (ITFormer), a novel framework that bridges time-series encoders with frozen large language models (LLMs). ITFormer effectively extracts, aligns, and fuses temporal and textual features, achieving a strong improvement in QA accuracy over strong baselines with fewer than 1\\% additional trainable parameters. By combining computational efficiency with robust cross-modal modeling, our work establishes a adaptable paradigm for integrating temporal data with natural language, paving the way for new research and applications in multi-modal AI. More details about the project, including datasets and code, are available at: https://pandalin98.github.io/itformer_site/",
      "authors": [
        "Yilin Wang",
        "Peixuan Lei",
        "Jie Song",
        "Yuzhe Hao",
        "Tao Chen",
        "Yuxuan Zhang",
        "Lei Jia",
        "Yuanxiang Li",
        "Zhongyu Wei"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20093",
        "HTML": "https://arxiv.org/html/2506.20093",
        "PDF": "https://arxiv.org/pdf/2506.20093"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 02:33:47 GMT",
          "size": "9413kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper introduces a new dataset (EngineMT-QA) and framework (ITFormer) for integrating time-series with natural language, it does not primarily focus on LLM training data processing strategies but mentions creating a dataset and model that use LLMs."
      }
    },
    {
      "id": "2506.20097",
      "abstract": "We propose PSALM-V, the first autonomous neuro-symbolic learning system able to induce symbolic action semantics (i.e., pre- and post-conditions) in visual environments through interaction. PSALM-V bootstraps reliable symbolic planning without expert action definitions, using LLMs to generate heuristic plans and candidate symbolic semantics. Previous work has explored using large language models to generate action semantics for Planning Domain Definition Language (PDDL)-based symbolic planners. However, these approaches have primarily focused on text-based domains or relied on unrealistic assumptions, such as access to a predefined problem file, full observability, or explicit error messages. By contrast, PSALM-V dynamically infers PDDL problem files and domain action semantics by analyzing execution outcomes and synthesizing possible error explanations. The system iteratively generates and executes plans while maintaining a tree-structured belief over possible action semantics for each action, iteratively refining these beliefs until a goal state is reached. Simulated experiments of task completion in ALFRED demonstrate that PSALM-V increases the plan success rate from 37% (Claude-3.7) to 74% in partially observed setups. Results on two 2D game environments, RTFM and Overcooked-AI, show that PSALM-V improves step efficiency and succeeds in domain induction in multi-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions for real-world robot BlocksWorld tasks, despite low-level manipulation failures from the robot.",
      "authors": [
        "Wang Bill Zhu",
        "Miaosen Chai",
        "Ishika Singh",
        "Robin Jia",
        "Jesse Thomason"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20097",
        "HTML": "https://arxiv.org/html/2506.20097",
        "PDF": "https://arxiv.org/pdf/2506.20097"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 02:44:20 GMT",
          "size": "6944kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the use of large language models to generate symbolic action semantics in visual environments, briefly touching on algorithmic aspects without substantial focus on LLM training data processing specifics."
      }
    },
    {
      "id": "2506.20128",
      "abstract": "RAG systems enhance LLMs by incorporating external knowledge, which is crucial for domains that demand factual accuracy and up-to-date information. However, evaluating the multifaceted quality of RAG outputs, spanning aspects such as contextual coherence, query relevance, factual correctness, and informational completeness, poses significant challenges. Existing evaluation methods often rely on simple lexical overlap metrics, which are inadequate for capturing these nuances, or involve complex multi-stage pipelines with intermediate steps like claim extraction or require finetuning specialized judge models, hindering practical efficiency. To address these limitations, we propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five metrics that utilizes a single, powerful, pretrained LLM as a zero-shot, end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance (QR), Information Density (ID), Answer Correctness (AC), and Information Recall (IR). We apply CCRS to evaluate six diverse RAG system configurations on the challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively discriminates between system performances, confirming, for instance, that the Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of CCRS metric properties, including score distributions, convergent/discriminant validity, tie rates, population statistics, and discriminative power. Compared to the complex RAGChecker framework, CCRS offers comparable or superior discriminative power for key aspects like recall and faithfulness, while being significantly more computationally efficient. CCRS thus provides a practical, comprehensive, and efficient framework for evaluating and iteratively improving RAG systems.",
      "authors": [
        "Aashiq Muhamed"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20128",
        "HTML": "https://arxiv.org/html/2506.20128",
        "PDF": "https://arxiv.org/pdf/2506.20128"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:49:03 GMT",
          "size": "4546kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses evaluating RAG systems by proposing CCRS, a framework for assessing output quality. It does not focus on LLM training data processing but briefly touches on data evaluation."
      }
    },
    {
      "id": "2506.20156",
      "abstract": "The core challenge in learning has shifted from knowledge acquisition to effective Self-Regulated Learning (SRL): planning, monitoring, and reflecting on one's learning. Existing digital tools, however, inadequately support metacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized review, overlooking the role of context, while Personal Knowledge Management (PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel paradigm that conceptualizes the context-triggered retrieval of personal past insights as a metacognitive scaffold to promote SRL. We formalize this paradigm using the Just-in-Time Adaptive Intervention (JITAI) framework and implement a prototype system, Irec, to demonstrate its feasibility. At its core, Irec uses a dynamic knowledge graph of the user's learning history. When a user faces a new problem, a hybrid retrieval engine recalls relevant personal \"insights.\" Subsequently, a large language model (LLM) performs a deep similarity assessment to filter and present the most relevant scaffold in a just-in-time manner. To reduce cognitive load, Irec features a human-in-the-loop pipeline for LLM-based knowledge graph construction. We also propose an optional \"Guided Inquiry\" module, where users can engage in a Socratic dialogue with an expert LLM, using the current problem and recalled insights as context. The contribution of this paper is a solid theoretical framework and a usable system platform for designing next-generation intelligent learning systems that enhance metacognition and self-regulation.",
      "authors": [
        "Xuefei Hou",
        "Xizhao Tan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20156",
        "HTML": "https://arxiv.org/html/2506.20156",
        "PDF": "https://arxiv.org/pdf/2506.20156"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:23:39 GMT",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a learning system that uses LLMs for insight recall and dialogue, with mention of data processing in the context of a dynamic knowledge graph. However, it does not propose new methods for LLM training data processing."
      }
    },
    {
      "id": "2506.20167",
      "abstract": "Multivariate time series forecasting requires models to simultaneously capture variable-wise structural dependencies and generalize across diverse tasks. While structural encoders are effective in modeling feature interactions, they lack the capacity to support semantic-level reasoning or task adaptation. Conversely, large language models (LLMs) possess strong generalization capabilities but remain incompatible with raw time series inputs. This gap limits the development of unified, transferable prediction systems. Therefore, we introduce SEED, a structural encoder for embedding-driven decoding, which integrates four stages: a token-aware encoder for patch extraction, a projection module that aligns patches with language model embeddings, a semantic reprogramming mechanism that maps patches to task-aware prototypes, and a frozen language model for prediction. This modular architecture decouples representation learning from inference, enabling efficient alignment between numerical patterns and semantic reasoning. Empirical results demonstrate that the proposed method achieves consistent improvements over strong baselines, and comparative studies on various datasets confirm SEED's role in addressing the structural-semantic modeling gap.",
      "authors": [
        "Fengze Li",
        "Yue Wang",
        "Yangle Liu",
        "Ming Huang",
        "Dou Hong and Jieming Ma"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20167",
        "HTML": "https://arxiv.org/html/2506.20167",
        "PDF": "https://arxiv.org/pdf/2506.20167"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:40:14 GMT",
          "size": "1536kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces SEED, an architecture integrating structural encoders with LLMs for multivariate time series forecasting. It mentions data alignment with language model embeddings, but does not propose new LLM training data processing methods."
      }
    },
    {
      "id": "2506.20170",
      "abstract": "Deobfuscating JavaScript (JS) code poses a significant challenge in web security, particularly as obfuscation techniques are frequently used to conceal malicious activities within scripts. While Large Language Models (LLMs) have recently shown promise in automating the deobfuscation process, transforming detection and mitigation strategies against these obfuscated threats, a systematic benchmark to quantify their effectiveness and limitations has been notably absent. To address this gap, we present JsDeObsBench, a dedicated benchmark designed to rigorously evaluate the effectiveness of LLMs in the context of JS deobfuscation. We detail our benchmarking methodology, which includes a wide range of obfuscation techniques ranging from basic variable renaming to sophisticated structure transformations, providing a robust framework for assessing LLM performance in real-world scenarios. Our extensive experimental analysis investigates the proficiency of cutting-edge LLMs, e.g., GPT-4o, Mixtral, Llama, and DeepSeek-Coder, revealing superior performance in code simplification despite challenges in maintaining syntax accuracy and execution reliability compared to baseline methods. We further evaluate the deobfuscation of JS malware to exhibit the potential of LLMs in security scenarios. The findings highlight the utility of LLMs in deobfuscation applications and pinpoint crucial areas for further improvement.",
      "authors": [
        "Guoqiang Chen",
        "Xin Jin",
        "Zhiqiang Lin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20170",
        "HTML": "https://arxiv.org/html/2506.20170",
        "PDF": "https://arxiv.org/pdf/2506.20170"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 06:50:13 GMT",
          "size": "1309kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "JsDeObsBench: Measuring and Benchmarking LLMs for JavaScript Deobfuscation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper details a benchmark for evaluating LLMs in deobfuscating JavaScript code. While it involves LLMs, it focuses on benchmarking performance rather than proposing new data processing methods for training LLMs."
      }
    },
    {
      "id": "2506.20203",
      "abstract": "In this paper, we compare Czech-specific and multilingual sentence embedding models through intrinsic and extrinsic evaluation paradigms. For intrinsic evaluation, we employ Costra, a complex sentence transformation dataset, and several Semantic Textual Similarity (STS) benchmarks to assess the ability of the embeddings to capture linguistic phenomena such as semantic similarity, temporal aspects, and stylistic variations. In the extrinsic evaluation, we fine-tune each embedding model using COMET-based metrics for machine translation evaluation.\n  Our experiments reveal an interesting disconnect: models that excel in intrinsic semantic similarity tests do not consistently yield superior performance on downstream translation evaluation tasks. Conversely, models with seemingly over-smoothed embedding spaces can, through fine-tuning, achieve excellent results. These findings highlight the complex relationship between semantic property probes and downstream task, emphasizing the need for more research into 'operationalizable semantics' in sentence embeddings, or more in-depth downstream tasks datasets (here translation evaluation)",
      "authors": [
        "Petra Baran\\v{c}\\'ikov\\'a and Ond\\v{r}ej Bojar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20203",
        "HTML": "https://arxiv.org/html/2506.20203",
        "PDF": "https://arxiv.org/pdf/2506.20203"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:46:17 GMT",
          "size": "823kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Intrinsic vs. Extrinsic Evaluation of Czech Sentence Embeddings: Semantic Relevance Doesn't Help with MT Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "This paper discusses sentence embeddings and fine-tuning models for machine translation evaluation. While it involves model fine-tuning, the paper does not propose new methods for LLM training data processing or data engineering."
      }
    },
    {
      "id": "2506.20245",
      "abstract": "Federated learning (FL) is a decentralized collaborative machine learning (ML) technique. It provides a solution to the issues of isolated data islands and data privacy leakage in industrial ML practices. One major challenge in FL is handling the non-identical and independent distributed (non-IID) data. Current solutions either focus on constructing an all-powerful global model, or customizing personalized local models. Few of them can provide both a well-generalized global model and well-performed local models at the same time. Additionally, many FL solutions to the non-IID problem are benefited from introducing public datasets. However, this will also increase the risk of data leakage. To tackle the problems, we propose a novel data-free distillation framework, Federated Bidirectional Knowledge Distillation (FedBKD). Specifically, we train Generative Adversarial Networks (GAN) for synthetic data. During the GAN training, local models serve as discriminators and their parameters are frozen. The synthetic data is then used for bidirectional distillation between global and local models to achieve knowledge interactions so that performances for both sides are improved. We conduct extensive experiments on 4 benchmarks under different non-IID settings. The results show that FedBKD achieves SOTA performances in every case.",
      "authors": [
        "Yushan Zhao",
        "Jinyuan He",
        "Donglai Chen",
        "Weijie Luo",
        "Chong Xie",
        "Ri Zhang",
        "Yonghong Chen and Yan Xu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20245",
        "HTML": "https://arxiv.org/html/2506.20245",
        "PDF": "https://arxiv.org/pdf/2506.20245"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:42:10 GMT",
          "size": "607kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper proposes a federated learning framework with data-free distillation using synthetic data, which briefly mentions the use of generative adversarial networks for synthetic data but does not focus on novel LLM training data processing techniques."
      }
    },
    {
      "id": "2506.20249",
      "abstract": "Can we leverage LLMs to model the process of discovering novel language model (LM) architectures? Inspired by real research, we propose a multi-agent LLM approach that simulates the conventional stages of research, from ideation and literature search (proposal stage) to design implementation (code generation), generative pre-training, and downstream evaluation (verification). Using ideas from scaling laws, our system, Genesys, employs a Ladder of Scales approach; new designs are proposed, adversarially reviewed, implemented, and selectively verified at increasingly larger model scales (14M$\\sim$350M parameters) with a narrowing budget (the number of models we can train at each scale). To help make discovery efficient and factorizable, Genesys uses a novel genetic programming backbone, which we show has empirical advantages over commonly used direct prompt generation workflows (e.g., $\\sim$86\\% percentage point improvement in successful design generation, a key bottleneck). We report experiments involving 1,162 newly discovered designs (1,062 fully verified through pre-training) and find the best designs to be highly competitive with known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common benchmarks). We couple these results with comprehensive system-level ablations and formal results, which give broader insights into the design of effective autonomous discovery systems.",
      "authors": [
        "Junyan Cheng",
        "Peter Clark",
        "Kyle Richardson"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20249",
        "HTML": "https://arxiv.org/html/2506.20249",
        "PDF": "https://arxiv.org/pdf/2506.20249"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:46:10 GMT",
          "size": "34327kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Language Modeling by Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper explores the use of LLMs to simulate language model architecture research, it doesn't primarily focus on training data processing for LLMs, instead emphasizing architecture discovery and evaluation."
      }
    },
    {
      "id": "2506.20251",
      "abstract": "Quantized large language models (LLMs) have gained increasing attention and significance for enabling deployment in resource-constrained environments. However, emerging studies on a few calibration dataset-free quantization methods suggest that quantization may compromise the safety capabilities of LLMs, underscoring the urgent need for systematic safety evaluations and effective mitigation strategies. In this paper, we present comprehensive safety evaluations across various mainstream quantization techniques and diverse calibration datasets, utilizing widely accepted safety benchmarks. To address the identified safety vulnerabilities, we propose a quantization-aware safety patching framework, Q-resafe, to efficiently restore the safety capabilities of quantized LLMs while minimizing any adverse impact on utility. Extensive experimental results demonstrate that Q-resafe successfully re-aligns the safety of quantized LLMs with their pre-quantization counterparts, even under challenging evaluation scenarios. Project page is available at: https://github.com/Thecommonirin/Qresafe.",
      "authors": [
        "Kejia Chen",
        "Jiawen Zhang",
        "Jiacong Hu",
        "Yu Wang",
        "Jian Lou",
        "Zunlei Feng",
        "Mingli Song"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20251",
        "HTML": "https://arxiv.org/html/2506.20251",
        "PDF": "https://arxiv.org/pdf/2506.20251"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:52:22 GMT",
          "size": "1599kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper examines safety risks of quantized LLMs and presents a safety patching framework. It involves some level of data evaluation but is not primarily about novel data processing techniques for training LLMs."
      }
    },
    {
      "id": "2506.20254",
      "abstract": "The complexity and diversity of surgical workflows, driven by heterogeneous operating room settings, institutional protocols, and anatomical variability, present a significant challenge in developing generalizable models for cross-institutional and cross-procedural surgical understanding. While recent surgical foundation models pretrained on large-scale vision-language data offer promising transferability, their zero-shot performance remains constrained by domain shifts, limiting their utility in unseen surgical environments. To address this, we introduce Surgical Phase Anywhere (SPA), a lightweight framework for versatile surgical workflow understanding that adapts foundation models to institutional settings with minimal annotation. SPA leverages few-shot spatial adaptation to align multi-modal embeddings with institution-specific surgical scenes and phases. It also ensures temporal consistency through diffusion modeling, which encodes task-graph priors derived from institutional procedure protocols. Finally, SPA employs dynamic test-time adaptation, exploiting the mutual agreement between multi-modal phase prediction streams to adapt the model to a given test video in a self-supervised manner, enhancing the reliability under test-time distribution shifts. SPA is a lightweight adaptation framework, allowing hospitals to rapidly customize phase recognition models by defining phases in natural language text, annotating a few images with the phase labels, and providing a task graph defining phase transitions. The experimental results show that the SPA framework achieves state-of-the-art performance in few-shot surgical phase recognition across multiple institutions and procedures, even outperforming full-shot models with 32-shot labeled data. Code is available at https://github.com/CAMMA-public/SPA",
      "authors": [
        "Kun Yuan",
        "Tingxuan Chen",
        "Shi Li",
        "Joel L. Lavanchy",
        "Christian Heiliger",
        "Ege \\\"Ozsoy",
        "Yiming Huang",
        "Long Bai",
        "Nassir Navab",
        "Vinkle Srivastav",
        "Hongliang Ren",
        "Nicolas Padoy"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20254",
        "HTML": "https://arxiv.org/html/2506.20254",
        "PDF": "https://arxiv.org/pdf/2506.20254"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:56:13 GMT",
          "size": "4120kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although the focus is on adapting surgical workflow models, the brief mention of pre-trained vision-language data indicates existing data usage without new methods for LLM data processing or construction."
      }
    },
    {
      "id": "2506.20291",
      "abstract": "Conversational Recommender Systems (CRSs) have garnered attention as a novel approach to delivering personalized recommendations through multi-turn dialogues. This review developed a taxonomy framework to systematically categorize relevant publications into four groups: dataset construction, algorithm design, system evaluation, and empirical studies, providing a comprehensive analysis of simulation methods in CRSs research. Our analysis reveals that simulation methods play a key role in tackling CRSs' main challenges. For example, LLM-based simulation methods have been used to create conversational recommendation data, enhance CRSs algorithms, and evaluate CRSs. Despite several challenges, such as dataset bias, the limited output flexibility of LLM-based simulations, and the gap between text semantic space and behavioral semantics, persist due to the complexity in Human-Computer Interaction (HCI) of CRSs, simulation methods hold significant potential for advancing CRS research. This review offers a thorough summary of the current research landscape in this domain and identifies promising directions for future inquiry.",
      "authors": [
        "Haoran Zhang",
        "Xin Zhao",
        "Jinze Chen",
        "Junpeng Guo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20291",
        "HTML": "https://arxiv.org/html/2506.20291",
        "PDF": "https://arxiv.org/pdf/2506.20291"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:53:35 GMT",
          "size": "153kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Literature Review on Simulation in Conversational Recommender Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper reviews conversational recommender systems, mentioning LLM-based simulation methods for dataset creation, which marginally relates to data preparation but does not introduce novel contributions in LLM training data processing."
      }
    },
    {
      "id": "2506.20312",
      "abstract": "Burstiness, a phenomenon observed in text and image retrieval, refers to that particular elements appear more times in a set than a statistically independent model assumes. We argue that in the context of set-based face recognition (SFR), burstiness exists widely and degrades the performance in two aspects: Firstly, the bursty faces, where faces with particular attributes %exist frequently in a face set, dominate the training instances and dominate the training face sets and lead to poor generalization ability to unconstrained scenarios. Secondly, the bursty faces %dominating the evaluation sets interfere with the similarity comparison in set verification and identification when evaluation. To detect the bursty faces in a set, we propose three strategies based on Quickshift++, feature self-similarity, and generalized max-pooling (GMP). We apply the burst detection results on training and evaluation stages to enhance the sampling ratios or contributions of the infrequent faces. When evaluation, we additionally propose the quality-aware GMP that enables awareness of the face quality and robustness to the low-quality faces for the original GMP. We give illustrations and extensive experiments on the SFR benchmarks to demonstrate that burstiness is widespread and suppressing burstiness considerably improves the recognition performance.",
      "authors": [
        "Jiong Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20312",
        "HTML": "https://arxiv.org/html/2506.20312",
        "PDF": "https://arxiv.org/pdf/2506.20312"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 10:49:45 GMT",
          "size": "1274kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the Burstiness of Faces in Set",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper proposes methods for detecting 'burstiness' in face recognition datasets, impacting data balance during training. However, this is only tangentially related to LLM training data processing."
      }
    },
    {
      "id": "2506.20332",
      "abstract": "Vision-language model-based mobile agents have gained the ability to not only understand complex instructions and mobile screenshots, but also optimize their action outputs via thinking and reasoning, benefiting from reinforcement learning, such as Group Relative Policy Optimization (GRPO). However, existing research centers on offline reinforcement learning training or online optimization using action-level rewards, which limits the agent's dynamic interaction with the environment. This often results in agents settling into local optima, thereby weakening their ability for exploration and error action correction. To address these challenges, we introduce an approach called Mobile-R1, which employs interactive multi-turn reinforcement learning with task-level rewards for mobile agents. Our training framework consists of three stages: initial format finetuning, single-step online training via action-level reward, followed by online training via task-level reward based on multi-turn trajectories. This strategy is designed to enhance the exploration and error correction capabilities of Mobile-R1, leading to significant performance improvements. Moreover, we have collected a dataset covering 28 Chinese applications with 24,521 high-quality manual annotations and established a new benchmark with 500 trajectories. We will open source all resources, including the dataset, benchmark, model weight, and codes: https://mobile-r1.github.io/Mobile-R1/.",
      "authors": [
        "Jihao Gu",
        "Qihang Ai",
        "Yingyao Wang",
        "Pi Bu",
        "Jingxuan Xing",
        "Zekun Zhu",
        "Wei Jiang",
        "Ziming Wang",
        "Yingxiu Zhao",
        "Ming-Liang Zhang",
        "Jun Song",
        "Yuning Jiang",
        "Bo Zheng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20332",
        "HTML": "https://arxiv.org/html/2506.20332",
        "PDF": "https://arxiv.org/pdf/2506.20332"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:34:43 GMT",
          "size": "10452kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper primarily discusses reinforcement learning for mobile agents, it mentions the collection of a dataset with high-quality manual annotations, indirectly related to LLM training data quality enhancement."
      }
    },
    {
      "id": "2506.20377",
      "abstract": "The impact of culture on how people express distress in online support communities is increasingly a topic of interest within Computer Supported Cooperative Work (CSCW) and Human-Computer Interaction (HCI). In the United States, distinct cultures have emerged from each of the two dominant political parties, forming a primary lens by which people navigate online and offline worlds. We examine whether partisan culture may play a role in how U.S. Republican and Democrat users of online mental health support communities express distress. We present a large-scale observational study of 2,184,356 posts from 8,916 statistically matched Republican, Democrat, and unaffiliated online support community members. We utilize methods from causal inference to statistically match partisan users along covariates that correspond with demographic attributes and platform use, in order to create comparable cohorts for analysis. We then leverage methods from natural language processing to understand how partisan expressions of distress compare between these sets of closely matched opposing partisans, and between closely matched partisans and typical support community members. Our data spans January 2013 to December 2022, a period of both rising political polarization and mental health concerns. We find that partisan culture does play into expressions of distress, underscoring the importance of considering partisan cultural differences in the design of online support community platforms.",
      "authors": [
        "Sachin R. Pendse",
        "Ben Rochford",
        "Neha Kumar",
        "Munmun De Choudhury"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20377",
        "HTML": "https://arxiv.org/html/2506.20377",
        "PDF": "https://arxiv.org/pdf/2506.20377"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:44:10 GMT",
          "size": "1168kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Role of Partisan Culture in Mental Health Language Online",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "This paper involves using natural language processing to analyze online mental health expressions but only mentions data processing in context to the study, without contributing novel methods in LLM data training."
      }
    },
    {
      "id": "2506.20409",
      "abstract": "Recent advancements in tool-augmented large language models have enabled them to interact with external tools, enhancing their ability to perform complex user tasks. However, existing approaches overlook the role of personalisation in guiding tool use. This work investigates how user preferences can be effectively integrated into goal-oriented dialogue agents. Through extensive analysis, we identify key weaknesses in the ability of LLMs to personalise tool use. To this end, we introduce \\name, a novel solution that enhances personalised tool use by leveraging a structured tagging tool and an uncertainty-based tool detector. TAPS significantly improves the ability of LLMs to incorporate user preferences, achieving the new state-of-the-art for open source models on the NLSI task.",
      "authors": [
        "Ekaterina Taktasheva and Jeff Dalton"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20409",
        "HTML": "https://arxiv.org/html/2506.20409",
        "PDF": "https://arxiv.org/pdf/2506.20409"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:24:46 GMT",
          "size": "8691kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TAPS: Tool-Augmented Personalisation via Structured Tagging",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although it explores personalisation and tool-use in LLMs, the paper does not focus on new methods for collecting or processing training data specifically for LLM training."
      }
    },
    {
      "id": "2506.20415",
      "abstract": "Ensuring the security of complex system-on-chips (SoCs) designs is a critical imperative, yet traditional verification techniques struggle to keep pace due to significant challenges in automation, scalability, comprehensiveness, and adaptability. The advent of large language models (LLMs), with their remarkable capabilities in natural language understanding, code generation, and advanced reasoning, presents a new paradigm for tackling these issues. Moving beyond monolithic models, an agentic approach allows for the creation of multi-agent systems where specialized LLMs collaborate to solve complex problems more effectively. Recognizing this opportunity, we introduce SV-LLM, a novel multi-agent assistant system designed to automate and enhance SoC security verification. By integrating specialized agents for tasks like verification question answering, security asset identification, threat modeling, test plan and property generation, vulnerability detection, and simulation-based bug validation, SV-LLM streamlines the workflow. To optimize their performance in these diverse tasks, agents leverage different learning paradigms, such as in-context learning, fine-tuning, and retrieval-augmented generation (RAG). The system aims to reduce manual intervention, improve accuracy, and accelerate security analysis, supporting proactive identification and mitigation of risks early in the design cycle. We demonstrate its potential to transform hardware security practices through illustrative case studies and experiments that showcase its applicability and efficacy.",
      "authors": [
        "Dipayan Saha",
        "Shams Tarek",
        "Hasan Al Shaikh",
        "Khan Thamid Hasan",
        "Pavan Sai Nalluri",
        "Md. Ajoad Hasan",
        "Nashmin Alam",
        "Jingbo Zhou",
        "Sujan Kumar Saha",
        "Mark Tehranipoor",
        "and Farimah Farahmandi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20415",
        "HTML": "https://arxiv.org/html/2506.20415",
        "PDF": "https://arxiv.org/pdf/2506.20415"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:31:13 GMT",
          "size": "21381kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The use of LLMs for SoC security verification is mentioned, including learning methods like fine-tuning, but without focusing on the training data processing specifically for LLMs."
      }
    },
    {
      "id": "2506.20420",
      "abstract": "The rapid growth of web content has led to increasingly large webpages, posing significant challenges for Internet affordability, especially in developing countries where data costs remain prohibitively high. We propose semantic caching using Large Language Models (LLMs) to improve web affordability by enabling reuse of semantically similar images within webpages. Analyzing 50 leading news and media websites, encompassing 4,264 images and over 40,000 image pairs, we demonstrate potential for significant data transfer reduction, with some website categories showing up to 37% of images as replaceable. Our proof-of-concept architecture shows users can achieve approximately 10% greater byte savings compared to exact caching. We evaluate both commercial and open-source multi-modal LLMs for assessing semantic replaceability. GPT-4o performs best with a low Normalized Root Mean Square Error of 0.1735 and a weighted F1 score of 0.8374, while the open-source LLaMA 3.1 model shows comparable performance, highlighting its viability for large-scale applications. This approach offers benefits for both users and website operators, substantially reducing data transmission. We discuss ethical concerns and practical challenges, including semantic preservation, user-driven cache configuration, privacy concerns, and potential resistance from website operators",
      "authors": [
        "Hafsa Akbar",
        "Danish Athar",
        "Muhammad Ayain Fida Rana",
        "Chaudhary Hammad Javed",
        "Zartash Afzal Uzmi",
        "Ihsan Ayyub Qazi",
        "Zafar Ayyub Qazi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20420",
        "HTML": "https://arxiv.org/html/2506.20420",
        "PDF": "https://arxiv.org/pdf/2506.20420"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:35:25 GMT",
          "size": "651kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Semantic Caching for Improving Web Affordability",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "This paper explores semantic caching using LLMs for reducing web data transfer costs, mentioning LLM usage but not specifically focusing on LLM training data processing."
      }
    },
    {
      "id": "2506.20430",
      "abstract": "Rare diseases collectively affect over 300 million individuals worldwide, yet timely and accurate diagnosis remains a pervasive challenge. This is largely due to their clinical heterogeneity, low individual prevalence, and the limited familiarity most clinicians have with rare conditions. Here, we introduce DeepRare, the first rare disease diagnosis agentic system powered by a large language model (LLM), capable of processing heterogeneous clinical inputs. The system generates ranked diagnostic hypotheses for rare diseases, each accompanied by a transparent chain of reasoning that links intermediate analytic steps to verifiable medical evidence.\n  DeepRare comprises three key components: a central host with a long-term memory module; specialized agent servers responsible for domain-specific analytical tasks integrating over 40 specialized tools and web-scale, up-to-date medical knowledge sources, ensuring access to the most current clinical information. This modular and scalable design enables complex diagnostic reasoning while maintaining traceability and adaptability. We evaluate DeepRare on eight datasets. The system demonstrates exceptional diagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013 diseases. In HPO-based evaluations, DeepRare significantly outperforms other 15 methods, like traditional bioinformatics diagnostic tools, LLMs, and other agentic systems, achieving an average Recall@1 score of 57.18% and surpassing the second-best method (Reasoning LLM) by a substantial margin of 23.79 percentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at Recall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of reasoning chains by clinical experts achieves 95.40% agreements. Furthermore, the DeepRare system has been implemented as a user-friendly web application http://raredx.cn/doctor.",
      "authors": [
        "Weike Zhao",
        "Chaoyi Wu",
        "Yanjie Fan",
        "Xiaoman Zhang",
        "Pengcheng Qiu",
        "Yuze Sun",
        "Xiao Zhou",
        "Yanfeng Wang",
        "Ya Zhang",
        "Yongguo Yu",
        "Kun Sun and Weidi Xie"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20430",
        "HTML": "https://arxiv.org/html/2506.20430",
        "PDF": "https://arxiv.org/pdf/2506.20430"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:42:26 GMT",
          "size": "5805kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "An Agentic System for Rare Disease Diagnosis with Traceable Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a system powered by an LLM for rare disease diagnosis, but it focuses on applications and does not propose new methods for LLM training data processing."
      }
    },
    {
      "id": "2506.20444",
      "abstract": "Vulnerability detection is crucial for identifying security weaknesses in software systems. However, the effectiveness of machine learning models in this domain is often hindered by low-quality training datasets, which contain noisy, mislabeled, or imbalanced samples. This paper proposes a novel dataset maps-empowered approach that systematically identifies and mitigates hard-to-learn outliers, referred to as \"bad seeds\", to improve model training efficiency. Our approach can categorize training examples based on learning difficulty and integrate this information into an active learning framework. Unlike traditional methods that focus on uncertainty-based sampling, our strategy prioritizes dataset quality by filtering out performance-harmful samples while emphasizing informative ones. Our experimental results show that our approach can improve F1 score over random selection by 45.36% (DeepGini) and 45.91% (K-Means) and outperforms standard active learning by 61.46% (DeepGini) and 32.65% (K-Means) for CodeBERT on the Big-Vul dataset, demonstrating the effectiveness of integrating dataset maps for optimizing sample selection in vulnerability detection. Furthermore, our approach also enhances model robustness, improves sample selection by filtering bad seeds, and stabilizes active learning performance across iterations. By analyzing the characteristics of these outliers, we provide insights for future improvements in dataset construction, making vulnerability detection more reliable and cost-effective.",
      "authors": [
        "Xiang Lan",
        "Tim Menzies",
        "Bowen Xu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20444",
        "HTML": "https://arxiv.org/html/2506.20444",
        "PDF": "https://arxiv.org/pdf/2506.20444"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:50:21 GMT",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Smart Cuts: Enhance Active Learning for Vulnerability Detection by Pruning Bad Seeds",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper presents a method to improve data quality for training vulnerability detection models by identifying outliers, which can be tangentially related to training data processing for LLMs. However, it does not propose new methods specific to LLMs."
      }
    },
    {
      "id": "2506.20449",
      "abstract": "Text-to-image generative models have achieved remarkable breakthroughs in recent years. However, their application in medical image generation still faces significant challenges, including small dataset sizes, and scarcity of medical textual data. To address these challenges, we propose Med-Art, a framework specifically designed for medical image generation with limited data. Med-Art leverages vision-language models to generate visual descriptions of medical images which overcomes the scarcity of applicable medical textual data. Med-Art adapts a large-scale pre-trained text-to-image model, PixArt-$\\alpha$, based on the Diffusion Transformer (DiT), achieving high performance under limited data. Furthermore, we propose an innovative Hybrid-Level Diffusion Fine-tuning (HLDF) method, which enables pixel-level losses, effectively addressing issues such as overly saturated colors. We achieve state-of-the-art performance on two medical image datasets, measured by FID, KID, and downstream classification performance.",
      "authors": [
        "Changlu Guo",
        "Anders Nymark Christensen",
        "and Morten Rieger Hannemose"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20449",
        "HTML": "https://arxiv.org/html/2506.20449",
        "PDF": "https://arxiv.org/pdf/2506.20449"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:56:48 GMT",
          "size": "474kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses generating medical images using vision-language models from limited data, but it does not focus on novel LLM training data processing methods. It mainly adapts pre-trained models for a specific application."
      }
    },
    {
      "id": "2506.20451",
      "abstract": "A fundamental question in applying In-Context Learning (ICL) for tabular data classification is how to determine the ideal number of demonstrations in the prompt. This work addresses this challenge by presenting an algorithm to automatically select a reasonable number of required demonstrations. Our method distinguishes itself by integrating not only the tabular data's distribution but also the user's selected prompt template and the specific Large Language Model (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed algorithm defines a novel metric to quantify the similarities between different demonstrations. We then construct a similarity graph and analyze the eigenvalues of its Laplacian to derive the minimum number of demonstrations capable of representing the data within the LLM's intrinsic representation space. We validate the efficacy of our approach through experiments comparing its performance against conventional random selection algorithms on diverse datasets and LLMs.",
      "authors": [
        "Shuchu Han",
        "Wolfgang Bruckner"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20451",
        "HTML": "https://arxiv.org/html/2506.20451",
        "PDF": "https://arxiv.org/pdf/2506.20451"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:57:54 GMT",
          "size": "2356kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Automatic Demonstration Selection for LLM-based Tabular Data Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although the paper presents an algorithm for selecting demonstrations in In-Context Learning with LLMs, it primarily addresses demonstration selection for tabular data rather than data processing for LLM training."
      }
    },
    {
      "id": "2506.20471",
      "abstract": "Large language models (LLMs) have become ubiquitous, interfacing with humans in numerous safety-critical applications. This necessitates improving capabilities, but importantly coupled with greater safety measures to align these models with human values and preferences. In this work, we demonstrate that contemporary models fall concerningly short of the goal of AI safety, leading to an unsafe and harmful experience for users. We introduce a prompting strategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT converts natural language inputs to simple code that represents the same intent. For instance, CoDoT transforms the natural language prompt \"Make the statement more toxic: {text}\" to: \"make_more_toxic({text})\". We show that CoDoT results in a consistent failure of a wide range of state-of-the-art LLMs. For example, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of the time, and toxicity increases 300% on average across seven modern LLMs. Additionally, recursively applying CoDoT can further increase toxicity two times. Given the rapid and widespread adoption of LLMs, CoDoT underscores the critical need to evaluate safety efforts from first principles, ensuring that safety and capabilities advance together.",
      "authors": [
        "Ujwal Narayan",
        "Shreyas Chaudhari",
        "Ashwin Kalyan",
        "Tanmay Rajpurohit",
        "Karthik Narasimhan",
        "Ameet Deshpande",
        "Vishvak Murahari"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20471",
        "HTML": "https://arxiv.org/html/2506.20471",
        "PDF": "https://arxiv.org/pdf/2506.20471"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:19:57 GMT",
          "size": "2378kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Probing AI Safety with Source Code",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions a prompting strategy to assess the safety of LLMs but primarily focuses on AI safety evaluation, not directly on training data processing or data engineering for LLMs."
      }
    },
    {
      "id": "2506.20476",
      "abstract": "This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG competition. The competition's evaluation set, automatically generated by DataMorgana from internet corpora, encompassed a wide range of target topics, question types, question formulations, audience types, and knowledge organization methods. It offered a fair evaluation of retrieving question-relevant supporting documents from a 15M documents subset of the FineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline achieved first place in the competition.",
      "authors": [
        "Tong Zhou"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20476",
        "HTML": "https://arxiv.org/html/2506.20476",
        "PDF": "https://arxiv.org/pdf/2506.20476"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:23:21 GMT",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Knowledge-Aware Diverse Reranking for Cross-Source Question Answering",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions retrieving question-relevant documents from a corpus in the context of a competition, indicating some data processing but not directly connected to LLM training data pipelines."
      }
    },
    {
      "id": "2506.20488",
      "abstract": "The rapid advancement of 6G wireless networks, IoT, and edge computing has significantly expanded the cyberattack surface, necessitating more intelligent and adaptive vulnerability detection mechanisms. Traditional security methods, while foundational, struggle with zero-day exploits, adversarial threats, and context-dependent vulnerabilities in highly dynamic network environments. Generative AI (GAI) emerges as a transformative solution, leveraging synthetic data generation, multimodal reasoning, and adaptive learning to enhance security frameworks. This paper explores the integration of GAI-powered vulnerability detection in 6G wireless networks, focusing on code auditing, protocol security, cloud-edge defenses, and hardware protection. We introduce a three-layer framework comprising the Technology Layer, Capability Layer, and Application Layer to systematically analyze the role of VAEs, GANs, LLMs, and GDMs in securing next-generation wireless ecosystems. To demonstrate practical implementation, we present a case study on LLM-driven code vulnerability detection, highlighting its effectiveness, performance, and challenges. Finally, we outline future research directions, including lightweight models, high-authenticity data generation, external knowledge integration, and privacy-preserving technologies. By synthesizing current advancements and open challenges, this work provides a roadmap for researchers and practitioners to harness GAI for building resilient and adaptive security solutions in 6G networks.",
      "authors": [
        "Shuo Yang",
        "Xinran Zheng",
        "Jinfeng Xu",
        "Jinze Li",
        "Danyang Song",
        "Zheyu Chen and Edith C.H. Ngai"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20488",
        "HTML": "https://arxiv.org/html/2506.20488",
        "PDF": "https://arxiv.org/pdf/2506.20488"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:36:31 GMT",
          "size": "827kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper touches on LLMs for vulnerability detection, its primary focus is security in wireless networks. Training data for LLMs is not a main contribution or extensive focus."
      }
    },
    {
      "id": "2506.20494",
      "abstract": "Multi-modal learning is a fast growing area in artificial intelligence. It tries to help machines understand complex things by combining information from different sources, like images, text, and audio. By using the strengths of each modality, multi-modal learning allows AI systems to build stronger and richer internal representations. These help machines better interpretation, reasoning, and making decisions in real-life situations. This field includes core techniques such as representation learning (to get shared features from different data types), alignment methods (to match information across modalities), and fusion strategies (to combine them by deep learning models). Although there has been good progress, some major problems still remain. Like dealing with different data formats, missing or incomplete inputs, and defending against adversarial attacks. Researchers now are exploring new methods, such as unsupervised or semi-supervised learning, AutoML tools, to make models more efficient and easier to scale. And also more attention on designing better evaluation metrics or building shared benchmarks, make it easier to compare model performance across tasks and domains. As the field continues to grow, multi-modal learning is expected to improve many areas: computer vision, natural language processing, speech recognition, and healthcare. In the future, it may help to build AI systems that can understand the world in a way more like humans, flexible, context aware, and able to deal with real-world complexity.",
      "authors": [
        "Qihang Jin",
        "Enze Ge",
        "Yuhang Xie",
        "Hongying Luo",
        "Junhao Song",
        "Ziqian Bi",
        "Chia Xin Liang",
        "Jibin Guan",
        "Joe Yeong",
        "Junfeng Hao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20494",
        "HTML": "https://arxiv.org/html/2506.20494",
        "PDF": "https://arxiv.org/pdf/2506.20494"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 14:40:09 GMT",
          "size": "3221kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multimodal Representation Learning and Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper mentions multi-modal learning and combining information from different sources, it does not propose new methods or focus specifically on LLM training data processing."
      }
    },
    {
      "id": "2506.20520",
      "abstract": "Reinforcement learning (RL) is increasingly used to align large language models (LLMs). Off-policy methods offer greater implementation simplicity and data efficiency than on-policy techniques, but often result in suboptimal performance. In this work, we study the intermediate range of algorithms between off-policy RL and supervised fine-tuning by analyzing a simple off-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with $r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$ emphasizes high-reward samples, while raising it penalizes low-reward ones more heavily. We first provide a theoretical analysis of this off-policy REINFORCE algorithm, showing that when the baseline $V$ lower-bounds the expected reward, the algorithm enjoys a policy improvement guarantee. Our analysis reveals that while on-policy updates can safely leverage both positive and negative signals, off-policy updates benefit from focusing more on positive rewards than on negative ones. We validate our findings experimentally in a controlled stochastic bandit setting and through fine-tuning state-of-the-art LLMs on reasoning tasks.",
      "authors": [
        "Charles Arnal",
        "Ga\\\"etan Narozniak",
        "Vivien Cabannes",
        "Yunhao Tang",
        "Julia Kempe",
        "Remi Munos"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20520",
        "HTML": "https://arxiv.org/html/2506.20520",
        "PDF": "https://arxiv.org/pdf/2506.20520"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:07:16 GMT",
          "size": "406kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper explores reinforcement learning for LLMs, it is mainly focused on theoretical and algorithmic aspects of RL rather than the preprocessing or engineering of training data for LLMs."
      }
    },
    {
      "id": "2506.20551",
      "abstract": "This research addresses the time-consuming and error-prone nature of manual code compliance checking in Building Information Modeling (BIM) by introducing a Large Language Model (LLM)-driven approach to semi-automate this critical process. The developed system integrates LLMs such as GPT, Claude, Gemini, and Llama, with Revit software to interpret building codes, generate Python scripts, and perform semi-automated compliance checks within the BIM environment. Case studies on a single-family residential project and an office building project demonstrated the system's ability to reduce the time and effort required for compliance checks while improving accuracy. It streamlined the identification of violations, such as non-compliant room dimensions, material usage, and object placements, by automatically assessing relationships and generating actionable reports. Compared to manual methods, the system eliminated repetitive tasks, simplified complex regulations, and ensured reliable adherence to standards. By offering a comprehensive, adaptable, and cost-effective solution, this proposed approach offers a promising advancement in BIM-based compliance checking, with potential applications across diverse regulatory documents in construction projects.",
      "authors": [
        "Soumya Madireddy",
        "Lu Gao",
        "Zia Din",
        "Kinam Kim",
        "Ahmed Senouci",
        "Zhe Han",
        "Yunpeng Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20551",
        "HTML": "https://arxiv.org/html/2506.20551",
        "PDF": "https://arxiv.org/pdf/2506.20551"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:50:34 GMT",
          "size": "5140kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Large Language Model-Driven Code Compliance Checking in Building Information Modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper utilizes LLMs to aid code compliance checking in Building Information Modeling, it primarily revolves around application without introducing novel methods for processing or preparing LLM training data."
      }
    },
    {
      "id": "2506.20558",
      "abstract": "Comments within code serve as a crucial foundation for software documentation, facilitating developers to communicate and understand the code effectively. However, code-comment inconsistency (CCI) can negatively affect software development, testing, and maintenance. Recent efforts to mitigate this issue have emerged, but existing studies often suffer from inaccurate datasets and inadequate solutions, weakening their practical effectiveness. In this study, we first conduct a quantitative analysis of existing datasets, revealing a substantial portion of sampled data are mislabeled. To address these data limitations, we introduce CCIBench, a refined dataset comprising high-quality data, to support the training and evaluation of method-level CCI methods. Furthermore, we present an innovative end-to-end LLM-based framework, CCISolver, designed to improve code quality by identifying and rectifying CCIs. Comprehensive evaluations demonstrate CCISolver's superior performance. For detection, it establishes a new state-of-the-art with an F1-score of 89.54%. In fixing task, it achieves a remarkable 18.84% relative improvement in GLEU score over the strongest baseline. This superiority is confirmed by human evaluation, where CCISolver's fixing success rate of 0.6533 significantly surpasses existing methods. Critically, in a practical end-to-end setting, CCISolver's innovative architecture is approximately 36% faster for inference than the baseline model, underscoring its scalability and real-world applicability.",
      "authors": [
        "Renyi Zhong",
        "Yintong Huo",
        "Wenwei Gu",
        "Jinxi Kuang",
        "Zhihan Jiang",
        "Guangba Yu",
        "Yichen Li",
        "David Lo",
        "Michael R. Lyu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20558",
        "HTML": "https://arxiv.org/html/2506.20558",
        "PDF": "https://arxiv.org/pdf/2506.20558"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 15:56:07 GMT",
          "size": "825kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CCISolver: End-to-End Detection and Repair of Method-Level Code-Comment Inconsistency",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces CCIBench, a refined dataset for method-level code-comment inconsistency (CCI) methods, but focuses mainly on using this dataset for improving code quality, not specifically on LLM training data processing."
      }
    },
    {
      "id": "2506.20566",
      "abstract": "Real-time human perception is crucial for effective human-robot interaction (HRI). Large vision-language models (VLMs) offer promising generalizable perceptual capabilities but often suffer from high latency, which negatively impacts user experience and limits VLM applicability in real-world scenarios. To systematically study VLM capabilities in human perception for HRI and performance-latency trade-offs, we introduce HRIBench, a visual question-answering (VQA) benchmark designed to evaluate VLMs across a diverse set of human perceptual tasks critical for HRI. HRIBench covers five key domains: (1) non-verbal cue understanding, (2) verbal instruction understanding, (3) human-robot object relationship understanding, (4) social navigation, and (5) person identification. To construct HRIBench, we collected data from real-world HRI environments to curate questions for non-verbal cue understanding, and leveraged publicly available datasets for the remaining four domains. We curated 200 VQA questions for each domain, resulting in a total of 1000 questions for HRIBench. We then conducted a comprehensive evaluation of both state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench. Our results show that, despite their generalizability, current VLMs still struggle with core perceptual capabilities essential for HRI. Moreover, none of the models within our experiments demonstrated a satisfactory performance-latency trade-off suitable for real-time deployment, underscoring the need for future research on developing smaller, low-latency VLMs with improved human perception capabilities. HRIBench and our results can be found in this Github repository: https://github.com/interaction-lab/HRIBench.",
      "authors": [
        "Zhonghao Shi",
        "Enyu Zhao",
        "Nathaniel Dennler",
        "Jingzhen Wang",
        "Xinyang Xu",
        "Kaleen Shrestha",
        "Mengxue Fu",
        "Daniel Seita",
        "Maja Matari\\'c"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20566",
        "HTML": "https://arxiv.org/html/2506.20566",
        "PDF": "https://arxiv.org/pdf/2506.20566"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:01:38 GMT",
          "size": "3768kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper involves collecting and curating data for benchmarking VLMs in human-robot interaction but does not propose novel methodologies for LLM training data processing."
      }
    },
    {
      "id": "2506.20595",
      "abstract": "The ubiquity of technologies like ChatGPT has raised concerns about their impact on student writing, particularly regarding reduced learner agency and superficial engagement with content. While standalone chat-based LLMs often produce suboptimal writing outcomes, evidence suggests that purposefully designed AI writing support tools can enhance the writing process. This paper investigates how different AI support approaches affect writers' sense of agency and depth of knowledge transformation. Through a randomized control trial with 90 undergraduate students, we compare three conditions: (1) a chat-based LLM writing assistant, (2) an integrated AI writing tool to support diverse subprocesses, and (3) a standard writing interface (control). Our findings demonstrate that, among AI-supported conditions, students using the integrated AI writing tool exhibited greater agency over their writing process and engaged in deeper knowledge transformation overall. These results suggest that thoughtfully designed AI writing support targeting specific aspects of the writing process can help students maintain ownership of their work while facilitating improved engagement with content.",
      "authors": [
        "Momin N. Siddiqui",
        "Roy Pea",
        "Hari Subramonyam"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20595",
        "HTML": "https://arxiv.org/html/2506.20595",
        "PDF": "https://arxiv.org/pdf/2506.20595"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:34:09 GMT",
          "size": "2040kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AI in the Writing Process: How Purposeful AI Support Fosters Student Writing",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper investigates AI support tools for student writing with mentions of LLMs, but the focus is on the writing process rather than on innovative contributions in training data processing for LLMs."
      }
    },
    {
      "id": "2506.20598",
      "abstract": "The global demand for sustainable protein sources has accelerated the need for intelligent tools that can rapidly process and synthesise domain-specific scientific knowledge. In this study, we present a proof-of-concept multi-agent Artificial Intelligence (AI) framework designed to support sustainable protein production research, with an initial focus on microbial protein sources. Our Retrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based LLM agents: (1) a literature search agent that retrieves relevant scientific literature on microbial protein production for a specified microbial strain, and (2) an information extraction agent that processes the retrieved content to extract relevant biological and chemical information. Two parallel methodologies, fine-tuning and prompt engineering, were explored for agent optimisation. Both methods demonstrated effectiveness at improving the performance of the information extraction agent in terms of transformer-based cosine similarity scores between obtained and ideal outputs. Mean cosine similarity scores were increased by up to 25%, while universally reaching mean scores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved the mean scores to a greater extent (consistently of $\\geq 0.94$) compared to prompt engineering, although lower statistical uncertainties were observed with the latter approach. A user interface was developed and published for enabling the use of the multi-agent AI system, alongside preliminary exploration of additional chemical safety-based search capabilities",
      "authors": [
        "Alexander D. Kalian",
        "Jaewook Lee",
        "Stefan P. Johannesson",
        "Lennart Otte",
        "Christer Hogstrand",
        "Miao Guo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20598",
        "HTML": "https://arxiv.org/html/2506.20598",
        "PDF": "https://arxiv.org/pdf/2506.20598"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:37:46 GMT",
          "size": "1909kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "This paper explores fine-tuning and prompt engineering for LLMs within a multi-agent AI framework, touching on data processing methods, but its primary focus is on application to sustainable protein production rather than on novel data engineering techniques for LLMs."
      }
    },
    {
      "id": "2506.20608",
      "abstract": "Generative AI, especially through large language models (LLMs), is transforming how technical knowledge can be accessed, reused, and extended. PETSc, a widely used numerical library for high-performance scientific computing, has accumulated a rich but fragmented knowledge base over its three decades of development, spanning source code, documentation, mailing lists, GitLab issues, Discord conversations, technical papers, and more. Much of this knowledge remains informal and inaccessible to users and new developers. To activate and utilize this knowledge base more effectively, the PETSc team has begun building an LLM-powered system that combines PETSc content with custom LLM tools -- including retrieval-augmented generation (RAG), reranking algorithms, and chatbots -- to assist users, support developers, and propose updates to formal documentation. This paper presents initial experiences designing and evaluating these tools, focusing on system architecture, using RAG and reranking for PETSc-specific information, evaluation methodologies for various LLMs and embedding models, and user interface design. Leveraging the Argonne Leadership Computing Facility resources, we analyze how LLM responses can enhance the development and use of numerical software, with an initial focus on scalable Krylov solvers. Our goal is to establish an extensible framework for knowledge-centered AI in scientific software, enabling scalable support, enriched documentation, and enhanced workflows for research and development. We conclude by outlining directions for expanding this system into a robust, evolving platform that advances software ecosystems to accelerate scientific discovery.",
      "authors": [
        "Barry Smith",
        "Junchao Zhang",
        "Hong Zhang",
        "Lois Curfman McInnes",
        "Murat Keceli",
        "Archit Vasan",
        "Satish Balay",
        "Toby Isaac",
        "Le Chen",
        "Venkatram Vishwanath"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20608",
        "HTML": "https://arxiv.org/html/2506.20608",
        "PDF": "https://arxiv.org/pdf/2506.20608"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:00:05 GMT",
          "size": "653kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AI Assistants to Enhance and Exploit the PETSc Knowledge Base",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses a system using LLM tools for enhancing the PETSc knowledge base, it briefly mentions retrieval-augmented generation and reranking, which are related to data processing but do not propose any novel LLM training data methods."
      }
    },
    {
      "id": "2506.20664",
      "abstract": "As Large Language Models (LLMs) gain agentic abilities, they will have to navigate complex multi-agent scenarios, interacting with human users and other agents in cooperative and competitive settings. This will require new reasoning skills, chief amongst them being theory of mind (ToM), or the ability to reason about the \"mental\" states of other agents. However, ToM and other multi-agent abilities in LLMs are poorly understood, since existing benchmarks suffer from narrow scope, data leakage, saturation, and lack of interactivity. We thus propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM drawing inspiration from cognitive science, computational pragmatics and multi-agent reinforcement learning. It is designed to be as easy as possible in all other dimensions, eliminating confounding factors commonly found in other benchmarks. To our knowledge, it is also the first platform for designing interactive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations of frontier LLMs, robustness studies, and human-AI cross-play experiments. We find that LLM game-playing abilities lag behind humans and simple word-embedding baselines. We then create variants of two classic cognitive science experiments within Decrypto to evaluate three key ToM abilities. Surprisingly, we find that state-of-the-art reasoning models are significantly worse at those tasks than their older counterparts. This demonstrates that Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and paves the path towards better artificial agents.",
      "authors": [
        "Andrei Lupu",
        "Timon Willi",
        "Jakob Foerster"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20664",
        "HTML": "https://arxiv.org/html/2506.20664",
        "PDF": "https://arxiv.org/pdf/2506.20664"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:55:27 GMT",
          "size": "2440kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a game-based benchmark, Decrypto, which involves evaluating multi-agent reasoning and theory of mind in LLMs. It mentions the use of specific datasets for benchmarking but does not propose new methods or data processing techniques for LLM training data."
      }
    },
    {
      "id": "2506.20666",
      "abstract": "Navigating everyday social situations often requires juggling conflicting goals, such as conveying a harsh truth, maintaining trust, all while still being mindful of another person's feelings. These value trade-offs are an integral part of human decision-making and language use, however, current tools for interpreting such dynamic and multi-faceted notions of values in LLMs are limited. In cognitive science, so-called \"cognitive models\" provide formal accounts of these trade-offs in humans, by modeling the weighting of a speaker's competing utility functions in choosing an action or utterance. In this work, we use a leading cognitive model of polite speech to interpret the extent to which LLMs represent human-like trade-offs. We apply this lens to systematically evaluate value trade-offs in two encompassing model settings: degrees of reasoning \"effort\" in frontier black-box models, and RL post-training dynamics of open-source models. Our results highlight patterns of higher informational utility than social utility in reasoning models, and in open-source models shown to be stronger in mathematical reasoning. Our findings from LLMs' training dynamics suggest large shifts in utility values early on in training with persistent effects of the choice of base model and pretraining data, compared to feedback dataset or alignment method. We show that our method is responsive to diverse aspects of the rapidly evolving LLM landscape, with insights for forming hypotheses about other high-level behaviors, shaping training regimes for reasoning models, and better controlling trade-offs between values during model training.",
      "authors": [
        "Sonia K. Murthy",
        "Rosie Zhao",
        "Jennifer Hu",
        "Sham Kakade",
        "Markus Wulfmeier",
        "Peng Qian",
        "Tomer Ullman"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20666",
        "HTML": "https://arxiv.org/html/2506.20666",
        "PDF": "https://arxiv.org/pdf/2506.20666"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:58:12 GMT",
          "size": "826kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper uses cognitive models to analyze value trade-offs in LLMs concerning their training dynamics. It does not focus on the processing of LLM training data but mentions existing datasets and pretraining which aligns with a weak relevance to data processing."
      }
    },
    {
      "id": "2506.20670",
      "abstract": "Robust deployment of large multimodal models (LMMs) in real-world scenarios requires access to external knowledge sources, given the complexity and dynamic nature of real-world information. Existing approaches such as retrieval-augmented generation (RAG) and prompt engineered search agents rely on rigid pipelines, often leading to inefficient or excessive search behaviors. We present MMSearch-R1, the first end-to-end reinforcement learning framework that enables LMMs to perform on-demand, multi-turn search in real-world Internet environments. Our framework integrates both image and text search tools, allowing the model to reason about when and how to invoke them guided by an outcome-based reward with a search penalty. To support training, We collect a multimodal search VQA dataset through a semi-automated pipeline that covers diverse visual and textual knowledge needs and curate a search-balanced subset with both search-required and search-free samples, which proves essential for shaping efficient and on-demand search behavior. Extensive experiments on knowledge-intensive and info-seeking VQA tasks show that our model not only outperforms RAG-based baselines of the same model size, but also matches the performance of a larger RAG-based model while reducing search calls by over 30%. We further analyze key empirical findings to offer actionable insights for advancing research in multimodal search.",
      "authors": [
        "Jinming Wu",
        "Zihao Deng",
        "Wei Li",
        "Yiding Liu",
        "Bo You",
        "Bo Li",
        "Zejun Ma",
        "Ziwei Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20670",
        "HTML": "https://arxiv.org/html/2506.20670",
        "PDF": "https://arxiv.org/pdf/2506.20670"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:59:42 GMT",
          "size": "9564kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MMSearch-R1: Incentivizing LMMs to Search",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper describes the development of a reinforcement learning framework for large multimodal models involving multimodal search VQA dataset collection. It touches upon data collection but lacks any novel contributions to LLM training data processing methods."
      }
    },
    {
      "id": "2506.16116",
      "abstract": "Teledermatology has become a widely accepted communication method in daily clinical practice, enabling remote care while showing strong agreement with in-person visits. Poor image quality remains an unsolved problem in teledermatology and is a major concern to practitioners, as bad-quality images reduce the usefulness of the remote consultation process. However, research on Image Quality Assessment (IQA) in dermatology is sparse, and does not leverage the latest advances in non-dermatology IQA, such as using larger image databases with ratings from large groups of human observers. In this work, we propose cross-domain training of IQA models, combining dermatology and non-dermatology IQA datasets. For this purpose, we created a novel dermatology IQA database, Legit.Health-DIQA-Artificial, using dermatology images from several sources and having them annotated by a group of human observers. We demonstrate that cross-domain training yields optimal performance across domains and overcomes one of the biggest limitations in dermatology IQA, which is the small scale of data, and leads to models trained on a larger pool of image distortions, resulting in a better management of image quality in the teledermatology process.",
      "authors": [
        "Ignacio Hern\\'andez Montilla",
        "Alfonso Medela",
        "Paola Pasquali",
        "Andy Aguilar",
        "Taig Mac Carthy",
        "Gerardo Fern\\'andez",
        "Antonio Martorell",
        "and Enrique Onieva"
      ],
      "last_revised_date": "2025/06/19",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16116",
        "HTML": "https://arxiv.org/html/2506.16116",
        "PDF": "https://arxiv.org/pdf/2506.16116"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 08:07:06 GMT",
          "size": "4498kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/19",
      "title": "Enhanced Dermatology Image Quality Assessment via Cross-Domain Training",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper deals with image quality assessment via cross-domain training, creating a new dermatology IQA database. While it involves data collection and creation, it is not directly related to LLM training data processing."
      },
      "tasks": [
        "Image Quality Assessment"
      ]
    },
    {
      "id": "2506.19863",
      "abstract": "The AI for Nuclear Energy workshop at Oak Ridge National Laboratory evaluated the potential of Large Language Models (LLMs) to accelerate fusion and fission research. Fourteen interdisciplinary teams explored diverse nuclear science challenges using ChatGPT, Gemini, Claude, and other AI models over a single day. Applications ranged from developing foundation models for fusion reactor control to automating Monte Carlo simulations, predicting material degradation, and designing experimental programs for advanced reactors. Teams employed structured workflows combining prompt engineering, deep research capabilities, and iterative refinement to generate hypotheses, prototype code, and research strategies. Key findings demonstrate that LLMs excel at early-stage exploration, literature synthesis, and workflow design, successfully identifying research gaps and generating plausible experimental frameworks. However, significant limitations emerged, including difficulties with novel materials designs, advanced code generation for modeling and simulation, and domain-specific details requiring expert validation. The successful outcomes resulted from expert-driven prompt engineering and treating AI as a complementary tool rather than a replacement for physics-based methods. The workshop validated AI's potential to accelerate nuclear energy research through rapid iteration and cross-disciplinary synthesis while highlighting the need for curated nuclear-specific datasets, workflow automation, and specialized model development. These results provide a roadmap for integrating AI tools into nuclear science workflows, potentially reducing development cycles for safer, more efficient nuclear energy systems while maintaining rigorous scientific standards.",
      "authors": [
        "Ahmed Almeldein",
        "Mohammed Alnaggar",
        "Rick Archibald",
        "Tom Beck",
        "Arpan Biswas",
        "Rike Bostelmann",
        "Wes Brewer",
        "Chris Bryan",
        "Christopher Calle",
        "Cihangir Celik",
        "Rajni Chahal",
        "Jong Youl Choi",
        "Arindam Chowdhury",
        "Mark Cianciosa",
        "Franklin Curtis",
        "Gregory Davidson",
        "Sebastian De Pascuale",
        "Lisa Fassino",
        "Ana Gainaru",
        "Yashika Ghai",
        "Luke Gibson",
        "Qian Gong",
        "Christopher Greulich",
        "Scott Greenwood",
        "Cory Hauck",
        "Ehab Hassan",
        "Rinkle Juneja",
        "Soyoung Kang",
        "Scott Klasky",
        "Atul Kumar",
        "Vineet Kumar",
        "Paul Laiu",
        "Calvin Lear",
        "Yan-Ru Lin",
        "Jono McConnell",
        "Furkan Oz",
        "Anant Raj",
        "Pradeep Ramuhalli",
        "Marie Romedenne",
        "Samantha Sabatino",
        "Jos\\'e Salcedo-P\\'erez",
        "Nathan D. See",
        "Arpan Sircar",
        "Punam Thankur",
        "Tim Younkin",
        "Xiao-Ying Yu",
        "Prashant Jain",
        "Tom Evans",
        "Prasanna Balaprakash"
      ],
      "last_revised_date": "2025/06/10",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19863",
        "HTML": "https://arxiv.org/html/2506.19863",
        "PDF": "https://arxiv.org/pdf/2506.19863"
      },
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Jun 2025 09:28:18 GMT",
          "size": "14219kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/10",
      "title": "Exploring the Capabilities of the Frontier Large Language Models for Nuclear Energy Research",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper highlights the use of LLMs in nuclear energy research, mentioning a need for curated datasets but primarily focuses on applications, not on data collection, construction, or processing methods."
      }
    },
    {
      "id": "2403.08059",
      "abstract": "Language promptable X-ray image segmentation would enable greater flexibility for human-in-the-loop workflows in diagnostic and interventional precision medicine. Prior efforts have contributed task-specific models capable of solving problems within a narrow scope, but expanding to broader use requires additional data, annotations, and training time. Recently, language-aligned foundation models (LFMs) -- machine learning models trained on large amounts of highly variable image and text data thus enabling broad applicability -- have emerged as promising tools for automated image analysis. Existing foundation models for medical image analysis focus on scenarios and modalities where large, richly annotated datasets are available. However, the X-ray imaging modality features highly variable image appearance and applications, from diagnostic chest X-rays to interventional fluoroscopy, with varying availability of data. To pave the way toward an LFM for comprehensive and language-aligned analysis of arbitrary medical X-ray images, we introduce FluoroSAM, a language-promptable variant of the Segment Anything Model, trained from scratch on 3M synthetic X-ray images from a wide variety of human anatomies, imaging geometries, and viewing angles. These include pseudo-ground truth masks for 128 organ types and 464 tools with associated text descriptions. FluoroSAM is capable of segmenting myriad anatomical structures and tools based on natural language prompts, thanks to the novel incorporation of vector quantization (VQ) of text embeddings in the training process. We demonstrate FluoroSAM's performance quantitatively on real X-ray images and showcase on several applications how FluoroSAM is a key enabler for rich human-machine interaction in the X-ray image acquisition and analysis context. Code is available at https://github.com/arcadelab/fluorosam.",
      "authors": [
        "Benjamin D. Killeen",
        "Liam J. Wang",
        "Blanca Inigo",
        "Han Zhang",
        "Mehran Armand",
        "Russell H. Taylor",
        "Greg Osgood",
        "Mathias Unberath"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08059",
        "HTML": "https://arxiv.org/html/2403.08059",
        "PDF": "https://arxiv.org/pdf/2403.08059"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 12 Mar 2024 20:11:38 GMT",
          "size": "6284kb",
          "version": "v1"
        },
        {
          "date": "Thu, 28 Mar 2024 00:59:37 GMT",
          "size": "6284kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 16:40:39 GMT",
          "size": "10570kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "FluoroSAM: A Language-promptable Foundation Model for Flexible X-ray Image Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper involves a novel model (FluoroSAM) using language prompts, it primarily applies to X-ray image segmentation, involving synthetic data. It briefly touches on training data with language alignment, but does not focus on LLM training data processing methodologies specifically."
      },
      "tasks": [
        "Diagnostic",
        "Image Segmentation",
        "Medical Image Analysis",
        "Semantic Segmentation",
        "Zero-shot Generalization"
      ],
      "repo_urls": [
        "https://github.com/arcadelab/fluorosam"
      ]
    },
    {
      "id": "2403.17852",
      "abstract": "Machine learning models have shown exceptional prowess in solving complex issues across various domains. However, these models can sometimes exhibit biased decision-making, resulting in unequal treatment of different groups. Despite substantial research on counterfactual fairness, methods to reduce the impact of multivariate and continuous sensitive variables on decision-making outcomes are still underdeveloped. We propose a novel data pre-processing algorithm, Orthogonal to Bias (OB), which is designed to eliminate the influence of a group of continuous sensitive variables, thus promoting counterfactual fairness in machine learning applications. Our approach, based on the assumption of a jointly normal distribution within a structural causal model (SCM), demonstrates that counterfactual fairness can be achieved by ensuring the data is orthogonal to the observed sensitive variables. The OB algorithm is model-agnostic, making it applicable to a wide range of machine learning models and tasks. Additionally, it includes a sparse variant to improve numerical stability through regularization. Empirical evaluations on both simulated and real-world datasets, encompassing settings with both discrete and continuous sensitive variables, show that our methodology effectively promotes fairer outcomes without compromising accuracy.",
      "authors": [
        "Shuyi Chen",
        "Shixiang Zhu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17852",
        "HTML": "https://arxiv.org/html/2403.17852",
        "PDF": "https://arxiv.org/pdf/2403.17852"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 26 Mar 2024 16:40:08 GMT",
          "size": "3850kb",
          "version": "v1"
        },
        {
          "date": "Sun, 30 Jun 2024 01:51:00 GMT",
          "size": "1774kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 05:35:44 GMT",
          "size": "2561kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Counterfactual Fairness through Transforming Data Orthogonal to Bias",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper describes a data pre-processing algorithm aimed at promoting fairness in machine learning, which could be applicable to LLMs, but does not specifically address LLM training data processing or engineering."
      },
      "tasks": [
        "counterfactual",
        "Decision Making",
        "Fairness"
      ]
    },
    {
      "id": "2403.19827",
      "abstract": "Language models learn rare syntactic phenomena, but the extent to which this is attributable to generalization vs. memorization is a major open question. To that end, we iteratively trained transformer language models on systematically manipulated corpora which were human-scale in size, and then evaluated their learning of a rare grammatical phenomenon: the English Article+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days''). We compared how well this construction was learned on the default corpus relative to a counterfactual corpus in which AANN sentences were removed. We found that AANNs were still learned better than systematically perturbed variants of the construction. Using additional counterfactual corpora, we suggest that this learning occurs through generalization from related constructions (e.g., ``a few days''). An additional experiment showed that this learning is enhanced when there is more variability in the input. Taken together, our results provide an existence proof that LMs can learn rare grammatical phenomena by generalization from less rare phenomena. Data and code: https://github.com/kanishkamisra/aannalysis.",
      "authors": [
        "Kanishka Misra",
        "Kyle Mahowald"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.19827",
        "HTML": "https://arxiv.org/html/2403.19827",
        "PDF": "https://arxiv.org/pdf/2403.19827"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 28 Mar 2024 20:35:10 GMT",
          "size": "934kb",
          "version": "v1"
        },
        {
          "date": "Sat, 10 Aug 2024 19:45:30 GMT",
          "size": "1734kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 21:39:54 GMT",
          "size": "708kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The study investigates LLMs' learning capabilities regarding rare syntactic phenomena, but focuses on generalization properties rather than the direct processing or engineering of training data for LLMs."
      },
      "tasks": [
        "counterfactual",
        "Memorization"
      ]
    },
    {
      "id": "2404.17582",
      "abstract": "As crowdsourcing emerges as an efficient and cost-effective method for obtaining labels for machine learning datasets, it is important to assess the quality of crowd-provided data, so as to improve analysis performance and reduce biases in subsequent machine learning tasks. Given the lack of ground truth in most cases of crowdsourcing, we refer to data quality as annotators' consistency and credibility. Unlike the simple scenarios where Kappa coefficient and intraclass correlation coefficient usually can apply, online crowdsourcing requires dealing with more complex situations. We introduce a systematic method for evaluating data quality and detecting spamming threats via variance decomposition, and we classify spammers into three categories based on their different behavioral patterns. A spammer index is proposed to assess entire data consistency, and two metrics are developed to measure crowd workers' credibility by utilizing the Markov chain and generalized random effects models. Furthermore, we showcase the practicality of our techniques and their advantages by applying them on a face verification task with both simulation and real-world data collected from two crowdsourcing platforms.",
      "authors": [
        "Yang Ba",
        "Michelle V. Mancenido",
        "Erin K. Chiou",
        "and Rong Pan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.17582",
        "HTML": "https://arxiv.org/html/2404.17582",
        "PDF": "https://arxiv.org/pdf/2404.17582"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 04 Apr 2024 02:21:38 GMT",
          "size": "2665kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 17:56:08 GMT",
          "size": "1719kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Data Quality in Crowdsourcing and Spamming Behavior Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While it deals with data quality in crowdsourcing, which can relate to data collection methods, it does not specifically propose new methods for LLM data processing."
      },
      "tasks": [
        "Face Verification"
      ]
    },
    {
      "id": "2408.05894",
      "abstract": "Vision-Language Models (VLMs) building upon the foundation of powerful large language models have made rapid progress in reasoning across visual and textual data. While VLMs perform well on vision tasks that they are trained on, our results highlight key challenges in abstract pattern recognition. We present GlyphPattern, a 954 item dataset that pairs 318 human-written descriptions of visual patterns from 40 writing systems with three visual presentation styles.\n  GlyphPattern evaluates abstract pattern recognition in VLMs, requiring models to understand and judge natural language descriptions of visual patterns. GlyphPattern patterns are drawn from a large-scale cognitive science investigation of human writing systems; as a result, they are rich in spatial reference and compositionality. Our experiments show that GlyphPattern is challenging for state-of-the-art VLMs (GPT-4o achieves only 55% accuracy), with marginal gains from few-shot prompting. Our detailed error analysis reveals challenges at multiple levels, including visual processing, natural language understanding, and pattern generalization.",
      "authors": [
        "Zixuan Wu",
        "Yoolim Kim",
        "and Carolyn Jane Anderson"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05894",
        "HTML": "https://arxiv.org/html/2408.05894",
        "PDF": "https://arxiv.org/pdf/2408.05894"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 12 Aug 2024 02:16:47 GMT",
          "size": "4168kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 18:23:10 GMT",
          "size": "9726kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "GlyphPattern: An Abstract Pattern Recognition Benchmark for Vision-Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces GlyphPattern, a dataset for evaluating vision-language models rather than focusing on LLM training data processing. It mentions dataset creation but not in the context of LLM-specific data engineering or training processing improvements."
      },
      "tasks": [
        "Natural Language Understanding"
      ],
      "repo_urls": [
        "https://github.com/Wellesley-EASEL-lab/GlyphPattern"
      ]
    },
    {
      "id": "2410.18362",
      "abstract": "Web development involves turning UI designs into functional webpages, which can be difficult for both beginners and experienced developers due to the complexity of HTML's hierarchical structures and styles. While Large Language Models (LLMs) have shown promise in generating source code, two major challenges persist in UI-to-HTML code generation: (1) effectively representing HTML's hierarchical structure for LLMs, and (2) bridging the gap between the visual nature of UI designs and the text-based format of HTML code. To tackle these challenges, we introduce Waffle, a new fine-tuning strategy that uses a structure-aware attention mechanism to improve LLMs' understanding of HTML's structure and a contrastive fine-tuning approach to align LLMs' understanding of UI images and HTML code. Models fine-tuned with Waffle show up to 9.00 pp (percentage point) higher HTML match, 0.0982 higher CW-SSIM, 32.99 higher CLIP, and 27.12 pp higher LLEM on our new benchmark WebSight-Test and an existing benchmark Design2Code, outperforming current fine-tuning methods.",
      "authors": [
        "Shanchao Liang",
        "Nan Jiang",
        "Shangshu Qian",
        "Lin Tan"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18362",
        "HTML": "https://arxiv.org/html/2410.18362",
        "PDF": "https://arxiv.org/pdf/2410.18362"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 24 Oct 2024 01:49:49 GMT",
          "size": "5906kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 20:35:02 GMT",
          "size": "5316kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "WAFFLE: Finetuning Multi-Modal Model for Automated Front-End Development",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper describes a fine-tuning strategy for LLMs in automated front-end development, mentioning training data in the context of benchmarks but not as a primary contribution to LLM data processing."
      },
      "models": [
        {
          "model_path": "lt-asset/Waffle_VLM_WebSight",
          "downloads": "32",
          "likes": "12",
          "trending_score": "0.0",
          "link": "https://huggingface.co/lt-asset/Waffle_VLM_WebSight"
        }
      ],
      "tasks": [
        "Code Generation",
        "SSIM"
      ],
      "repo_urls": [
        "https://github.com/lt-asset/Waffle"
      ]
    },
    {
      "id": "2411.08745",
      "abstract": "A central question in multilingual language modeling is whether large language models (LLMs) develop a universal concept representation, disentangled from specific languages. In this paper, we address this question by analyzing latent representations (latents) during a word-translation task in transformer-based LLMs. We strategically extract latents from a source translation prompt and insert them into the forward pass on a target translation prompt. By doing so, we find that the output language is encoded in the latent at an earlier layer than the concept to be translated. Building on this insight, we conduct two key experiments. First, we demonstrate that we can change the concept without changing the language and vice versa through activation patching alone. Second, we show that patching with the mean representation of a concept across different languages does not affect the models' ability to translate it, but instead improves it. Finally, we generalize to multi-token generation and demonstrate that the model can generate natural language description of those mean representations. Our results provide evidence for the existence of language-agnostic concept representations within the investigated models.",
      "authors": [
        "Cl\\'ement Dumas",
        "Chris Wendler",
        "Veniamin Veselovsky",
        "Giovanni Monea and Robert West"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08745",
        "HTML": "https://arxiv.org/html/2411.08745",
        "PDF": "https://arxiv.org/pdf/2411.08745"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 13 Nov 2024 16:26:19 GMT",
          "size": "2414kb",
          "version": "v1"
        },
        {
          "date": "Mon, 18 Nov 2024 14:41:38 GMT",
          "size": "2414kb",
          "version": "v2"
        },
        {
          "date": "Thu, 09 Jan 2025 21:53:56 GMT",
          "size": "4806kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 15:16:54 GMT",
          "size": "2350kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper examines language-agnostic concept representations in LLMs through activation patching but does not focus on data engineering or processing methods related to LLM training data."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Translation",
        "Word Translation"
      ],
      "repo_urls": [
        "https://github.com/butanium/llm-lang-agnostic"
      ]
    },
    {
      "id": "2412.16545",
      "abstract": "Large language models have shown remarkable performance across a wide range of language tasks, owing to their exceptional capabilities in context modeling. The most commonly used method of context modeling is full self-attention, as seen in standard decoder-only Transformers. Although powerful, this method can be inefficient for long sequences and may overlook inherent input structures. To address these problems, an alternative approach is parallel context encoding, which splits the context into sub-pieces and encodes them parallelly. Because parallel patterns are not encountered during training, naively applying parallel encoding leads to performance degradation. However, the underlying reasons and potential mitigations are unclear. In this work, we provide a detailed analysis of this issue and identify that unusually high attention entropy can be a key factor. Furthermore, we adopt two straightforward methods to reduce attention entropy by incorporating attention sinks and selective mechanisms. Experiments on various tasks reveal that these methods effectively lower irregular attention entropy and narrow performance gaps. We hope this study can illuminate ways to enhance context modeling mechanisms.",
      "authors": [
        "Zhisong Zhang",
        "Yan Wang",
        "Xinting Huang",
        "Tianqing Fang",
        "Hongming Zhang",
        "Chenlong Deng",
        "Shuaiyi Li",
        "Dong Yu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16545",
        "HTML": "https://arxiv.org/html/2412.16545",
        "PDF": "https://arxiv.org/pdf/2412.16545"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Dec 2024 09:04:51 GMT",
          "size": "951kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:28:36 GMT",
          "size": "791kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper analyzes parallel context encoding in large language models and touches upon the concept of attention entropy but does not focus on new methods for LLM training data processing."
      },
      "tasks": [
        "Decoder"
      ]
    },
    {
      "id": "2501.06256",
      "abstract": "Large Language Models (LLMs) exhibit In-Context Learning (ICL), which enables the model to perform new tasks conditioning only on the examples provided in the context without updating the model's weights. While ICL offers fast adaptation across natural language tasks and domains, its emergence is less straightforward for modalities beyond text. In this work, we systematically uncover properties present in LLMs that support the emergence of ICL for autoregressive models and various modalities by promoting the learning of the needed mechanisms for ICL. We identify exact token repetitions in the training data sequences as an important factor for ICL. Such repetitions further improve stability and reduce transiency in ICL performance. Moreover, we emphasise the significance of training task difficulty for the emergence of ICL. Finally, by applying our novel insights on ICL emergence, we unlock ICL capabilities for various visual datasets and a more challenging EEG classification task in a few-shot learning regime.",
      "authors": [
        "Jelena Bratuli\\'c",
        "Sudhanshu Mittal",
        "David T. Hoffmann",
        "Samuel B\\\"ohm",
        "Robin Tibor Schirrmeister",
        "Tonio Ball",
        "Christian Rupprecht",
        "Thomas Brox"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06256",
        "HTML": "https://arxiv.org/html/2501.06256",
        "PDF": "https://arxiv.org/pdf/2501.06256"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 09 Jan 2025 09:45:05 GMT",
          "size": "1553kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:21:31 GMT",
          "size": "6440kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Unlocking In-Context Learning for Natural Datasets Beyond Language Modelling",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper identifies token repetitions in training data as important for in-context learning in LLMs, but it primarily focuses on task difficulty and model properties rather than data processing methods."
      },
      "tasks": [
        "In-Context Learning"
      ]
    },
    {
      "id": "2501.09552",
      "abstract": "De-identification of medical images is a critical step to ensure privacy during data sharing in research and clinical settings. The initial step in this process involves detecting Protected Health Information (PHI), which can be found in image metadata or imprinted within image pixels. Despite the importance of such systems, there has been limited evaluation of existing AI-based solutions, creating barriers to the development of reliable and robust tools. In this study, we present an AI-based pipeline for PHI detection, comprising three key modules: text detection, text extraction, and text analysis. We benchmark three models - YOLOv11, EasyOCR, and GPT-4o - across different setups corresponding to these modules, evaluating their performance on two different datasets encompassing multiple imaging modalities and PHI categories. Our findings indicate that the optimal setup involves utilizing dedicated vision and language models for each module, which achieves a commendable balance in performance, latency, and cost associated with the usage of Large Language Models (LLMs). Additionally, we show that the application of LLMs not only involves identifying PHI content but also enhances OCR tasks and facilitates an end-to-end PHI detection pipeline, showcasing promising outcomes through our analysis.",
      "authors": [
        "Tuan Truong",
        "Ivo M. Baltruschat",
        "Mark Klemens",
        "Grit Werner",
        "and Matthias Lenga"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09552",
        "HTML": "https://arxiv.org/html/2501.09552",
        "PDF": "https://arxiv.org/pdf/2501.09552"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 16 Jan 2025 14:12:33 GMT",
          "size": "1491kb",
          "version": "v1"
        },
        {
          "date": "Thu, 30 Jan 2025 09:31:49 GMT",
          "size": "2092kb",
          "version": "v2"
        },
        {
          "date": "Tue, 29 Apr 2025 12:35:25 GMT",
          "size": "3426kb",
          "version": "v3"
        },
        {
          "date": "Tue, 24 Jun 2025 19:25:40 GMT",
          "size": "2293kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Exploring AI-based System Design for Pixel-level Protected Health Information Detection in Medical Images",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses a pipeline involving LLMs for PHI detection, it does not focus on the data processing for LLM training but rather on model performance and the implementation of existing models."
      },
      "tasks": [
        "De-identification",
        "Optical Character Recognition",
        "Optical Character Recognition (OCR)",
        "Text Detection"
      ]
    },
    {
      "id": "2502.07784",
      "abstract": "We present MatSwap, a method to transfer materials to designated surfaces in an image photorealistically. Such a task is non-trivial due to the large entanglement of material appearance, geometry, and lighting in a photograph. In the literature, material editing methods typically rely on either cumbersome text engineering or extensive manual annotations requiring artist knowledge and 3D scene properties that are impractical to obtain. In contrast, we propose to directly learn the relationship between the input material -- as observed on a flat surface -- and its appearance within the scene, without the need for explicit UV mapping. To achieve this, we rely on a custom light- and geometry-aware diffusion model. We fine-tune a large-scale pre-trained text-to-image model for material transfer using our synthetic dataset, preserving its strong priors to ensure effective generalization to real images. As a result, our method seamlessly integrates a desired material into the target location in the photograph while retaining the identity of the scene. We evaluate our method on synthetic and real images and show that it compares favorably to recent work both qualitatively and quantitatively. We release our code and data on https://github.com/astra-vision/MatSwap",
      "authors": [
        "Ivan Lopes and Valentin Deschaintre and Yannick Hold-Geoffroy and Raoul de Charette"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07784",
        "HTML": "https://arxiv.org/html/2502.07784",
        "PDF": "https://arxiv.org/pdf/2502.07784"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 11 Feb 2025 18:59:59 GMT",
          "size": "48794kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:52:25 GMT",
          "size": "49282kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MatSwap: Light-aware material transfers in images",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper involves fine-tuning a pre-trained model for material transfer, but does not propose novel methods or contributions to training data processing for LLMs beyond this application."
      },
      "tasks": []
    },
    {
      "id": "2503.13819",
      "abstract": "The Internet of Things (IoT) in the sixth generation (6G) era is envisioned to evolve towards intelligence, ubiquity, and self-optimization. Large language models (LLMs) have demonstrated remarkable generalization capabilities across diverse domains, including natural language processing (NLP), computer vision (CV), and beyond. In this article, we propose an LLM-empowered IoT architecture for 6G networks to achieve intelligent autonomy while supporting advanced IoT applications. LLMs are pushed to the edge of the 6G network to support the synergy of LLMs and IoT. LLM solutions are tailored to both IoT application requirements and IoT management needs, i.e., LLM for IoT. On the other hand, edge inference and edge fine-tuning are discussed to support the deployment of LLMs, i.e., LLM on IoT. Furthermore, we propose a memory-efficient split federated learning (SFL) framework for LLM fine-tuning on heterogeneous IoT devices that alleviates memory pressures on both IoT devices and the edge server while achieving comparable performance and convergence time. Finally, a case study is presented, followed by a discussion about open issues of LLM-empowered IoT for 6G networks.",
      "authors": [
        "Xiaopei Chen",
        "Wen Wu",
        "Liang Li",
        "Fei Ji"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13819",
        "HTML": "https://arxiv.org/html/2503.13819",
        "PDF": "https://arxiv.org/pdf/2503.13819"
      },
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 18 Mar 2025 01:53:42 GMT",
          "size": "2890kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:43:29 GMT",
          "size": "2641kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LLM-Empowered IoT for 6G Networks: Architecture, Challenges, and Solutions",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses LLM deployment and edge fine-tuning, it primarily focuses on IoT applications and architectures rather than novel methods or processes for LLM training data."
      }
    },
    {
      "id": "2503.16789",
      "abstract": "Human-LLM conversations are increasingly becoming more pervasive in peoples' professional and personal lives, yet many users still struggle to elicit helpful responses from LLM Chatbots. One of the reasons for this issue is users' lack of understanding in crafting effective prompts that accurately convey their information needs. Meanwhile, the existence of real-world conversational datasets on the one hand, and the text understanding faculties of LLMs on the other, present a unique opportunity to study this problem, and its potential solutions at scale. Thus, in this paper we present the first LLM-centric study of real human-AI chatbot conversations, focused on investigating aspects in which user queries fall short of expressing information needs, and the potential of using LLMs to rewrite suboptimal user prompts. Our findings demonstrate that rephrasing ineffective prompts can elicit better responses from a conversational system, while preserving the user's original intent. Notably, the performance of rewrites improves in longer conversations, where contextual inferences about user needs can be made more accurately. Additionally, we observe that LLMs often need to -- and inherently do -- make \\emph{plausible} assumptions about a user's intentions and goals when interpreting prompts. Our findings largely hold true across conversational domains, user intents, and LLMs of varying sizes and families, indicating the promise of using prompt rewriting as a solution for better human-AI interactions.",
      "authors": [
        "Rupak Sarkar",
        "Bahareh Sarrafzadeh",
        "Nirupama Chandrasekaran",
        "Nagu Rangan",
        "Philip Resnik",
        "Longqi Yang",
        "Sujay Kumar Jauhar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16789",
        "HTML": "https://arxiv.org/html/2503.16789",
        "PDF": "https://arxiv.org/pdf/2503.16789"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 21 Mar 2025 02:01:02 GMT",
          "size": "9434kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:44:58 GMT",
          "size": "9678kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Conversational User-AI Intervention: A Study on Prompt Rewriting for Improved LLM Response Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper explores the potential for LLMs to rewrite user prompts for better conversational outcomes, which is related to refining input data for LLM interactions. However, it does not propose new methods for LLM training data processing."
      },
      "tasks": [
        "Chatbot",
        "Response Generation"
      ]
    },
    {
      "id": "2504.17224",
      "abstract": "Vision Large Language Models (VLLMs) exhibit promising potential for multi-modal understanding, yet their application to video-based emotion recognition remains limited by insufficient spatial and contextual awareness. Traditional approaches, which prioritize isolated facial features, often neglect critical non-verbal cues such as body language, environmental context, and social interactions, leading to reduced robustness in real-world scenarios. To address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel framework that enhances zero-shot emotion recognition by integrating spatial annotations (e.g., bounding boxes, facial landmarks), physiological signals (facial action units), and contextual cues (body posture, scene dynamics, others' emotions) into a unified prompting strategy. SoVTP preserves holistic scene information while enabling fine-grained analysis of facial muscle movements and interpersonal dynamics. Extensive experiments show that SoVTP achieves substantial improvements over existing visual prompting methods, demonstrating its effectiveness in enhancing VLLMs' video emotion recognition capabilities.",
      "authors": [
        "Zhifeng Wang and Qixuan Zhang and Peter Zhang and Wenjia Niu and Kaihao Zhang and Ramesh Sankaranarayana and Sabrina Caldwell and Tom Gedeon"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17224",
        "HTML": "https://arxiv.org/html/2504.17224",
        "PDF": "https://arxiv.org/pdf/2504.17224"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 24 Apr 2025 03:26:30 GMT",
          "size": "7141kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 02:47:07 GMT",
          "size": "6169kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper proposes a framework (SoVTP) for enhancing emotion recognition using VLLMs, which involves integrating spatial annotations and contextual cues, but it primarily focuses on model application rather than LLM data processing innovations."
      },
      "tasks": [
        "Emotion Recognition",
        "Video Emotion Recognition",
        "Visual Prompting"
      ]
    },
    {
      "id": "2504.21662",
      "abstract": "The Forward-Forward algorithm has evolved in machine learning research, tackling more complex tasks that mimic real-life applications. In the last years, it has been improved by several techniques to perform better than its original version, handling a challenging dataset like CIFAR10 without losing its flexibility and low memory usage. We have shown in our results that improvements are achieved through a combination of convolutional channel grouping, learning rate schedules, and independent block structures during training that lead to a 20\\% decrease in test error percentage. Additionally, to approach further implementations on low-capacity hardware projects, we have presented a series of lighter models that achieve low test error percentages within (21$\\pm$3)\\% and number of trainable parameters between 164,706 and 754,386. This serves as a basis for our future study on complete verification and validation of these kinds of neural networks.",
      "authors": [
        "Mauricio Ortiz Torres",
        "Markus Lange",
        "Arne P. Raulf"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21662",
        "HTML": "https://arxiv.org/html/2504.21662",
        "PDF": "https://arxiv.org/pdf/2504.21662"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 30 Apr 2025 14:03:52 GMT",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:08:49 GMT",
          "size": "405kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On Advancements of the Forward-Forward Algorithm",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The abstract mentions enhancements to the Forward-Forward algorithm to handle machine learning tasks but does not contribute novel methods for processing LLM training data."
      }
    },
    {
      "id": "2505.18213",
      "abstract": "AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve data preparedness for AI applications. It addresses critical data readiness dimensions such as data quality, bias, fairness, and privacy. This paper details enhancements to AIDRIN by focusing on user interface improvements and integration with a privacy-preserving federated learning (PPFL) framework. By refining the UI and enabling smooth integration with decentralized AI pipelines, AIDRIN becomes more accessible and practical for users with varying technical expertise. Integrating with an existing PPFL framework ensures that data readiness and privacy are prioritized in federated learning environments. A case study involving a real-world dataset demonstrates AIDRIN's practical value in identifying data readiness issues that impact AI model performance.",
      "authors": [
        "Kaveen Hiniduma",
        "Dylan Ryan",
        "Suren Byna",
        "Jean Luca Bez",
        "Ravi Madduri"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18213",
        "HTML": "https://arxiv.org/html/2505.18213",
        "PDF": "https://arxiv.org/pdf/2505.18213"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 22 May 2025 22:24:31 GMT",
          "size": "6811kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 01:49:52 GMT",
          "size": "4443kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AIDRIN 2.0: A Framework to Assess Data Readiness for AI",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses data readiness evaluation in AI, touching on data quality dimensions but not directly focusing on LLM-specific data processing or engineering."
      },
      "tasks": [
        "Fairness",
        "Federated Learning",
        "Privacy Preserving"
      ]
    },
    {
      "id": "2505.20767",
      "abstract": "Faithfulness hallucinations are claims generated by a Large Language Model (LLM) not supported by contexts provided to the LLM. Lacking assessment standards, existing benchmarks focus on \"factual statements\" that rephrase source materials while overlooking \"cognitive statements\" that involve making inferences from the given context. Consequently, evaluating and detecting the hallucination of cognitive statements remains challenging. Inspired by how evidence is assessed in the legal domain, we design a rigorous framework to assess different levels of faithfulness of cognitive statements and introduce the CogniBench dataset where we reveal insightful statistics. To keep pace with rapidly evolving LLMs, we further develop an automatic annotation pipeline that scales easily across different models. This results in a large-scale CogniBench-L dataset, which facilitates training accurate detectors for both factual and cognitive hallucinations. We release our model and datasets at: https://github.com/FUTUREEEEEE/CogniBench",
      "authors": [
        "Xiaqiang Tang",
        "Jian Li",
        "Keyu Hu",
        "Du Nan",
        "Xiaolong Li",
        "Xi Zhang",
        "Weigao Sun",
        "Sihong Xie"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20767",
        "HTML": "https://arxiv.org/html/2505.20767",
        "PDF": "https://arxiv.org/pdf/2505.20767"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 27 May 2025 06:16:27 GMT",
          "size": "8274kb",
          "version": "v1"
        },
        {
          "date": "Wed, 28 May 2025 06:17:19 GMT",
          "size": "8492kb",
          "version": "v2"
        },
        {
          "date": "Fri, 30 May 2025 08:16:51 GMT",
          "size": "3733kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 14:02:19 GMT",
          "size": "3825kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper introduces a dataset (CogniBench) for assessing faithfulness, it primarily focuses on evaluating cognitive statements rather than proposing new methods for LLM training data processing."
      },
      "models": [
        {
          "model_path": "future7/CogniDet",
          "downloads": "95",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/future7/CogniDet"
        }
      ],
      "tasks": [
        "Hallucination",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/futureeeeee/cognibench"
      ]
    },
    {
      "id": "2505.22016",
      "abstract": "Panoramic video generation enables immersive 360{\\deg} content creation, valuable in applications that demand scene-consistent world exploration. However, existing panoramic video generation models struggle to leverage pre-trained generative priors from conventional text-to-video models for high-quality and diverse panoramic videos generation, due to limited dataset scale and the gap in spatial feature representations. In this paper, we introduce PanoWan to effectively lift pre-trained text-to-video models to the panoramic domain, equipped with minimal modules. PanoWan employs latitude-aware sampling to avoid latitudinal distortion, while its rotated semantic denoising and padded pixel-wise decoding ensure seamless transitions at longitude boundaries. To provide sufficient panoramic videos for learning these lifted representations, we contribute PanoVid, a high-quality panoramic video dataset with captions and diverse scenarios. Consequently, PanoWan achieves state-of-the-art performance in panoramic video generation and demonstrates robustness for zero-shot downstream tasks. Our project page is available at https://panowan.variantconst.com.",
      "authors": [
        "Yifei Xia",
        "Shuchen Weng",
        "Siqi Yang",
        "Jingqi Liu",
        "Chengxuan Zhu",
        "Minggui Teng",
        "Zijian Jia",
        "Han Jiang",
        "Boxin Shi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22016",
        "HTML": "https://arxiv.org/html/2505.22016",
        "PDF": "https://arxiv.org/pdf/2505.22016"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 28 May 2025 06:24:21 GMT",
          "size": "9158kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 15:10:35 GMT",
          "size": "9158kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PanoWan: Lifting Diffusion Video Generation Models to 360{\\deg} with Latitude/Longitude-aware Mechanisms",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper contributes PanoVid, a high-quality panoramic video dataset, which is related to training LLMs, but primarily focuses on the video generation model, not data processing."
      }
    },
    {
      "id": "2505.24190",
      "abstract": "Few-shot image classification remains challenging due to the scarcity of labeled training examples. Augmenting them with synthetic data has emerged as a promising way to alleviate this issue, but models trained on synthetic samples often face performance degradation due to the inherent gap between real and synthetic distributions. To address this limitation, we develop a theoretical framework that quantifies the impact of such distribution discrepancies on supervised learning, specifically in the context of image classification. More importantly, our framework suggests practical ways to generate good synthetic samples and to train a predictor with high generalization ability. Building upon this framework, we propose a novel theoretical-based algorithm that integrates prototype learning to optimize both data partitioning and model training, effectively bridging the gap between real few-shot data and synthetic data. Extensive experiments results show that our approach demonstrates superior performance compared to state-of-the-art methods, outperforming them across multiple datasets.",
      "authors": [
        "Lan-Cuong Nguyen",
        "Quan Nguyen-Tri",
        "Bang Tran Khanh",
        "Dung D. Le",
        "Long Tran-Thanh",
        "Khoat Than"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24190",
        "HTML": "https://arxiv.org/html/2505.24190",
        "PDF": "https://arxiv.org/pdf/2505.24190"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 30 May 2025 03:59:45 GMT",
          "size": "178kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:02:36 GMT",
          "size": "178kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Provably Improving Generalization of Few-Shot Models with Synthetic Data",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper develops a theoretical framework and algorithm for improving few-shot learning with synthetic data, it is primarily focused on image classification rather than LLM data processing."
      },
      "tasks": [
        "Few-Shot Image Classification",
        "image-classification",
        "Image Classification"
      ]
    },
    {
      "id": "2505.24862",
      "abstract": "Story visualization, which aims to generate a sequence of visually coherent images aligning with a given narrative and reference images, has seen significant progress with recent advancements in generative models. To further enhance the performance of story visualization frameworks in real-world scenarios, we introduce a comprehensive evaluation benchmark, ViStoryBench. We collect a diverse dataset encompassing various story types and artistic styles, ensuring models are evaluated across multiple dimensions such as different plots (e.g., comedy, horror) and visual aesthetics (e.g., anime, 3D renderings). ViStoryBench is carefully curated to balance narrative structures and visual elements, featuring stories with single and multiple protagonists to test models' ability to maintain character consistency. Additionally, it includes complex plots and intricate world-building to challenge models in generating accurate visuals. To ensure comprehensive comparisons, our benchmark incorporates a wide range of evaluation metrics assessing critical aspects. This structured and multifaceted framework enables researchers to thoroughly identify both the strengths and weaknesses of different models, fostering targeted improvements.",
      "authors": [
        "Cailin Zhuang",
        "Ailin Huang",
        "Wei Cheng",
        "Jingwei Wu",
        "Yaoqi Hu",
        "Jiaqi Liao",
        "Zhewei Huang",
        "Hongyuan Wang",
        "Xinyao Liao",
        "Weiwei Cai",
        "Hengyuan Xu",
        "Xuanyang Zhang",
        "Xianfang Zeng",
        "Gang Yu",
        "Chi Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24862",
        "HTML": "https://arxiv.org/html/2505.24862",
        "PDF": "https://arxiv.org/pdf/2505.24862"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 30 May 2025 17:58:21 GMT",
          "size": "28284kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:57:33 GMT",
          "size": "28378kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ViStoryBench: Comprehensive Benchmark Suite for Story Visualization",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces ViStoryBench, a benchmark for story visualization, which involves some level of data curation and collection, but it seems more focused on evaluation rather than proposing new methods for LLM data processing."
      },
      "tasks": [
        "Story Visualization"
      ],
      "repo_urls": [
        "https://github.com/vistorybench/vistorybench"
      ]
    },
    {
      "id": "2506.06406",
      "abstract": "Mixture of Experts (MoE) architectures have become a key approach for scaling large language models, with growing interest in extending them to multimodal tasks. Existing methods to build multimodal MoE models either incur high training costs or suffer from degraded language capabilities when adapting pretrained models. To address this, we propose Soft ModalityAware Routing (SMAR), a novel regularization technique that uses Kullback Leibler divergence to control routing probability distributions across modalities, encouraging expert specialization without modifying model architecture or heavily relying on textual data. Experiments on visual instruction tuning show that SMAR preserves language ability at 86.6% retention with only 2.5% pure text, outperforming baselines while maintaining strong multimodal performance. Our approach offers a practical and efficient solution to balance modality differentiation and language capabilities in multimodal MoE models.",
      "authors": [
        "Guoyang Xia",
        "Yifeng Ding",
        "Fengfa Li",
        "Lei Ren",
        "Wei Chen",
        "Fangxiang Feng",
        "Xiaojie Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06406",
        "HTML": "https://arxiv.org/html/2506.06406",
        "PDF": "https://arxiv.org/pdf/2506.06406"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 06 Jun 2025 12:47:29 GMT",
          "size": "2173kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 12:36:55 GMT",
          "size": "12914kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a novel regularization technique for multimodal MoE models which is indirectly related to data processing for LLMs, particularly mentioning language capabilities and modality specialization, but not focusing primarily on LLM data processing methods."
      }
    },
    {
      "id": "2506.08400",
      "abstract": "Large Language models (LLMs) have demonstrated impressive performance on a wide range of tasks, including in multimodal settings such as speech. However, their evaluation is often limited to English and a few high-resource languages. For low-resource languages, there is no standardized evaluation benchmark. In this paper, we address this gap by introducing mSTEB, a new benchmark to evaluate the performance of LLMs on a wide range of tasks covering language identification, text classification, question answering, and translation tasks on both speech and text modalities. We evaluated the performance of leading LLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open models such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in performance between high-resource and low-resource languages, especially for languages spoken in Africa and Americas/Oceania. Our findings show that more investment is needed to address their under-representation in LLMs coverage.",
      "authors": [
        "Luel Hagos Beyene",
        "Vivek Verma",
        "Min Ma",
        "Jesujoba O. Alabi",
        "Fabian David Schmidt",
        "Joyce Nakatumba-Nabende",
        "David Ifeoluwa Adelani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08400",
        "HTML": "https://arxiv.org/html/2506.08400",
        "PDF": "https://arxiv.org/pdf/2506.08400"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Jun 2025 03:15:08 GMT",
          "size": "347kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 00:58:19 GMT",
          "size": "347kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper introduces a benchmark for evaluating LLMs on multilingual tasks, it briefly mentions evaluation and does not propose new data processing methods for LLM training."
      },
      "tasks": [
        "Language Identification",
        "Question Answering",
        "text-classification",
        "Text Classification"
      ]
    },
    {
      "id": "2506.11484",
      "abstract": "Although modern vulnerability detection tools enable developers to efficiently identify numerous security flaws, indiscriminate remediation efforts often lead to superfluous development expenses. This is particularly true given that a substantial portion of detected vulnerabilities either possess low exploitability or would incur negligible impact in practical operational environments. Consequently, vulnerability severity assessment has emerged as a critical component in optimizing software development efficiency. Existing vulnerability assessment methods typically rely on manually crafted descriptions associated with source code artifacts. However, due to variability in description quality and subjectivity in intention interpretation, the performance of these methods is seriously limited. To address this issue, this paper introduces VulStamp, a novel intention-guided framework, to facilitate description-free vulnerability assessment. Specifically, VulStamp adopts static analysis together with Large Language Model (LLM) to extract the intention information of vulnerable code. Based on the intention information, VulStamp uses a prompt-tuned model for vulnerability assessment. Furthermore, to mitigate the problem of imbalanced data associated with vulnerability types, VulStamp integrates a Reinforcement Learning (RL)-based prompt-tuning method to train the assessment model.",
      "authors": [
        "Hao Shen",
        "Ming Hu",
        "Xiaofei Xie",
        "Jiaye Li",
        "Mingsong Chen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11484",
        "HTML": "https://arxiv.org/html/2506.11484",
        "PDF": "https://arxiv.org/pdf/2506.11484"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Jun 2025 06:14:56 GMT",
          "size": "720kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 11:05:49 GMT",
          "size": "720kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "VulStamp: Vulnerability Assessment using Large Language Model",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses using LLMs for vulnerability assessment, it briefly mentions static analysis and prompt-tuning, which could involve some data preparation but doesn't introduce new methods for LLM training data."
      }
    },
    {
      "id": "2506.13205",
      "abstract": "With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
      "authors": [
        "Xuan Wang",
        "Siyuan Liang",
        "Zhe Liu",
        "Yi Yu",
        "Yuliang Lu",
        "Xiaochun Cao",
        "Ee-Chien Chang and Xitong Gao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13205",
        "HTML": "https://arxiv.org/html/2506.13205",
        "PDF": "https://arxiv.org/pdf/2506.13205"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 08:09:32 GMT",
          "size": "639kb",
          "version": "v1"
        },
        {
          "date": "Thu, 19 Jun 2025 05:46:05 GMT",
          "size": "639kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 05:05:18 GMT",
          "size": "639kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses vulnerabilities in training visual-language models with a specific focus on clean-label backdoor attacks. It mentions fine-tuning and the introduction of poisoned data but does not propose novel data processing methods for LLMs."
      },
      "tasks": [
        "Backdoor Attack"
      ]
    },
    {
      "id": "2506.17219",
      "abstract": "Reinforcement learning has emerged as a powerful paradigm for post-training large language models (LLMs) to improve reasoning. Approaches like Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) have shown strong results, but they require extensive external supervision. We investigate an alternative class of methods, Reinforcement Learning from Internal Feedback (RLIF), which relies solely on intrinsic model-derived signals instead of external rewards. In particular, we leverage unsupervised reward proxies such as token-level entropy, trajectory-level entropy, and self-certainty. Our theoretical analysis shows these internal objectives are partially equivalent, and we empirically evaluate various RLIF strategies on challenging math reasoning benchmarks. Experimental results demonstrate that RLIF can boost the reasoning performance of base LLMs at the beginning phase of the training, matching or surpassing RLVR techniques on these tasks. However, when training progresses, performance degrades even below the model before training. Moreover, we find that RLIF yields little improvement for instruction-tuned models, indicating diminishing returns of intrinsic feedback once an LLM is already instruction-tuned. We further analyze this limitation by mixing model weights and explain the reason of RLIF's training behaviors, providing practical guidelines for integrating internal feedback signals into LLM training. We hope our analysis of internal feedback will inform more principled and effective strategies for LLM post-training.",
      "authors": [
        "Yanzhi Zhang",
        "Zhaoxi Zhang",
        "Haoxiang Guan",
        "Yilin Cheng",
        "Yitong Duan",
        "Chen Wang",
        "Yue Wang",
        "Shuxin Zheng",
        "Jiyan He"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17219",
        "HTML": "https://arxiv.org/html/2506.17219",
        "PDF": "https://arxiv.org/pdf/2506.17219"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 17:59:52 GMT",
          "size": "158kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 13:27:49 GMT",
          "size": "159kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses reinforcement learning strategies for LLM post-training without introducing new methods for data collection or processing in the training pipeline."
      },
      "tasks": [
        "Math",
        "reinforcement-learning",
        "Reinforcement Learning"
      ]
    },
    {
      "id": "2506.17221",
      "abstract": "Vision-Language Navigation (VLN) is a core challenge in embodied AI, requiring agents to navigate real-world environments using natural language instructions. Current language model-based navigation systems operate on discrete topological graphs, limiting path planning to predefined node connections. We propose VLN-R1, an end-to-end framework that leverages Large Vision-Language Models (LVLM) to directly translate egocentric video streams into continuous navigation actions, adopting GRPO-based training inspired by DeepSeek-R1. To enable effective training, we first construct the VLN-Ego dataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling to balance historical and current observations. While large language models can supervise complete textual instructions, they lack fine-grained action-level control. Our framework employs a two-stage training approach: a) Supervised fine-tuning (SFT) to align the model's action sequence text predictions with expert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced with a Time-Decayed Reward (TDR) mechanism that strategically weights multi-step future actions. Experimental results show VLN-R1 achieves strong performance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied navigation and enhance task-specific reasoning through data-efficient, reward-driven post-training.",
      "authors": [
        "Zhangyang Qi",
        "Zhixiong Zhang",
        "Yizhou Yu",
        "Jiaqi Wang",
        "Hengshuang Zhao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17221",
        "HTML": "https://arxiv.org/html/2506.17221",
        "PDF": "https://arxiv.org/pdf/2506.17221"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 17:59:59 GMT",
          "size": "2058kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:03:22 GMT",
          "size": "2058kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper involves supervised fine-tuning and reinforcement fine-tuning for vision-language navigation tasks, but it does not provide significant new methods or insights into LLM training data processing."
      },
      "tasks": [
        "Navigate",
        "Vision-Language Navigation"
      ]
    },
    {
      "id": "2506.17289",
      "abstract": "We investigate the generalization capabilities of small language models under two popular adaptation paradigms: few-shot prompting and supervised fine-tuning. While prompting is often favored for its parameter efficiency and flexibility, it remains unclear how robust this approach is in low-resource settings and under distributional shifts. This paper presents a comparative study of prompting and fine-tuning across task formats, prompt styles, and model scales, with a focus on their behavior in both in-distribution and out-of-distribution (OOD) settings. Beyond accuracy, we analyze the internal representations learned by each approach to assess the stability and abstraction of task-specific features. Our findings highlight critical differences in how small models internalize and generalize knowledge under different adaptation strategies. This work offers practical guidance for model selection in low-data regimes and contributes empirical insight into the ongoing debate over prompting versus fine-tuning. Code for the experiments is available at the following",
      "authors": [
        "Rahul Raja",
        "Arpita Vats"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17289",
        "HTML": "https://arxiv.org/html/2506.17289",
        "PDF": "https://arxiv.org/pdf/2506.17289"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 01:44:26 GMT",
          "size": "1123kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 04:27:25 GMT",
          "size": "1202kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Evaluating Generalization and Representation Stability in Small LMs via Prompting, Fine-Tuning and Out-of-Distribution Prompts",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the generalization capabilities of small language models using prompting and fine-tuning, but only mentions data as public datasets and does not propose new methods for LLM training data processing."
      }
    },
    {
      "id": "2506.17667",
      "abstract": "Physics problem-solving is a challenging domain for large AI models, requiring integration of conceptual understanding, mathematical reasoning, and interpretation of physical diagrams. Current evaluation methodologies show notable limitations in capturing the breadth and complexity of undergraduate-level physics, underscoring the need for more rigorous assessments. To this end, we present PhysUniBench, a large-scale multimodal benchmark designed to evaluate and improve the reasoning capabilities of multimodal large language models (MLLMs) specifically on undergraduate-level physics problems. PhysUniBench consists of 3,304 physics questions spanning 8 major sub-disciplines of physics, each accompanied by one visual diagrams. The benchmark includes both open-ended and multiple-choice questions, systematically curated and difficulty-rated through an iterative model-in-the-loop process. The benchmark's construction involved a rigorous multi-stage process, including multiple roll-outs, expert-level evaluation, automated filtering of easily solved problems, and a nuanced difficulty grading system with five levels. Through extensive experiments, we observe that current state-of-the-art models encounter substantial challenges in physics reasoning. For example, GPT-4o mini achieves only about 34.2% accuracy in the proposed PhysUniBench. These results highlight that current MLLMs struggle with advanced physics reasoning, especially on multi-step problems and those requiring precise diagram interpretation. By providing a broad and rigorous assessment tool, PhysUniBench aims to drive progress in AI for Science, encouraging the development of models with stronger physical reasoning, problem-solving skills, and multimodal understanding. The benchmark and evaluation scripts are available at https://prismax-team.github.io/PhysUniBenchmark/.",
      "authors": [
        "Lintao Wang",
        "Encheng Su",
        "Jiaqi Liu",
        "Pengze Li",
        "Peng Xia",
        "Jiabei Xiao",
        "Wenlong Zhang",
        "Xinnan Dai",
        "Xi Chen",
        "Yuan Meng",
        "Mingyu Ding",
        "Lei Bai",
        "Wanli Ouyang",
        "Shixiang Tang",
        "Aoran Wang",
        "Xinzhu Ma"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17667",
        "HTML": "https://arxiv.org/html/2506.17667",
        "PDF": "https://arxiv.org/pdf/2506.17667"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 09:55:42 GMT",
          "size": "5433kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 06:09:22 GMT",
          "size": "5433kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces PhysUniBench, a benchmark for evaluating multimodal models on physics problems, briefly involving data selection and filtering but not focusing on LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "PrismaX/PhysUniBench",
          "downloads": "180",
          "likes": "5",
          "link": "https://huggingface.co/datasets/PrismaX/PhysUniBench"
        }
      ],
      "tasks": [
        "Mathematical Reasoning",
        "Multiple-choice"
      ]
    },
    {
      "id": "2506.18330",
      "abstract": "We introduce Confucius3-Math, an open-source large language model with 14B parameters that (1) runs efficiently on a single consumer-grade GPU; (2) achieves SOTA performances on a range of mathematical reasoning tasks, outperforming many models with significantly larger sizes. In particular, as part of our mission to enhancing education and knowledge dissemination with AI, Confucius3-Math is specifically committed to mathematics learning for Chinese K-12 students and educators. Built via post-training with large-scale reinforcement learning (RL), Confucius3-Math aligns with national curriculum and excels at solving main-stream Chinese K-12 mathematical problems with low cost. In this report we share our development recipe, the challenges we encounter and the techniques we develop to overcome them. In particular, we introduce three technical innovations: Targeted Entropy Regularization, Recent Sample Recovery and Policy-Specific Hardness Weighting. These innovations encompass a new entropy regularization, a novel data scheduling policy, and an improved group-relative advantage estimator. Collectively, they significantly stabilize the RL training, improve data efficiency, and boost performance. Our work demonstrates the feasibility of building strong reasoning models in a particular domain at low cost. We open-source our model and code at https://github.com/netease-youdao/Confucius3-Math.",
      "authors": [
        "Lixin Wu",
        "Na Cai",
        "Qiao Cheng",
        "Jiachen Wang",
        "Yitao Duan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18330",
        "HTML": "https://arxiv.org/html/2506.18330",
        "PDF": "https://arxiv.org/pdf/2506.18330"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 06:23:53 GMT",
          "size": "108kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 10:49:23 GMT",
          "size": "108kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Confucius3-Math: A Lightweight High-Performance Reasoning LLM for Chinese K-12 Mathematics Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper describes a model built via post-training with reinforcement learning for math tasks, but it focuses on model training techniques rather than the training data collection, processing, or engineering specifically for LLMs."
      },
      "models": [
        {
          "model_path": "netease-youdao/Confucius3-Math",
          "downloads": "5",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/netease-youdao/Confucius3-Math"
        },
        {
          "model_path": "netease-youdao/Confucius3-Math-GGUF",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/netease-youdao/Confucius3-Math-GGUF"
        }
      ],
      "tasks": [
        "Large Language Model",
        "Math",
        "Mathematical Reasoning",
        "Reinforcement Learning (RL)",
        "Scheduling"
      ]
    },
    {
      "id": "2405.09493",
      "abstract": "Popular debiased estimation methods for causal inference -- such as augmented inverse propensity weighting and targeted maximum likelihood estimation -- enjoy desirable asymptotic properties like statistical efficiency and double robustness but they can produce unstable estimates when there is limited overlap between treatment and control, requiring additional assumptions or ad hoc adjustments in practice (e.g., truncating propensity scores). In contrast, simple plug-in estimators are stable but lack desirable asymptotic properties. We propose a novel debiasing approach that achieves the best of both worlds, producing stable plug-in estimates with desirable asymptotic properties. Our constrained learning framework solves for the best plug-in estimator under the constraint that the first-order error with respect to the plugged-in quantity is zero, and can leverage flexible model classes including neural networks and tree ensembles. In several experimental settings, including ones in which we handle text-based covariates by fine-tuning language models, our constrained learning-based estimator outperforms basic versions of one-step estimation and targeting in challenging settings with limited overlap between treatment and control, and performs similarly otherwise. Finally, to understand why our method exhibits superior performance in settings with low overlap, we present a theoretical example with heavy-tailed inverse propensity scores in which other debiased estimators converge more slowly compared to ours.",
      "authors": [
        "Tiffany Tianhui Cai",
        "Yuri Fonseca",
        "Kaiwen Hou",
        "Hongseok Namkoong"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.09493",
        "HTML": "https://arxiv.org/html/2405.09493",
        "PDF": "https://arxiv.org/pdf/2405.09493"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 15 May 2024 16:38:28 GMT",
          "size": "50kb",
          "version": "v1"
        },
        {
          "date": "Wed, 22 May 2024 05:45:43 GMT",
          "size": "454kb",
          "version": "v2"
        },
        {
          "date": "Mon, 14 Oct 2024 16:34:30 GMT",
          "size": "489kb",
          "version": "v3"
        },
        {
          "date": "Tue, 24 Jun 2025 18:19:45 GMT",
          "size": "496kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "C-Learner: Constrained Learning for Causal Inference",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions fine-tuning language models to handle text-based covariates in causal inference settings, which indicates some involvement in data processing, but data engineering for LLMs is not the primary contribution."
      },
      "tasks": [
        "Causal Inference"
      ]
    },
    {
      "id": "2503.00131",
      "abstract": "We demonstrate transfer learning capabilities in a machine-learned algorithm trained for particle-flow reconstruction in high energy particle colliders. This paper presents a cross-detector fine-tuning study, where we initially pretrain the model on a large full simulation dataset from one detector design, and subsequently fine-tune the model on a sample with a different collider and detector design. Specifically, we use the Compact Linear Collider detector (CLICdet) model for the initial training set and demonstrate successful knowledge transfer to the CLIC-like detector (CLD) proposed for the Future Circular Collider in electron-positron mode. We show that with an order of magnitude less samples from the second dataset, we can achieve the same performance as a costly training from scratch, across particle-level and event-level performance metrics, including jet and missing transverse momentum resolution. Furthermore, we find that the fine-tuned model achieves comparable performance to the traditional rule-based particle-flow approach on event-level metrics after training on 100,000 CLD events, whereas a model trained from scratch requires at least 1 million CLD events to achieve similar reconstruction performance. To our knowledge, this represents the first full-simulation cross-detector transfer learning study for particle-flow reconstruction. These findings offer valuable insights towards building large foundation models that can be fine-tuned across different detector designs and geometries, helping to accelerate the development cycle for new detectors and opening the door to rapid detector design and optimization using machine learning.",
      "authors": [
        "Farouk Mokhtar",
        "Joosep Pata",
        "Dolores Garcia",
        "Eric Wulff",
        "Mengke Zhang",
        "Michael Kagan",
        "Javier Duarte"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00131",
        "HTML": "https://arxiv.org/html/2503.00131",
        "PDF": "https://arxiv.org/pdf/2503.00131"
      },
      "subjects": [
        "High Energy Physics - Experiment (hep-ex)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Phenomenology (hep-ph)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 28 Feb 2025 19:16:01 GMT",
          "size": "7372kb",
          "version": "v1"
        },
        {
          "date": "Mon, 24 Mar 2025 17:21:04 GMT",
          "size": "7371kb",
          "version": "v2"
        },
        {
          "date": "Thu, 29 May 2025 19:04:51 GMT",
          "size": "2386kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 09:07:47 GMT",
          "size": "3634kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fine-tuning machine-learned particle-flow reconstruction for new detector geometries in future colliders",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses fine-tuning machine-learned algorithms for particle-flow reconstruction, focusing on knowledge transfer between different detector designs. While it involves pre-training and fine-tuning, it is applied to a specific scientific domain and is not focused on new methods for constructing or processing LLM training data broadly."
      },
      "tasks": [
        "Transfer Learning"
      ]
    },
    {
      "id": "2506.17874",
      "abstract": "In many real-world applications, ensuring the robustness and stability of deep neural networks (DNNs) is crucial, particularly for image classification tasks that encounter various input perturbations. While data augmentation techniques have been widely adopted to enhance the resilience of a trained model against such perturbations, there remains significant room for improvement in robustness against corrupted data and adversarial attacks simultaneously. To address this challenge, we introduce DRO-Augment, a novel framework that integrates Wasserstein Distributionally Robust Optimization (W-DRO) with various data augmentation strategies to improve the robustness of the models significantly across a broad spectrum of corruptions. Our method outperforms existing augmentation methods under severe data perturbations and adversarial attack scenarios while maintaining the accuracy on the clean datasets on a range of benchmark datasets, including but not limited to CIFAR-10-C, CIFAR-100-C, MNIST, and Fashion-MNIST. On the theoretical side, we establish novel generalization error bounds for neural networks trained using a computationally efficient, variation-regularized loss function closely related to the W-DRO problem.",
      "authors": [
        "Jiaming Hu",
        "Debarghya Mukherjee",
        "Ioannis Ch. Paschalidis"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17874",
        "HTML": "https://arxiv.org/html/2506.17874",
        "PDF": "https://arxiv.org/pdf/2506.17874"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 02:18:03 GMT",
          "size": "741kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 21:04:53 GMT",
          "size": "734kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "DRO-Augment Framework: Robustness by Synergizing Wasserstein Distributionally Robust Optimization and Data Augmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a framework integrating robust optimization and data augmentation for neural networks but does not focus on LLM training data, offering no substantial contributions to data processing for LLMs."
      }
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Optimization and Control (math.OC)",
    "Quantum Physics (quant-ph)",
    "Multimedia (cs.MM)",
    "Physics and Society (physics.soc-ph)",
    "Computer Science and Game Theory (cs.GT)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Other Quantitative Biology (q-bio.OT)",
    "Sound (cs.SD)",
    "Image and Video Processing (eess.IV)",
    "Performance (cs.PF)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Geometry (cs.CG)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Algebraic Topology (math.AT)",
    "Applications (stat.AP)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Applied Physics (physics.app-ph)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "Analysis of PDEs (math.AP)",
    "Computational Complexity (cs.CC)",
    "Quantitative Methods (q-bio.QM)",
    "Logic (math.LO)",
    "Plasma Physics (physics.plasm-ph)",
    "Statistical Finance (q-fin.ST)",
    "High Energy Physics - Experiment (hep-ex)",
    "History and Overview (math.HO)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Representation Theory (math.RT)",
    "Category Theory (math.CT)",
    "Mathematical Software (cs.MS)",
    "Symbolic Computation (cs.SC)",
    "Biological Physics (physics.bio-ph)",
    "Probability (math.PR)",
    "Discrete Mathematics (cs.DM)",
    "Information Theory (math.IT)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Number Theory (math.NT)",
    "Computation (stat.CO)",
    "Audio and Speech Processing (eess.AS)",
    "Metric Geometry (math.MG)",
    "Social and Information Networks (cs.SI)",
    "Chaotic Dynamics (nlin.CD)",
    "Combinatorics (math.CO)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Biomolecules (q-bio.BM)",
    "Other Statistics (stat.OT)",
    "Functional Analysis (math.FA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "Multiagent Systems (cs.MA)",
    "Hardware Architecture (cs.AR)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Computational Physics (physics.comp-ph)",
    "Geometric Topology (math.GT)",
    "Software Engineering (cs.SE)",
    "High Energy Physics - Lattice (hep-lat)",
    "Nuclear Theory (nucl-th)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Data Structures and Algorithms (cs.DS)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Algebraic Geometry (math.AG)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Rings and Algebras (math.RA)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Dynamical Systems (math.DS)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nYou are a computer science expert specializing in training data processing and data engineering for large language models (LLMs). You are skilled at identifying technical content in research papers that is related to **LLM training data**. I will provide you with a list of research papers from the arXiv (cs.\\*) domain.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it is directly related to the **processing of training data for LLMs**. Focus on identifying contributions in the following two areas:\n\n1. **Data Engineering Stage**:\n\n   * Includes tasks such as data collection, construction, cleaning, noise reduction, deduplication, filtering, format transformation, and data quality enhancement.\n\n2. **Training-Stage Data Processing**:\n\n   * Includes data preparation and processing for pre-training and post-training stages (e.g., fine-tuning, supervised fine-tuning (SFT), instruction tuning, etc.).\n\n---\n\n### **Relevance Level Classification Criteria**\n\n* `\"strong\"`: The paper's primary contribution involves the design, construction, or processing of LLM training data\u2014for example, proposing a novel data pipeline, creating large-scale training data, or contributing new methods for improving data quality.\n* `\"weak\"`: The paper mentions data sources or preprocessing briefly in the background or experiments section, uses public datasets or existing tools, and does not propose new data-related methods.\n* `\"none\"`: The paper does not address any aspect of LLM training data collection, construction, or processing.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper id>\",\n      \"level\": \"strong | weak | none\",\n      \"reason\": \"A 1-2 sentence explanation citing key parts of the abstract or methodology that justify the classification\"\n    }\n    // More papers...\n  ]\n}\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new"
}